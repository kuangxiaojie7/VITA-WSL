{"time": 1766585047.467289, "phase": "train", "update": 1, "total_env_steps": 3200, "episode_reward": 0.07404029369354248, "value_loss": 0.9150926152865092, "policy_loss": -0.006465801208398148, "dist_entropy": 1.8906875769297282, "actor_grad_norm": 0.09636351466178894, "critic_grad_norm": 1.4849544763565063, "ratio": 0.999969482421875, "entropy": 1.8906875769297282, "incre_win_rate": 0.0, "step": 1}
{"time": 1766585062.4141998, "phase": "eval", "update": 1, "total_env_steps": 3200, "eval_win_rate": 0.0, "eval_episode_reward": 6.905790441176468, "step": 1}
{"time": 1766585066.9764566, "phase": "train", "update": 2, "total_env_steps": 6400, "episode_reward": 0.09304840862751007, "value_loss": 0.8691377401351928, "policy_loss": -0.005479164839364141, "dist_entropy": 1.935529645284017, "actor_grad_norm": 0.1011633574962616, "critic_grad_norm": 2.053809881210327, "ratio": 1.0013035535812378, "entropy": 1.935529645284017, "incre_win_rate": 0.0, "step": 2}
{"time": 1766585071.6277988, "phase": "train", "update": 3, "total_env_steps": 9600, "episode_reward": 0.09862975031137466, "value_loss": 0.3071656823158264, "policy_loss": -0.0040973541261790794, "dist_entropy": 1.9388420581817627, "actor_grad_norm": 0.07975783199071884, "critic_grad_norm": 1.6965888738632202, "ratio": 1.0001558065414429, "entropy": 1.9388420581817627, "incre_win_rate": 0.0, "step": 3}
{"time": 1766585076.16303, "phase": "train", "update": 4, "total_env_steps": 12800, "episode_reward": 0.1063694879412651, "value_loss": 0.18557965556780498, "policy_loss": -0.004968878237461786, "dist_entropy": 1.9171621640523275, "actor_grad_norm": 0.09646903723478317, "critic_grad_norm": 1.228956699371338, "ratio": 1.0002639293670654, "entropy": 1.9171621640523275, "incre_win_rate": 0.0, "step": 4}
{"time": 1766585080.7299054, "phase": "train", "update": 5, "total_env_steps": 16000, "episode_reward": 0.11139093339443207, "value_loss": 0.136564568678538, "policy_loss": -0.006602740636274736, "dist_entropy": 1.9100757519404092, "actor_grad_norm": 0.11624278128147125, "critic_grad_norm": 0.9420543313026428, "ratio": 1.0003156661987305, "entropy": 1.9100757519404092, "incre_win_rate": 0.0, "step": 5}
{"time": 1766585085.4233038, "phase": "train", "update": 6, "total_env_steps": 19200, "episode_reward": 0.11685739457607269, "value_loss": 0.11652107040087382, "policy_loss": -0.006298369377720784, "dist_entropy": 1.907923698425293, "actor_grad_norm": 0.09869550913572311, "critic_grad_norm": 0.7414912581443787, "ratio": 0.9998141527175903, "entropy": 1.907923698425293, "incre_win_rate": 0.0, "step": 6}
{"time": 1766585090.0079947, "phase": "train", "update": 7, "total_env_steps": 22400, "episode_reward": 0.12695926427841187, "value_loss": 0.10171842426061631, "policy_loss": -0.005806895722403797, "dist_entropy": 1.883287215232849, "actor_grad_norm": 0.08395297080278397, "critic_grad_norm": 0.7845261693000793, "ratio": 1.0003581047058105, "entropy": 1.883287215232849, "incre_win_rate": 0.0, "step": 7}
{"time": 1766585094.5863118, "phase": "train", "update": 8, "total_env_steps": 25600, "episode_reward": 0.1353507936000824, "value_loss": 0.0845576489965121, "policy_loss": -0.006751600701237473, "dist_entropy": 1.874124534924825, "actor_grad_norm": 0.09577576816082001, "critic_grad_norm": 0.43516603112220764, "ratio": 0.9989824295043945, "entropy": 1.874124534924825, "incre_win_rate": 0.0, "step": 8}
{"time": 1766585099.1684542, "phase": "train", "update": 9, "total_env_steps": 28800, "episode_reward": 0.1386197954416275, "value_loss": 0.06957222024599712, "policy_loss": -0.007444828997105901, "dist_entropy": 1.8755115350087483, "actor_grad_norm": 0.10090617090463638, "critic_grad_norm": 0.33541950583457947, "ratio": 0.9995660185813904, "entropy": 1.8755115350087483, "incre_win_rate": 0.0, "step": 9}
{"time": 1766585103.7495997, "phase": "train", "update": 10, "total_env_steps": 32000, "episode_reward": 0.14366576075553894, "value_loss": 0.07228065431118011, "policy_loss": -0.007861834434807235, "dist_entropy": 1.8644010543823242, "actor_grad_norm": 0.11797357350587845, "critic_grad_norm": 0.3015497922897339, "ratio": 0.9994634389877319, "entropy": 1.8644010543823242, "incre_win_rate": 0.0, "step": 10}
{"time": 1766585108.3124518, "phase": "train", "update": 11, "total_env_steps": 35200, "episode_reward": 0.14268840849399567, "value_loss": 0.06277363697687785, "policy_loss": -0.008570404034342498, "dist_entropy": 1.8491400798161826, "actor_grad_norm": 0.10241995751857758, "critic_grad_norm": 0.2231685072183609, "ratio": 1.0004446506500244, "entropy": 1.8491400798161826, "incre_win_rate": 0.0, "step": 11}
{"time": 1766585113.044701, "phase": "train", "update": 12, "total_env_steps": 38400, "episode_reward": 0.15030254423618317, "value_loss": 0.05956391220291456, "policy_loss": -0.008418191763919225, "dist_entropy": 1.8211312850316366, "actor_grad_norm": 0.1423773169517517, "critic_grad_norm": 0.21601517498493195, "ratio": 1.0005537271499634, "entropy": 1.8211312850316366, "incre_win_rate": 0.0, "step": 12}
{"time": 1766585117.6967192, "phase": "train", "update": 13, "total_env_steps": 41600, "episode_reward": 0.15678155422210693, "value_loss": 0.06748268827795982, "policy_loss": -0.007950809995204129, "dist_entropy": 1.7826505343119303, "actor_grad_norm": 0.12560313940048218, "critic_grad_norm": 0.20818349719047546, "ratio": 0.999813437461853, "entropy": 1.7826505343119303, "incre_win_rate": 0.0, "step": 13}
{"time": 1766585122.3019307, "phase": "train", "update": 14, "total_env_steps": 44800, "episode_reward": 0.16483074426651, "value_loss": 0.060586409519116084, "policy_loss": -0.00833448641583135, "dist_entropy": 1.7793866316477458, "actor_grad_norm": 0.1309061497449875, "critic_grad_norm": 0.2604507803916931, "ratio": 1.0000828504562378, "entropy": 1.7793866316477458, "incre_win_rate": 0.0, "step": 14}
{"time": 1766585126.8925865, "phase": "train", "update": 15, "total_env_steps": 48000, "episode_reward": 0.16411840915679932, "value_loss": 0.05240064983566602, "policy_loss": -0.008740890715383228, "dist_entropy": 1.7022515853246054, "actor_grad_norm": 0.13546310365200043, "critic_grad_norm": 0.12350285053253174, "ratio": 0.9996947050094604, "entropy": 1.7022515853246054, "incre_win_rate": 0.0, "step": 15}
{"time": 1766585131.5666997, "phase": "train", "update": 16, "total_env_steps": 51200, "episode_reward": 0.1821078509092331, "value_loss": 0.04296506742636363, "policy_loss": -0.00888445110654179, "dist_entropy": 1.6847841580708822, "actor_grad_norm": 0.1401803195476532, "critic_grad_norm": 0.10022086650133133, "ratio": 0.9986923336982727, "entropy": 1.6847841580708822, "incre_win_rate": 0.0, "step": 16}
{"time": 1766585136.293308, "phase": "train", "update": 17, "total_env_steps": 54400, "episode_reward": 0.1882781982421875, "value_loss": 0.04024887929360072, "policy_loss": -0.008343457133123403, "dist_entropy": 1.6525362332661946, "actor_grad_norm": 0.15193171799182892, "critic_grad_norm": 0.07249400019645691, "ratio": 0.9995587468147278, "entropy": 1.6525362332661946, "incre_win_rate": 0.0, "step": 17}
{"time": 1766585140.9832711, "phase": "train", "update": 18, "total_env_steps": 57600, "episode_reward": 0.18859298527240753, "value_loss": 0.04383164395888647, "policy_loss": -0.009604718385615147, "dist_entropy": 1.61498118241628, "actor_grad_norm": 0.14683598279953003, "critic_grad_norm": 0.07799628376960754, "ratio": 0.9999436736106873, "entropy": 1.61498118241628, "incre_win_rate": 0.0, "step": 18}
{"time": 1766585145.6113706, "phase": "train", "update": 19, "total_env_steps": 60800, "episode_reward": 0.1915709227323532, "value_loss": 0.042254664252201715, "policy_loss": -0.008945384187966946, "dist_entropy": 1.5727479139963785, "actor_grad_norm": 0.12574997544288635, "critic_grad_norm": 0.14167530834674835, "ratio": 1.0000146627426147, "entropy": 1.5727479139963785, "incre_win_rate": 0.0, "step": 19}
{"time": 1766585150.3499808, "phase": "train", "update": 20, "total_env_steps": 64000, "episode_reward": 0.18816867470741272, "value_loss": 0.04641770447293917, "policy_loss": -0.00875971158893331, "dist_entropy": 1.551633087793986, "actor_grad_norm": 0.1257438361644745, "critic_grad_norm": 0.09951525181531906, "ratio": 1.0003808736801147, "entropy": 1.551633087793986, "incre_win_rate": 0.0, "step": 20}
{"time": 1766585154.9628186, "phase": "train", "update": 21, "total_env_steps": 67200, "episode_reward": 0.1840088814496994, "value_loss": 0.04929342120885849, "policy_loss": -0.009137431955289103, "dist_entropy": 1.493781073888143, "actor_grad_norm": 0.11876631528139114, "critic_grad_norm": 0.1275346577167511, "ratio": 0.9994792342185974, "entropy": 1.493781073888143, "incre_win_rate": 0.0, "step": 21}
{"time": 1766585165.0826657, "phase": "eval", "update": 21, "total_env_steps": 67200, "eval_win_rate": 0.0, "eval_episode_reward": 11.4554993872549, "step": 21}
{"time": 1766585169.7846951, "phase": "train", "update": 22, "total_env_steps": 70400, "episode_reward": 0.21291132271289825, "value_loss": 0.04252602135141691, "policy_loss": -0.008742827556345152, "dist_entropy": 1.449869434038798, "actor_grad_norm": 0.10895136743783951, "critic_grad_norm": 0.12552200257778168, "ratio": 1.000260353088379, "entropy": 1.449869434038798, "incre_win_rate": 0.0, "step": 22}
{"time": 1766585174.4577155, "phase": "train", "update": 23, "total_env_steps": 73600, "episode_reward": 0.2111404836177826, "value_loss": 0.0364610825975736, "policy_loss": -0.009019322112323517, "dist_entropy": 1.424660356839498, "actor_grad_norm": 0.13980552554130554, "critic_grad_norm": 0.11226170510053635, "ratio": 0.9992588758468628, "entropy": 1.424660356839498, "incre_win_rate": 0.0, "step": 23}
{"time": 1766585179.0381296, "phase": "train", "update": 24, "total_env_steps": 76800, "episode_reward": 0.19695696234703064, "value_loss": 0.038833786050478616, "policy_loss": -0.009317779852894621, "dist_entropy": 1.3870810588200888, "actor_grad_norm": 0.12669023871421814, "critic_grad_norm": 0.09261021018028259, "ratio": 0.999268114566803, "entropy": 1.3870810588200888, "incre_win_rate": 0.0, "step": 24}
{"time": 1766585183.6283228, "phase": "train", "update": 25, "total_env_steps": 80000, "episode_reward": 0.2099793404340744, "value_loss": 0.03654346093535423, "policy_loss": -0.009638486919809413, "dist_entropy": 1.381420914332072, "actor_grad_norm": 0.15730196237564087, "critic_grad_norm": 0.08179807662963867, "ratio": 1.0000412464141846, "entropy": 1.381420914332072, "incre_win_rate": 0.0, "step": 25}
{"time": 1766585188.1929903, "phase": "train", "update": 26, "total_env_steps": 83200, "episode_reward": 0.2125275880098343, "value_loss": 0.04003949736555417, "policy_loss": -0.011529769966810158, "dist_entropy": 1.3512954473495484, "actor_grad_norm": 0.15804311633110046, "critic_grad_norm": 0.20025724172592163, "ratio": 0.9993014335632324, "entropy": 1.3512954473495484, "incre_win_rate": 0.0, "step": 26}
{"time": 1766585192.8211231, "phase": "train", "update": 27, "total_env_steps": 86400, "episode_reward": 0.2209482491016388, "value_loss": 0.03401488761107127, "policy_loss": -0.00932334568052653, "dist_entropy": 1.3166749954223633, "actor_grad_norm": 0.15481878817081451, "critic_grad_norm": 0.08252878487110138, "ratio": 1.000414252281189, "entropy": 1.3166749954223633, "incre_win_rate": 0.0, "step": 27}
{"time": 1766585197.4655747, "phase": "train", "update": 28, "total_env_steps": 89600, "episode_reward": 0.2156311273574829, "value_loss": 0.03343510131041209, "policy_loss": -0.009658380846491354, "dist_entropy": 1.3009852568308513, "actor_grad_norm": 0.13702832162380219, "critic_grad_norm": 0.08147569745779037, "ratio": 1.0000847578048706, "entropy": 1.3009852568308513, "incre_win_rate": 0.0, "step": 28}
{"time": 1766585202.0634904, "phase": "train", "update": 29, "total_env_steps": 92800, "episode_reward": 0.2227650135755539, "value_loss": 0.03442357853055, "policy_loss": -0.01039326861841611, "dist_entropy": 1.2810108025868734, "actor_grad_norm": 0.1391535848379135, "critic_grad_norm": 0.07120300829410553, "ratio": 0.9984480142593384, "entropy": 1.2810108025868734, "incre_win_rate": 0.0, "step": 29}
{"time": 1766585206.656269, "phase": "train", "update": 30, "total_env_steps": 96000, "episode_reward": 0.22203661501407623, "value_loss": 0.03440337032079697, "policy_loss": -0.01139481019670517, "dist_entropy": 1.2367999076843261, "actor_grad_norm": 0.1792600452899933, "critic_grad_norm": 0.14013338088989258, "ratio": 0.9995319843292236, "entropy": 1.2367999076843261, "incre_win_rate": 0.0, "step": 30}
{"time": 1766585211.5997577, "phase": "train", "update": 31, "total_env_steps": 99200, "episode_reward": 0.22940410673618317, "value_loss": 0.039540560295184456, "policy_loss": -0.01022552987401042, "dist_entropy": 1.2327085336049397, "actor_grad_norm": 0.15938183665275574, "critic_grad_norm": 0.09330733865499496, "ratio": 1.0001308917999268, "entropy": 1.2327085336049397, "incre_win_rate": 0.014285714285714285, "step": 31}
{"time": 1766585216.690132, "phase": "train", "update": 32, "total_env_steps": 102400, "episode_reward": 0.23638328909873962, "value_loss": 0.029884730031092963, "policy_loss": -0.010856757959042692, "dist_entropy": 1.2157931327819824, "actor_grad_norm": 0.14586171507835388, "critic_grad_norm": 0.07183187454938889, "ratio": 0.9982662796974182, "entropy": 1.2157931327819824, "incre_win_rate": 0.0, "step": 32}
{"time": 1766585221.6021695, "phase": "train", "update": 33, "total_env_steps": 105600, "episode_reward": 0.23122090101242065, "value_loss": 0.03377406100432078, "policy_loss": -0.010637049995493204, "dist_entropy": 1.1775159200032552, "actor_grad_norm": 0.1362277716398239, "critic_grad_norm": 0.04887472465634346, "ratio": 0.999249279499054, "entropy": 1.1775159200032552, "incre_win_rate": 0.0, "step": 33}
{"time": 1766585226.4392414, "phase": "train", "update": 34, "total_env_steps": 108800, "episode_reward": 0.23114584386348724, "value_loss": 0.03010676900545756, "policy_loss": -0.010432488945217007, "dist_entropy": 1.169944461186727, "actor_grad_norm": 0.1614416390657425, "critic_grad_norm": 0.10432929545640945, "ratio": 0.9990745782852173, "entropy": 1.169944461186727, "incre_win_rate": 0.0, "step": 34}
{"time": 1766585231.2179885, "phase": "train", "update": 35, "total_env_steps": 112000, "episode_reward": 0.2306908816099167, "value_loss": 0.04835297912359238, "policy_loss": -0.010302676132161064, "dist_entropy": 1.1399381717046102, "actor_grad_norm": 0.13205331563949585, "critic_grad_norm": 0.11591115593910217, "ratio": 1.0000888109207153, "entropy": 1.1399381717046102, "incre_win_rate": 0.06060606060606061, "step": 35}
{"time": 1766585236.0492063, "phase": "train", "update": 36, "total_env_steps": 115200, "episode_reward": 0.24376608431339264, "value_loss": 0.041681646804014844, "policy_loss": -0.010899094126985176, "dist_entropy": 1.1259743690490722, "actor_grad_norm": 0.13787893950939178, "critic_grad_norm": 0.0881645455956459, "ratio": 0.9999802112579346, "entropy": 1.1259743690490722, "incre_win_rate": 0.03076923076923077, "step": 36}
{"time": 1766585240.9216456, "phase": "train", "update": 37, "total_env_steps": 118400, "episode_reward": 0.23993031680583954, "value_loss": 0.041785225520531336, "policy_loss": -0.011191208608450864, "dist_entropy": 1.0971464157104491, "actor_grad_norm": 0.15079377591609955, "critic_grad_norm": 0.052083570510149, "ratio": 0.9999041557312012, "entropy": 1.0971464157104491, "incre_win_rate": 0.014925373134328358, "step": 37}
{"time": 1766585245.5633914, "phase": "train", "update": 38, "total_env_steps": 121600, "episode_reward": 0.23649510741233826, "value_loss": 0.0282121063520511, "policy_loss": -0.010245630040440027, "dist_entropy": 1.0807295401891073, "actor_grad_norm": 0.15923628211021423, "critic_grad_norm": 0.0910368263721466, "ratio": 1.000319480895996, "entropy": 1.0807295401891073, "incre_win_rate": 0.0, "step": 38}
{"time": 1766585250.2045765, "phase": "train", "update": 39, "total_env_steps": 124800, "episode_reward": 0.23841223120689392, "value_loss": 0.03102040874461333, "policy_loss": -0.011319464450012381, "dist_entropy": 1.0719178120295207, "actor_grad_norm": 0.15177281200885773, "critic_grad_norm": 0.07810438424348831, "ratio": 1.0001275539398193, "entropy": 1.0719178120295207, "incre_win_rate": 0.015151515151515152, "step": 39}
{"time": 1766585254.8395758, "phase": "train", "update": 40, "total_env_steps": 128000, "episode_reward": 0.2289169728755951, "value_loss": 0.042646571745475134, "policy_loss": -0.010752975604799058, "dist_entropy": 1.0553221702575684, "actor_grad_norm": 0.14980417490005493, "critic_grad_norm": 0.08545739948749542, "ratio": 0.9993329644203186, "entropy": 1.0553221702575684, "incre_win_rate": 0.04838709677419355, "step": 40}
{"time": 1766585259.4908571, "phase": "train", "update": 41, "total_env_steps": 131200, "episode_reward": 0.25505131483078003, "value_loss": 0.03318061778942744, "policy_loss": -0.010474893612043464, "dist_entropy": 1.064064327875773, "actor_grad_norm": 0.12796542048454285, "critic_grad_norm": 0.06962016224861145, "ratio": 0.9987785220146179, "entropy": 1.064064327875773, "incre_win_rate": 0.014705882352941176, "step": 41}
{"time": 1766585266.368613, "phase": "eval", "update": 41, "total_env_steps": 131200, "eval_win_rate": 0.28125, "eval_episode_reward": 14.726945465686274, "step": 41}
{"time": 1766585270.9285038, "phase": "train", "update": 42, "total_env_steps": 134400, "episode_reward": 0.24737900495529175, "value_loss": 0.042814015348752336, "policy_loss": -0.0107453840540462, "dist_entropy": 1.0288326263427734, "actor_grad_norm": 0.13866351544857025, "critic_grad_norm": 0.10530748963356018, "ratio": 0.9995396137237549, "entropy": 1.0288326263427734, "incre_win_rate": 0.0625, "step": 42}
{"time": 1766585275.4453075, "phase": "train", "update": 43, "total_env_steps": 137600, "episode_reward": 0.24548408389091492, "value_loss": 0.04469756111502647, "policy_loss": -0.010845647632064725, "dist_entropy": 1.0161539793014527, "actor_grad_norm": 0.18594515323638916, "critic_grad_norm": 0.08761732280254364, "ratio": 0.9992988705635071, "entropy": 1.0161539793014527, "incre_win_rate": 0.1, "step": 43}
{"time": 1766585279.9626966, "phase": "train", "update": 44, "total_env_steps": 140800, "episode_reward": 0.2268121987581253, "value_loss": 0.047843021402756376, "policy_loss": -0.010880804048841834, "dist_entropy": 1.0035376985867819, "actor_grad_norm": 0.16689647734165192, "critic_grad_norm": 0.06320264935493469, "ratio": 0.9995458722114563, "entropy": 1.0035376985867819, "incre_win_rate": 0.0847457627118644, "step": 44}
{"time": 1766585284.481289, "phase": "train", "update": 45, "total_env_steps": 144000, "episode_reward": 0.2412101775407791, "value_loss": 0.03484143043557803, "policy_loss": -0.010476106717207282, "dist_entropy": 1.0021482865015665, "actor_grad_norm": 0.1803603619337082, "critic_grad_norm": 0.10470867902040482, "ratio": 0.9999601244926453, "entropy": 1.0021482865015665, "incre_win_rate": 0.029411764705882353, "step": 45}
{"time": 1766585289.0475793, "phase": "train", "update": 46, "total_env_steps": 147200, "episode_reward": 0.2482399046421051, "value_loss": 0.03522020702560743, "policy_loss": -0.010203459175057598, "dist_entropy": 0.9824602047602335, "actor_grad_norm": 0.17900843918323517, "critic_grad_norm": 0.07169268280267715, "ratio": 0.9992780685424805, "entropy": 0.9824602047602335, "incre_win_rate": 0.03225806451612903, "step": 46}
{"time": 1766585293.6648712, "phase": "train", "update": 47, "total_env_steps": 150400, "episode_reward": 0.257331520318985, "value_loss": 0.031809454411268236, "policy_loss": -0.010715775437776168, "dist_entropy": 0.9531728148460388, "actor_grad_norm": 0.17485713958740234, "critic_grad_norm": 0.08655650168657303, "ratio": 0.9996324777603149, "entropy": 0.9531728148460388, "incre_win_rate": 0.07462686567164178, "step": 47}
{"time": 1766585298.231104, "phase": "train", "update": 48, "total_env_steps": 153600, "episode_reward": 0.23468369245529175, "value_loss": 0.039772921800613405, "policy_loss": -0.011305181523614276, "dist_entropy": 0.9358990470568339, "actor_grad_norm": 0.17589834332466125, "critic_grad_norm": 0.051733147352933884, "ratio": 0.9993075132369995, "entropy": 0.9358990470568339, "incre_win_rate": 0.06557377049180328, "step": 48}
{"time": 1766585302.7349417, "phase": "train", "update": 49, "total_env_steps": 156800, "episode_reward": 0.25645604729652405, "value_loss": 0.04604276393850645, "policy_loss": -0.009743485662873634, "dist_entropy": 0.9141653935114543, "actor_grad_norm": 0.17049042880535126, "critic_grad_norm": 0.21708081662654877, "ratio": 0.9988437294960022, "entropy": 0.9141653935114543, "incre_win_rate": 0.1111111111111111, "step": 49}
{"time": 1766585307.2627215, "phase": "train", "update": 50, "total_env_steps": 160000, "episode_reward": 0.25354090332984924, "value_loss": 0.03843174874782562, "policy_loss": -0.01007025699009514, "dist_entropy": 0.9174475948015849, "actor_grad_norm": 0.21504157781600952, "critic_grad_norm": 0.07491642981767654, "ratio": 0.999367892742157, "entropy": 0.9174475948015849, "incre_win_rate": 0.07692307692307693, "step": 50}
{"time": 1766585311.7537534, "phase": "train", "update": 51, "total_env_steps": 163200, "episode_reward": 0.2635761499404907, "value_loss": 0.05335508460799853, "policy_loss": -0.010205691489563289, "dist_entropy": 0.8968443989753723, "actor_grad_norm": 0.17892155051231384, "critic_grad_norm": 0.10773253440856934, "ratio": 0.998984158039093, "entropy": 0.8968443989753723, "incre_win_rate": 0.140625, "step": 51}
{"time": 1766585316.3046465, "phase": "train", "update": 52, "total_env_steps": 166400, "episode_reward": 0.252192884683609, "value_loss": 0.042549304415782294, "policy_loss": -0.011229359396049195, "dist_entropy": 0.8894773920377096, "actor_grad_norm": 0.18352662026882172, "critic_grad_norm": 0.24585798382759094, "ratio": 0.9980981945991516, "entropy": 0.8894773920377096, "incre_win_rate": 0.0967741935483871, "step": 52}
{"time": 1766585320.8490798, "phase": "train", "update": 53, "total_env_steps": 169600, "episode_reward": 0.2624816298484802, "value_loss": 0.0464684434235096, "policy_loss": -0.011233003860016548, "dist_entropy": 0.874877683321635, "actor_grad_norm": 0.20447468757629395, "critic_grad_norm": 0.1697627753019333, "ratio": 0.9976012706756592, "entropy": 0.874877683321635, "incre_win_rate": 0.18032786885245902, "step": 53}
{"time": 1766585325.3621597, "phase": "train", "update": 54, "total_env_steps": 172800, "episode_reward": 0.2607743442058563, "value_loss": 0.03727486878633499, "policy_loss": -0.011594682343406267, "dist_entropy": 0.8615993539492289, "actor_grad_norm": 0.14536096155643463, "critic_grad_norm": 0.12959568202495575, "ratio": 0.999160647392273, "entropy": 0.8615993539492289, "incre_win_rate": 0.08064516129032258, "step": 54}
{"time": 1766585329.8761363, "phase": "train", "update": 55, "total_env_steps": 176000, "episode_reward": 0.2535194456577301, "value_loss": 0.03389418919881185, "policy_loss": -0.010705353575010198, "dist_entropy": 0.8462592959403992, "actor_grad_norm": 0.14348725974559784, "critic_grad_norm": 0.0853036642074585, "ratio": 1.0005879402160645, "entropy": 0.8462592959403992, "incre_win_rate": 0.1111111111111111, "step": 55}
{"time": 1766585334.4208424, "phase": "train", "update": 56, "total_env_steps": 179200, "episode_reward": 0.2639223337173462, "value_loss": 0.03806933512290319, "policy_loss": -0.011443853708314222, "dist_entropy": 0.8416533946990967, "actor_grad_norm": 0.1907479614019394, "critic_grad_norm": 0.040660396218299866, "ratio": 0.9981848001480103, "entropy": 0.8416533946990967, "incre_win_rate": 0.13114754098360656, "step": 56}
{"time": 1766585338.9452076, "phase": "train", "update": 57, "total_env_steps": 182400, "episode_reward": 0.2664836049079895, "value_loss": 0.052533222983280815, "policy_loss": -0.011504494908876624, "dist_entropy": 0.8166643460591634, "actor_grad_norm": 0.19482900202274323, "critic_grad_norm": 0.05850044637918472, "ratio": 0.9989308714866638, "entropy": 0.8166643460591634, "incre_win_rate": 0.16129032258064516, "step": 57}
{"time": 1766585343.434674, "phase": "train", "update": 58, "total_env_steps": 185600, "episode_reward": 0.2709987759590149, "value_loss": 0.039199622720479964, "policy_loss": -0.011136910907932791, "dist_entropy": 0.7972838242848714, "actor_grad_norm": 0.16093021631240845, "critic_grad_norm": 0.053396761417388916, "ratio": 0.99878990650177, "entropy": 0.7972838242848714, "incre_win_rate": 0.23333333333333334, "step": 58}
{"time": 1766585347.9780602, "phase": "train", "update": 59, "total_env_steps": 188800, "episode_reward": 0.27311885356903076, "value_loss": 0.041999864081541695, "policy_loss": -0.010281794577769196, "dist_entropy": 0.7918166359265645, "actor_grad_norm": 0.20721876621246338, "critic_grad_norm": 0.0986122414469719, "ratio": 0.9995597004890442, "entropy": 0.7918166359265645, "incre_win_rate": 0.14285714285714285, "step": 59}
{"time": 1766585352.4832637, "phase": "train", "update": 60, "total_env_steps": 192000, "episode_reward": 0.2786121666431427, "value_loss": 0.044715660313765206, "policy_loss": -0.010430951828813824, "dist_entropy": 0.7816806634267172, "actor_grad_norm": 0.16578805446624756, "critic_grad_norm": 0.05623271316289902, "ratio": 0.9999560117721558, "entropy": 0.7816806634267172, "incre_win_rate": 0.1774193548387097, "step": 60}
{"time": 1766585356.9162326, "phase": "train", "update": 61, "total_env_steps": 195200, "episode_reward": 0.2637055516242981, "value_loss": 0.03416271060705185, "policy_loss": -0.011462271416523133, "dist_entropy": 0.779317581653595, "actor_grad_norm": 0.15727369487285614, "critic_grad_norm": 0.04158109426498413, "ratio": 0.9995455145835876, "entropy": 0.779317581653595, "incre_win_rate": 0.13333333333333333, "step": 61}
{"time": 1766585364.0145588, "phase": "eval", "update": 61, "total_env_steps": 195200, "eval_win_rate": 0.1875, "eval_episode_reward": 14.884267769607845, "step": 61}
{"time": 1766585368.5328424, "phase": "train", "update": 62, "total_env_steps": 198400, "episode_reward": 0.27848193049430847, "value_loss": 0.0381391612191995, "policy_loss": -0.010393876513637679, "dist_entropy": 0.7680203239123027, "actor_grad_norm": 0.137939915060997, "critic_grad_norm": 0.08931382745504379, "ratio": 0.9990100860595703, "entropy": 0.7680203239123027, "incre_win_rate": 0.125, "step": 62}
{"time": 1766585373.023733, "phase": "train", "update": 63, "total_env_steps": 201600, "episode_reward": 0.27404794096946716, "value_loss": 0.03755225737889608, "policy_loss": -0.010701931822789135, "dist_entropy": 0.7726256887118021, "actor_grad_norm": 0.19442224502563477, "critic_grad_norm": 0.06426553428173065, "ratio": 1.0000923871994019, "entropy": 0.7726256887118021, "incre_win_rate": 0.25862068965517243, "step": 63}
{"time": 1766585377.5499704, "phase": "train", "update": 64, "total_env_steps": 204800, "episode_reward": 0.2885148823261261, "value_loss": 0.04003738164901734, "policy_loss": -0.010276578270958936, "dist_entropy": 0.7302800854047139, "actor_grad_norm": 0.17093200981616974, "critic_grad_norm": 0.04699067398905754, "ratio": 0.9994221329689026, "entropy": 0.7302800854047139, "incre_win_rate": 0.25, "step": 64}
{"time": 1766585382.0341113, "phase": "train", "update": 65, "total_env_steps": 208000, "episode_reward": 0.26892080903053284, "value_loss": 0.04639504998922348, "policy_loss": -0.010477127899698738, "dist_entropy": 0.7517837444941203, "actor_grad_norm": 0.2292078733444214, "critic_grad_norm": 0.05430879071354866, "ratio": 0.9995136857032776, "entropy": 0.7517837444941203, "incre_win_rate": 0.18461538461538463, "step": 65}
{"time": 1766585386.5598235, "phase": "train", "update": 66, "total_env_steps": 211200, "episode_reward": 0.2780231237411499, "value_loss": 0.038463856528202695, "policy_loss": -0.010789451510103258, "dist_entropy": 0.7643420179684957, "actor_grad_norm": 0.20361216366291046, "critic_grad_norm": 0.08098330348730087, "ratio": 0.9994565844535828, "entropy": 0.7643420179684957, "incre_win_rate": 0.21311475409836064, "step": 66}
{"time": 1766585391.0848606, "phase": "train", "update": 67, "total_env_steps": 214400, "episode_reward": 0.28597351908683777, "value_loss": 0.039330522219340004, "policy_loss": -0.009777679294024939, "dist_entropy": 0.7513828674952189, "actor_grad_norm": 0.14340442419052124, "critic_grad_norm": 0.13568183779716492, "ratio": 0.9998907446861267, "entropy": 0.7513828674952189, "incre_win_rate": 0.3508771929824561, "step": 67}
{"time": 1766585395.571245, "phase": "train", "update": 68, "total_env_steps": 217600, "episode_reward": 0.2653079330921173, "value_loss": 0.04037932232022286, "policy_loss": -0.011749244498056062, "dist_entropy": 0.7558074633280436, "actor_grad_norm": 0.2747316062450409, "critic_grad_norm": 0.1380476951599121, "ratio": 1.000261664390564, "entropy": 0.7558074633280436, "incre_win_rate": 0.20689655172413793, "step": 68}
{"time": 1766585400.0738504, "phase": "train", "update": 69, "total_env_steps": 220800, "episode_reward": 0.2769378125667572, "value_loss": 0.03833188712596893, "policy_loss": -0.010913345070486713, "dist_entropy": 0.7147734443346659, "actor_grad_norm": 0.23716095089912415, "critic_grad_norm": 0.07237280160188675, "ratio": 0.9983275532722473, "entropy": 0.7147734443346659, "incre_win_rate": 0.20634920634920634, "step": 69}
{"time": 1766585404.5887878, "phase": "train", "update": 70, "total_env_steps": 224000, "episode_reward": 0.2795596122741699, "value_loss": 0.03837355275948842, "policy_loss": -0.010734964452946845, "dist_entropy": 0.740833596388499, "actor_grad_norm": 0.18269458413124084, "critic_grad_norm": 0.14810924232006073, "ratio": 0.998497724533081, "entropy": 0.740833596388499, "incre_win_rate": 0.2711864406779661, "step": 70}
{"time": 1766585409.1170871, "phase": "train", "update": 71, "total_env_steps": 227200, "episode_reward": 0.25823989510536194, "value_loss": 0.03436902140577634, "policy_loss": -0.011610924266960627, "dist_entropy": 0.7289401412010192, "actor_grad_norm": 0.2226143330335617, "critic_grad_norm": 0.07125357538461685, "ratio": 0.9993132948875427, "entropy": 0.7289401412010192, "incre_win_rate": 0.2545454545454545, "step": 71}
{"time": 1766585413.5814314, "phase": "train", "update": 72, "total_env_steps": 230400, "episode_reward": 0.2677558362483978, "value_loss": 0.03445218106110891, "policy_loss": -0.011062504595855433, "dist_entropy": 0.7075472076733907, "actor_grad_norm": 0.2520652115345001, "critic_grad_norm": 0.05624698847532272, "ratio": 0.9986517429351807, "entropy": 0.7075472076733907, "incre_win_rate": 0.19672131147540983, "step": 72}
{"time": 1766585418.058201, "phase": "train", "update": 73, "total_env_steps": 233600, "episode_reward": 0.2790272831916809, "value_loss": 0.04047014067570368, "policy_loss": -0.010956473418014904, "dist_entropy": 0.7105079571406047, "actor_grad_norm": 0.1758928894996643, "critic_grad_norm": 0.08815973997116089, "ratio": 0.9995072484016418, "entropy": 0.7105079571406047, "incre_win_rate": 0.2786885245901639, "step": 73}
{"time": 1766585422.487292, "phase": "train", "update": 74, "total_env_steps": 236800, "episode_reward": 0.26745402812957764, "value_loss": 0.03410943945248922, "policy_loss": -0.0111455494217779, "dist_entropy": 0.7130906144777934, "actor_grad_norm": 0.24307774007320404, "critic_grad_norm": 0.04238555207848549, "ratio": 1.000771403312683, "entropy": 0.7130906144777934, "incre_win_rate": 0.32727272727272727, "step": 74}
{"time": 1766585426.9922287, "phase": "train", "update": 75, "total_env_steps": 240000, "episode_reward": 0.2817493975162506, "value_loss": 0.035738271474838254, "policy_loss": -0.009288927297600698, "dist_entropy": 0.69415762424469, "actor_grad_norm": 0.22046642005443573, "critic_grad_norm": 0.07709947228431702, "ratio": 0.9998221397399902, "entropy": 0.69415762424469, "incre_win_rate": 0.20967741935483872, "step": 75}
{"time": 1766585431.5518174, "phase": "train", "update": 76, "total_env_steps": 243200, "episode_reward": 0.26815488934516907, "value_loss": 0.03693439240256945, "policy_loss": -0.01054385082010943, "dist_entropy": 0.7064824899037679, "actor_grad_norm": 0.29960834980010986, "critic_grad_norm": 0.03769683465361595, "ratio": 0.9994399547576904, "entropy": 0.7064824899037679, "incre_win_rate": 0.22033898305084745, "step": 76}
{"time": 1766585436.0587595, "phase": "train", "update": 77, "total_env_steps": 246400, "episode_reward": 0.29224342107772827, "value_loss": 0.03994803378979365, "policy_loss": -0.01084277580174889, "dist_entropy": 0.7043282628059387, "actor_grad_norm": 0.21196924149990082, "critic_grad_norm": 0.12624911963939667, "ratio": 0.9988853931427002, "entropy": 0.7043282628059387, "incre_win_rate": 0.3620689655172414, "step": 77}
{"time": 1766585440.5471578, "phase": "train", "update": 78, "total_env_steps": 249600, "episode_reward": 0.2668520510196686, "value_loss": 0.04102868189414342, "policy_loss": -0.01115838978755761, "dist_entropy": 0.7193794250488281, "actor_grad_norm": 0.2567114531993866, "critic_grad_norm": 0.15615426003932953, "ratio": 1.0002998113632202, "entropy": 0.7193794250488281, "incre_win_rate": 0.2631578947368421, "step": 78}
{"time": 1766585445.1486676, "phase": "train", "update": 79, "total_env_steps": 252800, "episode_reward": 0.2915809154510498, "value_loss": 0.041796297580003736, "policy_loss": -0.00994970304236702, "dist_entropy": 0.6904363552729289, "actor_grad_norm": 0.18095290660858154, "critic_grad_norm": 0.07326753437519073, "ratio": 0.9992231726646423, "entropy": 0.6904363552729289, "incre_win_rate": 0.4, "step": 79}
{"time": 1766585449.5779083, "phase": "train", "update": 80, "total_env_steps": 256000, "episode_reward": 0.2697288691997528, "value_loss": 0.02972532610098521, "policy_loss": -0.010257090686148728, "dist_entropy": 0.6908611377080282, "actor_grad_norm": 0.1809704750776291, "critic_grad_norm": 0.07587043195962906, "ratio": 1.0003570318222046, "entropy": 0.6908611377080282, "incre_win_rate": 0.24561403508771928, "step": 80}
{"time": 1766585454.0765452, "phase": "train", "update": 81, "total_env_steps": 259200, "episode_reward": 0.2892425060272217, "value_loss": 0.032459425553679463, "policy_loss": -0.00961357401536939, "dist_entropy": 0.6889816959698994, "actor_grad_norm": 0.17519882321357727, "critic_grad_norm": 0.03670130670070648, "ratio": 0.9996533393859863, "entropy": 0.6889816959698994, "incre_win_rate": 0.29508196721311475, "step": 81}
{"time": 1766585461.2730763, "phase": "eval", "update": 81, "total_env_steps": 259200, "eval_win_rate": 0.59375, "eval_episode_reward": 17.35998774509804, "step": 81}
{"time": 1766585465.789509, "phase": "train", "update": 82, "total_env_steps": 262400, "episode_reward": 0.28172487020492554, "value_loss": 0.027898917595545452, "policy_loss": -0.00993727434684691, "dist_entropy": 0.6523849765459696, "actor_grad_norm": 0.1409069150686264, "critic_grad_norm": 0.04145245626568794, "ratio": 0.9991960525512695, "entropy": 0.6523849765459696, "incre_win_rate": 0.25, "step": 82}
{"time": 1766585470.3615472, "phase": "train", "update": 83, "total_env_steps": 265600, "episode_reward": 0.29398438334465027, "value_loss": 0.02916640155017376, "policy_loss": -0.01002149468030827, "dist_entropy": 0.698498006661733, "actor_grad_norm": 0.18948118388652802, "critic_grad_norm": 0.09023119509220123, "ratio": 0.9986729025840759, "entropy": 0.698498006661733, "incre_win_rate": 0.3620689655172414, "step": 83}
{"time": 1766585474.8150523, "phase": "train", "update": 84, "total_env_steps": 268800, "episode_reward": 0.27572381496429443, "value_loss": 0.030936686818798385, "policy_loss": -0.010682171691097626, "dist_entropy": 0.7021237929662069, "actor_grad_norm": 0.1778680384159088, "critic_grad_norm": 0.05320803448557854, "ratio": 1.0004174709320068, "entropy": 0.7021237929662069, "incre_win_rate": 0.3103448275862069, "step": 84}
{"time": 1766585479.3150947, "phase": "train", "update": 85, "total_env_steps": 272000, "episode_reward": 0.30758196115493774, "value_loss": 0.033702495197455086, "policy_loss": -0.010607098611169855, "dist_entropy": 0.677359938621521, "actor_grad_norm": 0.21987897157669067, "critic_grad_norm": 0.03601595014333725, "ratio": 0.9991856813430786, "entropy": 0.677359938621521, "incre_win_rate": 0.4576271186440678, "step": 85}
{"time": 1766585483.8323274, "phase": "train", "update": 86, "total_env_steps": 275200, "episode_reward": 0.2730882465839386, "value_loss": 0.028535377110044162, "policy_loss": -0.010335120455455165, "dist_entropy": 0.6922851959864299, "actor_grad_norm": 0.17682109773159027, "critic_grad_norm": 0.046992167830467224, "ratio": 0.9987208843231201, "entropy": 0.6922851959864299, "incre_win_rate": 0.2982456140350877, "step": 86}
{"time": 1766585488.2709944, "phase": "train", "update": 87, "total_env_steps": 278400, "episode_reward": 0.2739407420158386, "value_loss": 0.029031699399153392, "policy_loss": -0.01014677566946703, "dist_entropy": 0.6805188298225403, "actor_grad_norm": 0.1594250351190567, "critic_grad_norm": 0.1082477867603302, "ratio": 0.9999750852584839, "entropy": 0.6805188298225403, "incre_win_rate": 0.2631578947368421, "step": 87}
{"time": 1766585492.794451, "phase": "train", "update": 88, "total_env_steps": 281600, "episode_reward": 0.27467602491378784, "value_loss": 0.031053303803006808, "policy_loss": -0.011873846455066773, "dist_entropy": 0.6839121659596761, "actor_grad_norm": 0.19715382158756256, "critic_grad_norm": 0.15301629900932312, "ratio": 0.9988692402839661, "entropy": 0.6839121659596761, "incre_win_rate": 0.4444444444444444, "step": 88}
{"time": 1766585497.3454103, "phase": "train", "update": 89, "total_env_steps": 284800, "episode_reward": 0.29338082671165466, "value_loss": 0.026731557150681814, "policy_loss": -0.01118421574471095, "dist_entropy": 0.676199471950531, "actor_grad_norm": 0.15043942630290985, "critic_grad_norm": 0.11079223453998566, "ratio": 0.9987688660621643, "entropy": 0.676199471950531, "incre_win_rate": 0.44642857142857145, "step": 89}
{"time": 1766585502.0662208, "phase": "train", "update": 90, "total_env_steps": 288000, "episode_reward": 0.28327131271362305, "value_loss": 0.02882804547746976, "policy_loss": -0.011990071798035256, "dist_entropy": 0.6865326444307963, "actor_grad_norm": 0.15742574632167816, "critic_grad_norm": 0.06018929183483124, "ratio": 0.9998103976249695, "entropy": 0.6865326444307963, "incre_win_rate": 0.3793103448275862, "step": 90}
{"time": 1766585506.5501966, "phase": "train", "update": 91, "total_env_steps": 291200, "episode_reward": 0.27910616993904114, "value_loss": 0.025997820124030114, "policy_loss": -0.010299069423564334, "dist_entropy": 0.6618752400080363, "actor_grad_norm": 0.20504477620124817, "critic_grad_norm": 0.060395531356334686, "ratio": 1.0004535913467407, "entropy": 0.6618752400080363, "incre_win_rate": 0.25862068965517243, "step": 91}
{"time": 1766585511.1521022, "phase": "train", "update": 92, "total_env_steps": 294400, "episode_reward": 0.30027270317077637, "value_loss": 0.027756322051088016, "policy_loss": -0.010323181303170751, "dist_entropy": 0.6520565152168274, "actor_grad_norm": 0.16374064981937408, "critic_grad_norm": 0.05219466611742973, "ratio": 1.0003759860992432, "entropy": 0.6520565152168274, "incre_win_rate": 0.4576271186440678, "step": 92}
{"time": 1766585515.6948755, "phase": "train", "update": 93, "total_env_steps": 297600, "episode_reward": 0.2936136722564697, "value_loss": 0.026317278668284417, "policy_loss": -0.01036696368003452, "dist_entropy": 0.6414066433906556, "actor_grad_norm": 0.19739384949207306, "critic_grad_norm": 0.11915803700685501, "ratio": 0.9987660050392151, "entropy": 0.6414066433906556, "incre_win_rate": 0.45614035087719296, "step": 93}
{"time": 1766585520.2333412, "phase": "train", "update": 94, "total_env_steps": 300800, "episode_reward": 0.296114444732666, "value_loss": 0.025573810065786042, "policy_loss": -0.010483561142624432, "dist_entropy": 0.6709328810373942, "actor_grad_norm": 0.26429101824760437, "critic_grad_norm": 0.05047379434108734, "ratio": 0.999915361404419, "entropy": 0.6709328810373942, "incre_win_rate": 0.43859649122807015, "step": 94}
{"time": 1766585524.7700026, "phase": "train", "update": 95, "total_env_steps": 304000, "episode_reward": 0.3043390214443207, "value_loss": 0.02355579249560833, "policy_loss": -0.010128644204520192, "dist_entropy": 0.6422138889630635, "actor_grad_norm": 0.214009627699852, "critic_grad_norm": 0.043697260320186615, "ratio": 0.9998449087142944, "entropy": 0.6422138889630635, "incre_win_rate": 0.4915254237288136, "step": 95}
{"time": 1766585529.2849863, "phase": "train", "update": 96, "total_env_steps": 307200, "episode_reward": 0.3051868975162506, "value_loss": 0.025083374232053757, "policy_loss": -0.011489068074654796, "dist_entropy": 0.6579402645428976, "actor_grad_norm": 0.17106853425502777, "critic_grad_norm": 0.035055480897426605, "ratio": 0.9994444251060486, "entropy": 0.6579402645428976, "incre_win_rate": 0.5818181818181818, "step": 96}
{"time": 1766585533.733165, "phase": "train", "update": 97, "total_env_steps": 310400, "episode_reward": 0.2853148281574249, "value_loss": 0.026836127415299414, "policy_loss": -0.01083112058108521, "dist_entropy": 0.6252256711324056, "actor_grad_norm": 0.1660957783460617, "critic_grad_norm": 0.03010806441307068, "ratio": 1.0000567436218262, "entropy": 0.6252256711324056, "incre_win_rate": 0.45454545454545453, "step": 97}
{"time": 1766585538.2848635, "phase": "train", "update": 98, "total_env_steps": 313600, "episode_reward": 0.31572920083999634, "value_loss": 0.02508112316330274, "policy_loss": -0.009477954582883778, "dist_entropy": 0.6203693350156149, "actor_grad_norm": 0.1892213672399521, "critic_grad_norm": 0.08787844330072403, "ratio": 0.9988722801208496, "entropy": 0.6203693350156149, "incre_win_rate": 0.6140350877192983, "step": 98}
{"time": 1766585542.8010504, "phase": "train", "update": 99, "total_env_steps": 316800, "episode_reward": 0.3110883831977844, "value_loss": 0.033076104894280436, "policy_loss": -0.011180762328933606, "dist_entropy": 0.6464587966601054, "actor_grad_norm": 0.18273380398750305, "critic_grad_norm": 0.07789716124534607, "ratio": 0.9991955757141113, "entropy": 0.6464587966601054, "incre_win_rate": 0.5689655172413793, "step": 99}
{"time": 1766585547.339517, "phase": "train", "update": 100, "total_env_steps": 320000, "episode_reward": 0.31521522998809814, "value_loss": 0.028317693869272867, "policy_loss": -0.011520979246347452, "dist_entropy": 0.6385426044464111, "actor_grad_norm": 0.1797393262386322, "critic_grad_norm": 0.07690712064504623, "ratio": 0.9995459318161011, "entropy": 0.6385426044464111, "incre_win_rate": 0.576271186440678, "step": 100}
{"time": 1766585551.8061454, "phase": "train", "update": 101, "total_env_steps": 323200, "episode_reward": 0.3190916180610657, "value_loss": 0.023935096710920332, "policy_loss": -0.011253555100464515, "dist_entropy": 0.6441771109898885, "actor_grad_norm": 0.17041707038879395, "critic_grad_norm": 0.049031391739845276, "ratio": 0.9992538690567017, "entropy": 0.6441771109898885, "incre_win_rate": 0.6428571428571429, "step": 101}
{"time": 1766585559.4731815, "phase": "eval", "update": 101, "total_env_steps": 323200, "eval_win_rate": 0.78125, "eval_episode_reward": 18.7671568627451, "step": 101}
{"time": 1766585563.9871287, "phase": "train", "update": 102, "total_env_steps": 326400, "episode_reward": 0.29242953658103943, "value_loss": 0.027074103678266206, "policy_loss": -0.011724040023198275, "dist_entropy": 0.6502893487612407, "actor_grad_norm": 0.1691025048494339, "critic_grad_norm": 0.08945969492197037, "ratio": 0.9993373155593872, "entropy": 0.6502893487612407, "incre_win_rate": 0.5, "step": 102}
{"time": 1766585568.524557, "phase": "train", "update": 103, "total_env_steps": 329600, "episode_reward": 0.294601708650589, "value_loss": 0.024836506942907968, "policy_loss": -0.011101496338974925, "dist_entropy": 0.6244626482327779, "actor_grad_norm": 0.19176913797855377, "critic_grad_norm": 0.06192097067832947, "ratio": 0.9996055960655212, "entropy": 0.6244626482327779, "incre_win_rate": 0.4727272727272727, "step": 103}
{"time": 1766585573.0545056, "phase": "train", "update": 104, "total_env_steps": 332800, "episode_reward": 0.3037208914756775, "value_loss": 0.021021221453944843, "policy_loss": -0.01068926907158243, "dist_entropy": 0.625666614373525, "actor_grad_norm": 0.17522591352462769, "critic_grad_norm": 0.09255632013082504, "ratio": 0.9992763996124268, "entropy": 0.625666614373525, "incre_win_rate": 0.5892857142857143, "step": 104}
{"time": 1766585577.618328, "phase": "train", "update": 105, "total_env_steps": 336000, "episode_reward": 0.32420191168785095, "value_loss": 0.02039001559217771, "policy_loss": -0.011275222613372696, "dist_entropy": 0.6223820726076762, "actor_grad_norm": 0.1639745682477951, "critic_grad_norm": 0.08977047353982925, "ratio": 0.9984691739082336, "entropy": 0.6223820726076762, "incre_win_rate": 0.7192982456140351, "step": 105}
{"time": 1766585582.0858662, "phase": "train", "update": 106, "total_env_steps": 339200, "episode_reward": 0.2928929328918457, "value_loss": 0.024964702626069386, "policy_loss": -0.010681132528263977, "dist_entropy": 0.6305782953898112, "actor_grad_norm": 0.16379909217357635, "critic_grad_norm": 0.11085806787014008, "ratio": 1.0008944272994995, "entropy": 0.6305782953898112, "incre_win_rate": 0.5370370370370371, "step": 106}
{"time": 1766585586.5993884, "phase": "train", "update": 107, "total_env_steps": 342400, "episode_reward": 0.31427544355392456, "value_loss": 0.020957847063740095, "policy_loss": -0.010490935086321802, "dist_entropy": 0.6291290203730265, "actor_grad_norm": 0.22157181799411774, "critic_grad_norm": 0.046854712069034576, "ratio": 0.999313235282898, "entropy": 0.6291290203730265, "incre_win_rate": 0.5614035087719298, "step": 107}
{"time": 1766585591.1102593, "phase": "train", "update": 108, "total_env_steps": 345600, "episode_reward": 0.31708791851997375, "value_loss": 0.022471492861708006, "policy_loss": -0.0105853515086802, "dist_entropy": 0.6072305043538412, "actor_grad_norm": 0.1747995764017105, "critic_grad_norm": 0.03255772590637207, "ratio": 0.9989032745361328, "entropy": 0.6072305043538412, "incre_win_rate": 0.6206896551724138, "step": 108}
{"time": 1766585595.6929142, "phase": "train", "update": 109, "total_env_steps": 348800, "episode_reward": 0.33531635999679565, "value_loss": 0.024897721285621326, "policy_loss": -0.01064238267000519, "dist_entropy": 0.6322082201639811, "actor_grad_norm": 0.20753484964370728, "critic_grad_norm": 0.07728312909603119, "ratio": 0.9989975094795227, "entropy": 0.6322082201639811, "incre_win_rate": 0.7543859649122807, "step": 109}
{"time": 1766585600.1877773, "phase": "train", "update": 110, "total_env_steps": 352000, "episode_reward": 0.3081342279911041, "value_loss": 0.02068909741938114, "policy_loss": -0.010689808032043875, "dist_entropy": 0.6186248183250427, "actor_grad_norm": 0.16155117750167847, "critic_grad_norm": 0.04338984563946724, "ratio": 1.0010029077529907, "entropy": 0.6186248183250427, "incre_win_rate": 0.6909090909090909, "step": 110}
{"time": 1766585604.7414834, "phase": "train", "update": 111, "total_env_steps": 355200, "episode_reward": 0.32127222418785095, "value_loss": 0.021389550964037576, "policy_loss": -0.010098292185679725, "dist_entropy": 0.5900841315587362, "actor_grad_norm": 0.1668481081724167, "critic_grad_norm": 0.06317024677991867, "ratio": 1.0003437995910645, "entropy": 0.5900841315587362, "incre_win_rate": 0.6607142857142857, "step": 111}
{"time": 1766585609.250157, "phase": "train", "update": 112, "total_env_steps": 358400, "episode_reward": 0.32188495993614197, "value_loss": 0.02272380453844865, "policy_loss": -0.010862188686703434, "dist_entropy": 0.6031210899353028, "actor_grad_norm": 0.17221081256866455, "critic_grad_norm": 0.07737834006547928, "ratio": 0.998953640460968, "entropy": 0.6031210899353028, "incre_win_rate": 0.7241379310344828, "step": 112}
{"time": 1766585613.742378, "phase": "train", "update": 113, "total_env_steps": 361600, "episode_reward": 0.30805376172065735, "value_loss": 0.024366195251544317, "policy_loss": -0.011279574204392873, "dist_entropy": 0.5935735265413921, "actor_grad_norm": 0.22871167957782745, "critic_grad_norm": 0.11705164611339569, "ratio": 0.9995756149291992, "entropy": 0.5935735265413921, "incre_win_rate": 0.543859649122807, "step": 113}
{"time": 1766585618.2602925, "phase": "train", "update": 114, "total_env_steps": 364800, "episode_reward": 0.32078278064727783, "value_loss": 0.022155686095356942, "policy_loss": -0.010238266550594944, "dist_entropy": 0.6209473450978596, "actor_grad_norm": 0.19501183927059174, "critic_grad_norm": 0.06335267424583435, "ratio": 0.9999110698699951, "entropy": 0.6209473450978596, "incre_win_rate": 0.6909090909090909, "step": 114}
{"time": 1766585622.7187436, "phase": "train", "update": 115, "total_env_steps": 368000, "episode_reward": 0.3135807514190674, "value_loss": 0.021306914215286573, "policy_loss": -0.011331077077167843, "dist_entropy": 0.628967301050822, "actor_grad_norm": 0.17452892661094666, "critic_grad_norm": 0.06297089904546738, "ratio": 0.999531090259552, "entropy": 0.628967301050822, "incre_win_rate": 0.6727272727272727, "step": 115}
{"time": 1766585627.2004535, "phase": "train", "update": 116, "total_env_steps": 371200, "episode_reward": 0.30874237418174744, "value_loss": 0.019939647987484932, "policy_loss": -0.010082456273104157, "dist_entropy": 0.6274691104888916, "actor_grad_norm": 0.16090959310531616, "critic_grad_norm": 0.0669693797826767, "ratio": 1.000138521194458, "entropy": 0.6274691104888916, "incre_win_rate": 0.6727272727272727, "step": 116}
{"time": 1766585631.6672785, "phase": "train", "update": 117, "total_env_steps": 374400, "episode_reward": 0.34329888224601746, "value_loss": 0.019660432760914167, "policy_loss": -0.010554901928435119, "dist_entropy": 0.607533073425293, "actor_grad_norm": 0.15532495081424713, "critic_grad_norm": 0.10787564516067505, "ratio": 0.9988165497779846, "entropy": 0.607533073425293, "incre_win_rate": 0.7966101694915254, "step": 117}
{"time": 1766585636.200571, "phase": "train", "update": 118, "total_env_steps": 377600, "episode_reward": 0.3247411549091339, "value_loss": 0.0182760958870252, "policy_loss": -0.01082659517247085, "dist_entropy": 0.5795945167541504, "actor_grad_norm": 0.18063825368881226, "critic_grad_norm": 0.06822943687438965, "ratio": 0.9997392296791077, "entropy": 0.5795945167541504, "incre_win_rate": 0.6909090909090909, "step": 118}
{"time": 1766585640.6970801, "phase": "train", "update": 119, "total_env_steps": 380800, "episode_reward": 0.3367111086845398, "value_loss": 0.02555644723276297, "policy_loss": -0.010201071415845557, "dist_entropy": 0.5748679081598917, "actor_grad_norm": 0.19991885125637054, "critic_grad_norm": 0.026923349127173424, "ratio": 0.9989466667175293, "entropy": 0.5748679081598917, "incre_win_rate": 0.7213114754098361, "step": 119}
{"time": 1766585645.1527705, "phase": "train", "update": 120, "total_env_steps": 384000, "episode_reward": 0.3234221935272217, "value_loss": 0.02293081283569336, "policy_loss": -0.010392121222857516, "dist_entropy": 0.5772272984186808, "actor_grad_norm": 0.1810704618692398, "critic_grad_norm": 0.08803416043519974, "ratio": 0.9995814561843872, "entropy": 0.5772272984186808, "incre_win_rate": 0.631578947368421, "step": 120}
{"time": 1766585649.7024183, "phase": "train", "update": 121, "total_env_steps": 387200, "episode_reward": 0.3169386088848114, "value_loss": 0.02081439346075058, "policy_loss": -0.011196195162166588, "dist_entropy": 0.6208666324615478, "actor_grad_norm": 0.20331767201423645, "critic_grad_norm": 0.0487697534263134, "ratio": 0.9999239444732666, "entropy": 0.6208666324615478, "incre_win_rate": 0.7090909090909091, "step": 121}
{"time": 1766585658.427444, "phase": "eval", "update": 121, "total_env_steps": 387200, "eval_win_rate": 0.59375, "eval_episode_reward": 17.938495710784316, "step": 121}
{"time": 1766585662.9343987, "phase": "train", "update": 122, "total_env_steps": 390400, "episode_reward": 0.3142731189727783, "value_loss": 0.022342714418967565, "policy_loss": -0.010779916053311921, "dist_entropy": 0.604472295443217, "actor_grad_norm": 0.17522692680358887, "critic_grad_norm": 0.033135805279016495, "ratio": 0.9991529583930969, "entropy": 0.604472295443217, "incre_win_rate": 0.6428571428571429, "step": 122}
{"time": 1766585667.4722598, "phase": "train", "update": 123, "total_env_steps": 393600, "episode_reward": 0.31648436188697815, "value_loss": 0.01976065933704376, "policy_loss": -0.010842718225576913, "dist_entropy": 0.6134935657183329, "actor_grad_norm": 0.16768500208854675, "critic_grad_norm": 0.07524419575929642, "ratio": 0.9995197653770447, "entropy": 0.6134935657183329, "incre_win_rate": 0.6379310344827587, "step": 123}
{"time": 1766585672.1442957, "phase": "train", "update": 124, "total_env_steps": 396800, "episode_reward": 0.3161083161830902, "value_loss": 0.021575198074181876, "policy_loss": -0.0106485673529973, "dist_entropy": 0.5862312475840251, "actor_grad_norm": 0.1722756177186966, "critic_grad_norm": 0.04206288233399391, "ratio": 1.0008236169815063, "entropy": 0.5862312475840251, "incre_win_rate": 0.6545454545454545, "step": 124}
{"time": 1766585676.9537363, "phase": "train", "update": 125, "total_env_steps": 400000, "episode_reward": 0.330101877450943, "value_loss": 0.01801285147666931, "policy_loss": -0.010656486353276288, "dist_entropy": 0.5796851436297099, "actor_grad_norm": 0.18738017976284027, "critic_grad_norm": 0.044736843556165695, "ratio": 1.0002163648605347, "entropy": 0.5796851436297099, "incre_win_rate": 0.7288135593220338, "step": 125}
{"time": 1766585681.4889667, "phase": "train", "update": 126, "total_env_steps": 403200, "episode_reward": 0.32122930884361267, "value_loss": 0.026346535235643388, "policy_loss": -0.009546419758431787, "dist_entropy": 0.5899652759234111, "actor_grad_norm": 0.1579783856868744, "critic_grad_norm": 0.03464493155479431, "ratio": 1.0001882314682007, "entropy": 0.5899652759234111, "incre_win_rate": 0.6785714285714286, "step": 126}
{"time": 1766585686.064137, "phase": "train", "update": 127, "total_env_steps": 406400, "episode_reward": 0.3202374279499054, "value_loss": 0.02099522203207016, "policy_loss": -0.011103882459984978, "dist_entropy": 0.5994128982226054, "actor_grad_norm": 0.20966142416000366, "critic_grad_norm": 0.05879620462656021, "ratio": 0.9996612071990967, "entropy": 0.5994128982226054, "incre_win_rate": 0.7017543859649122, "step": 127}
{"time": 1766585690.5815923, "phase": "train", "update": 128, "total_env_steps": 409600, "episode_reward": 0.33055296540260315, "value_loss": 0.017393520226081212, "policy_loss": -0.009016818205901226, "dist_entropy": 0.5847155014673869, "actor_grad_norm": 0.1712995022535324, "critic_grad_norm": 0.0331321619451046, "ratio": 0.9992068409919739, "entropy": 0.5847155014673869, "incre_win_rate": 0.7758620689655172, "step": 128}
{"time": 1766585695.0656645, "phase": "train", "update": 129, "total_env_steps": 412800, "episode_reward": 0.3332574963569641, "value_loss": 0.01863404785593351, "policy_loss": -0.010805167185066486, "dist_entropy": 0.6017076333363851, "actor_grad_norm": 0.15647320449352264, "critic_grad_norm": 0.050551217049360275, "ratio": 0.9985342025756836, "entropy": 0.6017076333363851, "incre_win_rate": 0.7543859649122807, "step": 129}
{"time": 1766585699.57443, "phase": "train", "update": 130, "total_env_steps": 416000, "episode_reward": 0.3323743939399719, "value_loss": 0.018392699708541235, "policy_loss": -0.010426116878798552, "dist_entropy": 0.5914368033409119, "actor_grad_norm": 0.1559075117111206, "critic_grad_norm": 0.06076527386903763, "ratio": 0.9985827803611755, "entropy": 0.5914368033409119, "incre_win_rate": 0.6724137931034483, "step": 130}
{"time": 1766585704.0670931, "phase": "train", "update": 131, "total_env_steps": 419200, "episode_reward": 0.3286535143852234, "value_loss": 0.01665116858979066, "policy_loss": -0.011139050687616722, "dist_entropy": 0.5961154500643412, "actor_grad_norm": 0.2270059734582901, "critic_grad_norm": 0.033624254167079926, "ratio": 0.9985833168029785, "entropy": 0.5961154500643412, "incre_win_rate": 0.7413793103448276, "step": 131}
{"time": 1766585708.6774921, "phase": "train", "update": 132, "total_env_steps": 422400, "episode_reward": 0.33576440811157227, "value_loss": 0.016555400441090266, "policy_loss": -0.009902929615457624, "dist_entropy": 0.6085563540458679, "actor_grad_norm": 0.16681042313575745, "critic_grad_norm": 0.03292645886540413, "ratio": 1.0003098249435425, "entropy": 0.6085563540458679, "incre_win_rate": 0.7586206896551724, "step": 132}
{"time": 1766585713.1758304, "phase": "train", "update": 133, "total_env_steps": 425600, "episode_reward": 0.3135554790496826, "value_loss": 0.016682747192680834, "policy_loss": -0.010920767498278867, "dist_entropy": 0.5900676449139913, "actor_grad_norm": 0.17162460088729858, "critic_grad_norm": 0.1018022820353508, "ratio": 0.9997718334197998, "entropy": 0.5900676449139913, "incre_win_rate": 0.7407407407407407, "step": 133}
{"time": 1766585717.6924355, "phase": "train", "update": 134, "total_env_steps": 428800, "episode_reward": 0.3334183692932129, "value_loss": 0.01759915774067243, "policy_loss": -0.009935506179555393, "dist_entropy": 0.6032193859418233, "actor_grad_norm": 0.14272592961788177, "critic_grad_norm": 0.07569068670272827, "ratio": 0.9994721412658691, "entropy": 0.6032193859418233, "incre_win_rate": 0.7894736842105263, "step": 134}
{"time": 1766585722.3117568, "phase": "train", "update": 135, "total_env_steps": 432000, "episode_reward": 0.3270389139652252, "value_loss": 0.019179404651125272, "policy_loss": -0.010769807579148487, "dist_entropy": 0.6331732511520386, "actor_grad_norm": 0.1821390837430954, "critic_grad_norm": 0.11650987714529037, "ratio": 0.9996610283851624, "entropy": 0.6331732511520386, "incre_win_rate": 0.6779661016949152, "step": 135}
{"time": 1766585726.903974, "phase": "train", "update": 136, "total_env_steps": 435200, "episode_reward": 0.3187140226364136, "value_loss": 0.016238790564239027, "policy_loss": -0.010447393078113503, "dist_entropy": 0.621874459584554, "actor_grad_norm": 0.18146182596683502, "critic_grad_norm": 0.06424476206302643, "ratio": 0.9994595050811768, "entropy": 0.621874459584554, "incre_win_rate": 0.7407407407407407, "step": 136}
{"time": 1766585731.454858, "phase": "train", "update": 137, "total_env_steps": 438400, "episode_reward": 0.335540771484375, "value_loss": 0.014578333124518394, "policy_loss": -0.01062361975563988, "dist_entropy": 0.6275104324022929, "actor_grad_norm": 0.2346770018339157, "critic_grad_norm": 0.03008774109184742, "ratio": 0.9995921850204468, "entropy": 0.6275104324022929, "incre_win_rate": 0.7627118644067796, "step": 137}
{"time": 1766585735.9901032, "phase": "train", "update": 138, "total_env_steps": 441600, "episode_reward": 0.30906787514686584, "value_loss": 0.0200198981910944, "policy_loss": -0.01112048325858197, "dist_entropy": 0.6113342841466268, "actor_grad_norm": 0.16874195635318756, "critic_grad_norm": 0.020754599943757057, "ratio": 0.9997084736824036, "entropy": 0.6113342841466268, "incre_win_rate": 0.660377358490566, "step": 138}
{"time": 1766585740.535449, "phase": "train", "update": 139, "total_env_steps": 444800, "episode_reward": 0.336365669965744, "value_loss": 0.01704484559595585, "policy_loss": -0.01073565922821634, "dist_entropy": 0.5911921779314677, "actor_grad_norm": 0.21568360924720764, "critic_grad_norm": 0.017396388575434685, "ratio": 0.9994964599609375, "entropy": 0.5911921779314677, "incre_win_rate": 0.7627118644067796, "step": 139}
{"time": 1766585744.9784265, "phase": "train", "update": 140, "total_env_steps": 448000, "episode_reward": 0.3336772322654724, "value_loss": 0.015861585922539233, "policy_loss": -0.01177017642773753, "dist_entropy": 0.6071097215016683, "actor_grad_norm": 0.1774681657552719, "critic_grad_norm": 0.06284897774457932, "ratio": 0.9989005327224731, "entropy": 0.6071097215016683, "incre_win_rate": 0.7543859649122807, "step": 140}
{"time": 1766585749.4952369, "phase": "train", "update": 141, "total_env_steps": 451200, "episode_reward": 0.329653799533844, "value_loss": 0.01612661648541689, "policy_loss": -0.010978909568694442, "dist_entropy": 0.6065272291501363, "actor_grad_norm": 0.17812803387641907, "critic_grad_norm": 0.04892033711075783, "ratio": 0.9993309378623962, "entropy": 0.6065272291501363, "incre_win_rate": 0.8070175438596491, "step": 141}
{"time": 1766585756.9739637, "phase": "eval", "update": 141, "total_env_steps": 451200, "eval_win_rate": 0.8125, "eval_episode_reward": 18.829273897058822, "step": 141}
{"time": 1766585761.5139582, "phase": "train", "update": 142, "total_env_steps": 454400, "episode_reward": 0.32674938440322876, "value_loss": 0.018287845080097516, "policy_loss": -0.010800755324758764, "dist_entropy": 0.578212563196818, "actor_grad_norm": 0.1625247597694397, "critic_grad_norm": 0.02640090137720108, "ratio": 0.9997127652168274, "entropy": 0.578212563196818, "incre_win_rate": 0.8148148148148148, "step": 142}
{"time": 1766585766.1205065, "phase": "train", "update": 143, "total_env_steps": 457600, "episode_reward": 0.3324180543422699, "value_loss": 0.01809377024571101, "policy_loss": -0.011358688969585036, "dist_entropy": 0.5573491017023723, "actor_grad_norm": 0.18701918423175812, "critic_grad_norm": 0.023399800062179565, "ratio": 0.9988605976104736, "entropy": 0.5573491017023723, "incre_win_rate": 0.6949152542372882, "step": 143}
{"time": 1766585770.7421215, "phase": "train", "update": 144, "total_env_steps": 460800, "episode_reward": 0.3198253810405731, "value_loss": 0.023320274924238524, "policy_loss": -0.011468360434525949, "dist_entropy": 0.5866671323776245, "actor_grad_norm": 0.2101793736219406, "critic_grad_norm": 0.07029478996992111, "ratio": 0.9995442628860474, "entropy": 0.5866671323776245, "incre_win_rate": 0.7068965517241379, "step": 144}
{"time": 1766585775.2906284, "phase": "train", "update": 145, "total_env_steps": 464000, "episode_reward": 0.32361900806427, "value_loss": 0.018082114309072493, "policy_loss": -0.011581388954932473, "dist_entropy": 0.5815388679504394, "actor_grad_norm": 0.16666804254055023, "critic_grad_norm": 0.1220424473285675, "ratio": 0.9992687702178955, "entropy": 0.5815388679504394, "incre_win_rate": 0.7592592592592593, "step": 145}
{"time": 1766585779.9164, "phase": "train", "update": 146, "total_env_steps": 467200, "episode_reward": 0.33928462862968445, "value_loss": 0.015107011919220288, "policy_loss": -0.01121581509243524, "dist_entropy": 0.5937972068786621, "actor_grad_norm": 0.22165419161319733, "critic_grad_norm": 0.07128622382879257, "ratio": 0.9989081025123596, "entropy": 0.5937972068786621, "incre_win_rate": 0.7894736842105263, "step": 146}
{"time": 1766585784.3614535, "phase": "train", "update": 147, "total_env_steps": 470400, "episode_reward": 0.3218926191329956, "value_loss": 0.017679016664624216, "policy_loss": -0.011655726076705501, "dist_entropy": 0.5843878070513407, "actor_grad_norm": 0.18104176223278046, "critic_grad_norm": 0.056231699883937836, "ratio": 0.9989117980003357, "entropy": 0.5843878070513407, "incre_win_rate": 0.7321428571428571, "step": 147}
{"time": 1766585788.843497, "phase": "train", "update": 148, "total_env_steps": 473600, "episode_reward": 0.3147740364074707, "value_loss": 0.017916369313995043, "policy_loss": -0.010089547581726303, "dist_entropy": 0.5789272824923197, "actor_grad_norm": 0.1886165589094162, "critic_grad_norm": 0.05116796866059303, "ratio": 0.998569905757904, "entropy": 0.5789272824923197, "incre_win_rate": 0.6428571428571429, "step": 148}
{"time": 1766585793.4186397, "phase": "train", "update": 149, "total_env_steps": 476800, "episode_reward": 0.35355547070503235, "value_loss": 0.012586744502186775, "policy_loss": -0.011078583759955525, "dist_entropy": 0.5889959573745728, "actor_grad_norm": 0.18096688389778137, "critic_grad_norm": 0.03199094161391258, "ratio": 0.9997389912605286, "entropy": 0.5889959573745728, "incre_win_rate": 0.8813559322033898, "step": 149}
{"time": 1766585797.9612393, "phase": "train", "update": 150, "total_env_steps": 480000, "episode_reward": 0.319575697183609, "value_loss": 0.016717588404814403, "policy_loss": -0.010858711969687818, "dist_entropy": 0.5734960834185282, "actor_grad_norm": 0.18772190809249878, "critic_grad_norm": 0.11527281254529953, "ratio": 0.9997711777687073, "entropy": 0.5734960834185282, "incre_win_rate": 0.6964285714285714, "step": 150}
{"time": 1766585802.4707837, "phase": "train", "update": 151, "total_env_steps": 483200, "episode_reward": 0.329705148935318, "value_loss": 0.01814827596147855, "policy_loss": -0.011747474741507436, "dist_entropy": 0.5976806640625, "actor_grad_norm": 0.1741129606962204, "critic_grad_norm": 0.038016028702259064, "ratio": 1.0001922845840454, "entropy": 0.5976806640625, "incre_win_rate": 0.7678571428571429, "step": 151}
{"time": 1766585806.997408, "phase": "train", "update": 152, "total_env_steps": 486400, "episode_reward": 0.3323284387588501, "value_loss": 0.01703511501351992, "policy_loss": -0.011302572221185395, "dist_entropy": 0.5747259736061097, "actor_grad_norm": 0.16581220924854279, "critic_grad_norm": 0.025905264541506767, "ratio": 1.0005601644515991, "entropy": 0.5747259736061097, "incre_win_rate": 0.7241379310344828, "step": 152}
{"time": 1766585811.5602524, "phase": "train", "update": 153, "total_env_steps": 489600, "episode_reward": 0.34225568175315857, "value_loss": 0.015494461668034394, "policy_loss": -0.01214556187798621, "dist_entropy": 0.5684522112210592, "actor_grad_norm": 0.15989689528942108, "critic_grad_norm": 0.040414486080408096, "ratio": 0.9998199343681335, "entropy": 0.5684522112210592, "incre_win_rate": 0.7666666666666667, "step": 153}
{"time": 1766585816.0187812, "phase": "train", "update": 154, "total_env_steps": 492800, "episode_reward": 0.32895833253860474, "value_loss": 0.016865445797642074, "policy_loss": -0.011328179730318114, "dist_entropy": 0.5965725739796957, "actor_grad_norm": 0.165315642952919, "critic_grad_norm": 0.052925024181604385, "ratio": 0.9993590712547302, "entropy": 0.5965725739796957, "incre_win_rate": 0.7321428571428571, "step": 154}
{"time": 1766585820.5389473, "phase": "train", "update": 155, "total_env_steps": 496000, "episode_reward": 0.32245171070098877, "value_loss": 0.01651816926896572, "policy_loss": -0.011148858205301338, "dist_entropy": 0.5855631271998087, "actor_grad_norm": 0.18939758837223053, "critic_grad_norm": 0.0408438965678215, "ratio": 1.0003429651260376, "entropy": 0.5855631271998087, "incre_win_rate": 0.75, "step": 155}
{"time": 1766585825.11561, "phase": "train", "update": 156, "total_env_steps": 499200, "episode_reward": 0.3206855058670044, "value_loss": 0.01751004606485367, "policy_loss": -0.01120746135804159, "dist_entropy": 0.6101547678311666, "actor_grad_norm": 0.14514587819576263, "critic_grad_norm": 0.06780189275741577, "ratio": 0.9993994832038879, "entropy": 0.6101547678311666, "incre_win_rate": 0.6964285714285714, "step": 156}
{"time": 1766585829.7133846, "phase": "train", "update": 157, "total_env_steps": 502400, "episode_reward": 0.33557984232902527, "value_loss": 0.01628596099714438, "policy_loss": -0.011253954410317608, "dist_entropy": 0.6170329133669535, "actor_grad_norm": 0.1633262187242508, "critic_grad_norm": 0.03148942068219185, "ratio": 0.9997920989990234, "entropy": 0.6170329133669535, "incre_win_rate": 0.7, "step": 157}
{"time": 1766585834.3188858, "phase": "train", "update": 158, "total_env_steps": 505600, "episode_reward": 0.33573225140571594, "value_loss": 0.016899373506506284, "policy_loss": -0.01223443771952321, "dist_entropy": 0.6223741054534913, "actor_grad_norm": 0.23526546359062195, "critic_grad_norm": 0.041928816586732864, "ratio": 0.9994304776191711, "entropy": 0.6223741054534913, "incre_win_rate": 0.7586206896551724, "step": 158}
{"time": 1766585838.9498568, "phase": "train", "update": 159, "total_env_steps": 508800, "episode_reward": 0.3409850001335144, "value_loss": 0.01955255021651586, "policy_loss": -0.011407470105320528, "dist_entropy": 0.6283538540204366, "actor_grad_norm": 0.22828707098960876, "critic_grad_norm": 0.03177214413881302, "ratio": 1.001173973083496, "entropy": 0.6283538540204366, "incre_win_rate": 0.7758620689655172, "step": 159}
{"time": 1766585843.4730437, "phase": "train", "update": 160, "total_env_steps": 512000, "episode_reward": 0.32346734404563904, "value_loss": 0.015640976652503014, "policy_loss": -0.01178732404757549, "dist_entropy": 0.6175782322883606, "actor_grad_norm": 0.22251275181770325, "critic_grad_norm": 0.07030212134122849, "ratio": 0.9998223781585693, "entropy": 0.6175782322883606, "incre_win_rate": 0.6607142857142857, "step": 160}
{"time": 1766585848.0046415, "phase": "train", "update": 161, "total_env_steps": 515200, "episode_reward": 0.332711398601532, "value_loss": 0.01748995346327623, "policy_loss": -0.01206272142758289, "dist_entropy": 0.611585263411204, "actor_grad_norm": 0.22458262741565704, "critic_grad_norm": 0.0373435840010643, "ratio": 0.9994798898696899, "entropy": 0.611585263411204, "incre_win_rate": 0.7, "step": 161}
{"time": 1766585855.3142977, "phase": "eval", "update": 161, "total_env_steps": 515200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.81188725490196, "step": 161}
{"time": 1766585859.8604145, "phase": "train", "update": 162, "total_env_steps": 518400, "episode_reward": 0.33756279945373535, "value_loss": 0.018099340548117956, "policy_loss": -0.011563563962216576, "dist_entropy": 0.615722135702769, "actor_grad_norm": 0.21935148537158966, "critic_grad_norm": 0.05064302310347557, "ratio": 0.9980643391609192, "entropy": 0.615722135702769, "incre_win_rate": 0.711864406779661, "step": 162}
{"time": 1766585864.3933184, "phase": "train", "update": 163, "total_env_steps": 521600, "episode_reward": 0.3344899117946625, "value_loss": 0.019636320571104687, "policy_loss": -0.012563508427762807, "dist_entropy": 0.5987703760464986, "actor_grad_norm": 0.18717175722122192, "critic_grad_norm": 0.03289388120174408, "ratio": 0.999847948551178, "entropy": 0.5987703760464986, "incre_win_rate": 0.7, "step": 163}
{"time": 1766585904.2027733, "phase": "train", "update": 164, "total_env_steps": 524800, "episode_reward": 0.326973021030426, "value_loss": 0.055671168863773345, "policy_loss": -0.010313036761688465, "dist_entropy": 0.617722237110138, "actor_grad_norm": 0.1554872691631317, "critic_grad_norm": 0.096672922372818, "ratio": 0.9984652996063232, "entropy": 0.617722237110138, "incre_win_rate": 0.7058823529411765, "step": 164}
{"time": 1766585908.7957537, "phase": "train", "update": 165, "total_env_steps": 528000, "episode_reward": 0.3317562937736511, "value_loss": 0.019318474580844243, "policy_loss": -0.01182812059945017, "dist_entropy": 0.6158682823181152, "actor_grad_norm": 0.21084946393966675, "critic_grad_norm": 0.05464056134223938, "ratio": 0.9987554550170898, "entropy": 0.6158682823181152, "incre_win_rate": 0.7, "step": 165}
{"time": 1766585913.3598142, "phase": "train", "update": 166, "total_env_steps": 531200, "episode_reward": 0.31044504046440125, "value_loss": 0.017953560998042423, "policy_loss": -0.012642222227653595, "dist_entropy": 0.6227132678031921, "actor_grad_norm": 0.19907857477664948, "critic_grad_norm": 0.09385129064321518, "ratio": 0.9988004565238953, "entropy": 0.6227132678031921, "incre_win_rate": 0.6727272727272727, "step": 166}
{"time": 1766585917.903594, "phase": "train", "update": 167, "total_env_steps": 534400, "episode_reward": 0.326572448015213, "value_loss": 0.021501489107807477, "policy_loss": -0.012321910631107139, "dist_entropy": 0.6161067883173624, "actor_grad_norm": 0.23184755444526672, "critic_grad_norm": 0.11602607369422913, "ratio": 0.9996722340583801, "entropy": 0.6161067883173624, "incre_win_rate": 0.6229508196721312, "step": 167}
{"time": 1766585922.4306614, "phase": "train", "update": 168, "total_env_steps": 537600, "episode_reward": 0.32741573452949524, "value_loss": 0.019979061931371687, "policy_loss": -0.011132505120359919, "dist_entropy": 0.6084315220514933, "actor_grad_norm": 0.19239534437656403, "critic_grad_norm": 0.14188125729560852, "ratio": 0.9978654980659485, "entropy": 0.6084315220514933, "incre_win_rate": 0.7142857142857143, "step": 168}
{"time": 1766585926.955461, "phase": "train", "update": 169, "total_env_steps": 540800, "episode_reward": 0.3295036852359772, "value_loss": 0.021972227717439334, "policy_loss": -0.011527953914900321, "dist_entropy": 0.6106416742006938, "actor_grad_norm": 0.20785221457481384, "critic_grad_norm": 0.06025967746973038, "ratio": 0.9993094205856323, "entropy": 0.6106416742006938, "incre_win_rate": 0.65, "step": 169}
{"time": 1766585931.6290343, "phase": "train", "update": 170, "total_env_steps": 544000, "episode_reward": 0.3214299976825714, "value_loss": 0.01926803564031919, "policy_loss": -0.011916510487805947, "dist_entropy": 0.6121879140535991, "actor_grad_norm": 0.20147094130516052, "critic_grad_norm": 0.04466177150607109, "ratio": 0.9998148083686829, "entropy": 0.6121879140535991, "incre_win_rate": 0.6379310344827587, "step": 170}
{"time": 1766585936.3245869, "phase": "train", "update": 171, "total_env_steps": 547200, "episode_reward": 0.3321254849433899, "value_loss": 0.0207119715710481, "policy_loss": -0.011741190717565075, "dist_entropy": 0.6134839415550232, "actor_grad_norm": 0.21028392016887665, "critic_grad_norm": 0.032018452882766724, "ratio": 0.9991478323936462, "entropy": 0.6134839415550232, "incre_win_rate": 0.6333333333333333, "step": 171}
{"time": 1766585940.9203122, "phase": "train", "update": 172, "total_env_steps": 550400, "episode_reward": 0.32150962948799133, "value_loss": 0.020728978887200357, "policy_loss": -0.01286140836565816, "dist_entropy": 0.6061755736668905, "actor_grad_norm": 0.23237071931362152, "critic_grad_norm": 0.02568041905760765, "ratio": 0.9985659122467041, "entropy": 0.6061755736668905, "incre_win_rate": 0.6140350877192983, "step": 172}
{"time": 1766585945.7039468, "phase": "train", "update": 173, "total_env_steps": 553600, "episode_reward": 0.3188304305076599, "value_loss": 0.020466758186618486, "policy_loss": -0.011580144506813876, "dist_entropy": 0.613309379418691, "actor_grad_norm": 0.2383006364107132, "critic_grad_norm": 0.03899185359477997, "ratio": 0.9982532858848572, "entropy": 0.613309379418691, "incre_win_rate": 0.6727272727272727, "step": 173}
{"time": 1766585950.3100834, "phase": "train", "update": 174, "total_env_steps": 556800, "episode_reward": 0.312099426984787, "value_loss": 0.02080158106982708, "policy_loss": -0.012435453772454964, "dist_entropy": 0.6169283390045166, "actor_grad_norm": 0.20539741218090057, "critic_grad_norm": 0.029697395861148834, "ratio": 0.9984543323516846, "entropy": 0.6169283390045166, "incre_win_rate": 0.6785714285714286, "step": 174}
{"time": 1766585955.091551, "phase": "train", "update": 175, "total_env_steps": 560000, "episode_reward": 0.3282184302806854, "value_loss": 0.015124701770643394, "policy_loss": -0.012167834907285643, "dist_entropy": 0.6085890968640645, "actor_grad_norm": 0.18374967575073242, "critic_grad_norm": 0.04958905652165413, "ratio": 0.9989543557167053, "entropy": 0.6085890968640645, "incre_win_rate": 0.75, "step": 175}
{"time": 1766585959.6655774, "phase": "train", "update": 176, "total_env_steps": 563200, "episode_reward": 0.3231847584247589, "value_loss": 0.016529768084486324, "policy_loss": -0.0120899733568109, "dist_entropy": 0.6226121068000794, "actor_grad_norm": 0.18533988296985626, "critic_grad_norm": 0.03795594722032547, "ratio": 0.9991996884346008, "entropy": 0.6226121068000794, "incre_win_rate": 0.6271186440677966, "step": 176}
{"time": 1766585964.428656, "phase": "train", "update": 177, "total_env_steps": 566400, "episode_reward": 0.3183410167694092, "value_loss": 0.020936034495631854, "policy_loss": -0.01173373278403839, "dist_entropy": 0.6154752492904663, "actor_grad_norm": 0.2528201937675476, "critic_grad_norm": 0.06566010415554047, "ratio": 0.9989495277404785, "entropy": 0.6154752492904663, "incre_win_rate": 0.5614035087719298, "step": 177}
{"time": 1766585969.0392215, "phase": "train", "update": 178, "total_env_steps": 569600, "episode_reward": 0.30772364139556885, "value_loss": 0.021760582799712817, "policy_loss": -0.013086712685709283, "dist_entropy": 0.6128271659215291, "actor_grad_norm": 0.20151254534721375, "critic_grad_norm": 0.053991496562957764, "ratio": 0.9992930889129639, "entropy": 0.6128271659215291, "incre_win_rate": 0.6140350877192983, "step": 178}
{"time": 1766585973.6902928, "phase": "train", "update": 179, "total_env_steps": 572800, "episode_reward": 0.30653417110443115, "value_loss": 0.019717548911770185, "policy_loss": -0.01314926701129006, "dist_entropy": 0.6285582621892293, "actor_grad_norm": 0.21521693468093872, "critic_grad_norm": 0.060167621821165085, "ratio": 0.9979928731918335, "entropy": 0.6285582621892293, "incre_win_rate": 0.6481481481481481, "step": 179}
{"time": 1766585978.327884, "phase": "train", "update": 180, "total_env_steps": 576000, "episode_reward": 0.31549710035324097, "value_loss": 0.020912205427885057, "policy_loss": -0.013425404944788966, "dist_entropy": 0.6295870860417684, "actor_grad_norm": 0.18739143013954163, "critic_grad_norm": 0.03988729044795036, "ratio": 0.9995707273483276, "entropy": 0.6295870860417684, "incre_win_rate": 0.625, "step": 180}
{"time": 1766585982.9676127, "phase": "train", "update": 181, "total_env_steps": 579200, "episode_reward": 0.3272901177406311, "value_loss": 0.02261724459628264, "policy_loss": -0.012629483876139602, "dist_entropy": 0.6097823182741801, "actor_grad_norm": 0.18362635374069214, "critic_grad_norm": 0.03162975236773491, "ratio": 1.0003576278686523, "entropy": 0.6097823182741801, "incre_win_rate": 0.7288135593220338, "step": 181}
{"time": 1766585990.3085709, "phase": "eval", "update": 181, "total_env_steps": 579200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.41636029411765, "step": 181}
{"time": 1766585994.998283, "phase": "train", "update": 182, "total_env_steps": 582400, "episode_reward": 0.32069775462150574, "value_loss": 0.01892552152276039, "policy_loss": -0.012825031026327831, "dist_entropy": 0.6207156260808309, "actor_grad_norm": 0.1996087282896042, "critic_grad_norm": 0.04225195199251175, "ratio": 0.998011589050293, "entropy": 0.6207156260808309, "incre_win_rate": 0.7037037037037037, "step": 182}
{"time": 1766585999.6612463, "phase": "train", "update": 183, "total_env_steps": 585600, "episode_reward": 0.33156633377075195, "value_loss": 0.02007186027864615, "policy_loss": -0.012627739704673856, "dist_entropy": 0.6177244663238526, "actor_grad_norm": 0.22240392863750458, "critic_grad_norm": 0.03656885400414467, "ratio": 0.9988937973976135, "entropy": 0.6177244663238526, "incre_win_rate": 0.7333333333333333, "step": 183}
{"time": 1766586004.2948864, "phase": "train", "update": 184, "total_env_steps": 588800, "episode_reward": 0.3213786482810974, "value_loss": 0.019626059383153916, "policy_loss": -0.012447688926967496, "dist_entropy": 0.6283158342043559, "actor_grad_norm": 0.18903924524784088, "critic_grad_norm": 0.021885355934500694, "ratio": 0.9990665912628174, "entropy": 0.6283158342043559, "incre_win_rate": 0.6607142857142857, "step": 184}
{"time": 1766586008.9089541, "phase": "train", "update": 185, "total_env_steps": 592000, "episode_reward": 0.3264024257659912, "value_loss": 0.01944487579166889, "policy_loss": -0.01187831146633916, "dist_entropy": 0.6085498452186584, "actor_grad_norm": 0.20267927646636963, "critic_grad_norm": 0.07301643490791321, "ratio": 0.9993758201599121, "entropy": 0.6085498452186584, "incre_win_rate": 0.6333333333333333, "step": 185}
{"time": 1766586013.5183249, "phase": "train", "update": 186, "total_env_steps": 595200, "episode_reward": 0.32858380675315857, "value_loss": 0.017823963860670724, "policy_loss": -0.012469964296081552, "dist_entropy": 0.6406750321388245, "actor_grad_norm": 0.19602368772029877, "critic_grad_norm": 0.03943976014852524, "ratio": 1.0001647472381592, "entropy": 0.6406750321388245, "incre_win_rate": 0.6724137931034483, "step": 186}
{"time": 1766586018.0869892, "phase": "train", "update": 187, "total_env_steps": 598400, "episode_reward": 0.3265073895454407, "value_loss": 0.01951594774921735, "policy_loss": -0.011686860780813883, "dist_entropy": 0.6235736966133117, "actor_grad_norm": 0.17740453779697418, "critic_grad_norm": 0.03782610222697258, "ratio": 0.9995107650756836, "entropy": 0.6235736966133117, "incre_win_rate": 0.7678571428571429, "step": 187}
{"time": 1766586022.6664886, "phase": "train", "update": 188, "total_env_steps": 601600, "episode_reward": 0.3183126449584961, "value_loss": 0.020855885992447535, "policy_loss": -0.012373370678835727, "dist_entropy": 0.6052330931027731, "actor_grad_norm": 0.2616936266422272, "critic_grad_norm": 0.1221991553902626, "ratio": 1.0004206895828247, "entropy": 0.6052330931027731, "incre_win_rate": 0.6491228070175439, "step": 188}
{"time": 1766586027.2362132, "phase": "train", "update": 189, "total_env_steps": 604800, "episode_reward": 0.31146520376205444, "value_loss": 0.020995062962174415, "policy_loss": -0.01226937830754021, "dist_entropy": 0.5876497189203899, "actor_grad_norm": 0.19543425738811493, "critic_grad_norm": 0.12097693234682083, "ratio": 0.9988009929656982, "entropy": 0.5876497189203899, "incre_win_rate": 0.5789473684210527, "step": 189}
{"time": 1766586031.7966328, "phase": "train", "update": 190, "total_env_steps": 608000, "episode_reward": 0.3239023983478546, "value_loss": 0.022279462094108263, "policy_loss": -0.011619191204079015, "dist_entropy": 0.5819765170415242, "actor_grad_norm": 0.24071088433265686, "critic_grad_norm": 0.09690769761800766, "ratio": 0.9988502264022827, "entropy": 0.5819765170415242, "incre_win_rate": 0.6166666666666667, "step": 190}
{"time": 1766586036.3485518, "phase": "train", "update": 191, "total_env_steps": 611200, "episode_reward": 0.31813880801200867, "value_loss": 0.021387245133519174, "policy_loss": -0.012192623553928073, "dist_entropy": 0.5968563278516134, "actor_grad_norm": 0.21118126809597015, "critic_grad_norm": 0.05685533210635185, "ratio": 0.9977845549583435, "entropy": 0.5968563278516134, "incre_win_rate": 0.6101694915254238, "step": 191}
{"time": 1766586040.9610198, "phase": "train", "update": 192, "total_env_steps": 614400, "episode_reward": 0.3286994695663452, "value_loss": 0.02060323456923167, "policy_loss": -0.011131553762580874, "dist_entropy": 0.5780121286710104, "actor_grad_norm": 0.22670993208885193, "critic_grad_norm": 0.031241903081536293, "ratio": 1.0002918243408203, "entropy": 0.5780121286710104, "incre_win_rate": 0.6551724137931034, "step": 192}
{"time": 1766586045.5480094, "phase": "train", "update": 193, "total_env_steps": 617600, "episode_reward": 0.3418627679347992, "value_loss": 0.01830832747121652, "policy_loss": -0.010598523610159323, "dist_entropy": 0.5689701398213705, "actor_grad_norm": 0.2024756222963333, "critic_grad_norm": 0.027578944340348244, "ratio": 1.000231146812439, "entropy": 0.5689701398213705, "incre_win_rate": 0.6833333333333333, "step": 193}
{"time": 1766586050.0555382, "phase": "train", "update": 194, "total_env_steps": 620800, "episode_reward": 0.3156227171421051, "value_loss": 0.021424720933039983, "policy_loss": -0.011871288125188072, "dist_entropy": 0.5655341625213623, "actor_grad_norm": 0.1963975429534912, "critic_grad_norm": 0.0417582131922245, "ratio": 0.999821662902832, "entropy": 0.5655341625213623, "incre_win_rate": 0.6428571428571429, "step": 194}
{"time": 1766586054.6610441, "phase": "train", "update": 195, "total_env_steps": 624000, "episode_reward": 0.3330131769180298, "value_loss": 0.022860468303163847, "policy_loss": -0.01160130963480886, "dist_entropy": 0.5739943981170654, "actor_grad_norm": 0.19361849129199982, "critic_grad_norm": 0.04556573927402496, "ratio": 0.9997696876525879, "entropy": 0.5739943981170654, "incre_win_rate": 0.6290322580645161, "step": 195}
{"time": 1766586059.2507813, "phase": "train", "update": 196, "total_env_steps": 627200, "episode_reward": 0.32586702704429626, "value_loss": 0.021800430988272033, "policy_loss": -0.01095668902377156, "dist_entropy": 0.5666811903317769, "actor_grad_norm": 0.2104554921388626, "critic_grad_norm": 0.026049530133605003, "ratio": 0.9989891052246094, "entropy": 0.5666811903317769, "incre_win_rate": 0.6491228070175439, "step": 196}
{"time": 1766586063.8363748, "phase": "train", "update": 197, "total_env_steps": 630400, "episode_reward": 0.327284038066864, "value_loss": 0.01791411153972149, "policy_loss": -0.01121319938737635, "dist_entropy": 0.5782641569773356, "actor_grad_norm": 0.1680983006954193, "critic_grad_norm": 0.07640361040830612, "ratio": 0.9991786479949951, "entropy": 0.5782641569773356, "incre_win_rate": 0.7068965517241379, "step": 197}
{"time": 1766586068.3825543, "phase": "train", "update": 198, "total_env_steps": 633600, "episode_reward": 0.3172227144241333, "value_loss": 0.021362925693392754, "policy_loss": -0.011712981945932673, "dist_entropy": 0.5908393700917561, "actor_grad_norm": 0.18344439566135406, "critic_grad_norm": 0.07897508889436722, "ratio": 0.9988952279090881, "entropy": 0.5908393700917561, "incre_win_rate": 0.6842105263157895, "step": 198}
{"time": 1766586072.8960223, "phase": "train", "update": 199, "total_env_steps": 636800, "episode_reward": 0.329276978969574, "value_loss": 0.01624076658238967, "policy_loss": -0.012083786006909729, "dist_entropy": 0.5663959940274557, "actor_grad_norm": 0.2512430250644684, "critic_grad_norm": 0.03988068178296089, "ratio": 0.998866617679596, "entropy": 0.5663959940274557, "incre_win_rate": 0.7368421052631579, "step": 199}
{"time": 1766586077.4332113, "phase": "train", "update": 200, "total_env_steps": 640000, "episode_reward": 0.31848424673080444, "value_loss": 0.019529157256086668, "policy_loss": -0.012379685925458735, "dist_entropy": 0.5619734168052674, "actor_grad_norm": 0.1777305155992508, "critic_grad_norm": 0.11769035458564758, "ratio": 0.999384343624115, "entropy": 0.5619734168052674, "incre_win_rate": 0.625, "step": 200}
{"time": 1766586081.9668512, "phase": "train", "update": 201, "total_env_steps": 643200, "episode_reward": 0.32362133264541626, "value_loss": 0.02137950696051121, "policy_loss": -0.011334174748408069, "dist_entropy": 0.5736452221870423, "actor_grad_norm": 0.18168644607067108, "critic_grad_norm": 0.05304514616727829, "ratio": 0.9992323517799377, "entropy": 0.5736452221870423, "incre_win_rate": 0.6842105263157895, "step": 201}
{"time": 1766586089.7713778, "phase": "eval", "update": 201, "total_env_steps": 643200, "eval_win_rate": 0.84375, "eval_episode_reward": 19.139935661764707, "step": 201}
{"time": 1766586094.3286016, "phase": "train", "update": 202, "total_env_steps": 646400, "episode_reward": 0.30899128317832947, "value_loss": 0.020892956977089247, "policy_loss": -0.012322290990322433, "dist_entropy": 0.5974056243896484, "actor_grad_norm": 0.23210430145263672, "critic_grad_norm": 0.03128707781434059, "ratio": 0.9996406435966492, "entropy": 0.5974056243896484, "incre_win_rate": 0.625, "step": 202}
{"time": 1766586098.8528965, "phase": "train", "update": 203, "total_env_steps": 649600, "episode_reward": 0.31846123933792114, "value_loss": 0.016472401469945906, "policy_loss": -0.011031526388981187, "dist_entropy": 0.6074628869692484, "actor_grad_norm": 0.20302928984165192, "critic_grad_norm": 0.036144424229860306, "ratio": 0.9987034201622009, "entropy": 0.6074628869692484, "incre_win_rate": 0.7272727272727273, "step": 203}
{"time": 1766586103.3981082, "phase": "train", "update": 204, "total_env_steps": 652800, "episode_reward": 0.31384575366973877, "value_loss": 0.019996062417825065, "policy_loss": -0.011698402783918737, "dist_entropy": 0.6036894838015239, "actor_grad_norm": 0.23205967247486115, "critic_grad_norm": 0.05613643676042557, "ratio": 0.9993274807929993, "entropy": 0.6036894838015239, "incre_win_rate": 0.6964285714285714, "step": 204}
{"time": 1766586107.9928803, "phase": "train", "update": 205, "total_env_steps": 656000, "episode_reward": 0.32934054732322693, "value_loss": 0.018670537446935972, "policy_loss": -0.011226838013841464, "dist_entropy": 0.5808947642644247, "actor_grad_norm": 0.19544100761413574, "critic_grad_norm": 0.10074977576732635, "ratio": 0.9994051456451416, "entropy": 0.5808947642644247, "incre_win_rate": 0.7636363636363637, "step": 205}
{"time": 1766586112.546766, "phase": "train", "update": 206, "total_env_steps": 659200, "episode_reward": 0.31917279958724976, "value_loss": 0.020492649699250857, "policy_loss": -0.011823093278061947, "dist_entropy": 0.590412990252177, "actor_grad_norm": 0.24194413423538208, "critic_grad_norm": 0.051083359867334366, "ratio": 0.9997031688690186, "entropy": 0.590412990252177, "incre_win_rate": 0.7142857142857143, "step": 206}
{"time": 1766586117.1539917, "phase": "train", "update": 207, "total_env_steps": 662400, "episode_reward": 0.33014020323753357, "value_loss": 0.015179639185468356, "policy_loss": -0.012472683563436723, "dist_entropy": 0.5815106431643168, "actor_grad_norm": 0.20936991274356842, "critic_grad_norm": 0.0786825492978096, "ratio": 0.9986858367919922, "entropy": 0.5815106431643168, "incre_win_rate": 0.7192982456140351, "step": 207}
{"time": 1766586121.6923952, "phase": "train", "update": 208, "total_env_steps": 665600, "episode_reward": 0.3232046365737915, "value_loss": 0.021495237946510315, "policy_loss": -0.011539924423640002, "dist_entropy": 0.5800584435462952, "actor_grad_norm": 0.1926340013742447, "critic_grad_norm": 0.057864245027303696, "ratio": 0.9983853697776794, "entropy": 0.5800584435462952, "incre_win_rate": 0.6949152542372882, "step": 208}
{"time": 1766586126.225646, "phase": "train", "update": 209, "total_env_steps": 668800, "episode_reward": 0.31093829870224, "value_loss": 0.02376273348927498, "policy_loss": -0.012431669057043375, "dist_entropy": 0.5627782424290975, "actor_grad_norm": 0.2180645763874054, "critic_grad_norm": 0.1065789982676506, "ratio": 0.9991496205329895, "entropy": 0.5627782424290975, "incre_win_rate": 0.5862068965517241, "step": 209}
{"time": 1766586130.8732433, "phase": "train", "update": 210, "total_env_steps": 672000, "episode_reward": 0.3094531297683716, "value_loss": 0.016802534398933252, "policy_loss": -0.01226134132998622, "dist_entropy": 0.6053597529729208, "actor_grad_norm": 0.2605971395969391, "critic_grad_norm": 0.061566147953271866, "ratio": 0.9993792176246643, "entropy": 0.6053597529729208, "incre_win_rate": 0.625, "step": 210}
{"time": 1766586135.4472787, "phase": "train", "update": 211, "total_env_steps": 675200, "episode_reward": 0.31612056493759155, "value_loss": 0.016638851600388686, "policy_loss": -0.011473936745452799, "dist_entropy": 0.5699979265530905, "actor_grad_norm": 0.18921029567718506, "critic_grad_norm": 0.05457484722137451, "ratio": 0.9997643232345581, "entropy": 0.5699979265530905, "incre_win_rate": 0.6851851851851852, "step": 211}
{"time": 1766586140.064793, "phase": "train", "update": 212, "total_env_steps": 678400, "episode_reward": 0.32902881503105164, "value_loss": 0.016223296771446863, "policy_loss": -0.012283791938513863, "dist_entropy": 0.5724850535392761, "actor_grad_norm": 0.2547101378440857, "critic_grad_norm": 0.0327913872897625, "ratio": 0.99946129322052, "entropy": 0.5724850535392761, "incre_win_rate": 0.7192982456140351, "step": 212}
{"time": 1766586144.6717894, "phase": "train", "update": 213, "total_env_steps": 681600, "episode_reward": 0.31652113795280457, "value_loss": 0.019245011359453203, "policy_loss": -0.012242276352017712, "dist_entropy": 0.5786997437477112, "actor_grad_norm": 0.19037026166915894, "critic_grad_norm": 0.051907412707805634, "ratio": 0.9996808171272278, "entropy": 0.5786997437477112, "incre_win_rate": 0.6551724137931034, "step": 213}
{"time": 1766586149.289486, "phase": "train", "update": 214, "total_env_steps": 684800, "episode_reward": 0.32178235054016113, "value_loss": 0.02416897565126419, "policy_loss": -0.012750228179126093, "dist_entropy": 0.5724181175231934, "actor_grad_norm": 0.18745103478431702, "critic_grad_norm": 0.07974766939878464, "ratio": 0.9998325109481812, "entropy": 0.5724181175231934, "incre_win_rate": 0.6545454545454545, "step": 214}
{"time": 1766586153.8258412, "phase": "train", "update": 215, "total_env_steps": 688000, "episode_reward": 0.3244263231754303, "value_loss": 0.022463492304086684, "policy_loss": -0.012645372073608977, "dist_entropy": 0.5540404717127482, "actor_grad_norm": 0.1886281818151474, "critic_grad_norm": 0.03902673348784447, "ratio": 0.9988380670547485, "entropy": 0.5540404717127482, "incre_win_rate": 0.639344262295082, "step": 215}
{"time": 1766586158.4617581, "phase": "train", "update": 216, "total_env_steps": 691200, "episode_reward": 0.33650198578834534, "value_loss": 0.018293709059556327, "policy_loss": -0.012266166428988375, "dist_entropy": 0.5550006667772929, "actor_grad_norm": 0.18036849796772003, "critic_grad_norm": 0.03467173874378204, "ratio": 0.9993858337402344, "entropy": 0.5550006667772929, "incre_win_rate": 0.7068965517241379, "step": 216}
{"time": 1766586163.0273798, "phase": "train", "update": 217, "total_env_steps": 694400, "episode_reward": 0.33388635516166687, "value_loss": 0.015432828788956006, "policy_loss": -0.011592354653204495, "dist_entropy": 0.5596979657808939, "actor_grad_norm": 0.18393348157405853, "critic_grad_norm": 0.01714617758989334, "ratio": 0.998899519443512, "entropy": 0.5596979657808939, "incre_win_rate": 0.7413793103448276, "step": 217}
{"time": 1766586167.6086838, "phase": "train", "update": 218, "total_env_steps": 697600, "episode_reward": 0.33146291971206665, "value_loss": 0.021117519587278366, "policy_loss": -0.011591670897115118, "dist_entropy": 0.5661452809969584, "actor_grad_norm": 0.1809389293193817, "critic_grad_norm": 0.047041524201631546, "ratio": 1.0000789165496826, "entropy": 0.5661452809969584, "incre_win_rate": 0.6896551724137931, "step": 218}
{"time": 1766586172.1524677, "phase": "train", "update": 219, "total_env_steps": 700800, "episode_reward": 0.33087238669395447, "value_loss": 0.015502301851908366, "policy_loss": -0.011534653053190406, "dist_entropy": 0.5632314483324686, "actor_grad_norm": 0.20893019437789917, "critic_grad_norm": 0.04409319907426834, "ratio": 0.998608410358429, "entropy": 0.5632314483324686, "incre_win_rate": 0.6896551724137931, "step": 219}
{"time": 1766586176.6891596, "phase": "train", "update": 220, "total_env_steps": 704000, "episode_reward": 0.3279595971107483, "value_loss": 0.018176693469285965, "policy_loss": -0.010912957931305941, "dist_entropy": 0.5669656356175741, "actor_grad_norm": 0.22508201003074646, "critic_grad_norm": 0.07730040699243546, "ratio": 0.9982843995094299, "entropy": 0.5669656356175741, "incre_win_rate": 0.6379310344827587, "step": 220}
{"time": 1766586181.3584714, "phase": "train", "update": 221, "total_env_steps": 707200, "episode_reward": 0.3274977207183838, "value_loss": 0.018443466102083524, "policy_loss": -0.0123366492903898, "dist_entropy": 0.5878689567248027, "actor_grad_norm": 0.17679429054260254, "critic_grad_norm": 0.06076700612902641, "ratio": 0.9986386299133301, "entropy": 0.5878689567248027, "incre_win_rate": 0.7068965517241379, "step": 221}
{"time": 1766586188.712273, "phase": "eval", "update": 221, "total_env_steps": 707200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.71277573529412, "step": 221}
{"time": 1766586193.3068693, "phase": "train", "update": 222, "total_env_steps": 710400, "episode_reward": 0.344942569732666, "value_loss": 0.016492614336311818, "policy_loss": -0.012112233397332754, "dist_entropy": 0.6037584582964579, "actor_grad_norm": 0.21084214746952057, "critic_grad_norm": 0.09058380126953125, "ratio": 0.999213695526123, "entropy": 0.6037584582964579, "incre_win_rate": 0.7333333333333333, "step": 222}
{"time": 1766586197.9180946, "phase": "train", "update": 223, "total_env_steps": 713600, "episode_reward": 0.337715208530426, "value_loss": 0.015043977710107962, "policy_loss": -0.011610563366911226, "dist_entropy": 0.5899391492207845, "actor_grad_norm": 0.2262841910123825, "critic_grad_norm": 0.05938071757555008, "ratio": 0.9993127584457397, "entropy": 0.5899391492207845, "incre_win_rate": 0.7368421052631579, "step": 223}
{"time": 1766586202.4142492, "phase": "train", "update": 224, "total_env_steps": 716800, "episode_reward": 0.3282666802406311, "value_loss": 0.014274533713857333, "policy_loss": -0.011377606551479857, "dist_entropy": 0.6043416500091553, "actor_grad_norm": 0.22790741920471191, "critic_grad_norm": 0.02692706137895584, "ratio": 0.9995120167732239, "entropy": 0.6043416500091553, "incre_win_rate": 0.6833333333333333, "step": 224}
{"time": 1766586206.9576643, "phase": "train", "update": 225, "total_env_steps": 720000, "episode_reward": 0.3441452383995056, "value_loss": 0.012076880720754465, "policy_loss": -0.01220997283616505, "dist_entropy": 0.6196141958236694, "actor_grad_norm": 0.19068792462348938, "critic_grad_norm": 0.04284597560763359, "ratio": 0.9984984397888184, "entropy": 0.6196141958236694, "incre_win_rate": 0.7857142857142857, "step": 225}
{"time": 1766586211.5417042, "phase": "train", "update": 226, "total_env_steps": 723200, "episode_reward": 0.3195159435272217, "value_loss": 0.01997847283879916, "policy_loss": -0.012246053644694636, "dist_entropy": 0.6142406105995178, "actor_grad_norm": 0.21301673352718353, "critic_grad_norm": 0.08983157575130463, "ratio": 0.9993911981582642, "entropy": 0.6142406105995178, "incre_win_rate": 0.6, "step": 226}
{"time": 1766586216.0995274, "phase": "train", "update": 227, "total_env_steps": 726400, "episode_reward": 0.3252841830253601, "value_loss": 0.018643338481585184, "policy_loss": -0.01087476543029311, "dist_entropy": 0.5870251615842184, "actor_grad_norm": 0.18460354208946228, "critic_grad_norm": 0.037573494017124176, "ratio": 0.9997931718826294, "entropy": 0.5870251615842184, "incre_win_rate": 0.6140350877192983, "step": 227}
{"time": 1766586220.7117195, "phase": "train", "update": 228, "total_env_steps": 729600, "episode_reward": 0.3227044939994812, "value_loss": 0.021013051519791284, "policy_loss": -0.012085367094977902, "dist_entropy": 0.6110794186592102, "actor_grad_norm": 0.1750604510307312, "critic_grad_norm": 0.040050994604825974, "ratio": 0.9994848966598511, "entropy": 0.6110794186592102, "incre_win_rate": 0.5573770491803278, "step": 228}
{"time": 1766586225.2608888, "phase": "train", "update": 229, "total_env_steps": 732800, "episode_reward": 0.32747164368629456, "value_loss": 0.01731760042409102, "policy_loss": -0.011273049621081555, "dist_entropy": 0.6005725741386414, "actor_grad_norm": 0.2204127013683319, "critic_grad_norm": 0.042316753417253494, "ratio": 0.9986386895179749, "entropy": 0.6005725741386414, "incre_win_rate": 0.6206896551724138, "step": 229}
{"time": 1766586229.8491166, "phase": "train", "update": 230, "total_env_steps": 736000, "episode_reward": 0.3359282910823822, "value_loss": 0.016332477206985156, "policy_loss": -0.011166346614490822, "dist_entropy": 0.5977174162864685, "actor_grad_norm": 0.17221057415008545, "critic_grad_norm": 0.04140888527035713, "ratio": 0.998683512210846, "entropy": 0.5977174162864685, "incre_win_rate": 0.6065573770491803, "step": 230}
{"time": 1766586234.408365, "phase": "train", "update": 231, "total_env_steps": 739200, "episode_reward": 0.33604857325553894, "value_loss": 0.01575475533803304, "policy_loss": -0.011602474439609267, "dist_entropy": 0.5995258768399556, "actor_grad_norm": 0.20242635905742645, "critic_grad_norm": 0.11038056015968323, "ratio": 0.999198853969574, "entropy": 0.5995258768399556, "incre_win_rate": 0.7586206896551724, "step": 231}
{"time": 1766586239.1168869, "phase": "train", "update": 232, "total_env_steps": 742400, "episode_reward": 0.33003753423690796, "value_loss": 0.019198507939775785, "policy_loss": -0.01198618282618232, "dist_entropy": 0.5869954506556193, "actor_grad_norm": 0.1915511041879654, "critic_grad_norm": 0.07880797982215881, "ratio": 0.9986432194709778, "entropy": 0.5869954506556193, "incre_win_rate": 0.6491228070175439, "step": 232}
{"time": 1766586243.6701033, "phase": "train", "update": 233, "total_env_steps": 745600, "episode_reward": 0.34622398018836975, "value_loss": 0.014556961134076118, "policy_loss": -0.010526154323910457, "dist_entropy": 0.5834155917167664, "actor_grad_norm": 0.2245875597000122, "critic_grad_norm": 0.08614033460617065, "ratio": 0.9991105198860168, "entropy": 0.5834155917167664, "incre_win_rate": 0.8166666666666667, "step": 233}
{"time": 1766586248.3283238, "phase": "train", "update": 234, "total_env_steps": 748800, "episode_reward": 0.3408946096897125, "value_loss": 0.014795849720637003, "policy_loss": -0.011331579177484249, "dist_entropy": 0.5843330184618633, "actor_grad_norm": 0.20409438014030457, "critic_grad_norm": 0.08650514483451843, "ratio": 0.9996932148933411, "entropy": 0.5843330184618633, "incre_win_rate": 0.7457627118644068, "step": 234}
{"time": 1766586252.948052, "phase": "train", "update": 235, "total_env_steps": 752000, "episode_reward": 0.3345182538032532, "value_loss": 0.01798127591609955, "policy_loss": -0.0113425737912569, "dist_entropy": 0.5958608229955037, "actor_grad_norm": 0.19273360073566437, "critic_grad_norm": 0.031601663678884506, "ratio": 0.9985673427581787, "entropy": 0.5958608229955037, "incre_win_rate": 0.7068965517241379, "step": 235}
{"time": 1766586257.5655184, "phase": "train", "update": 236, "total_env_steps": 755200, "episode_reward": 0.34604549407958984, "value_loss": 0.012801031954586506, "policy_loss": -0.0115933330753478, "dist_entropy": 0.6246511220932007, "actor_grad_norm": 0.1806938648223877, "critic_grad_norm": 0.0420234277844429, "ratio": 0.9991683959960938, "entropy": 0.6246511220932007, "incre_win_rate": 0.7966101694915254, "step": 236}
{"time": 1766586262.139975, "phase": "train", "update": 237, "total_env_steps": 758400, "episode_reward": 0.3482973277568817, "value_loss": 0.013924527727067471, "policy_loss": -0.01181487045397939, "dist_entropy": 0.6024656534194947, "actor_grad_norm": 0.15629751980304718, "critic_grad_norm": 0.021377312019467354, "ratio": 0.9985223412513733, "entropy": 0.6024656534194947, "incre_win_rate": 0.75, "step": 237}
{"time": 1766586266.7636838, "phase": "train", "update": 238, "total_env_steps": 761600, "episode_reward": 0.3239162266254425, "value_loss": 0.019318541263540587, "policy_loss": -0.011856328696317557, "dist_entropy": 0.6122127890586853, "actor_grad_norm": 0.19026947021484375, "critic_grad_norm": 0.19226403534412384, "ratio": 0.9993622303009033, "entropy": 0.6122127890586853, "incre_win_rate": 0.5254237288135594, "step": 238}
{"time": 1766586271.3880577, "phase": "train", "update": 239, "total_env_steps": 764800, "episode_reward": 0.34658318758010864, "value_loss": 0.01560608937094609, "policy_loss": -0.010754118127360357, "dist_entropy": 0.6213749289512634, "actor_grad_norm": 0.19014251232147217, "critic_grad_norm": 0.046880897134542465, "ratio": 0.9989562034606934, "entropy": 0.6213749289512634, "incre_win_rate": 0.8166666666666667, "step": 239}
{"time": 1766586275.8953552, "phase": "train", "update": 240, "total_env_steps": 768000, "episode_reward": 0.3192402422428131, "value_loss": 0.019670799747109412, "policy_loss": -0.011537360352193105, "dist_entropy": 0.6036876320838929, "actor_grad_norm": 0.23667654395103455, "critic_grad_norm": 0.07875911891460419, "ratio": 0.9989091753959656, "entropy": 0.6036876320838929, "incre_win_rate": 0.6181818181818182, "step": 240}
{"time": 1766586280.4898574, "phase": "train", "update": 241, "total_env_steps": 771200, "episode_reward": 0.3359551429748535, "value_loss": 0.015029797268410524, "policy_loss": -0.010651708041621315, "dist_entropy": 0.6220852335294088, "actor_grad_norm": 0.19462114572525024, "critic_grad_norm": 0.04964452609419823, "ratio": 0.9990530014038086, "entropy": 0.6220852335294088, "incre_win_rate": 0.7457627118644068, "step": 241}
{"time": 1766586287.5898144, "phase": "eval", "update": 241, "total_env_steps": 771200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.83670343137255, "step": 241}
{"time": 1766586292.1330695, "phase": "train", "update": 242, "total_env_steps": 774400, "episode_reward": 0.3125704526901245, "value_loss": 0.01761175220211347, "policy_loss": -0.011960804703109791, "dist_entropy": 0.614702316125234, "actor_grad_norm": 0.17611998319625854, "critic_grad_norm": 0.08294221758842468, "ratio": 1.0001980066299438, "entropy": 0.614702316125234, "incre_win_rate": 0.6140350877192983, "step": 242}
{"time": 1766586296.7613828, "phase": "train", "update": 243, "total_env_steps": 777600, "episode_reward": 0.33388787508010864, "value_loss": 0.016033501426378886, "policy_loss": -0.011151639611377936, "dist_entropy": 0.6069678227106731, "actor_grad_norm": 0.2291424572467804, "critic_grad_norm": 0.06551200896501541, "ratio": 0.9991840124130249, "entropy": 0.6069678227106731, "incre_win_rate": 0.6842105263157895, "step": 243}
{"time": 1766586301.3766015, "phase": "train", "update": 244, "total_env_steps": 780800, "episode_reward": 0.3329036235809326, "value_loss": 0.015958218152324358, "policy_loss": -0.012297660331781035, "dist_entropy": 0.6087313214937846, "actor_grad_norm": 0.23434148728847504, "critic_grad_norm": 0.04667232930660248, "ratio": 0.9991762042045593, "entropy": 0.6087313214937846, "incre_win_rate": 0.7288135593220338, "step": 244}
{"time": 1766586306.1780534, "phase": "train", "update": 245, "total_env_steps": 784000, "episode_reward": 0.3455859422683716, "value_loss": 0.016048899851739407, "policy_loss": -0.010157004309295796, "dist_entropy": 0.606828773021698, "actor_grad_norm": 0.2127884179353714, "critic_grad_norm": 0.03824339807033539, "ratio": 1.0001966953277588, "entropy": 0.606828773021698, "incre_win_rate": 0.7966101694915254, "step": 245}
{"time": 1766586310.873626, "phase": "train", "update": 246, "total_env_steps": 787200, "episode_reward": 0.3470749258995056, "value_loss": 0.01598433405160904, "policy_loss": -0.011126511933367549, "dist_entropy": 0.5998013178507487, "actor_grad_norm": 0.1676502525806427, "critic_grad_norm": 0.026802746579051018, "ratio": 0.9992731809616089, "entropy": 0.5998013178507487, "incre_win_rate": 0.7796610169491526, "step": 246}
{"time": 1766586315.4386213, "phase": "train", "update": 247, "total_env_steps": 790400, "episode_reward": 0.33187270164489746, "value_loss": 0.01807716575761636, "policy_loss": -0.011724121232808216, "dist_entropy": 0.5973808526992798, "actor_grad_norm": 0.20731183886528015, "critic_grad_norm": 0.06792932003736496, "ratio": 1.0001342296600342, "entropy": 0.5973808526992798, "incre_win_rate": 0.6842105263157895, "step": 247}
{"time": 1766586320.0333571, "phase": "train", "update": 248, "total_env_steps": 793600, "episode_reward": 0.34845206141471863, "value_loss": 0.012124631553888321, "policy_loss": -0.010799521153922834, "dist_entropy": 0.5984658996264139, "actor_grad_norm": 0.18728592991828918, "critic_grad_norm": 0.045634277164936066, "ratio": 0.9997828602790833, "entropy": 0.5984658996264139, "incre_win_rate": 0.819672131147541, "step": 248}
{"time": 1766586324.6177707, "phase": "train", "update": 249, "total_env_steps": 796800, "episode_reward": 0.3534635603427887, "value_loss": 0.011742314385871092, "policy_loss": -0.010703560452985764, "dist_entropy": 0.5767501791318258, "actor_grad_norm": 0.19030123949050903, "critic_grad_norm": 0.038960009813308716, "ratio": 0.9995144009590149, "entropy": 0.5767501791318258, "incre_win_rate": 0.8571428571428571, "step": 249}
{"time": 1766586329.201145, "phase": "train", "update": 250, "total_env_steps": 800000, "episode_reward": 0.3512461483478546, "value_loss": 0.012151819902161758, "policy_loss": -0.010379259593444108, "dist_entropy": 0.5690498073895772, "actor_grad_norm": 0.18257102370262146, "critic_grad_norm": 0.029572831466794014, "ratio": 0.9989089369773865, "entropy": 0.5690498073895772, "incre_win_rate": 0.7903225806451613, "step": 250}
{"time": 1766586333.724889, "phase": "train", "update": 251, "total_env_steps": 803200, "episode_reward": 0.3518305718898773, "value_loss": 0.010464597990115483, "policy_loss": -0.010834291394505157, "dist_entropy": 0.5837011456489563, "actor_grad_norm": 0.1597035825252533, "critic_grad_norm": 0.036424972116947174, "ratio": 0.997904896736145, "entropy": 0.5837011456489563, "incre_win_rate": 0.8947368421052632, "step": 251}
{"time": 1766586338.340253, "phase": "train", "update": 252, "total_env_steps": 806400, "episode_reward": 0.3399203419685364, "value_loss": 0.014064907779296238, "policy_loss": -0.010576665455371882, "dist_entropy": 0.5669042309125264, "actor_grad_norm": 0.15930330753326416, "critic_grad_norm": 0.10019275546073914, "ratio": 0.9989962577819824, "entropy": 0.5669042309125264, "incre_win_rate": 0.7540983606557377, "step": 252}
{"time": 1766586342.9427671, "phase": "train", "update": 253, "total_env_steps": 809600, "episode_reward": 0.3466797173023224, "value_loss": 0.013332986707488696, "policy_loss": -0.010629648049852372, "dist_entropy": 0.5678882280985514, "actor_grad_norm": 0.15815386176109314, "critic_grad_norm": 0.03872416168451309, "ratio": 1.0004286766052246, "entropy": 0.5678882280985514, "incre_win_rate": 0.7719298245614035, "step": 253}
{"time": 1766586347.4374282, "phase": "train", "update": 254, "total_env_steps": 812800, "episode_reward": 0.33948224782943726, "value_loss": 0.01908244291941325, "policy_loss": -0.011347608904262074, "dist_entropy": 0.5676532983779907, "actor_grad_norm": 0.2091255635023117, "critic_grad_norm": 0.049806416034698486, "ratio": 1.0004193782806396, "entropy": 0.5676532983779907, "incre_win_rate": 0.7049180327868853, "step": 254}
{"time": 1766586352.0355465, "phase": "train", "update": 255, "total_env_steps": 816000, "episode_reward": 0.32271063327789307, "value_loss": 0.016008882224559783, "policy_loss": -0.010832195015656037, "dist_entropy": 0.5691096941630046, "actor_grad_norm": 0.1890193521976471, "critic_grad_norm": 0.053345829248428345, "ratio": 0.9988487362861633, "entropy": 0.5691096941630046, "incre_win_rate": 0.6724137931034483, "step": 255}
{"time": 1766586356.578952, "phase": "train", "update": 256, "total_env_steps": 819200, "episode_reward": 0.3551417291164398, "value_loss": 0.012162957650919756, "policy_loss": -0.010781372451168163, "dist_entropy": 0.5640362501144409, "actor_grad_norm": 0.19042515754699707, "critic_grad_norm": 0.0469820499420166, "ratio": 1.0007575750350952, "entropy": 0.5640362501144409, "incre_win_rate": 0.8275862068965517, "step": 256}
{"time": 1766586361.1493454, "phase": "train", "update": 257, "total_env_steps": 822400, "episode_reward": 0.3407314419746399, "value_loss": 0.013263148814439773, "policy_loss": -0.011774373745746894, "dist_entropy": 0.5662501255671183, "actor_grad_norm": 0.17372357845306396, "critic_grad_norm": 0.024532413110136986, "ratio": 0.999479353427887, "entropy": 0.5662501255671183, "incre_win_rate": 0.7333333333333333, "step": 257}
{"time": 1766586365.8192668, "phase": "train", "update": 258, "total_env_steps": 825600, "episode_reward": 0.34752991795539856, "value_loss": 0.014042715976635615, "policy_loss": -0.010557998502902895, "dist_entropy": 0.5589706381162007, "actor_grad_norm": 0.17620432376861572, "critic_grad_norm": 0.04341509938240051, "ratio": 1.0000746250152588, "entropy": 0.5589706381162007, "incre_win_rate": 0.7288135593220338, "step": 258}
{"time": 1766586370.4636207, "phase": "train", "update": 259, "total_env_steps": 828800, "episode_reward": 0.3359757959842682, "value_loss": 0.014624522253870963, "policy_loss": -0.010657732341543161, "dist_entropy": 0.5551340778668722, "actor_grad_norm": 0.20147085189819336, "critic_grad_norm": 0.04112939536571503, "ratio": 0.9993360638618469, "entropy": 0.5551340778668722, "incre_win_rate": 0.6833333333333333, "step": 259}
{"time": 1766586375.0471945, "phase": "train", "update": 260, "total_env_steps": 832000, "episode_reward": 0.3373858630657196, "value_loss": 0.014161601414283116, "policy_loss": -0.011718146192725007, "dist_entropy": 0.5620928923288981, "actor_grad_norm": 0.17793458700180054, "critic_grad_norm": 0.03943448141217232, "ratio": 0.9991609454154968, "entropy": 0.5620928923288981, "incre_win_rate": 0.7068965517241379, "step": 260}
{"time": 1766586379.597044, "phase": "train", "update": 261, "total_env_steps": 835200, "episode_reward": 0.35259345173835754, "value_loss": 0.010269000319143136, "policy_loss": -0.011025208400333024, "dist_entropy": 0.5635742465655009, "actor_grad_norm": 0.19467157125473022, "critic_grad_norm": 0.10217919200658798, "ratio": 0.9983507394790649, "entropy": 0.5635742465655009, "incre_win_rate": 0.847457627118644, "step": 261}
{"time": 1766586386.6703415, "phase": "eval", "update": 261, "total_env_steps": 835200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.787071078431374, "step": 261}
{"time": 1766586391.2784064, "phase": "train", "update": 262, "total_env_steps": 838400, "episode_reward": 0.3436703383922577, "value_loss": 0.012377431926627954, "policy_loss": -0.010881479978398546, "dist_entropy": 0.5451857129732768, "actor_grad_norm": 0.15728676319122314, "critic_grad_norm": 0.03423314169049263, "ratio": 0.998971700668335, "entropy": 0.5451857129732768, "incre_win_rate": 0.8245614035087719, "step": 262}
{"time": 1766586395.9301293, "phase": "train", "update": 263, "total_env_steps": 841600, "episode_reward": 0.35747474431991577, "value_loss": 0.01406689106176297, "policy_loss": -0.010075319322520688, "dist_entropy": 0.5541363636652629, "actor_grad_norm": 0.19349169731140137, "critic_grad_norm": 0.02727595902979374, "ratio": 0.9994983673095703, "entropy": 0.5541363636652629, "incre_win_rate": 0.7741935483870968, "step": 263}
{"time": 1766586400.5290527, "phase": "train", "update": 264, "total_env_steps": 844800, "episode_reward": 0.35265934467315674, "value_loss": 0.010142859444022179, "policy_loss": -0.011188879678441784, "dist_entropy": 0.555553138256073, "actor_grad_norm": 0.16276012361049652, "critic_grad_norm": 0.038634903728961945, "ratio": 0.9991148114204407, "entropy": 0.555553138256073, "incre_win_rate": 0.8333333333333334, "step": 264}
{"time": 1766586405.109032, "phase": "train", "update": 265, "total_env_steps": 848000, "episode_reward": 0.35839155316352844, "value_loss": 0.008287493946651618, "policy_loss": -0.010376812852841037, "dist_entropy": 0.5627830187479655, "actor_grad_norm": 0.16087323427200317, "critic_grad_norm": 0.042086392641067505, "ratio": 1.0001659393310547, "entropy": 0.5627830187479655, "incre_win_rate": 0.8305084745762712, "step": 265}
{"time": 1766586409.6958232, "phase": "train", "update": 266, "total_env_steps": 851200, "episode_reward": 0.3553163409233093, "value_loss": 0.011166402511298657, "policy_loss": -0.010579088106789905, "dist_entropy": 0.5619632760683696, "actor_grad_norm": 0.2099394053220749, "critic_grad_norm": 0.017203377559781075, "ratio": 0.9990103840827942, "entropy": 0.5619632760683696, "incre_win_rate": 0.8421052631578947, "step": 266}
{"time": 1766586414.3444457, "phase": "train", "update": 267, "total_env_steps": 854400, "episode_reward": 0.3565150201320648, "value_loss": 0.015026071978112062, "policy_loss": -0.010546593267295633, "dist_entropy": 0.5377920309702555, "actor_grad_norm": 0.19438166916370392, "critic_grad_norm": 0.04285292327404022, "ratio": 0.9994289875030518, "entropy": 0.5377920309702555, "incre_win_rate": 0.7777777777777778, "step": 267}
{"time": 1766586418.876436, "phase": "train", "update": 268, "total_env_steps": 857600, "episode_reward": 0.3467785120010376, "value_loss": 0.011686819605529308, "policy_loss": -0.0107114128005558, "dist_entropy": 0.5522953828175863, "actor_grad_norm": 0.1719198375940323, "critic_grad_norm": 0.030278436839580536, "ratio": 0.9996188282966614, "entropy": 0.5522953828175863, "incre_win_rate": 0.7833333333333333, "step": 268}
{"time": 1766586423.5138772, "phase": "train", "update": 269, "total_env_steps": 860800, "episode_reward": 0.355724573135376, "value_loss": 0.012347077329953512, "policy_loss": -0.010326485793872091, "dist_entropy": 0.5552766720453898, "actor_grad_norm": 0.1520545333623886, "critic_grad_norm": 0.019519703462719917, "ratio": 0.9991961717605591, "entropy": 0.5552766720453898, "incre_win_rate": 0.8135593220338984, "step": 269}
{"time": 1766586428.043704, "phase": "train", "update": 270, "total_env_steps": 864000, "episode_reward": 0.3510194718837738, "value_loss": 0.010909466817975045, "policy_loss": -0.010518488896721934, "dist_entropy": 0.5664694547653198, "actor_grad_norm": 0.15886659920215607, "critic_grad_norm": 0.023169541731476784, "ratio": 0.9983735084533691, "entropy": 0.5664694547653198, "incre_win_rate": 0.8333333333333334, "step": 270}
{"time": 1766586432.6019762, "phase": "train", "update": 271, "total_env_steps": 867200, "episode_reward": 0.35272517800331116, "value_loss": 0.01037074780712525, "policy_loss": -0.010169068949616703, "dist_entropy": 0.5477642258008321, "actor_grad_norm": 0.17117147147655487, "critic_grad_norm": 0.01718374714255333, "ratio": 1.000138282775879, "entropy": 0.5477642258008321, "incre_win_rate": 0.7931034482758621, "step": 271}
{"time": 1766586437.2187595, "phase": "train", "update": 272, "total_env_steps": 870400, "episode_reward": 0.3554220199584961, "value_loss": 0.009861648827791215, "policy_loss": -0.01068384779204526, "dist_entropy": 0.5707392692565918, "actor_grad_norm": 0.17076925933361053, "critic_grad_norm": 0.022393133491277695, "ratio": 0.999643087387085, "entropy": 0.5707392692565918, "incre_win_rate": 0.8524590163934426, "step": 272}
{"time": 1766586441.9137983, "phase": "train", "update": 273, "total_env_steps": 873600, "episode_reward": 0.3561902642250061, "value_loss": 0.010055950470268726, "policy_loss": -0.011000376592235501, "dist_entropy": 0.5537424802780151, "actor_grad_norm": 0.18225477635860443, "critic_grad_norm": 0.08741742372512817, "ratio": 1.0004914999008179, "entropy": 0.5537424802780151, "incre_win_rate": 0.8333333333333334, "step": 273}
{"time": 1766586446.5838144, "phase": "train", "update": 274, "total_env_steps": 876800, "episode_reward": 0.3475758731365204, "value_loss": 0.012768787083526452, "policy_loss": -0.009629683813771332, "dist_entropy": 0.5432993292808532, "actor_grad_norm": 0.1492265909910202, "critic_grad_norm": 0.055341675877571106, "ratio": 0.9998399615287781, "entropy": 0.5432993292808532, "incre_win_rate": 0.7833333333333333, "step": 274}
{"time": 1766586451.1301315, "phase": "train", "update": 275, "total_env_steps": 880000, "episode_reward": 0.36045342683792114, "value_loss": 0.010133469042678674, "policy_loss": -0.009936995813491951, "dist_entropy": 0.5278134504954021, "actor_grad_norm": 0.1563652604818344, "critic_grad_norm": 0.03316836059093475, "ratio": 1.001507043838501, "entropy": 0.5278134504954021, "incre_win_rate": 0.85, "step": 275}
{"time": 1766586455.7219946, "phase": "train", "update": 276, "total_env_steps": 883200, "episode_reward": 0.3606395423412323, "value_loss": 0.010676044722398121, "policy_loss": -0.010453028555843484, "dist_entropy": 0.5246426145235698, "actor_grad_norm": 0.17659229040145874, "critic_grad_norm": 0.026822196319699287, "ratio": 0.9986331462860107, "entropy": 0.5246426145235698, "incre_win_rate": 0.819672131147541, "step": 276}
{"time": 1766586460.334178, "phase": "train", "update": 277, "total_env_steps": 886400, "episode_reward": 0.35518768429756165, "value_loss": 0.01077825694034497, "policy_loss": -0.01013741596219262, "dist_entropy": 0.5560895045598347, "actor_grad_norm": 0.14739343523979187, "critic_grad_norm": 0.024620218202471733, "ratio": 0.9995073676109314, "entropy": 0.5560895045598347, "incre_win_rate": 0.8596491228070176, "step": 277}
{"time": 1766586465.0238802, "phase": "train", "update": 278, "total_env_steps": 889600, "episode_reward": 0.3534490168094635, "value_loss": 0.009696728984514872, "policy_loss": -0.010359330022341831, "dist_entropy": 0.5440801501274108, "actor_grad_norm": 0.14094173908233643, "critic_grad_norm": 0.03927469626069069, "ratio": 0.9986310005187988, "entropy": 0.5440801501274108, "incre_win_rate": 0.7619047619047619, "step": 278}
{"time": 1766586469.6129797, "phase": "train", "update": 279, "total_env_steps": 892800, "episode_reward": 0.360836386680603, "value_loss": 0.011321076626578967, "policy_loss": -0.009890938469664927, "dist_entropy": 0.5334541877110799, "actor_grad_norm": 0.1595257669687271, "critic_grad_norm": 0.028850683942437172, "ratio": 0.9993317127227783, "entropy": 0.5334541877110799, "incre_win_rate": 0.8448275862068966, "step": 279}
{"time": 1766586474.2810862, "phase": "train", "update": 280, "total_env_steps": 896000, "episode_reward": 0.3514154553413391, "value_loss": 0.013962273548046748, "policy_loss": -0.01128030148769265, "dist_entropy": 0.5366958538691203, "actor_grad_norm": 0.17186273634433746, "critic_grad_norm": 0.04274309054017067, "ratio": 0.9993404746055603, "entropy": 0.5366958538691203, "incre_win_rate": 0.7540983606557377, "step": 280}
{"time": 1766586478.8699963, "phase": "train", "update": 281, "total_env_steps": 899200, "episode_reward": 0.3432154059410095, "value_loss": 0.01333529595285654, "policy_loss": -0.011228466876979266, "dist_entropy": 0.5470418810844422, "actor_grad_norm": 0.16341982781887054, "critic_grad_norm": 0.030339600518345833, "ratio": 0.9996498823165894, "entropy": 0.5470418810844422, "incre_win_rate": 0.7627118644067796, "step": 281}
{"time": 1766586485.7350786, "phase": "eval", "update": 281, "total_env_steps": 899200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.756127450980394, "step": 281}
{"time": 1766586490.4121802, "phase": "train", "update": 282, "total_env_steps": 902400, "episode_reward": 0.36590227484703064, "value_loss": 0.010551413334906102, "policy_loss": -0.009604646701675297, "dist_entropy": 0.5667284846305847, "actor_grad_norm": 0.13522402942180634, "critic_grad_norm": 0.01940125599503517, "ratio": 0.999505877494812, "entropy": 0.5667284846305847, "incre_win_rate": 0.8688524590163934, "step": 282}
{"time": 1766586495.099499, "phase": "train", "update": 283, "total_env_steps": 905600, "episode_reward": 0.35032933950424194, "value_loss": 0.011297796666622163, "policy_loss": -0.010601977694868007, "dist_entropy": 0.5805419842402141, "actor_grad_norm": 0.16769571602344513, "critic_grad_norm": 0.01516424398869276, "ratio": 1.0002468824386597, "entropy": 0.5805419842402141, "incre_win_rate": 0.75, "step": 283}
{"time": 1766586499.649801, "phase": "train", "update": 284, "total_env_steps": 908800, "episode_reward": 0.36257660388946533, "value_loss": 0.010717275055746238, "policy_loss": -0.00991972376669755, "dist_entropy": 0.5618764162063599, "actor_grad_norm": 0.19149358570575714, "critic_grad_norm": 0.04712275043129921, "ratio": 1.000172734260559, "entropy": 0.5618764162063599, "incre_win_rate": 0.8360655737704918, "step": 284}
{"time": 1766586504.2660081, "phase": "train", "update": 285, "total_env_steps": 912000, "episode_reward": 0.3654312193393707, "value_loss": 0.012364130839705468, "policy_loss": -0.009481420296358796, "dist_entropy": 0.5546186129252116, "actor_grad_norm": 0.2023518830537796, "critic_grad_norm": 0.05324071645736694, "ratio": 0.9995452761650085, "entropy": 0.5546186129252116, "incre_win_rate": 0.8064516129032258, "step": 285}
{"time": 1766586508.8304734, "phase": "train", "update": 286, "total_env_steps": 915200, "episode_reward": 0.3567746579647064, "value_loss": 0.010428770817816258, "policy_loss": -0.010333584344074371, "dist_entropy": 0.5781206727027893, "actor_grad_norm": 0.201297789812088, "critic_grad_norm": 0.029817581176757812, "ratio": 1.0001556873321533, "entropy": 0.5781206727027893, "incre_win_rate": 0.7377049180327869, "step": 286}
{"time": 1766586513.5082235, "phase": "train", "update": 287, "total_env_steps": 918400, "episode_reward": 0.3643527925014496, "value_loss": 0.009271653803686301, "policy_loss": -0.009538551015302942, "dist_entropy": 0.5777006149291992, "actor_grad_norm": 0.15027503669261932, "critic_grad_norm": 0.016379399225115776, "ratio": 1.0008337497711182, "entropy": 0.5777006149291992, "incre_win_rate": 0.85, "step": 287}
{"time": 1766586518.0661843, "phase": "train", "update": 288, "total_env_steps": 921600, "episode_reward": 0.36841145157814026, "value_loss": 0.008265460282564164, "policy_loss": -0.010597336003903498, "dist_entropy": 0.5738360762596131, "actor_grad_norm": 0.14982664585113525, "critic_grad_norm": 0.03007606230676174, "ratio": 0.9993817806243896, "entropy": 0.5738360762596131, "incre_win_rate": 0.8870967741935484, "step": 288}
{"time": 1766586522.810386, "phase": "train", "update": 289, "total_env_steps": 924800, "episode_reward": 0.36532706022262573, "value_loss": 0.012012477839986484, "policy_loss": -0.01030100844411918, "dist_entropy": 0.5684470295906067, "actor_grad_norm": 0.16661740839481354, "critic_grad_norm": 0.027090316638350487, "ratio": 1.0001667737960815, "entropy": 0.5684470295906067, "incre_win_rate": 0.8166666666666667, "step": 289}
{"time": 1766586527.5706077, "phase": "train", "update": 290, "total_env_steps": 928000, "episode_reward": 0.3737277686595917, "value_loss": 0.006884945929050446, "policy_loss": -0.011072104376284149, "dist_entropy": 0.609518293539683, "actor_grad_norm": 0.16787633299827576, "critic_grad_norm": 0.08314669132232666, "ratio": 0.9983837604522705, "entropy": 0.609518293539683, "incre_win_rate": 0.9344262295081968, "step": 290}
{"time": 1766586532.2431047, "phase": "train", "update": 291, "total_env_steps": 931200, "episode_reward": 0.3584926724433899, "value_loss": 0.013423622772097587, "policy_loss": -0.010699916863800497, "dist_entropy": 0.5707186063130697, "actor_grad_norm": 0.1840808391571045, "critic_grad_norm": 0.11884759366512299, "ratio": 1.0009042024612427, "entropy": 0.5707186063130697, "incre_win_rate": 0.7777777777777778, "step": 291}
{"time": 1766586536.8316371, "phase": "train", "update": 292, "total_env_steps": 934400, "episode_reward": 0.3692448139190674, "value_loss": 0.009802253109713395, "policy_loss": -0.010943474713101864, "dist_entropy": 0.6084371685981751, "actor_grad_norm": 0.1713167130947113, "critic_grad_norm": 0.05856671184301376, "ratio": 1.0000749826431274, "entropy": 0.6084371685981751, "incre_win_rate": 0.8852459016393442, "step": 292}
{"time": 1766586541.3962648, "phase": "train", "update": 293, "total_env_steps": 937600, "episode_reward": 0.3496851921081543, "value_loss": 0.011789699209233125, "policy_loss": -0.010213506235894934, "dist_entropy": 0.5782359798749288, "actor_grad_norm": 0.15079350769519806, "critic_grad_norm": 0.07705666124820709, "ratio": 0.998833417892456, "entropy": 0.5782359798749288, "incre_win_rate": 0.7796610169491526, "step": 293}
{"time": 1766586546.1838486, "phase": "train", "update": 294, "total_env_steps": 940800, "episode_reward": 0.3700842261314392, "value_loss": 0.010356205701828002, "policy_loss": -0.010048882614029015, "dist_entropy": 0.5923165639241537, "actor_grad_norm": 0.14927981793880463, "critic_grad_norm": 0.03386334702372551, "ratio": 0.9995017051696777, "entropy": 0.5923165639241537, "incre_win_rate": 0.8688524590163934, "step": 294}
{"time": 1766586550.7963958, "phase": "train", "update": 295, "total_env_steps": 944000, "episode_reward": 0.36715152859687805, "value_loss": 0.008724427533646424, "policy_loss": -0.010178983477449796, "dist_entropy": 0.6107757886250814, "actor_grad_norm": 0.13851982355117798, "critic_grad_norm": 0.04674312472343445, "ratio": 0.9982420206069946, "entropy": 0.6107757886250814, "incre_win_rate": 0.8709677419354839, "step": 295}
{"time": 1766586555.6266491, "phase": "train", "update": 296, "total_env_steps": 947200, "episode_reward": 0.37038832902908325, "value_loss": 0.011708552141984303, "policy_loss": -0.010788724274879277, "dist_entropy": 0.5824553966522217, "actor_grad_norm": 0.15403734147548676, "critic_grad_norm": 0.03968586027622223, "ratio": 0.9996748566627502, "entropy": 0.5824553966522217, "incre_win_rate": 0.85, "step": 296}
{"time": 1766586560.2771115, "phase": "train", "update": 297, "total_env_steps": 950400, "episode_reward": 0.36885419487953186, "value_loss": 0.009856385613481204, "policy_loss": -0.010525898060990831, "dist_entropy": 0.5824186603228251, "actor_grad_norm": 0.14928677678108215, "critic_grad_norm": 0.030542243272066116, "ratio": 0.9986147880554199, "entropy": 0.5824186603228251, "incre_win_rate": 0.8888888888888888, "step": 297}
{"time": 1766586565.0736427, "phase": "train", "update": 298, "total_env_steps": 953600, "episode_reward": 0.3704281747341156, "value_loss": 0.008478188266356787, "policy_loss": -0.01113065323296117, "dist_entropy": 0.5954479893048604, "actor_grad_norm": 0.1560840904712677, "critic_grad_norm": 0.022695425897836685, "ratio": 0.9986551403999329, "entropy": 0.5954479893048604, "incre_win_rate": 0.8833333333333333, "step": 298}
{"time": 1766586569.6421564, "phase": "train", "update": 299, "total_env_steps": 956800, "episode_reward": 0.3634321391582489, "value_loss": 0.009708932600915432, "policy_loss": -0.010716561679357283, "dist_entropy": 0.6004179199536641, "actor_grad_norm": 0.15808254480361938, "critic_grad_norm": 0.024235596880316734, "ratio": 0.9988294243812561, "entropy": 0.6004179199536641, "incre_win_rate": 0.8548387096774194, "step": 299}
{"time": 1766586574.2767951, "phase": "train", "update": 300, "total_env_steps": 960000, "episode_reward": 0.3644263446331024, "value_loss": 0.013199907292922338, "policy_loss": -0.010596520198545296, "dist_entropy": 0.5941267291704814, "actor_grad_norm": 0.17783239483833313, "critic_grad_norm": 0.02170611172914505, "ratio": 1.000409483909607, "entropy": 0.5941267291704814, "incre_win_rate": 0.8548387096774194, "step": 300}
{"time": 1766586578.9539273, "phase": "train", "update": 301, "total_env_steps": 963200, "episode_reward": 0.36299097537994385, "value_loss": 0.011598633540173372, "policy_loss": -0.010640860743659412, "dist_entropy": 0.6011006832122803, "actor_grad_norm": 0.1924366056919098, "critic_grad_norm": 0.016252567991614342, "ratio": 0.9992936849594116, "entropy": 0.6011006832122803, "incre_win_rate": 0.7796610169491526, "step": 301}
{"time": 1766586585.5901456, "phase": "eval", "update": 301, "total_env_steps": 963200, "eval_win_rate": 1.0, "eval_episode_reward": 20.0, "step": 301}
{"time": 1766586590.1490266, "phase": "train", "update": 302, "total_env_steps": 966400, "episode_reward": 0.36221277713775635, "value_loss": 0.014451813449462255, "policy_loss": -0.009919965906758914, "dist_entropy": 0.5744483311971028, "actor_grad_norm": 0.1814262419939041, "critic_grad_norm": 0.01429428718984127, "ratio": 0.9998951554298401, "entropy": 0.5744483311971028, "incre_win_rate": 0.7936507936507936, "step": 302}
{"time": 1766586594.77374, "phase": "train", "update": 303, "total_env_steps": 969600, "episode_reward": 0.3668765127658844, "value_loss": 0.014128044061362744, "policy_loss": -0.010257553043180679, "dist_entropy": 0.6079710682233175, "actor_grad_norm": 0.14119592308998108, "critic_grad_norm": 0.06001114472746849, "ratio": 0.9990351796150208, "entropy": 0.6079710682233175, "incre_win_rate": 0.8833333333333333, "step": 303}
{"time": 1766586599.4279323, "phase": "train", "update": 304, "total_env_steps": 972800, "episode_reward": 0.36702054738998413, "value_loss": 0.011428617934385935, "policy_loss": -0.010679400064033, "dist_entropy": 0.6095061500867208, "actor_grad_norm": 0.16654331982135773, "critic_grad_norm": 0.032220419496297836, "ratio": 1.0003163814544678, "entropy": 0.6095061500867208, "incre_win_rate": 0.8387096774193549, "step": 304}
{"time": 1766586603.9526358, "phase": "train", "update": 305, "total_env_steps": 976000, "episode_reward": 0.3578592538833618, "value_loss": 0.01005413569509983, "policy_loss": -0.011277842374857804, "dist_entropy": 0.5835739930470785, "actor_grad_norm": 0.17698132991790771, "critic_grad_norm": 0.028899801895022392, "ratio": 1.0001447200775146, "entropy": 0.5835739930470785, "incre_win_rate": 0.8524590163934426, "step": 305}
{"time": 1766586608.554411, "phase": "train", "update": 306, "total_env_steps": 979200, "episode_reward": 0.3688909411430359, "value_loss": 0.009958378970623016, "policy_loss": -0.010431992226092035, "dist_entropy": 0.6076233267784119, "actor_grad_norm": 0.16525141894817352, "critic_grad_norm": 0.0424763560295105, "ratio": 0.9995733499526978, "entropy": 0.6076233267784119, "incre_win_rate": 0.8412698412698413, "step": 306}
{"time": 1766586613.1377304, "phase": "train", "update": 307, "total_env_steps": 982400, "episode_reward": 0.3739016652107239, "value_loss": 0.00929682906717062, "policy_loss": -0.008945847510003328, "dist_entropy": 0.5865285634994507, "actor_grad_norm": 0.1595914512872696, "critic_grad_norm": 0.018933363258838654, "ratio": 1.0005356073379517, "entropy": 0.5865285634994507, "incre_win_rate": 0.8833333333333333, "step": 307}
{"time": 1766586617.724873, "phase": "train", "update": 308, "total_env_steps": 985600, "episode_reward": 0.3617823123931885, "value_loss": 0.012280322859684627, "policy_loss": -0.010479425593737565, "dist_entropy": 0.59286128282547, "actor_grad_norm": 0.16175596415996552, "critic_grad_norm": 0.045183032751083374, "ratio": 0.9994966983795166, "entropy": 0.59286128282547, "incre_win_rate": 0.7966101694915254, "step": 308}
{"time": 1766586622.3079782, "phase": "train", "update": 309, "total_env_steps": 988800, "episode_reward": 0.35538986325263977, "value_loss": 0.011818945221602917, "policy_loss": -0.0099917295658796, "dist_entropy": 0.5913284540176391, "actor_grad_norm": 0.13867078721523285, "critic_grad_norm": 0.04015811160206795, "ratio": 0.9999751448631287, "entropy": 0.5913284540176391, "incre_win_rate": 0.8688524590163934, "step": 309}
{"time": 1766586626.9965663, "phase": "train", "update": 310, "total_env_steps": 992000, "episode_reward": 0.35563570261001587, "value_loss": 0.011535647449394067, "policy_loss": -0.011291189609229531, "dist_entropy": 0.5913925369580587, "actor_grad_norm": 0.1471935510635376, "critic_grad_norm": 0.08614400774240494, "ratio": 0.9995197057723999, "entropy": 0.5913925369580587, "incre_win_rate": 0.7704918032786885, "step": 310}
{"time": 1766586631.5260952, "phase": "train", "update": 311, "total_env_steps": 995200, "episode_reward": 0.3644469976425171, "value_loss": 0.00965811318407456, "policy_loss": -0.010319196162039291, "dist_entropy": 0.635489265124003, "actor_grad_norm": 0.2011161595582962, "critic_grad_norm": 0.04040655866265297, "ratio": 0.9998849034309387, "entropy": 0.635489265124003, "incre_win_rate": 0.8548387096774194, "step": 311}
{"time": 1766586636.0365305, "phase": "train", "update": 312, "total_env_steps": 998400, "episode_reward": 0.3488036096096039, "value_loss": 0.013793554715812206, "policy_loss": -0.011601278345015469, "dist_entropy": 0.6168247977892558, "actor_grad_norm": 0.16183583438396454, "critic_grad_norm": 0.0953545793890953, "ratio": 0.9993730187416077, "entropy": 0.6168247977892558, "incre_win_rate": 0.7213114754098361, "step": 312}
{"time": 1766586640.6246946, "phase": "train", "update": 313, "total_env_steps": 1001600, "episode_reward": 0.36169886589050293, "value_loss": 0.013950223103165627, "policy_loss": -0.010711797888927304, "dist_entropy": 0.6242953062057495, "actor_grad_norm": 0.14070729911327362, "critic_grad_norm": 0.045306332409381866, "ratio": 0.9985259771347046, "entropy": 0.6242953062057495, "incre_win_rate": 0.8166666666666667, "step": 313}
{"time": 1766586645.1993597, "phase": "train", "update": 314, "total_env_steps": 1004800, "episode_reward": 0.3472801744937897, "value_loss": 0.01260166261345148, "policy_loss": -0.01032847478106902, "dist_entropy": 0.6006388823191325, "actor_grad_norm": 0.17764170467853546, "critic_grad_norm": 0.03176723048090935, "ratio": 1.000526785850525, "entropy": 0.6006388823191325, "incre_win_rate": 0.7627118644067796, "step": 314}
{"time": 1766586649.7843013, "phase": "train", "update": 315, "total_env_steps": 1008000, "episode_reward": 0.3634941875934601, "value_loss": 0.012780597619712352, "policy_loss": -0.009751169154508244, "dist_entropy": 0.5944943388303121, "actor_grad_norm": 0.16610431671142578, "critic_grad_norm": 0.026688946411013603, "ratio": 0.9991186857223511, "entropy": 0.5944943388303121, "incre_win_rate": 0.8387096774193549, "step": 315}
{"time": 1766586654.3853853, "phase": "train", "update": 316, "total_env_steps": 1011200, "episode_reward": 0.3577650189399719, "value_loss": 0.01323248508075873, "policy_loss": -0.010906759132082774, "dist_entropy": 0.6191463311513264, "actor_grad_norm": 0.18921877443790436, "critic_grad_norm": 0.02032165415585041, "ratio": 0.9993541836738586, "entropy": 0.6191463311513264, "incre_win_rate": 0.7868852459016393, "step": 316}
{"time": 1766586659.0220737, "phase": "train", "update": 317, "total_env_steps": 1014400, "episode_reward": 0.35265395045280457, "value_loss": 0.01403055948515733, "policy_loss": -0.010256704206901427, "dist_entropy": 0.6048566857973735, "actor_grad_norm": 0.16776251792907715, "critic_grad_norm": 0.07141220569610596, "ratio": 1.0000708103179932, "entropy": 0.6048566857973735, "incre_win_rate": 0.7, "step": 317}
{"time": 1766586663.5939229, "phase": "train", "update": 318, "total_env_steps": 1017600, "episode_reward": 0.36857151985168457, "value_loss": 0.014697284810245037, "policy_loss": -0.009652342679232125, "dist_entropy": 0.6169358690579733, "actor_grad_norm": 0.19078786671161652, "critic_grad_norm": 0.028629934415221214, "ratio": 0.9996183514595032, "entropy": 0.6169358690579733, "incre_win_rate": 0.75, "step": 318}
{"time": 1766586668.227397, "phase": "train", "update": 319, "total_env_steps": 1020800, "episode_reward": 0.36979472637176514, "value_loss": 0.012403117554883162, "policy_loss": -0.01006573541964831, "dist_entropy": 0.6088372906049092, "actor_grad_norm": 0.1662883758544922, "critic_grad_norm": 0.03182549402117729, "ratio": 0.9995777606964111, "entropy": 0.6088372906049092, "incre_win_rate": 0.828125, "step": 319}
{"time": 1766586672.8560169, "phase": "train", "update": 320, "total_env_steps": 1024000, "episode_reward": 0.363601416349411, "value_loss": 0.015432997172077497, "policy_loss": -0.010123244610502328, "dist_entropy": 0.5955249031384786, "actor_grad_norm": 0.17151352763175964, "critic_grad_norm": 0.027345165610313416, "ratio": 1.0000149011611938, "entropy": 0.5955249031384786, "incre_win_rate": 0.8064516129032258, "step": 320}
{"time": 1766586677.5011034, "phase": "train", "update": 321, "total_env_steps": 1027200, "episode_reward": 0.37790825963020325, "value_loss": 0.013181146730979284, "policy_loss": -0.00916866085079088, "dist_entropy": 0.6138961672782898, "actor_grad_norm": 0.1493345946073532, "critic_grad_norm": 0.05329880863428116, "ratio": 1.000227689743042, "entropy": 0.6138961672782898, "incre_win_rate": 0.828125, "step": 321}
{"time": 1766586684.1052659, "phase": "eval", "update": 321, "total_env_steps": 1027200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.349647671568626, "step": 321}
{"time": 1766586688.7793438, "phase": "train", "update": 322, "total_env_steps": 1030400, "episode_reward": 0.3718474209308624, "value_loss": 0.015051596922179063, "policy_loss": -0.01041001723962438, "dist_entropy": 0.638774327437083, "actor_grad_norm": 0.20492123067378998, "critic_grad_norm": 0.044521477073431015, "ratio": 1.000874400138855, "entropy": 0.638774327437083, "incre_win_rate": 0.8225806451612904, "step": 322}
{"time": 1766586693.355094, "phase": "train", "update": 323, "total_env_steps": 1033600, "episode_reward": 0.37069398164749146, "value_loss": 0.016828253989418347, "policy_loss": -0.011121427224070857, "dist_entropy": 0.6242778817812602, "actor_grad_norm": 0.1566205769777298, "critic_grad_norm": 0.032821498811244965, "ratio": 0.9996997117996216, "entropy": 0.6242778817812602, "incre_win_rate": 0.734375, "step": 323}
{"time": 1766586697.96685, "phase": "train", "update": 324, "total_env_steps": 1036800, "episode_reward": 0.3526248335838318, "value_loss": 0.013912720854083698, "policy_loss": -0.011018467490707451, "dist_entropy": 0.6406551162401836, "actor_grad_norm": 0.18515276908874512, "critic_grad_norm": 0.023030739277601242, "ratio": 0.9989883899688721, "entropy": 0.6406551162401836, "incre_win_rate": 0.7049180327868853, "step": 324}
{"time": 1766586702.5440598, "phase": "train", "update": 325, "total_env_steps": 1040000, "episode_reward": 0.3605016767978668, "value_loss": 0.014402307259539763, "policy_loss": -0.011213200473722889, "dist_entropy": 0.6687628865242005, "actor_grad_norm": 0.1619463413953781, "critic_grad_norm": 0.01697361283004284, "ratio": 1.0008912086486816, "entropy": 0.6687628865242005, "incre_win_rate": 0.7741935483870968, "step": 325}
{"time": 1766586707.1322775, "phase": "train", "update": 326, "total_env_steps": 1043200, "episode_reward": 0.3652435839176178, "value_loss": 0.014802726296087107, "policy_loss": -0.010861353708871016, "dist_entropy": 0.6614610910415649, "actor_grad_norm": 0.15421162545681, "critic_grad_norm": 0.021358754485845566, "ratio": 0.9996305108070374, "entropy": 0.6614610910415649, "incre_win_rate": 0.7903225806451613, "step": 326}
{"time": 1766586737.1377068, "phase": "train", "update": 327, "total_env_steps": 1046400, "episode_reward": 0.34028953313827515, "value_loss": 0.045905738075574236, "policy_loss": -0.009643819166768708, "dist_entropy": 0.647850219408671, "actor_grad_norm": 0.1823013573884964, "critic_grad_norm": 0.15694747865200043, "ratio": 0.999596357345581, "entropy": 0.647850219408671, "incre_win_rate": 0.6785714285714286, "step": 327}
{"time": 1766586741.66992, "phase": "train", "update": 328, "total_env_steps": 1049600, "episode_reward": 0.3576815128326416, "value_loss": 0.013393516714374224, "policy_loss": -0.011491649257117941, "dist_entropy": 0.6677705645561218, "actor_grad_norm": 0.17058499157428741, "critic_grad_norm": 0.06820443272590637, "ratio": 0.9989278316497803, "entropy": 0.6677705645561218, "incre_win_rate": 0.7377049180327869, "step": 328}
{"time": 1766586746.1872072, "phase": "train", "update": 329, "total_env_steps": 1052800, "episode_reward": 0.3401585817337036, "value_loss": 0.015483547188341617, "policy_loss": -0.011706157109476579, "dist_entropy": 0.6641187389691671, "actor_grad_norm": 0.1548040509223938, "critic_grad_norm": 0.03737539425492287, "ratio": 0.9993342757225037, "entropy": 0.6641187389691671, "incre_win_rate": 0.7, "step": 329}
{"time": 1766586750.7632396, "phase": "train", "update": 330, "total_env_steps": 1056000, "episode_reward": 0.34741804003715515, "value_loss": 0.010810242220759391, "policy_loss": -0.011151463147582063, "dist_entropy": 0.6561763683954874, "actor_grad_norm": 0.1585932970046997, "critic_grad_norm": 0.029291467741131783, "ratio": 0.9997327327728271, "entropy": 0.6561763683954874, "incre_win_rate": 0.7966101694915254, "step": 330}
{"time": 1766586755.3279648, "phase": "train", "update": 331, "total_env_steps": 1059200, "episode_reward": 0.3608456254005432, "value_loss": 0.011402302732070288, "policy_loss": -0.010633098453218774, "dist_entropy": 0.6380515853563945, "actor_grad_norm": 0.1870497614145279, "critic_grad_norm": 0.020568877458572388, "ratio": 1.0003844499588013, "entropy": 0.6380515853563945, "incre_win_rate": 0.8166666666666667, "step": 331}
{"time": 1766586760.0312989, "phase": "train", "update": 332, "total_env_steps": 1062400, "episode_reward": 0.3499157726764679, "value_loss": 0.015775929018855096, "policy_loss": -0.011049917677004355, "dist_entropy": 0.6470393141110738, "actor_grad_norm": 0.17658428847789764, "critic_grad_norm": 0.0785156711935997, "ratio": 1.0009620189666748, "entropy": 0.6470393141110738, "incre_win_rate": 0.7288135593220338, "step": 332}
{"time": 1766586764.6232328, "phase": "train", "update": 333, "total_env_steps": 1065600, "episode_reward": 0.3383433222770691, "value_loss": 0.018092790246009828, "policy_loss": -0.011415352209831912, "dist_entropy": 0.6126289288202922, "actor_grad_norm": 0.19999565184116364, "critic_grad_norm": 0.04557674005627632, "ratio": 1.0006736516952515, "entropy": 0.6126289288202922, "incre_win_rate": 0.7049180327868853, "step": 333}
{"time": 1766586769.245458, "phase": "train", "update": 334, "total_env_steps": 1068800, "episode_reward": 0.35785388946533203, "value_loss": 0.013896552162865798, "policy_loss": -0.009839389311653927, "dist_entropy": 0.607880703608195, "actor_grad_norm": 0.1784030944108963, "critic_grad_norm": 0.05011870339512825, "ratio": 1.0005905628204346, "entropy": 0.607880703608195, "incre_win_rate": 0.7741935483870968, "step": 334}
{"time": 1766586773.7839487, "phase": "train", "update": 335, "total_env_steps": 1072000, "episode_reward": 0.3566727936267853, "value_loss": 0.015600710424284141, "policy_loss": -0.010047037383506858, "dist_entropy": 0.6100288391113281, "actor_grad_norm": 0.18968534469604492, "critic_grad_norm": 0.03031770884990692, "ratio": 0.9984991550445557, "entropy": 0.6100288391113281, "incre_win_rate": 0.7540983606557377, "step": 335}
{"time": 1766586778.4658055, "phase": "train", "update": 336, "total_env_steps": 1075200, "episode_reward": 0.36060431599617004, "value_loss": 0.01650380107263724, "policy_loss": -0.009704998445640692, "dist_entropy": 0.6016613006591797, "actor_grad_norm": 0.18148697912693024, "critic_grad_norm": 0.022290412336587906, "ratio": 0.9998375177383423, "entropy": 0.6016613006591797, "incre_win_rate": 0.8032786885245902, "step": 336}
{"time": 1766586783.192224, "phase": "train", "update": 337, "total_env_steps": 1078400, "episode_reward": 0.3620634078979492, "value_loss": 0.015279635414481163, "policy_loss": -0.010265376920191709, "dist_entropy": 0.6148152232170105, "actor_grad_norm": 0.16676625609397888, "critic_grad_norm": 0.0225007776170969, "ratio": 0.9987859129905701, "entropy": 0.6148152232170105, "incre_win_rate": 0.7777777777777778, "step": 337}
{"time": 1766586787.7097268, "phase": "train", "update": 338, "total_env_steps": 1081600, "episode_reward": 0.3432222902774811, "value_loss": 0.01569652302811543, "policy_loss": -0.010477659311025296, "dist_entropy": 0.6260926087697347, "actor_grad_norm": 0.14955171942710876, "critic_grad_norm": 0.05649825930595398, "ratio": 0.9989432692527771, "entropy": 0.6260926087697347, "incre_win_rate": 0.6896551724137931, "step": 338}
{"time": 1766586792.378846, "phase": "train", "update": 339, "total_env_steps": 1084800, "episode_reward": 0.365942120552063, "value_loss": 0.010940893739461898, "policy_loss": -0.010196809920913097, "dist_entropy": 0.6196283976236979, "actor_grad_norm": 0.17936767637729645, "critic_grad_norm": 0.04194320738315582, "ratio": 0.9993837475776672, "entropy": 0.6196283976236979, "incre_win_rate": 0.8064516129032258, "step": 339}
{"time": 1766586796.9319565, "phase": "train", "update": 340, "total_env_steps": 1088000, "episode_reward": 0.3628937005996704, "value_loss": 0.013846170219282309, "policy_loss": -0.009683465889966669, "dist_entropy": 0.6158252954483032, "actor_grad_norm": 0.15860098600387573, "critic_grad_norm": 0.05237981677055359, "ratio": 0.9990339279174805, "entropy": 0.6158252954483032, "incre_win_rate": 0.8412698412698413, "step": 340}
{"time": 1766586801.5578399, "phase": "train", "update": 341, "total_env_steps": 1091200, "episode_reward": 0.37159162759780884, "value_loss": 0.013317137522002061, "policy_loss": -0.010501591031264875, "dist_entropy": 0.6104252139727274, "actor_grad_norm": 0.16990028321743011, "critic_grad_norm": 0.04549560323357582, "ratio": 0.9992067813873291, "entropy": 0.6104252139727274, "incre_win_rate": 0.8360655737704918, "step": 341}
{"time": 1766586808.248061, "phase": "eval", "update": 341, "total_env_steps": 1091200, "eval_win_rate": 1.0, "eval_episode_reward": 20.020067401960784, "step": 341}
{"time": 1766586812.9408486, "phase": "train", "update": 342, "total_env_steps": 1094400, "episode_reward": 0.34996092319488525, "value_loss": 0.014135684818029404, "policy_loss": -0.01050279166303249, "dist_entropy": 0.6154066165288289, "actor_grad_norm": 0.1741783767938614, "critic_grad_norm": 0.05292363464832306, "ratio": 0.9993495345115662, "entropy": 0.6154066165288289, "incre_win_rate": 0.75, "step": 342}
{"time": 1766586817.5125911, "phase": "train", "update": 343, "total_env_steps": 1097600, "episode_reward": 0.33646753430366516, "value_loss": 0.017196274176239968, "policy_loss": -0.01128433423024949, "dist_entropy": 0.6230780005455017, "actor_grad_norm": 0.14926773309707642, "critic_grad_norm": 0.08019598573446274, "ratio": 0.9993899464607239, "entropy": 0.6230780005455017, "incre_win_rate": 0.6896551724137931, "step": 343}
{"time": 1766586822.1605065, "phase": "train", "update": 344, "total_env_steps": 1100800, "episode_reward": 0.3602159917354584, "value_loss": 0.011488300127287706, "policy_loss": -0.010964657095140733, "dist_entropy": 0.6438570698102315, "actor_grad_norm": 0.17161999642848969, "critic_grad_norm": 0.03840087726712227, "ratio": 0.998928427696228, "entropy": 0.6438570698102315, "incre_win_rate": 0.75, "step": 344}
{"time": 1766586826.6894479, "phase": "train", "update": 345, "total_env_steps": 1104000, "episode_reward": 0.3639323115348816, "value_loss": 0.013591341053446135, "policy_loss": -0.009464955639256327, "dist_entropy": 0.6232598702112834, "actor_grad_norm": 0.15459629893302917, "critic_grad_norm": 0.029485709965229034, "ratio": 0.9999497532844543, "entropy": 0.6232598702112834, "incre_win_rate": 0.8166666666666667, "step": 345}
{"time": 1766586831.3239655, "phase": "train", "update": 346, "total_env_steps": 1107200, "episode_reward": 0.3588786721229553, "value_loss": 0.012392429200311502, "policy_loss": -0.011085038146007756, "dist_entropy": 0.6317770600318908, "actor_grad_norm": 0.16714167594909668, "critic_grad_norm": 0.01698151044547558, "ratio": 1.0002098083496094, "entropy": 0.6317770600318908, "incre_win_rate": 0.8360655737704918, "step": 346}
{"time": 1766586835.8854687, "phase": "train", "update": 347, "total_env_steps": 1110400, "episode_reward": 0.34855011105537415, "value_loss": 0.012147013780971367, "policy_loss": -0.009919586153653863, "dist_entropy": 0.6281577825546265, "actor_grad_norm": 0.13977456092834473, "critic_grad_norm": 0.0331105999648571, "ratio": 1.0003877878189087, "entropy": 0.6281577825546265, "incre_win_rate": 0.875, "step": 347}
{"time": 1766586840.4821863, "phase": "train", "update": 348, "total_env_steps": 1113600, "episode_reward": 0.3374173045158386, "value_loss": 0.01618241754670938, "policy_loss": -0.010394973512739132, "dist_entropy": 0.6212857604026795, "actor_grad_norm": 0.22629041969776154, "critic_grad_norm": 0.05954650789499283, "ratio": 0.9984761476516724, "entropy": 0.6212857604026795, "incre_win_rate": 0.6290322580645161, "step": 348}
{"time": 1766586845.069125, "phase": "train", "update": 349, "total_env_steps": 1116800, "episode_reward": 0.3651447594165802, "value_loss": 0.010570522708197435, "policy_loss": -0.01025053573743951, "dist_entropy": 0.6297323862711589, "actor_grad_norm": 0.19933557510375977, "critic_grad_norm": 0.023000556975603104, "ratio": 0.9993129968643188, "entropy": 0.6297323862711589, "incre_win_rate": 0.8333333333333334, "step": 349}
{"time": 1766586849.700624, "phase": "train", "update": 350, "total_env_steps": 1120000, "episode_reward": 0.3656862676143646, "value_loss": 0.013928279591103395, "policy_loss": -0.010566726650138018, "dist_entropy": 0.6182084043820699, "actor_grad_norm": 0.15113696455955505, "critic_grad_norm": 0.02735385112464428, "ratio": 0.9997510313987732, "entropy": 0.6182084043820699, "incre_win_rate": 0.8225806451612904, "step": 350}
{"time": 1766586854.7034996, "phase": "train", "update": 351, "total_env_steps": 1123200, "episode_reward": 0.3727351427078247, "value_loss": 0.009849489914874237, "policy_loss": -0.011330024943036202, "dist_entropy": 0.6432949662208557, "actor_grad_norm": 0.1823955625295639, "critic_grad_norm": 0.04208524897694588, "ratio": 0.999298632144928, "entropy": 0.6432949662208557, "incre_win_rate": 0.8870967741935484, "step": 351}
{"time": 1766586859.2952707, "phase": "train", "update": 352, "total_env_steps": 1126400, "episode_reward": 0.373555451631546, "value_loss": 0.011265798658132552, "policy_loss": -0.010542045816101601, "dist_entropy": 0.6266866842905681, "actor_grad_norm": 0.198362335562706, "critic_grad_norm": 0.021830739453434944, "ratio": 0.9988141059875488, "entropy": 0.6266866842905681, "incre_win_rate": 0.9016393442622951, "step": 352}
{"time": 1766586863.9710147, "phase": "train", "update": 353, "total_env_steps": 1129600, "episode_reward": 0.3586527407169342, "value_loss": 0.014390297854940096, "policy_loss": -0.010202814756476405, "dist_entropy": 0.633178198337555, "actor_grad_norm": 0.16262194514274597, "critic_grad_norm": 0.027635710313916206, "ratio": 0.9998798370361328, "entropy": 0.633178198337555, "incre_win_rate": 0.8166666666666667, "step": 353}
{"time": 1766586868.6003747, "phase": "train", "update": 354, "total_env_steps": 1132800, "episode_reward": 0.35498011112213135, "value_loss": 0.011514599559207757, "policy_loss": -0.01021620441349403, "dist_entropy": 0.6440821448961894, "actor_grad_norm": 0.17673909664154053, "critic_grad_norm": 0.019993195310235023, "ratio": 0.9994657039642334, "entropy": 0.6440821448961894, "incre_win_rate": 0.8064516129032258, "step": 354}
{"time": 1766586873.237014, "phase": "train", "update": 355, "total_env_steps": 1136000, "episode_reward": 0.35580042004585266, "value_loss": 0.012069489806890488, "policy_loss": -0.01065420555208713, "dist_entropy": 0.6518534064292908, "actor_grad_norm": 0.20427042245864868, "critic_grad_norm": 0.02482006698846817, "ratio": 0.9991817474365234, "entropy": 0.6518534064292908, "incre_win_rate": 0.8620689655172413, "step": 355}
{"time": 1766586877.795163, "phase": "train", "update": 356, "total_env_steps": 1139200, "episode_reward": 0.361732542514801, "value_loss": 0.009308661644657453, "policy_loss": -0.011273145106916143, "dist_entropy": 0.6465180158615113, "actor_grad_norm": 0.17838461697101593, "critic_grad_norm": 0.0404910109937191, "ratio": 0.9987762570381165, "entropy": 0.6465180158615113, "incre_win_rate": 0.8360655737704918, "step": 356}
{"time": 1766586882.4705722, "phase": "train", "update": 357, "total_env_steps": 1142400, "episode_reward": 0.3560202121734619, "value_loss": 0.0112236263230443, "policy_loss": -0.011414830641428371, "dist_entropy": 0.6632537444432577, "actor_grad_norm": 0.18750087916851044, "critic_grad_norm": 0.02815699577331543, "ratio": 0.9990251660346985, "entropy": 0.6632537444432577, "incre_win_rate": 0.8360655737704918, "step": 357}
{"time": 1766586887.4985843, "phase": "train", "update": 358, "total_env_steps": 1145600, "episode_reward": 0.3465019762516022, "value_loss": 0.010608976272245248, "policy_loss": -0.0124539714024948, "dist_entropy": 0.6664261897404988, "actor_grad_norm": 0.16578729450702667, "critic_grad_norm": 0.051743749529123306, "ratio": 0.9990038275718689, "entropy": 0.6664261897404988, "incre_win_rate": 0.7586206896551724, "step": 358}
{"time": 1766586892.0783174, "phase": "train", "update": 359, "total_env_steps": 1148800, "episode_reward": 0.3517402112483978, "value_loss": 0.014151232875883579, "policy_loss": -0.011678909468540156, "dist_entropy": 0.6494605779647827, "actor_grad_norm": 0.16033487021923065, "critic_grad_norm": 0.05183342844247818, "ratio": 0.9987569451332092, "entropy": 0.6494605779647827, "incre_win_rate": 0.7966101694915254, "step": 359}
{"time": 1766586896.622902, "phase": "train", "update": 360, "total_env_steps": 1152000, "episode_reward": 0.34096357226371765, "value_loss": 0.012642318507035573, "policy_loss": -0.011258955518915552, "dist_entropy": 0.6615548928578695, "actor_grad_norm": 0.15928468108177185, "critic_grad_norm": 0.033112287521362305, "ratio": 0.9983989000320435, "entropy": 0.6615548928578695, "incre_win_rate": 0.7758620689655172, "step": 360}
{"time": 1766586901.189482, "phase": "train", "update": 361, "total_env_steps": 1155200, "episode_reward": 0.34427008032798767, "value_loss": 0.012740869695941607, "policy_loss": -0.012148282732141998, "dist_entropy": 0.6397146622339884, "actor_grad_norm": 0.20032528042793274, "critic_grad_norm": 0.026013867929577827, "ratio": 0.9992431998252869, "entropy": 0.6397146622339884, "incre_win_rate": 0.7931034482758621, "step": 361}
{"time": 1766586908.4029548, "phase": "eval", "update": 361, "total_env_steps": 1155200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.776194852941178, "step": 361}
{"time": 1766586913.0470097, "phase": "train", "update": 362, "total_env_steps": 1158400, "episode_reward": 0.3630354106426239, "value_loss": 0.010317450078825155, "policy_loss": -0.01149092262008035, "dist_entropy": 0.6338663419087728, "actor_grad_norm": 0.19736163318157196, "critic_grad_norm": 0.031381577253341675, "ratio": 0.9988294243812561, "entropy": 0.6338663419087728, "incre_win_rate": 0.9, "step": 362}
{"time": 1766586917.5571475, "phase": "train", "update": 363, "total_env_steps": 1161600, "episode_reward": 0.35297563672065735, "value_loss": 0.009446465720733007, "policy_loss": -0.010521018727978533, "dist_entropy": 0.6172544519106548, "actor_grad_norm": 0.16564080119132996, "critic_grad_norm": 0.027358543127775192, "ratio": 1.0006492137908936, "entropy": 0.6172544519106548, "incre_win_rate": 0.8305084745762712, "step": 363}
{"time": 1766586922.1263943, "phase": "train", "update": 364, "total_env_steps": 1164800, "episode_reward": 0.3579633831977844, "value_loss": 0.013275310893853505, "policy_loss": -0.010987903238136454, "dist_entropy": 0.5995782732963562, "actor_grad_norm": 0.16663570702075958, "critic_grad_norm": 0.04860706999897957, "ratio": 1.00007164478302, "entropy": 0.5995782732963562, "incre_win_rate": 0.8333333333333334, "step": 364}
{"time": 1766586926.7147317, "phase": "train", "update": 365, "total_env_steps": 1168000, "episode_reward": 0.35667744278907776, "value_loss": 0.008983442311485608, "policy_loss": -0.011231964610961143, "dist_entropy": 0.6230845888455708, "actor_grad_norm": 0.1890048235654831, "critic_grad_norm": 0.023366518318653107, "ratio": 1.000720500946045, "entropy": 0.6230845888455708, "incre_win_rate": 0.8813559322033898, "step": 365}
{"time": 1766586931.2578566, "phase": "train", "update": 366, "total_env_steps": 1171200, "episode_reward": 0.3708440661430359, "value_loss": 0.013115395543475945, "policy_loss": -0.011003436221866043, "dist_entropy": 0.5956968188285827, "actor_grad_norm": 0.17455869913101196, "critic_grad_norm": 0.04788852483034134, "ratio": 1.0007257461547852, "entropy": 0.5956968188285827, "incre_win_rate": 0.8360655737704918, "step": 366}
{"time": 1766586935.8740277, "phase": "train", "update": 367, "total_env_steps": 1174400, "episode_reward": 0.3746989667415619, "value_loss": 0.010818015535672505, "policy_loss": -0.010517712457787336, "dist_entropy": 0.592827292283376, "actor_grad_norm": 0.199525848031044, "critic_grad_norm": 0.028651470318436623, "ratio": 1.000016450881958, "entropy": 0.592827292283376, "incre_win_rate": 0.859375, "step": 367}
{"time": 1766586940.4797595, "phase": "train", "update": 368, "total_env_steps": 1177600, "episode_reward": 0.3633287250995636, "value_loss": 0.010789989617963631, "policy_loss": -0.010594786684732564, "dist_entropy": 0.6092931191126506, "actor_grad_norm": 0.18779383599758148, "critic_grad_norm": 0.027500158175826073, "ratio": 0.9987123608589172, "entropy": 0.6092931191126506, "incre_win_rate": 0.8387096774193549, "step": 368}
{"time": 1766586945.0511715, "phase": "train", "update": 369, "total_env_steps": 1180800, "episode_reward": 0.3655798137187958, "value_loss": 0.00942386786142985, "policy_loss": -0.011325048351392298, "dist_entropy": 0.6107260068257649, "actor_grad_norm": 0.18831633031368256, "critic_grad_norm": 0.02707069180905819, "ratio": 0.9995128512382507, "entropy": 0.6107260068257649, "incre_win_rate": 0.8833333333333333, "step": 369}
{"time": 1766586949.6800396, "phase": "train", "update": 370, "total_env_steps": 1184000, "episode_reward": 0.36196690797805786, "value_loss": 0.012879955520232519, "policy_loss": -0.01110400094277395, "dist_entropy": 0.5963141043980916, "actor_grad_norm": 0.16929209232330322, "critic_grad_norm": 0.05775323137640953, "ratio": 1.001046895980835, "entropy": 0.5963141043980916, "incre_win_rate": 0.8166666666666667, "step": 370}
{"time": 1766586954.2990198, "phase": "train", "update": 371, "total_env_steps": 1187200, "episode_reward": 0.3392448127269745, "value_loss": 0.015352513020237287, "policy_loss": -0.011247469895667687, "dist_entropy": 0.5824866890907288, "actor_grad_norm": 0.21690982580184937, "critic_grad_norm": 0.0920446589589119, "ratio": 1.000696063041687, "entropy": 0.5824866890907288, "incre_win_rate": 0.6833333333333333, "step": 371}
{"time": 1766586958.965627, "phase": "train", "update": 372, "total_env_steps": 1190400, "episode_reward": 0.34244489669799805, "value_loss": 0.015353715730210145, "policy_loss": -0.010344016057410244, "dist_entropy": 0.5909665862719218, "actor_grad_norm": 0.15821854770183563, "critic_grad_norm": 0.0405169352889061, "ratio": 0.9994152188301086, "entropy": 0.5909665862719218, "incre_win_rate": 0.7, "step": 372}
{"time": 1766586963.7960334, "phase": "train", "update": 373, "total_env_steps": 1193600, "episode_reward": 0.351070761680603, "value_loss": 0.0126931290452679, "policy_loss": -0.011722046752710468, "dist_entropy": 0.610162357489268, "actor_grad_norm": 0.16261249780654907, "critic_grad_norm": 0.036129456013441086, "ratio": 1.0006062984466553, "entropy": 0.610162357489268, "incre_win_rate": 0.8135593220338984, "step": 373}
{"time": 1766586968.529554, "phase": "train", "update": 374, "total_env_steps": 1196800, "episode_reward": 0.36896753311157227, "value_loss": 0.012869109896322091, "policy_loss": -0.009213532180658509, "dist_entropy": 0.5854222774505615, "actor_grad_norm": 0.1498333215713501, "critic_grad_norm": 0.027534538879990578, "ratio": 1.0005000829696655, "entropy": 0.5854222774505615, "incre_win_rate": 0.8548387096774194, "step": 374}
{"time": 1766586973.1659799, "phase": "train", "update": 375, "total_env_steps": 1200000, "episode_reward": 0.36636489629745483, "value_loss": 0.014974143045643965, "policy_loss": -0.01088769419984222, "dist_entropy": 0.5767722487449646, "actor_grad_norm": 0.15825983881950378, "critic_grad_norm": 0.04322608560323715, "ratio": 1.0003525018692017, "entropy": 0.5767722487449646, "incre_win_rate": 0.8225806451612904, "step": 375}
{"time": 1766586977.6894138, "phase": "train", "update": 376, "total_env_steps": 1203200, "episode_reward": 0.36164215207099915, "value_loss": 0.013084208220243454, "policy_loss": -0.010842728180165295, "dist_entropy": 0.600876533985138, "actor_grad_norm": 0.15324243903160095, "critic_grad_norm": 0.02210167981684208, "ratio": 0.9998316764831543, "entropy": 0.600876533985138, "incre_win_rate": 0.8225806451612904, "step": 376}
{"time": 1766586982.2608538, "phase": "train", "update": 377, "total_env_steps": 1206400, "episode_reward": 0.3680652379989624, "value_loss": 0.01157113624115785, "policy_loss": -0.01089719010031871, "dist_entropy": 0.6078063249588013, "actor_grad_norm": 0.19686667621135712, "critic_grad_norm": 0.028565386310219765, "ratio": 0.9986128807067871, "entropy": 0.6078063249588013, "incre_win_rate": 0.8360655737704918, "step": 377}
{"time": 1766586987.0125523, "phase": "train", "update": 378, "total_env_steps": 1209600, "episode_reward": 0.36234527826309204, "value_loss": 0.015581929435332617, "policy_loss": -0.009691571480367145, "dist_entropy": 0.6073207139968873, "actor_grad_norm": 0.1330733299255371, "critic_grad_norm": 0.0796714723110199, "ratio": 1.000550627708435, "entropy": 0.6073207139968873, "incre_win_rate": 0.8387096774193549, "step": 378}
{"time": 1766586991.5929077, "phase": "train", "update": 379, "total_env_steps": 1212800, "episode_reward": 0.3509022891521454, "value_loss": 0.0159117945159475, "policy_loss": -0.010817676744123853, "dist_entropy": 0.6109720826148987, "actor_grad_norm": 0.1498986780643463, "critic_grad_norm": 0.04969699680805206, "ratio": 0.9988287687301636, "entropy": 0.6109720826148987, "incre_win_rate": 0.7868852459016393, "step": 379}
{"time": 1766586996.235271, "phase": "train", "update": 380, "total_env_steps": 1216000, "episode_reward": 0.3544538915157318, "value_loss": 0.016973825419942537, "policy_loss": -0.010511615507203942, "dist_entropy": 0.6141570250193278, "actor_grad_norm": 0.1894824504852295, "critic_grad_norm": 0.02836182713508606, "ratio": 0.9995912909507751, "entropy": 0.6141570250193278, "incre_win_rate": 0.7540983606557377, "step": 380}
{"time": 1766587000.8865, "phase": "train", "update": 381, "total_env_steps": 1219200, "episode_reward": 0.36264631152153015, "value_loss": 0.009488060201207797, "policy_loss": -0.011408260721494893, "dist_entropy": 0.6190604766209921, "actor_grad_norm": 0.16069485247135162, "critic_grad_norm": 0.03933282569050789, "ratio": 0.9989005327224731, "entropy": 0.6190604766209921, "incre_win_rate": 0.819672131147541, "step": 381}
{"time": 1766587007.924408, "phase": "eval", "update": 381, "total_env_steps": 1219200, "eval_win_rate": 1.0, "eval_episode_reward": 20.011948529411764, "step": 381}
{"time": 1766587012.4857135, "phase": "train", "update": 382, "total_env_steps": 1222400, "episode_reward": 0.36300015449523926, "value_loss": 0.011594096881647904, "policy_loss": -0.011053480466589842, "dist_entropy": 0.6031815052032471, "actor_grad_norm": 0.17330577969551086, "critic_grad_norm": 0.07176924496889114, "ratio": 0.999308705329895, "entropy": 0.6031815052032471, "incre_win_rate": 0.9107142857142857, "step": 382}
{"time": 1766587017.1265981, "phase": "train", "update": 383, "total_env_steps": 1225600, "episode_reward": 0.3715602159500122, "value_loss": 0.009639994117120902, "policy_loss": -0.011240705856050682, "dist_entropy": 0.592642092704773, "actor_grad_norm": 0.16923226416110992, "critic_grad_norm": 0.054749924689531326, "ratio": 0.9990777373313904, "entropy": 0.592642092704773, "incre_win_rate": 0.8253968253968254, "step": 383}
{"time": 1766587021.7950792, "phase": "train", "update": 384, "total_env_steps": 1228800, "episode_reward": 0.3665632903575897, "value_loss": 0.011160142533481122, "policy_loss": -0.010078604999680845, "dist_entropy": 0.6279470960299174, "actor_grad_norm": 0.18880653381347656, "critic_grad_norm": 0.022420372813940048, "ratio": 0.9995338916778564, "entropy": 0.6279470960299174, "incre_win_rate": 0.8870967741935484, "step": 384}
{"time": 1766587026.4787018, "phase": "train", "update": 385, "total_env_steps": 1232000, "episode_reward": 0.36023440957069397, "value_loss": 0.013016965302328268, "policy_loss": -0.01165215295043017, "dist_entropy": 0.5867771506309509, "actor_grad_norm": 0.166375070810318, "critic_grad_norm": 0.048390042036771774, "ratio": 1.0001989603042603, "entropy": 0.5867771506309509, "incre_win_rate": 0.8032786885245902, "step": 385}
{"time": 1766587031.0949662, "phase": "train", "update": 386, "total_env_steps": 1235200, "episode_reward": 0.369632363319397, "value_loss": 0.012643804711600145, "policy_loss": -0.01101856395633168, "dist_entropy": 0.5893900831540425, "actor_grad_norm": 0.16436538100242615, "critic_grad_norm": 0.03051370196044445, "ratio": 0.9991317987442017, "entropy": 0.5893900831540425, "incre_win_rate": 0.828125, "step": 386}
{"time": 1766587035.7381291, "phase": "train", "update": 387, "total_env_steps": 1238400, "episode_reward": 0.36545494198799133, "value_loss": 0.010611339223881562, "policy_loss": -0.011810292899354617, "dist_entropy": 0.6008586486180624, "actor_grad_norm": 0.16063407063484192, "critic_grad_norm": 0.023406976833939552, "ratio": 0.9995525479316711, "entropy": 0.6008586486180624, "incre_win_rate": 0.896551724137931, "step": 387}
{"time": 1766587040.3619175, "phase": "train", "update": 388, "total_env_steps": 1241600, "episode_reward": 0.3602045178413391, "value_loss": 0.012751922197639941, "policy_loss": -0.0113468133746494, "dist_entropy": 0.6113711357116699, "actor_grad_norm": 0.1550636738538742, "critic_grad_norm": 0.025772718712687492, "ratio": 0.9981702566146851, "entropy": 0.6113711357116699, "incre_win_rate": 0.8333333333333334, "step": 388}
{"time": 1766587045.032137, "phase": "train", "update": 389, "total_env_steps": 1244800, "episode_reward": 0.3758386969566345, "value_loss": 0.009992743283510208, "policy_loss": -0.010607804832947447, "dist_entropy": 0.6022015690803528, "actor_grad_norm": 0.1618371456861496, "critic_grad_norm": 0.02301754243671894, "ratio": 0.9997361302375793, "entropy": 0.6022015690803528, "incre_win_rate": 0.90625, "step": 389}
{"time": 1766587049.5844324, "phase": "train", "update": 390, "total_env_steps": 1248000, "episode_reward": 0.35481616854667664, "value_loss": 0.012815069407224655, "policy_loss": -0.011164485574905807, "dist_entropy": 0.6124022205670675, "actor_grad_norm": 0.18976454436779022, "critic_grad_norm": 0.031180091202259064, "ratio": 0.9998533725738525, "entropy": 0.6124022205670675, "incre_win_rate": 0.8305084745762712, "step": 390}
{"time": 1766587054.114745, "phase": "train", "update": 391, "total_env_steps": 1251200, "episode_reward": 0.3683532476425171, "value_loss": 0.014407710048059623, "policy_loss": -0.01209376866686398, "dist_entropy": 0.6079538464546204, "actor_grad_norm": 0.18151873350143433, "critic_grad_norm": 0.02832847833633423, "ratio": 0.9998430609703064, "entropy": 0.6079538464546204, "incre_win_rate": 0.85, "step": 391}
{"time": 1766587058.791451, "phase": "train", "update": 392, "total_env_steps": 1254400, "episode_reward": 0.35699066519737244, "value_loss": 0.016517276565233868, "policy_loss": -0.011733923269491223, "dist_entropy": 0.5945128281911214, "actor_grad_norm": 0.2063833475112915, "critic_grad_norm": 0.08109277486801147, "ratio": 0.9998511672019958, "entropy": 0.5945128281911214, "incre_win_rate": 0.7580645161290323, "step": 392}
{"time": 1766587063.3255455, "phase": "train", "update": 393, "total_env_steps": 1257600, "episode_reward": 0.36556679010391235, "value_loss": 0.013891781556109588, "policy_loss": -0.011126250641131227, "dist_entropy": 0.5920190850893656, "actor_grad_norm": 0.1561342179775238, "critic_grad_norm": 0.043905604630708694, "ratio": 0.9993904829025269, "entropy": 0.5920190850893656, "incre_win_rate": 0.7936507936507936, "step": 393}
{"time": 1766587067.9290376, "phase": "train", "update": 394, "total_env_steps": 1260800, "episode_reward": 0.3616391122341156, "value_loss": 0.009799534020324548, "policy_loss": -0.011032706011129297, "dist_entropy": 0.5960263291994731, "actor_grad_norm": 0.1552213579416275, "critic_grad_norm": 0.019673768430948257, "ratio": 0.9996850490570068, "entropy": 0.5960263291994731, "incre_win_rate": 0.8360655737704918, "step": 394}
{"time": 1766587072.51116, "phase": "train", "update": 395, "total_env_steps": 1264000, "episode_reward": 0.35635262727737427, "value_loss": 0.014359970887502035, "policy_loss": -0.011447650478694981, "dist_entropy": 0.5903916478157043, "actor_grad_norm": 0.18471591174602509, "critic_grad_norm": 0.02410013973712921, "ratio": 0.9995944499969482, "entropy": 0.5903916478157043, "incre_win_rate": 0.7931034482758621, "step": 395}
{"time": 1766587077.100204, "phase": "train", "update": 396, "total_env_steps": 1267200, "episode_reward": 0.3648245930671692, "value_loss": 0.009611904621124268, "policy_loss": -0.011139843979095095, "dist_entropy": 0.5926525513331096, "actor_grad_norm": 0.17429392039775848, "critic_grad_norm": 0.07866008579730988, "ratio": 0.999186098575592, "entropy": 0.5926525513331096, "incre_win_rate": 0.8387096774193549, "step": 396}
{"time": 1766587081.6460454, "phase": "train", "update": 397, "total_env_steps": 1270400, "episode_reward": 0.3552788197994232, "value_loss": 0.011013700378437836, "policy_loss": -0.011854290506740502, "dist_entropy": 0.5880241552988689, "actor_grad_norm": 0.17283646762371063, "critic_grad_norm": 0.036952562630176544, "ratio": 0.9999830722808838, "entropy": 0.5880241552988689, "incre_win_rate": 0.7540983606557377, "step": 397}
{"time": 1766587086.2606108, "phase": "train", "update": 398, "total_env_steps": 1273600, "episode_reward": 0.3599257171154022, "value_loss": 0.014106071678300698, "policy_loss": -0.010736561403049284, "dist_entropy": 0.5816142400105794, "actor_grad_norm": 0.20411226153373718, "critic_grad_norm": 0.031119536608457565, "ratio": 0.9993972778320312, "entropy": 0.5816142400105794, "incre_win_rate": 0.819672131147541, "step": 398}
{"time": 1766587090.840652, "phase": "train", "update": 399, "total_env_steps": 1276800, "episode_reward": 0.34908315539360046, "value_loss": 0.010693050113817056, "policy_loss": -0.011423974059637961, "dist_entropy": 0.6080007433891297, "actor_grad_norm": 0.1744929403066635, "critic_grad_norm": 0.054349277168512344, "ratio": 0.9995793104171753, "entropy": 0.6080007433891297, "incre_win_rate": 0.8275862068965517, "step": 399}
{"time": 1766587095.3894675, "phase": "train", "update": 400, "total_env_steps": 1280000, "episode_reward": 0.3573521673679352, "value_loss": 0.012247094201544921, "policy_loss": -0.011067216855531114, "dist_entropy": 0.5716915766398112, "actor_grad_norm": 0.1711844652891159, "critic_grad_norm": 0.022519243881106377, "ratio": 0.9990795254707336, "entropy": 0.5716915766398112, "incre_win_rate": 0.8064516129032258, "step": 400}
{"time": 1766587100.0319622, "phase": "train", "update": 401, "total_env_steps": 1283200, "episode_reward": 0.3629419505596161, "value_loss": 0.01188061988602082, "policy_loss": -0.01042499464784612, "dist_entropy": 0.578214430809021, "actor_grad_norm": 0.13191843032836914, "critic_grad_norm": 0.05983534827828407, "ratio": 0.999783456325531, "entropy": 0.578214430809021, "incre_win_rate": 0.864406779661017, "step": 401}
{"time": 1766587107.247082, "phase": "eval", "update": 401, "total_env_steps": 1283200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.88403799019608, "step": 401}
{"time": 1766587111.8287454, "phase": "train", "update": 402, "total_env_steps": 1286400, "episode_reward": 0.35522595047950745, "value_loss": 0.013418593009312947, "policy_loss": -0.011908307980245069, "dist_entropy": 0.5818430701891582, "actor_grad_norm": 0.15891525149345398, "critic_grad_norm": 0.02467050962150097, "ratio": 0.998497724533081, "entropy": 0.5818430701891582, "incre_win_rate": 0.8064516129032258, "step": 402}
{"time": 1766587116.4000099, "phase": "train", "update": 403, "total_env_steps": 1289600, "episode_reward": 0.3692256510257721, "value_loss": 0.009088331150511901, "policy_loss": -0.01010529905658378, "dist_entropy": 0.5988054235776266, "actor_grad_norm": 0.15100662410259247, "critic_grad_norm": 0.06217283755540848, "ratio": 1.0003780126571655, "entropy": 0.5988054235776266, "incre_win_rate": 0.9137931034482759, "step": 403}
{"time": 1766587120.9590218, "phase": "train", "update": 404, "total_env_steps": 1292800, "episode_reward": 0.36637407541275024, "value_loss": 0.011252290879686674, "policy_loss": -0.011541530728760564, "dist_entropy": 0.5925310850143433, "actor_grad_norm": 0.24819861352443695, "critic_grad_norm": 0.0359160378575325, "ratio": 0.9997830390930176, "entropy": 0.5925310850143433, "incre_win_rate": 0.8666666666666667, "step": 404}
{"time": 1766587125.5146346, "phase": "train", "update": 405, "total_env_steps": 1296000, "episode_reward": 0.3574877381324768, "value_loss": 0.008283549671371777, "policy_loss": -0.010689718150569643, "dist_entropy": 0.6263159314791361, "actor_grad_norm": 0.16948682069778442, "critic_grad_norm": 0.016937997192144394, "ratio": 0.9986422657966614, "entropy": 0.6263159314791361, "incre_win_rate": 0.8524590163934426, "step": 405}
{"time": 1766587130.2057593, "phase": "train", "update": 406, "total_env_steps": 1299200, "episode_reward": 0.3569362759590149, "value_loss": 0.010222586803138256, "policy_loss": -0.011676252494457539, "dist_entropy": 0.6072046160697937, "actor_grad_norm": 0.17478489875793457, "critic_grad_norm": 0.03085809201002121, "ratio": 0.99986732006073, "entropy": 0.6072046160697937, "incre_win_rate": 0.819672131147541, "step": 406}
{"time": 1766587134.758849, "phase": "train", "update": 407, "total_env_steps": 1302400, "episode_reward": 0.357718288898468, "value_loss": 0.012209839249650637, "policy_loss": -0.010893653114896, "dist_entropy": 0.6124877532323202, "actor_grad_norm": 0.19717009365558624, "critic_grad_norm": 0.04720557481050491, "ratio": 0.9992824196815491, "entropy": 0.6124877532323202, "incre_win_rate": 0.7833333333333333, "step": 407}
{"time": 1766587139.4760594, "phase": "train", "update": 408, "total_env_steps": 1305600, "episode_reward": 0.3735845983028412, "value_loss": 0.009505520574748516, "policy_loss": -0.010035016311883756, "dist_entropy": 0.6166470567385356, "actor_grad_norm": 0.16758526861667633, "critic_grad_norm": 0.024844300001859665, "ratio": 0.9995653629302979, "entropy": 0.6166470567385356, "incre_win_rate": 0.9032258064516129, "step": 408}
{"time": 1766587144.0215654, "phase": "train", "update": 409, "total_env_steps": 1308800, "episode_reward": 0.35532477498054504, "value_loss": 0.014979399181902409, "policy_loss": -0.011054147960362571, "dist_entropy": 0.6174279570579528, "actor_grad_norm": 0.15592733025550842, "critic_grad_norm": 0.03932184725999832, "ratio": 0.9999440312385559, "entropy": 0.6174279570579528, "incre_win_rate": 0.7704918032786885, "step": 409}
{"time": 1766587148.6490617, "phase": "train", "update": 410, "total_env_steps": 1312000, "episode_reward": 0.34700292348861694, "value_loss": 0.01490328721702099, "policy_loss": -0.012306799047115647, "dist_entropy": 0.630579674243927, "actor_grad_norm": 0.15096066892147064, "critic_grad_norm": 0.030840672552585602, "ratio": 1.0004981756210327, "entropy": 0.630579674243927, "incre_win_rate": 0.7758620689655172, "step": 410}
{"time": 1766587153.3092318, "phase": "train", "update": 411, "total_env_steps": 1315200, "episode_reward": 0.37132740020751953, "value_loss": 0.01051099132746458, "policy_loss": -0.011544413198866187, "dist_entropy": 0.6253910978635152, "actor_grad_norm": 0.1839413195848465, "critic_grad_norm": 0.03224055469036102, "ratio": 0.998823344707489, "entropy": 0.6253910978635152, "incre_win_rate": 0.8571428571428571, "step": 411}
{"time": 1766587157.9814236, "phase": "train", "update": 412, "total_env_steps": 1318400, "episode_reward": 0.3535240590572357, "value_loss": 0.0155433913692832, "policy_loss": -0.011512405710183771, "dist_entropy": 0.6338576634724935, "actor_grad_norm": 0.1912311613559723, "critic_grad_norm": 0.021972643211483955, "ratio": 0.9987775683403015, "entropy": 0.6338576634724935, "incre_win_rate": 0.7540983606557377, "step": 412}
{"time": 1766587162.6815305, "phase": "train", "update": 413, "total_env_steps": 1321600, "episode_reward": 0.37233608961105347, "value_loss": 0.00996883741269509, "policy_loss": -0.01257712514640493, "dist_entropy": 0.6244400342305502, "actor_grad_norm": 0.15945389866828918, "critic_grad_norm": 0.02216249145567417, "ratio": 0.9993259310722351, "entropy": 0.6244400342305502, "incre_win_rate": 0.8833333333333333, "step": 413}
{"time": 1766587167.3539817, "phase": "train", "update": 414, "total_env_steps": 1324800, "episode_reward": 0.3471836447715759, "value_loss": 0.01293620007733504, "policy_loss": -0.011307694946087092, "dist_entropy": 0.6069987018903097, "actor_grad_norm": 0.17256119847297668, "critic_grad_norm": 0.027485650032758713, "ratio": 0.9998334646224976, "entropy": 0.6069987018903097, "incre_win_rate": 0.8032786885245902, "step": 414}
{"time": 1766587172.0062249, "phase": "train", "update": 415, "total_env_steps": 1328000, "episode_reward": 0.3631686866283417, "value_loss": 0.011290750155846277, "policy_loss": -0.010977271142408302, "dist_entropy": 0.5888003945350647, "actor_grad_norm": 0.18086887896060944, "critic_grad_norm": 0.042455218732357025, "ratio": 1.0003010034561157, "entropy": 0.5888003945350647, "incre_win_rate": 0.8166666666666667, "step": 415}
{"time": 1766587176.6206753, "phase": "train", "update": 416, "total_env_steps": 1331200, "episode_reward": 0.3520810306072235, "value_loss": 0.012563406924406688, "policy_loss": -0.012279313695233303, "dist_entropy": 0.6007023255030314, "actor_grad_norm": 0.16252553462982178, "critic_grad_norm": 0.044176582247018814, "ratio": 0.998292088508606, "entropy": 0.6007023255030314, "incre_win_rate": 0.7966101694915254, "step": 416}
{"time": 1766587181.231252, "phase": "train", "update": 417, "total_env_steps": 1334400, "episode_reward": 0.3601447641849518, "value_loss": 0.014761350055535635, "policy_loss": -0.011382160340713435, "dist_entropy": 0.5826398452123006, "actor_grad_norm": 0.1484629213809967, "critic_grad_norm": 0.03304930776357651, "ratio": 1.0000005960464478, "entropy": 0.5826398452123006, "incre_win_rate": 0.7846153846153846, "step": 417}
{"time": 1766587185.8006976, "phase": "train", "update": 418, "total_env_steps": 1337600, "episode_reward": 0.35915136337280273, "value_loss": 0.011115326173603534, "policy_loss": -0.011591726012442885, "dist_entropy": 0.5873661160469055, "actor_grad_norm": 0.15600357949733734, "critic_grad_norm": 0.03554980456829071, "ratio": 0.9985932111740112, "entropy": 0.5873661160469055, "incre_win_rate": 0.8771929824561403, "step": 418}
{"time": 1766587190.9335387, "phase": "train", "update": 419, "total_env_steps": 1340800, "episode_reward": 0.3346813917160034, "value_loss": 0.016893527160088222, "policy_loss": -0.012666839047071932, "dist_entropy": 0.5912254730860392, "actor_grad_norm": 0.17097286880016327, "critic_grad_norm": 0.08766362071037292, "ratio": 0.9989467263221741, "entropy": 0.5912254730860392, "incre_win_rate": 0.711864406779661, "step": 419}
{"time": 1766587195.573934, "phase": "train", "update": 420, "total_env_steps": 1344000, "episode_reward": 0.3482207655906677, "value_loss": 0.017181196187933286, "policy_loss": -0.011735964814530438, "dist_entropy": 0.5879820585250854, "actor_grad_norm": 0.16943159699440002, "critic_grad_norm": 0.047446344047784805, "ratio": 0.998669445514679, "entropy": 0.5879820585250854, "incre_win_rate": 0.7333333333333333, "step": 420}
{"time": 1766587200.1678379, "phase": "train", "update": 421, "total_env_steps": 1347200, "episode_reward": 0.35859450697898865, "value_loss": 0.011939602221051853, "policy_loss": -0.010646022213586548, "dist_entropy": 0.5891511480013529, "actor_grad_norm": 0.16070935130119324, "critic_grad_norm": 0.04527750611305237, "ratio": 0.9992068409919739, "entropy": 0.5891511480013529, "incre_win_rate": 0.7833333333333333, "step": 421}
{"time": 1766587207.2378216, "phase": "eval", "update": 421, "total_env_steps": 1347200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.69937193627451, "step": 421}
{"time": 1766587212.0280192, "phase": "train", "update": 422, "total_env_steps": 1350400, "episode_reward": 0.35523590445518494, "value_loss": 0.012556166760623455, "policy_loss": -0.012128823775455367, "dist_entropy": 0.6024199525515238, "actor_grad_norm": 0.170383021235466, "critic_grad_norm": 0.020683297887444496, "ratio": 0.9994190335273743, "entropy": 0.6024199525515238, "incre_win_rate": 0.7619047619047619, "step": 422}
{"time": 1766587216.6042576, "phase": "train", "update": 423, "total_env_steps": 1353600, "episode_reward": 0.35303765535354614, "value_loss": 0.013700566875437895, "policy_loss": -0.011862467994431351, "dist_entropy": 0.6025013208389283, "actor_grad_norm": 0.17664553225040436, "critic_grad_norm": 0.034244097769260406, "ratio": 0.9987776279449463, "entropy": 0.6025013208389283, "incre_win_rate": 0.7758620689655172, "step": 423}
{"time": 1766587221.3006055, "phase": "train", "update": 424, "total_env_steps": 1356800, "episode_reward": 0.3493413031101227, "value_loss": 0.012654500827193261, "policy_loss": -0.011419887563532901, "dist_entropy": 0.6028365850448608, "actor_grad_norm": 0.181285098195076, "critic_grad_norm": 0.017666885629296303, "ratio": 0.9999904632568359, "entropy": 0.6028365850448608, "incre_win_rate": 0.7540983606557377, "step": 424}
{"time": 1766587225.8610914, "phase": "train", "update": 425, "total_env_steps": 1360000, "episode_reward": 0.366951584815979, "value_loss": 0.010671919770538807, "policy_loss": -0.010876913364727276, "dist_entropy": 0.5937966783841451, "actor_grad_norm": 0.1571541428565979, "critic_grad_norm": 0.03281126543879509, "ratio": 0.9997071623802185, "entropy": 0.5937966783841451, "incre_win_rate": 0.8666666666666667, "step": 425}
{"time": 1766587230.5302002, "phase": "train", "update": 426, "total_env_steps": 1363200, "episode_reward": 0.3471461534500122, "value_loss": 0.01052618008106947, "policy_loss": -0.011740144464882954, "dist_entropy": 0.5881643136342366, "actor_grad_norm": 0.160541370511055, "critic_grad_norm": 0.0469113327562809, "ratio": 0.9993681311607361, "entropy": 0.5881643136342366, "incre_win_rate": 0.847457627118644, "step": 426}
{"time": 1766587235.0860698, "phase": "train", "update": 427, "total_env_steps": 1366400, "episode_reward": 0.36565330624580383, "value_loss": 0.012530493177473545, "policy_loss": -0.011112856211255462, "dist_entropy": 0.6117354234059652, "actor_grad_norm": 0.17335590720176697, "critic_grad_norm": 0.04860715568065643, "ratio": 0.9997566342353821, "entropy": 0.6117354234059652, "incre_win_rate": 0.8870967741935484, "step": 427}
{"time": 1766587239.7122009, "phase": "train", "update": 428, "total_env_steps": 1369600, "episode_reward": 0.36091604828834534, "value_loss": 0.013224407844245435, "policy_loss": -0.010752577596484928, "dist_entropy": 0.6262150565783183, "actor_grad_norm": 0.15271185338497162, "critic_grad_norm": 0.04440651834011078, "ratio": 0.9995564222335815, "entropy": 0.6262150565783183, "incre_win_rate": 0.8793103448275862, "step": 428}
{"time": 1766587244.3306296, "phase": "train", "update": 429, "total_env_steps": 1372800, "episode_reward": 0.35580652952194214, "value_loss": 0.011473540713389714, "policy_loss": -0.012436447651559964, "dist_entropy": 0.6162946025530497, "actor_grad_norm": 0.16669563949108124, "critic_grad_norm": 0.031219758093357086, "ratio": 0.9990929961204529, "entropy": 0.6162946025530497, "incre_win_rate": 0.8225806451612904, "step": 429}
{"time": 1766587248.9186492, "phase": "train", "update": 430, "total_env_steps": 1376000, "episode_reward": 0.34658244252204895, "value_loss": 0.016330266868074737, "policy_loss": -0.01199980601420331, "dist_entropy": 0.6035947362581889, "actor_grad_norm": 0.19008281826972961, "critic_grad_norm": 0.05433112382888794, "ratio": 0.9985857009887695, "entropy": 0.6035947362581889, "incre_win_rate": 0.7241379310344828, "step": 430}
{"time": 1766587253.5444138, "phase": "train", "update": 431, "total_env_steps": 1379200, "episode_reward": 0.34300628304481506, "value_loss": 0.016359406523406506, "policy_loss": -0.012031760657505212, "dist_entropy": 0.5982199549674988, "actor_grad_norm": 0.18103203177452087, "critic_grad_norm": 0.06105244532227516, "ratio": 0.9990178942680359, "entropy": 0.5982199549674988, "incre_win_rate": 0.6774193548387096, "step": 431}
{"time": 1766587258.3375847, "phase": "train", "update": 432, "total_env_steps": 1382400, "episode_reward": 0.3584918677806854, "value_loss": 0.01177856841435035, "policy_loss": -0.011055571889907866, "dist_entropy": 0.6019635995229086, "actor_grad_norm": 0.17428036034107208, "critic_grad_norm": 0.03659821301698685, "ratio": 1.0000970363616943, "entropy": 0.6019635995229086, "incre_win_rate": 0.8135593220338984, "step": 432}
{"time": 1766587263.272809, "phase": "train", "update": 433, "total_env_steps": 1385600, "episode_reward": 0.3563564717769623, "value_loss": 0.012699558461705843, "policy_loss": -0.011523921389002585, "dist_entropy": 0.5882821043332418, "actor_grad_norm": 0.16209234297275543, "critic_grad_norm": 0.0233299657702446, "ratio": 0.999298095703125, "entropy": 0.5882821043332418, "incre_win_rate": 0.7936507936507936, "step": 433}
{"time": 1766587267.9824195, "phase": "train", "update": 434, "total_env_steps": 1388800, "episode_reward": 0.3568213880062103, "value_loss": 0.012786955138047536, "policy_loss": -0.011786726191164557, "dist_entropy": 0.5948009808858236, "actor_grad_norm": 0.1557687520980835, "critic_grad_norm": 0.04221256449818611, "ratio": 0.9987306594848633, "entropy": 0.5948009808858236, "incre_win_rate": 0.7966101694915254, "step": 434}
{"time": 1766587272.66713, "phase": "train", "update": 435, "total_env_steps": 1392000, "episode_reward": 0.3380843997001648, "value_loss": 0.014039196819067002, "policy_loss": -0.01314707769424975, "dist_entropy": 0.5951812744140625, "actor_grad_norm": 0.21443049609661102, "critic_grad_norm": 0.03941826894879341, "ratio": 0.9994789361953735, "entropy": 0.5951812744140625, "incre_win_rate": 0.7288135593220338, "step": 435}
{"time": 1766587277.29799, "phase": "train", "update": 436, "total_env_steps": 1395200, "episode_reward": 0.3516238033771515, "value_loss": 0.016715820506215097, "policy_loss": -0.010616384061878155, "dist_entropy": 0.5899300257364909, "actor_grad_norm": 0.1665351837873459, "critic_grad_norm": 0.01968604512512684, "ratio": 0.9999542236328125, "entropy": 0.5899300257364909, "incre_win_rate": 0.75, "step": 436}
{"time": 1766587281.8756795, "phase": "train", "update": 437, "total_env_steps": 1398400, "episode_reward": 0.37412530183792114, "value_loss": 0.010004986450076104, "policy_loss": -0.011211079327891109, "dist_entropy": 0.5927942951520284, "actor_grad_norm": 0.1652509719133377, "critic_grad_norm": 0.060498349368572235, "ratio": 0.9980078935623169, "entropy": 0.5927942951520284, "incre_win_rate": 0.9016393442622951, "step": 437}
{"time": 1766587286.5093138, "phase": "train", "update": 438, "total_env_steps": 1401600, "episode_reward": 0.3608946204185486, "value_loss": 0.012444435929258665, "policy_loss": -0.012417419108642965, "dist_entropy": 0.603049619992574, "actor_grad_norm": 0.2061641663312912, "critic_grad_norm": 0.029909886419773102, "ratio": 0.9995979070663452, "entropy": 0.603049619992574, "incre_win_rate": 0.8833333333333333, "step": 438}
{"time": 1766587291.1221855, "phase": "train", "update": 439, "total_env_steps": 1404800, "episode_reward": 0.34630516171455383, "value_loss": 0.01242431861658891, "policy_loss": -0.012391323528324468, "dist_entropy": 0.5989304741223653, "actor_grad_norm": 0.17592045664787292, "critic_grad_norm": 0.022349556908011436, "ratio": 0.9998445510864258, "entropy": 0.5989304741223653, "incre_win_rate": 0.75, "step": 439}
{"time": 1766587296.0800397, "phase": "train", "update": 440, "total_env_steps": 1408000, "episode_reward": 0.3538327217102051, "value_loss": 0.013439972636600335, "policy_loss": -0.012156836848058105, "dist_entropy": 0.5832785646120707, "actor_grad_norm": 0.16987350583076477, "critic_grad_norm": 0.019649013876914978, "ratio": 0.9994720220565796, "entropy": 0.5832785646120707, "incre_win_rate": 0.7966101694915254, "step": 440}
{"time": 1766587300.7428055, "phase": "train", "update": 441, "total_env_steps": 1411200, "episode_reward": 0.3525720238685608, "value_loss": 0.009122320016225179, "policy_loss": -0.012651343010822557, "dist_entropy": 0.6038675626118978, "actor_grad_norm": 0.17301952838897705, "critic_grad_norm": 0.025726336985826492, "ratio": 0.999022901058197, "entropy": 0.6038675626118978, "incre_win_rate": 0.8, "step": 441}
{"time": 1766587307.7251775, "phase": "eval", "update": 441, "total_env_steps": 1411200, "eval_win_rate": 0.875, "eval_episode_reward": 19.25528492647059, "step": 441}
{"time": 1766587312.4762442, "phase": "train", "update": 442, "total_env_steps": 1414400, "episode_reward": 0.3559834659099579, "value_loss": 0.011297683541973432, "policy_loss": -0.011936835572611434, "dist_entropy": 0.6077284534772237, "actor_grad_norm": 0.22225704789161682, "critic_grad_norm": 0.033752016723155975, "ratio": 0.9999089241027832, "entropy": 0.6077284534772237, "incre_win_rate": 0.8, "step": 442}
{"time": 1766587317.1210787, "phase": "train", "update": 443, "total_env_steps": 1417600, "episode_reward": 0.35957416892051697, "value_loss": 0.010747134561340015, "policy_loss": -0.012065176889225171, "dist_entropy": 0.6017014304796855, "actor_grad_norm": 0.18458767235279083, "critic_grad_norm": 0.0333649143576622, "ratio": 0.999407172203064, "entropy": 0.6017014304796855, "incre_win_rate": 0.8813559322033898, "step": 443}
{"time": 1766587321.889049, "phase": "train", "update": 444, "total_env_steps": 1420800, "episode_reward": 0.3443481922149658, "value_loss": 0.014524205898245176, "policy_loss": -0.011528111373123788, "dist_entropy": 0.6027395526568095, "actor_grad_norm": 0.17977271974086761, "critic_grad_norm": 0.05721915513277054, "ratio": 0.9998173117637634, "entropy": 0.6027395526568095, "incre_win_rate": 0.7049180327868853, "step": 444}
{"time": 1766587326.4855025, "phase": "train", "update": 445, "total_env_steps": 1424000, "episode_reward": 0.3581992983818054, "value_loss": 0.013017795483271281, "policy_loss": -0.011142281913046522, "dist_entropy": 0.5937211314837137, "actor_grad_norm": 0.16757480800151825, "critic_grad_norm": 0.026829533278942108, "ratio": 0.9987399578094482, "entropy": 0.5937211314837137, "incre_win_rate": 0.8166666666666667, "step": 445}
{"time": 1766587331.1381927, "phase": "train", "update": 446, "total_env_steps": 1427200, "episode_reward": 0.36601561307907104, "value_loss": 0.01290761816004912, "policy_loss": -0.011787271990202441, "dist_entropy": 0.6038950920104981, "actor_grad_norm": 0.1871340572834015, "critic_grad_norm": 0.042745716869831085, "ratio": 0.9989814162254333, "entropy": 0.6038950920104981, "incre_win_rate": 0.85, "step": 446}
{"time": 1766587335.8273113, "phase": "train", "update": 447, "total_env_steps": 1430400, "episode_reward": 0.352299302816391, "value_loss": 0.013186795202394326, "policy_loss": -0.011599444222676425, "dist_entropy": 0.6038545687993367, "actor_grad_norm": 0.18632872402668, "critic_grad_norm": 0.05663590878248215, "ratio": 1.0002697706222534, "entropy": 0.6038545687993367, "incre_win_rate": 0.8032786885245902, "step": 447}
{"time": 1766587340.455964, "phase": "train", "update": 448, "total_env_steps": 1433600, "episode_reward": 0.3631679117679596, "value_loss": 0.010047899621228377, "policy_loss": -0.011908801896325727, "dist_entropy": 0.5974064071973165, "actor_grad_norm": 0.16440393030643463, "critic_grad_norm": 0.06484072655439377, "ratio": 0.9998825788497925, "entropy": 0.5974064071973165, "incre_win_rate": 0.8709677419354839, "step": 448}
{"time": 1766587345.060465, "phase": "train", "update": 449, "total_env_steps": 1436800, "episode_reward": 0.33805686235427856, "value_loss": 0.014368866321941216, "policy_loss": -0.011313079227706168, "dist_entropy": 0.5970144391059875, "actor_grad_norm": 0.1664104163646698, "critic_grad_norm": 0.03270299732685089, "ratio": 1.0000898838043213, "entropy": 0.5970144391059875, "incre_win_rate": 0.75, "step": 449}
{"time": 1766587349.647378, "phase": "train", "update": 450, "total_env_steps": 1440000, "episode_reward": 0.35686808824539185, "value_loss": 0.010552837327122689, "policy_loss": -0.011789865718675211, "dist_entropy": 0.580472715695699, "actor_grad_norm": 0.19511477649211884, "critic_grad_norm": 0.02235802635550499, "ratio": 1.0012389421463013, "entropy": 0.580472715695699, "incre_win_rate": 0.8305084745762712, "step": 450}
{"time": 1766587354.3773751, "phase": "train", "update": 451, "total_env_steps": 1443200, "episode_reward": 0.3583371639251709, "value_loss": 0.012492003291845322, "policy_loss": -0.01094700088707062, "dist_entropy": 0.5954585472742716, "actor_grad_norm": 0.16469989717006683, "critic_grad_norm": 0.014398298226296902, "ratio": 0.999848484992981, "entropy": 0.5954585472742716, "incre_win_rate": 0.8064516129032258, "step": 451}
{"time": 1766587359.0508492, "phase": "train", "update": 452, "total_env_steps": 1446400, "episode_reward": 0.3591620922088623, "value_loss": 0.01025960004578034, "policy_loss": -0.01160597510088195, "dist_entropy": 0.6094353397687277, "actor_grad_norm": 0.17779307067394257, "critic_grad_norm": 0.017742261290550232, "ratio": 1.0006369352340698, "entropy": 0.6094353397687277, "incre_win_rate": 0.864406779661017, "step": 452}
{"time": 1766587363.7826202, "phase": "train", "update": 453, "total_env_steps": 1449600, "episode_reward": 0.35247015953063965, "value_loss": 0.011483747512102127, "policy_loss": -0.012451541486203154, "dist_entropy": 0.6118935505549113, "actor_grad_norm": 0.17370541393756866, "critic_grad_norm": 0.06860509514808655, "ratio": 0.9979694485664368, "entropy": 0.6118935505549113, "incre_win_rate": 0.7868852459016393, "step": 453}
{"time": 1766587368.3415098, "phase": "train", "update": 454, "total_env_steps": 1452800, "episode_reward": 0.3639192581176758, "value_loss": 0.010098936098317305, "policy_loss": -0.011678760465549469, "dist_entropy": 0.6113449215888977, "actor_grad_norm": 0.1597420871257782, "critic_grad_norm": 0.035835713148117065, "ratio": 0.99888014793396, "entropy": 0.6113449215888977, "incre_win_rate": 0.8524590163934426, "step": 454}
{"time": 1766587372.981599, "phase": "train", "update": 455, "total_env_steps": 1456000, "episode_reward": 0.3354335427284241, "value_loss": 0.014493142440915107, "policy_loss": -0.012025578063569735, "dist_entropy": 0.6162986040115357, "actor_grad_norm": 0.17614465951919556, "critic_grad_norm": 0.048047035932540894, "ratio": 0.9992318749427795, "entropy": 0.6162986040115357, "incre_win_rate": 0.7719298245614035, "step": 455}
{"time": 1766587377.5280678, "phase": "train", "update": 456, "total_env_steps": 1459200, "episode_reward": 0.3593336045742035, "value_loss": 0.01255995836108923, "policy_loss": -0.011775976741593298, "dist_entropy": 0.6115224758783976, "actor_grad_norm": 0.16938121616840363, "critic_grad_norm": 0.0405721478164196, "ratio": 1.0000181198120117, "entropy": 0.6115224758783976, "incre_win_rate": 0.85, "step": 456}
{"time": 1766587382.1603007, "phase": "train", "update": 457, "total_env_steps": 1462400, "episode_reward": 0.35069623589515686, "value_loss": 0.015163953974843025, "policy_loss": -0.011697160660196933, "dist_entropy": 0.5999130606651306, "actor_grad_norm": 0.18352146446704865, "critic_grad_norm": 0.06242189183831215, "ratio": 0.9999725818634033, "entropy": 0.5999130606651306, "incre_win_rate": 0.7301587301587301, "step": 457}
{"time": 1766587386.7132905, "phase": "train", "update": 458, "total_env_steps": 1465600, "episode_reward": 0.34735986590385437, "value_loss": 0.01048283874988556, "policy_loss": -0.010377616426852872, "dist_entropy": 0.6029985785484314, "actor_grad_norm": 0.16976839303970337, "critic_grad_norm": 0.022984223440289497, "ratio": 0.9991984963417053, "entropy": 0.6029985785484314, "incre_win_rate": 0.8214285714285714, "step": 458}
{"time": 1766587391.3325493, "phase": "train", "update": 459, "total_env_steps": 1468800, "episode_reward": 0.36624619364738464, "value_loss": 0.01385613518456618, "policy_loss": -0.012013797266365955, "dist_entropy": 0.5898576577504476, "actor_grad_norm": 0.15331457555294037, "critic_grad_norm": 0.07688470184803009, "ratio": 0.9992268085479736, "entropy": 0.5898576577504476, "incre_win_rate": 0.8412698412698413, "step": 459}
{"time": 1766587395.9104326, "phase": "train", "update": 460, "total_env_steps": 1472000, "episode_reward": 0.3536527156829834, "value_loss": 0.014534227425853412, "policy_loss": -0.010911445429648363, "dist_entropy": 0.609431533018748, "actor_grad_norm": 0.16845351457595825, "critic_grad_norm": 0.029436780139803886, "ratio": 0.9997706413269043, "entropy": 0.609431533018748, "incre_win_rate": 0.7868852459016393, "step": 460}
{"time": 1766587400.4671874, "phase": "train", "update": 461, "total_env_steps": 1475200, "episode_reward": 0.3401685059070587, "value_loss": 0.016194243853290876, "policy_loss": -0.011834352487587789, "dist_entropy": 0.5934298714001973, "actor_grad_norm": 0.1813374161720276, "critic_grad_norm": 0.02844211645424366, "ratio": 0.9995999336242676, "entropy": 0.5934298714001973, "incre_win_rate": 0.7288135593220338, "step": 461}
{"time": 1766587407.9633288, "phase": "eval", "update": 461, "total_env_steps": 1475200, "eval_win_rate": 1.0, "eval_episode_reward": 20.022058823529413, "step": 461}
{"time": 1766587412.6783862, "phase": "train", "update": 462, "total_env_steps": 1478400, "episode_reward": 0.34968748688697815, "value_loss": 0.013878835923969745, "policy_loss": -0.0117308403751764, "dist_entropy": 0.6186896522839864, "actor_grad_norm": 0.16336937248706818, "critic_grad_norm": 0.026021704077720642, "ratio": 0.99929279088974, "entropy": 0.6186896522839864, "incre_win_rate": 0.8421052631578947, "step": 462}
{"time": 1766587417.4233527, "phase": "train", "update": 463, "total_env_steps": 1481600, "episode_reward": 0.3284167945384979, "value_loss": 0.016372283610204857, "policy_loss": -0.013062345603447056, "dist_entropy": 0.6221850832303365, "actor_grad_norm": 0.15355193614959717, "critic_grad_norm": 0.03851916640996933, "ratio": 0.999523937702179, "entropy": 0.6221850832303365, "incre_win_rate": 0.6666666666666666, "step": 463}
{"time": 1766587422.0552702, "phase": "train", "update": 464, "total_env_steps": 1484800, "episode_reward": 0.32921722531318665, "value_loss": 0.015397773558894793, "policy_loss": -0.012958044498657036, "dist_entropy": 0.6085373957951864, "actor_grad_norm": 0.17927950620651245, "critic_grad_norm": 0.03142939507961273, "ratio": 0.9997189044952393, "entropy": 0.6085373957951864, "incre_win_rate": 0.7454545454545455, "step": 464}
{"time": 1766587426.7049618, "phase": "train", "update": 465, "total_env_steps": 1488000, "episode_reward": 0.3507276177406311, "value_loss": 0.01364622103671233, "policy_loss": -0.012074764745292536, "dist_entropy": 0.6144899288813274, "actor_grad_norm": 0.18118663132190704, "critic_grad_norm": 0.03824610635638237, "ratio": 0.9991282820701599, "entropy": 0.6144899288813274, "incre_win_rate": 0.7580645161290323, "step": 465}
{"time": 1766587431.2383068, "phase": "train", "update": 466, "total_env_steps": 1491200, "episode_reward": 0.3411274552345276, "value_loss": 0.013322726761301359, "policy_loss": -0.011888874381734619, "dist_entropy": 0.6061919967333476, "actor_grad_norm": 0.17937949299812317, "critic_grad_norm": 0.03529134765267372, "ratio": 0.999836802482605, "entropy": 0.6061919967333476, "incre_win_rate": 0.7543859649122807, "step": 466}
{"time": 1766587435.8316345, "phase": "train", "update": 467, "total_env_steps": 1494400, "episode_reward": 0.337621808052063, "value_loss": 0.010678896183768908, "policy_loss": -0.011351175616378365, "dist_entropy": 0.6164982835451762, "actor_grad_norm": 0.15610937774181366, "critic_grad_norm": 0.01814131811261177, "ratio": 0.9993188977241516, "entropy": 0.6164982835451762, "incre_win_rate": 0.7288135593220338, "step": 467}
{"time": 1766587440.493163, "phase": "train", "update": 468, "total_env_steps": 1497600, "episode_reward": 0.3509122431278229, "value_loss": 0.011888665022949378, "policy_loss": -0.011587849767828591, "dist_entropy": 0.6191814064979553, "actor_grad_norm": 0.14921797811985016, "critic_grad_norm": 0.028472524136304855, "ratio": 1.000348687171936, "entropy": 0.6191814064979553, "incre_win_rate": 0.8135593220338984, "step": 468}
{"time": 1766587445.1735244, "phase": "train", "update": 469, "total_env_steps": 1500800, "episode_reward": 0.35699447989463806, "value_loss": 0.00972509067505598, "policy_loss": -0.012161636657287053, "dist_entropy": 0.627585788567861, "actor_grad_norm": 0.16634026169776917, "critic_grad_norm": 0.016191916540265083, "ratio": 0.9992902278900146, "entropy": 0.627585788567861, "incre_win_rate": 0.8333333333333334, "step": 469}
{"time": 1766587449.806742, "phase": "train", "update": 470, "total_env_steps": 1504000, "episode_reward": 0.33821234107017517, "value_loss": 0.013793364850183327, "policy_loss": -0.011918088017737461, "dist_entropy": 0.6297073682149251, "actor_grad_norm": 0.17499679327011108, "critic_grad_norm": 0.02466329000890255, "ratio": 1.0000511407852173, "entropy": 0.6297073682149251, "incre_win_rate": 0.7857142857142857, "step": 470}
{"time": 1766587454.4973433, "phase": "train", "update": 471, "total_env_steps": 1507200, "episode_reward": 0.36497780680656433, "value_loss": 0.010260858200490474, "policy_loss": -0.011999034415917246, "dist_entropy": 0.6236506660779317, "actor_grad_norm": 0.17515897750854492, "critic_grad_norm": 0.052692823112010956, "ratio": 0.9972755908966064, "entropy": 0.6236506660779317, "incre_win_rate": 0.8548387096774194, "step": 471}
{"time": 1766587459.0977495, "phase": "train", "update": 472, "total_env_steps": 1510400, "episode_reward": 0.3495940864086151, "value_loss": 0.010857839013139407, "policy_loss": -0.010667682987277279, "dist_entropy": 0.6290142893791199, "actor_grad_norm": 0.17733395099639893, "critic_grad_norm": 0.019422108307480812, "ratio": 0.9985836744308472, "entropy": 0.6290142893791199, "incre_win_rate": 0.8103448275862069, "step": 472}
{"time": 1766587463.7165895, "phase": "train", "update": 473, "total_env_steps": 1513600, "episode_reward": 0.3652328550815582, "value_loss": 0.014213089893261591, "policy_loss": -0.01092288871481808, "dist_entropy": 0.6230554421742757, "actor_grad_norm": 0.19504320621490479, "critic_grad_norm": 0.03488682955503464, "ratio": 0.9991309642791748, "entropy": 0.6230554421742757, "incre_win_rate": 0.8253968253968254, "step": 473}
{"time": 1766587468.293944, "phase": "train", "update": 474, "total_env_steps": 1516800, "episode_reward": 0.349037230014801, "value_loss": 0.013468583797415097, "policy_loss": -0.011567914580763746, "dist_entropy": 0.6054652253786723, "actor_grad_norm": 0.2368125021457672, "critic_grad_norm": 0.030287789180874825, "ratio": 0.9995715618133545, "entropy": 0.6054652253786723, "incre_win_rate": 0.7758620689655172, "step": 474}
{"time": 1766587472.908492, "phase": "train", "update": 475, "total_env_steps": 1520000, "episode_reward": 0.34518688917160034, "value_loss": 0.013624903621772926, "policy_loss": -0.011830046853173808, "dist_entropy": 0.6159781416257223, "actor_grad_norm": 0.1659039407968521, "critic_grad_norm": 0.02362215891480446, "ratio": 0.9985368847846985, "entropy": 0.6159781416257223, "incre_win_rate": 0.7704918032786885, "step": 475}
{"time": 1766587477.5337005, "phase": "train", "update": 476, "total_env_steps": 1523200, "episode_reward": 0.3380614221096039, "value_loss": 0.014722794853150844, "policy_loss": -0.01224234651322007, "dist_entropy": 0.6225649992624919, "actor_grad_norm": 0.22269341349601746, "critic_grad_norm": 0.028218286111950874, "ratio": 0.999079167842865, "entropy": 0.6225649992624919, "incre_win_rate": 0.7413793103448276, "step": 476}
{"time": 1766587482.058049, "phase": "train", "update": 477, "total_env_steps": 1526400, "episode_reward": 0.35221201181411743, "value_loss": 0.01413025837391615, "policy_loss": -0.011141039517918708, "dist_entropy": 0.6078976194063822, "actor_grad_norm": 0.15555822849273682, "critic_grad_norm": 0.02644299529492855, "ratio": 0.9995977878570557, "entropy": 0.6078976194063822, "incre_win_rate": 0.7868852459016393, "step": 477}
{"time": 1766587486.6821406, "phase": "train", "update": 478, "total_env_steps": 1529600, "episode_reward": 0.34177929162979126, "value_loss": 0.01709215876956781, "policy_loss": -0.011896937281686821, "dist_entropy": 0.6118409673372904, "actor_grad_norm": 0.18499968945980072, "critic_grad_norm": 0.03538341447710991, "ratio": 1.0006455183029175, "entropy": 0.6118409673372904, "incre_win_rate": 0.711864406779661, "step": 478}
{"time": 1766587491.5136733, "phase": "train", "update": 479, "total_env_steps": 1532800, "episode_reward": 0.35680991411209106, "value_loss": 0.010563626637061436, "policy_loss": -0.010814891372225096, "dist_entropy": 0.6159961263338725, "actor_grad_norm": 0.14072111248970032, "critic_grad_norm": 0.060008756816387177, "ratio": 0.9995275735855103, "entropy": 0.6159961263338725, "incre_win_rate": 0.847457627118644, "step": 479}
{"time": 1766587496.475923, "phase": "train", "update": 480, "total_env_steps": 1536000, "episode_reward": 0.34957414865493774, "value_loss": 0.012280799572666486, "policy_loss": -0.011758568775981833, "dist_entropy": 0.6043526728947958, "actor_grad_norm": 0.21361222863197327, "critic_grad_norm": 0.016049569472670555, "ratio": 0.9982446432113647, "entropy": 0.6043526728947958, "incre_win_rate": 0.8166666666666667, "step": 480}
{"time": 1766587501.105275, "phase": "train", "update": 481, "total_env_steps": 1539200, "episode_reward": 0.3650206923484802, "value_loss": 0.005769628255317609, "policy_loss": -0.012414937511531103, "dist_entropy": 0.5875166058540344, "actor_grad_norm": 0.19698362052440643, "critic_grad_norm": 0.08748779445886612, "ratio": 0.9996931552886963, "entropy": 0.5875166058540344, "incre_win_rate": 0.9152542372881356, "step": 481}
{"time": 1766587508.2950153, "phase": "eval", "update": 481, "total_env_steps": 1539200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.8773743872549, "step": 481}
{"time": 1766587512.9405222, "phase": "train", "update": 482, "total_env_steps": 1542400, "episode_reward": 0.35571616888046265, "value_loss": 0.008676938277979692, "policy_loss": -0.01113643223017675, "dist_entropy": 0.6132049878438314, "actor_grad_norm": 0.157624289393425, "critic_grad_norm": 0.03346169739961624, "ratio": 0.9991207718849182, "entropy": 0.6132049878438314, "incre_win_rate": 0.8333333333333334, "step": 482}
{"time": 1766587517.5972703, "phase": "train", "update": 483, "total_env_steps": 1545600, "episode_reward": 0.3703576922416687, "value_loss": 0.006976816865305106, "policy_loss": -0.01162262337786899, "dist_entropy": 0.5867520054181417, "actor_grad_norm": 0.1528162658214569, "critic_grad_norm": 0.03575842082500458, "ratio": 0.9993091821670532, "entropy": 0.5867520054181417, "incre_win_rate": 0.9180327868852459, "step": 483}
{"time": 1766587522.2480586, "phase": "train", "update": 484, "total_env_steps": 1548800, "episode_reward": 0.3655683398246765, "value_loss": 0.010663556742171447, "policy_loss": -0.010477773983555554, "dist_entropy": 0.5943679173787435, "actor_grad_norm": 0.18097618222236633, "critic_grad_norm": 0.019348986446857452, "ratio": 0.9998427629470825, "entropy": 0.5943679173787435, "incre_win_rate": 0.8688524590163934, "step": 484}
{"time": 1766587526.961086, "phase": "train", "update": 485, "total_env_steps": 1552000, "episode_reward": 0.362284779548645, "value_loss": 0.012787183125813803, "policy_loss": -0.010510089967282947, "dist_entropy": 0.5960772673288981, "actor_grad_norm": 0.15747548639774323, "critic_grad_norm": 0.018453462049365044, "ratio": 0.999242901802063, "entropy": 0.5960772673288981, "incre_win_rate": 0.85, "step": 485}
{"time": 1766587531.655258, "phase": "train", "update": 486, "total_env_steps": 1555200, "episode_reward": 0.3632766306400299, "value_loss": 0.011429775568346182, "policy_loss": -0.011278465633806908, "dist_entropy": 0.5961623549461365, "actor_grad_norm": 0.1631637066602707, "critic_grad_norm": 0.02672276273369789, "ratio": 0.9989216327667236, "entropy": 0.5961623549461365, "incre_win_rate": 0.8360655737704918, "step": 486}
{"time": 1766587536.2653983, "phase": "train", "update": 487, "total_env_steps": 1558400, "episode_reward": 0.36359989643096924, "value_loss": 0.00827845639238755, "policy_loss": -0.010477382720673608, "dist_entropy": 0.5646729826927185, "actor_grad_norm": 0.17873574793338776, "critic_grad_norm": 0.02333383448421955, "ratio": 0.9994497895240784, "entropy": 0.5646729826927185, "incre_win_rate": 0.8983050847457628, "step": 487}
{"time": 1766587540.9232724, "phase": "train", "update": 488, "total_env_steps": 1561600, "episode_reward": 0.36451900005340576, "value_loss": 0.005871826099852721, "policy_loss": -0.010688400483166069, "dist_entropy": 0.5844715595245361, "actor_grad_norm": 0.1729615479707718, "critic_grad_norm": 0.013479935936629772, "ratio": 1.0006054639816284, "entropy": 0.5844715595245361, "incre_win_rate": 0.9180327868852459, "step": 488}
{"time": 1766587545.5884113, "phase": "train", "update": 489, "total_env_steps": 1564800, "episode_reward": 0.3570442795753479, "value_loss": 0.007982887358715137, "policy_loss": -0.010650769885773004, "dist_entropy": 0.5815345923105876, "actor_grad_norm": 0.14038066565990448, "critic_grad_norm": 0.012121491134166718, "ratio": 0.9997044801712036, "entropy": 0.5815345923105876, "incre_win_rate": 0.8813559322033898, "step": 489}
{"time": 1766587575.8804927, "phase": "train", "update": 490, "total_env_steps": 1568000, "episode_reward": 0.35013559460639954, "value_loss": 0.07300095160802206, "policy_loss": -0.00807622584590361, "dist_entropy": 0.5698049783706665, "actor_grad_norm": 0.14452345669269562, "critic_grad_norm": 0.2397754043340683, "ratio": 1.0009171962738037, "entropy": 0.5698049783706665, "incre_win_rate": 0.7818181818181819, "step": 490}
{"time": 1766587580.5569887, "phase": "train", "update": 491, "total_env_steps": 1571200, "episode_reward": 0.37216755747795105, "value_loss": 0.009644060395658016, "policy_loss": -0.009169940389698065, "dist_entropy": 0.5756517926851908, "actor_grad_norm": 0.16483579576015472, "critic_grad_norm": 0.10845988988876343, "ratio": 0.9997661709785461, "entropy": 0.5756517926851908, "incre_win_rate": 0.873015873015873, "step": 491}
{"time": 1766587585.2005422, "phase": "train", "update": 492, "total_env_steps": 1574400, "episode_reward": 0.3672028183937073, "value_loss": 0.010097429094215234, "policy_loss": -0.011033076178111874, "dist_entropy": 0.5747063557306925, "actor_grad_norm": 0.1435023695230484, "critic_grad_norm": 0.022593388333916664, "ratio": 0.9989666938781738, "entropy": 0.5747063557306925, "incre_win_rate": 0.8548387096774194, "step": 492}
{"time": 1766587589.8003151, "phase": "train", "update": 493, "total_env_steps": 1577600, "episode_reward": 0.35873621702194214, "value_loss": 0.010494091734290122, "policy_loss": -0.010674225025821708, "dist_entropy": 0.5815470019976298, "actor_grad_norm": 0.19007550179958344, "critic_grad_norm": 0.03135397285223007, "ratio": 0.9982466697692871, "entropy": 0.5815470019976298, "incre_win_rate": 0.8688524590163934, "step": 493}
{"time": 1766587594.36406, "phase": "train", "update": 494, "total_env_steps": 1580800, "episode_reward": 0.35283929109573364, "value_loss": 0.008607413060963154, "policy_loss": -0.011207649703940111, "dist_entropy": 0.5951605518658956, "actor_grad_norm": 0.1722724735736847, "critic_grad_norm": 0.023431483656167984, "ratio": 0.9995533227920532, "entropy": 0.5951605518658956, "incre_win_rate": 0.8771929824561403, "step": 494}
{"time": 1766587598.9657342, "phase": "train", "update": 495, "total_env_steps": 1584000, "episode_reward": 0.37136104702949524, "value_loss": 0.009941000180939833, "policy_loss": -0.010111587362442265, "dist_entropy": 0.5877324899037679, "actor_grad_norm": 0.15822182595729828, "critic_grad_norm": 0.016663582995533943, "ratio": 0.9994946718215942, "entropy": 0.5877324899037679, "incre_win_rate": 0.8709677419354839, "step": 495}
{"time": 1766587603.5757124, "phase": "train", "update": 496, "total_env_steps": 1587200, "episode_reward": 0.36855778098106384, "value_loss": 0.007160508539527655, "policy_loss": -0.01109945455671261, "dist_entropy": 0.5705550869305929, "actor_grad_norm": 0.15912748873233795, "critic_grad_norm": 0.031044404953718185, "ratio": 0.9986899495124817, "entropy": 0.5705550869305929, "incre_win_rate": 0.9166666666666666, "step": 496}
{"time": 1766587608.268293, "phase": "train", "update": 497, "total_env_steps": 1590400, "episode_reward": 0.36324524879455566, "value_loss": 0.01095170055826505, "policy_loss": -0.010720203071326751, "dist_entropy": 0.5812591155370076, "actor_grad_norm": 0.1365809142589569, "critic_grad_norm": 0.025316765531897545, "ratio": 0.9993084073066711, "entropy": 0.5812591155370076, "incre_win_rate": 0.8524590163934426, "step": 497}
{"time": 1766587612.8864121, "phase": "train", "update": 498, "total_env_steps": 1593600, "episode_reward": 0.35806065797805786, "value_loss": 0.00957314030577739, "policy_loss": -0.011364963447203518, "dist_entropy": 0.585239311059316, "actor_grad_norm": 0.21901752054691315, "critic_grad_norm": 0.022209294140338898, "ratio": 0.9994989633560181, "entropy": 0.585239311059316, "incre_win_rate": 0.864406779661017, "step": 498}
{"time": 1766587617.529548, "phase": "train", "update": 499, "total_env_steps": 1596800, "episode_reward": 0.3677489459514618, "value_loss": 0.01014709211885929, "policy_loss": -0.010320935211688465, "dist_entropy": 0.5655176679293314, "actor_grad_norm": 0.12517982721328735, "critic_grad_norm": 0.013408754020929337, "ratio": 0.9994668364524841, "entropy": 0.5655176679293314, "incre_win_rate": 0.8870967741935484, "step": 499}
{"time": 1766587622.104195, "phase": "train", "update": 500, "total_env_steps": 1600000, "episode_reward": 0.3582575023174286, "value_loss": 0.009296553147335847, "policy_loss": -0.010821495190663317, "dist_entropy": 0.5548451781272888, "actor_grad_norm": 0.16119340062141418, "critic_grad_norm": 0.024030597880482674, "ratio": 0.9986959099769592, "entropy": 0.5548451781272888, "incre_win_rate": 0.8305084745762712, "step": 500}
{"time": 1766587626.7754622, "phase": "train", "update": 501, "total_env_steps": 1603200, "episode_reward": 0.37277424335479736, "value_loss": 0.006438077986240387, "policy_loss": -0.010757191018342382, "dist_entropy": 0.5702776630719503, "actor_grad_norm": 0.1576317399740219, "critic_grad_norm": 0.03670414909720421, "ratio": 0.999947726726532, "entropy": 0.5702776630719503, "incre_win_rate": 0.9180327868852459, "step": 501}
{"time": 1766587633.9679253, "phase": "eval", "update": 501, "total_env_steps": 1603200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.766620710784316, "step": 501}
{"time": 1766587638.6192188, "phase": "train", "update": 502, "total_env_steps": 1606400, "episode_reward": 0.36396294832229614, "value_loss": 0.009524247484902541, "policy_loss": -0.011818623675298075, "dist_entropy": 0.5694297909736633, "actor_grad_norm": 0.16289420425891876, "critic_grad_norm": 0.02172449603676796, "ratio": 0.9989047050476074, "entropy": 0.5694297909736633, "incre_win_rate": 0.9, "step": 502}
{"time": 1766587643.5386043, "phase": "train", "update": 503, "total_env_steps": 1609600, "episode_reward": 0.3627382218837738, "value_loss": 0.011317652650177479, "policy_loss": -0.010758062971867351, "dist_entropy": 0.5646195848782857, "actor_grad_norm": 0.18825459480285645, "critic_grad_norm": 0.013433476909995079, "ratio": 0.9996678829193115, "entropy": 0.5646195848782857, "incre_win_rate": 0.8360655737704918, "step": 503}
{"time": 1766587648.2545946, "phase": "train", "update": 504, "total_env_steps": 1612800, "episode_reward": 0.362776517868042, "value_loss": 0.010258457933863005, "policy_loss": -0.01120824235081083, "dist_entropy": 0.5844792246818542, "actor_grad_norm": 0.15368424355983734, "critic_grad_norm": 0.025737013667821884, "ratio": 1.0004281997680664, "entropy": 0.5844792246818542, "incre_win_rate": 0.8333333333333334, "step": 504}
{"time": 1766587652.8140786, "phase": "train", "update": 505, "total_env_steps": 1616000, "episode_reward": 0.36187270283699036, "value_loss": 0.010468088711301485, "policy_loss": -0.01134781940414437, "dist_entropy": 0.5816712141036987, "actor_grad_norm": 0.16574600338935852, "critic_grad_norm": 0.03438832610845566, "ratio": 1.0000842809677124, "entropy": 0.5816712141036987, "incre_win_rate": 0.8064516129032258, "step": 505}
{"time": 1766587657.444187, "phase": "train", "update": 506, "total_env_steps": 1619200, "episode_reward": 0.3602443337440491, "value_loss": 0.00971665997058153, "policy_loss": -0.011056209391485557, "dist_entropy": 0.5884607831637064, "actor_grad_norm": 0.13896015286445618, "critic_grad_norm": 0.03520428016781807, "ratio": 0.9992709755897522, "entropy": 0.5884607831637064, "incre_win_rate": 0.8333333333333334, "step": 506}
{"time": 1766587662.0914252, "phase": "train", "update": 507, "total_env_steps": 1622400, "episode_reward": 0.36669957637786865, "value_loss": 0.011680319967369238, "policy_loss": -0.010846145935677972, "dist_entropy": 0.5800219893455505, "actor_grad_norm": 0.14631198346614838, "critic_grad_norm": 0.03984345868229866, "ratio": 0.9991535544395447, "entropy": 0.5800219893455505, "incre_win_rate": 0.8688524590163934, "step": 507}
{"time": 1766587666.6869304, "phase": "train", "update": 508, "total_env_steps": 1625600, "episode_reward": 0.3603707253932953, "value_loss": 0.012982805073261262, "policy_loss": -0.010505397037510042, "dist_entropy": 0.5942192435264587, "actor_grad_norm": 0.16434049606323242, "critic_grad_norm": 0.03868277370929718, "ratio": 0.9982696175575256, "entropy": 0.5942192435264587, "incre_win_rate": 0.8225806451612904, "step": 508}
{"time": 1766587671.341853, "phase": "train", "update": 509, "total_env_steps": 1628800, "episode_reward": 0.3791375756263733, "value_loss": 0.00636078796039025, "policy_loss": -0.010175680619561452, "dist_entropy": 0.573732336362203, "actor_grad_norm": 0.15924100577831268, "critic_grad_norm": 0.05312275141477585, "ratio": 1.0002819299697876, "entropy": 0.573732336362203, "incre_win_rate": 0.9344262295081968, "step": 509}
{"time": 1766587676.0391123, "phase": "train", "update": 510, "total_env_steps": 1632000, "episode_reward": 0.36039215326309204, "value_loss": 0.009649695145587127, "policy_loss": -0.011327562895332951, "dist_entropy": 0.5692723035812378, "actor_grad_norm": 0.2158721536397934, "critic_grad_norm": 0.04439849033951759, "ratio": 0.9991045594215393, "entropy": 0.5692723035812378, "incre_win_rate": 0.8225806451612904, "step": 510}
{"time": 1766587680.648173, "phase": "train", "update": 511, "total_env_steps": 1635200, "episode_reward": 0.3656977415084839, "value_loss": 0.011670367357631524, "policy_loss": -0.010906356260377947, "dist_entropy": 0.5657329241434733, "actor_grad_norm": 0.16105179488658905, "critic_grad_norm": 0.028963185846805573, "ratio": 1.0005748271942139, "entropy": 0.5657329241434733, "incre_win_rate": 0.8387096774193549, "step": 511}
{"time": 1766587685.2530894, "phase": "train", "update": 512, "total_env_steps": 1638400, "episode_reward": 0.3610209822654724, "value_loss": 0.01114403052876393, "policy_loss": -0.011061204042140579, "dist_entropy": 0.5806312561035156, "actor_grad_norm": 0.14926475286483765, "critic_grad_norm": 0.025078244507312775, "ratio": 0.9992121458053589, "entropy": 0.5806312561035156, "incre_win_rate": 0.8333333333333334, "step": 512}
{"time": 1766587689.9381666, "phase": "train", "update": 513, "total_env_steps": 1641600, "episode_reward": 0.3620251417160034, "value_loss": 0.010361254836122194, "policy_loss": -0.010150598924357723, "dist_entropy": 0.5640158971150716, "actor_grad_norm": 0.1373165249824524, "critic_grad_norm": 0.023200558498501778, "ratio": 0.9998739361763, "entropy": 0.5640158971150716, "incre_win_rate": 0.8032786885245902, "step": 513}
{"time": 1766587694.558804, "phase": "train", "update": 514, "total_env_steps": 1644800, "episode_reward": 0.36375921964645386, "value_loss": 0.009894785471260548, "policy_loss": -0.010430745305898388, "dist_entropy": 0.5832549850145976, "actor_grad_norm": 0.15859003365039825, "critic_grad_norm": 0.014910105615854263, "ratio": 0.9991753697395325, "entropy": 0.5832549850145976, "incre_win_rate": 0.8360655737704918, "step": 514}
{"time": 1766587699.1933117, "phase": "train", "update": 515, "total_env_steps": 1648000, "episode_reward": 0.35483917593955994, "value_loss": 0.009264083889623484, "policy_loss": -0.011078719125110107, "dist_entropy": 0.5506350477536519, "actor_grad_norm": 0.1677098423242569, "critic_grad_norm": 0.02874143421649933, "ratio": 0.9991186261177063, "entropy": 0.5506350477536519, "incre_win_rate": 0.8305084745762712, "step": 515}
{"time": 1766587703.754817, "phase": "train", "update": 516, "total_env_steps": 1651200, "episode_reward": 0.3642823398113251, "value_loss": 0.012270897688965002, "policy_loss": -0.01061106927656302, "dist_entropy": 0.5565052072207133, "actor_grad_norm": 0.14187560975551605, "critic_grad_norm": 0.04802778735756874, "ratio": 1.000328779220581, "entropy": 0.5565052072207133, "incre_win_rate": 0.8253968253968254, "step": 516}
{"time": 1766587708.3963168, "phase": "train", "update": 517, "total_env_steps": 1654400, "episode_reward": 0.37515705823898315, "value_loss": 0.007962009652207296, "policy_loss": -0.009950140738061464, "dist_entropy": 0.5632945656776428, "actor_grad_norm": 0.1409948766231537, "critic_grad_norm": 0.03925703465938568, "ratio": 0.9996405243873596, "entropy": 0.5632945656776428, "incre_win_rate": 0.9016393442622951, "step": 517}
{"time": 1766587713.0237658, "phase": "train", "update": 518, "total_env_steps": 1657600, "episode_reward": 0.3688395917415619, "value_loss": 0.01105729832003514, "policy_loss": -0.011034741960269418, "dist_entropy": 0.5621926069259644, "actor_grad_norm": 0.148010715842247, "critic_grad_norm": 0.037787292152643204, "ratio": 0.9995182156562805, "entropy": 0.5621926069259644, "incre_win_rate": 0.8548387096774194, "step": 518}
{"time": 1766587717.6269307, "phase": "train", "update": 519, "total_env_steps": 1660800, "episode_reward": 0.3628339469432831, "value_loss": 0.009767973981797694, "policy_loss": -0.010889480246734706, "dist_entropy": 0.575779648621877, "actor_grad_norm": 0.16184811294078827, "critic_grad_norm": 0.016374386847019196, "ratio": 1.000157356262207, "entropy": 0.575779648621877, "incre_win_rate": 0.8333333333333334, "step": 519}
{"time": 1766587722.259627, "phase": "train", "update": 520, "total_env_steps": 1664000, "episode_reward": 0.3712078928947449, "value_loss": 0.008565086002151171, "policy_loss": -0.011351458040311967, "dist_entropy": 0.5850258668263754, "actor_grad_norm": 0.181328684091568, "critic_grad_norm": 0.021280545741319656, "ratio": 1.000343918800354, "entropy": 0.5850258668263754, "incre_win_rate": 0.8852459016393442, "step": 520}
{"time": 1766587726.903035, "phase": "train", "update": 521, "total_env_steps": 1667200, "episode_reward": 0.3531479835510254, "value_loss": 0.010806383440891902, "policy_loss": -0.010858090359241146, "dist_entropy": 0.5796735684076945, "actor_grad_norm": 0.1411304473876953, "critic_grad_norm": 0.02835659682750702, "ratio": 0.9993487596511841, "entropy": 0.5796735684076945, "incre_win_rate": 0.7903225806451613, "step": 521}
{"time": 1766587733.8457282, "phase": "eval", "update": 521, "total_env_steps": 1667200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.82406556372549, "step": 521}
{"time": 1766587738.4740014, "phase": "train", "update": 522, "total_env_steps": 1670400, "episode_reward": 0.35926470160484314, "value_loss": 0.013325122309227784, "policy_loss": -0.009823839676026106, "dist_entropy": 0.5607166727383931, "actor_grad_norm": 0.1443421095609665, "critic_grad_norm": 0.026351364329457283, "ratio": 1.0003845691680908, "entropy": 0.5607166727383931, "incre_win_rate": 0.8135593220338984, "step": 522}
{"time": 1766587743.116644, "phase": "train", "update": 523, "total_env_steps": 1673600, "episode_reward": 0.3589721620082855, "value_loss": 0.011343971267342568, "policy_loss": -0.011475843791548358, "dist_entropy": 0.5741327365239461, "actor_grad_norm": 0.1595563143491745, "critic_grad_norm": 0.02118738368153572, "ratio": 1.0005427598953247, "entropy": 0.5741327365239461, "incre_win_rate": 0.8095238095238095, "step": 523}
{"time": 1766587747.733004, "phase": "train", "update": 524, "total_env_steps": 1676800, "episode_reward": 0.35192710161209106, "value_loss": 0.012509798631072044, "policy_loss": -0.011115805530602074, "dist_entropy": 0.5585380514462789, "actor_grad_norm": 0.1747627556324005, "critic_grad_norm": 0.03192974254488945, "ratio": 1.0006568431854248, "entropy": 0.5585380514462789, "incre_win_rate": 0.8245614035087719, "step": 524}
{"time": 1766587752.3504653, "phase": "train", "update": 525, "total_env_steps": 1680000, "episode_reward": 0.37664294242858887, "value_loss": 0.005906138413896163, "policy_loss": -0.012366691307151949, "dist_entropy": 0.5908289631207784, "actor_grad_norm": 0.1709638386964798, "critic_grad_norm": 0.10007979720830917, "ratio": 0.9996417164802551, "entropy": 0.5908289631207784, "incre_win_rate": 0.967741935483871, "step": 525}
{"time": 1766587756.988007, "phase": "train", "update": 526, "total_env_steps": 1683200, "episode_reward": 0.3665755093097687, "value_loss": 0.008021510144074758, "policy_loss": -0.011240056826172662, "dist_entropy": 0.5954882383346558, "actor_grad_norm": 0.1631891429424286, "critic_grad_norm": 0.05936240404844284, "ratio": 0.9996078014373779, "entropy": 0.5954882383346558, "incre_win_rate": 0.9152542372881356, "step": 526}
{"time": 1766587761.6273954, "phase": "train", "update": 527, "total_env_steps": 1686400, "episode_reward": 0.3556526005268097, "value_loss": 0.011198089209695656, "policy_loss": -0.012614881543746037, "dist_entropy": 0.5853100101153056, "actor_grad_norm": 0.15843704342842102, "critic_grad_norm": 0.0386761911213398, "ratio": 0.999998152256012, "entropy": 0.5853100101153056, "incre_win_rate": 0.8166666666666667, "step": 527}
{"time": 1766587766.2205174, "phase": "train", "update": 528, "total_env_steps": 1689600, "episode_reward": 0.36757197976112366, "value_loss": 0.007058714174975952, "policy_loss": -0.011637244525847735, "dist_entropy": 0.601272177696228, "actor_grad_norm": 0.14886634051799774, "critic_grad_norm": 0.038790326565504074, "ratio": 0.9995233416557312, "entropy": 0.601272177696228, "incre_win_rate": 0.9180327868852459, "step": 528}
{"time": 1766587770.809155, "phase": "train", "update": 529, "total_env_steps": 1692800, "episode_reward": 0.3551631569862366, "value_loss": 0.00988062092413505, "policy_loss": -0.011555654650460193, "dist_entropy": 0.582496686776479, "actor_grad_norm": 0.1443370133638382, "critic_grad_norm": 0.03543631359934807, "ratio": 0.999448299407959, "entropy": 0.582496686776479, "incre_win_rate": 0.8135593220338984, "step": 529}
{"time": 1766587775.3876133, "phase": "train", "update": 530, "total_env_steps": 1696000, "episode_reward": 0.3523361086845398, "value_loss": 0.013582987524569035, "policy_loss": -0.012855936497505382, "dist_entropy": 0.6091933608055115, "actor_grad_norm": 0.16681690514087677, "critic_grad_norm": 0.030344828963279724, "ratio": 1.0006864070892334, "entropy": 0.6091933608055115, "incre_win_rate": 0.8448275862068966, "step": 530}
{"time": 1766587780.01844, "phase": "train", "update": 531, "total_env_steps": 1699200, "episode_reward": 0.353576123714447, "value_loss": 0.011356621918578943, "policy_loss": -0.011213137466809542, "dist_entropy": 0.5944973468780518, "actor_grad_norm": 0.14058928191661835, "critic_grad_norm": 0.017671987414360046, "ratio": 0.9988847970962524, "entropy": 0.5944973468780518, "incre_win_rate": 0.819672131147541, "step": 531}
{"time": 1766587784.6438274, "phase": "train", "update": 532, "total_env_steps": 1702400, "episode_reward": 0.35616809129714966, "value_loss": 0.012185424628357092, "policy_loss": -0.011744793456396015, "dist_entropy": 0.6006422082583109, "actor_grad_norm": 0.1989300549030304, "critic_grad_norm": 0.05732343718409538, "ratio": 0.9984810948371887, "entropy": 0.6006422082583109, "incre_win_rate": 0.8620689655172413, "step": 532}
{"time": 1766587789.2612264, "phase": "train", "update": 533, "total_env_steps": 1705600, "episode_reward": 0.354643851518631, "value_loss": 0.013193698599934578, "policy_loss": -0.013334313587714893, "dist_entropy": 0.5794200499852499, "actor_grad_norm": 0.18329676985740662, "critic_grad_norm": 0.037056829780340195, "ratio": 0.9984995126724243, "entropy": 0.5794200499852499, "incre_win_rate": 0.7868852459016393, "step": 533}
{"time": 1766587794.0116816, "phase": "train", "update": 534, "total_env_steps": 1708800, "episode_reward": 0.35738128423690796, "value_loss": 0.010390241692463557, "policy_loss": -0.012433050296073134, "dist_entropy": 0.590604563554128, "actor_grad_norm": 0.15521745383739471, "critic_grad_norm": 0.0322282537817955, "ratio": 0.99950110912323, "entropy": 0.590604563554128, "incre_win_rate": 0.819672131147541, "step": 534}
{"time": 1766587798.8802462, "phase": "train", "update": 535, "total_env_steps": 1712000, "episode_reward": 0.3605645000934601, "value_loss": 0.01178517546504736, "policy_loss": -0.011582393023696605, "dist_entropy": 0.5805835644404094, "actor_grad_norm": 0.15024301409721375, "critic_grad_norm": 0.023669442161917686, "ratio": 0.9998705983161926, "entropy": 0.5805835644404094, "incre_win_rate": 0.8360655737704918, "step": 535}
{"time": 1766587803.4776163, "phase": "train", "update": 536, "total_env_steps": 1715200, "episode_reward": 0.3602902889251709, "value_loss": 0.012226161484917005, "policy_loss": -0.011713846748253804, "dist_entropy": 0.5580034057299296, "actor_grad_norm": 0.14539165794849396, "critic_grad_norm": 0.040803611278533936, "ratio": 0.9985418319702148, "entropy": 0.5580034057299296, "incre_win_rate": 0.8620689655172413, "step": 536}
{"time": 1766587808.1230915, "phase": "train", "update": 537, "total_env_steps": 1718400, "episode_reward": 0.368419885635376, "value_loss": 0.0113425279657046, "policy_loss": -0.010720999084487442, "dist_entropy": 0.5854789694150289, "actor_grad_norm": 0.1679626852273941, "critic_grad_norm": 0.02439129911363125, "ratio": 1.0012834072113037, "entropy": 0.5854789694150289, "incre_win_rate": 0.8688524590163934, "step": 537}
{"time": 1766587812.8167582, "phase": "train", "update": 538, "total_env_steps": 1721600, "episode_reward": 0.3529771864414215, "value_loss": 0.013336914281050364, "policy_loss": -0.011824637013289419, "dist_entropy": 0.5753785053888957, "actor_grad_norm": 0.1687297523021698, "critic_grad_norm": 0.04488904029130936, "ratio": 0.9993010759353638, "entropy": 0.5753785053888957, "incre_win_rate": 0.8253968253968254, "step": 538}
{"time": 1766587817.3917594, "phase": "train", "update": 539, "total_env_steps": 1724800, "episode_reward": 0.3603469729423523, "value_loss": 0.010757927286128203, "policy_loss": -0.011340554474357608, "dist_entropy": 0.6004432996114095, "actor_grad_norm": 0.14383646845817566, "critic_grad_norm": 0.03082907572388649, "ratio": 0.9994440078735352, "entropy": 0.6004432996114095, "incre_win_rate": 0.8448275862068966, "step": 539}
{"time": 1766587822.0164044, "phase": "train", "update": 540, "total_env_steps": 1728000, "episode_reward": 0.3509758412837982, "value_loss": 0.011531546401480833, "policy_loss": -0.012220033990353348, "dist_entropy": 0.5949959516525268, "actor_grad_norm": 0.18065541982650757, "critic_grad_norm": 0.026649802923202515, "ratio": 0.9987282752990723, "entropy": 0.5949959516525268, "incre_win_rate": 0.8032786885245902, "step": 540}
{"time": 1766587826.599871, "phase": "train", "update": 541, "total_env_steps": 1731200, "episode_reward": 0.33577972650527954, "value_loss": 0.014160313705603281, "policy_loss": -0.013819945293453392, "dist_entropy": 0.5958938042322794, "actor_grad_norm": 0.20400705933570862, "critic_grad_norm": 0.06115225702524185, "ratio": 0.9990698099136353, "entropy": 0.5958938042322794, "incre_win_rate": 0.75, "step": 541}
{"time": 1766587833.813747, "phase": "eval", "update": 541, "total_env_steps": 1731200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.619791666666668, "step": 541}
{"time": 1766587838.3901534, "phase": "train", "update": 542, "total_env_steps": 1734400, "episode_reward": 0.34411075711250305, "value_loss": 0.011138409251968066, "policy_loss": -0.012819879812968792, "dist_entropy": 0.6049017707506815, "actor_grad_norm": 0.20074567198753357, "critic_grad_norm": 0.016644148156046867, "ratio": 0.999560534954071, "entropy": 0.6049017707506815, "incre_win_rate": 0.7966101694915254, "step": 542}
{"time": 1766587843.0150418, "phase": "train", "update": 543, "total_env_steps": 1737600, "episode_reward": 0.34093135595321655, "value_loss": 0.012460555943349997, "policy_loss": -0.01395366137930741, "dist_entropy": 0.6182610114415487, "actor_grad_norm": 0.20239068567752838, "critic_grad_norm": 0.09944552928209305, "ratio": 0.9997715950012207, "entropy": 0.6182610114415487, "incre_win_rate": 0.65, "step": 543}
{"time": 1766587847.6282835, "phase": "train", "update": 544, "total_env_steps": 1740800, "episode_reward": 0.3385416865348816, "value_loss": 0.012521444509426752, "policy_loss": -0.013447990401402876, "dist_entropy": 0.6085657556851705, "actor_grad_norm": 0.17692287266254425, "critic_grad_norm": 0.055570077151060104, "ratio": 0.9998306632041931, "entropy": 0.6085657556851705, "incre_win_rate": 0.7241379310344828, "step": 544}
{"time": 1766587852.2997897, "phase": "train", "update": 545, "total_env_steps": 1744000, "episode_reward": 0.34482231736183167, "value_loss": 0.016332496143877506, "policy_loss": -0.012895047708754248, "dist_entropy": 0.5981749296188354, "actor_grad_norm": 0.15749484300613403, "critic_grad_norm": 0.09700595587491989, "ratio": 1.000543475151062, "entropy": 0.5981749296188354, "incre_win_rate": 0.7166666666666667, "step": 545}
{"time": 1766587856.8861074, "phase": "train", "update": 546, "total_env_steps": 1747200, "episode_reward": 0.3478814363479614, "value_loss": 0.0138539619743824, "policy_loss": -0.012172142898090972, "dist_entropy": 0.5933750907580058, "actor_grad_norm": 0.19311732053756714, "critic_grad_norm": 0.01923764869570732, "ratio": 0.9990295767784119, "entropy": 0.5933750907580058, "incre_win_rate": 0.7627118644067796, "step": 546}
{"time": 1766587861.5272765, "phase": "train", "update": 547, "total_env_steps": 1750400, "episode_reward": 0.3476892113685608, "value_loss": 0.014686986990272998, "policy_loss": -0.0121343932490196, "dist_entropy": 0.5857629696528117, "actor_grad_norm": 0.17280445992946625, "critic_grad_norm": 0.035341691225767136, "ratio": 0.999308168888092, "entropy": 0.5857629696528117, "incre_win_rate": 0.6935483870967742, "step": 547}
{"time": 1766587866.180312, "phase": "train", "update": 548, "total_env_steps": 1753600, "episode_reward": 0.3630844056606293, "value_loss": 0.008716707987089952, "policy_loss": -0.012611654154582652, "dist_entropy": 0.5927066644032796, "actor_grad_norm": 0.22394657135009766, "critic_grad_norm": 0.035473741590976715, "ratio": 0.99931800365448, "entropy": 0.5927066644032796, "incre_win_rate": 0.864406779661017, "step": 548}
{"time": 1766587870.8127239, "phase": "train", "update": 549, "total_env_steps": 1756800, "episode_reward": 0.37332645058631897, "value_loss": 0.008666259019325178, "policy_loss": -0.012247091834649382, "dist_entropy": 0.5900569955507914, "actor_grad_norm": 0.15990640223026276, "critic_grad_norm": 0.05842398479580879, "ratio": 0.9986873269081116, "entropy": 0.5900569955507914, "incre_win_rate": 0.9193548387096774, "step": 549}
{"time": 1766587875.4191847, "phase": "train", "update": 550, "total_env_steps": 1760000, "episode_reward": 0.3508356213569641, "value_loss": 0.008248599246144295, "policy_loss": -0.012445858574619707, "dist_entropy": 0.6129989941914876, "actor_grad_norm": 0.16166585683822632, "critic_grad_norm": 0.04010545834898949, "ratio": 0.9993249773979187, "entropy": 0.6129989941914876, "incre_win_rate": 0.8596491228070176, "step": 550}
{"time": 1766587880.0569768, "phase": "train", "update": 551, "total_env_steps": 1763200, "episode_reward": 0.3561657667160034, "value_loss": 0.01358064878731966, "policy_loss": -0.012371135196607715, "dist_entropy": 0.586202613512675, "actor_grad_norm": 0.1708025485277176, "critic_grad_norm": 0.07778539508581161, "ratio": 1.0001667737960815, "entropy": 0.586202613512675, "incre_win_rate": 0.7619047619047619, "step": 551}
{"time": 1766587884.8342001, "phase": "train", "update": 552, "total_env_steps": 1766400, "episode_reward": 0.3608930706977844, "value_loss": 0.011926264315843583, "policy_loss": -0.012513348711729577, "dist_entropy": 0.5955597877502441, "actor_grad_norm": 0.1608973890542984, "critic_grad_norm": 0.03704842925071716, "ratio": 0.998203694820404, "entropy": 0.5955597877502441, "incre_win_rate": 0.8166666666666667, "step": 552}
{"time": 1766587889.5488997, "phase": "train", "update": 553, "total_env_steps": 1769600, "episode_reward": 0.3554357886314392, "value_loss": 0.012211042270064355, "policy_loss": -0.012220076129996945, "dist_entropy": 0.5983832756678263, "actor_grad_norm": 0.17095749080181122, "critic_grad_norm": 0.021631086245179176, "ratio": 0.9992126822471619, "entropy": 0.5983832756678263, "incre_win_rate": 0.8166666666666667, "step": 553}
{"time": 1766587894.206983, "phase": "train", "update": 554, "total_env_steps": 1772800, "episode_reward": 0.36254212260246277, "value_loss": 0.012490184356768927, "policy_loss": -0.012442562436124405, "dist_entropy": 0.6159448305765788, "actor_grad_norm": 0.16319060325622559, "critic_grad_norm": 0.012089054100215435, "ratio": 1.0004435777664185, "entropy": 0.6159448305765788, "incre_win_rate": 0.8166666666666667, "step": 554}
{"time": 1766587898.8035994, "phase": "train", "update": 555, "total_env_steps": 1776000, "episode_reward": 0.3593313694000244, "value_loss": 0.010379268291095893, "policy_loss": -0.012320683694676404, "dist_entropy": 0.613992714881897, "actor_grad_norm": 0.19574128091335297, "critic_grad_norm": 0.02386057749390602, "ratio": 0.9992004632949829, "entropy": 0.613992714881897, "incre_win_rate": 0.8360655737704918, "step": 555}
{"time": 1766587903.419856, "phase": "train", "update": 556, "total_env_steps": 1779200, "episode_reward": 0.35645684599876404, "value_loss": 0.01252950622389714, "policy_loss": -0.012446254469686361, "dist_entropy": 0.6120528260866801, "actor_grad_norm": 0.1749022752046585, "critic_grad_norm": 0.04980549216270447, "ratio": 0.9977385997772217, "entropy": 0.6120528260866801, "incre_win_rate": 0.7868852459016393, "step": 556}
{"time": 1766587908.0035865, "phase": "train", "update": 557, "total_env_steps": 1782400, "episode_reward": 0.3453768491744995, "value_loss": 0.012937131524085998, "policy_loss": -0.012683723472286109, "dist_entropy": 0.6280804793039958, "actor_grad_norm": 0.17182479798793793, "critic_grad_norm": 0.038790736347436905, "ratio": 0.9986390471458435, "entropy": 0.6280804793039958, "incre_win_rate": 0.7627118644067796, "step": 557}
{"time": 1766587912.6820872, "phase": "train", "update": 558, "total_env_steps": 1785600, "episode_reward": 0.35699066519737244, "value_loss": 0.011306581770380337, "policy_loss": -0.01137697509247999, "dist_entropy": 0.6182232618331909, "actor_grad_norm": 0.20743337273597717, "critic_grad_norm": 0.042759157717227936, "ratio": 0.9994581937789917, "entropy": 0.6182232618331909, "incre_win_rate": 0.8, "step": 558}
{"time": 1766587917.3235207, "phase": "train", "update": 559, "total_env_steps": 1788800, "episode_reward": 0.3603645861148834, "value_loss": 0.009893834218382835, "policy_loss": -0.011629575074560231, "dist_entropy": 0.5998715440432231, "actor_grad_norm": 0.19113852083683014, "critic_grad_norm": 0.03524909168481827, "ratio": 0.9975235462188721, "entropy": 0.5998715440432231, "incre_win_rate": 0.819672131147541, "step": 559}
{"time": 1766587921.9703867, "phase": "train", "update": 560, "total_env_steps": 1792000, "episode_reward": 0.36889398097991943, "value_loss": 0.010522938333451748, "policy_loss": -0.011017277740053543, "dist_entropy": 0.6204023003578186, "actor_grad_norm": 0.19147293269634247, "critic_grad_norm": 0.01922098733484745, "ratio": 0.9996134042739868, "entropy": 0.6204023003578186, "incre_win_rate": 0.8524590163934426, "step": 560}
{"time": 1766587926.6578565, "phase": "train", "update": 561, "total_env_steps": 1795200, "episode_reward": 0.37404564023017883, "value_loss": 0.007354559376835823, "policy_loss": -0.011435631388395961, "dist_entropy": 0.6233294645945231, "actor_grad_norm": 0.15189902484416962, "critic_grad_norm": 0.05490044876933098, "ratio": 0.9990241527557373, "entropy": 0.6233294645945231, "incre_win_rate": 0.9516129032258065, "step": 561}
{"time": 1766587933.9580286, "phase": "eval", "update": 561, "total_env_steps": 1795200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.40295649509804, "step": 561}
{"time": 1766587938.550458, "phase": "train", "update": 562, "total_env_steps": 1798400, "episode_reward": 0.34482768177986145, "value_loss": 0.015033557576437791, "policy_loss": -0.011390427147905413, "dist_entropy": 0.6042499581972758, "actor_grad_norm": 0.1684800386428833, "critic_grad_norm": 0.05988346040248871, "ratio": 1.001721978187561, "entropy": 0.6042499581972758, "incre_win_rate": 0.7758620689655172, "step": 562}
{"time": 1766587943.172474, "phase": "train", "update": 563, "total_env_steps": 1801600, "episode_reward": 0.3547977805137634, "value_loss": 0.015210985206067562, "policy_loss": -0.01153122558758876, "dist_entropy": 0.620313807328542, "actor_grad_norm": 0.1606253981590271, "critic_grad_norm": 0.0366864949464798, "ratio": 1.0001506805419922, "entropy": 0.620313807328542, "incre_win_rate": 0.7540983606557377, "step": 563}
{"time": 1766587947.741653, "phase": "train", "update": 564, "total_env_steps": 1804800, "episode_reward": 0.3500429093837738, "value_loss": 0.01236545859525601, "policy_loss": -0.012604027955476719, "dist_entropy": 0.6146015842755636, "actor_grad_norm": 0.17266958951950073, "critic_grad_norm": 0.056468136608600616, "ratio": 0.9985799193382263, "entropy": 0.6146015842755636, "incre_win_rate": 0.7796610169491526, "step": 564}
{"time": 1766587952.3798304, "phase": "train", "update": 565, "total_env_steps": 1808000, "episode_reward": 0.35643383860588074, "value_loss": 0.009385091811418533, "policy_loss": -0.012215480645627963, "dist_entropy": 0.6046614448229471, "actor_grad_norm": 0.1641097217798233, "critic_grad_norm": 0.04302483797073364, "ratio": 0.9999843835830688, "entropy": 0.6046614448229471, "incre_win_rate": 0.8333333333333334, "step": 565}
{"time": 1766587957.0818088, "phase": "train", "update": 566, "total_env_steps": 1811200, "episode_reward": 0.35728326439857483, "value_loss": 0.010381284418205421, "policy_loss": -0.012396875694110084, "dist_entropy": 0.5895964980125428, "actor_grad_norm": 0.1509203314781189, "critic_grad_norm": 0.026349663734436035, "ratio": 1.0005295276641846, "entropy": 0.5895964980125428, "incre_win_rate": 0.8225806451612904, "step": 566}
{"time": 1766587961.7996676, "phase": "train", "update": 567, "total_env_steps": 1814400, "episode_reward": 0.3495672643184662, "value_loss": 0.012584391050040722, "policy_loss": -0.012863339555029068, "dist_entropy": 0.5984688202540079, "actor_grad_norm": 0.20100761950016022, "critic_grad_norm": 0.026257842779159546, "ratio": 0.999725878238678, "entropy": 0.5984688202540079, "incre_win_rate": 0.7678571428571429, "step": 567}
{"time": 1766587966.4855022, "phase": "train", "update": 568, "total_env_steps": 1817600, "episode_reward": 0.3566896319389343, "value_loss": 0.010698724475999673, "policy_loss": -0.01261912875699333, "dist_entropy": 0.600592315196991, "actor_grad_norm": 0.1809386909008026, "critic_grad_norm": 0.06087322533130646, "ratio": 0.99956214427948, "entropy": 0.600592315196991, "incre_win_rate": 0.75, "step": 568}
{"time": 1766587971.1595132, "phase": "train", "update": 569, "total_env_steps": 1820800, "episode_reward": 0.36979395151138306, "value_loss": 0.010620631898442904, "policy_loss": -0.011969894086219313, "dist_entropy": 0.5872997800509135, "actor_grad_norm": 0.15384866297245026, "critic_grad_norm": 0.033915530890226364, "ratio": 0.9987331032752991, "entropy": 0.5872997800509135, "incre_win_rate": 0.8387096774193549, "step": 569}
{"time": 1766587975.7905037, "phase": "train", "update": 570, "total_env_steps": 1824000, "episode_reward": 0.36497703194618225, "value_loss": 0.012458257252971332, "policy_loss": -0.011738724888155616, "dist_entropy": 0.600410517056783, "actor_grad_norm": 0.13766276836395264, "critic_grad_norm": 0.013233845122158527, "ratio": 0.9991402626037598, "entropy": 0.600410517056783, "incre_win_rate": 0.8360655737704918, "step": 570}
{"time": 1766587980.3752353, "phase": "train", "update": 571, "total_env_steps": 1827200, "episode_reward": 0.35738664865493774, "value_loss": 0.011942042534550031, "policy_loss": -0.011536268792054235, "dist_entropy": 0.6038455168406168, "actor_grad_norm": 0.16688336431980133, "critic_grad_norm": 0.06210741028189659, "ratio": 1.0003888607025146, "entropy": 0.6038455168406168, "incre_win_rate": 0.85, "step": 571}
{"time": 1766587985.0470202, "phase": "train", "update": 572, "total_env_steps": 1830400, "episode_reward": 0.34988513588905334, "value_loss": 0.01371673196554184, "policy_loss": -0.012878279618168165, "dist_entropy": 0.6151174068450928, "actor_grad_norm": 0.1503567099571228, "critic_grad_norm": 0.041802674531936646, "ratio": 0.9989742636680603, "entropy": 0.6151174068450928, "incre_win_rate": 0.7586206896551724, "step": 572}
{"time": 1766587989.6633365, "phase": "train", "update": 573, "total_env_steps": 1833600, "episode_reward": 0.3550705015659332, "value_loss": 0.009042675917347273, "policy_loss": -0.012271821428295481, "dist_entropy": 0.6210171620051066, "actor_grad_norm": 0.2029729187488556, "critic_grad_norm": 0.0543697215616703, "ratio": 0.9998087882995605, "entropy": 0.6210171620051066, "incre_win_rate": 0.8387096774193549, "step": 573}
{"time": 1766587994.297047, "phase": "train", "update": 574, "total_env_steps": 1836800, "episode_reward": 0.36627912521362305, "value_loss": 0.006944336090236902, "policy_loss": -0.011688520190802383, "dist_entropy": 0.5898927370707194, "actor_grad_norm": 0.1712469607591629, "critic_grad_norm": 0.04767204448580742, "ratio": 0.9983410239219666, "entropy": 0.5898927370707194, "incre_win_rate": 0.896551724137931, "step": 574}
{"time": 1766587998.9507327, "phase": "train", "update": 575, "total_env_steps": 1840000, "episode_reward": 0.35260796546936035, "value_loss": 0.012142931794126828, "policy_loss": -0.01072542557901291, "dist_entropy": 0.6121635437011719, "actor_grad_norm": 0.1790321171283722, "critic_grad_norm": 0.025907954201102257, "ratio": 0.9992653131484985, "entropy": 0.6121635437011719, "incre_win_rate": 0.8135593220338984, "step": 575}
{"time": 1766588003.5833445, "phase": "train", "update": 576, "total_env_steps": 1843200, "episode_reward": 0.3573544919490814, "value_loss": 0.009157027987142404, "policy_loss": -0.012155099640851456, "dist_entropy": 0.59595312277476, "actor_grad_norm": 0.16963815689086914, "critic_grad_norm": 0.029580561444163322, "ratio": 0.9997293949127197, "entropy": 0.59595312277476, "incre_win_rate": 0.8387096774193549, "step": 576}
{"time": 1766588008.2304974, "phase": "train", "update": 577, "total_env_steps": 1846400, "episode_reward": 0.35107386112213135, "value_loss": 0.011971828838189444, "policy_loss": -0.012899098717724418, "dist_entropy": 0.6141668160756429, "actor_grad_norm": 0.1898553967475891, "critic_grad_norm": 0.02523401752114296, "ratio": 0.9996087551116943, "entropy": 0.6141668160756429, "incre_win_rate": 0.8103448275862069, "step": 577}
{"time": 1766588012.922958, "phase": "train", "update": 578, "total_env_steps": 1849600, "episode_reward": 0.36369794607162476, "value_loss": 0.009508071839809418, "policy_loss": -0.01015530681347201, "dist_entropy": 0.6001402934392294, "actor_grad_norm": 0.16536104679107666, "critic_grad_norm": 0.01944587752223015, "ratio": 0.9997342824935913, "entropy": 0.6001402934392294, "incre_win_rate": 0.8666666666666667, "step": 578}
{"time": 1766588017.5302749, "phase": "train", "update": 579, "total_env_steps": 1852800, "episode_reward": 0.34429001808166504, "value_loss": 0.01009241615732511, "policy_loss": -0.012103658437505752, "dist_entropy": 0.5984328667322795, "actor_grad_norm": 0.20784099400043488, "critic_grad_norm": 0.02802497334778309, "ratio": 0.9994826316833496, "entropy": 0.5984328667322795, "incre_win_rate": 0.8166666666666667, "step": 579}
{"time": 1766588022.174807, "phase": "train", "update": 580, "total_env_steps": 1856000, "episode_reward": 0.36511412262916565, "value_loss": 0.009047493214408557, "policy_loss": -0.011161899531084884, "dist_entropy": 0.5823889017105103, "actor_grad_norm": 0.16690216958522797, "critic_grad_norm": 0.030843786895275116, "ratio": 0.9993285536766052, "entropy": 0.5823889017105103, "incre_win_rate": 0.9137931034482759, "step": 580}
{"time": 1766588026.7335181, "phase": "train", "update": 581, "total_env_steps": 1859200, "episode_reward": 0.35341760516166687, "value_loss": 0.010419430894156296, "policy_loss": -0.012099030413839366, "dist_entropy": 0.5943679690361023, "actor_grad_norm": 0.16841095685958862, "critic_grad_norm": 0.023337945342063904, "ratio": 0.999039888381958, "entropy": 0.5943679690361023, "incre_win_rate": 0.8793103448275862, "step": 581}
{"time": 1766588034.113051, "phase": "eval", "update": 581, "total_env_steps": 1859200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.617876838235293, "step": 581}
{"time": 1766588038.6837947, "phase": "train", "update": 582, "total_env_steps": 1862400, "episode_reward": 0.3638564348220825, "value_loss": 0.009535003267228604, "policy_loss": -0.011922595365474346, "dist_entropy": 0.5892420331637065, "actor_grad_norm": 0.1754322201013565, "critic_grad_norm": 0.026616867631673813, "ratio": 1.0003299713134766, "entropy": 0.5892420331637065, "incre_win_rate": 0.8870967741935484, "step": 582}
{"time": 1766588043.4826274, "phase": "train", "update": 583, "total_env_steps": 1865600, "episode_reward": 0.36751532554626465, "value_loss": 0.00728339289004604, "policy_loss": -0.010920526016129629, "dist_entropy": 0.6047937830289205, "actor_grad_norm": 0.1400603950023651, "critic_grad_norm": 0.027191434055566788, "ratio": 1.0003706216812134, "entropy": 0.6047937830289205, "incre_win_rate": 0.9310344827586207, "step": 583}
{"time": 1766588048.1827748, "phase": "train", "update": 584, "total_env_steps": 1868800, "episode_reward": 0.3661397099494934, "value_loss": 0.01060670589407285, "policy_loss": -0.010507300769753177, "dist_entropy": 0.5934186458587647, "actor_grad_norm": 0.16247746348381042, "critic_grad_norm": 0.028670696541666985, "ratio": 1.0005178451538086, "entropy": 0.5934186458587647, "incre_win_rate": 0.8709677419354839, "step": 584}
{"time": 1766588053.0225697, "phase": "train", "update": 585, "total_env_steps": 1872000, "episode_reward": 0.3544914126396179, "value_loss": 0.010025516959528129, "policy_loss": -0.012289097038478757, "dist_entropy": 0.5797685186068217, "actor_grad_norm": 0.1422303169965744, "critic_grad_norm": 0.04486651346087456, "ratio": 0.9984352588653564, "entropy": 0.5797685186068217, "incre_win_rate": 0.8135593220338984, "step": 585}
{"time": 1766588057.9389656, "phase": "train", "update": 586, "total_env_steps": 1875200, "episode_reward": 0.352774977684021, "value_loss": 0.00898806011925141, "policy_loss": -0.01261546697880614, "dist_entropy": 0.6000741362571717, "actor_grad_norm": 0.15831877291202545, "critic_grad_norm": 0.02272150106728077, "ratio": 1.0007188320159912, "entropy": 0.6000741362571717, "incre_win_rate": 0.847457627118644, "step": 586}
{"time": 1766588062.7194335, "phase": "train", "update": 587, "total_env_steps": 1878400, "episode_reward": 0.31774359941482544, "value_loss": 0.012437584934135278, "policy_loss": -0.013195957748962428, "dist_entropy": 0.5799258947372437, "actor_grad_norm": 0.15112903714179993, "critic_grad_norm": 0.062376752495765686, "ratio": 1.000244140625, "entropy": 0.5799258947372437, "incre_win_rate": 0.6851851851851852, "step": 587}
{"time": 1766588068.147694, "phase": "train", "update": 588, "total_env_steps": 1881600, "episode_reward": 0.3316858112812042, "value_loss": 0.011101111272970835, "policy_loss": -0.012306519171121029, "dist_entropy": 0.5952480475107829, "actor_grad_norm": 0.19311554729938507, "critic_grad_norm": 0.031643133610486984, "ratio": 1.000322937965393, "entropy": 0.5952480475107829, "incre_win_rate": 0.7543859649122807, "step": 588}
{"time": 1766588073.4362202, "phase": "train", "update": 589, "total_env_steps": 1884800, "episode_reward": 0.35580116510391235, "value_loss": 0.00848573421438535, "policy_loss": -0.011617139803788253, "dist_entropy": 0.5936972618103027, "actor_grad_norm": 0.1467260867357254, "critic_grad_norm": 0.010694367811083794, "ratio": 0.9988535046577454, "entropy": 0.5936972618103027, "incre_win_rate": 0.8524590163934426, "step": 589}
{"time": 1766588078.380968, "phase": "train", "update": 590, "total_env_steps": 1888000, "episode_reward": 0.34650811553001404, "value_loss": 0.011790813567737738, "policy_loss": -0.012630898299552959, "dist_entropy": 0.5785748322804769, "actor_grad_norm": 0.1984640657901764, "critic_grad_norm": 0.03622933849692345, "ratio": 1.0005226135253906, "entropy": 0.5785748322804769, "incre_win_rate": 0.7796610169491526, "step": 590}
{"time": 1766588083.0970972, "phase": "train", "update": 591, "total_env_steps": 1891200, "episode_reward": 0.3663235604763031, "value_loss": 0.007948845500747363, "policy_loss": -0.011268859091083053, "dist_entropy": 0.577276885509491, "actor_grad_norm": 0.18611615896224976, "critic_grad_norm": 0.08509761095046997, "ratio": 0.9994915723800659, "entropy": 0.577276885509491, "incre_win_rate": 0.8983050847457628, "step": 591}
{"time": 1766588087.8167386, "phase": "train", "update": 592, "total_env_steps": 1894400, "episode_reward": 0.35455575585365295, "value_loss": 0.012212960422039032, "policy_loss": -0.011445775020990822, "dist_entropy": 0.5681968530019125, "actor_grad_norm": 0.17159785330295563, "critic_grad_norm": 0.040169794112443924, "ratio": 1.0008692741394043, "entropy": 0.5681968530019125, "incre_win_rate": 0.8032786885245902, "step": 592}
{"time": 1766588092.4842763, "phase": "train", "update": 593, "total_env_steps": 1897600, "episode_reward": 0.35732001066207886, "value_loss": 0.011730823727945486, "policy_loss": -0.011970623118013652, "dist_entropy": 0.5753028750419616, "actor_grad_norm": 0.16270819306373596, "critic_grad_norm": 0.01903042010962963, "ratio": 0.999252438545227, "entropy": 0.5753028750419616, "incre_win_rate": 0.8166666666666667, "step": 593}
{"time": 1766588097.1985538, "phase": "train", "update": 594, "total_env_steps": 1900800, "episode_reward": 0.354227215051651, "value_loss": 0.007260157819837331, "policy_loss": -0.012236882140957544, "dist_entropy": 0.5797173182169596, "actor_grad_norm": 0.1691284328699112, "critic_grad_norm": 0.010953357443213463, "ratio": 1.0001494884490967, "entropy": 0.5797173182169596, "incre_win_rate": 0.864406779661017, "step": 594}
{"time": 1766588101.862169, "phase": "train", "update": 595, "total_env_steps": 1904000, "episode_reward": 0.34222811460494995, "value_loss": 0.012365559736887613, "policy_loss": -0.012286282485634577, "dist_entropy": 0.6076115727424621, "actor_grad_norm": 0.1934615969657898, "critic_grad_norm": 0.05457981303334236, "ratio": 1.0002341270446777, "entropy": 0.6076115727424621, "incre_win_rate": 0.7894736842105263, "step": 595}
{"time": 1766588106.5229998, "phase": "train", "update": 596, "total_env_steps": 1907200, "episode_reward": 0.3353959918022156, "value_loss": 0.019275479018688202, "policy_loss": -0.01265029207591913, "dist_entropy": 0.5889386097590129, "actor_grad_norm": 0.1922580450773239, "critic_grad_norm": 0.0576339066028595, "ratio": 0.9990749955177307, "entropy": 0.5889386097590129, "incre_win_rate": 0.7931034482758621, "step": 596}
{"time": 1766588111.2765915, "phase": "train", "update": 597, "total_env_steps": 1910400, "episode_reward": 0.3480859398841858, "value_loss": 0.014709370272854964, "policy_loss": -0.0118501715319231, "dist_entropy": 0.5836331566174825, "actor_grad_norm": 0.1630803644657135, "critic_grad_norm": 0.039306506514549255, "ratio": 0.9997493028640747, "entropy": 0.5836331566174825, "incre_win_rate": 0.7142857142857143, "step": 597}
{"time": 1766588115.8992503, "phase": "train", "update": 598, "total_env_steps": 1913600, "episode_reward": 0.359779417514801, "value_loss": 0.01163952872157097, "policy_loss": -0.012382582262623032, "dist_entropy": 0.5770864089330038, "actor_grad_norm": 0.15128879249095917, "critic_grad_norm": 0.021689658984541893, "ratio": 0.9990932941436768, "entropy": 0.5770864089330038, "incre_win_rate": 0.8620689655172413, "step": 598}
{"time": 1766588120.7256684, "phase": "train", "update": 599, "total_env_steps": 1916800, "episode_reward": 0.3535071909427643, "value_loss": 0.010951074150701364, "policy_loss": -0.011827725594831999, "dist_entropy": 0.594140887260437, "actor_grad_norm": 0.17135339975357056, "critic_grad_norm": 0.025138912722468376, "ratio": 0.9994292855262756, "entropy": 0.594140887260437, "incre_win_rate": 0.864406779661017, "step": 599}
{"time": 1766588125.3917382, "phase": "train", "update": 600, "total_env_steps": 1920000, "episode_reward": 0.3595312535762787, "value_loss": 0.012253837597866853, "policy_loss": -0.011467713385422466, "dist_entropy": 0.5751428961753845, "actor_grad_norm": 0.15013930201530457, "critic_grad_norm": 0.021704060956835747, "ratio": 0.9999389052391052, "entropy": 0.5751428961753845, "incre_win_rate": 0.8360655737704918, "step": 600}
{"time": 1766588130.058847, "phase": "train", "update": 601, "total_env_steps": 1923200, "episode_reward": 0.36356157064437866, "value_loss": 0.007943361469854911, "policy_loss": -0.011237980196382936, "dist_entropy": 0.5626760125160217, "actor_grad_norm": 0.14688889682292938, "critic_grad_norm": 0.022251563146710396, "ratio": 0.9982088208198547, "entropy": 0.5626760125160217, "incre_win_rate": 0.864406779661017, "step": 601}
{"time": 1766588137.170488, "phase": "eval", "update": 601, "total_env_steps": 1923200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.649509803921568, "step": 601}
{"time": 1766588141.7993388, "phase": "train", "update": 602, "total_env_steps": 1926400, "episode_reward": 0.3408854305744171, "value_loss": 0.010971983584264914, "policy_loss": -0.012658071564456938, "dist_entropy": 0.5848015069961547, "actor_grad_norm": 0.14370004832744598, "critic_grad_norm": 0.03903299942612648, "ratio": 1.0001556873321533, "entropy": 0.5848015069961547, "incre_win_rate": 0.8103448275862069, "step": 602}
{"time": 1766588146.4738464, "phase": "train", "update": 603, "total_env_steps": 1929600, "episode_reward": 0.3690831959247589, "value_loss": 0.0083932942400376, "policy_loss": -0.011011839729962484, "dist_entropy": 0.5748597145080566, "actor_grad_norm": 0.14829987287521362, "critic_grad_norm": 0.026014497503638268, "ratio": 1.0007946491241455, "entropy": 0.5748597145080566, "incre_win_rate": 0.9016393442622951, "step": 603}
{"time": 1766588151.1025393, "phase": "train", "update": 604, "total_env_steps": 1932800, "episode_reward": 0.36125996708869934, "value_loss": 0.01133833018441995, "policy_loss": -0.011468644096837958, "dist_entropy": 0.5699684739112854, "actor_grad_norm": 0.19123928248882294, "critic_grad_norm": 0.04983028396964073, "ratio": 0.9996006488800049, "entropy": 0.5699684739112854, "incre_win_rate": 0.8548387096774194, "step": 604}
{"time": 1766588155.8437881, "phase": "train", "update": 605, "total_env_steps": 1936000, "episode_reward": 0.3382016122341156, "value_loss": 0.013655100638667742, "policy_loss": -0.012040793581711758, "dist_entropy": 0.5812337160110473, "actor_grad_norm": 0.20659074187278748, "critic_grad_norm": 0.07601934671401978, "ratio": 0.9995838403701782, "entropy": 0.5812337160110473, "incre_win_rate": 0.7192982456140351, "step": 605}
{"time": 1766588160.984179, "phase": "train", "update": 606, "total_env_steps": 1939200, "episode_reward": 0.34814417362213135, "value_loss": 0.01017865768323342, "policy_loss": -0.011699286152795333, "dist_entropy": 0.5651993195215861, "actor_grad_norm": 0.18400049209594727, "critic_grad_norm": 0.034425970166921616, "ratio": 0.9998537302017212, "entropy": 0.5651993195215861, "incre_win_rate": 0.8166666666666667, "step": 606}
{"time": 1766588165.6969194, "phase": "train", "update": 607, "total_env_steps": 1942400, "episode_reward": 0.34291207790374756, "value_loss": 0.012852010813852151, "policy_loss": -0.012151551672582766, "dist_entropy": 0.6027106364568074, "actor_grad_norm": 0.14183765649795532, "critic_grad_norm": 0.027791189029812813, "ratio": 0.9996367692947388, "entropy": 0.6027106364568074, "incre_win_rate": 0.7758620689655172, "step": 607}
{"time": 1766588170.5264475, "phase": "train", "update": 608, "total_env_steps": 1945600, "episode_reward": 0.3675612807273865, "value_loss": 0.007030778347204129, "policy_loss": -0.011866676406639638, "dist_entropy": 0.5962902863820394, "actor_grad_norm": 0.1513863205909729, "critic_grad_norm": 0.09615828096866608, "ratio": 0.9994452595710754, "entropy": 0.5962902863820394, "incre_win_rate": 0.9322033898305084, "step": 608}
{"time": 1766588175.2516913, "phase": "train", "update": 609, "total_env_steps": 1948800, "episode_reward": 0.3546982407569885, "value_loss": 0.010236569990714392, "policy_loss": -0.010422465666749758, "dist_entropy": 0.5829951922098796, "actor_grad_norm": 0.16916994750499725, "critic_grad_norm": 0.044153615832328796, "ratio": 0.999733030796051, "entropy": 0.5829951922098796, "incre_win_rate": 0.85, "step": 609}
{"time": 1766588180.0200043, "phase": "train", "update": 610, "total_env_steps": 1952000, "episode_reward": 0.3625582158565521, "value_loss": 0.00598396472632885, "policy_loss": -0.010875131247773239, "dist_entropy": 0.6047258575757345, "actor_grad_norm": 0.1470976173877716, "critic_grad_norm": 0.032048799097537994, "ratio": 0.9996844530105591, "entropy": 0.6047258575757345, "incre_win_rate": 0.9491525423728814, "step": 610}
{"time": 1766588185.823227, "phase": "train", "update": 611, "total_env_steps": 1955200, "episode_reward": 0.3561611771583557, "value_loss": 0.010435797708729903, "policy_loss": -0.012701393023192035, "dist_entropy": 0.6009668191274007, "actor_grad_norm": 0.17037954926490784, "critic_grad_norm": 0.07851967215538025, "ratio": 1.000416874885559, "entropy": 0.6009668191274007, "incre_win_rate": 0.8813559322033898, "step": 611}
{"time": 1766588191.438071, "phase": "train", "update": 612, "total_env_steps": 1958400, "episode_reward": 0.3516421616077423, "value_loss": 0.009564016573131084, "policy_loss": -0.011833565164415442, "dist_entropy": 0.5970390200614929, "actor_grad_norm": 0.16402482986450195, "critic_grad_norm": 0.02352234162390232, "ratio": 1.0006296634674072, "entropy": 0.5970390200614929, "incre_win_rate": 0.8793103448275862, "step": 612}
{"time": 1766588195.9693758, "phase": "train", "update": 613, "total_env_steps": 1961600, "episode_reward": 0.3640173375606537, "value_loss": 0.008857019059360028, "policy_loss": -0.011406482055757146, "dist_entropy": 0.5879144867261251, "actor_grad_norm": 0.16900889575481415, "critic_grad_norm": 0.029018908739089966, "ratio": 1.0002877712249756, "entropy": 0.5879144867261251, "incre_win_rate": 0.8852459016393442, "step": 613}
{"time": 1766588200.7081563, "phase": "train", "update": 614, "total_env_steps": 1964800, "episode_reward": 0.3598904609680176, "value_loss": 0.007243118031571309, "policy_loss": -0.011538882555224934, "dist_entropy": 0.6207463383674622, "actor_grad_norm": 0.1538204699754715, "critic_grad_norm": 0.02972087450325489, "ratio": 0.9989823698997498, "entropy": 0.6207463383674622, "incre_win_rate": 0.9310344827586207, "step": 614}
{"time": 1766588205.3657935, "phase": "train", "update": 615, "total_env_steps": 1968000, "episode_reward": 0.35968905687332153, "value_loss": 0.007626550582547982, "policy_loss": -0.011827534823578864, "dist_entropy": 0.6030216137568156, "actor_grad_norm": 0.1649315059185028, "critic_grad_norm": 0.018855508416891098, "ratio": 0.9998424053192139, "entropy": 0.6030216137568156, "incre_win_rate": 0.8833333333333333, "step": 615}
{"time": 1766588209.9040294, "phase": "train", "update": 616, "total_env_steps": 1971200, "episode_reward": 0.3510914742946625, "value_loss": 0.012217311809460321, "policy_loss": -0.011045240945137872, "dist_entropy": 0.6067672411600749, "actor_grad_norm": 0.16220280528068542, "critic_grad_norm": 0.06181621178984642, "ratio": 0.9984774589538574, "entropy": 0.6067672411600749, "incre_win_rate": 0.8135593220338984, "step": 616}
{"time": 1766588214.4126787, "phase": "train", "update": 617, "total_env_steps": 1974400, "episode_reward": 0.3553936779499054, "value_loss": 0.010597371372083823, "policy_loss": -0.011540472315804113, "dist_entropy": 0.6070521036783855, "actor_grad_norm": 0.1624678671360016, "critic_grad_norm": 0.017175668850541115, "ratio": 1.000327706336975, "entropy": 0.6070521036783855, "incre_win_rate": 0.8333333333333334, "step": 617}
{"time": 1766588219.028586, "phase": "train", "update": 618, "total_env_steps": 1977600, "episode_reward": 0.356681227684021, "value_loss": 0.008794570652147135, "policy_loss": -0.012100430289032182, "dist_entropy": 0.603777817885081, "actor_grad_norm": 0.1524450182914734, "critic_grad_norm": 0.032484862953424454, "ratio": 1.0001957416534424, "entropy": 0.603777817885081, "incre_win_rate": 0.8360655737704918, "step": 618}
{"time": 1766588223.5174885, "phase": "train", "update": 619, "total_env_steps": 1980800, "episode_reward": 0.34520983695983887, "value_loss": 0.009875067758063476, "policy_loss": -0.011631010914486239, "dist_entropy": 0.5975459019343058, "actor_grad_norm": 0.2056737244129181, "critic_grad_norm": 0.05135047808289528, "ratio": 1.0006746053695679, "entropy": 0.5975459019343058, "incre_win_rate": 0.8035714285714286, "step": 619}
{"time": 1766588228.0533001, "phase": "train", "update": 620, "total_env_steps": 1984000, "episode_reward": 0.3561650216579437, "value_loss": 0.010174794246753056, "policy_loss": -0.011165590541029028, "dist_entropy": 0.5942009528477986, "actor_grad_norm": 0.1756974309682846, "critic_grad_norm": 0.049456775188446045, "ratio": 0.999862551689148, "entropy": 0.5942009528477986, "incre_win_rate": 0.8983050847457628, "step": 620}
{"time": 1766588232.4941747, "phase": "train", "update": 621, "total_env_steps": 1987200, "episode_reward": 0.3487361967563629, "value_loss": 0.011927579094966253, "policy_loss": -0.010050209681250049, "dist_entropy": 0.6171207825342814, "actor_grad_norm": 0.1265757828950882, "critic_grad_norm": 0.046795353293418884, "ratio": 0.9993541836738586, "entropy": 0.6171207825342814, "incre_win_rate": 0.85, "step": 621}
{"time": 1766588239.7940798, "phase": "eval", "update": 621, "total_env_steps": 1987200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.774509803921568, "step": 621}
{"time": 1766588244.5061858, "phase": "train", "update": 622, "total_env_steps": 1990400, "episode_reward": 0.35467296838760376, "value_loss": 0.009224958096941313, "policy_loss": -0.010899328960433744, "dist_entropy": 0.6086788733800252, "actor_grad_norm": 0.1484711617231369, "critic_grad_norm": 0.030845882371068, "ratio": 0.9999152421951294, "entropy": 0.6086788733800252, "incre_win_rate": 0.864406779661017, "step": 622}
{"time": 1766588249.3479502, "phase": "train", "update": 623, "total_env_steps": 1993600, "episode_reward": 0.34332340955734253, "value_loss": 0.011205688863992692, "policy_loss": -0.012256068908969553, "dist_entropy": 0.6207115809122722, "actor_grad_norm": 0.18419557809829712, "critic_grad_norm": 0.022296501323580742, "ratio": 0.9987998604774475, "entropy": 0.6207115809122722, "incre_win_rate": 0.7857142857142857, "step": 623}
{"time": 1766588254.0828938, "phase": "train", "update": 624, "total_env_steps": 1996800, "episode_reward": 0.3638955056667328, "value_loss": 0.009865281855066617, "policy_loss": -0.012114364203580053, "dist_entropy": 0.6125176787376404, "actor_grad_norm": 0.2165193259716034, "critic_grad_norm": 0.015554090961813927, "ratio": 0.9997312426567078, "entropy": 0.6125176787376404, "incre_win_rate": 0.8709677419354839, "step": 624}
{"time": 1766588258.5990036, "phase": "train", "update": 625, "total_env_steps": 2000000, "episode_reward": 0.35998010635375977, "value_loss": 0.010146397165954113, "policy_loss": -0.011822487419416442, "dist_entropy": 0.6004513104756674, "actor_grad_norm": 0.14170534908771515, "critic_grad_norm": 0.022537436336278915, "ratio": 0.9993088841438293, "entropy": 0.6004513104756674, "incre_win_rate": 0.847457627118644, "step": 625}
{"time": 1766588263.0807788, "phase": "train", "update": 626, "total_env_steps": 2003200, "episode_reward": 0.3711412250995636, "value_loss": 0.007666192545245091, "policy_loss": -0.010803842845187242, "dist_entropy": 0.5933984001477559, "actor_grad_norm": 0.16009417176246643, "critic_grad_norm": 0.031051892787218094, "ratio": 0.9994483590126038, "entropy": 0.5933984001477559, "incre_win_rate": 0.9193548387096774, "step": 626}
{"time": 1766588267.5439644, "phase": "train", "update": 627, "total_env_steps": 2006400, "episode_reward": 0.35717523097991943, "value_loss": 0.010650391938785713, "policy_loss": -0.011727961137115035, "dist_entropy": 0.6115293502807617, "actor_grad_norm": 0.15331952273845673, "critic_grad_norm": 0.03707584738731384, "ratio": 0.9985743165016174, "entropy": 0.6115293502807617, "incre_win_rate": 0.7868852459016393, "step": 627}
{"time": 1766588272.2355835, "phase": "train", "update": 628, "total_env_steps": 2009600, "episode_reward": 0.3534949719905853, "value_loss": 0.012426232111950715, "policy_loss": -0.012428509622179718, "dist_entropy": 0.5970595518747965, "actor_grad_norm": 0.14538809657096863, "critic_grad_norm": 0.05066027119755745, "ratio": 0.9997671246528625, "entropy": 0.5970595518747965, "incre_win_rate": 0.8103448275862069, "step": 628}
{"time": 1766588276.6988442, "phase": "train", "update": 629, "total_env_steps": 2012800, "episode_reward": 0.352283239364624, "value_loss": 0.015223914757370949, "policy_loss": -0.01202859925739593, "dist_entropy": 0.6002782583236694, "actor_grad_norm": 0.14508941769599915, "critic_grad_norm": 0.0383477658033371, "ratio": 0.9992589950561523, "entropy": 0.6002782583236694, "incre_win_rate": 0.7868852459016393, "step": 629}
{"time": 1766588281.3141203, "phase": "train", "update": 630, "total_env_steps": 2016000, "episode_reward": 0.3570266664028168, "value_loss": 0.010862376106282075, "policy_loss": -0.01170667319333063, "dist_entropy": 0.6010679125785827, "actor_grad_norm": 0.14254522323608398, "critic_grad_norm": 0.04562346637248993, "ratio": 0.9995436668395996, "entropy": 0.6010679125785827, "incre_win_rate": 0.8813559322033898, "step": 630}
{"time": 1766588285.892775, "phase": "train", "update": 631, "total_env_steps": 2019200, "episode_reward": 0.3536703586578369, "value_loss": 0.009543262359996637, "policy_loss": -0.011363506889241155, "dist_entropy": 0.6314924558003744, "actor_grad_norm": 0.13450895249843597, "critic_grad_norm": 0.045348841696977615, "ratio": 0.9990313649177551, "entropy": 0.6314924558003744, "incre_win_rate": 0.8620689655172413, "step": 631}
{"time": 1766588290.584524, "phase": "train", "update": 632, "total_env_steps": 2022400, "episode_reward": 0.34415289759635925, "value_loss": 0.012411325921614964, "policy_loss": -0.012315534706139412, "dist_entropy": 0.6107739488283793, "actor_grad_norm": 0.1812000274658203, "critic_grad_norm": 0.059812430292367935, "ratio": 0.9986122250556946, "entropy": 0.6107739488283793, "incre_win_rate": 0.75, "step": 632}
{"time": 1766588295.0512865, "phase": "train", "update": 633, "total_env_steps": 2025600, "episode_reward": 0.3512032628059387, "value_loss": 0.01310783065855503, "policy_loss": -0.01262049143583918, "dist_entropy": 0.612002428372701, "actor_grad_norm": 0.20108367502689362, "critic_grad_norm": 0.03262219950556755, "ratio": 0.9986264705657959, "entropy": 0.612002428372701, "incre_win_rate": 0.8135593220338984, "step": 633}
{"time": 1766588299.5600815, "phase": "train", "update": 634, "total_env_steps": 2028800, "episode_reward": 0.3573399484157562, "value_loss": 0.011416254503031572, "policy_loss": -0.012542152143543699, "dist_entropy": 0.6164440075556438, "actor_grad_norm": 0.18177132308483124, "critic_grad_norm": 0.04313395917415619, "ratio": 0.9998943209648132, "entropy": 0.6164440075556438, "incre_win_rate": 0.8524590163934426, "step": 634}
{"time": 1766588304.2045588, "phase": "train", "update": 635, "total_env_steps": 2032000, "episode_reward": 0.34846124053001404, "value_loss": 0.015052266232669354, "policy_loss": -0.011894133361998153, "dist_entropy": 0.6167982538541158, "actor_grad_norm": 0.1718098372220993, "critic_grad_norm": 0.054005544632673264, "ratio": 0.9999966025352478, "entropy": 0.6167982538541158, "incre_win_rate": 0.75, "step": 635}
{"time": 1766588308.721413, "phase": "train", "update": 636, "total_env_steps": 2035200, "episode_reward": 0.342561274766922, "value_loss": 0.017826351275046667, "policy_loss": -0.012319055655690173, "dist_entropy": 0.6043946027755738, "actor_grad_norm": 0.14887146651744843, "critic_grad_norm": 0.08533032983541489, "ratio": 0.9993847608566284, "entropy": 0.6043946027755738, "incre_win_rate": 0.7413793103448276, "step": 636}
{"time": 1766588313.5692308, "phase": "train", "update": 637, "total_env_steps": 2038400, "episode_reward": 0.35433825850486755, "value_loss": 0.012416187301278114, "policy_loss": -0.012235840032940834, "dist_entropy": 0.6104087750116984, "actor_grad_norm": 0.17008250951766968, "critic_grad_norm": 0.03556383401155472, "ratio": 0.9987376928329468, "entropy": 0.6104087750116984, "incre_win_rate": 0.7966101694915254, "step": 637}
{"time": 1766588318.078861, "phase": "train", "update": 638, "total_env_steps": 2041600, "episode_reward": 0.3524172902107239, "value_loss": 0.01304447501897812, "policy_loss": -0.01207775663968628, "dist_entropy": 0.6193168719609579, "actor_grad_norm": 0.16590505838394165, "critic_grad_norm": 0.018019231036305428, "ratio": 0.9993190169334412, "entropy": 0.6193168719609579, "incre_win_rate": 0.8064516129032258, "step": 638}
{"time": 1766588322.4567485, "phase": "train", "update": 639, "total_env_steps": 2044800, "episode_reward": 0.34901806712150574, "value_loss": 0.012473200013240178, "policy_loss": -0.011935851504029907, "dist_entropy": 0.6168483416239421, "actor_grad_norm": 0.1647244244813919, "critic_grad_norm": 0.029339727014303207, "ratio": 0.9988737106323242, "entropy": 0.6168483416239421, "incre_win_rate": 0.8070175438596491, "step": 639}
{"time": 1766588327.0023265, "phase": "train", "update": 640, "total_env_steps": 2048000, "episode_reward": 0.3454281687736511, "value_loss": 0.011761756738026936, "policy_loss": -0.012685977345557356, "dist_entropy": 0.6187956730524699, "actor_grad_norm": 0.1858435720205307, "critic_grad_norm": 0.02555720880627632, "ratio": 0.9986143112182617, "entropy": 0.6187956730524699, "incre_win_rate": 0.8103448275862069, "step": 640}
{"time": 1766588331.5871913, "phase": "train", "update": 641, "total_env_steps": 2051200, "episode_reward": 0.35240423679351807, "value_loss": 0.013562838236490885, "policy_loss": -0.012204308998772718, "dist_entropy": 0.6147959709167481, "actor_grad_norm": 0.1730797439813614, "critic_grad_norm": 0.015092027373611927, "ratio": 0.9994655847549438, "entropy": 0.6147959709167481, "incre_win_rate": 0.7903225806451613, "step": 641}
{"time": 1766588338.6113973, "phase": "eval", "update": 641, "total_env_steps": 2051200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.477941176470587, "step": 641}
{"time": 1766588343.0304708, "phase": "train", "update": 642, "total_env_steps": 2054400, "episode_reward": 0.3549548387527466, "value_loss": 0.011322019807994365, "policy_loss": -0.012610161219445597, "dist_entropy": 0.6080656528472901, "actor_grad_norm": 0.16450265049934387, "critic_grad_norm": 0.015924064442515373, "ratio": 0.9997701048851013, "entropy": 0.6080656528472901, "incre_win_rate": 0.8275862068965517, "step": 642}
{"time": 1766588347.5888722, "phase": "train", "update": 643, "total_env_steps": 2057600, "episode_reward": 0.35573530197143555, "value_loss": 0.011830252036452294, "policy_loss": -0.011707161186685274, "dist_entropy": 0.5919747988382975, "actor_grad_norm": 0.16258470714092255, "critic_grad_norm": 0.029897378757596016, "ratio": 0.9986873269081116, "entropy": 0.5919747988382975, "incre_win_rate": 0.8360655737704918, "step": 643}
{"time": 1766588352.2455, "phase": "train", "update": 644, "total_env_steps": 2060800, "episode_reward": 0.3631449043750763, "value_loss": 0.012875745880107085, "policy_loss": -0.01170760198442693, "dist_entropy": 0.5784841020901997, "actor_grad_norm": 0.15109391510486603, "critic_grad_norm": 0.025209622457623482, "ratio": 0.9996146559715271, "entropy": 0.5784841020901997, "incre_win_rate": 0.8166666666666667, "step": 644}
{"time": 1766588356.6662858, "phase": "train", "update": 645, "total_env_steps": 2064000, "episode_reward": 0.3494071662425995, "value_loss": 0.010347399984796841, "policy_loss": -0.011212453303341736, "dist_entropy": 0.598316470781962, "actor_grad_norm": 0.1777103692293167, "critic_grad_norm": 0.01330613624304533, "ratio": 1.000235915184021, "entropy": 0.598316470781962, "incre_win_rate": 0.85, "step": 645}
{"time": 1766588361.2911425, "phase": "train", "update": 646, "total_env_steps": 2067200, "episode_reward": 0.36662837862968445, "value_loss": 0.010923372519512971, "policy_loss": -0.01074841342768309, "dist_entropy": 0.5768298586209615, "actor_grad_norm": 0.16065068542957306, "critic_grad_norm": 0.044773440808057785, "ratio": 1.0003583431243896, "entropy": 0.5768298586209615, "incre_win_rate": 0.8983050847457628, "step": 646}
{"time": 1766588365.7691498, "phase": "train", "update": 647, "total_env_steps": 2070400, "episode_reward": 0.35710862278938293, "value_loss": 0.00813896826778849, "policy_loss": -0.01179878908514335, "dist_entropy": 0.5890201846758525, "actor_grad_norm": 0.1710284948348999, "critic_grad_norm": 0.044294245541095734, "ratio": 0.999643862247467, "entropy": 0.5890201846758525, "incre_win_rate": 0.8524590163934426, "step": 647}
{"time": 1766588370.2343476, "phase": "train", "update": 648, "total_env_steps": 2073600, "episode_reward": 0.36187273263931274, "value_loss": 0.010327742124597231, "policy_loss": -0.011237697080893365, "dist_entropy": 0.5818244496981303, "actor_grad_norm": 0.14019675552845, "critic_grad_norm": 0.02989252656698227, "ratio": 0.9988211989402771, "entropy": 0.5818244496981303, "incre_win_rate": 0.85, "step": 648}
{"time": 1766588374.6443744, "phase": "train", "update": 649, "total_env_steps": 2076800, "episode_reward": 0.3684084117412567, "value_loss": 0.00811390442152818, "policy_loss": -0.012139968142522642, "dist_entropy": 0.5845253626505534, "actor_grad_norm": 0.1602800041437149, "critic_grad_norm": 0.022798364982008934, "ratio": 1.0002995729446411, "entropy": 0.5845253626505534, "incre_win_rate": 0.8852459016393442, "step": 649}
{"time": 1766588379.0524855, "phase": "train", "update": 650, "total_env_steps": 2080000, "episode_reward": 0.3467922806739807, "value_loss": 0.013118186096350352, "policy_loss": -0.012803011898359232, "dist_entropy": 0.5845094720522562, "actor_grad_norm": 0.2273140251636505, "critic_grad_norm": 0.06167694181203842, "ratio": 0.9994814395904541, "entropy": 0.5845094720522562, "incre_win_rate": 0.7457627118644068, "step": 650}
{"time": 1766588383.4780812, "phase": "train", "update": 651, "total_env_steps": 2083200, "episode_reward": 0.3734903633594513, "value_loss": 0.006472532451152801, "policy_loss": -0.011946824827250424, "dist_entropy": 0.5768635829289754, "actor_grad_norm": 0.16072537004947662, "critic_grad_norm": 0.050406984984874725, "ratio": 0.9999549984931946, "entropy": 0.5768635829289754, "incre_win_rate": 0.9344262295081968, "step": 651}
{"time": 1766588387.9070466, "phase": "train", "update": 652, "total_env_steps": 2086400, "episode_reward": 0.3652481734752655, "value_loss": 0.010084962534407774, "policy_loss": -0.012128140535331393, "dist_entropy": 0.5648726304372151, "actor_grad_norm": 0.1502976268529892, "critic_grad_norm": 0.045179583132267, "ratio": 1.0008665323257446, "entropy": 0.5648726304372151, "incre_win_rate": 0.8333333333333334, "step": 652}
{"time": 1766588418.029633, "phase": "train", "update": 653, "total_env_steps": 2089600, "episode_reward": 0.35813573002815247, "value_loss": 0.060113026201725005, "policy_loss": -0.009551250000062813, "dist_entropy": 0.5823886156082153, "actor_grad_norm": 0.12213993817567825, "critic_grad_norm": 0.13783010840415955, "ratio": 1.0007423162460327, "entropy": 0.5823886156082153, "incre_win_rate": 0.8333333333333334, "step": 653}
{"time": 1766588422.465686, "phase": "train", "update": 654, "total_env_steps": 2092800, "episode_reward": 0.3667716085910797, "value_loss": 0.009430486833055814, "policy_loss": -0.010892293096806801, "dist_entropy": 0.5718367497126261, "actor_grad_norm": 0.17719562351703644, "critic_grad_norm": 0.0353553369641304, "ratio": 0.9994120597839355, "entropy": 0.5718367497126261, "incre_win_rate": 0.8360655737704918, "step": 654}
{"time": 1766588426.935535, "phase": "train", "update": 655, "total_env_steps": 2096000, "episode_reward": 0.3598989248275757, "value_loss": 0.015051036638518174, "policy_loss": -0.011007541336056192, "dist_entropy": 0.5684629599253337, "actor_grad_norm": 0.15599915385246277, "critic_grad_norm": 0.09845046699047089, "ratio": 1.0004408359527588, "entropy": 0.5684629599253337, "incre_win_rate": 0.7796610169491526, "step": 655}
{"time": 1766588431.3960152, "phase": "train", "update": 656, "total_env_steps": 2099200, "episode_reward": 0.35975492000579834, "value_loss": 0.01488866719106833, "policy_loss": -0.011623862602588748, "dist_entropy": 0.5734117507934571, "actor_grad_norm": 0.14915603399276733, "critic_grad_norm": 0.04529622569680214, "ratio": 1.0002237558364868, "entropy": 0.5734117507934571, "incre_win_rate": 0.796875, "step": 656}
{"time": 1766588436.0087655, "phase": "train", "update": 657, "total_env_steps": 2102400, "episode_reward": 0.3556043207645416, "value_loss": 0.013048181496560573, "policy_loss": -0.011715638507357557, "dist_entropy": 0.5888771653175354, "actor_grad_norm": 0.13292096555233002, "critic_grad_norm": 0.03347159922122955, "ratio": 0.9988863468170166, "entropy": 0.5888771653175354, "incre_win_rate": 0.8070175438596491, "step": 657}
{"time": 1766588440.386066, "phase": "train", "update": 658, "total_env_steps": 2105600, "episode_reward": 0.36697840690612793, "value_loss": 0.00987281147390604, "policy_loss": -0.01078055007256277, "dist_entropy": 0.5800243179003398, "actor_grad_norm": 0.13664929568767548, "critic_grad_norm": 0.02645542100071907, "ratio": 0.9995629787445068, "entropy": 0.5800243179003398, "incre_win_rate": 0.859375, "step": 658}
{"time": 1766588444.8747385, "phase": "train", "update": 659, "total_env_steps": 2108800, "episode_reward": 0.36519455909729004, "value_loss": 0.009949244248370329, "policy_loss": -0.011748241857668517, "dist_entropy": 0.5810311714808146, "actor_grad_norm": 0.14874424040317535, "critic_grad_norm": 0.046137914061546326, "ratio": 0.9995431900024414, "entropy": 0.5810311714808146, "incre_win_rate": 0.864406779661017, "step": 659}
{"time": 1766588449.390337, "phase": "train", "update": 660, "total_env_steps": 2112000, "episode_reward": 0.3686588704586029, "value_loss": 0.0054325684905052185, "policy_loss": -0.011125955852268514, "dist_entropy": 0.5735889832178752, "actor_grad_norm": 0.2023051530122757, "critic_grad_norm": 0.047902911901474, "ratio": 0.9990442395210266, "entropy": 0.5735889832178752, "incre_win_rate": 0.9344262295081968, "step": 660}
{"time": 1766588453.847775, "phase": "train", "update": 661, "total_env_steps": 2115200, "episode_reward": 0.3614974021911621, "value_loss": 0.013293916111191113, "policy_loss": -0.011980841672226461, "dist_entropy": 0.5767154932022095, "actor_grad_norm": 0.16311459243297577, "critic_grad_norm": 0.1113346666097641, "ratio": 1.0002076625823975, "entropy": 0.5767154932022095, "incre_win_rate": 0.8032786885245902, "step": 661}
{"time": 1766588460.7902014, "phase": "eval", "update": 661, "total_env_steps": 2115200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.70343137254902, "step": 661}
{"time": 1766588465.2508996, "phase": "train", "update": 662, "total_env_steps": 2118400, "episode_reward": 0.35867875814437866, "value_loss": 0.010268014421065648, "policy_loss": -0.0118233957380113, "dist_entropy": 0.5961258292198182, "actor_grad_norm": 0.1675211489200592, "critic_grad_norm": 0.05607449635863304, "ratio": 0.9997004270553589, "entropy": 0.5961258292198182, "incre_win_rate": 0.7868852459016393, "step": 662}
{"time": 1766588469.6771827, "phase": "train", "update": 663, "total_env_steps": 2121600, "episode_reward": 0.36935433745384216, "value_loss": 0.008917158531645934, "policy_loss": -0.011439688371502162, "dist_entropy": 0.6193639437357584, "actor_grad_norm": 0.18333804607391357, "critic_grad_norm": 0.05237150937318802, "ratio": 0.9997402429580688, "entropy": 0.6193639437357584, "incre_win_rate": 0.9016393442622951, "step": 663}
{"time": 1766588474.0917213, "phase": "train", "update": 664, "total_env_steps": 2124800, "episode_reward": 0.3707881569862366, "value_loss": 0.006983110370735328, "policy_loss": -0.011170147624342045, "dist_entropy": 0.6003624161084493, "actor_grad_norm": 0.15969009697437286, "critic_grad_norm": 0.03195175155997276, "ratio": 0.999860942363739, "entropy": 0.6003624161084493, "incre_win_rate": 0.8833333333333333, "step": 664}
{"time": 1766588478.5055819, "phase": "train", "update": 665, "total_env_steps": 2128000, "episode_reward": 0.3643956780433655, "value_loss": 0.016867101813356083, "policy_loss": -0.01208648685402475, "dist_entropy": 0.5964900096257527, "actor_grad_norm": 0.1502535194158554, "critic_grad_norm": 0.04978463798761368, "ratio": 1.000931978225708, "entropy": 0.5964900096257527, "incre_win_rate": 0.8253968253968254, "step": 665}
{"time": 1766588483.0527668, "phase": "train", "update": 666, "total_env_steps": 2131200, "episode_reward": 0.35314416885375977, "value_loss": 0.010737260493139425, "policy_loss": -0.012250007461921323, "dist_entropy": 0.6098266879717509, "actor_grad_norm": 0.1535089612007141, "critic_grad_norm": 0.04373141750693321, "ratio": 0.9992654919624329, "entropy": 0.6098266879717509, "incre_win_rate": 0.7796610169491526, "step": 666}
{"time": 1766588487.5095594, "phase": "train", "update": 667, "total_env_steps": 2134400, "episode_reward": 0.3647304177284241, "value_loss": 0.010295026376843453, "policy_loss": -0.01217142008509408, "dist_entropy": 0.6006556987762451, "actor_grad_norm": 0.17772656679153442, "critic_grad_norm": 0.04081157222390175, "ratio": 1.0008169412612915, "entropy": 0.6006556987762451, "incre_win_rate": 0.8548387096774194, "step": 667}
{"time": 1766588491.9303567, "phase": "train", "update": 668, "total_env_steps": 2137600, "episode_reward": 0.3573307394981384, "value_loss": 0.009692621355255445, "policy_loss": -0.012179187747184095, "dist_entropy": 0.5982468962669373, "actor_grad_norm": 0.14860065281391144, "critic_grad_norm": 0.017586812376976013, "ratio": 0.9996852278709412, "entropy": 0.5982468962669373, "incre_win_rate": 0.8793103448275862, "step": 668}
{"time": 1766588496.6463788, "phase": "train", "update": 669, "total_env_steps": 2140800, "episode_reward": 0.37146833539009094, "value_loss": 0.0069929032276074094, "policy_loss": -0.011400388149128086, "dist_entropy": 0.6011294921239217, "actor_grad_norm": 0.14808982610702515, "critic_grad_norm": 0.02366606891155243, "ratio": 0.9996895790100098, "entropy": 0.6011294921239217, "incre_win_rate": 0.8870967741935484, "step": 669}
{"time": 1766588501.8320827, "phase": "train", "update": 670, "total_env_steps": 2144000, "episode_reward": 0.3630070388317108, "value_loss": 0.010083959810435772, "policy_loss": -0.011815837715219383, "dist_entropy": 0.5984500845273336, "actor_grad_norm": 0.16703562438488007, "critic_grad_norm": 0.04375103861093521, "ratio": 0.9999560713768005, "entropy": 0.5984500845273336, "incre_win_rate": 0.8387096774193549, "step": 670}
{"time": 1766588507.2015913, "phase": "train", "update": 671, "total_env_steps": 2147200, "episode_reward": 0.35568931698799133, "value_loss": 0.010170516061286132, "policy_loss": -0.01189364171488639, "dist_entropy": 0.6004458944002787, "actor_grad_norm": 0.1450173556804657, "critic_grad_norm": 0.04622918739914894, "ratio": 0.9995156526565552, "entropy": 0.6004458944002787, "incre_win_rate": 0.75, "step": 671}
{"time": 1766588512.3293953, "phase": "train", "update": 672, "total_env_steps": 2150400, "episode_reward": 0.3553561568260193, "value_loss": 0.010406382195651532, "policy_loss": -0.0125561112568775, "dist_entropy": 0.6009149034818013, "actor_grad_norm": 0.18831928074359894, "critic_grad_norm": 0.020898284390568733, "ratio": 0.9998060464859009, "entropy": 0.6009149034818013, "incre_win_rate": 0.8, "step": 672}
{"time": 1766588517.161647, "phase": "train", "update": 673, "total_env_steps": 2153600, "episode_reward": 0.3642524480819702, "value_loss": 0.008728592470288277, "policy_loss": -0.01196560950171488, "dist_entropy": 0.6041409452756246, "actor_grad_norm": 0.15462389588356018, "critic_grad_norm": 0.017382031306624413, "ratio": 0.998291015625, "entropy": 0.6041409452756246, "incre_win_rate": 0.8524590163934426, "step": 673}
{"time": 1766588522.254017, "phase": "train", "update": 674, "total_env_steps": 2156800, "episode_reward": 0.34853246808052063, "value_loss": 0.00963400478164355, "policy_loss": -0.011776386212645207, "dist_entropy": 0.6061231255531311, "actor_grad_norm": 0.15540960431098938, "critic_grad_norm": 0.01861465349793434, "ratio": 0.9994720220565796, "entropy": 0.6061231255531311, "incre_win_rate": 0.8275862068965517, "step": 674}
{"time": 1766588528.4286087, "phase": "train", "update": 675, "total_env_steps": 2160000, "episode_reward": 0.3647150993347168, "value_loss": 0.010186047603686651, "policy_loss": -0.012197547739848128, "dist_entropy": 0.6114013115564982, "actor_grad_norm": 0.15965776145458221, "critic_grad_norm": 0.021622613072395325, "ratio": 0.9998467564582825, "entropy": 0.6114013115564982, "incre_win_rate": 0.8666666666666667, "step": 675}
{"time": 1766588534.4178672, "phase": "train", "update": 676, "total_env_steps": 2163200, "episode_reward": 0.3612101674079895, "value_loss": 0.008927367813885211, "policy_loss": -0.011792179685209684, "dist_entropy": 0.6204954743385315, "actor_grad_norm": 0.15762858092784882, "critic_grad_norm": 0.05005080997943878, "ratio": 0.9987308979034424, "entropy": 0.6204954743385315, "incre_win_rate": 0.8709677419354839, "step": 676}
{"time": 1766588540.0129206, "phase": "train", "update": 677, "total_env_steps": 2166400, "episode_reward": 0.3649556040763855, "value_loss": 0.00980875144402186, "policy_loss": -0.012709917552525478, "dist_entropy": 0.63003884156545, "actor_grad_norm": 0.14502796530723572, "critic_grad_norm": 0.02314758114516735, "ratio": 0.9997437000274658, "entropy": 0.63003884156545, "incre_win_rate": 0.8813559322033898, "step": 677}
{"time": 1766588544.8829677, "phase": "train", "update": 678, "total_env_steps": 2169600, "episode_reward": 0.3566804528236389, "value_loss": 0.009058711926142375, "policy_loss": -0.012545653993475034, "dist_entropy": 0.626997180779775, "actor_grad_norm": 0.17226114869117737, "critic_grad_norm": 0.012740479782223701, "ratio": 0.9988991022109985, "entropy": 0.626997180779775, "incre_win_rate": 0.819672131147541, "step": 678}
{"time": 1766588549.6096678, "phase": "train", "update": 679, "total_env_steps": 2172800, "episode_reward": 0.34935125708580017, "value_loss": 0.010519101346532504, "policy_loss": -0.013012513972505958, "dist_entropy": 0.6193274219830831, "actor_grad_norm": 0.18265485763549805, "critic_grad_norm": 0.06068558990955353, "ratio": 0.9997301697731018, "entropy": 0.6193274219830831, "incre_win_rate": 0.8070175438596491, "step": 679}
{"time": 1766588554.415421, "phase": "train", "update": 680, "total_env_steps": 2176000, "episode_reward": 0.36263787746429443, "value_loss": 0.010873508142928283, "policy_loss": -0.01271338072970991, "dist_entropy": 0.6164186557133993, "actor_grad_norm": 0.17112664878368378, "critic_grad_norm": 0.022522471845149994, "ratio": 0.9998729228973389, "entropy": 0.6164186557133993, "incre_win_rate": 0.8387096774193549, "step": 680}
{"time": 1766588559.1906562, "phase": "train", "update": 681, "total_env_steps": 2179200, "episode_reward": 0.3516252934932709, "value_loss": 0.010760268941521645, "policy_loss": -0.012107017341128313, "dist_entropy": 0.616174574693044, "actor_grad_norm": 0.16756880283355713, "critic_grad_norm": 0.020094046369194984, "ratio": 1.000530481338501, "entropy": 0.616174574693044, "incre_win_rate": 0.8166666666666667, "step": 681}
{"time": 1766588566.2679732, "phase": "eval", "update": 681, "total_env_steps": 2179200, "eval_win_rate": 1.0, "eval_episode_reward": 20.004442401960784, "step": 681}
{"time": 1766588570.8725414, "phase": "train", "update": 682, "total_env_steps": 2182400, "episode_reward": 0.34732457995414734, "value_loss": 0.01093971071143945, "policy_loss": -0.012687345850059728, "dist_entropy": 0.6278174559275309, "actor_grad_norm": 0.14737454056739807, "critic_grad_norm": 0.020369233563542366, "ratio": 0.9990334510803223, "entropy": 0.6278174559275309, "incre_win_rate": 0.7758620689655172, "step": 682}
{"time": 1766588575.6612148, "phase": "train", "update": 683, "total_env_steps": 2185600, "episode_reward": 0.3656013011932373, "value_loss": 0.0062782193534076216, "policy_loss": -0.012492661968733406, "dist_entropy": 0.645352856318156, "actor_grad_norm": 0.16602423787117004, "critic_grad_norm": 0.046271439641714096, "ratio": 0.9985437989234924, "entropy": 0.645352856318156, "incre_win_rate": 0.9032258064516129, "step": 683}
{"time": 1766588580.3571682, "phase": "train", "update": 684, "total_env_steps": 2188800, "episode_reward": 0.36026424169540405, "value_loss": 0.011516295497616132, "policy_loss": -0.012756249491446426, "dist_entropy": 0.6141330560048421, "actor_grad_norm": 0.1412149965763092, "critic_grad_norm": 0.0253573190420866, "ratio": 0.9997217655181885, "entropy": 0.6141330560048421, "incre_win_rate": 0.8620689655172413, "step": 684}
{"time": 1766588584.985132, "phase": "train", "update": 685, "total_env_steps": 2192000, "episode_reward": 0.3479235768318176, "value_loss": 0.009023117398222287, "policy_loss": -0.011553765647729601, "dist_entropy": 0.6235626896222433, "actor_grad_norm": 0.17838141322135925, "critic_grad_norm": 0.013789470307528973, "ratio": 1.0004427433013916, "entropy": 0.6235626896222433, "incre_win_rate": 0.8135593220338984, "step": 685}
{"time": 1766588589.7108667, "phase": "train", "update": 686, "total_env_steps": 2195200, "episode_reward": 0.3777933716773987, "value_loss": 0.005877059853325288, "policy_loss": -0.011865684621161185, "dist_entropy": 0.634924340248108, "actor_grad_norm": 0.14520388841629028, "critic_grad_norm": 0.05534512922167778, "ratio": 1.000017762184143, "entropy": 0.634924340248108, "incre_win_rate": 0.9354838709677419, "step": 686}
{"time": 1766588594.5332348, "phase": "train", "update": 687, "total_env_steps": 2198400, "episode_reward": 0.35916435718536377, "value_loss": 0.01072397716343403, "policy_loss": -0.011377669637075627, "dist_entropy": 0.6332189599672954, "actor_grad_norm": 0.13926774263381958, "critic_grad_norm": 0.04441499710083008, "ratio": 1.0006091594696045, "entropy": 0.6332189599672954, "incre_win_rate": 0.8688524590163934, "step": 687}
{"time": 1766588599.2823904, "phase": "train", "update": 688, "total_env_steps": 2201600, "episode_reward": 0.3471047878265381, "value_loss": 0.013758598081767558, "policy_loss": -0.011919043517478597, "dist_entropy": 0.632999308904012, "actor_grad_norm": 0.14865122735500336, "critic_grad_norm": 0.06531906127929688, "ratio": 1.0001945495605469, "entropy": 0.632999308904012, "incre_win_rate": 0.7413793103448276, "step": 688}
{"time": 1766588603.90377, "phase": "train", "update": 689, "total_env_steps": 2204800, "episode_reward": 0.3575804531574249, "value_loss": 0.011722290329635144, "policy_loss": -0.012200923185820282, "dist_entropy": 0.6382664720217387, "actor_grad_norm": 0.18752305209636688, "critic_grad_norm": 0.021023500710725784, "ratio": 0.9991978406906128, "entropy": 0.6382664720217387, "incre_win_rate": 0.8166666666666667, "step": 689}
{"time": 1766588608.4664564, "phase": "train", "update": 690, "total_env_steps": 2208000, "episode_reward": 0.3586672842502594, "value_loss": 0.01217378315826257, "policy_loss": -0.011103483182296259, "dist_entropy": 0.6204721649487813, "actor_grad_norm": 0.13962219655513763, "critic_grad_norm": 0.02702147327363491, "ratio": 0.9990566968917847, "entropy": 0.6204721649487813, "incre_win_rate": 0.819672131147541, "step": 690}
{"time": 1766588613.2349517, "phase": "train", "update": 691, "total_env_steps": 2211200, "episode_reward": 0.3544975519180298, "value_loss": 0.011777704395353795, "policy_loss": -0.012580474044860542, "dist_entropy": 0.6384567856788635, "actor_grad_norm": 0.1460031270980835, "critic_grad_norm": 0.025406617671251297, "ratio": 0.9990187883377075, "entropy": 0.6384567856788635, "incre_win_rate": 0.847457627118644, "step": 691}
{"time": 1766588617.91808, "phase": "train", "update": 692, "total_env_steps": 2214400, "episode_reward": 0.3398100733757019, "value_loss": 0.01606549204637607, "policy_loss": -0.011672481335188441, "dist_entropy": 0.6298148194948833, "actor_grad_norm": 0.1993117779493332, "critic_grad_norm": 0.0811639353632927, "ratio": 0.9997574090957642, "entropy": 0.6298148194948833, "incre_win_rate": 0.7457627118644068, "step": 692}
{"time": 1766588622.4646063, "phase": "train", "update": 693, "total_env_steps": 2217600, "episode_reward": 0.366403192281723, "value_loss": 0.008031462505459785, "policy_loss": -0.011918565094430752, "dist_entropy": 0.6396573781967163, "actor_grad_norm": 0.1584663987159729, "critic_grad_norm": 0.041428450495004654, "ratio": 0.9982866644859314, "entropy": 0.6396573781967163, "incre_win_rate": 0.8852459016393442, "step": 693}
{"time": 1766588627.0771372, "phase": "train", "update": 694, "total_env_steps": 2220800, "episode_reward": 0.35551702976226807, "value_loss": 0.010815555788576603, "policy_loss": -0.01158198258647758, "dist_entropy": 0.6266714096069336, "actor_grad_norm": 0.14496411383152008, "critic_grad_norm": 0.05678553134202957, "ratio": 1.0006201267242432, "entropy": 0.6266714096069336, "incre_win_rate": 0.8275862068965517, "step": 694}
{"time": 1766588631.630503, "phase": "train", "update": 695, "total_env_steps": 2224000, "episode_reward": 0.3635638952255249, "value_loss": 0.00685272254049778, "policy_loss": -0.011828989387340982, "dist_entropy": 0.6168880224227905, "actor_grad_norm": 0.18206705152988434, "critic_grad_norm": 0.026800915598869324, "ratio": 0.9996693730354309, "entropy": 0.6168880224227905, "incre_win_rate": 0.8870967741935484, "step": 695}
{"time": 1766588636.1910098, "phase": "train", "update": 696, "total_env_steps": 2227200, "episode_reward": 0.36967217922210693, "value_loss": 0.009430015894273917, "policy_loss": -0.012301226720046929, "dist_entropy": 0.6400114337603251, "actor_grad_norm": 0.15082643926143646, "critic_grad_norm": 0.03299383446574211, "ratio": 0.9996597170829773, "entropy": 0.6400114337603251, "incre_win_rate": 0.9, "step": 696}
{"time": 1766588640.7055635, "phase": "train", "update": 697, "total_env_steps": 2230400, "episode_reward": 0.3653630316257477, "value_loss": 0.007742823815594117, "policy_loss": -0.011932592885893692, "dist_entropy": 0.6278602361679078, "actor_grad_norm": 0.14476147294044495, "critic_grad_norm": 0.028835918754339218, "ratio": 1.0004733800888062, "entropy": 0.6278602361679078, "incre_win_rate": 0.8524590163934426, "step": 697}
{"time": 1766588645.2649014, "phase": "train", "update": 698, "total_env_steps": 2233600, "episode_reward": 0.3570672571659088, "value_loss": 0.00727775152772665, "policy_loss": -0.012462928354980817, "dist_entropy": 0.6312533458073933, "actor_grad_norm": 0.16414448618888855, "critic_grad_norm": 0.021381672471761703, "ratio": 0.9996643662452698, "entropy": 0.6312533458073933, "incre_win_rate": 0.8983050847457628, "step": 698}
{"time": 1766588649.7852054, "phase": "train", "update": 699, "total_env_steps": 2236800, "episode_reward": 0.3564468324184418, "value_loss": 0.007712616647283236, "policy_loss": -0.011934320962884708, "dist_entropy": 0.6280066490173339, "actor_grad_norm": 0.15859372913837433, "critic_grad_norm": 0.020625755190849304, "ratio": 1.0001544952392578, "entropy": 0.6280066490173339, "incre_win_rate": 0.8135593220338984, "step": 699}
{"time": 1766588654.2945633, "phase": "train", "update": 700, "total_env_steps": 2240000, "episode_reward": 0.3576256036758423, "value_loss": 0.012169523971776168, "policy_loss": -0.01244884683494784, "dist_entropy": 0.626646089553833, "actor_grad_norm": 0.16544397175312042, "critic_grad_norm": 0.024094486609101295, "ratio": 1.0001294612884521, "entropy": 0.626646089553833, "incre_win_rate": 0.8333333333333334, "step": 700}
{"time": 1766588658.8180807, "phase": "train", "update": 701, "total_env_steps": 2243200, "episode_reward": 0.3544500768184662, "value_loss": 0.009739001219471296, "policy_loss": -0.012670345386104032, "dist_entropy": 0.6311261057853699, "actor_grad_norm": 0.1481282263994217, "critic_grad_norm": 0.014192484319210052, "ratio": 0.9993530511856079, "entropy": 0.6311261057853699, "incre_win_rate": 0.8333333333333334, "step": 701}
{"time": 1766588665.8150008, "phase": "eval", "update": 701, "total_env_steps": 2243200, "eval_win_rate": 1.0, "eval_episode_reward": 20.00719975490196, "step": 701}
{"time": 1766588670.3584542, "phase": "train", "update": 702, "total_env_steps": 2246400, "episode_reward": 0.35066020488739014, "value_loss": 0.010546329679588478, "policy_loss": -0.011616102817791329, "dist_entropy": 0.635526978969574, "actor_grad_norm": 0.1558772325515747, "critic_grad_norm": 0.013592341914772987, "ratio": 0.9997003078460693, "entropy": 0.635526978969574, "incre_win_rate": 0.847457627118644, "step": 702}
{"time": 1766588674.8286262, "phase": "train", "update": 703, "total_env_steps": 2249600, "episode_reward": 0.35025736689567566, "value_loss": 0.011935104678074519, "policy_loss": -0.012830072160212088, "dist_entropy": 0.6368481953938802, "actor_grad_norm": 0.16364993155002594, "critic_grad_norm": 0.011497397907078266, "ratio": 0.999328076839447, "entropy": 0.6368481953938802, "incre_win_rate": 0.8103448275862069, "step": 703}
{"time": 1766588679.3308437, "phase": "train", "update": 704, "total_env_steps": 2252800, "episode_reward": 0.3570863902568817, "value_loss": 0.010532906278967857, "policy_loss": -0.013167241266227118, "dist_entropy": 0.6246188124020894, "actor_grad_norm": 0.15878626704216003, "critic_grad_norm": 0.016632582992315292, "ratio": 1.0000669956207275, "entropy": 0.6246188124020894, "incre_win_rate": 0.8095238095238095, "step": 704}
{"time": 1766588683.7660358, "phase": "train", "update": 705, "total_env_steps": 2256000, "episode_reward": 0.3441835343837738, "value_loss": 0.013419160929818949, "policy_loss": -0.012218069424859361, "dist_entropy": 0.6196561415990194, "actor_grad_norm": 0.14768116176128387, "critic_grad_norm": 0.06880456209182739, "ratio": 0.999906063079834, "entropy": 0.6196561415990194, "incre_win_rate": 0.7413793103448276, "step": 705}
{"time": 1766588688.2224832, "phase": "train", "update": 706, "total_env_steps": 2259200, "episode_reward": 0.3629932999610901, "value_loss": 0.010230179317295552, "policy_loss": -0.012008606016797548, "dist_entropy": 0.6097131411234538, "actor_grad_norm": 0.1418658196926117, "critic_grad_norm": 0.07502847909927368, "ratio": 0.9995064735412598, "entropy": 0.6097131411234538, "incre_win_rate": 0.8666666666666667, "step": 706}
{"time": 1766588692.770187, "phase": "train", "update": 707, "total_env_steps": 2262400, "episode_reward": 0.345962792634964, "value_loss": 0.011140985290209453, "policy_loss": -0.012525653195480876, "dist_entropy": 0.6101816097895304, "actor_grad_norm": 0.17362050712108612, "critic_grad_norm": 0.048209186643362045, "ratio": 0.9987647533416748, "entropy": 0.6101816097895304, "incre_win_rate": 0.7796610169491526, "step": 707}
{"time": 1766588697.3205185, "phase": "train", "update": 708, "total_env_steps": 2265600, "episode_reward": 0.3459620177745819, "value_loss": 0.012848690835138161, "policy_loss": -0.012823287294060038, "dist_entropy": 0.6200851718584697, "actor_grad_norm": 0.15797032415866852, "critic_grad_norm": 0.03459816426038742, "ratio": 0.9996834993362427, "entropy": 0.6200851718584697, "incre_win_rate": 0.7758620689655172, "step": 708}
{"time": 1766588701.8200095, "phase": "train", "update": 709, "total_env_steps": 2268800, "episode_reward": 0.35957565903663635, "value_loss": 0.00937871312101682, "policy_loss": -0.012755283021362373, "dist_entropy": 0.616746739546458, "actor_grad_norm": 0.17365480959415436, "critic_grad_norm": 0.033245086669921875, "ratio": 0.9998162388801575, "entropy": 0.616746739546458, "incre_win_rate": 0.8666666666666667, "step": 709}
{"time": 1766588706.3617449, "phase": "train", "update": 710, "total_env_steps": 2272000, "episode_reward": 0.3528783619403839, "value_loss": 0.013176487324138482, "policy_loss": -0.014211966650957681, "dist_entropy": 0.5968423883120219, "actor_grad_norm": 0.1699720174074173, "critic_grad_norm": 0.016588814556598663, "ratio": 0.9979753494262695, "entropy": 0.5968423883120219, "incre_win_rate": 0.8, "step": 710}
{"time": 1766588710.9591115, "phase": "train", "update": 711, "total_env_steps": 2275200, "episode_reward": 0.36985906958580017, "value_loss": 0.00974758006632328, "policy_loss": -0.012144473564148465, "dist_entropy": 0.626093864440918, "actor_grad_norm": 0.16667604446411133, "critic_grad_norm": 0.05204892158508301, "ratio": 0.99847811460495, "entropy": 0.626093864440918, "incre_win_rate": 0.8709677419354839, "step": 711}
{"time": 1766588715.5470107, "phase": "train", "update": 712, "total_env_steps": 2278400, "episode_reward": 0.35123544931411743, "value_loss": 0.012650149936477343, "policy_loss": -0.011947729919053055, "dist_entropy": 0.6328825116157532, "actor_grad_norm": 0.18567661941051483, "critic_grad_norm": 0.02220184914767742, "ratio": 0.9987806081771851, "entropy": 0.6328825116157532, "incre_win_rate": 0.7966101694915254, "step": 712}
{"time": 1766588720.218279, "phase": "train", "update": 713, "total_env_steps": 2281600, "episode_reward": 0.36333179473876953, "value_loss": 0.008753900850812594, "policy_loss": -0.011314857439455987, "dist_entropy": 0.629572081565857, "actor_grad_norm": 0.18554143607616425, "critic_grad_norm": 0.031960468739271164, "ratio": 0.999877393245697, "entropy": 0.629572081565857, "incre_win_rate": 0.8870967741935484, "step": 713}
{"time": 1766588725.155927, "phase": "train", "update": 714, "total_env_steps": 2284800, "episode_reward": 0.35781174898147583, "value_loss": 0.0072633073044319945, "policy_loss": -0.012694193213252446, "dist_entropy": 0.6210237701733907, "actor_grad_norm": 0.14640700817108154, "critic_grad_norm": 0.030912114307284355, "ratio": 0.9988489747047424, "entropy": 0.6210237701733907, "incre_win_rate": 0.8771929824561403, "step": 714}
{"time": 1766588729.910288, "phase": "train", "update": 715, "total_env_steps": 2288000, "episode_reward": 0.340036004781723, "value_loss": 0.012781777729590734, "policy_loss": -0.012402987982426339, "dist_entropy": 0.6141842802365621, "actor_grad_norm": 0.16205823421478271, "critic_grad_norm": 0.041981153190135956, "ratio": 0.9996771812438965, "entropy": 0.6141842802365621, "incre_win_rate": 0.7857142857142857, "step": 715}
{"time": 1766588734.6608841, "phase": "train", "update": 716, "total_env_steps": 2291200, "episode_reward": 0.36560356616973877, "value_loss": 0.004979220839838187, "policy_loss": -0.0134976159868368, "dist_entropy": 0.6223973790804546, "actor_grad_norm": 0.1750960797071457, "critic_grad_norm": 0.049848850816488266, "ratio": 0.9995365738868713, "entropy": 0.6223973790804546, "incre_win_rate": 0.9047619047619048, "step": 716}
{"time": 1766588739.119319, "phase": "train", "update": 717, "total_env_steps": 2294400, "episode_reward": 0.3624027371406555, "value_loss": 0.010420839488506316, "policy_loss": -0.011286593388103465, "dist_entropy": 0.6191429575284322, "actor_grad_norm": 0.1499713957309723, "critic_grad_norm": 0.03263916075229645, "ratio": 1.0005176067352295, "entropy": 0.6191429575284322, "incre_win_rate": 0.847457627118644, "step": 717}
{"time": 1766588743.5396907, "phase": "train", "update": 718, "total_env_steps": 2297600, "episode_reward": 0.3612990081310272, "value_loss": 0.011955303202072779, "policy_loss": -0.012018686151385793, "dist_entropy": 0.612496797243754, "actor_grad_norm": 0.18467429280281067, "critic_grad_norm": 0.032924313098192215, "ratio": 0.9993471503257751, "entropy": 0.612496797243754, "incre_win_rate": 0.8360655737704918, "step": 718}
{"time": 1766588747.936726, "phase": "train", "update": 719, "total_env_steps": 2300800, "episode_reward": 0.3529963493347168, "value_loss": 0.008192370956142744, "policy_loss": -0.011809715027823605, "dist_entropy": 0.6259104410807291, "actor_grad_norm": 0.17402590811252594, "critic_grad_norm": 0.025295373052358627, "ratio": 1.0004394054412842, "entropy": 0.6259104410807291, "incre_win_rate": 0.8524590163934426, "step": 719}
{"time": 1766588752.319649, "phase": "train", "update": 720, "total_env_steps": 2304000, "episode_reward": 0.3562423288822174, "value_loss": 0.009448728213707605, "policy_loss": -0.012793744897428402, "dist_entropy": 0.6280856450398763, "actor_grad_norm": 0.15528224408626556, "critic_grad_norm": 0.030147338286042213, "ratio": 0.9994125962257385, "entropy": 0.6280856450398763, "incre_win_rate": 0.8448275862068966, "step": 720}
{"time": 1766588756.7512593, "phase": "train", "update": 721, "total_env_steps": 2307200, "episode_reward": 0.33218979835510254, "value_loss": 0.013206613125900428, "policy_loss": -0.013800588766978686, "dist_entropy": 0.6148595492045085, "actor_grad_norm": 0.16590796411037445, "critic_grad_norm": 0.10340867936611176, "ratio": 1.0003072023391724, "entropy": 0.6148595492045085, "incre_win_rate": 0.6779661016949152, "step": 721}
{"time": 1766588763.6313796, "phase": "eval", "update": 721, "total_env_steps": 2307200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.508808210784313, "step": 721}
{"time": 1766588768.024347, "phase": "train", "update": 722, "total_env_steps": 2310400, "episode_reward": 0.35860833525657654, "value_loss": 0.009722456646462282, "policy_loss": -0.012114176296650687, "dist_entropy": 0.607126506169637, "actor_grad_norm": 0.1646067500114441, "critic_grad_norm": 0.07731501758098602, "ratio": 0.9999504685401917, "entropy": 0.607126506169637, "incre_win_rate": 0.8620689655172413, "step": 722}
{"time": 1766588772.457364, "phase": "train", "update": 723, "total_env_steps": 2313600, "episode_reward": 0.35931676626205444, "value_loss": 0.009627689234912395, "policy_loss": -0.011431199443250743, "dist_entropy": 0.6095150828361511, "actor_grad_norm": 0.1701560765504837, "critic_grad_norm": 0.03835000842809677, "ratio": 0.9987566471099854, "entropy": 0.6095150828361511, "incre_win_rate": 0.8387096774193549, "step": 723}
{"time": 1766588776.8947546, "phase": "train", "update": 724, "total_env_steps": 2316800, "episode_reward": 0.3570435047149658, "value_loss": 0.006796538550406695, "policy_loss": -0.012087493418073336, "dist_entropy": 0.6159530123074849, "actor_grad_norm": 0.18683047592639923, "critic_grad_norm": 0.010758602991700172, "ratio": 0.9999047517776489, "entropy": 0.6159530123074849, "incre_win_rate": 0.8947368421052632, "step": 724}
{"time": 1766588781.258073, "phase": "train", "update": 725, "total_env_steps": 2320000, "episode_reward": 0.35362744331359863, "value_loss": 0.010661485667030016, "policy_loss": -0.011885879529407362, "dist_entropy": 0.6155893961588542, "actor_grad_norm": 0.16576547920703888, "critic_grad_norm": 0.0459614023566246, "ratio": 0.9996909499168396, "entropy": 0.6155893961588542, "incre_win_rate": 0.8524590163934426, "step": 725}
{"time": 1766588785.7774086, "phase": "train", "update": 726, "total_env_steps": 2323200, "episode_reward": 0.3647487759590149, "value_loss": 0.009173013331989447, "policy_loss": -0.011322985100640419, "dist_entropy": 0.611431074142456, "actor_grad_norm": 0.1384347379207611, "critic_grad_norm": 0.048180725425481796, "ratio": 1.0003467798233032, "entropy": 0.611431074142456, "incre_win_rate": 0.9137931034482759, "step": 726}
{"time": 1766588790.4158084, "phase": "train", "update": 727, "total_env_steps": 2326400, "episode_reward": 0.369873583316803, "value_loss": 0.005893892732759317, "policy_loss": -0.010508258105572328, "dist_entropy": 0.6376992146174113, "actor_grad_norm": 0.14188331365585327, "critic_grad_norm": 0.02092926949262619, "ratio": 0.9977275133132935, "entropy": 0.6376992146174113, "incre_win_rate": 0.9344262295081968, "step": 727}
{"time": 1766588795.0140138, "phase": "train", "update": 728, "total_env_steps": 2329600, "episode_reward": 0.37397825717926025, "value_loss": 0.003563851894189914, "policy_loss": -0.011376699959334975, "dist_entropy": 0.6175849954287211, "actor_grad_norm": 0.14539645612239838, "critic_grad_norm": 0.032615892589092255, "ratio": 0.9994563460350037, "entropy": 0.6175849954287211, "incre_win_rate": 0.9672131147540983, "step": 728}
{"time": 1766588799.60261, "phase": "train", "update": 729, "total_env_steps": 2332800, "episode_reward": 0.3680169880390167, "value_loss": 0.006728258791069189, "policy_loss": -0.010900687115808811, "dist_entropy": 0.5894187132517497, "actor_grad_norm": 0.15182019770145416, "critic_grad_norm": 0.029932821169495583, "ratio": 0.9996957778930664, "entropy": 0.5894187132517497, "incre_win_rate": 0.8983050847457628, "step": 729}
{"time": 1766588804.103487, "phase": "train", "update": 730, "total_env_steps": 2336000, "episode_reward": 0.35583409667015076, "value_loss": 0.008726460238297781, "policy_loss": -0.0123153488335646, "dist_entropy": 0.6055331269900004, "actor_grad_norm": 0.1428883969783783, "critic_grad_norm": 0.05088743939995766, "ratio": 1.0004922151565552, "entropy": 0.6055331269900004, "incre_win_rate": 0.8360655737704918, "step": 730}
{"time": 1766588808.6121154, "phase": "train", "update": 731, "total_env_steps": 2339200, "episode_reward": 0.36697763204574585, "value_loss": 0.00727158614123861, "policy_loss": -0.013377965066337972, "dist_entropy": 0.6104291558265686, "actor_grad_norm": 0.16564710438251495, "critic_grad_norm": 0.021164875477552414, "ratio": 0.9985902309417725, "entropy": 0.6104291558265686, "incre_win_rate": 0.9, "step": 731}
{"time": 1766588813.0136924, "phase": "train", "update": 732, "total_env_steps": 2342400, "episode_reward": 0.3598223030567169, "value_loss": 0.009214628612001736, "policy_loss": -0.013453843186066667, "dist_entropy": 0.5938053210576375, "actor_grad_norm": 0.14197996258735657, "critic_grad_norm": 0.01731943152844906, "ratio": 0.9996131062507629, "entropy": 0.5938053210576375, "incre_win_rate": 0.8813559322033898, "step": 732}
{"time": 1766588817.5985181, "phase": "train", "update": 733, "total_env_steps": 2345600, "episode_reward": 0.35604703426361084, "value_loss": 0.010097312616805236, "policy_loss": -0.013533113487281886, "dist_entropy": 0.5985547105471293, "actor_grad_norm": 0.1479450762271881, "critic_grad_norm": 0.029407745227217674, "ratio": 0.9996302723884583, "entropy": 0.5985547105471293, "incre_win_rate": 0.847457627118644, "step": 733}
{"time": 1766588822.0133696, "phase": "train", "update": 734, "total_env_steps": 2348800, "episode_reward": 0.3556426167488098, "value_loss": 0.008602097475280365, "policy_loss": -0.012338168212688435, "dist_entropy": 0.6063421646753947, "actor_grad_norm": 0.13970504701137543, "critic_grad_norm": 0.016154907643795013, "ratio": 0.9994796514511108, "entropy": 0.6063421646753947, "incre_win_rate": 0.8524590163934426, "step": 734}
{"time": 1766588826.4605193, "phase": "train", "update": 735, "total_env_steps": 2352000, "episode_reward": 0.36722734570503235, "value_loss": 0.011191329670449097, "policy_loss": -0.012391564543267463, "dist_entropy": 0.6232723553975423, "actor_grad_norm": 0.13466867804527283, "critic_grad_norm": 0.0639602392911911, "ratio": 0.9994989037513733, "entropy": 0.6232723553975423, "incre_win_rate": 0.9482758620689655, "step": 735}
{"time": 1766588831.0834885, "phase": "train", "update": 736, "total_env_steps": 2355200, "episode_reward": 0.34376612305641174, "value_loss": 0.00867807852725188, "policy_loss": -0.013623071965255917, "dist_entropy": 0.6394390424092611, "actor_grad_norm": 0.2150636911392212, "critic_grad_norm": 0.03327962011098862, "ratio": 1.0000224113464355, "entropy": 0.6394390424092611, "incre_win_rate": 0.7796610169491526, "step": 736}
{"time": 1766588835.5031924, "phase": "train", "update": 737, "total_env_steps": 2358400, "episode_reward": 0.34323224425315857, "value_loss": 0.015181470662355423, "policy_loss": -0.012897472768005968, "dist_entropy": 0.6257146239280701, "actor_grad_norm": 0.18549670279026031, "critic_grad_norm": 0.05939031019806862, "ratio": 0.9982561469078064, "entropy": 0.6257146239280701, "incre_win_rate": 0.7758620689655172, "step": 737}
{"time": 1766588840.0525918, "phase": "train", "update": 738, "total_env_steps": 2361600, "episode_reward": 0.3508547842502594, "value_loss": 0.012153272703289985, "policy_loss": -0.013150071722155115, "dist_entropy": 0.6270224491755167, "actor_grad_norm": 0.1807476282119751, "critic_grad_norm": 0.026330601423978806, "ratio": 1.0006593465805054, "entropy": 0.6270224491755167, "incre_win_rate": 0.8688524590163934, "step": 738}
{"time": 1766588845.1595697, "phase": "train", "update": 739, "total_env_steps": 2364800, "episode_reward": 0.361796110868454, "value_loss": 0.008438366496314605, "policy_loss": -0.011638428882493675, "dist_entropy": 0.6364883224169413, "actor_grad_norm": 0.1556597799062729, "critic_grad_norm": 0.04010894149541855, "ratio": 0.9984927177429199, "entropy": 0.6364883224169413, "incre_win_rate": 0.864406779661017, "step": 739}
{"time": 1766588850.2066164, "phase": "train", "update": 740, "total_env_steps": 2368000, "episode_reward": 0.3506127595901489, "value_loss": 0.013589388752977053, "policy_loss": -0.012960484657358506, "dist_entropy": 0.6263103286425272, "actor_grad_norm": 0.15631598234176636, "critic_grad_norm": 0.026676759123802185, "ratio": 0.9997538924217224, "entropy": 0.6263103286425272, "incre_win_rate": 0.8, "step": 740}
{"time": 1766588855.1744597, "phase": "train", "update": 741, "total_env_steps": 2371200, "episode_reward": 0.3608187735080719, "value_loss": 0.008417029958218336, "policy_loss": -0.012153898138754945, "dist_entropy": 0.6323384801546733, "actor_grad_norm": 0.175562784075737, "critic_grad_norm": 0.03461001068353653, "ratio": 0.9985905885696411, "entropy": 0.6323384801546733, "incre_win_rate": 0.8793103448275862, "step": 741}
{"time": 1766588862.6353598, "phase": "eval", "update": 741, "total_env_steps": 2371200, "eval_win_rate": 1.0, "eval_episode_reward": 20.004748774509807, "step": 741}
{"time": 1766588867.5879009, "phase": "train", "update": 742, "total_env_steps": 2374400, "episode_reward": 0.3578791618347168, "value_loss": 0.008408831184109051, "policy_loss": -0.012369207885385928, "dist_entropy": 0.6140318473180135, "actor_grad_norm": 0.18926028907299042, "critic_grad_norm": 0.026060406118631363, "ratio": 1.0008478164672852, "entropy": 0.6140318473180135, "incre_win_rate": 0.8833333333333333, "step": 742}
{"time": 1766588872.2309382, "phase": "train", "update": 743, "total_env_steps": 2377600, "episode_reward": 0.3592463433742523, "value_loss": 0.007804348071416219, "policy_loss": -0.011975237690988176, "dist_entropy": 0.6225753227869669, "actor_grad_norm": 0.1471671164035797, "critic_grad_norm": 0.01775786094367504, "ratio": 1.000473976135254, "entropy": 0.6225753227869669, "incre_win_rate": 0.8666666666666667, "step": 743}
{"time": 1766588876.8987873, "phase": "train", "update": 744, "total_env_steps": 2380800, "episode_reward": 0.35148516297340393, "value_loss": 0.007522856971869866, "policy_loss": -0.012779763342891453, "dist_entropy": 0.6399491310119629, "actor_grad_norm": 0.14450016617774963, "critic_grad_norm": 0.018676167353987694, "ratio": 0.9998659491539001, "entropy": 0.6399491310119629, "incre_win_rate": 0.847457627118644, "step": 744}
{"time": 1766588881.5496545, "phase": "train", "update": 745, "total_env_steps": 2384000, "episode_reward": 0.35907861590385437, "value_loss": 0.006346702389419079, "policy_loss": -0.012697075482341329, "dist_entropy": 0.62941415309906, "actor_grad_norm": 0.15582126379013062, "critic_grad_norm": 0.028635600581765175, "ratio": 0.9991446137428284, "entropy": 0.62941415309906, "incre_win_rate": 0.8793103448275862, "step": 745}
{"time": 1766588886.1133232, "phase": "train", "update": 746, "total_env_steps": 2387200, "episode_reward": 0.3515908122062683, "value_loss": 0.009978458409508069, "policy_loss": -0.01269212049763008, "dist_entropy": 0.6472827434539795, "actor_grad_norm": 0.1426997184753418, "critic_grad_norm": 0.035508688539266586, "ratio": 1.000073790550232, "entropy": 0.6472827434539795, "incre_win_rate": 0.9, "step": 746}
{"time": 1766588890.7733693, "phase": "train", "update": 747, "total_env_steps": 2390400, "episode_reward": 0.3518267869949341, "value_loss": 0.012304046874245007, "policy_loss": -0.01290462144748119, "dist_entropy": 0.6374769449234009, "actor_grad_norm": 0.20731812715530396, "critic_grad_norm": 0.01934920996427536, "ratio": 0.9990701079368591, "entropy": 0.6374769449234009, "incre_win_rate": 0.7931034482758621, "step": 747}
{"time": 1766588895.357746, "phase": "train", "update": 748, "total_env_steps": 2393600, "episode_reward": 0.35519298911094666, "value_loss": 0.012561577123900254, "policy_loss": -0.012389378188529558, "dist_entropy": 0.6387683312098186, "actor_grad_norm": 0.17032919824123383, "critic_grad_norm": 0.03491221368312836, "ratio": 1.000608205795288, "entropy": 0.6387683312098186, "incre_win_rate": 0.8666666666666667, "step": 748}
{"time": 1766588900.032436, "phase": "train", "update": 749, "total_env_steps": 2396800, "episode_reward": 0.34378448128700256, "value_loss": 0.013173142323891322, "policy_loss": -0.013117502167922861, "dist_entropy": 0.6220656116803487, "actor_grad_norm": 0.20577406883239746, "critic_grad_norm": 0.054592058062553406, "ratio": 1.0003492832183838, "entropy": 0.6220656116803487, "incre_win_rate": 0.75, "step": 749}
{"time": 1766588904.6186097, "phase": "train", "update": 750, "total_env_steps": 2400000, "episode_reward": 0.3518374562263489, "value_loss": 0.010684525904556116, "policy_loss": -0.01289500456973561, "dist_entropy": 0.6361968755722046, "actor_grad_norm": 0.16888678073883057, "critic_grad_norm": 0.04165255278348923, "ratio": 0.9997127652168274, "entropy": 0.6361968755722046, "incre_win_rate": 0.8245614035087719, "step": 750}
{"time": 1766588909.2437167, "phase": "train", "update": 751, "total_env_steps": 2403200, "episode_reward": 0.3536466062068939, "value_loss": 0.011250017024576665, "policy_loss": -0.013211462962908626, "dist_entropy": 0.6344241142272949, "actor_grad_norm": 0.14564985036849976, "critic_grad_norm": 0.02118276059627533, "ratio": 1.000265121459961, "entropy": 0.6344241142272949, "incre_win_rate": 0.8333333333333334, "step": 751}
{"time": 1766588913.8944108, "phase": "train", "update": 752, "total_env_steps": 2406400, "episode_reward": 0.35618796944618225, "value_loss": 0.007856096234172582, "policy_loss": -0.011613907026926521, "dist_entropy": 0.6246593634287516, "actor_grad_norm": 0.19772355258464813, "critic_grad_norm": 0.035672880709171295, "ratio": 0.9993633031845093, "entropy": 0.6246593634287516, "incre_win_rate": 0.8333333333333334, "step": 752}
{"time": 1766588918.5074015, "phase": "train", "update": 753, "total_env_steps": 2409600, "episode_reward": 0.3610646426677704, "value_loss": 0.007238094819088777, "policy_loss": -0.012537784610039656, "dist_entropy": 0.634279712041219, "actor_grad_norm": 0.14054003357887268, "critic_grad_norm": 0.025664273649454117, "ratio": 0.9988868832588196, "entropy": 0.634279712041219, "incre_win_rate": 0.8983050847457628, "step": 753}
{"time": 1766588923.1783485, "phase": "train", "update": 754, "total_env_steps": 2412800, "episode_reward": 0.3562806248664856, "value_loss": 0.012528693800171216, "policy_loss": -0.012034475488669738, "dist_entropy": 0.6200828870137532, "actor_grad_norm": 0.1655052751302719, "critic_grad_norm": 0.06106969714164734, "ratio": 1.0009822845458984, "entropy": 0.6200828870137532, "incre_win_rate": 0.8360655737704918, "step": 754}
{"time": 1766588927.843558, "phase": "train", "update": 755, "total_env_steps": 2416000, "episode_reward": 0.35598114132881165, "value_loss": 0.009246568319698174, "policy_loss": -0.012029508362572964, "dist_entropy": 0.6060822049776713, "actor_grad_norm": 0.21543926000595093, "critic_grad_norm": 0.04986684024333954, "ratio": 0.9986826181411743, "entropy": 0.6060822049776713, "incre_win_rate": 0.8947368421052632, "step": 755}
{"time": 1766588932.4833503, "phase": "train", "update": 756, "total_env_steps": 2419200, "episode_reward": 0.3584038019180298, "value_loss": 0.00732620470225811, "policy_loss": -0.012556765470922453, "dist_entropy": 0.6213498910268148, "actor_grad_norm": 0.16392438113689423, "critic_grad_norm": 0.019359948113560677, "ratio": 1.0001180171966553, "entropy": 0.6213498910268148, "incre_win_rate": 0.8833333333333333, "step": 756}
{"time": 1766588937.1124, "phase": "train", "update": 757, "total_env_steps": 2422400, "episode_reward": 0.35047027468681335, "value_loss": 0.008685939572751522, "policy_loss": -0.012668780875274758, "dist_entropy": 0.6132957379023234, "actor_grad_norm": 0.13295072317123413, "critic_grad_norm": 0.02602553181350231, "ratio": 0.9982001781463623, "entropy": 0.6132957379023234, "incre_win_rate": 0.847457627118644, "step": 757}
{"time": 1766588941.7665856, "phase": "train", "update": 758, "total_env_steps": 2425600, "episode_reward": 0.35166364908218384, "value_loss": 0.012820350875457128, "policy_loss": -0.011901574107807988, "dist_entropy": 0.6106741984685262, "actor_grad_norm": 0.16263015568256378, "critic_grad_norm": 0.029631681740283966, "ratio": 0.9997305870056152, "entropy": 0.6106741984685262, "incre_win_rate": 0.8620689655172413, "step": 758}
{"time": 1766588946.4051921, "phase": "train", "update": 759, "total_env_steps": 2428800, "episode_reward": 0.3535585403442383, "value_loss": 0.013902273215353488, "policy_loss": -0.01135747256224331, "dist_entropy": 0.6090451200803121, "actor_grad_norm": 0.1702154576778412, "critic_grad_norm": 0.03225395455956459, "ratio": 0.9994829893112183, "entropy": 0.6090451200803121, "incre_win_rate": 0.8032786885245902, "step": 759}
{"time": 1766588951.104633, "phase": "train", "update": 760, "total_env_steps": 2432000, "episode_reward": 0.34902650117874146, "value_loss": 0.012136066270371278, "policy_loss": -0.01196695513742346, "dist_entropy": 0.6088261326154073, "actor_grad_norm": 0.14283640682697296, "critic_grad_norm": 0.02837197668850422, "ratio": 0.9990894198417664, "entropy": 0.6088261326154073, "incre_win_rate": 0.8103448275862069, "step": 760}
{"time": 1766588955.7751348, "phase": "train", "update": 761, "total_env_steps": 2435200, "episode_reward": 0.350674033164978, "value_loss": 0.013379592510561148, "policy_loss": -0.01169259276034135, "dist_entropy": 0.6230456511179606, "actor_grad_norm": 0.15992854535579681, "critic_grad_norm": 0.01749512180685997, "ratio": 1.0002669095993042, "entropy": 0.6230456511179606, "incre_win_rate": 0.8032786885245902, "step": 761}
{"time": 1766588970.1235592, "phase": "eval", "update": 761, "total_env_steps": 2435200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.38855698529412, "step": 761}
{"time": 1766588974.7642906, "phase": "train", "update": 762, "total_env_steps": 2438400, "episode_reward": 0.3544783890247345, "value_loss": 0.012892006772259872, "policy_loss": -0.011559802959315846, "dist_entropy": 0.6154113849004109, "actor_grad_norm": 0.1293499767780304, "critic_grad_norm": 0.021221553906798363, "ratio": 0.9996809959411621, "entropy": 0.6154113849004109, "incre_win_rate": 0.8305084745762712, "step": 762}
{"time": 1766588979.3486416, "phase": "train", "update": 763, "total_env_steps": 2441600, "episode_reward": 0.34901729226112366, "value_loss": 0.01076206360012293, "policy_loss": -0.01296077842690219, "dist_entropy": 0.6147178093592326, "actor_grad_norm": 0.16272741556167603, "critic_grad_norm": 0.01778189092874527, "ratio": 0.9995204210281372, "entropy": 0.6147178093592326, "incre_win_rate": 0.8421052631578947, "step": 763}
{"time": 1766588984.0084052, "phase": "train", "update": 764, "total_env_steps": 2444800, "episode_reward": 0.36085864901542664, "value_loss": 0.009500300387541454, "policy_loss": -0.011406053265161139, "dist_entropy": 0.6076788743336995, "actor_grad_norm": 0.15198257565498352, "critic_grad_norm": 0.032564062625169754, "ratio": 0.9989567995071411, "entropy": 0.6076788743336995, "incre_win_rate": 0.8833333333333333, "step": 764}
{"time": 1766588988.6321151, "phase": "train", "update": 765, "total_env_steps": 2448000, "episode_reward": 0.3519768714904785, "value_loss": 0.01353531318406264, "policy_loss": -0.0122190199264035, "dist_entropy": 0.625034244855245, "actor_grad_norm": 0.20172692835330963, "critic_grad_norm": 0.036855872720479965, "ratio": 1.00037682056427, "entropy": 0.625034244855245, "incre_win_rate": 0.8360655737704918, "step": 765}
{"time": 1766588993.251712, "phase": "train", "update": 766, "total_env_steps": 2451200, "episode_reward": 0.3543650507926941, "value_loss": 0.012343738228082657, "policy_loss": -0.012057690349197021, "dist_entropy": 0.6269173860549927, "actor_grad_norm": 0.1448049247264862, "critic_grad_norm": 0.04306190088391304, "ratio": 0.9994325041770935, "entropy": 0.6269173860549927, "incre_win_rate": 0.8620689655172413, "step": 766}
{"time": 1766588997.8204181, "phase": "train", "update": 767, "total_env_steps": 2454400, "episode_reward": 0.35077130794525146, "value_loss": 0.011996241472661495, "policy_loss": -0.0126856743838862, "dist_entropy": 0.6068762977917989, "actor_grad_norm": 0.1911296844482422, "critic_grad_norm": 0.0289996936917305, "ratio": 0.9989300966262817, "entropy": 0.6068762977917989, "incre_win_rate": 0.85, "step": 767}
{"time": 1766589002.4491944, "phase": "train", "update": 768, "total_env_steps": 2457600, "episode_reward": 0.3533509373664856, "value_loss": 0.008373421803116798, "policy_loss": -0.012961565531796993, "dist_entropy": 0.6199318051338196, "actor_grad_norm": 0.15113461017608643, "critic_grad_norm": 0.015367912128567696, "ratio": 1.000380039215088, "entropy": 0.6199318051338196, "incre_win_rate": 0.8448275862068966, "step": 768}
{"time": 1766589007.2166238, "phase": "train", "update": 769, "total_env_steps": 2460800, "episode_reward": 0.3575666546821594, "value_loss": 0.007529252053548892, "policy_loss": -0.011724230430784625, "dist_entropy": 0.6318644603093465, "actor_grad_norm": 0.12387567013502121, "critic_grad_norm": 0.01644904725253582, "ratio": 0.9992945194244385, "entropy": 0.6318644603093465, "incre_win_rate": 0.8813559322033898, "step": 769}
{"time": 1766589012.1611865, "phase": "train", "update": 770, "total_env_steps": 2464000, "episode_reward": 0.35777729749679565, "value_loss": 0.006085291846344868, "policy_loss": -0.010959777088430656, "dist_entropy": 0.6334183216094971, "actor_grad_norm": 0.12758979201316833, "critic_grad_norm": 0.016179732978343964, "ratio": 0.9985927939414978, "entropy": 0.6334183216094971, "incre_win_rate": 0.9137931034482759, "step": 770}
{"time": 1766589016.9007857, "phase": "train", "update": 771, "total_env_steps": 2467200, "episode_reward": 0.3553975224494934, "value_loss": 0.006869920125852028, "policy_loss": -0.011032717592188846, "dist_entropy": 0.6132882316907247, "actor_grad_norm": 0.1465955525636673, "critic_grad_norm": 0.01210184395313263, "ratio": 0.9984850883483887, "entropy": 0.6132882316907247, "incre_win_rate": 0.9, "step": 771}
{"time": 1766589021.6012366, "phase": "train", "update": 772, "total_env_steps": 2470400, "episode_reward": 0.3504549562931061, "value_loss": 0.008213202469050884, "policy_loss": -0.013074077034118167, "dist_entropy": 0.6135352611541748, "actor_grad_norm": 0.1496596485376358, "critic_grad_norm": 0.012542583979666233, "ratio": 1.0005978345870972, "entropy": 0.6135352611541748, "incre_win_rate": 0.8620689655172413, "step": 772}
{"time": 1766589026.3384264, "phase": "train", "update": 773, "total_env_steps": 2473600, "episode_reward": 0.3532713055610657, "value_loss": 0.008874921624859174, "policy_loss": -0.012872321765282812, "dist_entropy": 0.5924845258394877, "actor_grad_norm": 0.1659466028213501, "critic_grad_norm": 0.028040548786520958, "ratio": 0.9993491172790527, "entropy": 0.5924845258394877, "incre_win_rate": 0.8596491228070176, "step": 773}
{"time": 1766589030.9068937, "phase": "train", "update": 774, "total_env_steps": 2476800, "episode_reward": 0.3537048101425171, "value_loss": 0.008095664468904336, "policy_loss": -0.011868296723344685, "dist_entropy": 0.6031835873921713, "actor_grad_norm": 0.13686272501945496, "critic_grad_norm": 0.015085218474268913, "ratio": 1.0000990629196167, "entropy": 0.6031835873921713, "incre_win_rate": 0.8983050847457628, "step": 774}
{"time": 1766589035.5693324, "phase": "train", "update": 775, "total_env_steps": 2480000, "episode_reward": 0.35529640316963196, "value_loss": 0.009865664194027584, "policy_loss": -0.01123183564864026, "dist_entropy": 0.5934507687886555, "actor_grad_norm": 0.14146485924720764, "critic_grad_norm": 0.022134769707918167, "ratio": 0.9998461008071899, "entropy": 0.5934507687886555, "incre_win_rate": 0.8813559322033898, "step": 775}
{"time": 1766589040.3304164, "phase": "train", "update": 776, "total_env_steps": 2483200, "episode_reward": 0.3567838668823242, "value_loss": 0.007068712543696165, "policy_loss": -0.011766598103562842, "dist_entropy": 0.5971186359723409, "actor_grad_norm": 0.13550421595573425, "critic_grad_norm": 0.01339980959892273, "ratio": 0.9991517066955566, "entropy": 0.5971186359723409, "incre_win_rate": 0.8813559322033898, "step": 776}
{"time": 1766589045.1230752, "phase": "train", "update": 777, "total_env_steps": 2486400, "episode_reward": 0.33688727021217346, "value_loss": 0.014822369379301866, "policy_loss": -0.012443321758292806, "dist_entropy": 0.5920992453893026, "actor_grad_norm": 0.149991974234581, "critic_grad_norm": 0.07998143136501312, "ratio": 0.9998756647109985, "entropy": 0.5920992453893026, "incre_win_rate": 0.7666666666666667, "step": 777}
{"time": 1766589049.8627834, "phase": "train", "update": 778, "total_env_steps": 2489600, "episode_reward": 0.3557138741016388, "value_loss": 0.0095301304012537, "policy_loss": -0.011899705791565414, "dist_entropy": 0.5945151368776957, "actor_grad_norm": 0.16051821410655975, "critic_grad_norm": 0.039453547447919846, "ratio": 0.9986966252326965, "entropy": 0.5945151368776957, "incre_win_rate": 0.8392857142857143, "step": 778}
{"time": 1766589054.603572, "phase": "train", "update": 779, "total_env_steps": 2492800, "episode_reward": 0.3358103632926941, "value_loss": 0.009503010474145413, "policy_loss": -0.012646554698753221, "dist_entropy": 0.6008098721504211, "actor_grad_norm": 0.18148043751716614, "critic_grad_norm": 0.03960798680782318, "ratio": 0.9997186660766602, "entropy": 0.6008098721504211, "incre_win_rate": 0.8275862068965517, "step": 779}
{"time": 1766589059.3741996, "phase": "train", "update": 780, "total_env_steps": 2496000, "episode_reward": 0.34504443407058716, "value_loss": 0.011549895318845907, "policy_loss": -0.01166235038687707, "dist_entropy": 0.5880697687466939, "actor_grad_norm": 0.18026670813560486, "critic_grad_norm": 0.027003314346075058, "ratio": 0.9990940093994141, "entropy": 0.5880697687466939, "incre_win_rate": 0.8448275862068966, "step": 780}
{"time": 1766589064.0550659, "phase": "train", "update": 781, "total_env_steps": 2499200, "episode_reward": 0.3566199243068695, "value_loss": 0.008698094884554546, "policy_loss": -0.011396142604268297, "dist_entropy": 0.5854066212972006, "actor_grad_norm": 0.1434190571308136, "critic_grad_norm": 0.041479066014289856, "ratio": 1.0000051259994507, "entropy": 0.5854066212972006, "incre_win_rate": 0.8793103448275862, "step": 781}
{"time": 1766589071.0274658, "phase": "eval", "update": 781, "total_env_steps": 2499200, "eval_win_rate": 1.0, "eval_episode_reward": 20.002604166666664, "step": 781}
{"time": 1766589075.7434618, "phase": "train", "update": 782, "total_env_steps": 2502400, "episode_reward": 0.35066866874694824, "value_loss": 0.010363724951942762, "policy_loss": -0.012144199014346668, "dist_entropy": 0.6031967401504517, "actor_grad_norm": 0.13380612432956696, "critic_grad_norm": 0.017136018723249435, "ratio": 0.9990501403808594, "entropy": 0.6031967401504517, "incre_win_rate": 0.85, "step": 782}
{"time": 1766589080.5745406, "phase": "train", "update": 783, "total_env_steps": 2505600, "episode_reward": 0.3578331768512726, "value_loss": 0.006926319903383652, "policy_loss": -0.01237670703612442, "dist_entropy": 0.5919877688090006, "actor_grad_norm": 0.17741690576076508, "critic_grad_norm": 0.013722017407417297, "ratio": 0.9989861249923706, "entropy": 0.5919877688090006, "incre_win_rate": 0.896551724137931, "step": 783}
{"time": 1766589085.2500408, "phase": "train", "update": 784, "total_env_steps": 2508800, "episode_reward": 0.36140549182891846, "value_loss": 0.007539861307789882, "policy_loss": -0.01104562939448493, "dist_entropy": 0.580668032169342, "actor_grad_norm": 0.17600764334201813, "critic_grad_norm": 0.015329035930335522, "ratio": 0.9996028542518616, "entropy": 0.580668032169342, "incre_win_rate": 0.8813559322033898, "step": 784}
{"time": 1766589089.921667, "phase": "train", "update": 785, "total_env_steps": 2512000, "episode_reward": 0.36321157217025757, "value_loss": 0.006735368383427461, "policy_loss": -0.011045240202821145, "dist_entropy": 0.5923297484715779, "actor_grad_norm": 0.15371574461460114, "critic_grad_norm": 0.017689039930701256, "ratio": 0.9999753832817078, "entropy": 0.5923297484715779, "incre_win_rate": 0.8833333333333333, "step": 785}
{"time": 1766589094.7384167, "phase": "train", "update": 786, "total_env_steps": 2515200, "episode_reward": 0.35872700810432434, "value_loss": 0.007852001860737801, "policy_loss": -0.010777361423978012, "dist_entropy": 0.577075183391571, "actor_grad_norm": 0.16265854239463806, "critic_grad_norm": 0.03281330689787865, "ratio": 1.0014594793319702, "entropy": 0.577075183391571, "incre_win_rate": 0.85, "step": 786}
{"time": 1766589099.5361438, "phase": "train", "update": 787, "total_env_steps": 2518400, "episode_reward": 0.363709419965744, "value_loss": 0.009649034651617209, "policy_loss": -0.010992178780068211, "dist_entropy": 0.5956203619639079, "actor_grad_norm": 0.1557130217552185, "critic_grad_norm": 0.020375363528728485, "ratio": 0.9993141293525696, "entropy": 0.5956203619639079, "incre_win_rate": 0.8666666666666667, "step": 787}
{"time": 1766589104.1910853, "phase": "train", "update": 788, "total_env_steps": 2521600, "episode_reward": 0.3698391616344452, "value_loss": 0.006776108282307783, "policy_loss": -0.011404137533766819, "dist_entropy": 0.5800619920094808, "actor_grad_norm": 0.17829227447509766, "critic_grad_norm": 0.04366534203290939, "ratio": 0.9993361234664917, "entropy": 0.5800619920094808, "incre_win_rate": 0.9354838709677419, "step": 788}
{"time": 1766589108.9071286, "phase": "train", "update": 789, "total_env_steps": 2524800, "episode_reward": 0.37100720405578613, "value_loss": 0.004448684584349394, "policy_loss": -0.012112861018368015, "dist_entropy": 0.5756350874900817, "actor_grad_norm": 0.14871340990066528, "critic_grad_norm": 0.03377069532871246, "ratio": 0.9989404082298279, "entropy": 0.5756350874900817, "incre_win_rate": 0.9666666666666667, "step": 789}
{"time": 1766589113.837182, "phase": "train", "update": 790, "total_env_steps": 2528000, "episode_reward": 0.36541515588760376, "value_loss": 0.005059888213872909, "policy_loss": -0.0115776537919686, "dist_entropy": 0.5786844571431478, "actor_grad_norm": 0.13326729834079742, "critic_grad_norm": 0.01405799388885498, "ratio": 0.9999637007713318, "entropy": 0.5786844571431478, "incre_win_rate": 0.9322033898305084, "step": 790}
{"time": 1766589118.4387956, "phase": "train", "update": 791, "total_env_steps": 2531200, "episode_reward": 0.36948680877685547, "value_loss": 0.005136414710432291, "policy_loss": -0.01021289563313091, "dist_entropy": 0.556919805208842, "actor_grad_norm": 0.11664338409900665, "critic_grad_norm": 0.023288920521736145, "ratio": 0.9989318251609802, "entropy": 0.556919805208842, "incre_win_rate": 0.9344262295081968, "step": 791}
{"time": 1766589123.1242986, "phase": "train", "update": 792, "total_env_steps": 2534400, "episode_reward": 0.36326515674591064, "value_loss": 0.007773051566133896, "policy_loss": -0.011129437498063529, "dist_entropy": 0.5912144740422567, "actor_grad_norm": 0.14601892232894897, "critic_grad_norm": 0.02176625095307827, "ratio": 0.9998503923416138, "entropy": 0.5912144740422567, "incre_win_rate": 0.8666666666666667, "step": 792}
{"time": 1766589127.783375, "phase": "train", "update": 793, "total_env_steps": 2537600, "episode_reward": 0.3563694953918457, "value_loss": 0.01211179985354344, "policy_loss": -0.011184576711111541, "dist_entropy": 0.5678530772527058, "actor_grad_norm": 0.15970192849636078, "critic_grad_norm": 0.04296761006116867, "ratio": 1.000035047531128, "entropy": 0.5678530772527058, "incre_win_rate": 0.8666666666666667, "step": 793}
{"time": 1766589132.4233522, "phase": "train", "update": 794, "total_env_steps": 2540800, "episode_reward": 0.3628477454185486, "value_loss": 0.0073336844332516195, "policy_loss": -0.011208603517457998, "dist_entropy": 0.5770632306734721, "actor_grad_norm": 0.12697750329971313, "critic_grad_norm": 0.024516092613339424, "ratio": 0.998719334602356, "entropy": 0.5770632306734721, "incre_win_rate": 0.8813559322033898, "step": 794}
{"time": 1766589137.0748813, "phase": "train", "update": 795, "total_env_steps": 2544000, "episode_reward": 0.3503163456916809, "value_loss": 0.012377712378899257, "policy_loss": -0.01201504413036408, "dist_entropy": 0.594443150361379, "actor_grad_norm": 0.14829346537590027, "critic_grad_norm": 0.08906370401382446, "ratio": 1.000627040863037, "entropy": 0.594443150361379, "incre_win_rate": 0.8166666666666667, "step": 795}
{"time": 1766589141.650041, "phase": "train", "update": 796, "total_env_steps": 2547200, "episode_reward": 0.35678309202194214, "value_loss": 0.01000213585793972, "policy_loss": -0.010727704465481243, "dist_entropy": 0.5967128952344258, "actor_grad_norm": 0.1427612602710724, "critic_grad_norm": 0.04522360488772392, "ratio": 1.0013774633407593, "entropy": 0.5967128952344258, "incre_win_rate": 0.8620689655172413, "step": 796}
{"time": 1766589146.3259928, "phase": "train", "update": 797, "total_env_steps": 2550400, "episode_reward": 0.3670710623264313, "value_loss": 0.009529499523341655, "policy_loss": -0.01061760062431271, "dist_entropy": 0.6001834034919739, "actor_grad_norm": 0.13805149495601654, "critic_grad_norm": 0.03076477162539959, "ratio": 0.9999980926513672, "entropy": 0.6001834034919739, "incre_win_rate": 0.8870967741935484, "step": 797}
{"time": 1766589150.9740224, "phase": "train", "update": 798, "total_env_steps": 2553600, "episode_reward": 0.36492955684661865, "value_loss": 0.009616208324829737, "policy_loss": -0.01099641322193558, "dist_entropy": 0.5910278042157491, "actor_grad_norm": 0.12017108500003815, "critic_grad_norm": 0.01966693624854088, "ratio": 0.9984488487243652, "entropy": 0.5910278042157491, "incre_win_rate": 0.8833333333333333, "step": 798}
{"time": 1766589155.6549711, "phase": "train", "update": 799, "total_env_steps": 2556800, "episode_reward": 0.359567254781723, "value_loss": 0.008922663579384486, "policy_loss": -0.011651152675947607, "dist_entropy": 0.5985559821128845, "actor_grad_norm": 0.1484271138906479, "critic_grad_norm": 0.04499148204922676, "ratio": 0.998519778251648, "entropy": 0.5985559821128845, "incre_win_rate": 0.9152542372881356, "step": 799}
{"time": 1766589160.3104293, "phase": "train", "update": 800, "total_env_steps": 2560000, "episode_reward": 0.35146063566207886, "value_loss": 0.007132656499743461, "policy_loss": -0.01173726909499256, "dist_entropy": 0.5907378236452738, "actor_grad_norm": 0.13789361715316772, "critic_grad_norm": 0.02574089542031288, "ratio": 0.9999838471412659, "entropy": 0.5907378236452738, "incre_win_rate": 0.8947368421052632, "step": 800}
{"time": 1766589164.9450011, "phase": "train", "update": 801, "total_env_steps": 2563200, "episode_reward": 0.3590196371078491, "value_loss": 0.009577836282551289, "policy_loss": -0.01289344404604833, "dist_entropy": 0.5912667075792949, "actor_grad_norm": 0.14571408927440643, "critic_grad_norm": 0.013759654946625233, "ratio": 0.9997881650924683, "entropy": 0.5912667075792949, "incre_win_rate": 0.8833333333333333, "step": 801}
{"time": 1766589171.9320016, "phase": "eval", "update": 801, "total_env_steps": 2563200, "eval_win_rate": 1.0, "eval_episode_reward": 20.004901960784316, "step": 801}
{"time": 1766589176.5925703, "phase": "train", "update": 802, "total_env_steps": 2566400, "episode_reward": 0.36090147495269775, "value_loss": 0.005627395957708359, "policy_loss": -0.01207530498546466, "dist_entropy": 0.5907259225845337, "actor_grad_norm": 0.144812673330307, "critic_grad_norm": 0.046113934367895126, "ratio": 0.9983185529708862, "entropy": 0.5907259225845337, "incre_win_rate": 0.9661016949152542, "step": 802}
{"time": 1766589181.1824343, "phase": "train", "update": 803, "total_env_steps": 2569600, "episode_reward": 0.33931219577789307, "value_loss": 0.009307815258701642, "policy_loss": -0.01116181268188304, "dist_entropy": 0.59091184536616, "actor_grad_norm": 0.14422498643398285, "critic_grad_norm": 0.013468927703797817, "ratio": 1.0006643533706665, "entropy": 0.59091184536616, "incre_win_rate": 0.8214285714285714, "step": 803}
{"time": 1766589185.8275123, "phase": "train", "update": 804, "total_env_steps": 2572800, "episode_reward": 0.344117671251297, "value_loss": 0.01357317039122184, "policy_loss": -0.012839497658775538, "dist_entropy": 0.6048821171124776, "actor_grad_norm": 0.1463395059108734, "critic_grad_norm": 0.04569091275334358, "ratio": 0.9997808933258057, "entropy": 0.6048821171124776, "incre_win_rate": 0.8305084745762712, "step": 804}
{"time": 1766589190.4531357, "phase": "train", "update": 805, "total_env_steps": 2576000, "episode_reward": 0.353859543800354, "value_loss": 0.008818029860655467, "policy_loss": -0.011851155997392955, "dist_entropy": 0.6202652613321941, "actor_grad_norm": 0.14345864951610565, "critic_grad_norm": 0.030349979177117348, "ratio": 1.000096082687378, "entropy": 0.6202652613321941, "incre_win_rate": 0.847457627118644, "step": 805}
{"time": 1766589194.9979563, "phase": "train", "update": 806, "total_env_steps": 2579200, "episode_reward": 0.3335133492946625, "value_loss": 0.010461013453702131, "policy_loss": -0.012756862276108668, "dist_entropy": 0.6133456190427145, "actor_grad_norm": 0.13400596380233765, "critic_grad_norm": 0.04304051771759987, "ratio": 0.9997290372848511, "entropy": 0.6133456190427145, "incre_win_rate": 0.8421052631578947, "step": 806}
{"time": 1766589199.6736355, "phase": "train", "update": 807, "total_env_steps": 2582400, "episode_reward": 0.3354833126068115, "value_loss": 0.014677765344580014, "policy_loss": -0.01159195634177858, "dist_entropy": 0.6104191899299621, "actor_grad_norm": 0.13322700560092926, "critic_grad_norm": 0.05410999059677124, "ratio": 1.0001108646392822, "entropy": 0.6104191899299621, "incre_win_rate": 0.75, "step": 807}
{"time": 1766589204.28301, "phase": "train", "update": 808, "total_env_steps": 2585600, "episode_reward": 0.3332207500934601, "value_loss": 0.0165673203766346, "policy_loss": -0.012379853069124636, "dist_entropy": 0.6195234616597494, "actor_grad_norm": 0.15096734464168549, "critic_grad_norm": 0.031841978430747986, "ratio": 0.9993972778320312, "entropy": 0.6195234616597494, "incre_win_rate": 0.7413793103448276, "step": 808}
{"time": 1766589208.9629123, "phase": "train", "update": 809, "total_env_steps": 2588800, "episode_reward": 0.35039445757865906, "value_loss": 0.01082237164179484, "policy_loss": -0.01174795294527525, "dist_entropy": 0.6078565279642741, "actor_grad_norm": 0.1310444474220276, "critic_grad_norm": 0.021911021322011948, "ratio": 0.9987345337867737, "entropy": 0.6078565279642741, "incre_win_rate": 0.819672131147541, "step": 809}
{"time": 1766589213.5860224, "phase": "train", "update": 810, "total_env_steps": 2592000, "episode_reward": 0.34916818141937256, "value_loss": 0.009386892182131608, "policy_loss": -0.013052095566126808, "dist_entropy": 0.6099897225697836, "actor_grad_norm": 0.16737599670886993, "critic_grad_norm": 0.07752195745706558, "ratio": 0.9988558292388916, "entropy": 0.6099897225697836, "incre_win_rate": 0.8571428571428571, "step": 810}
{"time": 1766589218.2717068, "phase": "train", "update": 811, "total_env_steps": 2595200, "episode_reward": 0.3641490340232849, "value_loss": 0.008735243479410808, "policy_loss": -0.011925016938087651, "dist_entropy": 0.6114416003227234, "actor_grad_norm": 0.15089504420757294, "critic_grad_norm": 0.030083732679486275, "ratio": 0.9988921880722046, "entropy": 0.6114416003227234, "incre_win_rate": 0.8870967741935484, "step": 811}
{"time": 1766589222.8740342, "phase": "train", "update": 812, "total_env_steps": 2598400, "episode_reward": 0.36442023515701294, "value_loss": 0.006397828397651514, "policy_loss": -0.011629764731349468, "dist_entropy": 0.6187751054763794, "actor_grad_norm": 0.12519919872283936, "critic_grad_norm": 0.032137271016836166, "ratio": 0.9991737008094788, "entropy": 0.6187751054763794, "incre_win_rate": 0.9310344827586207, "step": 812}
{"time": 1766589227.5684166, "phase": "train", "update": 813, "total_env_steps": 2601600, "episode_reward": 0.3643620014190674, "value_loss": 0.006420603146155676, "policy_loss": -0.01127625397456408, "dist_entropy": 0.6063115239143372, "actor_grad_norm": 0.1485203057527542, "critic_grad_norm": 0.019268464297056198, "ratio": 0.9999104738235474, "entropy": 0.6063115239143372, "incre_win_rate": 0.9333333333333333, "step": 813}
{"time": 1766589232.2131438, "phase": "train", "update": 814, "total_env_steps": 2604800, "episode_reward": 0.35382354259490967, "value_loss": 0.012519348661104839, "policy_loss": -0.012625991405185447, "dist_entropy": 0.6228646675745646, "actor_grad_norm": 0.14070208370685577, "critic_grad_norm": 0.07967712730169296, "ratio": 0.9993164539337158, "entropy": 0.6228646675745646, "incre_win_rate": 0.8813559322033898, "step": 814}
{"time": 1766589236.9140346, "phase": "train", "update": 815, "total_env_steps": 2608000, "episode_reward": 0.35008805990219116, "value_loss": 0.009071359721322855, "policy_loss": -0.01224363225678573, "dist_entropy": 0.605583918094635, "actor_grad_norm": 0.1376703530550003, "critic_grad_norm": 0.03085392899811268, "ratio": 0.9986966848373413, "entropy": 0.605583918094635, "incre_win_rate": 0.85, "step": 815}
{"time": 1766589262.1348314, "phase": "train", "update": 816, "total_env_steps": 2611200, "episode_reward": 0.34165826439857483, "value_loss": 0.08150090376536051, "policy_loss": -0.008529888626665639, "dist_entropy": 0.6207959810892741, "actor_grad_norm": 0.11159761995077133, "critic_grad_norm": 0.2389681041240692, "ratio": 1.0022304058074951, "entropy": 0.6207959810892741, "incre_win_rate": 0.8363636363636363, "step": 816}
{"time": 1766589266.7686856, "phase": "train", "update": 817, "total_env_steps": 2614400, "episode_reward": 0.35818323493003845, "value_loss": 0.008164392380664746, "policy_loss": -0.012993005761652654, "dist_entropy": 0.6262397329012553, "actor_grad_norm": 0.13852982223033905, "critic_grad_norm": 0.05751924589276314, "ratio": 0.998711884021759, "entropy": 0.6262397329012553, "incre_win_rate": 0.9482758620689655, "step": 817}
{"time": 1766589271.494334, "phase": "train", "update": 818, "total_env_steps": 2617600, "episode_reward": 0.35573914647102356, "value_loss": 0.007213200069963932, "policy_loss": -0.01232841280861147, "dist_entropy": 0.6150033394495646, "actor_grad_norm": 0.15351279079914093, "critic_grad_norm": 0.058708298951387405, "ratio": 0.9987426400184631, "entropy": 0.6150033394495646, "incre_win_rate": 0.847457627118644, "step": 818}
{"time": 1766589276.5141473, "phase": "train", "update": 819, "total_env_steps": 2620800, "episode_reward": 0.338651180267334, "value_loss": 0.01016565269480149, "policy_loss": -0.011766102618994504, "dist_entropy": 0.6439623236656189, "actor_grad_norm": 0.1400032490491867, "critic_grad_norm": 0.03046008199453354, "ratio": 1.0003608465194702, "entropy": 0.6439623236656189, "incre_win_rate": 0.8571428571428571, "step": 819}
{"time": 1766589281.157685, "phase": "train", "update": 820, "total_env_steps": 2624000, "episode_reward": 0.3505759835243225, "value_loss": 0.009838202347358068, "policy_loss": -0.012910241390723816, "dist_entropy": 0.6513670523961385, "actor_grad_norm": 0.17588870227336884, "critic_grad_norm": 0.01571851596236229, "ratio": 1.0003639459609985, "entropy": 0.6513670523961385, "incre_win_rate": 0.864406779661017, "step": 820}
{"time": 1766589285.7875395, "phase": "train", "update": 821, "total_env_steps": 2627200, "episode_reward": 0.34957951307296753, "value_loss": 0.007050456013530493, "policy_loss": -0.012656910021496515, "dist_entropy": 0.6417292515436809, "actor_grad_norm": 0.13555613160133362, "critic_grad_norm": 0.017621468752622604, "ratio": 1.0001455545425415, "entropy": 0.6417292515436809, "incre_win_rate": 0.8571428571428571, "step": 821}
{"time": 1766589292.8949828, "phase": "eval", "update": 821, "total_env_steps": 2627200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.832567401960784, "step": 821}
{"time": 1766589297.705722, "phase": "train", "update": 822, "total_env_steps": 2630400, "episode_reward": 0.3496277332305908, "value_loss": 0.00822152371207873, "policy_loss": -0.013011872921993491, "dist_entropy": 0.6464215358098347, "actor_grad_norm": 0.2049611657857895, "critic_grad_norm": 0.020474039018154144, "ratio": 1.0010769367218018, "entropy": 0.6464215358098347, "incre_win_rate": 0.864406779661017, "step": 822}
{"time": 1766589302.2891347, "phase": "train", "update": 823, "total_env_steps": 2633600, "episode_reward": 0.3499395251274109, "value_loss": 0.010865980200469494, "policy_loss": -0.01317931834694311, "dist_entropy": 0.6474327445030212, "actor_grad_norm": 0.2037990689277649, "critic_grad_norm": 0.018204817548394203, "ratio": 1.0000040531158447, "entropy": 0.6474327445030212, "incre_win_rate": 0.847457627118644, "step": 823}
{"time": 1766589306.9027357, "phase": "train", "update": 824, "total_env_steps": 2636800, "episode_reward": 0.3633884787559509, "value_loss": 0.00850410976757606, "policy_loss": -0.010675868117742245, "dist_entropy": 0.6314297358194987, "actor_grad_norm": 0.1443435102701187, "critic_grad_norm": 0.021346963942050934, "ratio": 0.9993372559547424, "entropy": 0.6314297358194987, "incre_win_rate": 0.8983050847457628, "step": 824}
{"time": 1766589311.513271, "phase": "train", "update": 825, "total_env_steps": 2640000, "episode_reward": 0.3490678668022156, "value_loss": 0.010696261003613473, "policy_loss": -0.012493512440893065, "dist_entropy": 0.643374502658844, "actor_grad_norm": 0.14277060329914093, "critic_grad_norm": 0.04102711006999016, "ratio": 1.0004816055297852, "entropy": 0.643374502658844, "incre_win_rate": 0.864406779661017, "step": 825}
{"time": 1766589316.1068945, "phase": "train", "update": 826, "total_env_steps": 2643200, "episode_reward": 0.3547832667827606, "value_loss": 0.008950307903190454, "policy_loss": -0.01182392032835568, "dist_entropy": 0.6348336537679037, "actor_grad_norm": 0.15051518380641937, "critic_grad_norm": 0.01510465145111084, "ratio": 1.0002236366271973, "entropy": 0.6348336537679037, "incre_win_rate": 0.8813559322033898, "step": 826}
{"time": 1766589320.702257, "phase": "train", "update": 827, "total_env_steps": 2646400, "episode_reward": 0.35482078790664673, "value_loss": 0.011427995810906092, "policy_loss": -0.01193849803316643, "dist_entropy": 0.6360939025878907, "actor_grad_norm": 0.1505160927772522, "critic_grad_norm": 0.05919460579752922, "ratio": 0.9997107982635498, "entropy": 0.6360939025878907, "incre_win_rate": 0.8813559322033898, "step": 827}
{"time": 1766589325.313637, "phase": "train", "update": 828, "total_env_steps": 2649600, "episode_reward": 0.3571522831916809, "value_loss": 0.007477902776251237, "policy_loss": -0.011680503678950297, "dist_entropy": 0.6254641016324362, "actor_grad_norm": 0.15247568488121033, "critic_grad_norm": 0.033679407089948654, "ratio": 0.9979520440101624, "entropy": 0.6254641016324362, "incre_win_rate": 0.8666666666666667, "step": 828}
{"time": 1766589329.978159, "phase": "train", "update": 829, "total_env_steps": 2652800, "episode_reward": 0.3474571108818054, "value_loss": 0.01655856774499019, "policy_loss": -0.01282346137536455, "dist_entropy": 0.6380332708358765, "actor_grad_norm": 0.16819824278354645, "critic_grad_norm": 0.049232449382543564, "ratio": 0.9995716214179993, "entropy": 0.6380332708358765, "incre_win_rate": 0.8103448275862069, "step": 829}
{"time": 1766589334.7641757, "phase": "train", "update": 830, "total_env_steps": 2656000, "episode_reward": 0.3499862253665924, "value_loss": 0.011354267286757628, "policy_loss": -0.012356052244642986, "dist_entropy": 0.6171857555707295, "actor_grad_norm": 0.16106602549552917, "critic_grad_norm": 0.04750150442123413, "ratio": 1.0005687475204468, "entropy": 0.6171857555707295, "incre_win_rate": 0.85, "step": 830}
{"time": 1766589339.4853857, "phase": "train", "update": 831, "total_env_steps": 2659200, "episode_reward": 0.3605644702911377, "value_loss": 0.007996422176559766, "policy_loss": -0.011574559133446865, "dist_entropy": 0.6139194409052531, "actor_grad_norm": 0.15736645460128784, "critic_grad_norm": 0.056352272629737854, "ratio": 0.9997588992118835, "entropy": 0.6139194409052531, "incre_win_rate": 0.896551724137931, "step": 831}
{"time": 1766589344.1543694, "phase": "train", "update": 832, "total_env_steps": 2662400, "episode_reward": 0.3646147549152374, "value_loss": 0.005053388079007467, "policy_loss": -0.012566927020961316, "dist_entropy": 0.6343105991681417, "actor_grad_norm": 0.16489996016025543, "critic_grad_norm": 0.0688895508646965, "ratio": 0.9977613091468811, "entropy": 0.6343105991681417, "incre_win_rate": 0.9482758620689655, "step": 832}
{"time": 1766589348.8400958, "phase": "train", "update": 833, "total_env_steps": 2665600, "episode_reward": 0.3608241677284241, "value_loss": 0.006520952315380176, "policy_loss": -0.010422841240145194, "dist_entropy": 0.6194715380668641, "actor_grad_norm": 0.14449597895145416, "critic_grad_norm": 0.03531424328684807, "ratio": 0.9995160102844238, "entropy": 0.6194715380668641, "incre_win_rate": 0.9344262295081968, "step": 833}
{"time": 1766589353.4896455, "phase": "train", "update": 834, "total_env_steps": 2668800, "episode_reward": 0.34591150283813477, "value_loss": 0.009008631979425748, "policy_loss": -0.011777284289074371, "dist_entropy": 0.6225428422292073, "actor_grad_norm": 0.1557001769542694, "critic_grad_norm": 0.0878954827785492, "ratio": 0.9999607801437378, "entropy": 0.6225428422292073, "incre_win_rate": 0.8421052631578947, "step": 834}
{"time": 1766589358.3236487, "phase": "train", "update": 835, "total_env_steps": 2672000, "episode_reward": 0.3448024094104767, "value_loss": 0.010100983331600826, "policy_loss": -0.013393349959857895, "dist_entropy": 0.6211773196856181, "actor_grad_norm": 0.17045849561691284, "critic_grad_norm": 0.07693969458341599, "ratio": 1.000207781791687, "entropy": 0.6211773196856181, "incre_win_rate": 0.8275862068965517, "step": 835}
{"time": 1766589363.0643165, "phase": "train", "update": 836, "total_env_steps": 2675200, "episode_reward": 0.34879979491233826, "value_loss": 0.009611858117083708, "policy_loss": -0.012530313400198168, "dist_entropy": 0.6248323877652486, "actor_grad_norm": 0.19285698235034943, "critic_grad_norm": 0.03798670321702957, "ratio": 0.9994536638259888, "entropy": 0.6248323877652486, "incre_win_rate": 0.8793103448275862, "step": 836}
{"time": 1766589368.0075138, "phase": "train", "update": 837, "total_env_steps": 2678400, "episode_reward": 0.3530024290084839, "value_loss": 0.008899720571935176, "policy_loss": -0.011905695098791587, "dist_entropy": 0.6151436527570089, "actor_grad_norm": 0.1397141069173813, "critic_grad_norm": 0.01186097040772438, "ratio": 0.9991587400436401, "entropy": 0.6151436527570089, "incre_win_rate": 0.8666666666666667, "step": 837}
{"time": 1766589372.6327474, "phase": "train", "update": 838, "total_env_steps": 2681600, "episode_reward": 0.35680073499679565, "value_loss": 0.011002298444509506, "policy_loss": -0.011217077985764944, "dist_entropy": 0.6163040002187093, "actor_grad_norm": 0.1286201924085617, "critic_grad_norm": 0.02050579898059368, "ratio": 0.9989522695541382, "entropy": 0.6163040002187093, "incre_win_rate": 0.8928571428571429, "step": 838}
{"time": 1766589377.256292, "phase": "train", "update": 839, "total_env_steps": 2684800, "episode_reward": 0.3475375473499298, "value_loss": 0.00874172660211722, "policy_loss": -0.013122544644416697, "dist_entropy": 0.6208679676055908, "actor_grad_norm": 0.17694537341594696, "critic_grad_norm": 0.022564101964235306, "ratio": 0.9996504783630371, "entropy": 0.6208679676055908, "incre_win_rate": 0.85, "step": 839}
{"time": 1766589381.9357274, "phase": "train", "update": 840, "total_env_steps": 2688000, "episode_reward": 0.34156176447868347, "value_loss": 0.009882294138272603, "policy_loss": -0.01343543753031895, "dist_entropy": 0.6523107330004374, "actor_grad_norm": 0.16158011555671692, "critic_grad_norm": 0.029637856408953667, "ratio": 0.9994862675666809, "entropy": 0.6523107330004374, "incre_win_rate": 0.8392857142857143, "step": 840}
{"time": 1766589386.5558803, "phase": "train", "update": 841, "total_env_steps": 2691200, "episode_reward": 0.3526294529438019, "value_loss": 0.007548990876724323, "policy_loss": -0.013601097047359427, "dist_entropy": 0.6407999277114869, "actor_grad_norm": 0.16669932007789612, "critic_grad_norm": 0.020793011412024498, "ratio": 0.9998161196708679, "entropy": 0.6407999277114869, "incre_win_rate": 0.85, "step": 841}
{"time": 1766589393.8693829, "phase": "eval", "update": 841, "total_env_steps": 2691200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.56847426470588, "step": 841}
{"time": 1766589398.439077, "phase": "train", "update": 842, "total_env_steps": 2694400, "episode_reward": 0.33318936824798584, "value_loss": 0.01075389962643385, "policy_loss": -0.01282120429149624, "dist_entropy": 0.6372251907984415, "actor_grad_norm": 0.18356972932815552, "critic_grad_norm": 0.018709661439061165, "ratio": 0.9998891353607178, "entropy": 0.6372251907984415, "incre_win_rate": 0.8363636363636363, "step": 842}
{"time": 1766589403.041076, "phase": "train", "update": 843, "total_env_steps": 2697600, "episode_reward": 0.3534650504589081, "value_loss": 0.009802973767121633, "policy_loss": -0.013314775212688802, "dist_entropy": 0.6292520642280579, "actor_grad_norm": 0.17361760139465332, "critic_grad_norm": 0.019936637952923775, "ratio": 0.9995508790016174, "entropy": 0.6292520642280579, "incre_win_rate": 0.8793103448275862, "step": 843}
{"time": 1766589407.6799543, "phase": "train", "update": 844, "total_env_steps": 2700800, "episode_reward": 0.34611672163009644, "value_loss": 0.010401065895954768, "policy_loss": -0.012729409741904856, "dist_entropy": 0.6343615651130676, "actor_grad_norm": 0.15074478089809418, "critic_grad_norm": 0.028877167031168938, "ratio": 1.0006707906723022, "entropy": 0.6343615651130676, "incre_win_rate": 0.8771929824561403, "step": 844}
{"time": 1766589412.3234136, "phase": "train", "update": 845, "total_env_steps": 2704000, "episode_reward": 0.3446890115737915, "value_loss": 0.01165508988002936, "policy_loss": -0.013490803967242945, "dist_entropy": 0.6251718997955322, "actor_grad_norm": 0.14641258120536804, "critic_grad_norm": 0.025728393346071243, "ratio": 1.0000379085540771, "entropy": 0.6251718997955322, "incre_win_rate": 0.8305084745762712, "step": 845}
{"time": 1766589416.897835, "phase": "train", "update": 846, "total_env_steps": 2707200, "episode_reward": 0.3475804030895233, "value_loss": 0.008497226300338905, "policy_loss": -0.013561210154926121, "dist_entropy": 0.63834148645401, "actor_grad_norm": 0.14409615099430084, "critic_grad_norm": 0.014451147988438606, "ratio": 1.000401258468628, "entropy": 0.63834148645401, "incre_win_rate": 0.875, "step": 846}
{"time": 1766589421.5593631, "phase": "train", "update": 847, "total_env_steps": 2710400, "episode_reward": 0.3290724754333496, "value_loss": 0.01125406939536333, "policy_loss": -0.012692654246293244, "dist_entropy": 0.6378561973571777, "actor_grad_norm": 0.13695737719535828, "critic_grad_norm": 0.024291086941957474, "ratio": 1.0009511709213257, "entropy": 0.6378561973571777, "incre_win_rate": 0.8363636363636363, "step": 847}
{"time": 1766589426.1457253, "phase": "train", "update": 848, "total_env_steps": 2713600, "episode_reward": 0.34684130549430847, "value_loss": 0.012023842707276345, "policy_loss": -0.013615283762512339, "dist_entropy": 0.6284584164619446, "actor_grad_norm": 0.1836334466934204, "critic_grad_norm": 0.02491564303636551, "ratio": 0.9995154142379761, "entropy": 0.6284584164619446, "incre_win_rate": 0.8333333333333334, "step": 848}
{"time": 1766589430.7580316, "phase": "train", "update": 849, "total_env_steps": 2716800, "episode_reward": 0.34440410137176514, "value_loss": 0.011877630340556304, "policy_loss": -0.012652209525638607, "dist_entropy": 0.6320087154706319, "actor_grad_norm": 0.18589867651462555, "critic_grad_norm": 0.03191712498664856, "ratio": 0.9991002678871155, "entropy": 0.6320087154706319, "incre_win_rate": 0.8448275862068966, "step": 849}
{"time": 1766589435.4876902, "phase": "train", "update": 850, "total_env_steps": 2720000, "episode_reward": 0.3440387547016144, "value_loss": 0.014063391089439391, "policy_loss": -0.012273345219544752, "dist_entropy": 0.6455063621203104, "actor_grad_norm": 0.15774720907211304, "critic_grad_norm": 0.017967358231544495, "ratio": 1.0002363920211792, "entropy": 0.6455063621203104, "incre_win_rate": 0.8947368421052632, "step": 850}
{"time": 1766589440.1298125, "phase": "train", "update": 851, "total_env_steps": 2723200, "episode_reward": 0.3266054093837738, "value_loss": 0.013462511884669463, "policy_loss": -0.012734039394842966, "dist_entropy": 0.640730082988739, "actor_grad_norm": 0.16244186460971832, "critic_grad_norm": 0.03802772983908653, "ratio": 0.9984985589981079, "entropy": 0.640730082988739, "incre_win_rate": 0.7636363636363637, "step": 851}
{"time": 1766589444.6765957, "phase": "train", "update": 852, "total_env_steps": 2726400, "episode_reward": 0.3394516110420227, "value_loss": 0.013115767824153106, "policy_loss": -0.012478344144391447, "dist_entropy": 0.6264299988746643, "actor_grad_norm": 0.1522103250026703, "critic_grad_norm": 0.02716074325144291, "ratio": 0.9996702671051025, "entropy": 0.6264299988746643, "incre_win_rate": 0.8214285714285714, "step": 852}
{"time": 1766589449.2862198, "phase": "train", "update": 853, "total_env_steps": 2729600, "episode_reward": 0.34746018052101135, "value_loss": 0.013004455777506033, "policy_loss": -0.012059113109341506, "dist_entropy": 0.6271190683046977, "actor_grad_norm": 0.14514698088169098, "critic_grad_norm": 0.0571398064494133, "ratio": 0.9985661506652832, "entropy": 0.6271190683046977, "incre_win_rate": 0.8333333333333334, "step": 853}
{"time": 1766589454.170411, "phase": "train", "update": 854, "total_env_steps": 2732800, "episode_reward": 0.3504496216773987, "value_loss": 0.010076236973206202, "policy_loss": -0.012984822821865312, "dist_entropy": 0.6330848813056946, "actor_grad_norm": 0.16536077857017517, "critic_grad_norm": 0.04954264312982559, "ratio": 0.9992191195487976, "entropy": 0.6330848813056946, "incre_win_rate": 0.9122807017543859, "step": 854}
{"time": 1766589458.8343353, "phase": "train", "update": 855, "total_env_steps": 2736000, "episode_reward": 0.33395758271217346, "value_loss": 0.015838869474828245, "policy_loss": -0.012981403237362224, "dist_entropy": 0.6142343560854594, "actor_grad_norm": 0.1497143805027008, "critic_grad_norm": 0.09449916332960129, "ratio": 0.9991415739059448, "entropy": 0.6142343560854594, "incre_win_rate": 0.7758620689655172, "step": 855}
{"time": 1766589463.4675958, "phase": "train", "update": 856, "total_env_steps": 2739200, "episode_reward": 0.32618871331214905, "value_loss": 0.014105997110406557, "policy_loss": -0.013412782620575747, "dist_entropy": 0.6296281814575195, "actor_grad_norm": 0.1772565096616745, "critic_grad_norm": 0.03103731758892536, "ratio": 0.9993310570716858, "entropy": 0.6296281814575195, "incre_win_rate": 0.8113207547169812, "step": 856}
{"time": 1766589468.0482712, "phase": "train", "update": 857, "total_env_steps": 2742400, "episode_reward": 0.33107537031173706, "value_loss": 0.009820150956511498, "policy_loss": -0.012791399626377143, "dist_entropy": 0.6090511719385783, "actor_grad_norm": 0.179909810423851, "critic_grad_norm": 0.014555183239281178, "ratio": 0.9983270168304443, "entropy": 0.6090511719385783, "incre_win_rate": 0.7931034482758621, "step": 857}
{"time": 1766589472.6670108, "phase": "train", "update": 858, "total_env_steps": 2745600, "episode_reward": 0.33139169216156006, "value_loss": 0.01066279790053765, "policy_loss": -0.013753058338815549, "dist_entropy": 0.6327489574750265, "actor_grad_norm": 0.1697293221950531, "critic_grad_norm": 0.03168183192610741, "ratio": 0.9991067051887512, "entropy": 0.6327489574750265, "incre_win_rate": 0.8363636363636363, "step": 858}
{"time": 1766589477.2366052, "phase": "train", "update": 859, "total_env_steps": 2748800, "episode_reward": 0.34399664402008057, "value_loss": 0.00888736875106891, "policy_loss": -0.012125289101637312, "dist_entropy": 0.6107727924982707, "actor_grad_norm": 0.1312665343284607, "critic_grad_norm": 0.020478280261158943, "ratio": 1.000648856163025, "entropy": 0.6107727924982707, "incre_win_rate": 0.8421052631578947, "step": 859}
{"time": 1766589481.8697703, "phase": "train", "update": 860, "total_env_steps": 2752000, "episode_reward": 0.3510071933269501, "value_loss": 0.008217611908912658, "policy_loss": -0.01185623511885107, "dist_entropy": 0.6423001050949096, "actor_grad_norm": 0.14486448466777802, "critic_grad_norm": 0.02381238341331482, "ratio": 0.999127209186554, "entropy": 0.6423001050949096, "incre_win_rate": 0.896551724137931, "step": 860}
{"time": 1766589486.4871883, "phase": "train", "update": 861, "total_env_steps": 2755200, "episode_reward": 0.34498852491378784, "value_loss": 0.007967745823164781, "policy_loss": -0.012876510309247694, "dist_entropy": 0.623232650756836, "actor_grad_norm": 0.16397054493427277, "critic_grad_norm": 0.033599603921175, "ratio": 0.9982404708862305, "entropy": 0.623232650756836, "incre_win_rate": 0.8771929824561403, "step": 861}
{"time": 1766589494.0500011, "phase": "eval", "update": 861, "total_env_steps": 2755200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.740808823529413, "step": 861}
{"time": 1766589498.6257036, "phase": "train", "update": 862, "total_env_steps": 2758400, "episode_reward": 0.34535157680511475, "value_loss": 0.007714764898022016, "policy_loss": -0.01201912305582636, "dist_entropy": 0.6218022863070171, "actor_grad_norm": 0.16988424956798553, "critic_grad_norm": 0.023081615567207336, "ratio": 0.9994741678237915, "entropy": 0.6218022863070171, "incre_win_rate": 0.9107142857142857, "step": 862}
{"time": 1766589503.2466133, "phase": "train", "update": 863, "total_env_steps": 2761600, "episode_reward": 0.3413986265659332, "value_loss": 0.011681946677466233, "policy_loss": -0.012893502019450883, "dist_entropy": 0.6310888528823853, "actor_grad_norm": 0.16123677790164948, "critic_grad_norm": 0.05463127791881561, "ratio": 0.9983835816383362, "entropy": 0.6310888528823853, "incre_win_rate": 0.8571428571428571, "step": 863}
{"time": 1766589507.8093898, "phase": "train", "update": 864, "total_env_steps": 2764800, "episode_reward": 0.35878831148147583, "value_loss": 0.006533026074369748, "policy_loss": -0.011891411945712112, "dist_entropy": 0.633954914410909, "actor_grad_norm": 0.16580261290073395, "critic_grad_norm": 0.052570004016160965, "ratio": 0.9992170333862305, "entropy": 0.633954914410909, "incre_win_rate": 0.9827586206896551, "step": 864}
{"time": 1766589512.446819, "phase": "train", "update": 865, "total_env_steps": 2768000, "episode_reward": 0.3454243242740631, "value_loss": 0.007305937819182873, "policy_loss": -0.012300805252246505, "dist_entropy": 0.626642636458079, "actor_grad_norm": 0.14816872775554657, "critic_grad_norm": 0.02982393652200699, "ratio": 0.9996829628944397, "entropy": 0.626642636458079, "incre_win_rate": 0.8813559322033898, "step": 865}
{"time": 1766589517.0635383, "phase": "train", "update": 866, "total_env_steps": 2771200, "episode_reward": 0.3409374952316284, "value_loss": 0.01088541243225336, "policy_loss": -0.011713152242320746, "dist_entropy": 0.612205159664154, "actor_grad_norm": 0.1477871984243393, "critic_grad_norm": 0.04569479078054428, "ratio": 1.0006994009017944, "entropy": 0.612205159664154, "incre_win_rate": 0.8245614035087719, "step": 866}
{"time": 1766589521.7398207, "phase": "train", "update": 867, "total_env_steps": 2774400, "episode_reward": 0.3537507951259613, "value_loss": 0.006150427274405956, "policy_loss": -0.011805394969537038, "dist_entropy": 0.6460084756215413, "actor_grad_norm": 0.14858472347259521, "critic_grad_norm": 0.018983010202646255, "ratio": 0.9989603161811829, "entropy": 0.6460084756215413, "incre_win_rate": 0.9122807017543859, "step": 867}
{"time": 1766589526.4206169, "phase": "train", "update": 868, "total_env_steps": 2777600, "episode_reward": 0.33515551686286926, "value_loss": 0.00829860456287861, "policy_loss": -0.013944862424926896, "dist_entropy": 0.6346031705538432, "actor_grad_norm": 0.15257997810840607, "critic_grad_norm": 0.025713743641972542, "ratio": 0.9987085461616516, "entropy": 0.6346031705538432, "incre_win_rate": 0.8392857142857143, "step": 868}
{"time": 1766589531.0630584, "phase": "train", "update": 869, "total_env_steps": 2780800, "episode_reward": 0.34303155541419983, "value_loss": 0.008520210906863213, "policy_loss": -0.01291504485596325, "dist_entropy": 0.6333540002504985, "actor_grad_norm": 0.17013365030288696, "critic_grad_norm": 0.02059086412191391, "ratio": 0.9988832473754883, "entropy": 0.6333540002504985, "incre_win_rate": 0.896551724137931, "step": 869}
{"time": 1766589535.633995, "phase": "train", "update": 870, "total_env_steps": 2784000, "episode_reward": 0.34154337644577026, "value_loss": 0.00786408009007573, "policy_loss": -0.012653841098648281, "dist_entropy": 0.6453547279040018, "actor_grad_norm": 0.14557820558547974, "critic_grad_norm": 0.03854889050126076, "ratio": 0.9997579455375671, "entropy": 0.6453547279040018, "incre_win_rate": 0.875, "step": 870}
{"time": 1766589540.1982412, "phase": "train", "update": 871, "total_env_steps": 2787200, "episode_reward": 0.34566789865493774, "value_loss": 0.006253840246548255, "policy_loss": -0.012347493379039539, "dist_entropy": 0.6329764644304912, "actor_grad_norm": 0.16592755913734436, "critic_grad_norm": 0.0454728789627552, "ratio": 0.9995677471160889, "entropy": 0.6329764644304912, "incre_win_rate": 0.9122807017543859, "step": 871}
{"time": 1766589544.824264, "phase": "train", "update": 872, "total_env_steps": 2790400, "episode_reward": 0.34357690811157227, "value_loss": 0.0061185235778490705, "policy_loss": -0.012488150724394131, "dist_entropy": 0.6493094404538472, "actor_grad_norm": 0.18373838067054749, "critic_grad_norm": 0.03947178274393082, "ratio": 1.000390648841858, "entropy": 0.6493094404538472, "incre_win_rate": 0.8947368421052632, "step": 872}
{"time": 1766589549.4624057, "phase": "train", "update": 873, "total_env_steps": 2793600, "episode_reward": 0.33709943294525146, "value_loss": 0.012344465404748917, "policy_loss": -0.011854470594503634, "dist_entropy": 0.6367660363515218, "actor_grad_norm": 0.14813731610774994, "critic_grad_norm": 0.03870147839188576, "ratio": 1.000664234161377, "entropy": 0.6367660363515218, "incre_win_rate": 0.8214285714285714, "step": 873}
{"time": 1766589554.1417794, "phase": "train", "update": 874, "total_env_steps": 2796800, "episode_reward": 0.3459535837173462, "value_loss": 0.00808064800997575, "policy_loss": -0.012746018312532215, "dist_entropy": 0.6325387477874755, "actor_grad_norm": 0.1399868130683899, "critic_grad_norm": 0.045742232352495193, "ratio": 0.9997961521148682, "entropy": 0.6325387477874755, "incre_win_rate": 0.875, "step": 874}
{"time": 1766589558.726243, "phase": "train", "update": 875, "total_env_steps": 2800000, "episode_reward": 0.33568933606147766, "value_loss": 0.006558590941131115, "policy_loss": -0.01315010494758216, "dist_entropy": 0.6414750734965007, "actor_grad_norm": 0.1651124656200409, "critic_grad_norm": 0.016526343300938606, "ratio": 0.9997471570968628, "entropy": 0.6414750734965007, "incre_win_rate": 0.8771929824561403, "step": 875}
{"time": 1766589563.3248365, "phase": "train", "update": 876, "total_env_steps": 2803200, "episode_reward": 0.3386373817920685, "value_loss": 0.010195359773933887, "policy_loss": -0.013234314096064992, "dist_entropy": 0.6415512522061666, "actor_grad_norm": 0.18100029230117798, "critic_grad_norm": 0.03905279189348221, "ratio": 0.9991804361343384, "entropy": 0.6415512522061666, "incre_win_rate": 0.8545454545454545, "step": 876}
{"time": 1766589567.8790743, "phase": "train", "update": 877, "total_env_steps": 2806400, "episode_reward": 0.33953356742858887, "value_loss": 0.008444374861816565, "policy_loss": -0.012921530761742161, "dist_entropy": 0.6434231758117676, "actor_grad_norm": 0.13483327627182007, "critic_grad_norm": 0.016598204150795937, "ratio": 0.9985113739967346, "entropy": 0.6434231758117676, "incre_win_rate": 0.8928571428571429, "step": 877}
{"time": 1766589572.482341, "phase": "train", "update": 878, "total_env_steps": 2809600, "episode_reward": 0.33900734782218933, "value_loss": 0.005689530198772748, "policy_loss": -0.01186345699767107, "dist_entropy": 0.6387369553248088, "actor_grad_norm": 0.15082599222660065, "critic_grad_norm": 0.009480813518166542, "ratio": 0.9999256730079651, "entropy": 0.6387369553248088, "incre_win_rate": 0.9454545454545454, "step": 878}
{"time": 1766589577.0764177, "phase": "train", "update": 879, "total_env_steps": 2812800, "episode_reward": 0.3308042585849762, "value_loss": 0.008476353343576193, "policy_loss": -0.012496580585773624, "dist_entropy": 0.6352492928504944, "actor_grad_norm": 0.1440790593624115, "critic_grad_norm": 0.02079736813902855, "ratio": 1.0003069639205933, "entropy": 0.6352492928504944, "incre_win_rate": 0.8596491228070176, "step": 879}
{"time": 1766589581.633576, "phase": "train", "update": 880, "total_env_steps": 2816000, "episode_reward": 0.3256587088108063, "value_loss": 0.012356380621592203, "policy_loss": -0.013594835788792784, "dist_entropy": 0.6518926421801249, "actor_grad_norm": 0.13310374319553375, "critic_grad_norm": 0.04121861234307289, "ratio": 0.9990796446800232, "entropy": 0.6518926421801249, "incre_win_rate": 0.7636363636363637, "step": 880}
{"time": 1766589586.2233465, "phase": "train", "update": 881, "total_env_steps": 2819200, "episode_reward": 0.32589924335479736, "value_loss": 0.009832858232160409, "policy_loss": -0.012924777924168988, "dist_entropy": 0.6463700850804647, "actor_grad_norm": 0.13316744565963745, "critic_grad_norm": 0.012266597710549831, "ratio": 0.9998942613601685, "entropy": 0.6463700850804647, "incre_win_rate": 0.8148148148148148, "step": 881}
{"time": 1766589593.7100253, "phase": "eval", "update": 881, "total_env_steps": 2819200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.88235294117647, "step": 881}
{"time": 1766589598.3536487, "phase": "train", "update": 882, "total_env_steps": 2822400, "episode_reward": 0.3224363923072815, "value_loss": 0.010311149681607882, "policy_loss": -0.013638110775229013, "dist_entropy": 0.6676332910855611, "actor_grad_norm": 0.16081596910953522, "critic_grad_norm": 0.03432755917310715, "ratio": 0.9990492463111877, "entropy": 0.6676332910855611, "incre_win_rate": 0.7678571428571429, "step": 882}
{"time": 1766589602.9605036, "phase": "train", "update": 883, "total_env_steps": 2825600, "episode_reward": 0.32971814274787903, "value_loss": 0.009452067191402118, "policy_loss": -0.012361907380698275, "dist_entropy": 0.6479174137115479, "actor_grad_norm": 0.1639324575662613, "critic_grad_norm": 0.03296542167663574, "ratio": 0.9995741248130798, "entropy": 0.6479174137115479, "incre_win_rate": 0.8545454545454545, "step": 883}
{"time": 1766589607.5320354, "phase": "train", "update": 884, "total_env_steps": 2828800, "episode_reward": 0.33403265476226807, "value_loss": 0.012095064669847489, "policy_loss": -0.012923649044324985, "dist_entropy": 0.6520670175552368, "actor_grad_norm": 0.17440424859523773, "critic_grad_norm": 0.0686362087726593, "ratio": 0.9979910850524902, "entropy": 0.6520670175552368, "incre_win_rate": 0.8727272727272727, "step": 884}
{"time": 1766589612.1146703, "phase": "train", "update": 885, "total_env_steps": 2832000, "episode_reward": 0.3269018232822418, "value_loss": 0.011171796421209971, "policy_loss": -0.01298325977304368, "dist_entropy": 0.6332403699556987, "actor_grad_norm": 0.1547001153230667, "critic_grad_norm": 0.02019026130437851, "ratio": 1.0002706050872803, "entropy": 0.6332403699556987, "incre_win_rate": 0.8181818181818182, "step": 885}
{"time": 1766589616.7237105, "phase": "train", "update": 886, "total_env_steps": 2835200, "episode_reward": 0.31589385867118835, "value_loss": 0.009576580549279849, "policy_loss": -0.013451679511979365, "dist_entropy": 0.6482858896255493, "actor_grad_norm": 0.1594516634941101, "critic_grad_norm": 0.014354470185935497, "ratio": 1.0002962350845337, "entropy": 0.6482858896255493, "incre_win_rate": 0.8518518518518519, "step": 886}
{"time": 1766589621.2259138, "phase": "train", "update": 887, "total_env_steps": 2838400, "episode_reward": 0.31623467803001404, "value_loss": 0.013282455938557784, "policy_loss": -0.01471038339298237, "dist_entropy": 0.6442421396573385, "actor_grad_norm": 0.18378756940364838, "critic_grad_norm": 0.0566573366522789, "ratio": 0.99985671043396, "entropy": 0.6442421396573385, "incre_win_rate": 0.75, "step": 887}
{"time": 1766589625.8189602, "phase": "train", "update": 888, "total_env_steps": 2841600, "episode_reward": 0.3334895670413971, "value_loss": 0.008819083993633589, "policy_loss": -0.012660363513165861, "dist_entropy": 0.6437593221664428, "actor_grad_norm": 0.20298342406749725, "critic_grad_norm": 0.03896603360772133, "ratio": 0.9985588192939758, "entropy": 0.6437593221664428, "incre_win_rate": 0.8148148148148148, "step": 888}
{"time": 1766589630.7322657, "phase": "train", "update": 889, "total_env_steps": 2844800, "episode_reward": 0.331290602684021, "value_loss": 0.01260175257921219, "policy_loss": -0.013727928896457324, "dist_entropy": 0.6399253050486247, "actor_grad_norm": 0.1933358907699585, "critic_grad_norm": 0.02626977115869522, "ratio": 0.9996756315231323, "entropy": 0.6399253050486247, "incre_win_rate": 0.8245614035087719, "step": 889}
{"time": 1766589635.779053, "phase": "train", "update": 890, "total_env_steps": 2848000, "episode_reward": 0.3375237286090851, "value_loss": 0.010702290944755078, "policy_loss": -0.012732544817505223, "dist_entropy": 0.6426848570505778, "actor_grad_norm": 0.16150756180286407, "critic_grad_norm": 0.024608740583062172, "ratio": 0.99825519323349, "entropy": 0.6426848570505778, "incre_win_rate": 0.8214285714285714, "step": 890}
{"time": 1766589640.475813, "phase": "train", "update": 891, "total_env_steps": 2851200, "episode_reward": 0.3246522843837738, "value_loss": 0.012507441950341066, "policy_loss": -0.01357215419805679, "dist_entropy": 0.6538220524787903, "actor_grad_norm": 0.1599453091621399, "critic_grad_norm": 0.03924361988902092, "ratio": 1.0001235008239746, "entropy": 0.6538220524787903, "incre_win_rate": 0.8035714285714286, "step": 891}
{"time": 1766589645.146517, "phase": "train", "update": 892, "total_env_steps": 2854400, "episode_reward": 0.3155583441257477, "value_loss": 0.011343414895236492, "policy_loss": -0.012375594538613654, "dist_entropy": 0.6460984667142232, "actor_grad_norm": 0.15667904913425446, "critic_grad_norm": 0.0493512861430645, "ratio": 0.9993621110916138, "entropy": 0.6460984667142232, "incre_win_rate": 0.7735849056603774, "step": 892}
{"time": 1766589649.772305, "phase": "train", "update": 893, "total_env_steps": 2857600, "episode_reward": 0.3334880769252777, "value_loss": 0.01246443558484316, "policy_loss": -0.013006083107914417, "dist_entropy": 0.6452406605084737, "actor_grad_norm": 0.21118366718292236, "critic_grad_norm": 0.023527896031737328, "ratio": 0.9990503787994385, "entropy": 0.6452406605084737, "incre_win_rate": 0.8035714285714286, "step": 893}
{"time": 1766589654.4296336, "phase": "train", "update": 894, "total_env_steps": 2860800, "episode_reward": 0.31281787157058716, "value_loss": 0.016507537414630253, "policy_loss": -0.013621998293152634, "dist_entropy": 0.6359971801439921, "actor_grad_norm": 0.20829838514328003, "critic_grad_norm": 0.038759563118219376, "ratio": 0.9997137784957886, "entropy": 0.6359971801439921, "incre_win_rate": 0.6607142857142857, "step": 894}
{"time": 1766589659.040401, "phase": "train", "update": 895, "total_env_steps": 2864000, "episode_reward": 0.34582722187042236, "value_loss": 0.0074259135872125626, "policy_loss": -0.01298125726480445, "dist_entropy": 0.6526422659556071, "actor_grad_norm": 0.168902188539505, "critic_grad_norm": 0.08612383157014847, "ratio": 0.9985520839691162, "entropy": 0.6526422659556071, "incre_win_rate": 0.9464285714285714, "step": 895}
{"time": 1766589663.682116, "phase": "train", "update": 896, "total_env_steps": 2867200, "episode_reward": 0.34149664640426636, "value_loss": 0.006231514985362689, "policy_loss": -0.013699130983430527, "dist_entropy": 0.6567114075024922, "actor_grad_norm": 0.16716255247592926, "critic_grad_norm": 0.03482063487172127, "ratio": 1.0002354383468628, "entropy": 0.6567114075024922, "incre_win_rate": 0.8928571428571429, "step": 896}
{"time": 1766589668.2332187, "phase": "train", "update": 897, "total_env_steps": 2870400, "episode_reward": 0.32966992259025574, "value_loss": 0.012212458625435829, "policy_loss": -0.012436982387533864, "dist_entropy": 0.6275511741638183, "actor_grad_norm": 0.1631438285112381, "critic_grad_norm": 0.06491807848215103, "ratio": 0.9987871646881104, "entropy": 0.6275511741638183, "incre_win_rate": 0.8070175438596491, "step": 897}
{"time": 1766589672.781555, "phase": "train", "update": 898, "total_env_steps": 2873600, "episode_reward": 0.3223751485347748, "value_loss": 0.013466715005536874, "policy_loss": -0.01332132342519022, "dist_entropy": 0.6721256176630656, "actor_grad_norm": 0.1646215319633484, "critic_grad_norm": 0.05792533978819847, "ratio": 0.9999836087226868, "entropy": 0.6721256176630656, "incre_win_rate": 0.7777777777777778, "step": 898}
{"time": 1766589677.5250247, "phase": "train", "update": 899, "total_env_steps": 2876800, "episode_reward": 0.3135600686073303, "value_loss": 0.01810688612361749, "policy_loss": -0.012884090566629425, "dist_entropy": 0.6672418276468913, "actor_grad_norm": 0.1640917956829071, "critic_grad_norm": 0.05709930881857872, "ratio": 1.0002046823501587, "entropy": 0.6672418276468913, "incre_win_rate": 0.7592592592592593, "step": 899}
{"time": 1766589682.1553793, "phase": "train", "update": 900, "total_env_steps": 2880000, "episode_reward": 0.3414292335510254, "value_loss": 0.010251490709682306, "policy_loss": -0.012456260365087957, "dist_entropy": 0.6338107466697693, "actor_grad_norm": 0.14787398278713226, "critic_grad_norm": 0.05465736240148544, "ratio": 0.9991885423660278, "entropy": 0.6338107466697693, "incre_win_rate": 0.8135593220338984, "step": 900}
{"time": 1766589686.796274, "phase": "train", "update": 901, "total_env_steps": 2883200, "episode_reward": 0.3374563455581665, "value_loss": 0.010699588370819886, "policy_loss": -0.013301574128018483, "dist_entropy": 0.6580746293067932, "actor_grad_norm": 0.13964498043060303, "critic_grad_norm": 0.09511753916740417, "ratio": 0.9979888796806335, "entropy": 0.6580746293067932, "incre_win_rate": 0.8928571428571429, "step": 901}
{"time": 1766589694.1208475, "phase": "eval", "update": 901, "total_env_steps": 2883200, "eval_win_rate": 1.0, "eval_episode_reward": 20.013786764705884, "step": 901}
{"time": 1766589698.683783, "phase": "train", "update": 902, "total_env_steps": 2886400, "episode_reward": 0.3404986262321472, "value_loss": 0.008950054707626501, "policy_loss": -0.013666106770665465, "dist_entropy": 0.6644945939381918, "actor_grad_norm": 0.14444993436336517, "critic_grad_norm": 0.04414832964539528, "ratio": 0.9980174899101257, "entropy": 0.6644945939381918, "incre_win_rate": 0.8421052631578947, "step": 902}
{"time": 1766589703.294174, "phase": "train", "update": 903, "total_env_steps": 2889600, "episode_reward": 0.31564801931381226, "value_loss": 0.008715970627963542, "policy_loss": -0.014060733781743195, "dist_entropy": 0.6602781375249227, "actor_grad_norm": 0.1742444932460785, "critic_grad_norm": 0.04427693411707878, "ratio": 0.9990776777267456, "entropy": 0.6602781375249227, "incre_win_rate": 0.8461538461538461, "step": 903}
{"time": 1766589707.9587374, "phase": "train", "update": 904, "total_env_steps": 2892800, "episode_reward": 0.3303599953651428, "value_loss": 0.00806410660346349, "policy_loss": -0.012271302876542715, "dist_entropy": 0.6392732421557109, "actor_grad_norm": 0.16685844957828522, "critic_grad_norm": 0.04812166467308998, "ratio": 1.0000234842300415, "entropy": 0.6392732421557109, "incre_win_rate": 0.8181818181818182, "step": 904}
{"time": 1766589712.5009625, "phase": "train", "update": 905, "total_env_steps": 2896000, "episode_reward": 0.3420052230358124, "value_loss": 0.007566647479931513, "policy_loss": -0.01390192914930542, "dist_entropy": 0.63828417857488, "actor_grad_norm": 0.17422892153263092, "critic_grad_norm": 0.026933318004012108, "ratio": 0.9999760985374451, "entropy": 0.63828417857488, "incre_win_rate": 0.9107142857142857, "step": 905}
{"time": 1766589717.165135, "phase": "train", "update": 906, "total_env_steps": 2899200, "episode_reward": 0.33802008628845215, "value_loss": 0.006735046735654274, "policy_loss": -0.0109437925841713, "dist_entropy": 0.6309095184008281, "actor_grad_norm": 0.14652211964130402, "critic_grad_norm": 0.01995004341006279, "ratio": 0.9979605674743652, "entropy": 0.6309095184008281, "incre_win_rate": 0.9464285714285714, "step": 906}
{"time": 1766589721.708794, "phase": "train", "update": 907, "total_env_steps": 2902400, "episode_reward": 0.3354833424091339, "value_loss": 0.009413657151162625, "policy_loss": -0.011782363540401757, "dist_entropy": 0.659542993704478, "actor_grad_norm": 0.16552698612213135, "critic_grad_norm": 0.0239601731300354, "ratio": 1.000008225440979, "entropy": 0.659542993704478, "incre_win_rate": 0.8727272727272727, "step": 907}
{"time": 1766589726.3667274, "phase": "train", "update": 908, "total_env_steps": 2905600, "episode_reward": 0.32541435956954956, "value_loss": 0.008910971196989219, "policy_loss": -0.013318491915801664, "dist_entropy": 0.6601606408754984, "actor_grad_norm": 0.17102688550949097, "critic_grad_norm": 0.019633332267403603, "ratio": 0.998948872089386, "entropy": 0.6601606408754984, "incre_win_rate": 0.8333333333333334, "step": 908}
{"time": 1766589730.9992647, "phase": "train", "update": 909, "total_env_steps": 2908800, "episode_reward": 0.34213849902153015, "value_loss": 0.00624620212862889, "policy_loss": -0.011982249154183519, "dist_entropy": 0.6430478096008301, "actor_grad_norm": 0.17502674460411072, "critic_grad_norm": 0.041044238954782486, "ratio": 0.9998063445091248, "entropy": 0.6430478096008301, "incre_win_rate": 0.9454545454545454, "step": 909}
{"time": 1766589735.591557, "phase": "train", "update": 910, "total_env_steps": 2912000, "episode_reward": 0.34177008271217346, "value_loss": 0.006957836324969927, "policy_loss": -0.010731179078793692, "dist_entropy": 0.6217476725578308, "actor_grad_norm": 0.1516193002462387, "critic_grad_norm": 0.024277180433273315, "ratio": 1.0000317096710205, "entropy": 0.6217476725578308, "incre_win_rate": 0.8928571428571429, "step": 910}
{"time": 1766589740.1575766, "phase": "train", "update": 911, "total_env_steps": 2915200, "episode_reward": 0.33731696009635925, "value_loss": 0.010122568036119143, "policy_loss": -0.011976848138071242, "dist_entropy": 0.6274291594823201, "actor_grad_norm": 0.15607139468193054, "critic_grad_norm": 0.06310229003429413, "ratio": 1.0000784397125244, "entropy": 0.6274291594823201, "incre_win_rate": 0.8275862068965517, "step": 911}
{"time": 1766589744.7618148, "phase": "train", "update": 912, "total_env_steps": 2918400, "episode_reward": 0.3447181284427643, "value_loss": 0.0072803379346927, "policy_loss": -0.01156186905736547, "dist_entropy": 0.6307670752207438, "actor_grad_norm": 0.17224574089050293, "critic_grad_norm": 0.02444688230752945, "ratio": 1.0005637407302856, "entropy": 0.6307670752207438, "incre_win_rate": 0.8947368421052632, "step": 912}
{"time": 1766589749.4099615, "phase": "train", "update": 913, "total_env_steps": 2921600, "episode_reward": 0.33945927023887634, "value_loss": 0.009248129340509574, "policy_loss": -0.012291373685245806, "dist_entropy": 0.6280475417772929, "actor_grad_norm": 0.15711508691310883, "critic_grad_norm": 0.02590307965874672, "ratio": 1.000112771987915, "entropy": 0.6280475417772929, "incre_win_rate": 0.8596491228070176, "step": 913}
{"time": 1766589754.0278883, "phase": "train", "update": 914, "total_env_steps": 2924800, "episode_reward": 0.3429373800754547, "value_loss": 0.005605185373375813, "policy_loss": -0.0119047849847977, "dist_entropy": 0.6422073602676391, "actor_grad_norm": 0.15701650083065033, "critic_grad_norm": 0.027142325416207314, "ratio": 0.9987645745277405, "entropy": 0.6422073602676391, "incre_win_rate": 0.9074074074074074, "step": 914}
{"time": 1766589758.68935, "phase": "train", "update": 915, "total_env_steps": 2928000, "episode_reward": 0.3441360592842102, "value_loss": 0.00969925131648779, "policy_loss": -0.012708330944395147, "dist_entropy": 0.6254299879074097, "actor_grad_norm": 0.1743878722190857, "critic_grad_norm": 0.030714277178049088, "ratio": 0.9999483823776245, "entropy": 0.6254299879074097, "incre_win_rate": 0.8947368421052632, "step": 915}
{"time": 1766589763.54479, "phase": "train", "update": 916, "total_env_steps": 2931200, "episode_reward": 0.33357617259025574, "value_loss": 0.00856784296532472, "policy_loss": -0.013103362247549674, "dist_entropy": 0.6368644793828329, "actor_grad_norm": 0.16489803791046143, "critic_grad_norm": 0.01723281294107437, "ratio": 0.9998111724853516, "entropy": 0.6368644793828329, "incre_win_rate": 0.8571428571428571, "step": 916}
{"time": 1766589768.2957098, "phase": "train", "update": 917, "total_env_steps": 2934400, "episode_reward": 0.3348246216773987, "value_loss": 0.009288662237425645, "policy_loss": -0.012844804877007713, "dist_entropy": 0.6482369860013326, "actor_grad_norm": 0.19578953087329865, "critic_grad_norm": 0.018592169508337975, "ratio": 1.0000425577163696, "entropy": 0.6482369860013326, "incre_win_rate": 0.8909090909090909, "step": 917}
{"time": 1766589772.9247522, "phase": "train", "update": 918, "total_env_steps": 2937600, "episode_reward": 0.34053999185562134, "value_loss": 0.006739478837698698, "policy_loss": -0.011987358594924538, "dist_entropy": 0.6164779702822367, "actor_grad_norm": 0.17802293598651886, "critic_grad_norm": 0.039607319980859756, "ratio": 0.9998762607574463, "entropy": 0.6164779702822367, "incre_win_rate": 0.8928571428571429, "step": 918}
{"time": 1766589777.8435028, "phase": "train", "update": 919, "total_env_steps": 2940800, "episode_reward": 0.33542969822883606, "value_loss": 0.007209493530293306, "policy_loss": -0.011563955377603937, "dist_entropy": 0.6054985324541727, "actor_grad_norm": 0.1449553370475769, "critic_grad_norm": 0.033039651811122894, "ratio": 0.9984588027000427, "entropy": 0.6054985324541727, "incre_win_rate": 0.9090909090909091, "step": 919}
{"time": 1766589782.6284947, "phase": "train", "update": 920, "total_env_steps": 2944000, "episode_reward": 0.3552887737751007, "value_loss": 0.007229588398089012, "policy_loss": -0.009994459478632785, "dist_entropy": 0.6189484159151714, "actor_grad_norm": 0.1216905266046524, "critic_grad_norm": 0.01814640872180462, "ratio": 0.9990271925926208, "entropy": 0.6189484159151714, "incre_win_rate": 0.9166666666666666, "step": 920}
{"time": 1766589787.5153573, "phase": "train", "update": 921, "total_env_steps": 2947200, "episode_reward": 0.35335323214530945, "value_loss": 0.0070800933676461375, "policy_loss": -0.011138269111358075, "dist_entropy": 0.6197396437327067, "actor_grad_norm": 0.14651605486869812, "critic_grad_norm": 0.022181563079357147, "ratio": 0.9998748898506165, "entropy": 0.6197396437327067, "incre_win_rate": 0.8947368421052632, "step": 921}
{"time": 1766589794.9994178, "phase": "eval", "update": 921, "total_env_steps": 2947200, "eval_win_rate": 1.0, "eval_episode_reward": 20.0093443627451, "step": 921}
{"time": 1766589799.6522202, "phase": "train", "update": 922, "total_env_steps": 2950400, "episode_reward": 0.34597042202949524, "value_loss": 0.006410092456887165, "policy_loss": -0.012515018754437316, "dist_entropy": 0.6257959286371867, "actor_grad_norm": 0.13766416907310486, "critic_grad_norm": 0.021634135395288467, "ratio": 0.9998136162757874, "entropy": 0.6257959286371867, "incre_win_rate": 0.9285714285714286, "step": 922}
{"time": 1766589804.4061115, "phase": "train", "update": 923, "total_env_steps": 2953600, "episode_reward": 0.34373778104782104, "value_loss": 0.006537333720674118, "policy_loss": -0.011601760486622462, "dist_entropy": 0.6226784269014994, "actor_grad_norm": 0.12939901649951935, "critic_grad_norm": 0.028987914323806763, "ratio": 0.9998505711555481, "entropy": 0.6226784269014994, "incre_win_rate": 0.9285714285714286, "step": 923}
{"time": 1766589809.1510994, "phase": "train", "update": 924, "total_env_steps": 2956800, "episode_reward": 0.35133808851242065, "value_loss": 0.005339731027682622, "policy_loss": -0.011698955410147486, "dist_entropy": 0.6260802110036214, "actor_grad_norm": 0.1476586014032364, "critic_grad_norm": 0.015072167851030827, "ratio": 1.0003836154937744, "entropy": 0.6260802110036214, "incre_win_rate": 0.8983050847457628, "step": 924}
{"time": 1766589813.8233652, "phase": "train", "update": 925, "total_env_steps": 2960000, "episode_reward": 0.3432115614414215, "value_loss": 0.010033879180749257, "policy_loss": -0.012603970735684318, "dist_entropy": 0.6062299331029256, "actor_grad_norm": 0.1520576775074005, "critic_grad_norm": 0.021312903612852097, "ratio": 0.9987830519676208, "entropy": 0.6062299331029256, "incre_win_rate": 0.9090909090909091, "step": 925}
{"time": 1766589818.5455894, "phase": "train", "update": 926, "total_env_steps": 2963200, "episode_reward": 0.359846830368042, "value_loss": 0.005051886476576328, "policy_loss": -0.01101897267021883, "dist_entropy": 0.6166444341341655, "actor_grad_norm": 0.14073807001113892, "critic_grad_norm": 0.036517541855573654, "ratio": 1.0001081228256226, "entropy": 0.6166444341341655, "incre_win_rate": 0.9666666666666667, "step": 926}
{"time": 1766589823.1979728, "phase": "train", "update": 927, "total_env_steps": 2966400, "episode_reward": 0.3376631438732147, "value_loss": 0.009107854093114535, "policy_loss": -0.012399045407422211, "dist_entropy": 0.5993779341379801, "actor_grad_norm": 0.14397868514060974, "critic_grad_norm": 0.024554315954446793, "ratio": 1.0003877878189087, "entropy": 0.5993779341379801, "incre_win_rate": 0.875, "step": 927}
{"time": 1766589827.9315062, "phase": "train", "update": 928, "total_env_steps": 2969600, "episode_reward": 0.3642440140247345, "value_loss": 0.0035706716279188793, "policy_loss": -0.010850781530053647, "dist_entropy": 0.6176602323849996, "actor_grad_norm": 0.14105157554149628, "critic_grad_norm": 0.03534846007823944, "ratio": 0.9997222423553467, "entropy": 0.6176602323849996, "incre_win_rate": 0.9827586206896551, "step": 928}
{"time": 1766589832.5792568, "phase": "train", "update": 929, "total_env_steps": 2972800, "episode_reward": 0.3538541793823242, "value_loss": 0.004111828422173858, "policy_loss": -0.012092620623620102, "dist_entropy": 0.6079192996025086, "actor_grad_norm": 0.15476325154304504, "critic_grad_norm": 0.015480652451515198, "ratio": 0.9997257590293884, "entropy": 0.6079192996025086, "incre_win_rate": 0.9473684210526315, "step": 929}
{"time": 1766589837.210651, "phase": "train", "update": 930, "total_env_steps": 2976000, "episode_reward": 0.3596384823322296, "value_loss": 0.002908070416500171, "policy_loss": -0.011357713321585076, "dist_entropy": 0.6294790784517924, "actor_grad_norm": 0.16404695808887482, "critic_grad_norm": 0.01985527016222477, "ratio": 1.000171422958374, "entropy": 0.6294790784517924, "incre_win_rate": 0.9482758620689655, "step": 930}
{"time": 1766589841.7940311, "phase": "train", "update": 931, "total_env_steps": 2979200, "episode_reward": 0.361672043800354, "value_loss": 0.004026580788195133, "policy_loss": -0.010135267117563747, "dist_entropy": 0.6010058879852295, "actor_grad_norm": 0.1414160430431366, "critic_grad_norm": 0.011615818366408348, "ratio": 1.000135064125061, "entropy": 0.6010058879852295, "incre_win_rate": 0.9827586206896551, "step": 931}
{"time": 1766589846.37999, "phase": "train", "update": 932, "total_env_steps": 2982400, "episode_reward": 0.34376612305641174, "value_loss": 0.009996633231639861, "policy_loss": -0.011664895130095705, "dist_entropy": 0.5898370504379272, "actor_grad_norm": 0.14008711278438568, "critic_grad_norm": 0.07880213111639023, "ratio": 1.0009242296218872, "entropy": 0.5898370504379272, "incre_win_rate": 0.8275862068965517, "step": 932}
{"time": 1766589851.043598, "phase": "train", "update": 933, "total_env_steps": 2985600, "episode_reward": 0.34460246562957764, "value_loss": 0.007265080542614062, "policy_loss": -0.01112779846391921, "dist_entropy": 0.6233906388282776, "actor_grad_norm": 0.13814836740493774, "critic_grad_norm": 0.04517841339111328, "ratio": 1.0003745555877686, "entropy": 0.6233906388282776, "incre_win_rate": 0.9122807017543859, "step": 933}
{"time": 1766589855.6495383, "phase": "train", "update": 934, "total_env_steps": 2988800, "episode_reward": 0.35982614755630493, "value_loss": 0.0040988390178730095, "policy_loss": -0.011590137167329337, "dist_entropy": 0.5957584818204243, "actor_grad_norm": 0.14632607996463776, "critic_grad_norm": 0.02832755260169506, "ratio": 0.9999856948852539, "entropy": 0.5957584818204243, "incre_win_rate": 0.9473684210526315, "step": 934}
{"time": 1766589860.3420608, "phase": "train", "update": 935, "total_env_steps": 2992000, "episode_reward": 0.359406441450119, "value_loss": 0.005032378093649943, "policy_loss": -0.012046465105929846, "dist_entropy": 0.6091981490453084, "actor_grad_norm": 0.12931028008460999, "critic_grad_norm": 0.029933664947748184, "ratio": 0.999286949634552, "entropy": 0.6091981490453084, "incre_win_rate": 0.9322033898305084, "step": 935}
{"time": 1766589864.9199827, "phase": "train", "update": 936, "total_env_steps": 2995200, "episode_reward": 0.3585960566997528, "value_loss": 0.007242436365534862, "policy_loss": -0.010182982913611246, "dist_entropy": 0.6079367915789287, "actor_grad_norm": 0.12447935342788696, "critic_grad_norm": 0.023572109639644623, "ratio": 1.000599980354309, "entropy": 0.6079367915789287, "incre_win_rate": 0.9, "step": 936}
{"time": 1766589869.5718505, "phase": "train", "update": 937, "total_env_steps": 2998400, "episode_reward": 0.3475046455860138, "value_loss": 0.006595585836718479, "policy_loss": -0.01205777122834301, "dist_entropy": 0.6040419220924378, "actor_grad_norm": 0.1377788633108139, "critic_grad_norm": 0.01463514007627964, "ratio": 0.999596357345581, "entropy": 0.6040419220924378, "incre_win_rate": 0.8771929824561403, "step": 937}
{"time": 1766589874.1941679, "phase": "train", "update": 938, "total_env_steps": 3001600, "episode_reward": 0.35496705770492554, "value_loss": 0.008692438465853531, "policy_loss": -0.012447550353910704, "dist_entropy": 0.6152724583943685, "actor_grad_norm": 0.14855466783046722, "critic_grad_norm": 0.01733040064573288, "ratio": 0.9983623027801514, "entropy": 0.6152724583943685, "incre_win_rate": 0.9152542372881356, "step": 938}
{"time": 1766589878.810214, "phase": "train", "update": 939, "total_env_steps": 3004800, "episode_reward": 0.36381664872169495, "value_loss": 0.005433494752893845, "policy_loss": -0.011617301678004092, "dist_entropy": 0.5855424960454305, "actor_grad_norm": 0.15249724686145782, "critic_grad_norm": 0.040193308144807816, "ratio": 0.9990440011024475, "entropy": 0.5855424960454305, "incre_win_rate": 0.9482758620689655, "step": 939}
{"time": 1766589883.427528, "phase": "train", "update": 940, "total_env_steps": 3008000, "episode_reward": 0.34865275025367737, "value_loss": 0.010756354530652363, "policy_loss": -0.010946250413074192, "dist_entropy": 0.5935336391131083, "actor_grad_norm": 0.1578545719385147, "critic_grad_norm": 0.048059623688459396, "ratio": 0.9993839263916016, "entropy": 0.5935336391131083, "incre_win_rate": 0.864406779661017, "step": 940}
{"time": 1766589888.0501142, "phase": "train", "update": 941, "total_env_steps": 3011200, "episode_reward": 0.357866108417511, "value_loss": 0.003976690350100398, "policy_loss": -0.013126187916386792, "dist_entropy": 0.6030241648356119, "actor_grad_norm": 0.15278373658657074, "critic_grad_norm": 0.040874991565942764, "ratio": 0.999622642993927, "entropy": 0.6030241648356119, "incre_win_rate": 0.9649122807017544, "step": 941}
{"time": 1766589895.5482056, "phase": "eval", "update": 941, "total_env_steps": 3011200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.813036151960784, "step": 941}
{"time": 1766589900.3461962, "phase": "train", "update": 942, "total_env_steps": 3014400, "episode_reward": 0.3595021367073059, "value_loss": 0.007229376398026943, "policy_loss": -0.010973481672470342, "dist_entropy": 0.6002426703770956, "actor_grad_norm": 0.1387500762939453, "critic_grad_norm": 0.05166073516011238, "ratio": 1.0003626346588135, "entropy": 0.6002426703770956, "incre_win_rate": 0.9152542372881356, "step": 942}
{"time": 1766589904.966277, "phase": "train", "update": 943, "total_env_steps": 3017600, "episode_reward": 0.356765478849411, "value_loss": 0.006179391903181871, "policy_loss": -0.012074562496065274, "dist_entropy": 0.6034376502037049, "actor_grad_norm": 0.1444762796163559, "critic_grad_norm": 0.046781305223703384, "ratio": 0.9990810751914978, "entropy": 0.6034376502037049, "incre_win_rate": 0.9333333333333333, "step": 943}
{"time": 1766589909.6450381, "phase": "train", "update": 944, "total_env_steps": 3020800, "episode_reward": 0.358270525932312, "value_loss": 0.008020290452986956, "policy_loss": -0.011665514757702056, "dist_entropy": 0.6190545558929443, "actor_grad_norm": 0.13200882077217102, "critic_grad_norm": 0.03552545979619026, "ratio": 0.9996861219406128, "entropy": 0.6190545558929443, "incre_win_rate": 0.864406779661017, "step": 944}
{"time": 1766589914.2502248, "phase": "train", "update": 945, "total_env_steps": 3024000, "episode_reward": 0.3592180013656616, "value_loss": 0.006920204373697439, "policy_loss": -0.012141750056984554, "dist_entropy": 0.5881525039672851, "actor_grad_norm": 0.16140928864479065, "critic_grad_norm": 0.0188114233314991, "ratio": 0.999747633934021, "entropy": 0.5881525039672851, "incre_win_rate": 0.9473684210526315, "step": 945}
{"time": 1766589918.904057, "phase": "train", "update": 946, "total_env_steps": 3027200, "episode_reward": 0.3529151380062103, "value_loss": 0.006844153379400571, "policy_loss": -0.011794883194498122, "dist_entropy": 0.6023377656936646, "actor_grad_norm": 0.15892671048641205, "critic_grad_norm": 0.020370347425341606, "ratio": 1.0003222227096558, "entropy": 0.6023377656936646, "incre_win_rate": 0.8983050847457628, "step": 946}
{"time": 1766589923.5992672, "phase": "train", "update": 947, "total_env_steps": 3030400, "episode_reward": 0.35483765602111816, "value_loss": 0.006784420056889454, "policy_loss": -0.01172725938507142, "dist_entropy": 0.5982980887095134, "actor_grad_norm": 0.14638738334178925, "critic_grad_norm": 0.01578698121011257, "ratio": 1.0004087686538696, "entropy": 0.5982980887095134, "incre_win_rate": 0.8813559322033898, "step": 947}
{"time": 1766589928.1542242, "phase": "train", "update": 948, "total_env_steps": 3033600, "episode_reward": 0.3566000461578369, "value_loss": 0.008450176442662875, "policy_loss": -0.012125850866606714, "dist_entropy": 0.5932744423548381, "actor_grad_norm": 0.14579766988754272, "critic_grad_norm": 0.014090531505644321, "ratio": 0.9988681674003601, "entropy": 0.5932744423548381, "incre_win_rate": 0.8793103448275862, "step": 948}
{"time": 1766589932.8258367, "phase": "train", "update": 949, "total_env_steps": 3036800, "episode_reward": 0.340291827917099, "value_loss": 0.01054721511900425, "policy_loss": -0.012501471842176553, "dist_entropy": 0.6127962787946065, "actor_grad_norm": 0.15121005475521088, "critic_grad_norm": 0.0144474683329463, "ratio": 1.0005570650100708, "entropy": 0.6127962787946065, "incre_win_rate": 0.8421052631578947, "step": 949}
{"time": 1766589937.4033458, "phase": "train", "update": 950, "total_env_steps": 3040000, "episode_reward": 0.34395909309387207, "value_loss": 0.007793856194863716, "policy_loss": -0.011762130585698099, "dist_entropy": 0.6169447660446167, "actor_grad_norm": 0.13455945253372192, "critic_grad_norm": 0.018130553886294365, "ratio": 0.9997199177742004, "entropy": 0.6169447660446167, "incre_win_rate": 0.8275862068965517, "step": 950}
{"time": 1766589942.0724192, "phase": "train", "update": 951, "total_env_steps": 3043200, "episode_reward": 0.33825597167015076, "value_loss": 0.011896987942357858, "policy_loss": -0.012684682582873445, "dist_entropy": 0.6070516149202982, "actor_grad_norm": 0.14267408847808838, "critic_grad_norm": 0.02634252980351448, "ratio": 0.9999829530715942, "entropy": 0.6070516149202982, "incre_win_rate": 0.8392857142857143, "step": 951}
{"time": 1766589946.736468, "phase": "train", "update": 952, "total_env_steps": 3046400, "episode_reward": 0.34787681698799133, "value_loss": 0.010004404559731483, "policy_loss": -0.012746865819807832, "dist_entropy": 0.5989047129948933, "actor_grad_norm": 0.13285505771636963, "critic_grad_norm": 0.01740952953696251, "ratio": 0.9992361068725586, "entropy": 0.5989047129948933, "incre_win_rate": 0.8333333333333334, "step": 952}
{"time": 1766589951.4070466, "phase": "train", "update": 953, "total_env_steps": 3049600, "episode_reward": 0.33645910024642944, "value_loss": 0.014484449351827303, "policy_loss": -0.013062982542642487, "dist_entropy": 0.5990500529607137, "actor_grad_norm": 0.18078723549842834, "critic_grad_norm": 0.07726040482521057, "ratio": 1.0001732110977173, "entropy": 0.5990500529607137, "incre_win_rate": 0.7796610169491526, "step": 953}
{"time": 1766589956.0029585, "phase": "train", "update": 954, "total_env_steps": 3052800, "episode_reward": 0.3394714891910553, "value_loss": 0.011210515288015206, "policy_loss": -0.012388426691719209, "dist_entropy": 0.5890169898668925, "actor_grad_norm": 0.20312932133674622, "critic_grad_norm": 0.01926959864795208, "ratio": 0.9994795918464661, "entropy": 0.5890169898668925, "incre_win_rate": 0.7857142857142857, "step": 954}
{"time": 1766589960.630719, "phase": "train", "update": 955, "total_env_steps": 3056000, "episode_reward": 0.3480384647846222, "value_loss": 0.010715478658676147, "policy_loss": -0.012065346827572892, "dist_entropy": 0.610296889146169, "actor_grad_norm": 0.15997639298439026, "critic_grad_norm": 0.0398327074944973, "ratio": 0.9984354376792908, "entropy": 0.610296889146169, "incre_win_rate": 0.8620689655172413, "step": 955}
{"time": 1766589965.3187912, "phase": "train", "update": 956, "total_env_steps": 3059200, "episode_reward": 0.3475428819656372, "value_loss": 0.010735561201969782, "policy_loss": -0.011855569688160964, "dist_entropy": 0.6163414676984151, "actor_grad_norm": 0.15427710115909576, "critic_grad_norm": 0.02163957804441452, "ratio": 0.9996784329414368, "entropy": 0.6163414676984151, "incre_win_rate": 0.8620689655172413, "step": 956}
{"time": 1766589969.9350424, "phase": "train", "update": 957, "total_env_steps": 3062400, "episode_reward": 0.3458578586578369, "value_loss": 0.010833235581715901, "policy_loss": -0.012366682009331716, "dist_entropy": 0.6319312731424968, "actor_grad_norm": 0.15115511417388916, "critic_grad_norm": 0.03286559507250786, "ratio": 0.9997079372406006, "entropy": 0.6319312731424968, "incre_win_rate": 0.9107142857142857, "step": 957}
{"time": 1766589974.6127987, "phase": "train", "update": 958, "total_env_steps": 3065600, "episode_reward": 0.34686505794525146, "value_loss": 0.011304117366671562, "policy_loss": -0.012381724403920913, "dist_entropy": 0.610760756333669, "actor_grad_norm": 0.18215610086917877, "critic_grad_norm": 0.023080917075276375, "ratio": 1.0001448392868042, "entropy": 0.610760756333669, "incre_win_rate": 0.8166666666666667, "step": 958}
{"time": 1766589979.27237, "phase": "train", "update": 959, "total_env_steps": 3068800, "episode_reward": 0.3449234366416931, "value_loss": 0.007581482455134392, "policy_loss": -0.012911127175596941, "dist_entropy": 0.6191759943962097, "actor_grad_norm": 0.18951316177845, "critic_grad_norm": 0.019765788689255714, "ratio": 0.9992607235908508, "entropy": 0.6191759943962097, "incre_win_rate": 0.8928571428571429, "step": 959}
{"time": 1766589984.0086129, "phase": "train", "update": 960, "total_env_steps": 3072000, "episode_reward": 0.3616590201854706, "value_loss": 0.0052202725782990456, "policy_loss": -0.01169369196260952, "dist_entropy": 0.5922914306322734, "actor_grad_norm": 0.1594342738389969, "critic_grad_norm": 0.04008059948682785, "ratio": 1.0001922845840454, "entropy": 0.5922914306322734, "incre_win_rate": 0.9322033898305084, "step": 960}
{"time": 1766589988.5623693, "phase": "train", "update": 961, "total_env_steps": 3075200, "episode_reward": 0.3543175756931305, "value_loss": 0.006777452025562525, "policy_loss": -0.01141681721108417, "dist_entropy": 0.6112804253896077, "actor_grad_norm": 0.13631875813007355, "critic_grad_norm": 0.01743282377719879, "ratio": 0.9997584819793701, "entropy": 0.6112804253896077, "incre_win_rate": 0.9137931034482759, "step": 961}
{"time": 1766589995.734734, "phase": "eval", "update": 961, "total_env_steps": 3075200, "eval_win_rate": 1.0, "eval_episode_reward": 20.004748774509803, "step": 961}
{"time": 1766590000.3538582, "phase": "train", "update": 962, "total_env_steps": 3078400, "episode_reward": 0.3521997630596161, "value_loss": 0.007707798729340235, "policy_loss": -0.011463152496165207, "dist_entropy": 0.5973756114641825, "actor_grad_norm": 0.14603058993816376, "critic_grad_norm": 0.010637504979968071, "ratio": 0.9998220205307007, "entropy": 0.5973756114641825, "incre_win_rate": 0.9137931034482759, "step": 962}
{"time": 1766590004.981558, "phase": "train", "update": 963, "total_env_steps": 3081600, "episode_reward": 0.35727328062057495, "value_loss": 0.007901310765494904, "policy_loss": -0.012002715801331002, "dist_entropy": 0.6140499035517375, "actor_grad_norm": 0.15282481908798218, "critic_grad_norm": 0.012423265725374222, "ratio": 1.0004783868789673, "entropy": 0.6140499035517375, "incre_win_rate": 0.9298245614035088, "step": 963}
{"time": 1766590009.5947566, "phase": "train", "update": 964, "total_env_steps": 3084800, "episode_reward": 0.3545343279838562, "value_loss": 0.005008251934001843, "policy_loss": -0.011031205288794392, "dist_entropy": 0.6088490684827169, "actor_grad_norm": 0.14388786256313324, "critic_grad_norm": 0.011381811462342739, "ratio": 0.9993022084236145, "entropy": 0.6088490684827169, "incre_win_rate": 0.9491525423728814, "step": 964}
{"time": 1766590014.19965, "phase": "train", "update": 965, "total_env_steps": 3088000, "episode_reward": 0.35136181116104126, "value_loss": 0.006039797576765219, "policy_loss": -0.012683736166182768, "dist_entropy": 0.5996995051701863, "actor_grad_norm": 0.14689356088638306, "critic_grad_norm": 0.026796329766511917, "ratio": 0.9987649917602539, "entropy": 0.5996995051701863, "incre_win_rate": 0.8793103448275862, "step": 965}
{"time": 1766590018.7485383, "phase": "train", "update": 966, "total_env_steps": 3091200, "episode_reward": 0.3403163552284241, "value_loss": 0.010261499074598153, "policy_loss": -0.012596444434890941, "dist_entropy": 0.6154413342475891, "actor_grad_norm": 0.14442722499370575, "critic_grad_norm": 0.054284777492284775, "ratio": 1.0000882148742676, "entropy": 0.6154413342475891, "incre_win_rate": 0.8421052631578947, "step": 966}
{"time": 1766590023.3883007, "phase": "train", "update": 967, "total_env_steps": 3094400, "episode_reward": 0.34923866391181946, "value_loss": 0.007685972843319178, "policy_loss": -0.01258917408596408, "dist_entropy": 0.6258349378903707, "actor_grad_norm": 0.15886753797531128, "critic_grad_norm": 0.02510291337966919, "ratio": 0.9984869360923767, "entropy": 0.6258349378903707, "incre_win_rate": 0.8947368421052632, "step": 967}
{"time": 1766590027.9380765, "phase": "train", "update": 968, "total_env_steps": 3097600, "episode_reward": 0.3363955318927765, "value_loss": 0.011383916313449541, "policy_loss": -0.011921355331595626, "dist_entropy": 0.6269851764043172, "actor_grad_norm": 0.14435403048992157, "critic_grad_norm": 0.031596291810274124, "ratio": 0.9992349743843079, "entropy": 0.6269851764043172, "incre_win_rate": 0.7894736842105263, "step": 968}
{"time": 1766590032.5570712, "phase": "train", "update": 969, "total_env_steps": 3100800, "episode_reward": 0.34197843074798584, "value_loss": 0.010099878596762816, "policy_loss": -0.012729280093506646, "dist_entropy": 0.6255039811134339, "actor_grad_norm": 0.19473019242286682, "critic_grad_norm": 0.01954764872789383, "ratio": 1.0007977485656738, "entropy": 0.6255039811134339, "incre_win_rate": 0.8421052631578947, "step": 969}
{"time": 1766590037.137751, "phase": "train", "update": 970, "total_env_steps": 3104000, "episode_reward": 0.3464185297489166, "value_loss": 0.008557465982933839, "policy_loss": -0.012006004135649088, "dist_entropy": 0.6211280663808186, "actor_grad_norm": 0.16497273743152618, "critic_grad_norm": 0.04497670382261276, "ratio": 0.9996616244316101, "entropy": 0.6211280663808186, "incre_win_rate": 0.8947368421052632, "step": 970}
{"time": 1766590041.677706, "phase": "train", "update": 971, "total_env_steps": 3107200, "episode_reward": 0.3496469259262085, "value_loss": 0.009174109995365142, "policy_loss": -0.01278672941264271, "dist_entropy": 0.6262176990509033, "actor_grad_norm": 0.15118323266506195, "critic_grad_norm": 0.03098827227950096, "ratio": 1.0003821849822998, "entropy": 0.6262176990509033, "incre_win_rate": 0.8793103448275862, "step": 971}
{"time": 1766590046.2446039, "phase": "train", "update": 972, "total_env_steps": 3110400, "episode_reward": 0.35219287872314453, "value_loss": 0.0075020485557615755, "policy_loss": -0.011007378083054202, "dist_entropy": 0.6263996918996175, "actor_grad_norm": 0.1505093276500702, "critic_grad_norm": 0.02095002308487892, "ratio": 0.9996479153633118, "entropy": 0.6263996918996175, "incre_win_rate": 0.896551724137931, "step": 972}
{"time": 1766590050.8234618, "phase": "train", "update": 973, "total_env_steps": 3113600, "episode_reward": 0.35697534680366516, "value_loss": 0.005701168843855461, "policy_loss": -0.011706127061596305, "dist_entropy": 0.619200070699056, "actor_grad_norm": 0.14336101710796356, "critic_grad_norm": 0.011359388008713722, "ratio": 0.998971164226532, "entropy": 0.619200070699056, "incre_win_rate": 0.9137931034482759, "step": 973}
{"time": 1766590055.4290287, "phase": "train", "update": 974, "total_env_steps": 3116800, "episode_reward": 0.33714306354522705, "value_loss": 0.009372563349703949, "policy_loss": -0.011657077867602084, "dist_entropy": 0.6160452485084533, "actor_grad_norm": 0.16673025488853455, "critic_grad_norm": 0.023227673023939133, "ratio": 0.999768078327179, "entropy": 0.6160452485084533, "incre_win_rate": 0.8392857142857143, "step": 974}
{"time": 1766590059.9926908, "phase": "train", "update": 975, "total_env_steps": 3120000, "episode_reward": 0.3467026650905609, "value_loss": 0.008371886455764373, "policy_loss": -0.01145467992043135, "dist_entropy": 0.6064865708351135, "actor_grad_norm": 0.17907358705997467, "critic_grad_norm": 0.03571518883109093, "ratio": 1.0003056526184082, "entropy": 0.6064865708351135, "incre_win_rate": 0.8771929824561403, "step": 975}
{"time": 1766590064.7230666, "phase": "train", "update": 976, "total_env_steps": 3123200, "episode_reward": 0.3555108606815338, "value_loss": 0.008912511728703975, "policy_loss": -0.011339513122031282, "dist_entropy": 0.6044406692186991, "actor_grad_norm": 0.1620376855134964, "critic_grad_norm": 0.01621348038315773, "ratio": 1.0000278949737549, "entropy": 0.6044406692186991, "incre_win_rate": 0.8833333333333333, "step": 976}
{"time": 1766590069.3242226, "phase": "train", "update": 977, "total_env_steps": 3126400, "episode_reward": 0.3492424786090851, "value_loss": 0.008230244709799687, "policy_loss": -0.011712291666432862, "dist_entropy": 0.5949947317441304, "actor_grad_norm": 0.1782141774892807, "critic_grad_norm": 0.014730855822563171, "ratio": 0.9984935522079468, "entropy": 0.5949947317441304, "incre_win_rate": 0.8771929824561403, "step": 977}
{"time": 1766590073.958214, "phase": "train", "update": 978, "total_env_steps": 3129600, "episode_reward": 0.35808825492858887, "value_loss": 0.005559670645743609, "policy_loss": -0.010104534932630334, "dist_entropy": 0.5823664188385009, "actor_grad_norm": 0.18062427639961243, "critic_grad_norm": 0.016158439218997955, "ratio": 0.9995869994163513, "entropy": 0.5823664188385009, "incre_win_rate": 0.9491525423728814, "step": 978}
{"time": 1766590103.8741882, "phase": "train", "update": 979, "total_env_steps": 3132800, "episode_reward": 0.3294646441936493, "value_loss": 0.05749946137269338, "policy_loss": -0.009261209534970404, "dist_entropy": 0.6046173532803854, "actor_grad_norm": 0.13939213752746582, "critic_grad_norm": 0.14738434553146362, "ratio": 0.9999006986618042, "entropy": 0.6046173532803854, "incre_win_rate": 0.8076923076923077, "step": 979}
{"time": 1766590108.4140081, "phase": "train", "update": 980, "total_env_steps": 3136000, "episode_reward": 0.34204503893852234, "value_loss": 0.006616179893414179, "policy_loss": -0.01243995562477996, "dist_entropy": 0.6047832449277242, "actor_grad_norm": 0.16224022209644318, "critic_grad_norm": 0.05531394109129906, "ratio": 0.9998435974121094, "entropy": 0.6047832449277242, "incre_win_rate": 0.8909090909090909, "step": 980}
{"time": 1766590112.9951458, "phase": "train", "update": 981, "total_env_steps": 3139200, "episode_reward": 0.3595442473888397, "value_loss": 0.004166185948997736, "policy_loss": -0.011401296378827416, "dist_entropy": 0.611245310306549, "actor_grad_norm": 0.13132742047309875, "critic_grad_norm": 0.0715823620557785, "ratio": 0.9990474581718445, "entropy": 0.611245310306549, "incre_win_rate": 0.9661016949152542, "step": 981}
{"time": 1766590120.0892944, "phase": "eval", "update": 981, "total_env_steps": 3139200, "eval_win_rate": 1.0, "eval_episode_reward": 20.003982843137255, "step": 981}
{"time": 1766590124.697329, "phase": "train", "update": 982, "total_env_steps": 3142400, "episode_reward": 0.35291588306427, "value_loss": 0.006426813142995039, "policy_loss": -0.010639154936164156, "dist_entropy": 0.6217947920163472, "actor_grad_norm": 0.12478756904602051, "critic_grad_norm": 0.032471880316734314, "ratio": 0.9993323087692261, "entropy": 0.6217947920163472, "incre_win_rate": 0.8833333333333333, "step": 982}
{"time": 1766590129.246249, "phase": "train", "update": 983, "total_env_steps": 3145600, "episode_reward": 0.35846278071403503, "value_loss": 0.006660575885325671, "policy_loss": -0.01089958982044692, "dist_entropy": 0.6188947876294454, "actor_grad_norm": 0.13808278739452362, "critic_grad_norm": 0.019215283915400505, "ratio": 1.0007054805755615, "entropy": 0.6188947876294454, "incre_win_rate": 0.9122807017543859, "step": 983}
{"time": 1766590133.787652, "phase": "train", "update": 984, "total_env_steps": 3148800, "episode_reward": 0.34395909309387207, "value_loss": 0.00933807399123907, "policy_loss": -0.012213803540651469, "dist_entropy": 0.6398414015769959, "actor_grad_norm": 0.16363488137722015, "critic_grad_norm": 0.026592839509248734, "ratio": 0.9998424053192139, "entropy": 0.6398414015769959, "incre_win_rate": 0.8813559322033898, "step": 984}
{"time": 1766590138.4615896, "phase": "train", "update": 985, "total_env_steps": 3152000, "episode_reward": 0.3515670895576477, "value_loss": 0.010901256402333578, "policy_loss": -0.011270570813828347, "dist_entropy": 0.6335423310597738, "actor_grad_norm": 0.1505572646856308, "critic_grad_norm": 0.03753107413649559, "ratio": 1.0004221200942993, "entropy": 0.6335423310597738, "incre_win_rate": 0.8793103448275862, "step": 985}
{"time": 1766590143.290783, "phase": "train", "update": 986, "total_env_steps": 3155200, "episode_reward": 0.3448407053947449, "value_loss": 0.009051887318491936, "policy_loss": -0.012153950493996153, "dist_entropy": 0.6237338304519653, "actor_grad_norm": 0.1406271755695343, "critic_grad_norm": 0.017639202997088432, "ratio": 0.9966439604759216, "entropy": 0.6237338304519653, "incre_win_rate": 0.9090909090909091, "step": 986}
{"time": 1766590148.1223428, "phase": "train", "update": 987, "total_env_steps": 3158400, "episode_reward": 0.34639477729797363, "value_loss": 0.00929536862919728, "policy_loss": -0.012610002131376063, "dist_entropy": 0.6143297950426737, "actor_grad_norm": 0.17703916132450104, "critic_grad_norm": 0.02796352282166481, "ratio": 0.999985933303833, "entropy": 0.6143297950426737, "incre_win_rate": 0.8771929824561403, "step": 987}
{"time": 1766590152.7653244, "phase": "train", "update": 988, "total_env_steps": 3161600, "episode_reward": 0.3493451476097107, "value_loss": 0.00889508028825124, "policy_loss": -0.011246250148132948, "dist_entropy": 0.6228250900904337, "actor_grad_norm": 0.14526736736297607, "critic_grad_norm": 0.018299970775842667, "ratio": 0.9997796416282654, "entropy": 0.6228250900904337, "incre_win_rate": 0.9137931034482759, "step": 988}
{"time": 1766590157.397727, "phase": "train", "update": 989, "total_env_steps": 3164800, "episode_reward": 0.348060667514801, "value_loss": 0.006968467744688193, "policy_loss": -0.012452409597859078, "dist_entropy": 0.6183101455370585, "actor_grad_norm": 0.1355392336845398, "critic_grad_norm": 0.01269882544875145, "ratio": 1.0000030994415283, "entropy": 0.6183101455370585, "incre_win_rate": 0.8620689655172413, "step": 989}
{"time": 1766590162.208489, "phase": "train", "update": 990, "total_env_steps": 3168000, "episode_reward": 0.3502412736415863, "value_loss": 0.012467868191500505, "policy_loss": -0.012758244732339108, "dist_entropy": 0.6247083942095438, "actor_grad_norm": 0.13984964787960052, "critic_grad_norm": 0.01818210259079933, "ratio": 0.9991241097450256, "entropy": 0.6247083942095438, "incre_win_rate": 0.8448275862068966, "step": 990}
{"time": 1766590167.1688778, "phase": "train", "update": 991, "total_env_steps": 3171200, "episode_reward": 0.3623146414756775, "value_loss": 0.00542400556926926, "policy_loss": -0.012624320329911617, "dist_entropy": 0.6189324776331584, "actor_grad_norm": 0.1509857326745987, "critic_grad_norm": 0.04115501791238785, "ratio": 0.9997674822807312, "entropy": 0.6189324776331584, "incre_win_rate": 0.9491525423728814, "step": 991}
{"time": 1766590171.8392842, "phase": "train", "update": 992, "total_env_steps": 3174400, "episode_reward": 0.36599498987197876, "value_loss": 0.00531347282230854, "policy_loss": -0.011234493396705207, "dist_entropy": 0.5974424759546916, "actor_grad_norm": 0.13595592975616455, "critic_grad_norm": 0.0274690892547369, "ratio": 0.9991166591644287, "entropy": 0.5974424759546916, "incre_win_rate": 0.9666666666666667, "step": 992}
{"time": 1766590176.663731, "phase": "train", "update": 993, "total_env_steps": 3177600, "episode_reward": 0.36108455061912537, "value_loss": 0.006490845823039612, "policy_loss": -0.012565193097606672, "dist_entropy": 0.5896221796671549, "actor_grad_norm": 0.16313882172107697, "critic_grad_norm": 0.018364066258072853, "ratio": 1.0000404119491577, "entropy": 0.5896221796671549, "incre_win_rate": 0.896551724137931, "step": 993}
{"time": 1766590181.3260713, "phase": "train", "update": 994, "total_env_steps": 3180800, "episode_reward": 0.36313343048095703, "value_loss": 0.006173883937299252, "policy_loss": -0.01117798712266446, "dist_entropy": 0.5961723089218139, "actor_grad_norm": 0.1411253958940506, "critic_grad_norm": 0.020466895774006844, "ratio": 1.0004551410675049, "entropy": 0.5961723089218139, "incre_win_rate": 0.9166666666666666, "step": 994}
{"time": 1766590185.944657, "phase": "train", "update": 995, "total_env_steps": 3184000, "episode_reward": 0.3594377934932709, "value_loss": 0.0078049516305327415, "policy_loss": -0.011420695430454467, "dist_entropy": 0.5928249557813009, "actor_grad_norm": 0.13920390605926514, "critic_grad_norm": 0.017125679180026054, "ratio": 0.9989644289016724, "entropy": 0.5928249557813009, "incre_win_rate": 0.9310344827586207, "step": 995}
{"time": 1766590190.5556552, "phase": "train", "update": 996, "total_env_steps": 3187200, "episode_reward": 0.3646009564399719, "value_loss": 0.006388353773703178, "policy_loss": -0.012082947695893628, "dist_entropy": 0.5793132742245992, "actor_grad_norm": 0.1515091359615326, "critic_grad_norm": 0.022799286991357803, "ratio": 0.9991732239723206, "entropy": 0.5793132742245992, "incre_win_rate": 0.9180327868852459, "step": 996}
{"time": 1766590195.159183, "phase": "train", "update": 997, "total_env_steps": 3190400, "episode_reward": 0.3568283021450043, "value_loss": 0.008662705185512702, "policy_loss": -0.011963085529900278, "dist_entropy": 0.6080385565757751, "actor_grad_norm": 0.15788494050502777, "critic_grad_norm": 0.03017887845635414, "ratio": 0.9992568492889404, "entropy": 0.6080385565757751, "incre_win_rate": 0.8983050847457628, "step": 997}
{"time": 1766590200.1345835, "phase": "train", "update": 998, "total_env_steps": 3193600, "episode_reward": 0.3587844967842102, "value_loss": 0.006055526776860157, "policy_loss": -0.01231152894601569, "dist_entropy": 0.5947781960169475, "actor_grad_norm": 0.14320255815982819, "critic_grad_norm": 0.014153607189655304, "ratio": 0.9992273449897766, "entropy": 0.5947781960169475, "incre_win_rate": 0.9137931034482759, "step": 998}
{"time": 1766590204.9587731, "phase": "train", "update": 999, "total_env_steps": 3196800, "episode_reward": 0.35974419116973877, "value_loss": 0.007067432844390472, "policy_loss": -0.01210660857113055, "dist_entropy": 0.5943322936693828, "actor_grad_norm": 0.18013733625411987, "critic_grad_norm": 0.008444526232779026, "ratio": 0.999483048915863, "entropy": 0.5943322936693828, "incre_win_rate": 0.8833333333333333, "step": 999}
{"time": 1766590209.6987221, "phase": "train", "update": 1000, "total_env_steps": 3200000, "episode_reward": 0.3616827726364136, "value_loss": 0.010683196038007737, "policy_loss": -0.011707296092174602, "dist_entropy": 0.585623542467753, "actor_grad_norm": 0.14388325810432434, "critic_grad_norm": 0.0389687679708004, "ratio": 0.9995843172073364, "entropy": 0.585623542467753, "incre_win_rate": 0.8688524590163934, "step": 1000}
{"time": 1766590214.434902, "phase": "train", "update": 1001, "total_env_steps": 3203200, "episode_reward": 0.36902034282684326, "value_loss": 0.003773863598083456, "policy_loss": -0.011060229212993041, "dist_entropy": 0.5946019570032756, "actor_grad_norm": 0.14965657889842987, "critic_grad_norm": 0.04507550597190857, "ratio": 0.9985033273696899, "entropy": 0.5946019570032756, "incre_win_rate": 0.9661016949152542, "step": 1001}
{"time": 1766590222.0379596, "phase": "eval", "update": 1001, "total_env_steps": 3203200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.6436887254902, "step": 1001}
{"time": 1766590226.8462932, "phase": "train", "update": 1002, "total_env_steps": 3206400, "episode_reward": 0.35567328333854675, "value_loss": 0.006808285880833864, "policy_loss": -0.011447830136382701, "dist_entropy": 0.5839312116305033, "actor_grad_norm": 0.13253724575042725, "critic_grad_norm": 0.023146681487560272, "ratio": 1.00063157081604, "entropy": 0.5839312116305033, "incre_win_rate": 0.8947368421052632, "step": 1002}
{"time": 1766590231.2772214, "phase": "train", "update": 1003, "total_env_steps": 3209600, "episode_reward": 0.37117186188697815, "value_loss": 0.003767263237386942, "policy_loss": -0.010706909255228563, "dist_entropy": 0.6007008671760559, "actor_grad_norm": 0.1761285960674286, "critic_grad_norm": 0.015078531578183174, "ratio": 0.9998974204063416, "entropy": 0.6007008671760559, "incre_win_rate": 0.967741935483871, "step": 1003}
{"time": 1766590236.1523638, "phase": "train", "update": 1004, "total_env_steps": 3212800, "episode_reward": 0.36592987179756165, "value_loss": 0.00738257405658563, "policy_loss": -0.010104165441913438, "dist_entropy": 0.5989170591036479, "actor_grad_norm": 0.13253900408744812, "critic_grad_norm": 0.019691448658704758, "ratio": 1.0012924671173096, "entropy": 0.5989170591036479, "incre_win_rate": 0.9137931034482759, "step": 1004}
{"time": 1766590241.0189521, "phase": "train", "update": 1005, "total_env_steps": 3216000, "episode_reward": 0.3651577830314636, "value_loss": 0.00602950444445014, "policy_loss": -0.010855045799797836, "dist_entropy": 0.6069081425666809, "actor_grad_norm": 0.1418636292219162, "critic_grad_norm": 0.0195179246366024, "ratio": 0.9992737174034119, "entropy": 0.6069081425666809, "incre_win_rate": 0.9344262295081968, "step": 1005}
{"time": 1766590245.9020994, "phase": "train", "update": 1006, "total_env_steps": 3219200, "episode_reward": 0.352731317281723, "value_loss": 0.006899071888377269, "policy_loss": -0.011769459807141894, "dist_entropy": 0.6168996532758076, "actor_grad_norm": 0.13436126708984375, "critic_grad_norm": 0.019828878343105316, "ratio": 0.9994003772735596, "entropy": 0.6168996532758076, "incre_win_rate": 0.864406779661017, "step": 1006}
{"time": 1766590250.6196735, "phase": "train", "update": 1007, "total_env_steps": 3222400, "episode_reward": 0.3661175072193146, "value_loss": 0.006845450991143783, "policy_loss": -0.010843899233765815, "dist_entropy": 0.5939309557278951, "actor_grad_norm": 0.12291157990694046, "critic_grad_norm": 0.008210338652133942, "ratio": 0.9988979697227478, "entropy": 0.5939309557278951, "incre_win_rate": 0.9482758620689655, "step": 1007}
{"time": 1766590255.4790552, "phase": "train", "update": 1008, "total_env_steps": 3225600, "episode_reward": 0.3614705801010132, "value_loss": 0.005210747756063938, "policy_loss": -0.01044946096639497, "dist_entropy": 0.5949900190035502, "actor_grad_norm": 0.12951752543449402, "critic_grad_norm": 0.010382164269685745, "ratio": 1.0006431341171265, "entropy": 0.5949900190035502, "incre_win_rate": 0.9322033898305084, "step": 1008}
{"time": 1766590260.5856526, "phase": "train", "update": 1009, "total_env_steps": 3228800, "episode_reward": 0.36713695526123047, "value_loss": 0.00507406530280908, "policy_loss": -0.010408327001840216, "dist_entropy": 0.6148893356323242, "actor_grad_norm": 0.1293991208076477, "critic_grad_norm": 0.016630850732326508, "ratio": 0.998644232749939, "entropy": 0.6148893356323242, "incre_win_rate": 0.9516129032258065, "step": 1009}
{"time": 1766590265.3724575, "phase": "train", "update": 1010, "total_env_steps": 3232000, "episode_reward": 0.35772058367729187, "value_loss": 0.005714772175997496, "policy_loss": -0.010568782502361292, "dist_entropy": 0.6244744698206584, "actor_grad_norm": 0.11772728711366653, "critic_grad_norm": 0.015653569251298904, "ratio": 1.0000712871551514, "entropy": 0.6244744698206584, "incre_win_rate": 0.9122807017543859, "step": 1010}
{"time": 1766590270.1284547, "phase": "train", "update": 1011, "total_env_steps": 3235200, "episode_reward": 0.3610838055610657, "value_loss": 0.004623170041789611, "policy_loss": -0.01192576453624478, "dist_entropy": 0.6085378011067708, "actor_grad_norm": 0.1371537446975708, "critic_grad_norm": 0.013538413681089878, "ratio": 0.999836802482605, "entropy": 0.6085378011067708, "incre_win_rate": 0.9655172413793104, "step": 1011}
{"time": 1766590274.9712496, "phase": "train", "update": 1012, "total_env_steps": 3238400, "episode_reward": 0.3529312014579773, "value_loss": 0.007466142252087593, "policy_loss": -0.010619820871049039, "dist_entropy": 0.6137034932772318, "actor_grad_norm": 0.12413708865642548, "critic_grad_norm": 0.015857255086302757, "ratio": 0.9995697140693665, "entropy": 0.6137034932772318, "incre_win_rate": 0.8833333333333333, "step": 1012}
{"time": 1766590279.7871432, "phase": "train", "update": 1013, "total_env_steps": 3241600, "episode_reward": 0.3573077321052551, "value_loss": 0.007269008612881104, "policy_loss": -0.010817573608947365, "dist_entropy": 0.6225709795951844, "actor_grad_norm": 0.1318763643503189, "critic_grad_norm": 0.011227406561374664, "ratio": 0.9994795918464661, "entropy": 0.6225709795951844, "incre_win_rate": 0.8947368421052632, "step": 1013}
{"time": 1766590284.616227, "phase": "train", "update": 1014, "total_env_steps": 3244800, "episode_reward": 0.3616574704647064, "value_loss": 0.006023537584890922, "policy_loss": -0.011270733225408947, "dist_entropy": 0.6294490416844686, "actor_grad_norm": 0.15561357140541077, "critic_grad_norm": 0.02654077298939228, "ratio": 0.9995707869529724, "entropy": 0.6294490416844686, "incre_win_rate": 0.9166666666666666, "step": 1014}
{"time": 1766590289.2914617, "phase": "train", "update": 1015, "total_env_steps": 3248000, "episode_reward": 0.35752299427986145, "value_loss": 0.007323498651385307, "policy_loss": -0.01066692747654514, "dist_entropy": 0.6302199920018514, "actor_grad_norm": 0.13675935566425323, "critic_grad_norm": 0.024879906326532364, "ratio": 1.0001425743103027, "entropy": 0.6302199920018514, "incre_win_rate": 0.896551724137931, "step": 1015}
{"time": 1766590293.9042659, "phase": "train", "update": 1016, "total_env_steps": 3251200, "episode_reward": 0.34970590472221375, "value_loss": 0.007885434851050376, "policy_loss": -0.012109902003652539, "dist_entropy": 0.6120722651481628, "actor_grad_norm": 0.16206306219100952, "critic_grad_norm": 0.04320530965924263, "ratio": 0.999359130859375, "entropy": 0.6120722651481628, "incre_win_rate": 0.8448275862068966, "step": 1016}
{"time": 1766590298.7170215, "phase": "train", "update": 1017, "total_env_steps": 3254400, "episode_reward": 0.3605116605758667, "value_loss": 0.006048450277497371, "policy_loss": -0.011258097752829599, "dist_entropy": 0.6195145527521769, "actor_grad_norm": 0.14566001296043396, "critic_grad_norm": 0.030071690678596497, "ratio": 0.999873161315918, "entropy": 0.6195145527521769, "incre_win_rate": 0.9166666666666666, "step": 1017}
{"time": 1766590303.3786063, "phase": "train", "update": 1018, "total_env_steps": 3257600, "episode_reward": 0.3615954518318176, "value_loss": 0.010876919018725555, "policy_loss": -0.011153279728658917, "dist_entropy": 0.6178181489308675, "actor_grad_norm": 0.1401926577091217, "critic_grad_norm": 0.016704034060239792, "ratio": 1.0003985166549683, "entropy": 0.6178181489308675, "incre_win_rate": 0.9, "step": 1018}
{"time": 1766590308.1084719, "phase": "train", "update": 1019, "total_env_steps": 3260800, "episode_reward": 0.3633142113685608, "value_loss": 0.008213178223619859, "policy_loss": -0.011566030465013455, "dist_entropy": 0.6054298202196757, "actor_grad_norm": 0.13064973056316376, "critic_grad_norm": 0.04944612830877304, "ratio": 0.9984058737754822, "entropy": 0.6054298202196757, "incre_win_rate": 0.9322033898305084, "step": 1019}
{"time": 1766590312.734832, "phase": "train", "update": 1020, "total_env_steps": 3264000, "episode_reward": 0.3472641110420227, "value_loss": 0.010930294233063857, "policy_loss": -0.014076959731661277, "dist_entropy": 0.614206341902415, "actor_grad_norm": 0.13355952501296997, "critic_grad_norm": 0.05357656627893448, "ratio": 0.9992798566818237, "entropy": 0.614206341902415, "incre_win_rate": 0.8275862068965517, "step": 1020}
{"time": 1766590317.6142602, "phase": "train", "update": 1021, "total_env_steps": 3267200, "episode_reward": 0.34966376423835754, "value_loss": 0.007077208999544382, "policy_loss": -0.012056889944534532, "dist_entropy": 0.6222366213798523, "actor_grad_norm": 0.16685166954994202, "critic_grad_norm": 0.0156282689422369, "ratio": 0.9991031289100647, "entropy": 0.6222366213798523, "incre_win_rate": 0.8620689655172413, "step": 1021}
{"time": 1766590326.0242844, "phase": "eval", "update": 1021, "total_env_steps": 3267200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.443474264705884, "step": 1021}
{"time": 1766590331.4004457, "phase": "train", "update": 1022, "total_env_steps": 3270400, "episode_reward": 0.34818169474601746, "value_loss": 0.007623241810748974, "policy_loss": -0.011779901147608502, "dist_entropy": 0.619792103767395, "actor_grad_norm": 0.16300040483474731, "critic_grad_norm": 0.01468648761510849, "ratio": 1.0001530647277832, "entropy": 0.619792103767395, "incre_win_rate": 0.8833333333333333, "step": 1022}
{"time": 1766590336.5386872, "phase": "train", "update": 1023, "total_env_steps": 3273600, "episode_reward": 0.3428707420825958, "value_loss": 0.008700461561481158, "policy_loss": -0.012024658744459061, "dist_entropy": 0.6081156690915426, "actor_grad_norm": 0.1263662725687027, "critic_grad_norm": 0.012525971047580242, "ratio": 0.9982911944389343, "entropy": 0.6081156690915426, "incre_win_rate": 0.8214285714285714, "step": 1023}
{"time": 1766590341.930589, "phase": "train", "update": 1024, "total_env_steps": 3276800, "episode_reward": 0.34970054030418396, "value_loss": 0.007072810331980387, "policy_loss": -0.010615505347438632, "dist_entropy": 0.6090988755226135, "actor_grad_norm": 0.14241546392440796, "critic_grad_norm": 0.01608112081885338, "ratio": 0.9995666146278381, "entropy": 0.6090988755226135, "incre_win_rate": 0.8947368421052632, "step": 1024}
{"time": 1766590347.516538, "phase": "train", "update": 1025, "total_env_steps": 3280000, "episode_reward": 0.3484635651111603, "value_loss": 0.008922260068356992, "policy_loss": -0.011640146599032638, "dist_entropy": 0.6151026050249736, "actor_grad_norm": 0.14777426421642303, "critic_grad_norm": 0.022400572896003723, "ratio": 0.9995404481887817, "entropy": 0.6151026050249736, "incre_win_rate": 0.8793103448275862, "step": 1025}
{"time": 1766590352.7841873, "phase": "train", "update": 1026, "total_env_steps": 3283200, "episode_reward": 0.34931448101997375, "value_loss": 0.009489821828901767, "policy_loss": -0.011991796524177544, "dist_entropy": 0.6278164068857829, "actor_grad_norm": 0.15264727175235748, "critic_grad_norm": 0.053986746817827225, "ratio": 1.000409722328186, "entropy": 0.6278164068857829, "incre_win_rate": 0.8448275862068966, "step": 1026}
{"time": 1766590358.1915643, "phase": "train", "update": 1027, "total_env_steps": 3286400, "episode_reward": 0.33435896039009094, "value_loss": 0.017301564912001292, "policy_loss": -0.01207764498071171, "dist_entropy": 0.6124529163042705, "actor_grad_norm": 0.13354267179965973, "critic_grad_norm": 0.06904606521129608, "ratio": 0.9988493323326111, "entropy": 0.6124529163042705, "incre_win_rate": 0.7288135593220338, "step": 1027}
{"time": 1766590363.481457, "phase": "train", "update": 1028, "total_env_steps": 3289600, "episode_reward": 0.3493214249610901, "value_loss": 0.00849646342297395, "policy_loss": -0.011490872794540625, "dist_entropy": 0.6110386610031128, "actor_grad_norm": 0.12722481787204742, "critic_grad_norm": 0.06621251255273819, "ratio": 0.9987649917602539, "entropy": 0.6110386610031128, "incre_win_rate": 0.9107142857142857, "step": 1028}
{"time": 1766590368.7606547, "phase": "train", "update": 1029, "total_env_steps": 3292800, "episode_reward": 0.3531947135925293, "value_loss": 0.007377047557383776, "policy_loss": -0.012089983221877059, "dist_entropy": 0.6228474577267965, "actor_grad_norm": 0.1403486281633377, "critic_grad_norm": 0.03397182747721672, "ratio": 0.9981487393379211, "entropy": 0.6228474577267965, "incre_win_rate": 0.9016393442622951, "step": 1029}
{"time": 1766590374.0674329, "phase": "train", "update": 1030, "total_env_steps": 3296000, "episode_reward": 0.3380545377731323, "value_loss": 0.013587193377315999, "policy_loss": -0.012657800600728564, "dist_entropy": 0.6395052472750345, "actor_grad_norm": 0.14093154668807983, "critic_grad_norm": 0.030073776841163635, "ratio": 1.0002720355987549, "entropy": 0.6395052472750345, "incre_win_rate": 0.8, "step": 1030}
{"time": 1766590379.2318892, "phase": "train", "update": 1031, "total_env_steps": 3299200, "episode_reward": 0.33076441287994385, "value_loss": 0.010716207760075728, "policy_loss": -0.012169859147864889, "dist_entropy": 0.6323314507802328, "actor_grad_norm": 0.1404525637626648, "critic_grad_norm": 0.04585641995072365, "ratio": 1.0007826089859009, "entropy": 0.6323314507802328, "incre_win_rate": 0.8214285714285714, "step": 1031}
{"time": 1766590384.0260034, "phase": "train", "update": 1032, "total_env_steps": 3302400, "episode_reward": 0.3340311050415039, "value_loss": 0.010524955143531163, "policy_loss": -0.013373695673616244, "dist_entropy": 0.6414109269777933, "actor_grad_norm": 0.15538540482521057, "critic_grad_norm": 0.028241366147994995, "ratio": 1.0010766983032227, "entropy": 0.6414109269777933, "incre_win_rate": 0.7894736842105263, "step": 1032}
{"time": 1766590388.661234, "phase": "train", "update": 1033, "total_env_steps": 3305600, "episode_reward": 0.3417983949184418, "value_loss": 0.007268163748085499, "policy_loss": -0.012597014600950255, "dist_entropy": 0.6243918895721435, "actor_grad_norm": 0.13927505910396576, "critic_grad_norm": 0.038928743451833725, "ratio": 0.9993544220924377, "entropy": 0.6243918895721435, "incre_win_rate": 0.8928571428571429, "step": 1033}
{"time": 1766590393.2602623, "phase": "train", "update": 1034, "total_env_steps": 3308800, "episode_reward": 0.3458409905433655, "value_loss": 0.006790553126484156, "policy_loss": -0.012549673372283602, "dist_entropy": 0.6300953269004822, "actor_grad_norm": 0.15184323489665985, "critic_grad_norm": 0.04439334198832512, "ratio": 0.9985910654067993, "entropy": 0.6300953269004822, "incre_win_rate": 0.8771929824561403, "step": 1034}
{"time": 1766590397.841184, "phase": "train", "update": 1035, "total_env_steps": 3312000, "episode_reward": 0.34383654594421387, "value_loss": 0.007682053620616595, "policy_loss": -0.01198464890236437, "dist_entropy": 0.6316214760144552, "actor_grad_norm": 0.14763155579566956, "critic_grad_norm": 0.025379130616784096, "ratio": 0.998530924320221, "entropy": 0.6316214760144552, "incre_win_rate": 0.9454545454545454, "step": 1035}
{"time": 1766590402.4667258, "phase": "train", "update": 1036, "total_env_steps": 3315200, "episode_reward": 0.3344002664089203, "value_loss": 0.010052422372003397, "policy_loss": -0.012972181613680316, "dist_entropy": 0.6460052371025086, "actor_grad_norm": 0.1431020200252533, "critic_grad_norm": 0.04255400598049164, "ratio": 0.998866617679596, "entropy": 0.6460052371025086, "incre_win_rate": 0.8771929824561403, "step": 1036}
{"time": 1766590407.023374, "phase": "train", "update": 1037, "total_env_steps": 3318400, "episode_reward": 0.33340227603912354, "value_loss": 0.008522099504868189, "policy_loss": -0.012555642006390618, "dist_entropy": 0.6452802538871765, "actor_grad_norm": 0.14876319468021393, "critic_grad_norm": 0.023194173350930214, "ratio": 0.9992817640304565, "entropy": 0.6452802538871765, "incre_win_rate": 0.8703703703703703, "step": 1037}
{"time": 1766590411.6819882, "phase": "train", "update": 1038, "total_env_steps": 3321600, "episode_reward": 0.3432352840900421, "value_loss": 0.011622347682714463, "policy_loss": -0.011780421295595644, "dist_entropy": 0.61971142689387, "actor_grad_norm": 0.16969141364097595, "critic_grad_norm": 0.04621993377804756, "ratio": 1.0004379749298096, "entropy": 0.61971142689387, "incre_win_rate": 0.8333333333333334, "step": 1038}
{"time": 1766590416.2566006, "phase": "train", "update": 1039, "total_env_steps": 3324800, "episode_reward": 0.3306487500667572, "value_loss": 0.008590848992268245, "policy_loss": -0.012213714643245055, "dist_entropy": 0.6242431998252869, "actor_grad_norm": 0.13277728855609894, "critic_grad_norm": 0.013344688341021538, "ratio": 1.0002402067184448, "entropy": 0.6242431998252869, "incre_win_rate": 0.8363636363636363, "step": 1039}
{"time": 1766590420.8512, "phase": "train", "update": 1040, "total_env_steps": 3328000, "episode_reward": 0.3477175235748291, "value_loss": 0.008444078639149666, "policy_loss": -0.011768728472770818, "dist_entropy": 0.6183209419250488, "actor_grad_norm": 0.14613018929958344, "critic_grad_norm": 0.02157277800142765, "ratio": 0.9998958110809326, "entropy": 0.6183209419250488, "incre_win_rate": 0.8596491228070176, "step": 1040}
{"time": 1766590425.4628432, "phase": "train", "update": 1041, "total_env_steps": 3331200, "episode_reward": 0.3496568500995636, "value_loss": 0.009209968770543734, "policy_loss": -0.011811373514544244, "dist_entropy": 0.6197145183881124, "actor_grad_norm": 0.15485481917858124, "critic_grad_norm": 0.016765108332037926, "ratio": 0.9984068870544434, "entropy": 0.6197145183881124, "incre_win_rate": 0.847457627118644, "step": 1041}
{"time": 1766590433.0490737, "phase": "eval", "update": 1041, "total_env_steps": 3331200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.729013480392155, "step": 1041}
{"time": 1766590437.6686454, "phase": "train", "update": 1042, "total_env_steps": 3334400, "episode_reward": 0.3506755232810974, "value_loss": 0.009656953252851963, "policy_loss": -0.012386322025566205, "dist_entropy": 0.623421291510264, "actor_grad_norm": 0.13869398832321167, "critic_grad_norm": 0.011561177670955658, "ratio": 0.9988268613815308, "entropy": 0.623421291510264, "incre_win_rate": 0.896551724137931, "step": 1042}
{"time": 1766590442.318397, "phase": "train", "update": 1043, "total_env_steps": 3337600, "episode_reward": 0.3468344211578369, "value_loss": 0.010354789532721042, "policy_loss": -0.011830061361067123, "dist_entropy": 0.597785751024882, "actor_grad_norm": 0.1614178717136383, "critic_grad_norm": 0.011388950981199741, "ratio": 0.9989798665046692, "entropy": 0.597785751024882, "incre_win_rate": 0.8771929824561403, "step": 1043}
{"time": 1766590446.9319687, "phase": "train", "update": 1044, "total_env_steps": 3340800, "episode_reward": 0.35743796825408936, "value_loss": 0.008444271764407556, "policy_loss": -0.009465995478183704, "dist_entropy": 0.6086834152539571, "actor_grad_norm": 0.15884257853031158, "critic_grad_norm": 0.02716634050011635, "ratio": 0.9992919564247131, "entropy": 0.6086834152539571, "incre_win_rate": 0.9152542372881356, "step": 1044}
{"time": 1766590451.6132565, "phase": "train", "update": 1045, "total_env_steps": 3344000, "episode_reward": 0.3447778820991516, "value_loss": 0.008781123347580433, "policy_loss": -0.012314826244838647, "dist_entropy": 0.6261414448420207, "actor_grad_norm": 0.16008558869361877, "critic_grad_norm": 0.02442247048020363, "ratio": 1.0001903772354126, "entropy": 0.6261414448420207, "incre_win_rate": 0.8793103448275862, "step": 1045}
{"time": 1766590456.195001, "phase": "train", "update": 1046, "total_env_steps": 3347200, "episode_reward": 0.354464590549469, "value_loss": 0.005876272730529308, "policy_loss": -0.011834075895734486, "dist_entropy": 0.5991573850313823, "actor_grad_norm": 0.156993106007576, "critic_grad_norm": 0.028912432491779327, "ratio": 0.9985617399215698, "entropy": 0.5991573850313823, "incre_win_rate": 0.9122807017543859, "step": 1046}
{"time": 1766590460.8225386, "phase": "train", "update": 1047, "total_env_steps": 3350400, "episode_reward": 0.3487929105758667, "value_loss": 0.007846401166170835, "policy_loss": -0.010129735520776725, "dist_entropy": 0.5827858050664266, "actor_grad_norm": 0.13999530673027039, "critic_grad_norm": 0.022775938734412193, "ratio": 1.000348687171936, "entropy": 0.5827858050664266, "incre_win_rate": 0.8620689655172413, "step": 1047}
{"time": 1766590465.4258392, "phase": "train", "update": 1048, "total_env_steps": 3353600, "episode_reward": 0.3527412712574005, "value_loss": 0.010691672191023826, "policy_loss": -0.011046529986641455, "dist_entropy": 0.5870832562446594, "actor_grad_norm": 0.14629383385181427, "critic_grad_norm": 0.03890080004930496, "ratio": 0.9999898672103882, "entropy": 0.5870832562446594, "incre_win_rate": 0.8947368421052632, "step": 1048}
{"time": 1766590470.0664043, "phase": "train", "update": 1049, "total_env_steps": 3356800, "episode_reward": 0.3562883138656616, "value_loss": 0.008695578668266535, "policy_loss": -0.010046362823432749, "dist_entropy": 0.5756370464960734, "actor_grad_norm": 0.14962425827980042, "critic_grad_norm": 0.02067912369966507, "ratio": 0.9993618726730347, "entropy": 0.5756370464960734, "incre_win_rate": 0.9, "step": 1049}
{"time": 1766590474.7893646, "phase": "train", "update": 1050, "total_env_steps": 3360000, "episode_reward": 0.34622398018836975, "value_loss": 0.008433980649958055, "policy_loss": -0.010241495532594059, "dist_entropy": 0.6040257334709167, "actor_grad_norm": 0.12252161651849747, "critic_grad_norm": 0.023266471922397614, "ratio": 0.9991901516914368, "entropy": 0.6040257334709167, "incre_win_rate": 0.8596491228070176, "step": 1050}
{"time": 1766590479.538744, "phase": "train", "update": 1051, "total_env_steps": 3363200, "episode_reward": 0.34963157773017883, "value_loss": 0.010750961117446422, "policy_loss": -0.010660141890961464, "dist_entropy": 0.5914614160855611, "actor_grad_norm": 0.17230522632598877, "critic_grad_norm": 0.03075919859111309, "ratio": 0.99964439868927, "entropy": 0.5914614160855611, "incre_win_rate": 0.85, "step": 1051}
{"time": 1766590484.2634192, "phase": "train", "update": 1052, "total_env_steps": 3366400, "episode_reward": 0.3469094932079315, "value_loss": 0.00909046499679486, "policy_loss": -0.011852610720057773, "dist_entropy": 0.5957177956899007, "actor_grad_norm": 0.1367512196302414, "critic_grad_norm": 0.014495216310024261, "ratio": 0.9987538456916809, "entropy": 0.5957177956899007, "incre_win_rate": 0.9090909090909091, "step": 1052}
{"time": 1766590488.9804654, "phase": "train", "update": 1053, "total_env_steps": 3369600, "episode_reward": 0.34786614775657654, "value_loss": 0.007851910901566346, "policy_loss": -0.01040852505200256, "dist_entropy": 0.579932423432668, "actor_grad_norm": 0.1776890754699707, "critic_grad_norm": 0.010478788986802101, "ratio": 0.9976778626441956, "entropy": 0.579932423432668, "incre_win_rate": 0.847457627118644, "step": 1053}
{"time": 1766590493.616255, "phase": "train", "update": 1054, "total_env_steps": 3372800, "episode_reward": 0.35219669342041016, "value_loss": 0.007394500356167555, "policy_loss": -0.011763730719317777, "dist_entropy": 0.5960390528043111, "actor_grad_norm": 0.13244779407978058, "critic_grad_norm": 0.010247180238366127, "ratio": 1.0003726482391357, "entropy": 0.5960390528043111, "incre_win_rate": 0.9152542372881356, "step": 1054}
{"time": 1766590498.2680576, "phase": "train", "update": 1055, "total_env_steps": 3376000, "episode_reward": 0.3453921377658844, "value_loss": 0.009018920920789241, "policy_loss": -0.01165028968894338, "dist_entropy": 0.6097658793131511, "actor_grad_norm": 0.15695057809352875, "critic_grad_norm": 0.017700687050819397, "ratio": 0.9990932941436768, "entropy": 0.6097658793131511, "incre_win_rate": 0.8727272727272727, "step": 1055}
{"time": 1766590503.0434673, "phase": "train", "update": 1056, "total_env_steps": 3379200, "episode_reward": 0.3538549244403839, "value_loss": 0.008264165340612332, "policy_loss": -0.011990695937931584, "dist_entropy": 0.5963414827982585, "actor_grad_norm": 0.1473565697669983, "critic_grad_norm": 0.03317911922931671, "ratio": 0.999411404132843, "entropy": 0.5963414827982585, "incre_win_rate": 0.9152542372881356, "step": 1056}
{"time": 1766590507.7559092, "phase": "train", "update": 1057, "total_env_steps": 3382400, "episode_reward": 0.3596246838569641, "value_loss": 0.004780663270503282, "policy_loss": -0.010592093601234965, "dist_entropy": 0.5870785037676494, "actor_grad_norm": 0.1447039395570755, "critic_grad_norm": 0.012121831998229027, "ratio": 0.9986767172813416, "entropy": 0.5870785037676494, "incre_win_rate": 0.9482758620689655, "step": 1057}
{"time": 1766590512.4831731, "phase": "train", "update": 1058, "total_env_steps": 3385600, "episode_reward": 0.34739965200424194, "value_loss": 0.007298570809264978, "policy_loss": -0.011440948722967904, "dist_entropy": 0.6056769371032715, "actor_grad_norm": 0.1288643628358841, "critic_grad_norm": 0.019792066887021065, "ratio": 0.9997720122337341, "entropy": 0.6056769371032715, "incre_win_rate": 0.8771929824561403, "step": 1058}
{"time": 1766590517.1147904, "phase": "train", "update": 1059, "total_env_steps": 3388800, "episode_reward": 0.35599416494369507, "value_loss": 0.004911219173421463, "policy_loss": -0.011026432633778427, "dist_entropy": 0.603779943784078, "actor_grad_norm": 0.13868659734725952, "critic_grad_norm": 0.015284053049981594, "ratio": 0.9993177652359009, "entropy": 0.603779943784078, "incre_win_rate": 0.9310344827586207, "step": 1059}
{"time": 1766590521.7978187, "phase": "train", "update": 1060, "total_env_steps": 3392000, "episode_reward": 0.3483371436595917, "value_loss": 0.008017884412159523, "policy_loss": -0.012606752922051594, "dist_entropy": 0.6486676176389058, "actor_grad_norm": 0.14512714743614197, "critic_grad_norm": 0.0383673794567585, "ratio": 0.998900294303894, "entropy": 0.6486676176389058, "incre_win_rate": 0.896551724137931, "step": 1060}
{"time": 1766590526.4646003, "phase": "train", "update": 1061, "total_env_steps": 3395200, "episode_reward": 0.35028722882270813, "value_loss": 0.008216992175827423, "policy_loss": -0.010506534476366862, "dist_entropy": 0.6180558522542318, "actor_grad_norm": 0.13335350155830383, "critic_grad_norm": 0.023685045540332794, "ratio": 1.000060796737671, "entropy": 0.6180558522542318, "incre_win_rate": 0.8983050847457628, "step": 1061}
{"time": 1766590533.6495209, "phase": "eval", "update": 1061, "total_env_steps": 3395200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.770833333333332, "step": 1061}
{"time": 1766590538.2279022, "phase": "train", "update": 1062, "total_env_steps": 3398400, "episode_reward": 0.36125612258911133, "value_loss": 0.004792724208285411, "policy_loss": -0.010903597816930243, "dist_entropy": 0.5969714562098185, "actor_grad_norm": 0.12942059338092804, "critic_grad_norm": 0.039355941116809845, "ratio": 0.9977606534957886, "entropy": 0.5969714562098185, "incre_win_rate": 0.9482758620689655, "step": 1062}
{"time": 1766590542.8500695, "phase": "train", "update": 1063, "total_env_steps": 3401600, "episode_reward": 0.3475934565067291, "value_loss": 0.004909058846533298, "policy_loss": -0.01040301486029307, "dist_entropy": 0.610427216688792, "actor_grad_norm": 0.12988495826721191, "critic_grad_norm": 0.018615588545799255, "ratio": 0.9998497366905212, "entropy": 0.610427216688792, "incre_win_rate": 0.9298245614035088, "step": 1063}
{"time": 1766590547.4224405, "phase": "train", "update": 1064, "total_env_steps": 3404800, "episode_reward": 0.35461705923080444, "value_loss": 0.008898727657894293, "policy_loss": -0.01080490692055811, "dist_entropy": 0.5871185223261516, "actor_grad_norm": 0.12908656895160675, "critic_grad_norm": 0.016245901584625244, "ratio": 0.9998841285705566, "entropy": 0.5871185223261516, "incre_win_rate": 0.8947368421052632, "step": 1064}
{"time": 1766590552.0637596, "phase": "train", "update": 1065, "total_env_steps": 3408000, "episode_reward": 0.36520910263061523, "value_loss": 0.005348384597649177, "policy_loss": -0.010121634886863736, "dist_entropy": 0.6093080560366313, "actor_grad_norm": 0.13607175648212433, "critic_grad_norm": 0.02449466474354267, "ratio": 0.9985255599021912, "entropy": 0.6093080560366313, "incre_win_rate": 0.95, "step": 1065}
{"time": 1766590556.6740477, "phase": "train", "update": 1066, "total_env_steps": 3411200, "episode_reward": 0.35040056705474854, "value_loss": 0.00821948324640592, "policy_loss": -0.01126058259226473, "dist_entropy": 0.622091269493103, "actor_grad_norm": 0.12288002669811249, "critic_grad_norm": 0.022934885695576668, "ratio": 0.9991171360015869, "entropy": 0.622091269493103, "incre_win_rate": 0.896551724137931, "step": 1066}
{"time": 1766590561.3069246, "phase": "train", "update": 1067, "total_env_steps": 3414400, "episode_reward": 0.3552389442920685, "value_loss": 0.00803649825975299, "policy_loss": -0.011317743852527921, "dist_entropy": 0.6272979140281677, "actor_grad_norm": 0.14519008994102478, "critic_grad_norm": 0.024225812405347824, "ratio": 1.0003929138183594, "entropy": 0.6272979140281677, "incre_win_rate": 0.9137931034482759, "step": 1067}
{"time": 1766590565.890831, "phase": "train", "update": 1068, "total_env_steps": 3417600, "episode_reward": 0.3420879542827606, "value_loss": 0.00761787345012029, "policy_loss": -0.012508465202111078, "dist_entropy": 0.6203103423118591, "actor_grad_norm": 0.153523251414299, "critic_grad_norm": 0.020616954192519188, "ratio": 1.0002268552780151, "entropy": 0.6203103423118591, "incre_win_rate": 0.8392857142857143, "step": 1068}
{"time": 1766590570.6639662, "phase": "train", "update": 1069, "total_env_steps": 3420800, "episode_reward": 0.357445627450943, "value_loss": 0.0061714909970760345, "policy_loss": -0.011641475384892411, "dist_entropy": 0.6113142450650533, "actor_grad_norm": 0.1411849707365036, "critic_grad_norm": 0.028436370193958282, "ratio": 0.999989926815033, "entropy": 0.6113142450650533, "incre_win_rate": 0.9473684210526315, "step": 1069}
{"time": 1766590575.571592, "phase": "train", "update": 1070, "total_env_steps": 3424000, "episode_reward": 0.3660409152507782, "value_loss": 0.007007941137999296, "policy_loss": -0.010754287567541236, "dist_entropy": 0.6086278001467387, "actor_grad_norm": 0.12328717112541199, "critic_grad_norm": 0.011132718995213509, "ratio": 0.9998365640640259, "entropy": 0.6086278001467387, "incre_win_rate": 0.9193548387096774, "step": 1070}
{"time": 1766590580.3846717, "phase": "train", "update": 1071, "total_env_steps": 3427200, "episode_reward": 0.3575023114681244, "value_loss": 0.007263151090592146, "policy_loss": -0.011631578341751946, "dist_entropy": 0.6039128065109253, "actor_grad_norm": 0.1301308572292328, "critic_grad_norm": 0.015239470638334751, "ratio": 0.9985261559486389, "entropy": 0.6039128065109253, "incre_win_rate": 0.85, "step": 1071}
{"time": 1766590585.7915587, "phase": "train", "update": 1072, "total_env_steps": 3430400, "episode_reward": 0.36434435844421387, "value_loss": 0.00493205583964785, "policy_loss": -0.010555523854955121, "dist_entropy": 0.6072835564613343, "actor_grad_norm": 0.1125398725271225, "critic_grad_norm": 0.012979584746062756, "ratio": 0.9990007877349854, "entropy": 0.6072835564613343, "incre_win_rate": 0.9482758620689655, "step": 1072}
{"time": 1766590590.983394, "phase": "train", "update": 1073, "total_env_steps": 3433600, "episode_reward": 0.3610861003398895, "value_loss": 0.006951377851267656, "policy_loss": -0.011467389336528792, "dist_entropy": 0.5957275470097859, "actor_grad_norm": 0.14832384884357452, "critic_grad_norm": 0.013194074854254723, "ratio": 0.9987037181854248, "entropy": 0.5957275470097859, "incre_win_rate": 0.9, "step": 1073}
{"time": 1766590596.3069956, "phase": "train", "update": 1074, "total_env_steps": 3436800, "episode_reward": 0.35785922408103943, "value_loss": 0.005614482952902715, "policy_loss": -0.009894986464682157, "dist_entropy": 0.6021064639091491, "actor_grad_norm": 0.14998069405555725, "critic_grad_norm": 0.014511295594274998, "ratio": 1.0000158548355103, "entropy": 0.6021064639091491, "incre_win_rate": 0.8983050847457628, "step": 1074}
{"time": 1766590601.7223542, "phase": "train", "update": 1075, "total_env_steps": 3440000, "episode_reward": 0.37074604630470276, "value_loss": 0.00552285360172391, "policy_loss": -0.011098742609614949, "dist_entropy": 0.6141839424769083, "actor_grad_norm": 0.13656097650527954, "critic_grad_norm": 0.01179922092705965, "ratio": 0.9990159869194031, "entropy": 0.6141839424769083, "incre_win_rate": 0.95, "step": 1075}
{"time": 1766590607.1532817, "phase": "train", "update": 1076, "total_env_steps": 3443200, "episode_reward": 0.3621867299079895, "value_loss": 0.005384417188664278, "policy_loss": -0.01074287529245718, "dist_entropy": 0.6055375695228576, "actor_grad_norm": 0.12982690334320068, "critic_grad_norm": 0.012129822745919228, "ratio": 0.9986383318901062, "entropy": 0.6055375695228576, "incre_win_rate": 0.9333333333333333, "step": 1076}
{"time": 1766590612.5572171, "phase": "train", "update": 1077, "total_env_steps": 3446400, "episode_reward": 0.35323989391326904, "value_loss": 0.008100445785870155, "policy_loss": -0.010772943432831994, "dist_entropy": 0.6104366699854533, "actor_grad_norm": 0.12046460807323456, "critic_grad_norm": 0.01992340199649334, "ratio": 1.00003182888031, "entropy": 0.6104366699854533, "incre_win_rate": 0.9107142857142857, "step": 1077}
{"time": 1766590617.9589007, "phase": "train", "update": 1078, "total_env_steps": 3449600, "episode_reward": 0.35289523005485535, "value_loss": 0.008203334485491117, "policy_loss": -0.011890271723519657, "dist_entropy": 0.6342098832130432, "actor_grad_norm": 0.13439349830150604, "critic_grad_norm": 0.014520370401442051, "ratio": 1.0000221729278564, "entropy": 0.6342098832130432, "incre_win_rate": 0.847457627118644, "step": 1078}
{"time": 1766590623.198504, "phase": "train", "update": 1079, "total_env_steps": 3452800, "episode_reward": 0.34787681698799133, "value_loss": 0.009476752455035846, "policy_loss": -0.011832856352516312, "dist_entropy": 0.6411102930704753, "actor_grad_norm": 0.13803917169570923, "critic_grad_norm": 0.025523006916046143, "ratio": 1.0006836652755737, "entropy": 0.6411102930704753, "incre_win_rate": 0.8275862068965517, "step": 1079}
{"time": 1766590628.7510338, "phase": "train", "update": 1080, "total_env_steps": 3456000, "episode_reward": 0.34012407064437866, "value_loss": 0.009670386152962843, "policy_loss": -0.01210252921321171, "dist_entropy": 0.6468114614486694, "actor_grad_norm": 0.13213488459587097, "critic_grad_norm": 0.02185470052063465, "ratio": 0.9988131523132324, "entropy": 0.6468114614486694, "incre_win_rate": 0.8571428571428571, "step": 1080}
{"time": 1766590634.4846277, "phase": "train", "update": 1081, "total_env_steps": 3459200, "episode_reward": 0.3490808606147766, "value_loss": 0.007169802238543828, "policy_loss": -0.01228465770563029, "dist_entropy": 0.6408412218093872, "actor_grad_norm": 0.1491125226020813, "critic_grad_norm": 0.015194921754300594, "ratio": 0.9995263814926147, "entropy": 0.6408412218093872, "incre_win_rate": 0.8983050847457628, "step": 1081}
{"time": 1766590642.4745686, "phase": "eval", "update": 1081, "total_env_steps": 3459200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.85110294117647, "step": 1081}
{"time": 1766590647.111947, "phase": "train", "update": 1082, "total_env_steps": 3462400, "episode_reward": 0.35090380907058716, "value_loss": 0.006668957974761724, "policy_loss": -0.01131422300814838, "dist_entropy": 0.6235477725664774, "actor_grad_norm": 0.14125341176986694, "critic_grad_norm": 0.01974715292453766, "ratio": 0.9991130828857422, "entropy": 0.6235477725664774, "incre_win_rate": 0.9298245614035088, "step": 1082}
{"time": 1766590651.7999165, "phase": "train", "update": 1083, "total_env_steps": 3465600, "episode_reward": 0.35880669951438904, "value_loss": 0.008569239017864069, "policy_loss": -0.012227442026644534, "dist_entropy": 0.6213398814201355, "actor_grad_norm": 0.135149747133255, "critic_grad_norm": 0.03962460532784462, "ratio": 0.9989101886749268, "entropy": 0.6213398814201355, "incre_win_rate": 0.9, "step": 1083}
{"time": 1766590656.3874044, "phase": "train", "update": 1084, "total_env_steps": 3468800, "episode_reward": 0.3569171130657196, "value_loss": 0.00780654630313317, "policy_loss": -0.011995938499273015, "dist_entropy": 0.6137006799379985, "actor_grad_norm": 0.14697103202342987, "critic_grad_norm": 0.049319472163915634, "ratio": 0.9990198612213135, "entropy": 0.6137006799379985, "incre_win_rate": 0.9298245614035088, "step": 1084}
{"time": 1766590661.0515544, "phase": "train", "update": 1085, "total_env_steps": 3472000, "episode_reward": 0.35840460658073425, "value_loss": 0.0046966836166878545, "policy_loss": -0.010966487284992372, "dist_entropy": 0.6295974651972452, "actor_grad_norm": 0.14500215649604797, "critic_grad_norm": 0.03090071491897106, "ratio": 0.9999980926513672, "entropy": 0.6295974651972452, "incre_win_rate": 0.9152542372881356, "step": 1085}
{"time": 1766590665.6098592, "phase": "train", "update": 1086, "total_env_steps": 3475200, "episode_reward": 0.35214462876319885, "value_loss": 0.009752715068558852, "policy_loss": -0.013039961737842038, "dist_entropy": 0.6338883797327678, "actor_grad_norm": 0.15598443150520325, "critic_grad_norm": 0.0766286626458168, "ratio": 1.0004054307937622, "entropy": 0.6338883797327678, "incre_win_rate": 0.8333333333333334, "step": 1086}
{"time": 1766590670.241826, "phase": "train", "update": 1087, "total_env_steps": 3478400, "episode_reward": 0.3552512526512146, "value_loss": 0.007021177249650161, "policy_loss": -0.013183526806592264, "dist_entropy": 0.6087458928426107, "actor_grad_norm": 0.16280964016914368, "critic_grad_norm": 0.020164094865322113, "ratio": 0.9994315505027771, "entropy": 0.6087458928426107, "incre_win_rate": 0.8620689655172413, "step": 1087}
{"time": 1766590674.904505, "phase": "train", "update": 1088, "total_env_steps": 3481600, "episode_reward": 0.3491551876068115, "value_loss": 0.005407123329738776, "policy_loss": -0.012471948272249971, "dist_entropy": 0.6195284048716228, "actor_grad_norm": 0.1862478256225586, "critic_grad_norm": 0.0303337499499321, "ratio": 0.9990758299827576, "entropy": 0.6195284048716228, "incre_win_rate": 0.9137931034482759, "step": 1088}
{"time": 1766590679.5017982, "phase": "train", "update": 1089, "total_env_steps": 3484800, "episode_reward": 0.33995407819747925, "value_loss": 0.008923002270360787, "policy_loss": -0.01221866888618995, "dist_entropy": 0.6123736103375753, "actor_grad_norm": 0.1380525678396225, "critic_grad_norm": 0.03253360837697983, "ratio": 0.9992763996124268, "entropy": 0.6123736103375753, "incre_win_rate": 0.8275862068965517, "step": 1089}
{"time": 1766590684.0597355, "phase": "train", "update": 1090, "total_env_steps": 3488000, "episode_reward": 0.3622349798679352, "value_loss": 0.004324228720118602, "policy_loss": -0.011944930336979099, "dist_entropy": 0.6172535220781962, "actor_grad_norm": 0.14621171355247498, "critic_grad_norm": 0.06261380761861801, "ratio": 0.9998106956481934, "entropy": 0.6172535220781962, "incre_win_rate": 0.9310344827586207, "step": 1090}
{"time": 1766590688.6293797, "phase": "train", "update": 1091, "total_env_steps": 3491200, "episode_reward": 0.35271525382995605, "value_loss": 0.007907735214879115, "policy_loss": -0.01087041191278028, "dist_entropy": 0.5930415272712708, "actor_grad_norm": 0.13707950711250305, "critic_grad_norm": 0.03407059609889984, "ratio": 1.000856876373291, "entropy": 0.5930415272712708, "incre_win_rate": 0.8793103448275862, "step": 1091}
{"time": 1766590693.1818097, "phase": "train", "update": 1092, "total_env_steps": 3494400, "episode_reward": 0.3492073118686676, "value_loss": 0.006327728771915038, "policy_loss": -0.012947061549285384, "dist_entropy": 0.6133973916371663, "actor_grad_norm": 0.15843944251537323, "critic_grad_norm": 0.019373781979084015, "ratio": 0.9999657869338989, "entropy": 0.6133973916371663, "incre_win_rate": 0.9298245614035088, "step": 1092}
{"time": 1766590697.8537192, "phase": "train", "update": 1093, "total_env_steps": 3497600, "episode_reward": 0.36097657680511475, "value_loss": 0.006526254458973805, "policy_loss": -0.012683330436142034, "dist_entropy": 0.6063421289126079, "actor_grad_norm": 0.13131001591682434, "critic_grad_norm": 0.031581394374370575, "ratio": 0.9988080263137817, "entropy": 0.6063421289126079, "incre_win_rate": 0.8983050847457628, "step": 1093}
{"time": 1766590702.4237957, "phase": "train", "update": 1094, "total_env_steps": 3500800, "episode_reward": 0.35602709650993347, "value_loss": 0.006495531803617875, "policy_loss": -0.011592981621739303, "dist_entropy": 0.6166422963142395, "actor_grad_norm": 0.12775400280952454, "critic_grad_norm": 0.017588889226317406, "ratio": 0.999932050704956, "entropy": 0.6166422963142395, "incre_win_rate": 0.8793103448275862, "step": 1094}
{"time": 1766590707.065919, "phase": "train", "update": 1095, "total_env_steps": 3504000, "episode_reward": 0.356873482465744, "value_loss": 0.0048656756368776165, "policy_loss": -0.011610100815901763, "dist_entropy": 0.6133728782335918, "actor_grad_norm": 0.140373095870018, "critic_grad_norm": 0.009165630675852299, "ratio": 0.9985178709030151, "entropy": 0.6133728782335918, "incre_win_rate": 0.9322033898305084, "step": 1095}
{"time": 1766590711.6665618, "phase": "train", "update": 1096, "total_env_steps": 3507200, "episode_reward": 0.3490808606147766, "value_loss": 0.00785160701101025, "policy_loss": -0.013630470140160373, "dist_entropy": 0.6172605395317078, "actor_grad_norm": 0.14181385934352875, "critic_grad_norm": 0.012454167008399963, "ratio": 0.9985163807868958, "entropy": 0.6172605395317078, "incre_win_rate": 0.8771929824561403, "step": 1096}
{"time": 1766590716.2555149, "phase": "train", "update": 1097, "total_env_steps": 3510400, "episode_reward": 0.35834020376205444, "value_loss": 0.006152192472169796, "policy_loss": -0.010368760282257364, "dist_entropy": 0.617845873037974, "actor_grad_norm": 0.10872896760702133, "critic_grad_norm": 0.014322367496788502, "ratio": 1.0008008480072021, "entropy": 0.617845873037974, "incre_win_rate": 0.9152542372881356, "step": 1097}
{"time": 1766590720.8285596, "phase": "train", "update": 1098, "total_env_steps": 3513600, "episode_reward": 0.3601876497268677, "value_loss": 0.005762027172992627, "policy_loss": -0.012313811883999885, "dist_entropy": 0.618689235051473, "actor_grad_norm": 0.14985613524913788, "critic_grad_norm": 0.010314902290701866, "ratio": 0.9992679953575134, "entropy": 0.618689235051473, "incre_win_rate": 0.8833333333333333, "step": 1098}
{"time": 1766590725.44518, "phase": "train", "update": 1099, "total_env_steps": 3516800, "episode_reward": 0.35289138555526733, "value_loss": 0.010882087610661983, "policy_loss": -0.0128628148466035, "dist_entropy": 0.6137065966924031, "actor_grad_norm": 0.14262518286705017, "critic_grad_norm": 0.040150899440050125, "ratio": 1.0003412961959839, "entropy": 0.6137065966924031, "incre_win_rate": 0.8947368421052632, "step": 1099}
{"time": 1766590730.0539355, "phase": "train", "update": 1100, "total_env_steps": 3520000, "episode_reward": 0.3465418517589569, "value_loss": 0.01208090844253699, "policy_loss": -0.01252530770806833, "dist_entropy": 0.5880568941434224, "actor_grad_norm": 0.13489431142807007, "critic_grad_norm": 0.031455814838409424, "ratio": 1.000188946723938, "entropy": 0.5880568941434224, "incre_win_rate": 0.8448275862068966, "step": 1100}
{"time": 1766590734.7026272, "phase": "train", "update": 1101, "total_env_steps": 3523200, "episode_reward": 0.3541574776172638, "value_loss": 0.006566113916536173, "policy_loss": -0.011765170181117906, "dist_entropy": 0.6128833532333374, "actor_grad_norm": 0.13739103078842163, "critic_grad_norm": 0.024343255907297134, "ratio": 0.9983776807785034, "entropy": 0.6128833532333374, "incre_win_rate": 0.8688524590163934, "step": 1101}
{"time": 1766590741.9568424, "phase": "eval", "update": 1101, "total_env_steps": 3523200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.843826593137255, "step": 1101}
{"time": 1766590746.5471306, "phase": "train", "update": 1102, "total_env_steps": 3526400, "episode_reward": 0.35118409991264343, "value_loss": 0.009140447775522868, "policy_loss": -0.012258577336457558, "dist_entropy": 0.6059775749842325, "actor_grad_norm": 0.12385429441928864, "critic_grad_norm": 0.01719440147280693, "ratio": 1.0009063482284546, "entropy": 0.6059775749842325, "incre_win_rate": 0.8771929824561403, "step": 1102}
{"time": 1766590751.207329, "phase": "train", "update": 1103, "total_env_steps": 3529600, "episode_reward": 0.3307467997074127, "value_loss": 0.008585875295102597, "policy_loss": -0.01316694530354828, "dist_entropy": 0.6274566888809204, "actor_grad_norm": 0.1484028398990631, "critic_grad_norm": 0.013199650682508945, "ratio": 0.9994792342185974, "entropy": 0.6274566888809204, "incre_win_rate": 0.8148148148148148, "step": 1103}
{"time": 1766590755.7975187, "phase": "train", "update": 1104, "total_env_steps": 3532800, "episode_reward": 0.3478255271911621, "value_loss": 0.006398805696517229, "policy_loss": -0.011657781601488181, "dist_entropy": 0.6321524341901144, "actor_grad_norm": 0.14531297981739044, "critic_grad_norm": 0.014399058185517788, "ratio": 0.9999456405639648, "entropy": 0.6321524341901144, "incre_win_rate": 0.864406779661017, "step": 1104}
{"time": 1766590760.398649, "phase": "train", "update": 1105, "total_env_steps": 3536000, "episode_reward": 0.35005590319633484, "value_loss": 0.005237652547657489, "policy_loss": -0.01259924266866932, "dist_entropy": 0.6078638394673666, "actor_grad_norm": 0.14384452998638153, "critic_grad_norm": 0.015355086885392666, "ratio": 0.9986327886581421, "entropy": 0.6078638394673666, "incre_win_rate": 0.9298245614035088, "step": 1105}
{"time": 1766590765.0182526, "phase": "train", "update": 1106, "total_env_steps": 3539200, "episode_reward": 0.34843525290489197, "value_loss": 0.010346069559454918, "policy_loss": -0.012917916038466615, "dist_entropy": 0.6035666863123575, "actor_grad_norm": 0.14192448556423187, "critic_grad_norm": 0.06573420763015747, "ratio": 0.9986624121665955, "entropy": 0.6035666863123575, "incre_win_rate": 0.8333333333333334, "step": 1106}
{"time": 1766590769.6370893, "phase": "train", "update": 1107, "total_env_steps": 3542400, "episode_reward": 0.353246808052063, "value_loss": 0.00851066888620456, "policy_loss": -0.010856829584972161, "dist_entropy": 0.6097877422968546, "actor_grad_norm": 0.15141090750694275, "critic_grad_norm": 0.02511424943804741, "ratio": 0.9996840953826904, "entropy": 0.6097877422968546, "incre_win_rate": 0.896551724137931, "step": 1107}
{"time": 1766590774.2047148, "phase": "train", "update": 1108, "total_env_steps": 3545600, "episode_reward": 0.3531204164028168, "value_loss": 0.006655922066420317, "policy_loss": -0.01123463797267732, "dist_entropy": 0.6087423960367838, "actor_grad_norm": 0.13181832432746887, "critic_grad_norm": 0.022478537634015083, "ratio": 0.9994614720344543, "entropy": 0.6087423960367838, "incre_win_rate": 0.8771929824561403, "step": 1108}
{"time": 1766590778.8266778, "phase": "train", "update": 1109, "total_env_steps": 3548800, "episode_reward": 0.34633582830429077, "value_loss": 0.009860419419904549, "policy_loss": -0.011958227812039486, "dist_entropy": 0.6080997387568156, "actor_grad_norm": 0.13458392024040222, "critic_grad_norm": 0.01594819314777851, "ratio": 0.9991554617881775, "entropy": 0.6080997387568156, "incre_win_rate": 0.847457627118644, "step": 1109}
{"time": 1766590783.4110403, "phase": "train", "update": 1110, "total_env_steps": 3552000, "episode_reward": 0.3395794928073883, "value_loss": 0.008094761706888675, "policy_loss": -0.013500764227000417, "dist_entropy": 0.629103418191274, "actor_grad_norm": 0.12562210857868195, "critic_grad_norm": 0.040166083723306656, "ratio": 0.999837338924408, "entropy": 0.629103418191274, "incre_win_rate": 0.7931034482758621, "step": 1110}
{"time": 1766590788.0014029, "phase": "train", "update": 1111, "total_env_steps": 3555200, "episode_reward": 0.3350405991077423, "value_loss": 0.008445563353598117, "policy_loss": -0.012130425612245688, "dist_entropy": 0.6228088100751241, "actor_grad_norm": 0.17124956846237183, "critic_grad_norm": 0.015365504659712315, "ratio": 1.0001929998397827, "entropy": 0.6228088100751241, "incre_win_rate": 0.8392857142857143, "step": 1111}
{"time": 1766590792.6516654, "phase": "train", "update": 1112, "total_env_steps": 3558400, "episode_reward": 0.3528408110141754, "value_loss": 0.00769695732742548, "policy_loss": -0.012262124475575812, "dist_entropy": 0.6372203707695008, "actor_grad_norm": 0.15804941952228546, "critic_grad_norm": 0.016286198049783707, "ratio": 1.0002034902572632, "entropy": 0.6372203707695008, "incre_win_rate": 0.8448275862068966, "step": 1112}
{"time": 1766590797.2707653, "phase": "train", "update": 1113, "total_env_steps": 3561600, "episode_reward": 0.34468138217926025, "value_loss": 0.009288806468248367, "policy_loss": -0.0119491772040071, "dist_entropy": 0.6324296514193217, "actor_grad_norm": 0.15715262293815613, "critic_grad_norm": 0.024101227521896362, "ratio": 0.9990456700325012, "entropy": 0.6324296514193217, "incre_win_rate": 0.8620689655172413, "step": 1113}
{"time": 1766590802.08646, "phase": "train", "update": 1114, "total_env_steps": 3564800, "episode_reward": 0.3531602621078491, "value_loss": 0.005533604603260756, "policy_loss": -0.012187113399743528, "dist_entropy": 0.6354699571927388, "actor_grad_norm": 0.14521299302577972, "critic_grad_norm": 0.08037588000297546, "ratio": 0.9988941550254822, "entropy": 0.6354699571927388, "incre_win_rate": 0.8983050847457628, "step": 1114}
{"time": 1766590806.6595263, "phase": "train", "update": 1115, "total_env_steps": 3568000, "episode_reward": 0.35583409667015076, "value_loss": 0.004610098929454883, "policy_loss": -0.01263084289801005, "dist_entropy": 0.6446120699246725, "actor_grad_norm": 0.14298288524150848, "critic_grad_norm": 0.030956892296671867, "ratio": 0.9975966215133667, "entropy": 0.6446120699246725, "incre_win_rate": 0.9642857142857143, "step": 1115}
{"time": 1766590811.2912948, "phase": "train", "update": 1116, "total_env_steps": 3571200, "episode_reward": 0.3438396155834198, "value_loss": 0.008938870765268803, "policy_loss": -0.012475240685350285, "dist_entropy": 0.6385860641797384, "actor_grad_norm": 0.1368766874074936, "critic_grad_norm": 0.04376158118247986, "ratio": 1.0006157159805298, "entropy": 0.6385860641797384, "incre_win_rate": 0.8928571428571429, "step": 1116}
{"time": 1766590815.9385593, "phase": "train", "update": 1117, "total_env_steps": 3574400, "episode_reward": 0.3543773293495178, "value_loss": 0.0067341754833857214, "policy_loss": -0.01209697867337501, "dist_entropy": 0.6467609127362569, "actor_grad_norm": 0.13051295280456543, "critic_grad_norm": 0.025570157915353775, "ratio": 1.0001686811447144, "entropy": 0.6467609127362569, "incre_win_rate": 0.8852459016393442, "step": 1117}
{"time": 1766590820.5962286, "phase": "train", "update": 1118, "total_env_steps": 3577600, "episode_reward": 0.3540495038032532, "value_loss": 0.006553051155060529, "policy_loss": -0.011720859531817023, "dist_entropy": 0.642047127087911, "actor_grad_norm": 0.13515982031822205, "critic_grad_norm": 0.012133948504924774, "ratio": 1.0007692575454712, "entropy": 0.642047127087911, "incre_win_rate": 0.9285714285714286, "step": 1118}
{"time": 1766590825.2415316, "phase": "train", "update": 1119, "total_env_steps": 3580800, "episode_reward": 0.34296953678131104, "value_loss": 0.00793389327203234, "policy_loss": -0.012000844618764243, "dist_entropy": 0.6473797639211019, "actor_grad_norm": 0.1257816106081009, "critic_grad_norm": 0.01951618678867817, "ratio": 1.0003249645233154, "entropy": 0.6473797639211019, "incre_win_rate": 0.8771929824561403, "step": 1119}
{"time": 1766590829.8686712, "phase": "train", "update": 1120, "total_env_steps": 3584000, "episode_reward": 0.3400712311267853, "value_loss": 0.00890382540722688, "policy_loss": -0.012289161011178369, "dist_entropy": 0.633674172560374, "actor_grad_norm": 0.14236211776733398, "critic_grad_norm": 0.05158663168549538, "ratio": 1.0007832050323486, "entropy": 0.633674172560374, "incre_win_rate": 0.8166666666666667, "step": 1120}
{"time": 1766590834.458092, "phase": "train", "update": 1121, "total_env_steps": 3587200, "episode_reward": 0.3427213728427887, "value_loss": 0.010485221693913142, "policy_loss": -0.013245421485477967, "dist_entropy": 0.6267712910970052, "actor_grad_norm": 0.16356559097766876, "critic_grad_norm": 0.05482172593474388, "ratio": 0.9980724453926086, "entropy": 0.6267712910970052, "incre_win_rate": 0.8363636363636363, "step": 1121}
{"time": 1766590841.7339108, "phase": "eval", "update": 1121, "total_env_steps": 3587200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.62484681372549, "step": 1121}
{"time": 1766590846.3712337, "phase": "train", "update": 1122, "total_env_steps": 3590400, "episode_reward": 0.34685203433036804, "value_loss": 0.007838839416702588, "policy_loss": -0.013459425317794189, "dist_entropy": 0.6308342456817627, "actor_grad_norm": 0.17686833441257477, "critic_grad_norm": 0.02320287935435772, "ratio": 0.9990999102592468, "entropy": 0.6308342456817627, "incre_win_rate": 0.864406779661017, "step": 1122}
{"time": 1766590851.0827827, "phase": "train", "update": 1123, "total_env_steps": 3593600, "episode_reward": 0.35403722524642944, "value_loss": 0.004898935928940773, "policy_loss": -0.012677722721832652, "dist_entropy": 0.6431375781695048, "actor_grad_norm": 0.1339397430419922, "critic_grad_norm": 0.012230249121785164, "ratio": 1.0007545948028564, "entropy": 0.6431375781695048, "incre_win_rate": 0.8983050847457628, "step": 1123}
{"time": 1766590855.7045565, "phase": "train", "update": 1124, "total_env_steps": 3596800, "episode_reward": 0.35497015714645386, "value_loss": 0.004535354115068913, "policy_loss": -0.012068744357929618, "dist_entropy": 0.637582806746165, "actor_grad_norm": 0.14981333911418915, "critic_grad_norm": 0.011379810981452465, "ratio": 1.0003129243850708, "entropy": 0.637582806746165, "incre_win_rate": 0.8947368421052632, "step": 1124}
{"time": 1766590860.3345652, "phase": "train", "update": 1125, "total_env_steps": 3600000, "episode_reward": 0.3544860780239105, "value_loss": 0.004475740281244119, "policy_loss": -0.011086855983523946, "dist_entropy": 0.6209123373031616, "actor_grad_norm": 0.1399073600769043, "critic_grad_norm": 0.008153137750923634, "ratio": 0.9990319013595581, "entropy": 0.6209123373031616, "incre_win_rate": 0.9166666666666666, "step": 1125}
{"time": 1766590864.9617736, "phase": "train", "update": 1126, "total_env_steps": 3603200, "episode_reward": 0.3559581935405731, "value_loss": 0.008643136949588855, "policy_loss": -0.011744123539050359, "dist_entropy": 0.6425236860911051, "actor_grad_norm": 0.1355627477169037, "critic_grad_norm": 0.013563682325184345, "ratio": 1.0000981092453003, "entropy": 0.6425236860911051, "incre_win_rate": 0.896551724137931, "step": 1126}
{"time": 1766590869.6134083, "phase": "train", "update": 1127, "total_env_steps": 3606400, "episode_reward": 0.363012433052063, "value_loss": 0.005679906470080217, "policy_loss": -0.011770742434813996, "dist_entropy": 0.6472229679425557, "actor_grad_norm": 0.13931019604206085, "critic_grad_norm": 0.014825629070401192, "ratio": 0.9993107318878174, "entropy": 0.6472229679425557, "incre_win_rate": 0.9166666666666666, "step": 1127}
{"time": 1766590874.191957, "phase": "train", "update": 1128, "total_env_steps": 3609600, "episode_reward": 0.3518750071525574, "value_loss": 0.006274021603167057, "policy_loss": -0.012419267931256427, "dist_entropy": 0.6309478958447774, "actor_grad_norm": 0.15523654222488403, "critic_grad_norm": 0.0113409124314785, "ratio": 0.9999523758888245, "entropy": 0.6309478958447774, "incre_win_rate": 0.8947368421052632, "step": 1128}
{"time": 1766590878.8408043, "phase": "train", "update": 1129, "total_env_steps": 3612800, "episode_reward": 0.3576164245605469, "value_loss": 0.008308086140702168, "policy_loss": -0.012935709362392581, "dist_entropy": 0.6316158652305603, "actor_grad_norm": 0.14939549565315247, "critic_grad_norm": 0.05143355950713158, "ratio": 1.000118613243103, "entropy": 0.6316158652305603, "incre_win_rate": 0.8833333333333333, "step": 1129}
{"time": 1766590883.5075064, "phase": "train", "update": 1130, "total_env_steps": 3616000, "episode_reward": 0.35816484689712524, "value_loss": 0.007013163591424624, "policy_loss": -0.012415738310556416, "dist_entropy": 0.6470883051554362, "actor_grad_norm": 0.14772117137908936, "critic_grad_norm": 0.026658184826374054, "ratio": 1.0008740425109863, "entropy": 0.6470883051554362, "incre_win_rate": 0.8666666666666667, "step": 1130}
{"time": 1766590888.1555727, "phase": "train", "update": 1131, "total_env_steps": 3619200, "episode_reward": 0.3527098596096039, "value_loss": 0.007856844955434402, "policy_loss": -0.01278131772989178, "dist_entropy": 0.6700767159461976, "actor_grad_norm": 0.1351587474346161, "critic_grad_norm": 0.03980858623981476, "ratio": 0.9990149736404419, "entropy": 0.6700767159461976, "incre_win_rate": 0.9473684210526315, "step": 1131}
{"time": 1766590892.751681, "phase": "train", "update": 1132, "total_env_steps": 3622400, "episode_reward": 0.32560738921165466, "value_loss": 0.006964363157749176, "policy_loss": -0.012636800859607196, "dist_entropy": 0.6641849120457967, "actor_grad_norm": 0.1308821439743042, "critic_grad_norm": 0.01724180206656456, "ratio": 1.0004560947418213, "entropy": 0.6641849120457967, "incre_win_rate": 0.8333333333333334, "step": 1132}
{"time": 1766590897.3318107, "phase": "train", "update": 1133, "total_env_steps": 3625600, "episode_reward": 0.3513725697994232, "value_loss": 0.007373866531997919, "policy_loss": -0.01342565358348035, "dist_entropy": 0.6809742450714111, "actor_grad_norm": 0.14051680266857147, "critic_grad_norm": 0.01487424410879612, "ratio": 0.9996225237846375, "entropy": 0.6809742450714111, "incre_win_rate": 0.8833333333333333, "step": 1133}
{"time": 1766590901.9762847, "phase": "train", "update": 1134, "total_env_steps": 3628800, "episode_reward": 0.33961936831474304, "value_loss": 0.008870890612403553, "policy_loss": -0.01166012804206389, "dist_entropy": 0.6691131552060445, "actor_grad_norm": 0.1418067216873169, "critic_grad_norm": 0.023521726951003075, "ratio": 1.0002143383026123, "entropy": 0.6691131552060445, "incre_win_rate": 0.8571428571428571, "step": 1134}
{"time": 1766590906.6075368, "phase": "train", "update": 1135, "total_env_steps": 3632000, "episode_reward": 0.3453109860420227, "value_loss": 0.006716331529120604, "policy_loss": -0.013684466416347619, "dist_entropy": 0.6668031414349874, "actor_grad_norm": 0.13384132087230682, "critic_grad_norm": 0.008396145887672901, "ratio": 0.9996642470359802, "entropy": 0.6668031414349874, "incre_win_rate": 0.8771929824561403, "step": 1135}
{"time": 1766590911.3370154, "phase": "train", "update": 1136, "total_env_steps": 3635200, "episode_reward": 0.3362293541431427, "value_loss": 0.009255762211978436, "policy_loss": -0.013835921705283975, "dist_entropy": 0.6564136028289795, "actor_grad_norm": 0.17085056006908417, "critic_grad_norm": 0.05192342400550842, "ratio": 0.9987963438034058, "entropy": 0.6564136028289795, "incre_win_rate": 0.8214285714285714, "step": 1136}
{"time": 1766590916.0747778, "phase": "train", "update": 1137, "total_env_steps": 3638400, "episode_reward": 0.3426501154899597, "value_loss": 0.008772144839167596, "policy_loss": -0.013245689019530478, "dist_entropy": 0.6523763577143351, "actor_grad_norm": 0.15801532566547394, "critic_grad_norm": 0.03502550721168518, "ratio": 1.0000022649765015, "entropy": 0.6523763577143351, "incre_win_rate": 0.7931034482758621, "step": 1137}
{"time": 1766590920.7234168, "phase": "train", "update": 1138, "total_env_steps": 3641600, "episode_reward": 0.3537798821926117, "value_loss": 0.006333777712037166, "policy_loss": -0.0124378800040238, "dist_entropy": 0.665531853834788, "actor_grad_norm": 0.16176484525203705, "critic_grad_norm": 0.061882443726062775, "ratio": 0.9987033009529114, "entropy": 0.665531853834788, "incre_win_rate": 0.8666666666666667, "step": 1138}
{"time": 1766590925.3093493, "phase": "train", "update": 1139, "total_env_steps": 3644800, "episode_reward": 0.3466360569000244, "value_loss": 0.007975538385411103, "policy_loss": -0.013313929590331005, "dist_entropy": 0.6472751379013062, "actor_grad_norm": 0.18608729541301727, "critic_grad_norm": 0.030817199498414993, "ratio": 0.9993772506713867, "entropy": 0.6472751379013062, "incre_win_rate": 0.8596491228070176, "step": 1139}
{"time": 1766590929.9353535, "phase": "train", "update": 1140, "total_env_steps": 3648000, "episode_reward": 0.35205042362213135, "value_loss": 0.008091686448703209, "policy_loss": -0.011615814237289138, "dist_entropy": 0.6665048042933146, "actor_grad_norm": 0.15617622435092926, "critic_grad_norm": 0.014400443993508816, "ratio": 1.0009944438934326, "entropy": 0.6665048042933146, "incre_win_rate": 0.8620689655172413, "step": 1140}
{"time": 1766590934.610434, "phase": "train", "update": 1141, "total_env_steps": 3651200, "episode_reward": 0.35039445757865906, "value_loss": 0.009222056282063325, "policy_loss": -0.01278781337080268, "dist_entropy": 0.6542326211929321, "actor_grad_norm": 0.15001365542411804, "critic_grad_norm": 0.02284432202577591, "ratio": 1.0000991821289062, "entropy": 0.6542326211929321, "incre_win_rate": 0.8813559322033898, "step": 1141}
{"time": 1766590941.9636784, "phase": "eval", "update": 1141, "total_env_steps": 3651200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.831341911764707, "step": 1141}
{"time": 1766590972.960249, "phase": "train", "update": 1142, "total_env_steps": 3654400, "episode_reward": 0.3296070694923401, "value_loss": 0.0463626983265082, "policy_loss": -0.009949454626347175, "dist_entropy": 0.6318109114964803, "actor_grad_norm": 0.11809160560369492, "critic_grad_norm": 0.10351981222629547, "ratio": 1.000511884689331, "entropy": 0.6318109114964803, "incre_win_rate": 0.7692307692307693, "step": 1142}
{"time": 1766590977.524616, "phase": "train", "update": 1143, "total_env_steps": 3657600, "episode_reward": 0.3366161286830902, "value_loss": 0.010814810606340567, "policy_loss": -0.013225302517020528, "dist_entropy": 0.6418356021245321, "actor_grad_norm": 0.16087724268436432, "critic_grad_norm": 0.05110412836074829, "ratio": 0.998931348323822, "entropy": 0.6418356021245321, "incre_win_rate": 0.7627118644067796, "step": 1143}
{"time": 1766590982.171575, "phase": "train", "update": 1144, "total_env_steps": 3660800, "episode_reward": 0.3505231440067291, "value_loss": 0.005078502465039492, "policy_loss": -0.013251265866416399, "dist_entropy": 0.6364903251330057, "actor_grad_norm": 0.15074633061885834, "critic_grad_norm": 0.06270236521959305, "ratio": 0.9991350769996643, "entropy": 0.6364903251330057, "incre_win_rate": 0.9298245614035088, "step": 1144}
{"time": 1766590986.770927, "phase": "train", "update": 1145, "total_env_steps": 3664000, "episode_reward": 0.346315860748291, "value_loss": 0.007800550510485967, "policy_loss": -0.011347421927154737, "dist_entropy": 0.6411254008611044, "actor_grad_norm": 0.1453215777873993, "critic_grad_norm": 0.02647378109395504, "ratio": 1.0005505084991455, "entropy": 0.6411254008611044, "incre_win_rate": 0.8947368421052632, "step": 1145}
{"time": 1766590991.4026804, "phase": "train", "update": 1146, "total_env_steps": 3667200, "episode_reward": 0.35188573598861694, "value_loss": 0.0058702207170426846, "policy_loss": -0.01219337144578579, "dist_entropy": 0.6458302815755208, "actor_grad_norm": 0.1269570291042328, "critic_grad_norm": 0.017930928617715836, "ratio": 0.999586820602417, "entropy": 0.6458302815755208, "incre_win_rate": 0.9285714285714286, "step": 1146}
{"time": 1766590996.0394745, "phase": "train", "update": 1147, "total_env_steps": 3670400, "episode_reward": 0.35399430990219116, "value_loss": 0.0047706598105529945, "policy_loss": -0.013321037364060354, "dist_entropy": 0.6580430388450622, "actor_grad_norm": 0.13881297409534454, "critic_grad_norm": 0.01800007000565529, "ratio": 0.9987099170684814, "entropy": 0.6580430388450622, "incre_win_rate": 0.9655172413793104, "step": 1147}
{"time": 1766591000.6691635, "phase": "train", "update": 1148, "total_env_steps": 3673600, "episode_reward": 0.3527657985687256, "value_loss": 0.005563232023268938, "policy_loss": -0.011408034559341355, "dist_entropy": 0.6462348341941834, "actor_grad_norm": 0.12943482398986816, "critic_grad_norm": 0.017247650772333145, "ratio": 1.0005037784576416, "entropy": 0.6462348341941834, "incre_win_rate": 0.9166666666666666, "step": 1148}
{"time": 1766591005.2478943, "phase": "train", "update": 1149, "total_env_steps": 3676800, "episode_reward": 0.3435860872268677, "value_loss": 0.0043739860877394674, "policy_loss": -0.012135624474800011, "dist_entropy": 0.6423041582107544, "actor_grad_norm": 0.13076551258563995, "critic_grad_norm": 0.019234193488955498, "ratio": 0.9996650218963623, "entropy": 0.6423041582107544, "incre_win_rate": 0.8909090909090909, "step": 1149}
{"time": 1766591009.8284557, "phase": "train", "update": 1150, "total_env_steps": 3680000, "episode_reward": 0.346935510635376, "value_loss": 0.006492461481442054, "policy_loss": -0.013541235703212825, "dist_entropy": 0.6384456117947896, "actor_grad_norm": 0.15895940363407135, "critic_grad_norm": 0.026368508115410805, "ratio": 1.0004923343658447, "entropy": 0.6384456117947896, "incre_win_rate": 0.8620689655172413, "step": 1150}
{"time": 1766591014.4825456, "phase": "train", "update": 1151, "total_env_steps": 3683200, "episode_reward": 0.3495611250400543, "value_loss": 0.0069120043267806375, "policy_loss": -0.013936395308230468, "dist_entropy": 0.6228700200716655, "actor_grad_norm": 0.13988886773586273, "critic_grad_norm": 0.022287718951702118, "ratio": 0.9989024996757507, "entropy": 0.6228700200716655, "incre_win_rate": 0.8771929824561403, "step": 1151}
{"time": 1766591019.0350757, "phase": "train", "update": 1152, "total_env_steps": 3686400, "episode_reward": 0.3478638231754303, "value_loss": 0.006769030696401993, "policy_loss": -0.012494482044573612, "dist_entropy": 0.6404328942298889, "actor_grad_norm": 0.14804042875766754, "critic_grad_norm": 0.015580427832901478, "ratio": 1.000740885734558, "entropy": 0.6404328942298889, "incre_win_rate": 0.9122807017543859, "step": 1152}
{"time": 1766591023.6212142, "phase": "train", "update": 1153, "total_env_steps": 3689600, "episode_reward": 0.3458731770515442, "value_loss": 0.007751532799253861, "policy_loss": -0.012960120775744599, "dist_entropy": 0.6497041861216227, "actor_grad_norm": 0.1648866832256317, "critic_grad_norm": 0.019750555977225304, "ratio": 1.0007827281951904, "entropy": 0.6497041861216227, "incre_win_rate": 0.847457627118644, "step": 1153}
{"time": 1766591028.2632842, "phase": "train", "update": 1154, "total_env_steps": 3692800, "episode_reward": 0.33815717697143555, "value_loss": 0.010026651496688525, "policy_loss": -0.013545157890486336, "dist_entropy": 0.6347644488016765, "actor_grad_norm": 0.16194066405296326, "critic_grad_norm": 0.016883326694369316, "ratio": 0.9983766078948975, "entropy": 0.6347644488016765, "incre_win_rate": 0.8035714285714286, "step": 1154}
{"time": 1766591032.887241, "phase": "train", "update": 1155, "total_env_steps": 3696000, "episode_reward": 0.3582881689071655, "value_loss": 0.004566061527778705, "policy_loss": -0.012164796431852665, "dist_entropy": 0.6547663331031799, "actor_grad_norm": 0.12748518586158752, "critic_grad_norm": 0.05048592388629913, "ratio": 0.9996833205223083, "entropy": 0.6547663331031799, "incre_win_rate": 0.9661016949152542, "step": 1155}
{"time": 1766591037.4880447, "phase": "train", "update": 1156, "total_env_steps": 3699200, "episode_reward": 0.3394240140914917, "value_loss": 0.006063452145705621, "policy_loss": -0.012801770088599559, "dist_entropy": 0.6463057597478231, "actor_grad_norm": 0.1281663030385971, "critic_grad_norm": 0.03772033005952835, "ratio": 1.0000935792922974, "entropy": 0.6463057597478231, "incre_win_rate": 0.9090909090909091, "step": 1156}
{"time": 1766591042.1081305, "phase": "train", "update": 1157, "total_env_steps": 3702400, "episode_reward": 0.34545037150382996, "value_loss": 0.007344091280053059, "policy_loss": -0.013654218664206042, "dist_entropy": 0.6586264371871948, "actor_grad_norm": 0.13746562600135803, "critic_grad_norm": 0.03765345737338066, "ratio": 0.998894214630127, "entropy": 0.6586264371871948, "incre_win_rate": 0.8771929824561403, "step": 1157}
{"time": 1766591046.7190466, "phase": "train", "update": 1158, "total_env_steps": 3705600, "episode_reward": 0.34763404726982117, "value_loss": 0.00502939373254776, "policy_loss": -0.011691581279925837, "dist_entropy": 0.6635668396949768, "actor_grad_norm": 0.17666299641132355, "critic_grad_norm": 0.0118598947301507, "ratio": 1.000525712966919, "entropy": 0.6635668396949768, "incre_win_rate": 0.9473684210526315, "step": 1158}
{"time": 1766591051.4105887, "phase": "train", "update": 1159, "total_env_steps": 3708800, "episode_reward": 0.36082184314727783, "value_loss": 0.003900998504832387, "policy_loss": -0.010831498764657492, "dist_entropy": 0.6502025365829468, "actor_grad_norm": 0.17420388758182526, "critic_grad_norm": 0.009119052439928055, "ratio": 0.9995324611663818, "entropy": 0.6502025365829468, "incre_win_rate": 0.9310344827586207, "step": 1159}
{"time": 1766591056.0414076, "phase": "train", "update": 1160, "total_env_steps": 3712000, "episode_reward": 0.36043429374694824, "value_loss": 0.0032702552309880656, "policy_loss": -0.01266682022213293, "dist_entropy": 0.6416795969009399, "actor_grad_norm": 0.16273562610149384, "critic_grad_norm": 0.020683079957962036, "ratio": 1.000450849533081, "entropy": 0.6416795969009399, "incre_win_rate": 0.9827586206896551, "step": 1160}
{"time": 1766591060.6872773, "phase": "train", "update": 1161, "total_env_steps": 3715200, "episode_reward": 0.35645759105682373, "value_loss": 0.00502222195888559, "policy_loss": -0.012769731969468505, "dist_entropy": 0.6418934027353923, "actor_grad_norm": 0.14841631054878235, "critic_grad_norm": 0.018078068271279335, "ratio": 0.999742865562439, "entropy": 0.6418934027353923, "incre_win_rate": 0.9122807017543859, "step": 1161}
{"time": 1766591068.0700743, "phase": "eval", "update": 1161, "total_env_steps": 3715200, "eval_win_rate": 1.0, "eval_episode_reward": 20.011795343137255, "step": 1161}
{"time": 1766591072.7256656, "phase": "train", "update": 1162, "total_env_steps": 3718400, "episode_reward": 0.35721203684806824, "value_loss": 0.004280970323209962, "policy_loss": -0.011948310218151665, "dist_entropy": 0.634477722644806, "actor_grad_norm": 0.1491025984287262, "critic_grad_norm": 0.013755000196397305, "ratio": 0.9992008209228516, "entropy": 0.634477722644806, "incre_win_rate": 0.9491525423728814, "step": 1162}
{"time": 1766591077.3190737, "phase": "train", "update": 1163, "total_env_steps": 3721600, "episode_reward": 0.3502650260925293, "value_loss": 0.0034332589401553076, "policy_loss": -0.012606874771361732, "dist_entropy": 0.649636423587799, "actor_grad_norm": 0.13236568868160248, "critic_grad_norm": 0.01709284633398056, "ratio": 0.9999509453773499, "entropy": 0.649636423587799, "incre_win_rate": 0.9482758620689655, "step": 1163}
{"time": 1766591081.9359398, "phase": "train", "update": 1164, "total_env_steps": 3724800, "episode_reward": 0.34929534792900085, "value_loss": 0.0047061654428641, "policy_loss": -0.013666587612234101, "dist_entropy": 0.656095004081726, "actor_grad_norm": 0.12267711758613586, "critic_grad_norm": 0.014155837707221508, "ratio": 1.0006688833236694, "entropy": 0.656095004081726, "incre_win_rate": 0.8771929824561403, "step": 1164}
{"time": 1766591086.6162226, "phase": "train", "update": 1165, "total_env_steps": 3728000, "episode_reward": 0.3563740849494934, "value_loss": 0.0035606451022128266, "policy_loss": -0.011958268154376128, "dist_entropy": 0.6547060569127401, "actor_grad_norm": 0.16769635677337646, "critic_grad_norm": 0.008853320963680744, "ratio": 0.9991907477378845, "entropy": 0.6547060569127401, "incre_win_rate": 0.9482758620689655, "step": 1165}
{"time": 1766591091.2308376, "phase": "train", "update": 1166, "total_env_steps": 3731200, "episode_reward": 0.3694975674152374, "value_loss": 0.0045767982800801596, "policy_loss": -0.012700916186252915, "dist_entropy": 0.6420726736386617, "actor_grad_norm": 0.1389552354812622, "critic_grad_norm": 0.013381189666688442, "ratio": 0.9991263747215271, "entropy": 0.6420726736386617, "incre_win_rate": 0.9661016949152542, "step": 1166}
{"time": 1766591095.9068513, "phase": "train", "update": 1167, "total_env_steps": 3734400, "episode_reward": 0.3630844056606293, "value_loss": 0.004756332406153281, "policy_loss": -0.011197319739564667, "dist_entropy": 0.6366374055544536, "actor_grad_norm": 0.12911003828048706, "critic_grad_norm": 0.012296651490032673, "ratio": 1.00045907497406, "entropy": 0.6366374055544536, "incre_win_rate": 0.95, "step": 1167}
{"time": 1766591100.6421986, "phase": "train", "update": 1168, "total_env_steps": 3737600, "episode_reward": 0.3460654318332672, "value_loss": 0.007069393713027239, "policy_loss": -0.012240183298690492, "dist_entropy": 0.6377235531806946, "actor_grad_norm": 0.1533413827419281, "critic_grad_norm": 0.009640960022807121, "ratio": 0.9990830421447754, "entropy": 0.6377235531806946, "incre_win_rate": 0.8596491228070176, "step": 1168}
{"time": 1766591105.2785177, "phase": "train", "update": 1169, "total_env_steps": 3740800, "episode_reward": 0.3690096437931061, "value_loss": 0.004126046178862452, "policy_loss": -0.01164937190424382, "dist_entropy": 0.6358810106913249, "actor_grad_norm": 0.14413264393806458, "critic_grad_norm": 0.02910570241510868, "ratio": 1.0002446174621582, "entropy": 0.6358810106913249, "incre_win_rate": 0.9491525423728814, "step": 1169}
{"time": 1766591109.9223142, "phase": "train", "update": 1170, "total_env_steps": 3744000, "episode_reward": 0.3514874577522278, "value_loss": 0.005716413135329882, "policy_loss": -0.012582238190636493, "dist_entropy": 0.6496304829915365, "actor_grad_norm": 0.1359528750181198, "critic_grad_norm": 0.014838996343314648, "ratio": 0.9995112419128418, "entropy": 0.6496304829915365, "incre_win_rate": 0.9473684210526315, "step": 1170}
{"time": 1766591114.5374727, "phase": "train", "update": 1171, "total_env_steps": 3747200, "episode_reward": 0.3524678349494934, "value_loss": 0.007651161588728428, "policy_loss": -0.012822290213235495, "dist_entropy": 0.6401545683542887, "actor_grad_norm": 0.148908793926239, "critic_grad_norm": 0.039970383048057556, "ratio": 1.0003292560577393, "entropy": 0.6401545683542887, "incre_win_rate": 0.85, "step": 1171}
{"time": 1766591119.1950946, "phase": "train", "update": 1172, "total_env_steps": 3750400, "episode_reward": 0.3580874502658844, "value_loss": 0.0060984039989610515, "policy_loss": -0.012487501858131638, "dist_entropy": 0.6376012007395426, "actor_grad_norm": 0.1347149908542633, "critic_grad_norm": 0.016529083251953125, "ratio": 1.0004299879074097, "entropy": 0.6376012007395426, "incre_win_rate": 0.8833333333333333, "step": 1172}
{"time": 1766591123.8398993, "phase": "train", "update": 1173, "total_env_steps": 3753600, "episode_reward": 0.35566943883895874, "value_loss": 0.005020904292662939, "policy_loss": -0.012213963703500023, "dist_entropy": 0.6337689677874248, "actor_grad_norm": 0.13649477064609528, "critic_grad_norm": 0.022776523604989052, "ratio": 0.9987311959266663, "entropy": 0.6337689677874248, "incre_win_rate": 0.8947368421052632, "step": 1173}
{"time": 1766591128.496073, "phase": "train", "update": 1174, "total_env_steps": 3756800, "episode_reward": 0.34755513072013855, "value_loss": 0.006450081833948692, "policy_loss": -0.012014165020164568, "dist_entropy": 0.640581488609314, "actor_grad_norm": 0.1494535654783249, "critic_grad_norm": 0.03764975443482399, "ratio": 0.9990589022636414, "entropy": 0.640581488609314, "incre_win_rate": 0.864406779661017, "step": 1174}
{"time": 1766591133.1623404, "phase": "train", "update": 1175, "total_env_steps": 3760000, "episode_reward": 0.34904488921165466, "value_loss": 0.006144421268254518, "policy_loss": -0.013235479238309722, "dist_entropy": 0.6402102629343669, "actor_grad_norm": 0.14151589572429657, "critic_grad_norm": 0.01700541190803051, "ratio": 0.9996097683906555, "entropy": 0.6402102629343669, "incre_win_rate": 0.847457627118644, "step": 1175}
{"time": 1766591137.782372, "phase": "train", "update": 1176, "total_env_steps": 3763200, "episode_reward": 0.3505430221557617, "value_loss": 0.009536913720269997, "policy_loss": -0.013184017673992325, "dist_entropy": 0.647552224000295, "actor_grad_norm": 0.1632973700761795, "critic_grad_norm": 0.03681878000497818, "ratio": 0.9998136758804321, "entropy": 0.647552224000295, "incre_win_rate": 0.85, "step": 1176}
{"time": 1766591142.3663952, "phase": "train", "update": 1177, "total_env_steps": 3766400, "episode_reward": 0.324643075466156, "value_loss": 0.011048469133675099, "policy_loss": -0.013421784623096756, "dist_entropy": 0.6476242065429687, "actor_grad_norm": 0.1638154536485672, "critic_grad_norm": 0.03276347741484642, "ratio": 0.9994901418685913, "entropy": 0.6476242065429687, "incre_win_rate": 0.7777777777777778, "step": 1177}
{"time": 1766591147.0315094, "phase": "train", "update": 1178, "total_env_steps": 3769600, "episode_reward": 0.3633938729763031, "value_loss": 0.008547004001835981, "policy_loss": -0.012421944726138178, "dist_entropy": 0.6336999456087749, "actor_grad_norm": 0.13078205287456512, "critic_grad_norm": 0.03215940669178963, "ratio": 0.9994112253189087, "entropy": 0.6336999456087749, "incre_win_rate": 0.8688524590163934, "step": 1178}
{"time": 1766591151.723048, "phase": "train", "update": 1179, "total_env_steps": 3772800, "episode_reward": 0.354977011680603, "value_loss": 0.008165163453668356, "policy_loss": -0.012571985623240304, "dist_entropy": 0.6285890817642212, "actor_grad_norm": 0.13005715608596802, "critic_grad_norm": 0.020330175757408142, "ratio": 0.9993546605110168, "entropy": 0.6285890817642212, "incre_win_rate": 0.896551724137931, "step": 1179}
{"time": 1766591156.421303, "phase": "train", "update": 1180, "total_env_steps": 3776000, "episode_reward": 0.3561106026172638, "value_loss": 0.008037625656773647, "policy_loss": -0.012584122482988392, "dist_entropy": 0.6456308801968892, "actor_grad_norm": 0.14933350682258606, "critic_grad_norm": 0.04580790549516678, "ratio": 0.99969881772995, "entropy": 0.6456308801968892, "incre_win_rate": 0.8524590163934426, "step": 1180}
{"time": 1766591161.0560713, "phase": "train", "update": 1181, "total_env_steps": 3779200, "episode_reward": 0.340046763420105, "value_loss": 0.009338898273805777, "policy_loss": -0.01274893800676414, "dist_entropy": 0.6325433532396952, "actor_grad_norm": 0.15263789892196655, "critic_grad_norm": 0.024871446192264557, "ratio": 0.999866247177124, "entropy": 0.6325433532396952, "incre_win_rate": 0.8545454545454545, "step": 1181}
{"time": 1766591167.8388293, "phase": "eval", "update": 1181, "total_env_steps": 3779200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.764705882352942, "step": 1181}
{"time": 1766591172.4456525, "phase": "train", "update": 1182, "total_env_steps": 3782400, "episode_reward": 0.3497932255268097, "value_loss": 0.005717530380934477, "policy_loss": -0.012959400052417655, "dist_entropy": 0.6194414973258973, "actor_grad_norm": 0.12094836682081223, "critic_grad_norm": 0.03905034437775612, "ratio": 0.9998977184295654, "entropy": 0.6194414973258973, "incre_win_rate": 0.847457627118644, "step": 1182}
{"time": 1766591177.1259506, "phase": "train", "update": 1183, "total_env_steps": 3785600, "episode_reward": 0.3706832230091095, "value_loss": 0.0036404567149778207, "policy_loss": -0.012156889691023782, "dist_entropy": 0.6187371095021565, "actor_grad_norm": 0.14393649995326996, "critic_grad_norm": 0.030102960765361786, "ratio": 0.9988766312599182, "entropy": 0.6187371095021565, "incre_win_rate": 0.9508196721311475, "step": 1183}
{"time": 1766591181.7500453, "phase": "train", "update": 1184, "total_env_steps": 3788800, "episode_reward": 0.3591115474700928, "value_loss": 0.005303745530545712, "policy_loss": -0.012171175614751917, "dist_entropy": 0.6081457575162251, "actor_grad_norm": 0.1648152619600296, "critic_grad_norm": 0.021200770512223244, "ratio": 0.9995197057723999, "entropy": 0.6081457575162251, "incre_win_rate": 0.8983050847457628, "step": 1184}
{"time": 1766591186.4581869, "phase": "train", "update": 1185, "total_env_steps": 3792000, "episode_reward": 0.3693995177745819, "value_loss": 0.0029993852290014426, "policy_loss": -0.012540583311822692, "dist_entropy": 0.6231934547424316, "actor_grad_norm": 0.1855994611978531, "critic_grad_norm": 0.026043834164738655, "ratio": 0.9996454119682312, "entropy": 0.6231934547424316, "incre_win_rate": 0.9491525423728814, "step": 1185}
{"time": 1766591191.0745487, "phase": "train", "update": 1186, "total_env_steps": 3795200, "episode_reward": 0.3571154773235321, "value_loss": 0.006469532133390506, "policy_loss": -0.01316107043144541, "dist_entropy": 0.6107615470886231, "actor_grad_norm": 0.1332828253507614, "critic_grad_norm": 0.03885820508003235, "ratio": 0.9998398423194885, "entropy": 0.6107615470886231, "incre_win_rate": 0.8852459016393442, "step": 1186}
{"time": 1766591195.6905854, "phase": "train", "update": 1187, "total_env_steps": 3798400, "episode_reward": 0.3531196713447571, "value_loss": 0.008534122755130132, "policy_loss": -0.01225912916834299, "dist_entropy": 0.6153913656870524, "actor_grad_norm": 0.1421308070421219, "critic_grad_norm": 0.05569111928343773, "ratio": 0.9993945956230164, "entropy": 0.6153913656870524, "incre_win_rate": 0.8275862068965517, "step": 1187}
{"time": 1766591200.3245199, "phase": "train", "update": 1188, "total_env_steps": 3801600, "episode_reward": 0.35684895515441895, "value_loss": 0.005987275515993437, "policy_loss": -0.012216181779103568, "dist_entropy": 0.6257778326670329, "actor_grad_norm": 0.14993414282798767, "critic_grad_norm": 0.02201966755092144, "ratio": 1.0002021789550781, "entropy": 0.6257778326670329, "incre_win_rate": 0.8666666666666667, "step": 1188}
{"time": 1766591204.9997678, "phase": "train", "update": 1189, "total_env_steps": 3804800, "episode_reward": 0.3568918704986572, "value_loss": 0.007028968756397565, "policy_loss": -0.012201617147898958, "dist_entropy": 0.6198227723439534, "actor_grad_norm": 0.16110824048519135, "critic_grad_norm": 0.01876446232199669, "ratio": 0.9994305968284607, "entropy": 0.6198227723439534, "incre_win_rate": 0.896551724137931, "step": 1189}
{"time": 1766591209.6681795, "phase": "train", "update": 1190, "total_env_steps": 3808000, "episode_reward": 0.36063650250434875, "value_loss": 0.006289114182194074, "policy_loss": -0.012250623349674564, "dist_entropy": 0.5971110622088115, "actor_grad_norm": 0.15557782351970673, "critic_grad_norm": 0.02186739630997181, "ratio": 1.0006767511367798, "entropy": 0.5971110622088115, "incre_win_rate": 0.8360655737704918, "step": 1190}
{"time": 1766591214.279492, "phase": "train", "update": 1191, "total_env_steps": 3811200, "episode_reward": 0.3645228147506714, "value_loss": 0.006741028930991888, "policy_loss": -0.012739191302195725, "dist_entropy": 0.6214014172554017, "actor_grad_norm": 0.12089325487613678, "critic_grad_norm": 0.013069918379187584, "ratio": 1.00017511844635, "entropy": 0.6214014172554017, "incre_win_rate": 0.8813559322033898, "step": 1191}
{"time": 1766591218.9449272, "phase": "train", "update": 1192, "total_env_steps": 3814400, "episode_reward": 0.36364275217056274, "value_loss": 0.008922649609545866, "policy_loss": -0.012634848944129355, "dist_entropy": 0.6079664786656698, "actor_grad_norm": 0.12793691456317902, "critic_grad_norm": 0.019130006432533264, "ratio": 1.0006535053253174, "entropy": 0.6079664786656698, "incre_win_rate": 0.8688524590163934, "step": 1192}
{"time": 1766591223.6142812, "phase": "train", "update": 1193, "total_env_steps": 3817600, "episode_reward": 0.387567400932312, "value_loss": 0.0032455718610435724, "policy_loss": -0.012432222542377266, "dist_entropy": 0.6095911979675293, "actor_grad_norm": 0.13736675679683685, "critic_grad_norm": 0.040152356028556824, "ratio": 0.9993010759353638, "entropy": 0.6095911979675293, "incre_win_rate": 0.9838709677419355, "step": 1193}
{"time": 1766591228.2882905, "phase": "train", "update": 1194, "total_env_steps": 3820800, "episode_reward": 0.3572150766849518, "value_loss": 0.008514974483599265, "policy_loss": -0.013037564088664529, "dist_entropy": 0.6257980227470398, "actor_grad_norm": 0.1369071751832962, "critic_grad_norm": 0.033294495195150375, "ratio": 0.9988949298858643, "entropy": 0.6257980227470398, "incre_win_rate": 0.8360655737704918, "step": 1194}
{"time": 1766591232.9315352, "phase": "train", "update": 1195, "total_env_steps": 3824000, "episode_reward": 0.37408319115638733, "value_loss": 0.006342578710367282, "policy_loss": -0.010890363597350709, "dist_entropy": 0.6172201474507649, "actor_grad_norm": 0.12949047982692719, "critic_grad_norm": 0.014793544076383114, "ratio": 1.0000988245010376, "entropy": 0.6172201474507649, "incre_win_rate": 0.9180327868852459, "step": 1195}
{"time": 1766591237.590069, "phase": "train", "update": 1196, "total_env_steps": 3827200, "episode_reward": 0.3657590448856354, "value_loss": 0.006830798927694559, "policy_loss": -0.012212007154685504, "dist_entropy": 0.611847972869873, "actor_grad_norm": 0.14805810153484344, "critic_grad_norm": 0.01061134971678257, "ratio": 0.998192548751831, "entropy": 0.611847972869873, "incre_win_rate": 0.8983050847457628, "step": 1196}
{"time": 1766591242.27579, "phase": "train", "update": 1197, "total_env_steps": 3830400, "episode_reward": 0.37278416752815247, "value_loss": 0.006097229601194461, "policy_loss": -0.012729135472532368, "dist_entropy": 0.611532739798228, "actor_grad_norm": 0.13871857523918152, "critic_grad_norm": 0.010531220585107803, "ratio": 0.9983910918235779, "entropy": 0.611532739798228, "incre_win_rate": 0.9047619047619048, "step": 1197}
{"time": 1766591246.9192712, "phase": "train", "update": 1198, "total_env_steps": 3833600, "episode_reward": 0.3724954128265381, "value_loss": 0.008062187023460865, "policy_loss": -0.011717157248862738, "dist_entropy": 0.6146714687347412, "actor_grad_norm": 0.12617109715938568, "critic_grad_norm": 0.015557888895273209, "ratio": 0.9996837377548218, "entropy": 0.6146714687347412, "incre_win_rate": 0.9180327868852459, "step": 1198}
{"time": 1766591251.6296332, "phase": "train", "update": 1199, "total_env_steps": 3836800, "episode_reward": 0.37055912613868713, "value_loss": 0.008650142202774684, "policy_loss": -0.011817669508389155, "dist_entropy": 0.6178293903668721, "actor_grad_norm": 0.12201137840747833, "critic_grad_norm": 0.025428839027881622, "ratio": 0.9992931485176086, "entropy": 0.6178293903668721, "incre_win_rate": 0.9166666666666666, "step": 1199}
{"time": 1766591256.314414, "phase": "train", "update": 1200, "total_env_steps": 3840000, "episode_reward": 0.3689092993736267, "value_loss": 0.009555261582136154, "policy_loss": -0.012518866702278805, "dist_entropy": 0.6169130047162373, "actor_grad_norm": 0.13639017939567566, "critic_grad_norm": 0.014656648971140385, "ratio": 1.0003172159194946, "entropy": 0.6169130047162373, "incre_win_rate": 0.84375, "step": 1200}
{"time": 1766591260.9856784, "phase": "train", "update": 1201, "total_env_steps": 3843200, "episode_reward": 0.3602611720561981, "value_loss": 0.01001401369770368, "policy_loss": -0.012346699933015277, "dist_entropy": 0.6097235679626465, "actor_grad_norm": 0.13310056924819946, "critic_grad_norm": 0.022146746516227722, "ratio": 1.0008591413497925, "entropy": 0.6097235679626465, "incre_win_rate": 0.8135593220338984, "step": 1201}
{"time": 1766591267.949814, "phase": "eval", "update": 1201, "total_env_steps": 3843200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.85248161764706, "step": 1201}
{"time": 1766591272.6170712, "phase": "train", "update": 1202, "total_env_steps": 3846400, "episode_reward": 0.36861902475357056, "value_loss": 0.008312173870702584, "policy_loss": -0.012781942186039903, "dist_entropy": 0.6265310446421305, "actor_grad_norm": 0.12717214226722717, "critic_grad_norm": 0.019091803580522537, "ratio": 1.0002598762512207, "entropy": 0.6265310446421305, "incre_win_rate": 0.8870967741935484, "step": 1202}
{"time": 1766591277.274842, "phase": "train", "update": 1203, "total_env_steps": 3849600, "episode_reward": 0.3474058210849762, "value_loss": 0.009825208162268003, "policy_loss": -0.01248910228490748, "dist_entropy": 0.6220552206039429, "actor_grad_norm": 0.1406828761100769, "critic_grad_norm": 0.013058563694357872, "ratio": 1.0006954669952393, "entropy": 0.6220552206039429, "incre_win_rate": 0.7931034482758621, "step": 1203}
{"time": 1766591281.9401548, "phase": "train", "update": 1204, "total_env_steps": 3852800, "episode_reward": 0.3726325035095215, "value_loss": 0.007170661694059769, "policy_loss": -0.011845949123602395, "dist_entropy": 0.6162477850914001, "actor_grad_norm": 0.1242717057466507, "critic_grad_norm": 0.04263731464743614, "ratio": 0.9987664818763733, "entropy": 0.6162477850914001, "incre_win_rate": 0.9047619047619048, "step": 1204}
{"time": 1766591286.5747108, "phase": "train", "update": 1205, "total_env_steps": 3856000, "episode_reward": 0.3537937104701996, "value_loss": 0.00966200636078914, "policy_loss": -0.012213168993901983, "dist_entropy": 0.5993849237759908, "actor_grad_norm": 0.13808099925518036, "critic_grad_norm": 0.04627303034067154, "ratio": 1.0012946128845215, "entropy": 0.5993849237759908, "incre_win_rate": 0.7903225806451613, "step": 1205}
{"time": 1766591291.3091564, "phase": "train", "update": 1206, "total_env_steps": 3859200, "episode_reward": 0.3686366677284241, "value_loss": 0.008526866727819046, "policy_loss": -0.011774542760105079, "dist_entropy": 0.6019634962081909, "actor_grad_norm": 0.1306837499141693, "critic_grad_norm": 0.023475512862205505, "ratio": 0.9995777606964111, "entropy": 0.6019634962081909, "incre_win_rate": 0.8813559322033898, "step": 1206}
{"time": 1766591295.9496558, "phase": "train", "update": 1207, "total_env_steps": 3862400, "episode_reward": 0.36561277508735657, "value_loss": 0.005826926572869221, "policy_loss": -0.012483364843063309, "dist_entropy": 0.5895306944847107, "actor_grad_norm": 0.1448422372341156, "critic_grad_norm": 0.044380199164152145, "ratio": 1.000396490097046, "entropy": 0.5895306944847107, "incre_win_rate": 0.8870967741935484, "step": 1207}
{"time": 1766591300.633545, "phase": "train", "update": 1208, "total_env_steps": 3865600, "episode_reward": 0.37873852252960205, "value_loss": 0.004253248311579227, "policy_loss": -0.011520203657187266, "dist_entropy": 0.596467399597168, "actor_grad_norm": 0.11660245060920715, "critic_grad_norm": 0.03754030913114548, "ratio": 0.998434841632843, "entropy": 0.596467399597168, "incre_win_rate": 0.9508196721311475, "step": 1208}
{"time": 1766591305.278487, "phase": "train", "update": 1209, "total_env_steps": 3868800, "episode_reward": 0.3647296130657196, "value_loss": 0.0060567492929597695, "policy_loss": -0.011684447670215073, "dist_entropy": 0.5801827669143677, "actor_grad_norm": 0.13599568605422974, "critic_grad_norm": 0.018128734081983566, "ratio": 0.9992421269416809, "entropy": 0.5801827669143677, "incre_win_rate": 0.8833333333333333, "step": 1209}
{"time": 1766591309.9423642, "phase": "train", "update": 1210, "total_env_steps": 3872000, "episode_reward": 0.371377170085907, "value_loss": 0.0036184517356256645, "policy_loss": -0.011984815731814298, "dist_entropy": 0.5895566463470459, "actor_grad_norm": 0.12605716288089752, "critic_grad_norm": 0.016497259959578514, "ratio": 0.9991490840911865, "entropy": 0.5895566463470459, "incre_win_rate": 0.9166666666666666, "step": 1210}
{"time": 1766591314.6430645, "phase": "train", "update": 1211, "total_env_steps": 3875200, "episode_reward": 0.3667302429676056, "value_loss": 0.006130409458031257, "policy_loss": -0.00985429209912591, "dist_entropy": 0.5810504198074341, "actor_grad_norm": 0.12879909574985504, "critic_grad_norm": 0.028731735423207283, "ratio": 1.000648021697998, "entropy": 0.5810504198074341, "incre_win_rate": 0.8852459016393442, "step": 1211}
{"time": 1766591319.299257, "phase": "train", "update": 1212, "total_env_steps": 3878400, "episode_reward": 0.36787301301956177, "value_loss": 0.0068975685474773245, "policy_loss": -0.01174544281880306, "dist_entropy": 0.5846789161364238, "actor_grad_norm": 0.13530895113945007, "critic_grad_norm": 0.02724151872098446, "ratio": 1.0006489753723145, "entropy": 0.5846789161364238, "incre_win_rate": 0.8571428571428571, "step": 1212}
{"time": 1766591324.0231414, "phase": "train", "update": 1213, "total_env_steps": 3881600, "episode_reward": 0.3675888776779175, "value_loss": 0.002896260206277172, "policy_loss": -0.011371668328042499, "dist_entropy": 0.5784608165423075, "actor_grad_norm": 0.13549961149692535, "critic_grad_norm": 0.039501696825027466, "ratio": 0.9989966154098511, "entropy": 0.5784608165423075, "incre_win_rate": 0.9824561403508771, "step": 1213}
{"time": 1766591328.6792252, "phase": "train", "update": 1214, "total_env_steps": 3884800, "episode_reward": 0.3561810851097107, "value_loss": 0.003676893034329017, "policy_loss": -0.012628889098734438, "dist_entropy": 0.585970687866211, "actor_grad_norm": 0.13786740601062775, "critic_grad_norm": 0.015435409732162952, "ratio": 0.9997504353523254, "entropy": 0.585970687866211, "incre_win_rate": 0.9137931034482759, "step": 1214}
{"time": 1766591333.3041935, "phase": "train", "update": 1215, "total_env_steps": 3888000, "episode_reward": 0.3750973045825958, "value_loss": 0.004231198535611232, "policy_loss": -0.011707273333543355, "dist_entropy": 0.5754030545552572, "actor_grad_norm": 0.13716159760951996, "critic_grad_norm": 0.02751774899661541, "ratio": 1.0006803274154663, "entropy": 0.5754030545552572, "incre_win_rate": 0.9206349206349206, "step": 1215}
{"time": 1766591337.9706118, "phase": "train", "update": 1216, "total_env_steps": 3891200, "episode_reward": 0.37766698002815247, "value_loss": 0.004293654781455795, "policy_loss": -0.012171476895920819, "dist_entropy": 0.5928436676661174, "actor_grad_norm": 0.12599606812000275, "critic_grad_norm": 0.019935186952352524, "ratio": 1.0008832216262817, "entropy": 0.5928436676661174, "incre_win_rate": 0.9166666666666666, "step": 1216}
{"time": 1766591342.618536, "phase": "train", "update": 1217, "total_env_steps": 3894400, "episode_reward": 0.37753215432167053, "value_loss": 0.003758017485961318, "policy_loss": -0.01082205802547686, "dist_entropy": 0.5997915625572204, "actor_grad_norm": 0.14431503415107727, "critic_grad_norm": 0.009117352776229382, "ratio": 0.9990341663360596, "entropy": 0.5997915625572204, "incre_win_rate": 0.9516129032258065, "step": 1217}
{"time": 1766591347.235421, "phase": "train", "update": 1218, "total_env_steps": 3897600, "episode_reward": 0.3909834623336792, "value_loss": 0.0016847748852645357, "policy_loss": -0.011173362207332123, "dist_entropy": 0.5814244826634725, "actor_grad_norm": 0.12923407554626465, "critic_grad_norm": 0.01670321263372898, "ratio": 1.0000462532043457, "entropy": 0.5814244826634725, "incre_win_rate": 1.0, "step": 1218}
{"time": 1766591351.9135263, "phase": "train", "update": 1219, "total_env_steps": 3900800, "episode_reward": 0.374659925699234, "value_loss": 0.004405485574776927, "policy_loss": -0.011400203473119793, "dist_entropy": 0.6159863432248434, "actor_grad_norm": 0.1254197061061859, "critic_grad_norm": 0.02057325281202793, "ratio": 0.9997117519378662, "entropy": 0.6159863432248434, "incre_win_rate": 0.9322033898305084, "step": 1219}
{"time": 1766591356.5314975, "phase": "train", "update": 1220, "total_env_steps": 3904000, "episode_reward": 0.3724908232688904, "value_loss": 0.003899977107842763, "policy_loss": -0.011621899847561679, "dist_entropy": 0.614067260424296, "actor_grad_norm": 0.12361621856689453, "critic_grad_norm": 0.00949103757739067, "ratio": 1.0000123977661133, "entropy": 0.614067260424296, "incre_win_rate": 0.9508196721311475, "step": 1220}
{"time": 1766591361.1805873, "phase": "train", "update": 1221, "total_env_steps": 3907200, "episode_reward": 0.35063573718070984, "value_loss": 0.008296029611180226, "policy_loss": -0.0123524130316369, "dist_entropy": 0.6025556325912476, "actor_grad_norm": 0.13093343377113342, "critic_grad_norm": 0.047947391867637634, "ratio": 1.0005838871002197, "entropy": 0.6025556325912476, "incre_win_rate": 0.864406779661017, "step": 1221}
{"time": 1766591368.0823483, "phase": "eval", "update": 1221, "total_env_steps": 3907200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.74938725490196, "step": 1221}
{"time": 1766591372.7408543, "phase": "train", "update": 1222, "total_env_steps": 3910400, "episode_reward": 0.37483760714530945, "value_loss": 0.004458566972364982, "policy_loss": -0.011481163206061466, "dist_entropy": 0.6057145675023397, "actor_grad_norm": 0.13134081661701202, "critic_grad_norm": 0.01990026980638504, "ratio": 1.0014348030090332, "entropy": 0.6057145675023397, "incre_win_rate": 0.9508196721311475, "step": 1222}
{"time": 1766591377.3967855, "phase": "train", "update": 1223, "total_env_steps": 3913600, "episode_reward": 0.36634576320648193, "value_loss": 0.007355982468773921, "policy_loss": -0.012683213944592353, "dist_entropy": 0.5930754860242208, "actor_grad_norm": 0.12810948491096497, "critic_grad_norm": 0.030674032866954803, "ratio": 0.9985343217849731, "entropy": 0.5930754860242208, "incre_win_rate": 0.8833333333333333, "step": 1223}
{"time": 1766591382.0444856, "phase": "train", "update": 1224, "total_env_steps": 3916800, "episode_reward": 0.36166897416114807, "value_loss": 0.007756067936619123, "policy_loss": -0.013165283755522002, "dist_entropy": 0.58137499888738, "actor_grad_norm": 0.1513967365026474, "critic_grad_norm": 0.02556486427783966, "ratio": 0.9993031024932861, "entropy": 0.58137499888738, "incre_win_rate": 0.864406779661017, "step": 1224}
{"time": 1766591386.6760952, "phase": "train", "update": 1225, "total_env_steps": 3920000, "episode_reward": 0.37274816632270813, "value_loss": 0.005194059573113918, "policy_loss": -0.012505297938170182, "dist_entropy": 0.6185945789019267, "actor_grad_norm": 0.12612560391426086, "critic_grad_norm": 0.02161591872572899, "ratio": 0.9990991353988647, "entropy": 0.6185945789019267, "incre_win_rate": 0.8888888888888888, "step": 1225}
{"time": 1766591391.2839012, "phase": "train", "update": 1226, "total_env_steps": 3923200, "episode_reward": 0.3705054819583893, "value_loss": 0.004769894449661176, "policy_loss": -0.011420078847570873, "dist_entropy": 0.5919962326685587, "actor_grad_norm": 0.14045175909996033, "critic_grad_norm": 0.013290335424244404, "ratio": 0.9997372031211853, "entropy": 0.5919962326685587, "incre_win_rate": 0.9166666666666666, "step": 1226}
{"time": 1766591395.9732068, "phase": "train", "update": 1227, "total_env_steps": 3926400, "episode_reward": 0.380354642868042, "value_loss": 0.003468086989596486, "policy_loss": -0.011038899256590184, "dist_entropy": 0.6031417806943258, "actor_grad_norm": 0.12264512479305267, "critic_grad_norm": 0.007676354609429836, "ratio": 1.0000860691070557, "entropy": 0.6031417806943258, "incre_win_rate": 0.967741935483871, "step": 1227}
{"time": 1766591400.700753, "phase": "train", "update": 1228, "total_env_steps": 3929600, "episode_reward": 0.3538549542427063, "value_loss": 0.006064709307005008, "policy_loss": -0.012689255449544135, "dist_entropy": 0.6073152343432109, "actor_grad_norm": 0.129257932305336, "critic_grad_norm": 0.010646681301295757, "ratio": 0.999111533164978, "entropy": 0.6073152343432109, "incre_win_rate": 0.8793103448275862, "step": 1228}
{"time": 1766591405.3415432, "phase": "train", "update": 1229, "total_env_steps": 3932800, "episode_reward": 0.380303293466568, "value_loss": 0.007313228398561478, "policy_loss": -0.011727281047043903, "dist_entropy": 0.6027007659276327, "actor_grad_norm": 0.11760353296995163, "critic_grad_norm": 0.020005078986287117, "ratio": 0.9999985694885254, "entropy": 0.6027007659276327, "incre_win_rate": 0.9206349206349206, "step": 1229}
{"time": 1766591410.0117753, "phase": "train", "update": 1230, "total_env_steps": 3936000, "episode_reward": 0.38431602716445923, "value_loss": 0.005158528219908476, "policy_loss": -0.01081431447311895, "dist_entropy": 0.6113659063975017, "actor_grad_norm": 0.12269118428230286, "critic_grad_norm": 0.023227110505104065, "ratio": 0.9988923072814941, "entropy": 0.6113659063975017, "incre_win_rate": 0.9516129032258065, "step": 1230}
{"time": 1766591414.6125302, "phase": "train", "update": 1231, "total_env_steps": 3939200, "episode_reward": 0.3586803078651428, "value_loss": 0.007195996462057034, "policy_loss": -0.012057961260366313, "dist_entropy": 0.618706472714742, "actor_grad_norm": 0.1372901201248169, "critic_grad_norm": 0.024856729432940483, "ratio": 1.0001198053359985, "entropy": 0.618706472714742, "incre_win_rate": 0.8793103448275862, "step": 1231}
{"time": 1766591419.2507954, "phase": "train", "update": 1232, "total_env_steps": 3942400, "episode_reward": 0.37020373344421387, "value_loss": 0.005713266475747029, "policy_loss": -0.011152452027132161, "dist_entropy": 0.6142173647880554, "actor_grad_norm": 0.1298784464597702, "critic_grad_norm": 0.016983648762106895, "ratio": 1.000351071357727, "entropy": 0.6142173647880554, "incre_win_rate": 0.9516129032258065, "step": 1232}
{"time": 1766591423.8968647, "phase": "train", "update": 1233, "total_env_steps": 3945600, "episode_reward": 0.36626917123794556, "value_loss": 0.00755654505143563, "policy_loss": -0.01174110816216416, "dist_entropy": 0.5961619853973389, "actor_grad_norm": 0.12352973222732544, "critic_grad_norm": 0.010968267917633057, "ratio": 1.0000232458114624, "entropy": 0.5961619853973389, "incre_win_rate": 0.8833333333333333, "step": 1233}
{"time": 1766591428.5693107, "phase": "train", "update": 1234, "total_env_steps": 3948800, "episode_reward": 0.36105164885520935, "value_loss": 0.006235122370223205, "policy_loss": -0.012208245419707945, "dist_entropy": 0.6032557845115661, "actor_grad_norm": 0.11617958545684814, "critic_grad_norm": 0.016152439638972282, "ratio": 1.000404715538025, "entropy": 0.6032557845115661, "incre_win_rate": 0.896551724137931, "step": 1234}
{"time": 1766591433.180073, "phase": "train", "update": 1235, "total_env_steps": 3952000, "episode_reward": 0.3674080967903137, "value_loss": 0.006410725352664789, "policy_loss": -0.010323389007917664, "dist_entropy": 0.5804038484891255, "actor_grad_norm": 0.11801663786172867, "critic_grad_norm": 0.014787526801228523, "ratio": 1.0003716945648193, "entropy": 0.5804038484891255, "incre_win_rate": 0.9333333333333333, "step": 1235}
{"time": 1766591437.7538383, "phase": "train", "update": 1236, "total_env_steps": 3955200, "episode_reward": 0.3729534447193146, "value_loss": 0.005391972946623961, "policy_loss": -0.012277089164156508, "dist_entropy": 0.5754564007123312, "actor_grad_norm": 0.13046760857105255, "critic_grad_norm": 0.023708142340183258, "ratio": 0.9993751645088196, "entropy": 0.5754564007123312, "incre_win_rate": 0.9344262295081968, "step": 1236}
{"time": 1766591442.3940313, "phase": "train", "update": 1237, "total_env_steps": 3958400, "episode_reward": 0.3638932406902313, "value_loss": 0.007635899943610033, "policy_loss": -0.012375500681834713, "dist_entropy": 0.5800598581631978, "actor_grad_norm": 0.1252450942993164, "critic_grad_norm": 0.02037784829735756, "ratio": 1.0006725788116455, "entropy": 0.5800598581631978, "incre_win_rate": 0.8833333333333333, "step": 1237}
{"time": 1766591447.0379343, "phase": "train", "update": 1238, "total_env_steps": 3961600, "episode_reward": 0.3731701970100403, "value_loss": 0.004136105859652161, "policy_loss": -0.012516032136319844, "dist_entropy": 0.5828605572382609, "actor_grad_norm": 0.1389704793691635, "critic_grad_norm": 0.026357803493738174, "ratio": 0.9999135732650757, "entropy": 0.5828605572382609, "incre_win_rate": 0.9365079365079365, "step": 1238}
{"time": 1766591451.7022185, "phase": "train", "update": 1239, "total_env_steps": 3964800, "episode_reward": 0.36314183473587036, "value_loss": 0.007695428344110648, "policy_loss": -0.012465542980792322, "dist_entropy": 0.5918378829956055, "actor_grad_norm": 0.12589506804943085, "critic_grad_norm": 0.026702480390667915, "ratio": 1.0000536441802979, "entropy": 0.5918378829956055, "incre_win_rate": 0.864406779661017, "step": 1239}
{"time": 1766591456.3929653, "phase": "train", "update": 1240, "total_env_steps": 3968000, "episode_reward": 0.37033551931381226, "value_loss": 0.006565859106679757, "policy_loss": -0.010596115649620923, "dist_entropy": 0.5842042366663615, "actor_grad_norm": 0.113299161195755, "critic_grad_norm": 0.014664093032479286, "ratio": 0.9991818070411682, "entropy": 0.5842042366663615, "incre_win_rate": 0.9016393442622951, "step": 1240}
{"time": 1766591460.9990835, "phase": "train", "update": 1241, "total_env_steps": 3971200, "episode_reward": 0.37118566036224365, "value_loss": 0.006497610981265704, "policy_loss": -0.011685895862594957, "dist_entropy": 0.5944315950075786, "actor_grad_norm": 0.11982984840869904, "critic_grad_norm": 0.02886408381164074, "ratio": 0.9998485445976257, "entropy": 0.5944315950075786, "incre_win_rate": 0.95, "step": 1241}
{"time": 1766591467.9954329, "phase": "eval", "update": 1241, "total_env_steps": 3971200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.82107843137255, "step": 1241}
{"time": 1766591472.6351342, "phase": "train", "update": 1242, "total_env_steps": 3974400, "episode_reward": 0.3720611333847046, "value_loss": 0.004595364878575007, "policy_loss": -0.01206317556195226, "dist_entropy": 0.618135670820872, "actor_grad_norm": 0.1316470503807068, "critic_grad_norm": 0.009122433140873909, "ratio": 0.9987848401069641, "entropy": 0.618135670820872, "incre_win_rate": 0.9661016949152542, "step": 1242}
{"time": 1766591477.2389603, "phase": "train", "update": 1243, "total_env_steps": 3977600, "episode_reward": 0.37557828426361084, "value_loss": 0.004336752866705259, "policy_loss": -0.011069996566299523, "dist_entropy": 0.5859330654144287, "actor_grad_norm": 0.11717158555984497, "critic_grad_norm": 0.011362984776496887, "ratio": 0.9991173148155212, "entropy": 0.5859330654144287, "incre_win_rate": 0.9516129032258065, "step": 1243}
{"time": 1766591481.9986951, "phase": "train", "update": 1244, "total_env_steps": 3980800, "episode_reward": 0.3690778315067291, "value_loss": 0.008577654572824637, "policy_loss": -0.0110712407602288, "dist_entropy": 0.6127262512842814, "actor_grad_norm": 0.12077627331018448, "critic_grad_norm": 0.030744872987270355, "ratio": 1.0007398128509521, "entropy": 0.6127262512842814, "incre_win_rate": 0.9180327868852459, "step": 1244}
{"time": 1766591486.687578, "phase": "train", "update": 1245, "total_env_steps": 3984000, "episode_reward": 0.3625321686267853, "value_loss": 0.00822489174703757, "policy_loss": -0.01190247173756589, "dist_entropy": 0.5976085662841797, "actor_grad_norm": 0.12388027459383011, "critic_grad_norm": 0.008318483829498291, "ratio": 0.9995176196098328, "entropy": 0.5976085662841797, "incre_win_rate": 0.8833333333333333, "step": 1245}
{"time": 1766591491.3372045, "phase": "train", "update": 1246, "total_env_steps": 3987200, "episode_reward": 0.37554076313972473, "value_loss": 0.006924524127195279, "policy_loss": -0.012585215874616532, "dist_entropy": 0.6133758783340454, "actor_grad_norm": 0.13492940366268158, "critic_grad_norm": 0.020272236317396164, "ratio": 0.9997587203979492, "entropy": 0.6133758783340454, "incre_win_rate": 0.9344262295081968, "step": 1246}
{"time": 1766591495.907213, "phase": "train", "update": 1247, "total_env_steps": 3990400, "episode_reward": 0.3583126962184906, "value_loss": 0.008991062082350254, "policy_loss": -0.011950290788917576, "dist_entropy": 0.600646956761678, "actor_grad_norm": 0.13804425299167633, "critic_grad_norm": 0.03182516247034073, "ratio": 0.999570369720459, "entropy": 0.600646956761678, "incre_win_rate": 0.8813559322033898, "step": 1247}
{"time": 1766591500.5953774, "phase": "train", "update": 1248, "total_env_steps": 3993600, "episode_reward": 0.36721351742744446, "value_loss": 0.005008271088202795, "policy_loss": -0.011626047457820062, "dist_entropy": 0.6123141169548034, "actor_grad_norm": 0.13928283751010895, "critic_grad_norm": 0.007871674373745918, "ratio": 1.00014328956604, "entropy": 0.6123141169548034, "incre_win_rate": 0.9193548387096774, "step": 1248}
{"time": 1766591505.2168887, "phase": "train", "update": 1249, "total_env_steps": 3996800, "episode_reward": 0.37209635972976685, "value_loss": 0.004012517413745324, "policy_loss": -0.011695464567775577, "dist_entropy": 0.6082318464914958, "actor_grad_norm": 0.12817715108394623, "critic_grad_norm": 0.034608304500579834, "ratio": 1.000457763671875, "entropy": 0.6082318464914958, "incre_win_rate": 0.9344262295081968, "step": 1249}
{"time": 1766591509.815755, "phase": "train", "update": 1250, "total_env_steps": 4000000, "episode_reward": 0.35234835743904114, "value_loss": 0.006274743719647328, "policy_loss": -0.012298540223919237, "dist_entropy": 0.6169760982195537, "actor_grad_norm": 0.14123910665512085, "critic_grad_norm": 0.014830544590950012, "ratio": 0.9984372854232788, "entropy": 0.6169760982195537, "incre_win_rate": 0.9137931034482759, "step": 1250}
{"time": 1766591514.406506, "phase": "train", "update": 1251, "total_env_steps": 4003200, "episode_reward": 0.3606288433074951, "value_loss": 0.006178830160448948, "policy_loss": -0.01196204812034504, "dist_entropy": 0.6201560735702515, "actor_grad_norm": 0.12354867905378342, "critic_grad_norm": 0.018336478620767593, "ratio": 0.9984593987464905, "entropy": 0.6201560735702515, "incre_win_rate": 0.8771929824561403, "step": 1251}
{"time": 1766591519.0149534, "phase": "train", "update": 1252, "total_env_steps": 4006400, "episode_reward": 0.3523123562335968, "value_loss": 0.00596125399072965, "policy_loss": -0.012802367730337553, "dist_entropy": 0.6202199498812357, "actor_grad_norm": 0.14256523549556732, "critic_grad_norm": 0.010628761723637581, "ratio": 0.9985658526420593, "entropy": 0.6202199498812357, "incre_win_rate": 0.8793103448275862, "step": 1252}
{"time": 1766591523.64882, "phase": "train", "update": 1253, "total_env_steps": 4009600, "episode_reward": 0.3509635627269745, "value_loss": 0.008782366259644429, "policy_loss": -0.012550136198256704, "dist_entropy": 0.6129961133003234, "actor_grad_norm": 0.15707100927829742, "critic_grad_norm": 0.061941225081682205, "ratio": 1.000251054763794, "entropy": 0.6129961133003234, "incre_win_rate": 0.8333333333333334, "step": 1253}
{"time": 1766591528.3039296, "phase": "train", "update": 1254, "total_env_steps": 4012800, "episode_reward": 0.3642233610153198, "value_loss": 0.006239943920324246, "policy_loss": -0.013545393053631472, "dist_entropy": 0.623146673043569, "actor_grad_norm": 0.1340097188949585, "critic_grad_norm": 0.030613265931606293, "ratio": 0.999506950378418, "entropy": 0.623146673043569, "incre_win_rate": 0.9016393442622951, "step": 1254}
{"time": 1766591532.948162, "phase": "train", "update": 1255, "total_env_steps": 4016000, "episode_reward": 0.354977011680603, "value_loss": 0.005372240642706553, "policy_loss": -0.012248153655774037, "dist_entropy": 0.6340436935424805, "actor_grad_norm": 0.13081946969032288, "critic_grad_norm": 0.01272865105420351, "ratio": 1.000250220298767, "entropy": 0.6340436935424805, "incre_win_rate": 0.8596491228070176, "step": 1255}
{"time": 1766591537.5634842, "phase": "train", "update": 1256, "total_env_steps": 4019200, "episode_reward": 0.33657628297805786, "value_loss": 0.010371912084519864, "policy_loss": -0.013269628618731606, "dist_entropy": 0.6342642664909363, "actor_grad_norm": 0.14031384885311127, "critic_grad_norm": 0.028904464095830917, "ratio": 1.0003432035446167, "entropy": 0.6342642664909363, "incre_win_rate": 0.8571428571428571, "step": 1256}
{"time": 1766591542.2104585, "phase": "train", "update": 1257, "total_env_steps": 4022400, "episode_reward": 0.3571752607822418, "value_loss": 0.00859984460597237, "policy_loss": -0.012981369331826424, "dist_entropy": 0.6367550969123841, "actor_grad_norm": 0.17591051757335663, "critic_grad_norm": 0.040020253509283066, "ratio": 0.9997535943984985, "entropy": 0.6367550969123841, "incre_win_rate": 0.8833333333333333, "step": 1257}
{"time": 1766591546.8517056, "phase": "train", "update": 1258, "total_env_steps": 4025600, "episode_reward": 0.35737285017967224, "value_loss": 0.007883164597054322, "policy_loss": -0.012942012290828113, "dist_entropy": 0.6229128956794738, "actor_grad_norm": 0.1548835039138794, "critic_grad_norm": 0.031559113413095474, "ratio": 0.9999604821205139, "entropy": 0.6229128956794738, "incre_win_rate": 0.8813559322033898, "step": 1258}
{"time": 1766591551.4968433, "phase": "train", "update": 1259, "total_env_steps": 4028800, "episode_reward": 0.34556370973587036, "value_loss": 0.009428270595769088, "policy_loss": -0.013235175540352865, "dist_entropy": 0.6370806256930034, "actor_grad_norm": 0.14912399649620056, "critic_grad_norm": 0.017682595178484917, "ratio": 0.9999204874038696, "entropy": 0.6370806256930034, "incre_win_rate": 0.8135593220338984, "step": 1259}
{"time": 1766591556.0811703, "phase": "train", "update": 1260, "total_env_steps": 4032000, "episode_reward": 0.356741726398468, "value_loss": 0.0067279153813918436, "policy_loss": -0.013302561930121708, "dist_entropy": 0.6524512767791748, "actor_grad_norm": 0.14778217673301697, "critic_grad_norm": 0.03658968582749367, "ratio": 0.9987478852272034, "entropy": 0.6524512767791748, "incre_win_rate": 0.9310344827586207, "step": 1260}
{"time": 1766591560.7503028, "phase": "train", "update": 1261, "total_env_steps": 4035200, "episode_reward": 0.3509520888328552, "value_loss": 0.007891446600357692, "policy_loss": -0.013152386549452898, "dist_entropy": 0.6352810343106587, "actor_grad_norm": 0.14598003029823303, "critic_grad_norm": 0.030501481145620346, "ratio": 0.9999551773071289, "entropy": 0.6352810343106587, "incre_win_rate": 0.9298245614035088, "step": 1261}
{"time": 1766591567.5143697, "phase": "eval", "update": 1261, "total_env_steps": 4035200, "eval_win_rate": 1.0, "eval_episode_reward": 20.001685049019606, "step": 1261}
{"time": 1766591572.1652913, "phase": "train", "update": 1262, "total_env_steps": 4038400, "episode_reward": 0.34682902693748474, "value_loss": 0.007487876837452253, "policy_loss": -0.012291396592488013, "dist_entropy": 0.6286760131518047, "actor_grad_norm": 0.1479843407869339, "critic_grad_norm": 0.029879286885261536, "ratio": 1.0007846355438232, "entropy": 0.6286760131518047, "incre_win_rate": 0.8793103448275862, "step": 1262}
{"time": 1766591576.832316, "phase": "train", "update": 1263, "total_env_steps": 4041600, "episode_reward": 0.3458256721496582, "value_loss": 0.005231221113353968, "policy_loss": -0.01321945365703859, "dist_entropy": 0.626748239994049, "actor_grad_norm": 0.14566339552402496, "critic_grad_norm": 0.007114851847290993, "ratio": 0.9989922642707825, "entropy": 0.626748239994049, "incre_win_rate": 0.8947368421052632, "step": 1263}
{"time": 1766591581.4026186, "phase": "train", "update": 1264, "total_env_steps": 4044800, "episode_reward": 0.3446277379989624, "value_loss": 0.010217674200733502, "policy_loss": -0.012624721274052793, "dist_entropy": 0.6201167384783427, "actor_grad_norm": 0.1504986584186554, "critic_grad_norm": 0.04310048371553421, "ratio": 1.0001375675201416, "entropy": 0.6201167384783427, "incre_win_rate": 0.8103448275862069, "step": 1264}
{"time": 1766591586.0169191, "phase": "train", "update": 1265, "total_env_steps": 4048000, "episode_reward": 0.3616168797016144, "value_loss": 0.0071445918952425325, "policy_loss": -0.012108919821686943, "dist_entropy": 0.6100278655687968, "actor_grad_norm": 0.13270221650600433, "critic_grad_norm": 0.04174521565437317, "ratio": 0.9997291564941406, "entropy": 0.6100278655687968, "incre_win_rate": 0.9491525423728814, "step": 1265}
{"time": 1766591590.6235955, "phase": "train", "update": 1266, "total_env_steps": 4051200, "episode_reward": 0.3558548092842102, "value_loss": 0.004653692835321029, "policy_loss": -0.011950596416896057, "dist_entropy": 0.6345719615618388, "actor_grad_norm": 0.14344589412212372, "critic_grad_norm": 0.023415692150592804, "ratio": 0.9989950060844421, "entropy": 0.6345719615618388, "incre_win_rate": 0.9122807017543859, "step": 1266}
{"time": 1766591595.2311265, "phase": "train", "update": 1267, "total_env_steps": 4054400, "episode_reward": 0.3503599762916565, "value_loss": 0.005152099734793107, "policy_loss": -0.01254600652895063, "dist_entropy": 0.6226306756337484, "actor_grad_norm": 0.1361769586801529, "critic_grad_norm": 0.006981707643717527, "ratio": 0.9992641806602478, "entropy": 0.6226306756337484, "incre_win_rate": 0.9285714285714286, "step": 1267}
{"time": 1766591599.8974946, "phase": "train", "update": 1268, "total_env_steps": 4057600, "episode_reward": 0.3444776237010956, "value_loss": 0.0028371729732801516, "policy_loss": -0.013406777926846065, "dist_entropy": 0.634377137819926, "actor_grad_norm": 0.12760482728481293, "critic_grad_norm": 0.009614957496523857, "ratio": 0.9999773502349854, "entropy": 0.634377137819926, "incre_win_rate": 0.9310344827586207, "step": 1268}
{"time": 1766591604.5320702, "phase": "train", "update": 1269, "total_env_steps": 4060800, "episode_reward": 0.3593229353427887, "value_loss": 0.005404372730602821, "policy_loss": -0.013167406416634246, "dist_entropy": 0.6202236970265707, "actor_grad_norm": 0.15548446774482727, "critic_grad_norm": 0.017952507361769676, "ratio": 1.000313639640808, "entropy": 0.6202236970265707, "incre_win_rate": 0.9137931034482759, "step": 1269}
{"time": 1766591609.166498, "phase": "train", "update": 1270, "total_env_steps": 4064000, "episode_reward": 0.3526570200920105, "value_loss": 0.008765342893699806, "policy_loss": -0.012606686652791648, "dist_entropy": 0.6036876598993938, "actor_grad_norm": 0.16017599403858185, "critic_grad_norm": 0.04721328243613243, "ratio": 0.9995236992835999, "entropy": 0.6036876598993938, "incre_win_rate": 0.847457627118644, "step": 1270}
{"time": 1766591613.7819347, "phase": "train", "update": 1271, "total_env_steps": 4067200, "episode_reward": 0.34673333168029785, "value_loss": 0.007694190771629413, "policy_loss": -0.013856673182107215, "dist_entropy": 0.6160374164581299, "actor_grad_norm": 0.15268062055110931, "critic_grad_norm": 0.011433327570557594, "ratio": 1.0007840394973755, "entropy": 0.6160374164581299, "incre_win_rate": 0.8596491228070176, "step": 1271}
{"time": 1766591618.4016814, "phase": "train", "update": 1272, "total_env_steps": 4070400, "episode_reward": 0.36237746477127075, "value_loss": 0.007240360074987014, "policy_loss": -0.01286433873257143, "dist_entropy": 0.6133469184239705, "actor_grad_norm": 0.15488770604133606, "critic_grad_norm": 0.009029493667185307, "ratio": 1.0000927448272705, "entropy": 0.6133469184239705, "incre_win_rate": 0.9016393442622951, "step": 1272}
{"time": 1766591623.002264, "phase": "train", "update": 1273, "total_env_steps": 4073600, "episode_reward": 0.34970128536224365, "value_loss": 0.005631642291943232, "policy_loss": -0.013048939212723099, "dist_entropy": 0.6225771029790242, "actor_grad_norm": 0.13271832466125488, "critic_grad_norm": 0.022486679255962372, "ratio": 1.0002391338348389, "entropy": 0.6225771029790242, "incre_win_rate": 0.9122807017543859, "step": 1273}
{"time": 1766591627.6770432, "phase": "train", "update": 1274, "total_env_steps": 4076800, "episode_reward": 0.3691597878932953, "value_loss": 0.005038568532715241, "policy_loss": -0.012317034670644489, "dist_entropy": 0.6041253606478373, "actor_grad_norm": 0.1384955644607544, "critic_grad_norm": 0.011689338833093643, "ratio": 0.9991572499275208, "entropy": 0.6041253606478373, "incre_win_rate": 0.9491525423728814, "step": 1274}
{"time": 1766591632.3456547, "phase": "train", "update": 1275, "total_env_steps": 4080000, "episode_reward": 0.3511956036090851, "value_loss": 0.0060806337433556715, "policy_loss": -0.012157565432161732, "dist_entropy": 0.6020435611406962, "actor_grad_norm": 0.1379336267709732, "critic_grad_norm": 0.02156144753098488, "ratio": 1.0013768672943115, "entropy": 0.6020435611406962, "incre_win_rate": 0.8833333333333333, "step": 1275}
{"time": 1766591636.964016, "phase": "train", "update": 1276, "total_env_steps": 4083200, "episode_reward": 0.3674548268318176, "value_loss": 0.004499555875857671, "policy_loss": -0.012219837426023143, "dist_entropy": 0.6034828782081604, "actor_grad_norm": 0.1282392293214798, "critic_grad_norm": 0.009164569899439812, "ratio": 0.9991739392280579, "entropy": 0.6034828782081604, "incre_win_rate": 0.9152542372881356, "step": 1276}
{"time": 1766591641.5590296, "phase": "train", "update": 1277, "total_env_steps": 4086400, "episode_reward": 0.3569485545158386, "value_loss": 0.006205571846415599, "policy_loss": -0.012578575697849223, "dist_entropy": 0.6139111200968425, "actor_grad_norm": 0.14396460354328156, "critic_grad_norm": 0.010727602057158947, "ratio": 0.9993501901626587, "entropy": 0.6139111200968425, "incre_win_rate": 0.9152542372881356, "step": 1277}
{"time": 1766591646.2103329, "phase": "train", "update": 1278, "total_env_steps": 4089600, "episode_reward": 0.3726830780506134, "value_loss": 0.006749617587774992, "policy_loss": -0.011881950479469102, "dist_entropy": 0.6126364310582478, "actor_grad_norm": 0.1164681687951088, "critic_grad_norm": 0.01581750623881817, "ratio": 0.9988068342208862, "entropy": 0.6126364310582478, "incre_win_rate": 0.9666666666666667, "step": 1278}
{"time": 1766591650.8999574, "phase": "train", "update": 1279, "total_env_steps": 4092800, "episode_reward": 0.34863895177841187, "value_loss": 0.0062835032120347025, "policy_loss": -0.012342691406344268, "dist_entropy": 0.6030221581459045, "actor_grad_norm": 0.14121368527412415, "critic_grad_norm": 0.029225150123238564, "ratio": 0.999014139175415, "entropy": 0.6030221581459045, "incre_win_rate": 0.8620689655172413, "step": 1279}
{"time": 1766591655.5746942, "phase": "train", "update": 1280, "total_env_steps": 4096000, "episode_reward": 0.3639269471168518, "value_loss": 0.005448841086278359, "policy_loss": -0.01280236043645336, "dist_entropy": 0.6072117765744527, "actor_grad_norm": 0.1325409859418869, "critic_grad_norm": 0.010243477299809456, "ratio": 1.0001271963119507, "entropy": 0.6072117765744527, "incre_win_rate": 0.8983050847457628, "step": 1280}
{"time": 1766591660.2625523, "phase": "train", "update": 1281, "total_env_steps": 4099200, "episode_reward": 0.3510753810405731, "value_loss": 0.00634304170186321, "policy_loss": -0.012270281777646375, "dist_entropy": 0.6156214276949564, "actor_grad_norm": 0.13075289130210876, "critic_grad_norm": 0.014579419046640396, "ratio": 1.0000909566879272, "entropy": 0.6156214276949564, "incre_win_rate": 0.896551724137931, "step": 1281}
{"time": 1766591667.4425266, "phase": "eval", "update": 1281, "total_env_steps": 4099200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.881740196078432, "step": 1281}
{"time": 1766591672.1228487, "phase": "train", "update": 1282, "total_env_steps": 4102400, "episode_reward": 0.3697051405906677, "value_loss": 0.00535782997806867, "policy_loss": -0.011187180734556535, "dist_entropy": 0.6137423952420552, "actor_grad_norm": 0.13751263916492462, "critic_grad_norm": 0.019533386453986168, "ratio": 0.9992029070854187, "entropy": 0.6137423952420552, "incre_win_rate": 0.9180327868852459, "step": 1282}
{"time": 1766591676.7630196, "phase": "train", "update": 1283, "total_env_steps": 4105600, "episode_reward": 0.3618098795413971, "value_loss": 0.011076631397008896, "policy_loss": -0.012692345188625371, "dist_entropy": 0.6174462000528972, "actor_grad_norm": 0.12260116636753082, "critic_grad_norm": 0.02235409989953041, "ratio": 1.0002532005310059, "entropy": 0.6174462000528972, "incre_win_rate": 0.8813559322033898, "step": 1283}
{"time": 1766591681.4096677, "phase": "train", "update": 1284, "total_env_steps": 4108800, "episode_reward": 0.37053003907203674, "value_loss": 0.008386725125213464, "policy_loss": -0.01219124696865587, "dist_entropy": 0.6061903317769368, "actor_grad_norm": 0.1182640939950943, "critic_grad_norm": 0.021123183891177177, "ratio": 0.9987467527389526, "entropy": 0.6061903317769368, "incre_win_rate": 0.9344262295081968, "step": 1284}
{"time": 1766591686.0582135, "phase": "train", "update": 1285, "total_env_steps": 4112000, "episode_reward": 0.36709633469581604, "value_loss": 0.008849108157058557, "policy_loss": -0.011704259464940019, "dist_entropy": 0.6135629534721374, "actor_grad_norm": 0.12359149754047394, "critic_grad_norm": 0.012615818530321121, "ratio": 1.0009067058563232, "entropy": 0.6135629534721374, "incre_win_rate": 0.8524590163934426, "step": 1285}
{"time": 1766591690.7202873, "phase": "train", "update": 1286, "total_env_steps": 4115200, "episode_reward": 0.35501226782798767, "value_loss": 0.009453144297003746, "policy_loss": -0.013290256093591779, "dist_entropy": 0.6055363615353903, "actor_grad_norm": 0.14799624681472778, "critic_grad_norm": 0.0368310771882534, "ratio": 0.9990447163581848, "entropy": 0.6055363615353903, "incre_win_rate": 0.8833333333333333, "step": 1286}
{"time": 1766591695.3731344, "phase": "train", "update": 1287, "total_env_steps": 4118400, "episode_reward": 0.3719753324985504, "value_loss": 0.006742885243147612, "policy_loss": -0.012054561813632366, "dist_entropy": 0.6362953980763754, "actor_grad_norm": 0.12320468574762344, "critic_grad_norm": 0.0239288080483675, "ratio": 1.0007737874984741, "entropy": 0.6362953980763754, "incre_win_rate": 0.9180327868852459, "step": 1287}
{"time": 1766591700.057949, "phase": "train", "update": 1288, "total_env_steps": 4121600, "episode_reward": 0.37424784898757935, "value_loss": 0.003995137149468064, "policy_loss": -0.012950761930485062, "dist_entropy": 0.6396122217178345, "actor_grad_norm": 0.12317019701004028, "critic_grad_norm": 0.013998246751725674, "ratio": 0.9996432662010193, "entropy": 0.6396122217178345, "incre_win_rate": 0.9508196721311475, "step": 1288}
{"time": 1766591704.6604073, "phase": "train", "update": 1289, "total_env_steps": 4124800, "episode_reward": 0.3581564426422119, "value_loss": 0.006042159255594015, "policy_loss": -0.012612202794031429, "dist_entropy": 0.6457420190175375, "actor_grad_norm": 0.1359088122844696, "critic_grad_norm": 0.034494731575250626, "ratio": 0.9987760186195374, "entropy": 0.6457420190175375, "incre_win_rate": 0.864406779661017, "step": 1289}
{"time": 1766591709.3287642, "phase": "train", "update": 1290, "total_env_steps": 4128000, "episode_reward": 0.3638518750667572, "value_loss": 0.005230985147257646, "policy_loss": -0.012034004014313855, "dist_entropy": 0.6419134338696798, "actor_grad_norm": 0.1360497921705246, "critic_grad_norm": 0.015402676537632942, "ratio": 1.0003364086151123, "entropy": 0.6419134338696798, "incre_win_rate": 0.9152542372881356, "step": 1290}
{"time": 1766591713.9145305, "phase": "train", "update": 1291, "total_env_steps": 4131200, "episode_reward": 0.36443474888801575, "value_loss": 0.00534879881888628, "policy_loss": -0.012023762394300282, "dist_entropy": 0.6577224731445312, "actor_grad_norm": 0.1171470433473587, "critic_grad_norm": 0.015809394419193268, "ratio": 0.9989225268363953, "entropy": 0.6577224731445312, "incre_win_rate": 0.9491525423728814, "step": 1291}
{"time": 1766591718.5536253, "phase": "train", "update": 1292, "total_env_steps": 4134400, "episode_reward": 0.37112897634506226, "value_loss": 0.007966834089408318, "policy_loss": -0.011110670783856117, "dist_entropy": 0.648401657740275, "actor_grad_norm": 0.1207742914557457, "critic_grad_norm": 0.01822615973651409, "ratio": 1.0005091428756714, "entropy": 0.648401657740275, "incre_win_rate": 0.8870967741935484, "step": 1292}
{"time": 1766591723.2201288, "phase": "train", "update": 1293, "total_env_steps": 4137600, "episode_reward": 0.3777228593826294, "value_loss": 0.005166006678094467, "policy_loss": -0.011261474975978559, "dist_entropy": 0.6623814860979717, "actor_grad_norm": 0.11292262375354767, "critic_grad_norm": 0.026601798832416534, "ratio": 1.0009313821792603, "entropy": 0.6623814860979717, "incre_win_rate": 0.9672131147540983, "step": 1293}
{"time": 1766591727.878992, "phase": "train", "update": 1294, "total_env_steps": 4140800, "episode_reward": 0.3819638788700104, "value_loss": 0.0038487902221580345, "policy_loss": -0.011707401018877779, "dist_entropy": 0.6493243932723999, "actor_grad_norm": 0.11340223252773285, "critic_grad_norm": 0.024357043206691742, "ratio": 0.9979121685028076, "entropy": 0.6493243932723999, "incre_win_rate": 0.967741935483871, "step": 1294}
{"time": 1766591732.5499632, "phase": "train", "update": 1295, "total_env_steps": 4144000, "episode_reward": 0.3547143340110779, "value_loss": 0.0063920988701283935, "policy_loss": -0.012114570321395195, "dist_entropy": 0.6696336468060812, "actor_grad_norm": 0.130662739276886, "critic_grad_norm": 0.03774165362119675, "ratio": 1.000016689300537, "entropy": 0.6696336468060812, "incre_win_rate": 0.8333333333333334, "step": 1295}
{"time": 1766591737.1903555, "phase": "train", "update": 1296, "total_env_steps": 4147200, "episode_reward": 0.35963085293769836, "value_loss": 0.00604263103256623, "policy_loss": -0.012812001478908996, "dist_entropy": 0.6707715630531311, "actor_grad_norm": 0.134473979473114, "critic_grad_norm": 0.03411468118429184, "ratio": 1.0010123252868652, "entropy": 0.6707715630531311, "incre_win_rate": 0.8813559322033898, "step": 1296}
{"time": 1766591741.8456733, "phase": "train", "update": 1297, "total_env_steps": 4150400, "episode_reward": 0.3482314348220825, "value_loss": 0.007333998195827007, "policy_loss": -0.013562023649450338, "dist_entropy": 0.6891693989435832, "actor_grad_norm": 0.13983027637004852, "critic_grad_norm": 0.02420078031718731, "ratio": 0.999569833278656, "entropy": 0.6891693989435832, "incre_win_rate": 0.8793103448275862, "step": 1297}
{"time": 1766591746.507848, "phase": "train", "update": 1298, "total_env_steps": 4153600, "episode_reward": 0.3495802581310272, "value_loss": 0.008788705803453922, "policy_loss": -0.013393973974303227, "dist_entropy": 0.6733916083971659, "actor_grad_norm": 0.14104551076889038, "critic_grad_norm": 0.008939336985349655, "ratio": 1.0000815391540527, "entropy": 0.6733916083971659, "incre_win_rate": 0.8620689655172413, "step": 1298}
{"time": 1766591751.1263928, "phase": "train", "update": 1299, "total_env_steps": 4156800, "episode_reward": 0.3512515127658844, "value_loss": 0.005879929630706707, "policy_loss": -0.013175828761199337, "dist_entropy": 0.6633607188860575, "actor_grad_norm": 0.15396910905838013, "critic_grad_norm": 0.04279424622654915, "ratio": 1.0001765489578247, "entropy": 0.6633607188860575, "incre_win_rate": 0.896551724137931, "step": 1299}
{"time": 1766591755.8118353, "phase": "train", "update": 1300, "total_env_steps": 4160000, "episode_reward": 0.3622908890247345, "value_loss": 0.007708160330851873, "policy_loss": -0.012430095871895712, "dist_entropy": 0.6759963711102803, "actor_grad_norm": 0.13610491156578064, "critic_grad_norm": 0.03659728541970253, "ratio": 0.9999233484268188, "entropy": 0.6759963711102803, "incre_win_rate": 0.9152542372881356, "step": 1300}
{"time": 1766591760.464391, "phase": "train", "update": 1301, "total_env_steps": 4163200, "episode_reward": 0.3588404059410095, "value_loss": 0.0048116478448112805, "policy_loss": -0.01273921739839352, "dist_entropy": 0.6623030503590902, "actor_grad_norm": 0.14351792633533478, "critic_grad_norm": 0.01451497245579958, "ratio": 0.9984350204467773, "entropy": 0.6623030503590902, "incre_win_rate": 0.8813559322033898, "step": 1301}
{"time": 1766591767.7549648, "phase": "eval", "update": 1301, "total_env_steps": 4163200, "eval_win_rate": 1.0, "eval_episode_reward": 20.006280637254903, "step": 1301}
{"time": 1766591772.3974855, "phase": "train", "update": 1302, "total_env_steps": 4166400, "episode_reward": 0.3624218702316284, "value_loss": 0.005649631284177304, "policy_loss": -0.012487808777716698, "dist_entropy": 0.671912415822347, "actor_grad_norm": 0.1257135570049286, "critic_grad_norm": 0.026955006644129753, "ratio": 0.9979425072669983, "entropy": 0.671912415822347, "incre_win_rate": 0.9166666666666666, "step": 1302}
{"time": 1766591777.09658, "phase": "train", "update": 1303, "total_env_steps": 4169600, "episode_reward": 0.36394914984703064, "value_loss": 0.005804418430974086, "policy_loss": -0.012856768504993, "dist_entropy": 0.6705084919929505, "actor_grad_norm": 0.13649721443653107, "critic_grad_norm": 0.025873735547065735, "ratio": 0.999808132648468, "entropy": 0.6705084919929505, "incre_win_rate": 0.9482758620689655, "step": 1303}
{"time": 1766591781.7858555, "phase": "train", "update": 1304, "total_env_steps": 4172800, "episode_reward": 0.3493121862411499, "value_loss": 0.005039529719700416, "policy_loss": -0.013775218656158236, "dist_entropy": 0.6386053880055745, "actor_grad_norm": 0.15274542570114136, "critic_grad_norm": 0.017507953569293022, "ratio": 0.9998723268508911, "entropy": 0.6386053880055745, "incre_win_rate": 0.8166666666666667, "step": 1304}
{"time": 1766591811.7358906, "phase": "train", "update": 1305, "total_env_steps": 4176000, "episode_reward": 0.35147517919540405, "value_loss": 0.05773763110240301, "policy_loss": -0.010003561079615508, "dist_entropy": 0.6666415572166443, "actor_grad_norm": 0.1104331687092781, "critic_grad_norm": 0.12670990824699402, "ratio": 1.0009422302246094, "entropy": 0.6666415572166443, "incre_win_rate": 0.8596491228070176, "step": 1305}
{"time": 1766591816.3786232, "phase": "train", "update": 1306, "total_env_steps": 4179200, "episode_reward": 0.3523981273174286, "value_loss": 0.009094029106199742, "policy_loss": -0.014638248997531396, "dist_entropy": 0.698627519607544, "actor_grad_norm": 0.1741272509098053, "critic_grad_norm": 0.07553813606500626, "ratio": 0.9987753629684448, "entropy": 0.698627519607544, "incre_win_rate": 0.8596491228070176, "step": 1306}
{"time": 1766591821.0321934, "phase": "train", "update": 1307, "total_env_steps": 4182400, "episode_reward": 0.32796645164489746, "value_loss": 0.01438484558214744, "policy_loss": -0.013889229034072297, "dist_entropy": 0.6698543747266134, "actor_grad_norm": 0.16289514303207397, "critic_grad_norm": 0.042461179196834564, "ratio": 0.9994573593139648, "entropy": 0.6698543747266134, "incre_win_rate": 0.7678571428571429, "step": 1307}
{"time": 1766591825.560036, "phase": "train", "update": 1308, "total_env_steps": 4185600, "episode_reward": 0.326784610748291, "value_loss": 0.008765971598525843, "policy_loss": -0.014175928394434519, "dist_entropy": 0.6651669422785441, "actor_grad_norm": 0.14987075328826904, "critic_grad_norm": 0.03258413076400757, "ratio": 1.0002692937850952, "entropy": 0.6651669422785441, "incre_win_rate": 0.8070175438596491, "step": 1308}
{"time": 1766591830.166143, "phase": "train", "update": 1309, "total_env_steps": 4188800, "episode_reward": 0.3544592261314392, "value_loss": 0.008431954371432463, "policy_loss": -0.0132472657545098, "dist_entropy": 0.6745406985282898, "actor_grad_norm": 0.1328035145998001, "critic_grad_norm": 0.03145427256822586, "ratio": 0.9985154867172241, "entropy": 0.6745406985282898, "incre_win_rate": 0.9107142857142857, "step": 1309}
{"time": 1766591834.818288, "phase": "train", "update": 1310, "total_env_steps": 4192000, "episode_reward": 0.34251993894577026, "value_loss": 0.00880826786160469, "policy_loss": -0.014283234641482068, "dist_entropy": 0.6793784737586975, "actor_grad_norm": 0.13474954664707184, "critic_grad_norm": 0.04133995249867439, "ratio": 1.0002564191818237, "entropy": 0.6793784737586975, "incre_win_rate": 0.7796610169491526, "step": 1310}
{"time": 1766591839.4503863, "phase": "train", "update": 1311, "total_env_steps": 4195200, "episode_reward": 0.3389759659767151, "value_loss": 0.010696664390464624, "policy_loss": -0.014260588989985478, "dist_entropy": 0.682544485727946, "actor_grad_norm": 0.17891469597816467, "critic_grad_norm": 0.030271237716078758, "ratio": 0.9992820024490356, "entropy": 0.682544485727946, "incre_win_rate": 0.8070175438596491, "step": 1311}
{"time": 1766591844.0608456, "phase": "train", "update": 1312, "total_env_steps": 4198400, "episode_reward": 0.350157767534256, "value_loss": 0.009730442923804124, "policy_loss": -0.013079161333003242, "dist_entropy": 0.6778780261675517, "actor_grad_norm": 0.14887522161006927, "critic_grad_norm": 0.021404337137937546, "ratio": 1.0002373456954956, "entropy": 0.6778780261675517, "incre_win_rate": 0.819672131147541, "step": 1312}
{"time": 1766591848.6676776, "phase": "train", "update": 1313, "total_env_steps": 4201600, "episode_reward": 0.35076823830604553, "value_loss": 0.008040369053681691, "policy_loss": -0.012255232895945767, "dist_entropy": 0.6731430768966675, "actor_grad_norm": 0.12275123596191406, "critic_grad_norm": 0.026830483227968216, "ratio": 0.9999683499336243, "entropy": 0.6731430768966675, "incre_win_rate": 0.8928571428571429, "step": 1313}
{"time": 1766591853.340257, "phase": "train", "update": 1314, "total_env_steps": 4204800, "episode_reward": 0.3444354832172394, "value_loss": 0.010009960023065407, "policy_loss": -0.015044973719533061, "dist_entropy": 0.6732993086179098, "actor_grad_norm": 0.13112612068653107, "critic_grad_norm": 0.03144451603293419, "ratio": 0.999496340751648, "entropy": 0.6732993086179098, "incre_win_rate": 0.864406779661017, "step": 1314}
{"time": 1766591857.970891, "phase": "train", "update": 1315, "total_env_steps": 4208000, "episode_reward": 0.363285094499588, "value_loss": 0.006384774887313445, "policy_loss": -0.01196270583446714, "dist_entropy": 0.6597843845685323, "actor_grad_norm": 0.12993250787258148, "critic_grad_norm": 0.019930711016058922, "ratio": 1.000885248184204, "entropy": 0.6597843845685323, "incre_win_rate": 0.8666666666666667, "step": 1315}
{"time": 1766591862.6483505, "phase": "train", "update": 1316, "total_env_steps": 4211200, "episode_reward": 0.34456419944763184, "value_loss": 0.013642070069909095, "policy_loss": -0.015487632494244489, "dist_entropy": 0.6884636004765828, "actor_grad_norm": 0.18120001256465912, "critic_grad_norm": 0.024850888177752495, "ratio": 1.0001308917999268, "entropy": 0.6884636004765828, "incre_win_rate": 0.7833333333333333, "step": 1316}
{"time": 1766591867.2533712, "phase": "train", "update": 1317, "total_env_steps": 4214400, "episode_reward": 0.36275506019592285, "value_loss": 0.009289190731942653, "policy_loss": -0.011440770491821912, "dist_entropy": 0.6748245199521382, "actor_grad_norm": 0.12266136705875397, "critic_grad_norm": 0.03872879967093468, "ratio": 0.9998515248298645, "entropy": 0.6748245199521382, "incre_win_rate": 0.8983050847457628, "step": 1317}
{"time": 1766591871.803025, "phase": "train", "update": 1318, "total_env_steps": 4217600, "episode_reward": 0.3425750732421875, "value_loss": 0.008915399263302485, "policy_loss": -0.013387121114589225, "dist_entropy": 0.6672967433929443, "actor_grad_norm": 0.1302441954612732, "critic_grad_norm": 0.018001576885581017, "ratio": 0.999329149723053, "entropy": 0.6672967433929443, "incre_win_rate": 0.8070175438596491, "step": 1318}
{"time": 1766591876.448643, "phase": "train", "update": 1319, "total_env_steps": 4220800, "episode_reward": 0.3586427569389343, "value_loss": 0.008547632365177076, "policy_loss": -0.014252524664351778, "dist_entropy": 0.6840931336085002, "actor_grad_norm": 0.15337103605270386, "critic_grad_norm": 0.01356371771544218, "ratio": 0.9995303153991699, "entropy": 0.6840931336085002, "incre_win_rate": 0.873015873015873, "step": 1319}
{"time": 1766591881.0844579, "phase": "train", "update": 1320, "total_env_steps": 4224000, "episode_reward": 0.35612285137176514, "value_loss": 0.01115517175445954, "policy_loss": -0.012845063683462617, "dist_entropy": 0.6724482496579488, "actor_grad_norm": 0.15484276413917542, "critic_grad_norm": 0.040838778018951416, "ratio": 0.9991559982299805, "entropy": 0.6724482496579488, "incre_win_rate": 0.8620689655172413, "step": 1320}
{"time": 1766591885.7361298, "phase": "train", "update": 1321, "total_env_steps": 4227200, "episode_reward": 0.3650084137916565, "value_loss": 0.012157286703586578, "policy_loss": -0.013112100499144219, "dist_entropy": 0.6889274636904399, "actor_grad_norm": 0.1561141461133957, "critic_grad_norm": 0.017790546640753746, "ratio": 0.9992374777793884, "entropy": 0.6889274636904399, "incre_win_rate": 0.8709677419354839, "step": 1321}
{"time": 1766591892.6381693, "phase": "eval", "update": 1321, "total_env_steps": 4227200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.48062193627451, "step": 1321}
{"time": 1766591897.3084795, "phase": "train", "update": 1322, "total_env_steps": 4230400, "episode_reward": 0.3582912087440491, "value_loss": 0.008595223103960355, "policy_loss": -0.013226065972399207, "dist_entropy": 0.6957008798917135, "actor_grad_norm": 0.1774066537618637, "critic_grad_norm": 0.05669189617037773, "ratio": 0.999428927898407, "entropy": 0.6957008798917135, "incre_win_rate": 0.8793103448275862, "step": 1322}
{"time": 1766591901.8958933, "phase": "train", "update": 1323, "total_env_steps": 4233600, "episode_reward": 0.34000080823898315, "value_loss": 0.009086104854941369, "policy_loss": -0.014309535335531512, "dist_entropy": 0.6833650946617127, "actor_grad_norm": 0.17959773540496826, "critic_grad_norm": 0.0607830248773098, "ratio": 0.9994795322418213, "entropy": 0.6833650946617127, "incre_win_rate": 0.7627118644067796, "step": 1323}
{"time": 1766591906.5609288, "phase": "train", "update": 1324, "total_env_steps": 4236800, "episode_reward": 0.3648698031902313, "value_loss": 0.008218643659104904, "policy_loss": -0.013106375507131614, "dist_entropy": 0.6902716755867004, "actor_grad_norm": 0.1695062667131424, "critic_grad_norm": 0.034401703625917435, "ratio": 0.9996576905250549, "entropy": 0.6902716755867004, "incre_win_rate": 0.8983050847457628, "step": 1324}
{"time": 1766591911.2060683, "phase": "train", "update": 1325, "total_env_steps": 4240000, "episode_reward": 0.3528646230697632, "value_loss": 0.009971684776246548, "policy_loss": -0.01292119458150675, "dist_entropy": 0.6918903787930807, "actor_grad_norm": 0.17881342768669128, "critic_grad_norm": 0.04124537855386734, "ratio": 0.9997158050537109, "entropy": 0.6918903787930807, "incre_win_rate": 0.8, "step": 1325}
{"time": 1766591916.131351, "phase": "train", "update": 1326, "total_env_steps": 4243200, "episode_reward": 0.36910921335220337, "value_loss": 0.00918030614654223, "policy_loss": -0.012915586758239783, "dist_entropy": 0.6844939748446147, "actor_grad_norm": 0.15841662883758545, "critic_grad_norm": 0.018975799903273582, "ratio": 1.0000160932540894, "entropy": 0.6844939748446147, "incre_win_rate": 0.9016393442622951, "step": 1326}
{"time": 1766591920.8188388, "phase": "train", "update": 1327, "total_env_steps": 4246400, "episode_reward": 0.36101943254470825, "value_loss": 0.009916005345682303, "policy_loss": -0.013145432768590126, "dist_entropy": 0.6736478368441264, "actor_grad_norm": 0.1529085487127304, "critic_grad_norm": 0.02612856589257717, "ratio": 1.0011603832244873, "entropy": 0.6736478368441264, "incre_win_rate": 0.8833333333333333, "step": 1327}
{"time": 1766591925.5020769, "phase": "train", "update": 1328, "total_env_steps": 4249600, "episode_reward": 0.3654143810272217, "value_loss": 0.009106699811915557, "policy_loss": -0.012110998325091297, "dist_entropy": 0.6760696291923523, "actor_grad_norm": 0.12404835224151611, "critic_grad_norm": 0.05819417163729668, "ratio": 0.9990302920341492, "entropy": 0.6760696291923523, "incre_win_rate": 0.8870967741935484, "step": 1328}
{"time": 1766591930.147058, "phase": "train", "update": 1329, "total_env_steps": 4252800, "episode_reward": 0.3722686767578125, "value_loss": 0.00788006813575824, "policy_loss": -0.013604973780425666, "dist_entropy": 0.6737867037455241, "actor_grad_norm": 0.12287168949842453, "critic_grad_norm": 0.022679923102259636, "ratio": 0.9998700618743896, "entropy": 0.6737867037455241, "incre_win_rate": 0.9166666666666666, "step": 1329}
{"time": 1766591934.8246253, "phase": "train", "update": 1330, "total_env_steps": 4256000, "episode_reward": 0.3498077392578125, "value_loss": 0.01094368522365888, "policy_loss": -0.01307774616440535, "dist_entropy": 0.685251780351003, "actor_grad_norm": 0.15193243324756622, "critic_grad_norm": 0.04028254374861717, "ratio": 1.000465989112854, "entropy": 0.685251780351003, "incre_win_rate": 0.8448275862068966, "step": 1330}
{"time": 1766591939.5404503, "phase": "train", "update": 1331, "total_env_steps": 4259200, "episode_reward": 0.373835027217865, "value_loss": 0.0052460462786257265, "policy_loss": -0.012813228412446994, "dist_entropy": 0.699106486638387, "actor_grad_norm": 0.12361704558134079, "critic_grad_norm": 0.02195916138589382, "ratio": 0.9999898672103882, "entropy": 0.699106486638387, "incre_win_rate": 0.9672131147540983, "step": 1331}
{"time": 1766591944.1977549, "phase": "train", "update": 1332, "total_env_steps": 4262400, "episode_reward": 0.3828960061073303, "value_loss": 0.004802716399232547, "policy_loss": -0.01276923104596411, "dist_entropy": 0.6872805754343668, "actor_grad_norm": 0.13943396508693695, "critic_grad_norm": 0.020316405221819878, "ratio": 1.0001176595687866, "entropy": 0.6872805754343668, "incre_win_rate": 0.9365079365079365, "step": 1332}
{"time": 1766591948.8020985, "phase": "train", "update": 1333, "total_env_steps": 4265600, "episode_reward": 0.36771446466445923, "value_loss": 0.006084195865939061, "policy_loss": -0.012953346286536771, "dist_entropy": 0.6848897178967793, "actor_grad_norm": 0.13711866736412048, "critic_grad_norm": 0.01704617775976658, "ratio": 1.0002189874649048, "entropy": 0.6848897178967793, "incre_win_rate": 0.9152542372881356, "step": 1333}
{"time": 1766591953.451721, "phase": "train", "update": 1334, "total_env_steps": 4268800, "episode_reward": 0.3684696555137634, "value_loss": 0.003129754929492871, "policy_loss": -0.014144487455005598, "dist_entropy": 0.6864068667093913, "actor_grad_norm": 0.14493964612483978, "critic_grad_norm": 0.010552724823355675, "ratio": 0.9995416402816772, "entropy": 0.6864068667093913, "incre_win_rate": 0.9508196721311475, "step": 1334}
{"time": 1766591958.1547601, "phase": "train", "update": 1335, "total_env_steps": 4272000, "episode_reward": 0.35396984219551086, "value_loss": 0.009781135308245818, "policy_loss": -0.013334880693279653, "dist_entropy": 0.6961458245913188, "actor_grad_norm": 0.14428165555000305, "critic_grad_norm": 0.06705270707607269, "ratio": 1.001284122467041, "entropy": 0.6961458245913188, "incre_win_rate": 0.8305084745762712, "step": 1335}
{"time": 1766591962.832521, "phase": "train", "update": 1336, "total_env_steps": 4275200, "episode_reward": 0.36852484941482544, "value_loss": 0.005441691509137551, "policy_loss": -0.013004266399373717, "dist_entropy": 0.6941925207773845, "actor_grad_norm": 0.16023050248622894, "critic_grad_norm": 0.032793499529361725, "ratio": 0.999688446521759, "entropy": 0.6941925207773845, "incre_win_rate": 0.9666666666666667, "step": 1336}
{"time": 1766591967.572562, "phase": "train", "update": 1337, "total_env_steps": 4278400, "episode_reward": 0.3578416109085083, "value_loss": 0.007795783287535111, "policy_loss": -0.014261194448069621, "dist_entropy": 0.6928268909454346, "actor_grad_norm": 0.1680271029472351, "critic_grad_norm": 0.021553047001361847, "ratio": 0.9996027946472168, "entropy": 0.6928268909454346, "incre_win_rate": 0.8333333333333334, "step": 1337}
{"time": 1766591972.39497, "phase": "train", "update": 1338, "total_env_steps": 4281600, "episode_reward": 0.38027268648147583, "value_loss": 0.003495883056893945, "policy_loss": -0.013252523445000957, "dist_entropy": 0.6896965781847636, "actor_grad_norm": 0.14724305272102356, "critic_grad_norm": 0.044154711067676544, "ratio": 1.0011221170425415, "entropy": 0.6896965781847636, "incre_win_rate": 0.9672131147540983, "step": 1338}
{"time": 1766591977.0720546, "phase": "train", "update": 1339, "total_env_steps": 4284800, "episode_reward": 0.37423333525657654, "value_loss": 0.006955949651698271, "policy_loss": -0.011729666300698287, "dist_entropy": 0.6713227550188701, "actor_grad_norm": 0.14450128376483917, "critic_grad_norm": 0.023435143753886223, "ratio": 1.000838041305542, "entropy": 0.6713227550188701, "incre_win_rate": 0.9180327868852459, "step": 1339}
{"time": 1766591981.7634828, "phase": "train", "update": 1340, "total_env_steps": 4288000, "episode_reward": 0.3744393289089203, "value_loss": 0.006227816827595234, "policy_loss": -0.012248088318530392, "dist_entropy": 0.6808223883310954, "actor_grad_norm": 0.13357305526733398, "critic_grad_norm": 0.007031865417957306, "ratio": 0.9997649192810059, "entropy": 0.6808223883310954, "incre_win_rate": 0.9354838709677419, "step": 1340}
{"time": 1766591986.4754105, "phase": "train", "update": 1341, "total_env_steps": 4291200, "episode_reward": 0.3795473575592041, "value_loss": 0.00317170238122344, "policy_loss": -0.012454919234835889, "dist_entropy": 0.6826313575108846, "actor_grad_norm": 0.14089961349964142, "critic_grad_norm": 0.01144191063940525, "ratio": 0.9996230602264404, "entropy": 0.6826313575108846, "incre_win_rate": 0.967741935483871, "step": 1341}
{"time": 1766591993.2550404, "phase": "eval", "update": 1341, "total_env_steps": 4291200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.84742647058824, "step": 1341}
{"time": 1766591997.9432116, "phase": "train", "update": 1342, "total_env_steps": 4294400, "episode_reward": 0.39012640714645386, "value_loss": 0.00366413922359546, "policy_loss": -0.011587353958470933, "dist_entropy": 0.6562999248504638, "actor_grad_norm": 0.1395103484392166, "critic_grad_norm": 0.01513061486184597, "ratio": 1.0000170469284058, "entropy": 0.6562999248504638, "incre_win_rate": 0.9508196721311475, "step": 1342}
{"time": 1766592002.683662, "phase": "train", "update": 1343, "total_env_steps": 4297600, "episode_reward": 0.37819549441337585, "value_loss": 0.0049465146847069265, "policy_loss": -0.01209874257039445, "dist_entropy": 0.6616485873858134, "actor_grad_norm": 0.13452638685703278, "critic_grad_norm": 0.018179526552557945, "ratio": 0.9995476007461548, "entropy": 0.6616485873858134, "incre_win_rate": 0.9206349206349206, "step": 1343}
{"time": 1766592007.3404386, "phase": "train", "update": 1344, "total_env_steps": 4300800, "episode_reward": 0.3772449195384979, "value_loss": 0.0032120287107924622, "policy_loss": -0.012947946916967604, "dist_entropy": 0.6697371045748393, "actor_grad_norm": 0.11053627729415894, "critic_grad_norm": 0.008111493661999702, "ratio": 0.9994537234306335, "entropy": 0.6697371045748393, "incre_win_rate": 0.9672131147540983, "step": 1344}
{"time": 1766592012.5151188, "phase": "train", "update": 1345, "total_env_steps": 4304000, "episode_reward": 0.36914366483688354, "value_loss": 0.003714188514277339, "policy_loss": -0.013204272424146523, "dist_entropy": 0.6756666819254558, "actor_grad_norm": 0.1578756868839264, "critic_grad_norm": 0.012718847952783108, "ratio": 1.0000606775283813, "entropy": 0.6756666819254558, "incre_win_rate": 0.9508196721311475, "step": 1345}
{"time": 1766592017.251122, "phase": "train", "update": 1346, "total_env_steps": 4307200, "episode_reward": 0.3815158009529114, "value_loss": 0.0045959452167153355, "policy_loss": -0.01184218204698766, "dist_entropy": 0.6421969175338745, "actor_grad_norm": 0.12557625770568848, "critic_grad_norm": 0.006560401991009712, "ratio": 0.9998555779457092, "entropy": 0.6421969175338745, "incre_win_rate": 0.9193548387096774, "step": 1346}
{"time": 1766592021.9237745, "phase": "train", "update": 1347, "total_env_steps": 4310400, "episode_reward": 0.36062195897102356, "value_loss": 0.007739362834642331, "policy_loss": -0.012553205875057453, "dist_entropy": 0.6637117107709248, "actor_grad_norm": 0.14556284248828888, "critic_grad_norm": 0.03035401552915573, "ratio": 0.9999643564224243, "entropy": 0.6637117107709248, "incre_win_rate": 0.8813559322033898, "step": 1347}
{"time": 1766592026.5956717, "phase": "train", "update": 1348, "total_env_steps": 4313600, "episode_reward": 0.38156938552856445, "value_loss": 0.007368557527661324, "policy_loss": -0.01279190574309818, "dist_entropy": 0.6401500821113586, "actor_grad_norm": 0.1194387823343277, "critic_grad_norm": 0.016188539564609528, "ratio": 0.9979326725006104, "entropy": 0.6401500821113586, "incre_win_rate": 0.9354838709677419, "step": 1348}
{"time": 1766592031.3457754, "phase": "train", "update": 1349, "total_env_steps": 4316800, "episode_reward": 0.3703423738479614, "value_loss": 0.007366429083049297, "policy_loss": -0.012234094427755575, "dist_entropy": 0.680697516600291, "actor_grad_norm": 0.12844376266002655, "critic_grad_norm": 0.014693979173898697, "ratio": 0.9998425841331482, "entropy": 0.680697516600291, "incre_win_rate": 0.95, "step": 1349}
{"time": 1766592035.9966435, "phase": "train", "update": 1350, "total_env_steps": 4320000, "episode_reward": 0.3860868513584137, "value_loss": 0.003864729730412364, "policy_loss": -0.012195143699036256, "dist_entropy": 0.6169255216916402, "actor_grad_norm": 0.1257239133119583, "critic_grad_norm": 0.015817265957593918, "ratio": 0.9994315505027771, "entropy": 0.6169255216916402, "incre_win_rate": 0.9206349206349206, "step": 1350}
{"time": 1766592040.7339692, "phase": "train", "update": 1351, "total_env_steps": 4323200, "episode_reward": 0.379454642534256, "value_loss": 0.008251254105319579, "policy_loss": -0.011706382795512126, "dist_entropy": 0.6527149200439453, "actor_grad_norm": 0.14489701390266418, "critic_grad_norm": 0.015028227120637894, "ratio": 1.0000183582305908, "entropy": 0.6527149200439453, "incre_win_rate": 0.9047619047619048, "step": 1351}
{"time": 1766592045.3655505, "phase": "train", "update": 1352, "total_env_steps": 4326400, "episode_reward": 0.37624236941337585, "value_loss": 0.005306198354810476, "policy_loss": -0.012892986123051741, "dist_entropy": 0.64102650086085, "actor_grad_norm": 0.13627909123897552, "critic_grad_norm": 0.012813723646104336, "ratio": 1.0008758306503296, "entropy": 0.64102650086085, "incre_win_rate": 0.9344262295081968, "step": 1352}
{"time": 1766592050.0895948, "phase": "train", "update": 1353, "total_env_steps": 4329600, "episode_reward": 0.3798828125, "value_loss": 0.004015795762340227, "policy_loss": -0.012248043583311686, "dist_entropy": 0.6385390281677246, "actor_grad_norm": 0.13433660566806793, "critic_grad_norm": 0.007129007019102573, "ratio": 1.0009520053863525, "entropy": 0.6385390281677246, "incre_win_rate": 0.9508196721311475, "step": 1353}
{"time": 1766592054.7366853, "phase": "train", "update": 1354, "total_env_steps": 4332800, "episode_reward": 0.36104169487953186, "value_loss": 0.009167974504331747, "policy_loss": -0.01224199157357096, "dist_entropy": 0.6379281798998515, "actor_grad_norm": 0.1415194422006607, "critic_grad_norm": 0.027148103341460228, "ratio": 1.0004850625991821, "entropy": 0.6379281798998515, "incre_win_rate": 0.8666666666666667, "step": 1354}
{"time": 1766592059.455066, "phase": "train", "update": 1355, "total_env_steps": 4336000, "episode_reward": 0.3910363018512726, "value_loss": 0.0038719468439618746, "policy_loss": -0.012170716464588338, "dist_entropy": 0.6559690475463867, "actor_grad_norm": 0.11319012194871902, "critic_grad_norm": 0.015379438176751137, "ratio": 1.0000795125961304, "entropy": 0.6559690475463867, "incre_win_rate": 0.9523809523809523, "step": 1355}
{"time": 1766592064.180351, "phase": "train", "update": 1356, "total_env_steps": 4339200, "episode_reward": 0.37783777713775635, "value_loss": 0.0072397998534142975, "policy_loss": -0.013383070251897777, "dist_entropy": 0.6518191854159038, "actor_grad_norm": 0.14358249306678772, "critic_grad_norm": 0.01682478003203869, "ratio": 0.9990878105163574, "entropy": 0.6518191854159038, "incre_win_rate": 0.890625, "step": 1356}
{"time": 1766592068.8857706, "phase": "train", "update": 1357, "total_env_steps": 4342400, "episode_reward": 0.37474724650382996, "value_loss": 0.00625877675289909, "policy_loss": -0.012835624412916975, "dist_entropy": 0.664625608921051, "actor_grad_norm": 0.1282026618719101, "critic_grad_norm": 0.028885968029499054, "ratio": 1.0006723403930664, "entropy": 0.664625608921051, "incre_win_rate": 0.9193548387096774, "step": 1357}
{"time": 1766592073.4997602, "phase": "train", "update": 1358, "total_env_steps": 4345600, "episode_reward": 0.3736695945262909, "value_loss": 0.005761458569516738, "policy_loss": -0.012211250269263018, "dist_entropy": 0.6775338133176168, "actor_grad_norm": 0.12822899222373962, "critic_grad_norm": 0.01247446984052658, "ratio": 1.0000951290130615, "entropy": 0.6775338133176168, "incre_win_rate": 0.9016393442622951, "step": 1358}
{"time": 1766592078.2230465, "phase": "train", "update": 1359, "total_env_steps": 4348800, "episode_reward": 0.3765747547149658, "value_loss": 0.007402335200458765, "policy_loss": -0.012831263172113338, "dist_entropy": 0.6659484664599101, "actor_grad_norm": 0.1321057677268982, "critic_grad_norm": 0.05644810199737549, "ratio": 0.9987520575523376, "entropy": 0.6659484664599101, "incre_win_rate": 0.859375, "step": 1359}
{"time": 1766592082.9111633, "phase": "train", "update": 1360, "total_env_steps": 4352000, "episode_reward": 0.3684267997741699, "value_loss": 0.010124189406633377, "policy_loss": -0.012473317390832506, "dist_entropy": 0.6779133558273316, "actor_grad_norm": 0.1479915976524353, "critic_grad_norm": 0.02835276909172535, "ratio": 0.9984647631645203, "entropy": 0.6779133558273316, "incre_win_rate": 0.8524590163934426, "step": 1360}
{"time": 1766592087.6161213, "phase": "train", "update": 1361, "total_env_steps": 4355200, "episode_reward": 0.37270990014076233, "value_loss": 0.0071657287888228895, "policy_loss": -0.013106637220143586, "dist_entropy": 0.6672694603602092, "actor_grad_norm": 0.12587925791740417, "critic_grad_norm": 0.014773257076740265, "ratio": 1.0014264583587646, "entropy": 0.6672694603602092, "incre_win_rate": 0.8709677419354839, "step": 1361}
{"time": 1766592094.417696, "phase": "eval", "update": 1361, "total_env_steps": 4355200, "eval_win_rate": 1.0, "eval_episode_reward": 20.0, "step": 1361}
{"time": 1766592099.0724804, "phase": "train", "update": 1362, "total_env_steps": 4358400, "episode_reward": 0.3606671094894409, "value_loss": 0.008763595918814341, "policy_loss": -0.013529752019754445, "dist_entropy": 0.6722083409627279, "actor_grad_norm": 0.1406223028898239, "critic_grad_norm": 0.021587975323200226, "ratio": 0.9988009929656982, "entropy": 0.6722083409627279, "incre_win_rate": 0.8813559322033898, "step": 1362}
{"time": 1766592103.8227465, "phase": "train", "update": 1363, "total_env_steps": 4361600, "episode_reward": 0.3615173101425171, "value_loss": 0.01298308918873469, "policy_loss": -0.013362257650938621, "dist_entropy": 0.6845011472702026, "actor_grad_norm": 0.1265355795621872, "critic_grad_norm": 0.04721492901444435, "ratio": 1.0009318590164185, "entropy": 0.6845011472702026, "incre_win_rate": 0.8064516129032258, "step": 1363}
{"time": 1766592108.5409577, "phase": "train", "update": 1364, "total_env_steps": 4364800, "episode_reward": 0.36624619364738464, "value_loss": 0.012386305133501689, "policy_loss": -0.013566172271051375, "dist_entropy": 0.6848293383916219, "actor_grad_norm": 0.16839417815208435, "critic_grad_norm": 0.018000226467847824, "ratio": 0.9996396899223328, "entropy": 0.6848293383916219, "incre_win_rate": 0.8524590163934426, "step": 1364}
{"time": 1766592113.276921, "phase": "train", "update": 1365, "total_env_steps": 4368000, "episode_reward": 0.38143613934516907, "value_loss": 0.005411880929023028, "policy_loss": -0.011347235840321327, "dist_entropy": 0.67159583568573, "actor_grad_norm": 0.11933674663305283, "critic_grad_norm": 0.016867078840732574, "ratio": 1.000485897064209, "entropy": 0.67159583568573, "incre_win_rate": 0.890625, "step": 1365}
{"time": 1766592117.9425676, "phase": "train", "update": 1366, "total_env_steps": 4371200, "episode_reward": 0.36703968048095703, "value_loss": 0.01146121925363938, "policy_loss": -0.01315617701071557, "dist_entropy": 0.683699119091034, "actor_grad_norm": 0.1418209671974182, "critic_grad_norm": 0.01852007769048214, "ratio": 1.0005121231079102, "entropy": 0.683699119091034, "incre_win_rate": 0.8253968253968254, "step": 1366}
{"time": 1766592122.695797, "phase": "train", "update": 1367, "total_env_steps": 4374400, "episode_reward": 0.38255515694618225, "value_loss": 0.009428134560585022, "policy_loss": -0.01277893787396541, "dist_entropy": 0.6907938957214356, "actor_grad_norm": 0.1297854334115982, "critic_grad_norm": 0.01182335615158081, "ratio": 0.9998050928115845, "entropy": 0.6907938957214356, "incre_win_rate": 0.8870967741935484, "step": 1367}
{"time": 1766592127.3236144, "phase": "train", "update": 1368, "total_env_steps": 4377600, "episode_reward": 0.3649134635925293, "value_loss": 0.008330960509677727, "policy_loss": -0.014091458475232818, "dist_entropy": 0.6869258920351664, "actor_grad_norm": 0.15484827756881714, "critic_grad_norm": 0.02576838620007038, "ratio": 0.9996910095214844, "entropy": 0.6869258920351664, "incre_win_rate": 0.8666666666666667, "step": 1368}
{"time": 1766592132.0145934, "phase": "train", "update": 1369, "total_env_steps": 4380800, "episode_reward": 0.3723437488079071, "value_loss": 0.008259602170437575, "policy_loss": -0.013241935683386904, "dist_entropy": 0.7101622780164083, "actor_grad_norm": 0.11800535023212433, "critic_grad_norm": 0.028176087886095047, "ratio": 0.9999595880508423, "entropy": 0.7101622780164083, "incre_win_rate": 0.8888888888888888, "step": 1369}
{"time": 1766592136.7036746, "phase": "train", "update": 1370, "total_env_steps": 4384000, "episode_reward": 0.3768872618675232, "value_loss": 0.008642187155783177, "policy_loss": -0.013470029787677026, "dist_entropy": 0.6994608720143636, "actor_grad_norm": 0.11701183021068573, "critic_grad_norm": 0.02123696729540825, "ratio": 0.9993148446083069, "entropy": 0.6994608720143636, "incre_win_rate": 0.9047619047619048, "step": 1370}
{"time": 1766592141.3679326, "phase": "train", "update": 1371, "total_env_steps": 4387200, "episode_reward": 0.35745251178741455, "value_loss": 0.007411719517161449, "policy_loss": -0.012848938720259185, "dist_entropy": 0.6850930293401082, "actor_grad_norm": 0.11775007843971252, "critic_grad_norm": 0.03762440010905266, "ratio": 1.0002999305725098, "entropy": 0.6850930293401082, "incre_win_rate": 0.8135593220338984, "step": 1371}
{"time": 1766592146.0382204, "phase": "train", "update": 1372, "total_env_steps": 4390400, "episode_reward": 0.3696545660495758, "value_loss": 0.0075222979299724105, "policy_loss": -0.013064149063345099, "dist_entropy": 0.6935572942097982, "actor_grad_norm": 0.1354711800813675, "critic_grad_norm": 0.02272072434425354, "ratio": 1.0003767013549805, "entropy": 0.6935572942097982, "incre_win_rate": 0.9016393442622951, "step": 1372}
{"time": 1766592150.7547615, "phase": "train", "update": 1373, "total_env_steps": 4393600, "episode_reward": 0.3724111318588257, "value_loss": 0.00811516521498561, "policy_loss": -0.01249449817645143, "dist_entropy": 0.6868794520696004, "actor_grad_norm": 0.13485340774059296, "critic_grad_norm": 0.027806997299194336, "ratio": 1.0016242265701294, "entropy": 0.6868794520696004, "incre_win_rate": 0.8833333333333333, "step": 1373}
{"time": 1766592155.4274886, "phase": "train", "update": 1374, "total_env_steps": 4396800, "episode_reward": 0.3718803822994232, "value_loss": 0.009964920269946257, "policy_loss": -0.013609600965257112, "dist_entropy": 0.7119664867719014, "actor_grad_norm": 0.13074643909931183, "critic_grad_norm": 0.020798534154891968, "ratio": 0.9996774792671204, "entropy": 0.7119664867719014, "incre_win_rate": 0.9032258064516129, "step": 1374}
{"time": 1766592160.3944147, "phase": "train", "update": 1375, "total_env_steps": 4400000, "episode_reward": 0.36085784435272217, "value_loss": 0.00920335551102956, "policy_loss": -0.013944087984600628, "dist_entropy": 0.7119224945704142, "actor_grad_norm": 0.14475379884243011, "critic_grad_norm": 0.02628948539495468, "ratio": 1.0001821517944336, "entropy": 0.7119224945704142, "incre_win_rate": 0.8387096774193549, "step": 1375}
{"time": 1766592165.0744576, "phase": "train", "update": 1376, "total_env_steps": 4403200, "episode_reward": 0.3684903681278229, "value_loss": 0.010053036796549956, "policy_loss": -0.01382017968087427, "dist_entropy": 0.6989880959192912, "actor_grad_norm": 0.12572859227657318, "critic_grad_norm": 0.023209599778056145, "ratio": 0.9993349313735962, "entropy": 0.6989880959192912, "incre_win_rate": 0.8360655737704918, "step": 1376}
{"time": 1766592169.8312805, "phase": "train", "update": 1377, "total_env_steps": 4406400, "episode_reward": 0.36727404594421387, "value_loss": 0.008221823225418727, "policy_loss": -0.013006166464632922, "dist_entropy": 0.6954905072848002, "actor_grad_norm": 0.12712079286575317, "critic_grad_norm": 0.010661747306585312, "ratio": 1.000550627708435, "entropy": 0.6954905072848002, "incre_win_rate": 0.8688524590163934, "step": 1377}
{"time": 1766592174.4999907, "phase": "train", "update": 1378, "total_env_steps": 4409600, "episode_reward": 0.3550260663032532, "value_loss": 0.01424197902282079, "policy_loss": -0.01465567849198853, "dist_entropy": 0.6945589661598206, "actor_grad_norm": 0.13547304272651672, "critic_grad_norm": 0.02015332691371441, "ratio": 1.000569462776184, "entropy": 0.6945589661598206, "incre_win_rate": 0.8, "step": 1378}
{"time": 1766592179.1349478, "phase": "train", "update": 1379, "total_env_steps": 4412800, "episode_reward": 0.37550243735313416, "value_loss": 0.006741376252224048, "policy_loss": -0.012559383774367442, "dist_entropy": 0.6759632507960002, "actor_grad_norm": 0.12250616401433945, "critic_grad_norm": 0.061241671442985535, "ratio": 1.000609278678894, "entropy": 0.6759632507960002, "incre_win_rate": 0.9032258064516129, "step": 1379}
{"time": 1766592183.8655214, "phase": "train", "update": 1380, "total_env_steps": 4416000, "episode_reward": 0.36969897150993347, "value_loss": 0.007921404826144377, "policy_loss": -0.013718632255694274, "dist_entropy": 0.6660637180010478, "actor_grad_norm": 0.1328590363264084, "critic_grad_norm": 0.04666770622134209, "ratio": 0.9993223547935486, "entropy": 0.6660637180010478, "incre_win_rate": 0.8833333333333333, "step": 1380}
{"time": 1766592188.562233, "phase": "train", "update": 1381, "total_env_steps": 4419200, "episode_reward": 0.3762890696525574, "value_loss": 0.006451133514444033, "policy_loss": -0.012265702090966593, "dist_entropy": 0.689198621114095, "actor_grad_norm": 0.11787302047014236, "critic_grad_norm": 0.02300463430583477, "ratio": 0.9989789128303528, "entropy": 0.689198621114095, "incre_win_rate": 0.9516129032258065, "step": 1381}
{"time": 1766592195.3322482, "phase": "eval", "update": 1381, "total_env_steps": 4419200, "eval_win_rate": 1.0, "eval_episode_reward": 20.004136029411768, "step": 1381}
{"time": 1766592200.043078, "phase": "train", "update": 1382, "total_env_steps": 4422400, "episode_reward": 0.37116268277168274, "value_loss": 0.004509308189153671, "policy_loss": -0.013050372227651508, "dist_entropy": 0.7017267266909282, "actor_grad_norm": 0.12194980680942535, "critic_grad_norm": 0.009068616665899754, "ratio": 0.9993873238563538, "entropy": 0.7017267266909282, "incre_win_rate": 0.9016393442622951, "step": 1382}
{"time": 1766592204.735982, "phase": "train", "update": 1383, "total_env_steps": 4425600, "episode_reward": 0.3804764449596405, "value_loss": 0.00521181042616566, "policy_loss": -0.012792479747399927, "dist_entropy": 0.67805601755778, "actor_grad_norm": 0.13811834156513214, "critic_grad_norm": 0.00895511731505394, "ratio": 1.0002933740615845, "entropy": 0.67805601755778, "incre_win_rate": 0.9365079365079365, "step": 1383}
{"time": 1766592209.4258323, "phase": "train", "update": 1384, "total_env_steps": 4428800, "episode_reward": 0.3730330765247345, "value_loss": 0.007919869975497325, "policy_loss": -0.012858197724097546, "dist_entropy": 0.6997531056404114, "actor_grad_norm": 0.131484717130661, "critic_grad_norm": 0.022098194807767868, "ratio": 1.0000452995300293, "entropy": 0.6997531056404114, "incre_win_rate": 0.9180327868852459, "step": 1384}
{"time": 1766592214.2172663, "phase": "train", "update": 1385, "total_env_steps": 4432000, "episode_reward": 0.37631818652153015, "value_loss": 0.005590466844538847, "policy_loss": -0.012670027839709046, "dist_entropy": 0.6921531359354655, "actor_grad_norm": 0.13811348378658295, "critic_grad_norm": 0.03253424912691116, "ratio": 0.9996621608734131, "entropy": 0.6921531359354655, "incre_win_rate": 0.9180327868852459, "step": 1385}
{"time": 1766592218.9305005, "phase": "train", "update": 1386, "total_env_steps": 4435200, "episode_reward": 0.37615272402763367, "value_loss": 0.0070813550924261415, "policy_loss": -0.013100795441955408, "dist_entropy": 0.689794127146403, "actor_grad_norm": 0.1244375929236412, "critic_grad_norm": 0.030397778376936913, "ratio": 0.999821126461029, "entropy": 0.689794127146403, "incre_win_rate": 0.95, "step": 1386}
{"time": 1766592223.623269, "phase": "train", "update": 1387, "total_env_steps": 4438400, "episode_reward": 0.3502787947654724, "value_loss": 0.009654741982618969, "policy_loss": -0.012692319366777838, "dist_entropy": 0.6820032954216003, "actor_grad_norm": 0.1264878660440445, "critic_grad_norm": 0.030042614787817, "ratio": 0.9997307062149048, "entropy": 0.6820032954216003, "incre_win_rate": 0.8333333333333334, "step": 1387}
{"time": 1766592228.353761, "phase": "train", "update": 1388, "total_env_steps": 4441600, "episode_reward": 0.38257354497909546, "value_loss": 0.004480440107484659, "policy_loss": -0.012281164527637856, "dist_entropy": 0.7080210367838542, "actor_grad_norm": 0.12810339033603668, "critic_grad_norm": 0.028861181810498238, "ratio": 0.9985936880111694, "entropy": 0.7080210367838542, "incre_win_rate": 0.9193548387096774, "step": 1388}
{"time": 1766592233.074752, "phase": "train", "update": 1389, "total_env_steps": 4444800, "episode_reward": 0.3722012937068939, "value_loss": 0.0051798047808309395, "policy_loss": -0.012882329304074366, "dist_entropy": 0.7190816640853882, "actor_grad_norm": 0.1303022801876068, "critic_grad_norm": 0.01511546690016985, "ratio": 0.9991037249565125, "entropy": 0.7190816640853882, "incre_win_rate": 0.9508196721311475, "step": 1389}
{"time": 1766592237.6942914, "phase": "train", "update": 1390, "total_env_steps": 4448000, "episode_reward": 0.36309587955474854, "value_loss": 0.00912769107768933, "policy_loss": -0.01376215285976355, "dist_entropy": 0.7194585124651591, "actor_grad_norm": 0.1349891573190689, "critic_grad_norm": 0.029219724237918854, "ratio": 0.999900758266449, "entropy": 0.7194585124651591, "incre_win_rate": 0.8688524590163934, "step": 1390}
{"time": 1766592242.4559002, "phase": "train", "update": 1391, "total_env_steps": 4451200, "episode_reward": 0.36578357219696045, "value_loss": 0.007785062522937854, "policy_loss": -0.01295638840316163, "dist_entropy": 0.7268831173578898, "actor_grad_norm": 0.13418351113796234, "critic_grad_norm": 0.025815507397055626, "ratio": 1.0014492273330688, "entropy": 0.7268831173578898, "incre_win_rate": 0.8813559322033898, "step": 1391}
{"time": 1766592247.1595712, "phase": "train", "update": 1392, "total_env_steps": 4454400, "episode_reward": 0.3731924295425415, "value_loss": 0.0061580256869395575, "policy_loss": -0.012470155485611182, "dist_entropy": 0.703296172618866, "actor_grad_norm": 0.14198507368564606, "critic_grad_norm": 0.01797620765864849, "ratio": 0.9995235204696655, "entropy": 0.703296172618866, "incre_win_rate": 0.9180327868852459, "step": 1392}
{"time": 1766592251.8811533, "phase": "train", "update": 1393, "total_env_steps": 4457600, "episode_reward": 0.367087185382843, "value_loss": 0.007652751014878352, "policy_loss": -0.012634462107534716, "dist_entropy": 0.7018238107363383, "actor_grad_norm": 0.14634814858436584, "critic_grad_norm": 0.018383895978331566, "ratio": 1.00034499168396, "entropy": 0.7018238107363383, "incre_win_rate": 0.9, "step": 1393}
{"time": 1766592256.556062, "phase": "train", "update": 1394, "total_env_steps": 4460800, "episode_reward": 0.36452898383140564, "value_loss": 0.006390656003107628, "policy_loss": -0.013615448391610604, "dist_entropy": 0.6985278964042664, "actor_grad_norm": 0.1466030776500702, "critic_grad_norm": 0.026512041687965393, "ratio": 0.9981240630149841, "entropy": 0.6985278964042664, "incre_win_rate": 0.8833333333333333, "step": 1394}
{"time": 1766592261.2813468, "phase": "train", "update": 1395, "total_env_steps": 4464000, "episode_reward": 0.3743344247341156, "value_loss": 0.008298636320978403, "policy_loss": -0.012791952394693832, "dist_entropy": 0.6953374147415161, "actor_grad_norm": 0.12378399819135666, "critic_grad_norm": 0.014930770732462406, "ratio": 1.0003188848495483, "entropy": 0.6953374147415161, "incre_win_rate": 0.9047619047619048, "step": 1395}
{"time": 1766592265.9402528, "phase": "train", "update": 1396, "total_env_steps": 4467200, "episode_reward": 0.3493880331516266, "value_loss": 0.009845643614729246, "policy_loss": -0.012873978702699181, "dist_entropy": 0.7317197163899739, "actor_grad_norm": 0.13092917203903198, "critic_grad_norm": 0.02322704717516899, "ratio": 0.9997024536132812, "entropy": 0.7317197163899739, "incre_win_rate": 0.8305084745762712, "step": 1396}
{"time": 1766592270.6062615, "phase": "train", "update": 1397, "total_env_steps": 4470400, "episode_reward": 0.35952359437942505, "value_loss": 0.009479678235948086, "policy_loss": -0.015222669762080917, "dist_entropy": 0.7108699003855388, "actor_grad_norm": 0.15911568701267242, "critic_grad_norm": 0.04375357925891876, "ratio": 0.9988903403282166, "entropy": 0.7108699003855388, "incre_win_rate": 0.8166666666666667, "step": 1397}
{"time": 1766592275.3324714, "phase": "train", "update": 1398, "total_env_steps": 4473600, "episode_reward": 0.3505706191062927, "value_loss": 0.009424605282644431, "policy_loss": -0.012941131021454548, "dist_entropy": 0.705378254254659, "actor_grad_norm": 0.13911564648151398, "critic_grad_norm": 0.041773706674575806, "ratio": 1.000134825706482, "entropy": 0.705378254254659, "incre_win_rate": 0.8, "step": 1398}
{"time": 1766592280.08728, "phase": "train", "update": 1399, "total_env_steps": 4476800, "episode_reward": 0.3714698553085327, "value_loss": 0.010126303570965925, "policy_loss": -0.012633912993120095, "dist_entropy": 0.7235783298810323, "actor_grad_norm": 0.13223306834697723, "critic_grad_norm": 0.026354558765888214, "ratio": 1.0002307891845703, "entropy": 0.7235783298810323, "incre_win_rate": 0.8888888888888888, "step": 1399}
{"time": 1766592284.819403, "phase": "train", "update": 1400, "total_env_steps": 4480000, "episode_reward": 0.3567463457584381, "value_loss": 0.012368488187591235, "policy_loss": -0.012582881305856592, "dist_entropy": 0.7168413837750752, "actor_grad_norm": 0.12203060835599899, "critic_grad_norm": 0.02143382653594017, "ratio": 0.999286413192749, "entropy": 0.7168413837750752, "incre_win_rate": 0.864406779661017, "step": 1400}
{"time": 1766592289.500101, "phase": "train", "update": 1401, "total_env_steps": 4483200, "episode_reward": 0.36689493060112, "value_loss": 0.006749431292215983, "policy_loss": -0.012134472600614865, "dist_entropy": 0.7193390607833863, "actor_grad_norm": 0.10805603116750717, "critic_grad_norm": 0.025718148797750473, "ratio": 0.9996987581253052, "entropy": 0.7193390607833863, "incre_win_rate": 0.8666666666666667, "step": 1401}
{"time": 1766592296.3876576, "phase": "eval", "update": 1401, "total_env_steps": 4483200, "eval_win_rate": 1.0, "eval_episode_reward": 20.005361519607842, "step": 1401}
{"time": 1766592301.0296736, "phase": "train", "update": 1402, "total_env_steps": 4486400, "episode_reward": 0.3650068938732147, "value_loss": 0.009821394396324953, "policy_loss": -0.01224076456542799, "dist_entropy": 0.7055357058842977, "actor_grad_norm": 0.1356659233570099, "critic_grad_norm": 0.022665128111839294, "ratio": 1.0000317096710205, "entropy": 0.7055357058842977, "incre_win_rate": 0.8688524590163934, "step": 1402}
{"time": 1766592305.8181684, "phase": "train", "update": 1403, "total_env_steps": 4489600, "episode_reward": 0.36787304282188416, "value_loss": 0.005978971223036448, "policy_loss": -0.013166291844171004, "dist_entropy": 0.7154386878013611, "actor_grad_norm": 0.12331117689609528, "critic_grad_norm": 0.015216032043099403, "ratio": 0.9990781545639038, "entropy": 0.7154386878013611, "incre_win_rate": 0.9180327868852459, "step": 1403}
{"time": 1766592310.532331, "phase": "train", "update": 1404, "total_env_steps": 4492800, "episode_reward": 0.3648085296154022, "value_loss": 0.009637065355976422, "policy_loss": -0.0131318048909075, "dist_entropy": 0.695185919602712, "actor_grad_norm": 0.1301366686820984, "critic_grad_norm": 0.05046987161040306, "ratio": 1.0017114877700806, "entropy": 0.695185919602712, "incre_win_rate": 0.8688524590163934, "step": 1404}
{"time": 1766592315.2480345, "phase": "train", "update": 1405, "total_env_steps": 4496000, "episode_reward": 0.3698897063732147, "value_loss": 0.009146904386579991, "policy_loss": -0.014117702852850774, "dist_entropy": 0.6945641001065572, "actor_grad_norm": 0.12224502116441727, "critic_grad_norm": 0.023686032742261887, "ratio": 0.9991464018821716, "entropy": 0.6945641001065572, "incre_win_rate": 0.9, "step": 1405}
{"time": 1766592319.9709609, "phase": "train", "update": 1406, "total_env_steps": 4499200, "episode_reward": 0.3692356050014496, "value_loss": 0.009496065539618332, "policy_loss": -0.011708163303135658, "dist_entropy": 0.7170728365580241, "actor_grad_norm": 0.11711597442626953, "critic_grad_norm": 0.021172359585762024, "ratio": 0.9998438954353333, "entropy": 0.7170728365580241, "incre_win_rate": 0.9180327868852459, "step": 1406}
{"time": 1766592324.768787, "phase": "train", "update": 1407, "total_env_steps": 4502400, "episode_reward": 0.3728239834308624, "value_loss": 0.0073056549144287905, "policy_loss": -0.012876551633610234, "dist_entropy": 0.6910204688707987, "actor_grad_norm": 0.12389660626649857, "critic_grad_norm": 0.03646670654416084, "ratio": 0.9994312524795532, "entropy": 0.6910204688707987, "incre_win_rate": 0.9333333333333333, "step": 1407}
{"time": 1766592329.6343868, "phase": "train", "update": 1408, "total_env_steps": 4505600, "episode_reward": 0.37184664607048035, "value_loss": 0.006049308739602566, "policy_loss": -0.013253059021459516, "dist_entropy": 0.701423188050588, "actor_grad_norm": 0.1331416815519333, "critic_grad_norm": 0.03314816579222679, "ratio": 0.9981509447097778, "entropy": 0.701423188050588, "incre_win_rate": 0.8870967741935484, "step": 1408}
{"time": 1766592334.7014208, "phase": "train", "update": 1409, "total_env_steps": 4508800, "episode_reward": 0.36967217922210693, "value_loss": 0.006705511423448721, "policy_loss": -0.011414887116398376, "dist_entropy": 0.7053419391314188, "actor_grad_norm": 0.13261882960796356, "critic_grad_norm": 0.0145297572016716, "ratio": 0.9996209144592285, "entropy": 0.7053419391314188, "incre_win_rate": 0.9344262295081968, "step": 1409}
{"time": 1766592339.6483932, "phase": "train", "update": 1410, "total_env_steps": 4512000, "episode_reward": 0.36830347776412964, "value_loss": 0.007323098524163167, "policy_loss": -0.01278368977276898, "dist_entropy": 0.6903294682502746, "actor_grad_norm": 0.13005489110946655, "critic_grad_norm": 0.02752220630645752, "ratio": 0.9996903538703918, "entropy": 0.6903294682502746, "incre_win_rate": 0.9322033898305084, "step": 1410}
{"time": 1766592344.5807943, "phase": "train", "update": 1411, "total_env_steps": 4515200, "episode_reward": 0.37739965319633484, "value_loss": 0.006154260691255331, "policy_loss": -0.012379458745529821, "dist_entropy": 0.6836734135945638, "actor_grad_norm": 0.11370983719825745, "critic_grad_norm": 0.018975716084241867, "ratio": 0.9995515942573547, "entropy": 0.6836734135945638, "incre_win_rate": 0.9193548387096774, "step": 1411}
{"time": 1766592349.2487748, "phase": "train", "update": 1412, "total_env_steps": 4518400, "episode_reward": 0.36238208413124084, "value_loss": 0.004757804858187834, "policy_loss": -0.013899013521469782, "dist_entropy": 0.6928925752639771, "actor_grad_norm": 0.11674629896879196, "critic_grad_norm": 0.0188638586550951, "ratio": 0.9993706345558167, "entropy": 0.6928925752639771, "incre_win_rate": 0.9322033898305084, "step": 1412}
{"time": 1766592353.9697342, "phase": "train", "update": 1413, "total_env_steps": 4521600, "episode_reward": 0.36554303765296936, "value_loss": 0.009359440704186758, "policy_loss": -0.014044242264357838, "dist_entropy": 0.668347152074178, "actor_grad_norm": 0.1297662854194641, "critic_grad_norm": 0.04644768312573433, "ratio": 0.9992474317550659, "entropy": 0.668347152074178, "incre_win_rate": 0.8571428571428571, "step": 1413}
{"time": 1766592358.7953565, "phase": "train", "update": 1414, "total_env_steps": 4524800, "episode_reward": 0.3799302875995636, "value_loss": 0.003978430991992354, "policy_loss": -0.012858418915477898, "dist_entropy": 0.6798577586809794, "actor_grad_norm": 0.15364985167980194, "critic_grad_norm": 0.023259324952960014, "ratio": 1.000560998916626, "entropy": 0.6798577586809794, "incre_win_rate": 0.9193548387096774, "step": 1414}
{"time": 1766592363.606036, "phase": "train", "update": 1415, "total_env_steps": 4528000, "episode_reward": 0.3795986771583557, "value_loss": 0.005195769729713599, "policy_loss": -0.012015919450796749, "dist_entropy": 0.6878647605578104, "actor_grad_norm": 0.11503010988235474, "critic_grad_norm": 0.009167900308966637, "ratio": 1.0001329183578491, "entropy": 0.6878647605578104, "incre_win_rate": 0.9333333333333333, "step": 1415}
{"time": 1766592368.4616542, "phase": "train", "update": 1416, "total_env_steps": 4531200, "episode_reward": 0.38639628887176514, "value_loss": 0.00614506679897507, "policy_loss": -0.01426557382537131, "dist_entropy": 0.6709922909736633, "actor_grad_norm": 0.12796485424041748, "critic_grad_norm": 0.010027137584984303, "ratio": 0.9999063014984131, "entropy": 0.6709922909736633, "incre_win_rate": 0.9365079365079365, "step": 1416}
{"time": 1766592373.3782318, "phase": "train", "update": 1417, "total_env_steps": 4534400, "episode_reward": 0.382028192281723, "value_loss": 0.006268988891194264, "policy_loss": -0.013635567247208276, "dist_entropy": 0.6811360716819763, "actor_grad_norm": 0.13527065515518188, "critic_grad_norm": 0.01907389983534813, "ratio": 0.9993353486061096, "entropy": 0.6811360716819763, "incre_win_rate": 0.9365079365079365, "step": 1417}
{"time": 1766592378.1452703, "phase": "train", "update": 1418, "total_env_steps": 4537600, "episode_reward": 0.35622549057006836, "value_loss": 0.00743509695554773, "policy_loss": -0.01340545173698852, "dist_entropy": 0.6730896075566609, "actor_grad_norm": 0.1425924003124237, "critic_grad_norm": 0.01967237889766693, "ratio": 0.997823178768158, "entropy": 0.6730896075566609, "incre_win_rate": 0.8666666666666667, "step": 1418}
{"time": 1766592382.8542488, "phase": "train", "update": 1419, "total_env_steps": 4540800, "episode_reward": 0.3688511252403259, "value_loss": 0.006720758198450009, "policy_loss": -0.013525972996291102, "dist_entropy": 0.6543895959854126, "actor_grad_norm": 0.1231638714671135, "critic_grad_norm": 0.028284067288041115, "ratio": 1.000563144683838, "entropy": 0.6543895959854126, "incre_win_rate": 0.8833333333333333, "step": 1419}
{"time": 1766592387.729559, "phase": "train", "update": 1420, "total_env_steps": 4544000, "episode_reward": 0.3941161334514618, "value_loss": 0.004494357357422511, "policy_loss": -0.01269510571633153, "dist_entropy": 0.6821463545163472, "actor_grad_norm": 0.12333076447248459, "critic_grad_norm": 0.015516191720962524, "ratio": 0.9988492131233215, "entropy": 0.6821463545163472, "incre_win_rate": 0.953125, "step": 1420}
{"time": 1766592392.6818647, "phase": "train", "update": 1421, "total_env_steps": 4547200, "episode_reward": 0.36418426036834717, "value_loss": 0.011510486342012882, "policy_loss": -0.012326003299966715, "dist_entropy": 0.6824060002962749, "actor_grad_norm": 0.13439729809761047, "critic_grad_norm": 0.06992407143115997, "ratio": 0.9990684390068054, "entropy": 0.6824060002962749, "incre_win_rate": 0.8387096774193549, "step": 1421}
{"time": 1766592400.8335068, "phase": "eval", "update": 1421, "total_env_steps": 4547200, "eval_win_rate": 1.0, "eval_episode_reward": 20.012254901960784, "step": 1421}
{"time": 1766592406.2175727, "phase": "train", "update": 1422, "total_env_steps": 4550400, "episode_reward": 0.3729817867279053, "value_loss": 0.006423386683066686, "policy_loss": -0.013428554747779249, "dist_entropy": 0.6782342871030171, "actor_grad_norm": 0.13778646290302277, "critic_grad_norm": 0.030489768832921982, "ratio": 0.9999940395355225, "entropy": 0.6782342871030171, "incre_win_rate": 0.9016393442622951, "step": 1422}
{"time": 1766592411.1763692, "phase": "train", "update": 1423, "total_env_steps": 4553600, "episode_reward": 0.39185893535614014, "value_loss": 0.004238805314525962, "policy_loss": -0.012308499051057235, "dist_entropy": 0.6797953685124715, "actor_grad_norm": 0.14114069938659668, "critic_grad_norm": 0.03939380496740341, "ratio": 0.9994826316833496, "entropy": 0.6797953685124715, "incre_win_rate": 0.9838709677419355, "step": 1423}
{"time": 1766592416.2044027, "phase": "train", "update": 1424, "total_env_steps": 4556800, "episode_reward": 0.3735271394252777, "value_loss": 0.004529407651474079, "policy_loss": -0.012555475106515246, "dist_entropy": 0.6813622832298278, "actor_grad_norm": 0.13338065147399902, "critic_grad_norm": 0.02073468454182148, "ratio": 0.9981825947761536, "entropy": 0.6813622832298278, "incre_win_rate": 0.8852459016393442, "step": 1424}
{"time": 1766592421.1317053, "phase": "train", "update": 1425, "total_env_steps": 4560000, "episode_reward": 0.38019683957099915, "value_loss": 0.005159517315526803, "policy_loss": -0.011495024744219033, "dist_entropy": 0.6929428259531657, "actor_grad_norm": 0.11569326370954514, "critic_grad_norm": 0.02115033008158207, "ratio": 1.0000197887420654, "entropy": 0.6929428259531657, "incre_win_rate": 0.921875, "step": 1425}
{"time": 1766592425.9587133, "phase": "train", "update": 1426, "total_env_steps": 4563200, "episode_reward": 0.3868045210838318, "value_loss": 0.0050700874999165535, "policy_loss": -0.01354638306398878, "dist_entropy": 0.6790367245674134, "actor_grad_norm": 0.1487998217344284, "critic_grad_norm": 0.021065736189484596, "ratio": 0.9998732805252075, "entropy": 0.6790367245674134, "incre_win_rate": 0.921875, "step": 1426}
{"time": 1766592430.7105083, "phase": "train", "update": 1427, "total_env_steps": 4566400, "episode_reward": 0.38220128417015076, "value_loss": 0.005244647059589625, "policy_loss": -0.012481542607210135, "dist_entropy": 0.6673527717590332, "actor_grad_norm": 0.12145887315273285, "critic_grad_norm": 0.01711142621934414, "ratio": 0.9995838403701782, "entropy": 0.6673527717590332, "incre_win_rate": 0.9508196721311475, "step": 1427}
{"time": 1766592435.3757405, "phase": "train", "update": 1428, "total_env_steps": 4569600, "episode_reward": 0.3688158690929413, "value_loss": 0.007297073056300481, "policy_loss": -0.013434421574111373, "dist_entropy": 0.6815270622571309, "actor_grad_norm": 0.11661004275083542, "critic_grad_norm": 0.020232075825333595, "ratio": 1.00089430809021, "entropy": 0.6815270622571309, "incre_win_rate": 0.9180327868852459, "step": 1428}
{"time": 1766592440.0780857, "phase": "train", "update": 1429, "total_env_steps": 4572800, "episode_reward": 0.36875995993614197, "value_loss": 0.008236570283770561, "policy_loss": -0.012019676027017567, "dist_entropy": 0.6605083147684733, "actor_grad_norm": 0.12940607964992523, "critic_grad_norm": 0.016355540603399277, "ratio": 1.000321388244629, "entropy": 0.6605083147684733, "incre_win_rate": 0.8983050847457628, "step": 1429}
{"time": 1766592444.7552621, "phase": "train", "update": 1430, "total_env_steps": 4576000, "episode_reward": 0.38550397753715515, "value_loss": 0.0031855125911533833, "policy_loss": -0.012634257033559493, "dist_entropy": 0.6481789708137512, "actor_grad_norm": 0.12460547685623169, "critic_grad_norm": 0.02739521861076355, "ratio": 0.997958242893219, "entropy": 0.6481789708137512, "incre_win_rate": 0.9682539682539683, "step": 1430}
{"time": 1766592449.4762616, "phase": "train", "update": 1431, "total_env_steps": 4579200, "episode_reward": 0.39549171924591064, "value_loss": 0.0020957892760634423, "policy_loss": -0.011681097385713693, "dist_entropy": 0.647540279229482, "actor_grad_norm": 0.1214001253247261, "critic_grad_norm": 0.024528460577130318, "ratio": 0.9995892643928528, "entropy": 0.647540279229482, "incre_win_rate": 0.9841269841269841, "step": 1431}
{"time": 1766592454.2094007, "phase": "train", "update": 1432, "total_env_steps": 4582400, "episode_reward": 0.3940027356147766, "value_loss": 0.004801020243515571, "policy_loss": -0.011091104835708165, "dist_entropy": 0.6402981122334798, "actor_grad_norm": 0.11007226258516312, "critic_grad_norm": 0.020568469539284706, "ratio": 1.000184416770935, "entropy": 0.6402981122334798, "incre_win_rate": 0.953125, "step": 1432}
{"time": 1766592459.03967, "phase": "train", "update": 1433, "total_env_steps": 4585600, "episode_reward": 0.38856157660484314, "value_loss": 0.006954647352298101, "policy_loss": -0.011177069093924293, "dist_entropy": 0.6445477684338887, "actor_grad_norm": 0.11333053559064865, "critic_grad_norm": 0.01779218576848507, "ratio": 1.000105381011963, "entropy": 0.6445477684338887, "incre_win_rate": 0.9365079365079365, "step": 1433}
{"time": 1766592463.7229805, "phase": "train", "update": 1434, "total_env_steps": 4588800, "episode_reward": 0.3982712924480438, "value_loss": 0.00531219265734156, "policy_loss": -0.010954430163910919, "dist_entropy": 0.6605482856432597, "actor_grad_norm": 0.11261159181594849, "critic_grad_norm": 0.011548810638487339, "ratio": 0.99891197681427, "entropy": 0.6605482856432597, "incre_win_rate": 0.9692307692307692, "step": 1434}
{"time": 1766592468.4543178, "phase": "train", "update": 1435, "total_env_steps": 4592000, "episode_reward": 0.3885401487350464, "value_loss": 0.005525930256893238, "policy_loss": -0.011375614587111886, "dist_entropy": 0.6483487844467163, "actor_grad_norm": 0.11764486134052277, "critic_grad_norm": 0.01665940135717392, "ratio": 1.0006824731826782, "entropy": 0.6483487844467163, "incre_win_rate": 0.9375, "step": 1435}
{"time": 1766592473.099975, "phase": "train", "update": 1436, "total_env_steps": 4595200, "episode_reward": 0.3881472051143646, "value_loss": 0.005206287465989589, "policy_loss": -0.012218978902985237, "dist_entropy": 0.6457681457201639, "actor_grad_norm": 0.11296337097883224, "critic_grad_norm": 0.027253201231360435, "ratio": 1.000190019607544, "entropy": 0.6457681457201639, "incre_win_rate": 0.9365079365079365, "step": 1436}
{"time": 1766592477.948654, "phase": "train", "update": 1437, "total_env_steps": 4598400, "episode_reward": 0.3702351748943329, "value_loss": 0.006112206137428681, "policy_loss": -0.013400866968458776, "dist_entropy": 0.648077114423116, "actor_grad_norm": 0.13111740350723267, "critic_grad_norm": 0.026176439598202705, "ratio": 0.9997455477714539, "entropy": 0.648077114423116, "incre_win_rate": 0.8852459016393442, "step": 1437}
{"time": 1766592482.8194027, "phase": "train", "update": 1438, "total_env_steps": 4601600, "episode_reward": 0.36010876297950745, "value_loss": 0.009597634834547838, "policy_loss": -0.013580801776553623, "dist_entropy": 0.6430666844050089, "actor_grad_norm": 0.1323959231376648, "critic_grad_norm": 0.026236576959490776, "ratio": 1.0015265941619873, "entropy": 0.6430666844050089, "incre_win_rate": 0.85, "step": 1438}
{"time": 1766592487.7020006, "phase": "train", "update": 1439, "total_env_steps": 4604800, "episode_reward": 0.3778645694255829, "value_loss": 0.007191310139993827, "policy_loss": -0.01305641884649352, "dist_entropy": 0.6571886698404948, "actor_grad_norm": 0.12610062956809998, "critic_grad_norm": 0.03189808502793312, "ratio": 1.0005773305892944, "entropy": 0.6571886698404948, "incre_win_rate": 0.8888888888888888, "step": 1439}
{"time": 1766592492.389872, "phase": "train", "update": 1440, "total_env_steps": 4608000, "episode_reward": 0.3644041121006012, "value_loss": 0.007343953102827072, "policy_loss": -0.013187075174136472, "dist_entropy": 0.6627524296442667, "actor_grad_norm": 0.12165560573339462, "critic_grad_norm": 0.020752200856804848, "ratio": 0.9986259937286377, "entropy": 0.6627524296442667, "incre_win_rate": 0.9016393442622951, "step": 1440}
{"time": 1766592497.1742811, "phase": "train", "update": 1441, "total_env_steps": 4611200, "episode_reward": 0.3595350980758667, "value_loss": 0.008695264781514804, "policy_loss": -0.013553522542417321, "dist_entropy": 0.6544372916221619, "actor_grad_norm": 0.12634295225143433, "critic_grad_norm": 0.018167801201343536, "ratio": 0.999433159828186, "entropy": 0.6544372916221619, "incre_win_rate": 0.8596491228070176, "step": 1441}
{"time": 1766592504.0687084, "phase": "eval", "update": 1441, "total_env_steps": 4611200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.761335784313726, "step": 1441}
{"time": 1766592508.747205, "phase": "train", "update": 1442, "total_env_steps": 4614400, "episode_reward": 0.36289215087890625, "value_loss": 0.008169255933413904, "policy_loss": -0.013708624806034624, "dist_entropy": 0.6538665453592937, "actor_grad_norm": 0.12111848592758179, "critic_grad_norm": 0.02268066257238388, "ratio": 1.0008217096328735, "entropy": 0.6538665453592937, "incre_win_rate": 0.8253968253968254, "step": 1442}
{"time": 1766592513.3810525, "phase": "train", "update": 1443, "total_env_steps": 4617600, "episode_reward": 0.37251532077789307, "value_loss": 0.006739825693269571, "policy_loss": -0.013065940743632255, "dist_entropy": 0.6987935105959574, "actor_grad_norm": 0.13172072172164917, "critic_grad_norm": 0.024196313694119453, "ratio": 0.9994260668754578, "entropy": 0.6987935105959574, "incre_win_rate": 0.8833333333333333, "step": 1443}
{"time": 1766592518.0731485, "phase": "train", "update": 1444, "total_env_steps": 4620800, "episode_reward": 0.3801179826259613, "value_loss": 0.00667241041858991, "policy_loss": -0.013274601552363189, "dist_entropy": 0.6755436698595683, "actor_grad_norm": 0.11717189103364944, "critic_grad_norm": 0.02303357422351837, "ratio": 1.0004826784133911, "entropy": 0.6755436698595683, "incre_win_rate": 0.9523809523809523, "step": 1444}
{"time": 1766592522.7730982, "phase": "train", "update": 1445, "total_env_steps": 4624000, "episode_reward": 0.37974342703819275, "value_loss": 0.0052084576338529585, "policy_loss": -0.013133778659750324, "dist_entropy": 0.6923490722974142, "actor_grad_norm": 0.12096334993839264, "critic_grad_norm": 0.013966374099254608, "ratio": 1.000131607055664, "entropy": 0.6923490722974142, "incre_win_rate": 0.9508196721311475, "step": 1445}
{"time": 1766592527.361457, "phase": "train", "update": 1446, "total_env_steps": 4627200, "episode_reward": 0.36694395542144775, "value_loss": 0.009764826732377212, "policy_loss": -0.012635261088991474, "dist_entropy": 0.6751790563265483, "actor_grad_norm": 0.13289669156074524, "critic_grad_norm": 0.05243527889251709, "ratio": 1.0002351999282837, "entropy": 0.6751790563265483, "incre_win_rate": 0.8709677419354839, "step": 1446}
{"time": 1766592532.042651, "phase": "train", "update": 1447, "total_env_steps": 4630400, "episode_reward": 0.3696584105491638, "value_loss": 0.01005496686945359, "policy_loss": -0.013996507044521659, "dist_entropy": 0.6898288051287333, "actor_grad_norm": 0.1323825716972351, "critic_grad_norm": 0.026851428672671318, "ratio": 0.9992030262947083, "entropy": 0.6898288051287333, "incre_win_rate": 0.8524590163934426, "step": 1447}
{"time": 1766592536.9749072, "phase": "train", "update": 1448, "total_env_steps": 4633600, "episode_reward": 0.3727857172489166, "value_loss": 0.007509893706689278, "policy_loss": -0.014283862398126719, "dist_entropy": 0.6785491665204366, "actor_grad_norm": 0.12035850435495377, "critic_grad_norm": 0.008294212631881237, "ratio": 0.9994344711303711, "entropy": 0.6785491665204366, "incre_win_rate": 0.9032258064516129, "step": 1448}
{"time": 1766592541.9584305, "phase": "train", "update": 1449, "total_env_steps": 4636800, "episode_reward": 0.3812476694583893, "value_loss": 0.00537797346090277, "policy_loss": -0.012920836125654015, "dist_entropy": 0.6821084300676982, "actor_grad_norm": 0.12004589289426804, "critic_grad_norm": 0.03513798117637634, "ratio": 0.9996315240859985, "entropy": 0.6821084300676982, "incre_win_rate": 0.873015873015873, "step": 1449}
{"time": 1766592546.6660964, "phase": "train", "update": 1450, "total_env_steps": 4640000, "episode_reward": 0.37290212512016296, "value_loss": 0.007571742435296376, "policy_loss": -0.0126391524312312, "dist_entropy": 0.7006902058919271, "actor_grad_norm": 0.1363724172115326, "critic_grad_norm": 0.017105696722865105, "ratio": 0.9994593858718872, "entropy": 0.7006902058919271, "incre_win_rate": 0.8709677419354839, "step": 1450}
{"time": 1766592551.5722055, "phase": "train", "update": 1451, "total_env_steps": 4643200, "episode_reward": 0.38181450963020325, "value_loss": 0.005794339099278053, "policy_loss": -0.012970691788990744, "dist_entropy": 0.7058106541633606, "actor_grad_norm": 0.10890891402959824, "critic_grad_norm": 0.01572485640645027, "ratio": 0.9996750354766846, "entropy": 0.7058106541633606, "incre_win_rate": 0.9180327868852459, "step": 1451}
{"time": 1766592556.3715353, "phase": "train", "update": 1452, "total_env_steps": 4646400, "episode_reward": 0.3694477677345276, "value_loss": 0.012003213229278723, "policy_loss": -0.012700258138115336, "dist_entropy": 0.7064939896265666, "actor_grad_norm": 0.1111750677227974, "critic_grad_norm": 0.04684644937515259, "ratio": 0.9999033212661743, "entropy": 0.7064939896265666, "incre_win_rate": 0.8524590163934426, "step": 1452}
{"time": 1766592561.1129127, "phase": "train", "update": 1453, "total_env_steps": 4649600, "episode_reward": 0.3864774703979492, "value_loss": 0.009963514407475789, "policy_loss": -0.011794586852568045, "dist_entropy": 0.7056333263715108, "actor_grad_norm": 0.12317350506782532, "critic_grad_norm": 0.0376669205725193, "ratio": 0.9996183514595032, "entropy": 0.7056333263715108, "incre_win_rate": 0.9523809523809523, "step": 1453}
{"time": 1766592565.8098161, "phase": "train", "update": 1454, "total_env_steps": 4652800, "episode_reward": 0.37645450234413147, "value_loss": 0.007546702492982149, "policy_loss": -0.01310963727879712, "dist_entropy": 0.6935764233271281, "actor_grad_norm": 0.12686190009117126, "critic_grad_norm": 0.03989103063941002, "ratio": 0.9997597336769104, "entropy": 0.6935764233271281, "incre_win_rate": 0.8923076923076924, "step": 1454}
{"time": 1766592570.5744603, "phase": "train", "update": 1455, "total_env_steps": 4656000, "episode_reward": 0.3779488503932953, "value_loss": 0.008200643770396709, "policy_loss": -0.011032184883918224, "dist_entropy": 0.7121505260467529, "actor_grad_norm": 0.1094188317656517, "critic_grad_norm": 0.022143617272377014, "ratio": 1.0012818574905396, "entropy": 0.7121505260467529, "incre_win_rate": 0.9166666666666666, "step": 1455}
{"time": 1766592575.2714849, "phase": "train", "update": 1456, "total_env_steps": 4659200, "episode_reward": 0.381567120552063, "value_loss": 0.007209146053840717, "policy_loss": -0.012239983110362356, "dist_entropy": 0.6939573645591736, "actor_grad_norm": 0.11356794834136963, "critic_grad_norm": 0.03408968076109886, "ratio": 0.9973082542419434, "entropy": 0.6939573645591736, "incre_win_rate": 0.9365079365079365, "step": 1456}
{"time": 1766592579.969857, "phase": "train", "update": 1457, "total_env_steps": 4662400, "episode_reward": 0.3912339210510254, "value_loss": 0.005014128424227238, "policy_loss": -0.012097096694619343, "dist_entropy": 0.7099234342575074, "actor_grad_norm": 0.10467538237571716, "critic_grad_norm": 0.03588321805000305, "ratio": 0.9997621774673462, "entropy": 0.7099234342575074, "incre_win_rate": 0.9365079365079365, "step": 1457}
{"time": 1766592584.6599903, "phase": "train", "update": 1458, "total_env_steps": 4665600, "episode_reward": 0.38251611590385437, "value_loss": 0.006716861731062332, "policy_loss": -0.012687359675956127, "dist_entropy": 0.7031810482343038, "actor_grad_norm": 0.1116543859243393, "critic_grad_norm": 0.028335263952612877, "ratio": 1.0004963874816895, "entropy": 0.7031810482343038, "incre_win_rate": 0.953125, "step": 1458}
{"time": 1766592589.3971138, "phase": "train", "update": 1459, "total_env_steps": 4668800, "episode_reward": 0.382016658782959, "value_loss": 0.004322386377801498, "policy_loss": -0.011752635519853645, "dist_entropy": 0.7134650111198425, "actor_grad_norm": 0.1141381785273552, "critic_grad_norm": 0.01160021498799324, "ratio": 0.99967360496521, "entropy": 0.7134650111198425, "incre_win_rate": 0.95, "step": 1459}
{"time": 1766592594.119216, "phase": "train", "update": 1460, "total_env_steps": 4672000, "episode_reward": 0.3689085841178894, "value_loss": 0.006403690204024315, "policy_loss": -0.012562108541514287, "dist_entropy": 0.7168982187906902, "actor_grad_norm": 0.11626029014587402, "critic_grad_norm": 0.024715198203921318, "ratio": 1.0019307136535645, "entropy": 0.7168982187906902, "incre_win_rate": 0.9180327868852459, "step": 1460}
{"time": 1766592598.8006377, "phase": "train", "update": 1461, "total_env_steps": 4675200, "episode_reward": 0.36496400833129883, "value_loss": 0.008662277894715468, "policy_loss": -0.013527056453890888, "dist_entropy": 0.7320445696512858, "actor_grad_norm": 0.12177857756614685, "critic_grad_norm": 0.03907781466841698, "ratio": 1.0003632307052612, "entropy": 0.7320445696512858, "incre_win_rate": 0.9, "step": 1461}
{"time": 1766592605.8840718, "phase": "eval", "update": 1461, "total_env_steps": 4675200, "eval_win_rate": 1.0, "eval_episode_reward": 20.012254901960784, "step": 1461}
{"time": 1766592610.735976, "phase": "train", "update": 1462, "total_env_steps": 4678400, "episode_reward": 0.36961475014686584, "value_loss": 0.007636024337261915, "policy_loss": -0.01289447062154257, "dist_entropy": 0.698169223467509, "actor_grad_norm": 0.134188711643219, "critic_grad_norm": 0.023479029536247253, "ratio": 1.0003538131713867, "entropy": 0.698169223467509, "incre_win_rate": 0.8688524590163934, "step": 1462}
{"time": 1766592615.4695587, "phase": "train", "update": 1463, "total_env_steps": 4681600, "episode_reward": 0.3702634871006012, "value_loss": 0.008207940155019362, "policy_loss": -0.014368920556693846, "dist_entropy": 0.7221591432889303, "actor_grad_norm": 0.126621276140213, "critic_grad_norm": 0.025029661133885384, "ratio": 0.9992214441299438, "entropy": 0.7221591432889303, "incre_win_rate": 0.9166666666666666, "step": 1463}
{"time": 1766592620.2468917, "phase": "train", "update": 1464, "total_env_steps": 4684800, "episode_reward": 0.37064260244369507, "value_loss": 0.0068054515247543655, "policy_loss": -0.01338387503068077, "dist_entropy": 0.6976543307304383, "actor_grad_norm": 0.11822494119405746, "critic_grad_norm": 0.03006765991449356, "ratio": 0.9988024234771729, "entropy": 0.6976543307304383, "incre_win_rate": 0.873015873015873, "step": 1464}
{"time": 1766592624.9233763, "phase": "train", "update": 1465, "total_env_steps": 4688000, "episode_reward": 0.36363205313682556, "value_loss": 0.009129072912037373, "policy_loss": -0.014299972425021679, "dist_entropy": 0.7001867055892944, "actor_grad_norm": 0.12177453935146332, "critic_grad_norm": 0.016849922016263008, "ratio": 1.0001091957092285, "entropy": 0.7001867055892944, "incre_win_rate": 0.8833333333333333, "step": 1465}
{"time": 1766592629.7074456, "phase": "train", "update": 1466, "total_env_steps": 4691200, "episode_reward": 0.36079809069633484, "value_loss": 0.01143948572377364, "policy_loss": -0.014617947569969184, "dist_entropy": 0.7057978669802348, "actor_grad_norm": 0.1327676922082901, "critic_grad_norm": 0.027365034446120262, "ratio": 0.9996614456176758, "entropy": 0.7057978669802348, "incre_win_rate": 0.8524590163934426, "step": 1466}
{"time": 1766592634.5171292, "phase": "train", "update": 1467, "total_env_steps": 4694400, "episode_reward": 0.36979934573173523, "value_loss": 0.010294790007174015, "policy_loss": -0.013181712651549068, "dist_entropy": 0.6858856081962585, "actor_grad_norm": 0.11973956972360611, "critic_grad_norm": 0.019564133137464523, "ratio": 0.9986918568611145, "entropy": 0.6858856081962585, "incre_win_rate": 0.8666666666666667, "step": 1467}
{"time": 1766592664.8782182, "phase": "train", "update": 1468, "total_env_steps": 4697600, "episode_reward": 0.3511374294757843, "value_loss": 0.06386724263429641, "policy_loss": -0.011316426366013843, "dist_entropy": 0.688392186164856, "actor_grad_norm": 0.12199512869119644, "critic_grad_norm": 0.1588004231452942, "ratio": 1.0008578300476074, "entropy": 0.688392186164856, "incre_win_rate": 0.8214285714285714, "step": 1468}
{"time": 1766592669.5312846, "phase": "train", "update": 1469, "total_env_steps": 4700800, "episode_reward": 0.3684045374393463, "value_loss": 0.008838183525949717, "policy_loss": -0.013357610060529624, "dist_entropy": 0.6900137344996135, "actor_grad_norm": 0.12833671271800995, "critic_grad_norm": 0.10635180026292801, "ratio": 1.001575231552124, "entropy": 0.6900137344996135, "incre_win_rate": 0.9047619047619048, "step": 1469}
{"time": 1766592674.2659395, "phase": "train", "update": 1470, "total_env_steps": 4704000, "episode_reward": 0.37255823612213135, "value_loss": 0.010225124284625053, "policy_loss": -0.012488823470349075, "dist_entropy": 0.6982156912485759, "actor_grad_norm": 0.12328451871871948, "critic_grad_norm": 0.06921636313199997, "ratio": 1.0014064311981201, "entropy": 0.6982156912485759, "incre_win_rate": 0.9016393442622951, "step": 1470}
{"time": 1766592678.916558, "phase": "train", "update": 1471, "total_env_steps": 4707200, "episode_reward": 0.3684605062007904, "value_loss": 0.008238550523916881, "policy_loss": -0.014045756913962275, "dist_entropy": 0.7029690702756246, "actor_grad_norm": 0.13574804365634918, "critic_grad_norm": 0.06551921367645264, "ratio": 0.9976224303245544, "entropy": 0.7029690702756246, "incre_win_rate": 0.8833333333333333, "step": 1471}
{"time": 1766592683.582377, "phase": "train", "update": 1472, "total_env_steps": 4710400, "episode_reward": 0.3685210049152374, "value_loss": 0.008985357545316219, "policy_loss": -0.013193159442985328, "dist_entropy": 0.7126440604527792, "actor_grad_norm": 0.11665793508291245, "critic_grad_norm": 0.03349808230996132, "ratio": 1.0001240968704224, "entropy": 0.7126440604527792, "incre_win_rate": 0.9032258064516129, "step": 1472}
{"time": 1766592688.2266104, "phase": "train", "update": 1473, "total_env_steps": 4713600, "episode_reward": 0.3584589660167694, "value_loss": 0.006242212746292353, "policy_loss": -0.01396457885918115, "dist_entropy": 0.7219562451044719, "actor_grad_norm": 0.12288163602352142, "critic_grad_norm": 0.025013362988829613, "ratio": 0.9997752904891968, "entropy": 0.7219562451044719, "incre_win_rate": 0.896551724137931, "step": 1473}
{"time": 1766592692.9564364, "phase": "train", "update": 1474, "total_env_steps": 4716800, "episode_reward": 0.37283703684806824, "value_loss": 0.005261842782298724, "policy_loss": -0.013306817209468136, "dist_entropy": 0.7080029447873434, "actor_grad_norm": 0.1203986331820488, "critic_grad_norm": 0.019839128479361534, "ratio": 0.9992456436157227, "entropy": 0.7080029447873434, "incre_win_rate": 0.9833333333333333, "step": 1474}
{"time": 1766592697.6000018, "phase": "train", "update": 1475, "total_env_steps": 4720000, "episode_reward": 0.36856696009635925, "value_loss": 0.005324762811263402, "policy_loss": -0.014263436781532354, "dist_entropy": 0.7244924187660218, "actor_grad_norm": 0.1273348331451416, "critic_grad_norm": 0.01665552519261837, "ratio": 1.0001436471939087, "entropy": 0.7244924187660218, "incre_win_rate": 0.9344262295081968, "step": 1475}
{"time": 1766592702.301017, "phase": "train", "update": 1476, "total_env_steps": 4723200, "episode_reward": 0.37647825479507446, "value_loss": 0.00657459016268452, "policy_loss": -0.013788769246738752, "dist_entropy": 0.7086376468340556, "actor_grad_norm": 0.11979351192712784, "critic_grad_norm": 0.010782495141029358, "ratio": 1.0003100633621216, "entropy": 0.7086376468340556, "incre_win_rate": 0.9344262295081968, "step": 1476}
{"time": 1766592707.0240726, "phase": "train", "update": 1477, "total_env_steps": 4726400, "episode_reward": 0.37404564023017883, "value_loss": 0.005135158076882362, "policy_loss": -0.013965027853632487, "dist_entropy": 0.7074030796686809, "actor_grad_norm": 0.12464263290166855, "critic_grad_norm": 0.024731425568461418, "ratio": 0.9992479681968689, "entropy": 0.7074030796686809, "incre_win_rate": 0.9180327868852459, "step": 1477}
{"time": 1766592711.7317033, "phase": "train", "update": 1478, "total_env_steps": 4729600, "episode_reward": 0.3802412748336792, "value_loss": 0.005680469796061516, "policy_loss": -0.014220613779478223, "dist_entropy": 0.7022712985674541, "actor_grad_norm": 0.13200098276138306, "critic_grad_norm": 0.014272716827690601, "ratio": 0.9990419149398804, "entropy": 0.7022712985674541, "incre_win_rate": 0.9508196721311475, "step": 1478}
{"time": 1766592716.4194326, "phase": "train", "update": 1479, "total_env_steps": 4732800, "episode_reward": 0.3752320408821106, "value_loss": 0.007313415966928005, "policy_loss": -0.012659795778210754, "dist_entropy": 0.7021037141482035, "actor_grad_norm": 0.12604829668998718, "critic_grad_norm": 0.012316220439970493, "ratio": 1.0014947652816772, "entropy": 0.7021037141482035, "incre_win_rate": 0.9333333333333333, "step": 1479}
{"time": 1766592721.1353362, "phase": "train", "update": 1480, "total_env_steps": 4736000, "episode_reward": 0.373919278383255, "value_loss": 0.005849253696699937, "policy_loss": -0.01359496892166021, "dist_entropy": 0.7037268201510112, "actor_grad_norm": 0.14737096428871155, "critic_grad_norm": 0.010632929392158985, "ratio": 0.999926745891571, "entropy": 0.7037268201510112, "incre_win_rate": 0.9206349206349206, "step": 1480}
{"time": 1766592725.9011016, "phase": "train", "update": 1481, "total_env_steps": 4739200, "episode_reward": 0.3563380837440491, "value_loss": 0.0078002749321361385, "policy_loss": -0.013705905917071704, "dist_entropy": 0.7163300236066182, "actor_grad_norm": 0.12136512994766235, "critic_grad_norm": 0.020666316151618958, "ratio": 1.0003963708877563, "entropy": 0.7163300236066182, "incre_win_rate": 0.9473684210526315, "step": 1481}
{"time": 1766592732.8130503, "phase": "eval", "update": 1481, "total_env_steps": 4739200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.79610906862745, "step": 1481}
{"time": 1766592737.451694, "phase": "train", "update": 1482, "total_env_steps": 4742400, "episode_reward": 0.36371782422065735, "value_loss": 0.008635898338009913, "policy_loss": -0.013430422188429011, "dist_entropy": 0.6944695393244426, "actor_grad_norm": 0.12060120701789856, "critic_grad_norm": 0.043354082852602005, "ratio": 1.0000455379486084, "entropy": 0.6944695393244426, "incre_win_rate": 0.9016393442622951, "step": 1482}
{"time": 1766592742.1353328, "phase": "train", "update": 1483, "total_env_steps": 4745600, "episode_reward": 0.3694332242012024, "value_loss": 0.006359031361838182, "policy_loss": -0.01257793087739761, "dist_entropy": 0.6830080429712931, "actor_grad_norm": 0.12685754895210266, "critic_grad_norm": 0.009456231258809566, "ratio": 1.0000720024108887, "entropy": 0.6830080429712931, "incre_win_rate": 0.9016393442622951, "step": 1483}
{"time": 1766592747.0039895, "phase": "train", "update": 1484, "total_env_steps": 4748800, "episode_reward": 0.3774954080581665, "value_loss": 0.0050904012906054655, "policy_loss": -0.013467488857519546, "dist_entropy": 0.693765926361084, "actor_grad_norm": 0.13288214802742004, "critic_grad_norm": 0.019735345616936684, "ratio": 0.9991512894630432, "entropy": 0.693765926361084, "incre_win_rate": 0.9672131147540983, "step": 1484}
{"time": 1766592751.6566133, "phase": "train", "update": 1485, "total_env_steps": 4752000, "episode_reward": 0.3658486604690552, "value_loss": 0.004292443844800194, "policy_loss": -0.013460265779128674, "dist_entropy": 0.6863167444864909, "actor_grad_norm": 0.10937898606061935, "critic_grad_norm": 0.013024633750319481, "ratio": 0.9993505477905273, "entropy": 0.6863167444864909, "incre_win_rate": 0.9322033898305084, "step": 1485}
{"time": 1766592756.407662, "phase": "train", "update": 1486, "total_env_steps": 4755200, "episode_reward": 0.38629287481307983, "value_loss": 0.0034069197562833628, "policy_loss": -0.012896535453876841, "dist_entropy": 0.6826472997665405, "actor_grad_norm": 0.13083869218826294, "critic_grad_norm": 0.009378688409924507, "ratio": 0.9995938539505005, "entropy": 0.6826472997665405, "incre_win_rate": 0.9682539682539683, "step": 1486}
{"time": 1766592761.1451302, "phase": "train", "update": 1487, "total_env_steps": 4758400, "episode_reward": 0.37589922547340393, "value_loss": 0.00678724953904748, "policy_loss": -0.012224752409003987, "dist_entropy": 0.6822154839833577, "actor_grad_norm": 0.10864289849996567, "critic_grad_norm": 0.018470313400030136, "ratio": 1.001174807548523, "entropy": 0.6822154839833577, "incre_win_rate": 0.9354838709677419, "step": 1487}
{"time": 1766592765.8811753, "phase": "train", "update": 1488, "total_env_steps": 4761600, "episode_reward": 0.3797472417354584, "value_loss": 0.005127847070495287, "policy_loss": -0.012810737925103883, "dist_entropy": 0.6872707168261211, "actor_grad_norm": 0.1131790429353714, "critic_grad_norm": 0.011499851010739803, "ratio": 1.000936508178711, "entropy": 0.6872707168261211, "incre_win_rate": 0.9655172413793104, "step": 1488}
{"time": 1766592770.6223803, "phase": "train", "update": 1489, "total_env_steps": 4764800, "episode_reward": 0.3884635269641876, "value_loss": 0.0023415811515102784, "policy_loss": -0.012943439655456471, "dist_entropy": 0.6837501525878906, "actor_grad_norm": 0.12083320319652557, "critic_grad_norm": 0.015356125310063362, "ratio": 0.9995102286338806, "entropy": 0.6837501525878906, "incre_win_rate": 1.0, "step": 1489}
{"time": 1766592775.3647544, "phase": "train", "update": 1490, "total_env_steps": 4768000, "episode_reward": 0.37932518124580383, "value_loss": 0.004873590326557557, "policy_loss": -0.013395215618305655, "dist_entropy": 0.6864180445671082, "actor_grad_norm": 0.11613082140684128, "critic_grad_norm": 0.012176260352134705, "ratio": 0.9993568658828735, "entropy": 0.6864180445671082, "incre_win_rate": 0.9508196721311475, "step": 1490}
{"time": 1766592780.0729897, "phase": "train", "update": 1491, "total_env_steps": 4771200, "episode_reward": 0.3804572820663452, "value_loss": 0.0051902899208168185, "policy_loss": -0.012980569250945944, "dist_entropy": 0.6761380712191264, "actor_grad_norm": 0.1205459013581276, "critic_grad_norm": 0.024813901633024216, "ratio": 1.0005450248718262, "entropy": 0.6761380712191264, "incre_win_rate": 0.9047619047619048, "step": 1491}
{"time": 1766592784.801593, "phase": "train", "update": 1492, "total_env_steps": 4774400, "episode_reward": 0.37720972299575806, "value_loss": 0.0057014046547313535, "policy_loss": -0.012498587204709111, "dist_entropy": 0.6559588313102722, "actor_grad_norm": 0.11341731995344162, "critic_grad_norm": 0.03234141319990158, "ratio": 1.000389575958252, "entropy": 0.6559588313102722, "incre_win_rate": 0.9016393442622951, "step": 1492}
{"time": 1766592789.539639, "phase": "train", "update": 1493, "total_env_steps": 4777600, "episode_reward": 0.39124083518981934, "value_loss": 0.0028928569207588833, "policy_loss": -0.011920985735476583, "dist_entropy": 0.658314836025238, "actor_grad_norm": 0.11928800493478775, "critic_grad_norm": 0.014412506483495235, "ratio": 0.9992511868476868, "entropy": 0.658314836025238, "incre_win_rate": 0.9682539682539683, "step": 1493}
{"time": 1766592794.2362266, "phase": "train", "update": 1494, "total_env_steps": 4780800, "episode_reward": 0.39104777574539185, "value_loss": 0.003937486869593461, "policy_loss": -0.011909121324382236, "dist_entropy": 0.6608971039454142, "actor_grad_norm": 0.1163584515452385, "critic_grad_norm": 0.014676770195364952, "ratio": 1.000133752822876, "entropy": 0.6608971039454142, "incre_win_rate": 0.9682539682539683, "step": 1494}
{"time": 1766592799.092689, "phase": "train", "update": 1495, "total_env_steps": 4784000, "episode_reward": 0.3804633915424347, "value_loss": 0.004952404585977396, "policy_loss": -0.012800268796092477, "dist_entropy": 0.6708518902460734, "actor_grad_norm": 0.12805317342281342, "critic_grad_norm": 0.008232309482991695, "ratio": 1.0005184412002563, "entropy": 0.6708518902460734, "incre_win_rate": 0.9516129032258065, "step": 1495}
{"time": 1766592803.8812811, "phase": "train", "update": 1496, "total_env_steps": 4787200, "episode_reward": 0.3912339210510254, "value_loss": 0.0040323516974846525, "policy_loss": -0.01244558312503538, "dist_entropy": 0.6830374876658122, "actor_grad_norm": 0.12366670370101929, "critic_grad_norm": 0.021947864443063736, "ratio": 0.9986423254013062, "entropy": 0.6830374876658122, "incre_win_rate": 0.984375, "step": 1496}
{"time": 1766592808.6175401, "phase": "train", "update": 1497, "total_env_steps": 4790400, "episode_reward": 0.36726945638656616, "value_loss": 0.0059216430721183615, "policy_loss": -0.012358026055659603, "dist_entropy": 0.6714787681897482, "actor_grad_norm": 0.11558825522661209, "critic_grad_norm": 0.03229760378599167, "ratio": 0.9998779892921448, "entropy": 0.6714787681897482, "incre_win_rate": 0.9166666666666666, "step": 1497}
{"time": 1766592813.3733563, "phase": "train", "update": 1498, "total_env_steps": 4793600, "episode_reward": 0.38750383257865906, "value_loss": 0.006735955271869898, "policy_loss": -0.011249653106057212, "dist_entropy": 0.6503890077273051, "actor_grad_norm": 0.10499866306781769, "critic_grad_norm": 0.01011047326028347, "ratio": 0.9989892244338989, "entropy": 0.6503890077273051, "incre_win_rate": 0.9682539682539683, "step": 1498}
{"time": 1766592818.1406503, "phase": "train", "update": 1499, "total_env_steps": 4796800, "episode_reward": 0.3826769292354584, "value_loss": 0.005562350402275721, "policy_loss": -0.011957989714691546, "dist_entropy": 0.6753562569618226, "actor_grad_norm": 0.10636898875236511, "critic_grad_norm": 0.018718818202614784, "ratio": 0.9997482895851135, "entropy": 0.6753562569618226, "incre_win_rate": 0.9206349206349206, "step": 1499}
{"time": 1766592822.8078008, "phase": "train", "update": 1500, "total_env_steps": 4800000, "episode_reward": 0.3859260380268097, "value_loss": 0.004023818547526995, "policy_loss": -0.012012385909438686, "dist_entropy": 0.6839059591293335, "actor_grad_norm": 0.11381928622722626, "critic_grad_norm": 0.02743031457066536, "ratio": 0.9988867044448853, "entropy": 0.6839059591293335, "incre_win_rate": 0.967741935483871, "step": 1500}
