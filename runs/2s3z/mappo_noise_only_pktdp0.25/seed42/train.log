{"time": 1766662770.7517111, "phase": "train", "update": 1, "total_env_steps": 3200, "episode_reward": 0.07505974918603897, "value_loss": 0.8858232021331787, "policy_loss": -0.00685955881860707, "dist_entropy": 1.8908376932144164, "actor_grad_norm": 0.10468026995658875, "critic_grad_norm": 1.5080517530441284, "ratio": 1.0001039505004883, "entropy": 1.8908376932144164, "incre_win_rate": 0.0, "step": 1}
{"time": 1766662787.5397115, "phase": "eval", "update": 1, "total_env_steps": 3200, "eval_win_rate": 0.0, "eval_episode_reward": 5.759727328431369, "step": 1}
{"time": 1766662791.8099115, "phase": "train", "update": 2, "total_env_steps": 6400, "episode_reward": 0.08940870314836502, "value_loss": 0.8070005257924397, "policy_loss": -0.00557106866499737, "dist_entropy": 1.9170722881952922, "actor_grad_norm": 0.11877642571926117, "critic_grad_norm": 2.067286252975464, "ratio": 1.000423550605774, "entropy": 1.9170722881952922, "incre_win_rate": 0.0, "step": 2}
{"time": 1766662796.1240456, "phase": "train", "update": 3, "total_env_steps": 9600, "episode_reward": 0.10381586849689484, "value_loss": 0.4055900325377782, "policy_loss": -0.006666300620389383, "dist_entropy": 1.9296205361684164, "actor_grad_norm": 0.14441509544849396, "critic_grad_norm": 1.848206639289856, "ratio": 0.9997491240501404, "entropy": 1.9296205361684164, "incre_win_rate": 0.0, "step": 3}
{"time": 1766662800.6166103, "phase": "train", "update": 4, "total_env_steps": 12800, "episode_reward": 0.11549556255340576, "value_loss": 0.18785670896371207, "policy_loss": -0.005073318826163605, "dist_entropy": 1.9308617830276489, "actor_grad_norm": 0.1167551726102829, "critic_grad_norm": 1.2991101741790771, "ratio": 0.9992436170578003, "entropy": 1.9308617830276489, "incre_win_rate": 0.0, "step": 4}
{"time": 1766662804.9130766, "phase": "train", "update": 5, "total_env_steps": 16000, "episode_reward": 0.1291321963071823, "value_loss": 0.14763097961743674, "policy_loss": -0.004399208264804126, "dist_entropy": 1.95124241511027, "actor_grad_norm": 0.09215059876441956, "critic_grad_norm": 1.0245205163955688, "ratio": 1.0001864433288574, "entropy": 1.95124241511027, "incre_win_rate": 0.0, "step": 5}
{"time": 1766662809.3853533, "phase": "train", "update": 6, "total_env_steps": 19200, "episode_reward": 0.14739122986793518, "value_loss": 0.10071867406368255, "policy_loss": -0.005414418266299492, "dist_entropy": 1.9417908430099486, "actor_grad_norm": 0.09773141145706177, "critic_grad_norm": 0.79544597864151, "ratio": 1.0004032850265503, "entropy": 1.9417908430099486, "incre_win_rate": 0.0, "step": 6}
{"time": 1766662813.7549694, "phase": "train", "update": 7, "total_env_steps": 22400, "episode_reward": 0.15083181858062744, "value_loss": 0.08299231429894766, "policy_loss": -0.00595634568312479, "dist_entropy": 1.9168935298919678, "actor_grad_norm": 0.12779667973518372, "critic_grad_norm": 0.5955430269241333, "ratio": 1.0008221864700317, "entropy": 1.9168935298919678, "incre_win_rate": 0.0, "step": 7}
{"time": 1766662818.1627653, "phase": "train", "update": 8, "total_env_steps": 25600, "episode_reward": 0.142581969499588, "value_loss": 0.07453797807296117, "policy_loss": -0.0052403132751768075, "dist_entropy": 1.8880260308583579, "actor_grad_norm": 0.08881008625030518, "critic_grad_norm": 0.4586254358291626, "ratio": 0.9991083741188049, "entropy": 1.8880260308583579, "incre_win_rate": 0.0, "step": 8}
{"time": 1766662822.5360203, "phase": "train", "update": 9, "total_env_steps": 28800, "episode_reward": 0.15078814327716827, "value_loss": 0.06993047545353571, "policy_loss": -0.005511389734679284, "dist_entropy": 1.8693411827087403, "actor_grad_norm": 0.08118398487567902, "critic_grad_norm": 0.29797592759132385, "ratio": 0.999709963798523, "entropy": 1.8693411827087403, "incre_win_rate": 0.0, "step": 9}
{"time": 1766662826.8584611, "phase": "train", "update": 10, "total_env_steps": 32000, "episode_reward": 0.15306909382343292, "value_loss": 0.07244648784399033, "policy_loss": -0.006210805831858342, "dist_entropy": 1.8316474517186483, "actor_grad_norm": 0.10498500615358353, "critic_grad_norm": 0.3520648181438446, "ratio": 0.9996135234832764, "entropy": 1.8316474517186483, "incre_win_rate": 0.0, "step": 10}
{"time": 1766662831.270357, "phase": "train", "update": 11, "total_env_steps": 35200, "episode_reward": 0.1650574505329132, "value_loss": 0.055685837070147196, "policy_loss": -0.005970208195570829, "dist_entropy": 1.8216004769007366, "actor_grad_norm": 0.09021802246570587, "critic_grad_norm": 0.19441469013690948, "ratio": 1.0001552104949951, "entropy": 1.8216004769007366, "incre_win_rate": 0.0, "step": 11}
{"time": 1766662835.568471, "phase": "train", "update": 12, "total_env_steps": 38400, "episode_reward": 0.1543489694595337, "value_loss": 0.05698744306961696, "policy_loss": -0.006491052109844934, "dist_entropy": 1.789943846066793, "actor_grad_norm": 0.09689324349164963, "critic_grad_norm": 0.20688126981258392, "ratio": 0.9996321797370911, "entropy": 1.789943846066793, "incre_win_rate": 0.0, "step": 12}
{"time": 1766662840.060756, "phase": "train", "update": 13, "total_env_steps": 41600, "episode_reward": 0.1835278868675232, "value_loss": 0.056583084911108014, "policy_loss": -0.0061064722345965565, "dist_entropy": 1.7775997718175252, "actor_grad_norm": 0.09135561436414719, "critic_grad_norm": 0.27349168062210083, "ratio": 1.0005825757980347, "entropy": 1.7775997718175252, "incre_win_rate": 0.0, "step": 13}
{"time": 1766662844.52316, "phase": "train", "update": 14, "total_env_steps": 44800, "episode_reward": 0.1878301203250885, "value_loss": 0.04484208176533381, "policy_loss": -0.006846622628697337, "dist_entropy": 1.7622244675954184, "actor_grad_norm": 0.10235624760389328, "critic_grad_norm": 0.166652113199234, "ratio": 0.9996376037597656, "entropy": 1.7622244675954184, "incre_win_rate": 0.0, "step": 14}
{"time": 1766662848.867343, "phase": "train", "update": 15, "total_env_steps": 48000, "episode_reward": 0.18702511489391327, "value_loss": 0.04379469454288483, "policy_loss": -0.006018856600017841, "dist_entropy": 1.7004085381825764, "actor_grad_norm": 0.09331493824720383, "critic_grad_norm": 0.09634419530630112, "ratio": 1.000308871269226, "entropy": 1.7004085381825764, "incre_win_rate": 0.0, "step": 15}
{"time": 1766662853.2822492, "phase": "train", "update": 16, "total_env_steps": 51200, "episode_reward": 0.1928592324256897, "value_loss": 0.04333511913816134, "policy_loss": -0.005974060403576094, "dist_entropy": 1.6801234404246013, "actor_grad_norm": 0.09929072856903076, "critic_grad_norm": 0.09755709022283554, "ratio": 0.9986567497253418, "entropy": 1.6801234404246013, "incre_win_rate": 0.0, "step": 16}
{"time": 1766662857.7327032, "phase": "train", "update": 17, "total_env_steps": 54400, "episode_reward": 0.2009872943162918, "value_loss": 0.04405548125505447, "policy_loss": -0.006229578020525898, "dist_entropy": 1.6078808069229127, "actor_grad_norm": 0.07782481610774994, "critic_grad_norm": 0.059758275747299194, "ratio": 0.99995356798172, "entropy": 1.6078808069229127, "incre_win_rate": 0.0, "step": 17}
{"time": 1766662862.1045566, "phase": "train", "update": 18, "total_env_steps": 57600, "episode_reward": 0.19369791448116302, "value_loss": 0.04508571525414785, "policy_loss": -0.006608483927932577, "dist_entropy": 1.5644566774368287, "actor_grad_norm": 0.09098880738019943, "critic_grad_norm": 0.11368884146213531, "ratio": 0.9994977712631226, "entropy": 1.5644566774368287, "incre_win_rate": 0.0, "step": 18}
{"time": 1766662866.4653344, "phase": "train", "update": 19, "total_env_steps": 60800, "episode_reward": 0.19924938678741455, "value_loss": 0.04146140490969022, "policy_loss": -0.006316811446883245, "dist_entropy": 1.5178311586380004, "actor_grad_norm": 0.07452793419361115, "critic_grad_norm": 0.12362172454595566, "ratio": 1.0006322860717773, "entropy": 1.5178311586380004, "incre_win_rate": 0.0, "step": 19}
{"time": 1766662870.858229, "phase": "train", "update": 20, "total_env_steps": 64000, "episode_reward": 0.21061429381370544, "value_loss": 0.03886241987347603, "policy_loss": -0.00805653784265606, "dist_entropy": 1.4861282428105673, "actor_grad_norm": 0.13166013360023499, "critic_grad_norm": 0.1092735230922699, "ratio": 0.9993640184402466, "entropy": 1.4861282428105673, "incre_win_rate": 0.0, "step": 20}
{"time": 1766662875.2096822, "phase": "train", "update": 21, "total_env_steps": 67200, "episode_reward": 0.22413833439350128, "value_loss": 0.0321418405820926, "policy_loss": -0.006984181821859655, "dist_entropy": 1.465788221359253, "actor_grad_norm": 0.08342166244983673, "critic_grad_norm": 0.07187266647815704, "ratio": 0.999835193157196, "entropy": 1.465788221359253, "incre_win_rate": 0.0, "step": 21}
{"time": 1766662882.3253155, "phase": "eval", "update": 21, "total_env_steps": 67200, "eval_win_rate": 0.0625, "eval_episode_reward": 12.71063112745098, "step": 21}
{"time": 1766662886.648693, "phase": "train", "update": 22, "total_env_steps": 70400, "episode_reward": 0.22290058434009552, "value_loss": 0.032778167227904005, "policy_loss": -0.007712450368766592, "dist_entropy": 1.40544597307841, "actor_grad_norm": 0.10756594687700272, "critic_grad_norm": 0.11985529214143753, "ratio": 1.0000189542770386, "entropy": 1.40544597307841, "incre_win_rate": 0.0, "step": 22}
{"time": 1766662891.0251093, "phase": "train", "update": 23, "total_env_steps": 73600, "episode_reward": 0.22007201611995697, "value_loss": 0.03426448255777359, "policy_loss": -0.00872851110248547, "dist_entropy": 1.372064224878947, "actor_grad_norm": 0.12710224092006683, "critic_grad_norm": 0.1079377681016922, "ratio": 1.00077486038208, "entropy": 1.372064224878947, "incre_win_rate": 0.0, "step": 23}
{"time": 1766662895.393318, "phase": "train", "update": 24, "total_env_steps": 76800, "episode_reward": 0.22472809255123138, "value_loss": 0.03519467338919639, "policy_loss": -0.009120389799658568, "dist_entropy": 1.3334005991617839, "actor_grad_norm": 0.10349615663290024, "critic_grad_norm": 0.10444314032793045, "ratio": 1.00022292137146, "entropy": 1.3334005991617839, "incre_win_rate": 0.0, "step": 24}
{"time": 1766662899.7269392, "phase": "train", "update": 25, "total_env_steps": 80000, "episode_reward": 0.2308417707681656, "value_loss": 0.030173075571656226, "policy_loss": -0.0074933806996919355, "dist_entropy": 1.3168575525283814, "actor_grad_norm": 0.11866050958633423, "critic_grad_norm": 0.11853337287902832, "ratio": 0.9990346431732178, "entropy": 1.3168575525283814, "incre_win_rate": 0.0, "step": 25}
{"time": 1766662904.1015055, "phase": "train", "update": 26, "total_env_steps": 83200, "episode_reward": 0.2316528856754303, "value_loss": 0.030714612205823263, "policy_loss": -0.009086217329279478, "dist_entropy": 1.3037339607874552, "actor_grad_norm": 0.11576367914676666, "critic_grad_norm": 0.06335756182670593, "ratio": 0.9989784359931946, "entropy": 1.3037339607874552, "incre_win_rate": 0.0, "step": 26}
{"time": 1766662908.4111774, "phase": "train", "update": 27, "total_env_steps": 86400, "episode_reward": 0.23118489980697632, "value_loss": 0.03540048996607462, "policy_loss": -0.009791268107057978, "dist_entropy": 1.2660353660583497, "actor_grad_norm": 0.13798701763153076, "critic_grad_norm": 0.12663164734840393, "ratio": 0.9994325637817383, "entropy": 1.2660353660583497, "incre_win_rate": 0.0, "step": 27}
{"time": 1766662912.8036172, "phase": "train", "update": 28, "total_env_steps": 89600, "episode_reward": 0.2393757849931717, "value_loss": 0.029526006430387497, "policy_loss": -0.009190882106769986, "dist_entropy": 1.2485998471577961, "actor_grad_norm": 0.1218109205365181, "critic_grad_norm": 0.08312693238258362, "ratio": 0.9990931749343872, "entropy": 1.2485998471577961, "incre_win_rate": 0.0, "step": 28}
{"time": 1766662917.11793, "phase": "train", "update": 29, "total_env_steps": 92800, "episode_reward": 0.23583562672138214, "value_loss": 0.03777857199311256, "policy_loss": -0.009729461902720971, "dist_entropy": 1.2043047428131104, "actor_grad_norm": 0.12480048835277557, "critic_grad_norm": 0.06105337291955948, "ratio": 0.999826192855835, "entropy": 1.2043047428131104, "incre_win_rate": 0.014285714285714285, "step": 29}
{"time": 1766662921.492967, "phase": "train", "update": 30, "total_env_steps": 96000, "episode_reward": 0.2427627295255661, "value_loss": 0.03891112705071767, "policy_loss": -0.009510771428119114, "dist_entropy": 1.1877164522806802, "actor_grad_norm": 0.14378705620765686, "critic_grad_norm": 0.11165324598550797, "ratio": 0.9999483227729797, "entropy": 1.1877164522806802, "incre_win_rate": 0.014084507042253521, "step": 30}
{"time": 1766662925.831439, "phase": "train", "update": 31, "total_env_steps": 99200, "episode_reward": 0.24347732961177826, "value_loss": 0.028343677272399267, "policy_loss": -0.00934381806961729, "dist_entropy": 1.1316849867502847, "actor_grad_norm": 0.140346959233284, "critic_grad_norm": 0.040140219032764435, "ratio": 0.9990328550338745, "entropy": 1.1316849867502847, "incre_win_rate": 0.0, "step": 31}
{"time": 1766662930.1066854, "phase": "train", "update": 32, "total_env_steps": 102400, "episode_reward": 0.23696845769882202, "value_loss": 0.03357449248433113, "policy_loss": -0.010603978030043018, "dist_entropy": 1.130760955810547, "actor_grad_norm": 0.11385706812143326, "critic_grad_norm": 0.11632655560970306, "ratio": 1.000599980354309, "entropy": 1.130760955810547, "incre_win_rate": 0.0, "step": 32}
{"time": 1766662934.4475014, "phase": "train", "update": 33, "total_env_steps": 105600, "episode_reward": 0.2423100620508194, "value_loss": 0.03304159343242645, "policy_loss": -0.009289732987473561, "dist_entropy": 1.1001328706741333, "actor_grad_norm": 0.1566890925168991, "critic_grad_norm": 0.09283202141523361, "ratio": 0.9998278617858887, "entropy": 1.1001328706741333, "incre_win_rate": 0.0, "step": 33}
{"time": 1766662938.7544827, "phase": "train", "update": 34, "total_env_steps": 108800, "episode_reward": 0.2508823573589325, "value_loss": 0.0418283611536026, "policy_loss": -0.009308132275003444, "dist_entropy": 1.0741238435109457, "actor_grad_norm": 0.12946665287017822, "critic_grad_norm": 0.06130608916282654, "ratio": 1.0002979040145874, "entropy": 1.0741238435109457, "incre_win_rate": 0.028985507246376812, "step": 34}
{"time": 1766662943.1001759, "phase": "train", "update": 35, "total_env_steps": 112000, "episode_reward": 0.255798876285553, "value_loss": 0.02859517311056455, "policy_loss": -0.009293757671834869, "dist_entropy": 1.0635119756062825, "actor_grad_norm": 0.14003238081932068, "critic_grad_norm": 0.06225798279047012, "ratio": 0.9997081160545349, "entropy": 1.0635119756062825, "incre_win_rate": 0.014285714285714285, "step": 35}
{"time": 1766662947.4079072, "phase": "train", "update": 36, "total_env_steps": 115200, "episode_reward": 0.2529013752937317, "value_loss": 0.03981657748421033, "policy_loss": -0.0103775487628513, "dist_entropy": 1.0631191571553549, "actor_grad_norm": 0.13936860859394073, "critic_grad_norm": 0.0676896721124649, "ratio": 1.0008586645126343, "entropy": 1.0631191571553549, "incre_win_rate": 0.015151515151515152, "step": 36}
{"time": 1766662951.7577827, "phase": "train", "update": 37, "total_env_steps": 118400, "episode_reward": 0.24962471425533295, "value_loss": 0.02825307014087836, "policy_loss": -0.010212989045175291, "dist_entropy": 1.0528066873550415, "actor_grad_norm": 0.1438852846622467, "critic_grad_norm": 0.05143539607524872, "ratio": 1.000326156616211, "entropy": 1.0528066873550415, "incre_win_rate": 0.0, "step": 37}
{"time": 1766662956.0096529, "phase": "train", "update": 38, "total_env_steps": 121600, "episode_reward": 0.24786458909511566, "value_loss": 0.03249120488762856, "policy_loss": -0.009606155513921522, "dist_entropy": 1.038706612586975, "actor_grad_norm": 0.11850551515817642, "critic_grad_norm": 0.0353226438164711, "ratio": 0.9991806745529175, "entropy": 1.038706612586975, "incre_win_rate": 0.014492753623188406, "step": 38}
{"time": 1766662960.2626941, "phase": "train", "update": 39, "total_env_steps": 124800, "episode_reward": 0.2528454661369324, "value_loss": 0.0344061516225338, "policy_loss": -0.010192954392721514, "dist_entropy": 1.024743127822876, "actor_grad_norm": 0.14826402068138123, "critic_grad_norm": 0.06513043493032455, "ratio": 0.999973475933075, "entropy": 1.024743127822876, "incre_win_rate": 0.03125, "step": 39}
{"time": 1766662964.588708, "phase": "train", "update": 40, "total_env_steps": 128000, "episode_reward": 0.24435587227344513, "value_loss": 0.039292225738366444, "policy_loss": -0.010694607462034374, "dist_entropy": 1.0251955350240072, "actor_grad_norm": 0.16606535017490387, "critic_grad_norm": 0.058778852224349976, "ratio": 1.0004686117172241, "entropy": 1.0251955350240072, "incre_win_rate": 0.029850746268656716, "step": 40}
{"time": 1766662968.834338, "phase": "train", "update": 41, "total_env_steps": 131200, "episode_reward": 0.2558969259262085, "value_loss": 0.03366496836145719, "policy_loss": -0.010479467610469822, "dist_entropy": 1.0110329786936443, "actor_grad_norm": 0.13129612803459167, "critic_grad_norm": 0.04824027419090271, "ratio": 1.000715970993042, "entropy": 1.0110329786936443, "incre_win_rate": 0.029850746268656716, "step": 41}
{"time": 1766662975.8938687, "phase": "eval", "update": 41, "total_env_steps": 131200, "eval_win_rate": 0.46875, "eval_episode_reward": 16.677849264705884, "step": 41}
{"time": 1766662980.1769643, "phase": "train", "update": 42, "total_env_steps": 134400, "episode_reward": 0.2525275945663452, "value_loss": 0.0337896150847276, "policy_loss": -0.010131457002591378, "dist_entropy": 1.0133885304133097, "actor_grad_norm": 0.1536383330821991, "critic_grad_norm": 0.03588830307126045, "ratio": 0.9993747472763062, "entropy": 1.0133885304133097, "incre_win_rate": 0.015151515151515152, "step": 42}
{"time": 1766662984.522726, "phase": "train", "update": 43, "total_env_steps": 137600, "episode_reward": 0.2470603585243225, "value_loss": 0.03292794364194075, "policy_loss": -0.010403767891390874, "dist_entropy": 1.0025739630063375, "actor_grad_norm": 0.17202916741371155, "critic_grad_norm": 0.11601580679416656, "ratio": 0.9992396831512451, "entropy": 1.0025739630063375, "incre_win_rate": 0.015151515151515152, "step": 43}
{"time": 1766662988.730562, "phase": "train", "update": 44, "total_env_steps": 140800, "episode_reward": 0.2343803495168686, "value_loss": 0.03818409790595372, "policy_loss": -0.009780316237456076, "dist_entropy": 0.9751498222351074, "actor_grad_norm": 0.15699799358844757, "critic_grad_norm": 0.07738528400659561, "ratio": 0.9993859529495239, "entropy": 0.9751498222351074, "incre_win_rate": 0.03278688524590164, "step": 44}
{"time": 1766662993.0222304, "phase": "train", "update": 45, "total_env_steps": 144000, "episode_reward": 0.24705806374549866, "value_loss": 0.03664033735791842, "policy_loss": -0.010486342912770159, "dist_entropy": 0.9743263681729635, "actor_grad_norm": 0.1279813051223755, "critic_grad_norm": 0.05146871507167816, "ratio": 0.9994907975196838, "entropy": 0.9743263681729635, "incre_win_rate": 0.05, "step": 45}
{"time": 1766662997.2619205, "phase": "train", "update": 46, "total_env_steps": 147200, "episode_reward": 0.23798485100269318, "value_loss": 0.03490883658329646, "policy_loss": -0.009728544890053807, "dist_entropy": 0.9514786044756571, "actor_grad_norm": 0.13452382385730743, "critic_grad_norm": 0.07850479334592819, "ratio": 0.9999282956123352, "entropy": 0.9514786044756571, "incre_win_rate": 0.01639344262295082, "step": 46}
{"time": 1766663001.4654052, "phase": "train", "update": 47, "total_env_steps": 150400, "episode_reward": 0.2220098227262497, "value_loss": 0.029703167205055555, "policy_loss": -0.010092915291902215, "dist_entropy": 0.9521090547243755, "actor_grad_norm": 0.17223083972930908, "critic_grad_norm": 0.06560085713863373, "ratio": 1.0001208782196045, "entropy": 0.9521090547243755, "incre_win_rate": 0.01818181818181818, "step": 47}
{"time": 1766663005.7204113, "phase": "train", "update": 48, "total_env_steps": 153600, "episode_reward": 0.2290625125169754, "value_loss": 0.03479429855942726, "policy_loss": -0.009350990516550202, "dist_entropy": 0.9163480639457703, "actor_grad_norm": 0.14283594489097595, "critic_grad_norm": 0.1597561091184616, "ratio": 0.999820351600647, "entropy": 0.9163480639457703, "incre_win_rate": 0.038461538461538464, "step": 48}
{"time": 1766663009.968942, "phase": "train", "update": 49, "total_env_steps": 156800, "episode_reward": 0.23728707432746887, "value_loss": 0.03147417319317659, "policy_loss": -0.010239381663487753, "dist_entropy": 0.9181185364723206, "actor_grad_norm": 0.13440170884132385, "critic_grad_norm": 0.10236208140850067, "ratio": 0.9990253448486328, "entropy": 0.9181185364723206, "incre_win_rate": 0.04918032786885246, "step": 49}
{"time": 1766663014.229338, "phase": "train", "update": 50, "total_env_steps": 160000, "episode_reward": 0.24236749112606049, "value_loss": 0.03872744267185529, "policy_loss": -0.010690838069725098, "dist_entropy": 0.8925064166386922, "actor_grad_norm": 0.13990971446037292, "critic_grad_norm": 0.06666629761457443, "ratio": 0.9996126294136047, "entropy": 0.8925064166386922, "incre_win_rate": 0.08064516129032258, "step": 50}
{"time": 1766663018.5956328, "phase": "train", "update": 51, "total_env_steps": 163200, "episode_reward": 0.26106157898902893, "value_loss": 0.04724967405200005, "policy_loss": -0.010277334184590833, "dist_entropy": 0.8907274881998698, "actor_grad_norm": 0.1407792568206787, "critic_grad_norm": 0.22383655607700348, "ratio": 0.9978345632553101, "entropy": 0.8907274881998698, "incre_win_rate": 0.1694915254237288, "step": 51}
{"time": 1766663022.8548636, "phase": "train", "update": 52, "total_env_steps": 166400, "episode_reward": 0.2429894357919693, "value_loss": 0.03899474516510963, "policy_loss": -0.010058076034314686, "dist_entropy": 0.8585645278294881, "actor_grad_norm": 0.12328528612852097, "critic_grad_norm": 0.04793990030884743, "ratio": 1.000076413154602, "entropy": 0.8585645278294881, "incre_win_rate": 0.05263157894736842, "step": 52}
{"time": 1766663027.096043, "phase": "train", "update": 53, "total_env_steps": 169600, "episode_reward": 0.24115502834320068, "value_loss": 0.0395326795677344, "policy_loss": -0.010321629835684595, "dist_entropy": 0.8618259350458781, "actor_grad_norm": 0.160989448428154, "critic_grad_norm": 0.10244948416948318, "ratio": 0.9996393322944641, "entropy": 0.8618259350458781, "incre_win_rate": 0.07017543859649122, "step": 53}
{"time": 1766663031.3249204, "phase": "train", "update": 54, "total_env_steps": 172800, "episode_reward": 0.255118727684021, "value_loss": 0.034117162227630615, "policy_loss": -0.010285374173613585, "dist_entropy": 0.8222004016240437, "actor_grad_norm": 0.16910198330879211, "critic_grad_norm": 0.0633825734257698, "ratio": 0.9990249276161194, "entropy": 0.8222004016240437, "incre_win_rate": 0.1, "step": 54}
{"time": 1766663035.5777724, "phase": "train", "update": 55, "total_env_steps": 176000, "episode_reward": 0.2336864471435547, "value_loss": 0.03796029960115751, "policy_loss": -0.009786030795646638, "dist_entropy": 0.8552983125050863, "actor_grad_norm": 0.1550244241952896, "critic_grad_norm": 0.11491359770298004, "ratio": 0.9983157515525818, "entropy": 0.8552983125050863, "incre_win_rate": 0.1320754716981132, "step": 55}
{"time": 1766663039.7908266, "phase": "train", "update": 56, "total_env_steps": 179200, "episode_reward": 0.24899357557296753, "value_loss": 0.041195766131083174, "policy_loss": -0.010207570828796501, "dist_entropy": 0.8464266141255696, "actor_grad_norm": 0.14214617013931274, "critic_grad_norm": 0.09002610296010971, "ratio": 0.9992108345031738, "entropy": 0.8464266141255696, "incre_win_rate": 0.17857142857142858, "step": 56}
{"time": 1766663043.980822, "phase": "train", "update": 57, "total_env_steps": 182400, "episode_reward": 0.22357307374477386, "value_loss": 0.03235520819822947, "policy_loss": -0.010869604291208645, "dist_entropy": 0.8228016058603923, "actor_grad_norm": 0.15236352384090424, "critic_grad_norm": 0.06672912836074829, "ratio": 0.9988932013511658, "entropy": 0.8228016058603923, "incre_win_rate": 0.018518518518518517, "step": 57}
{"time": 1766663048.2720945, "phase": "train", "update": 58, "total_env_steps": 185600, "episode_reward": 0.22536920011043549, "value_loss": 0.030312423408031464, "policy_loss": -0.010223907466335901, "dist_entropy": 0.8391778667767843, "actor_grad_norm": 0.16219250857830048, "critic_grad_norm": 0.054224513471126556, "ratio": 0.9988551139831543, "entropy": 0.8391778667767843, "incre_win_rate": 0.058823529411764705, "step": 58}
{"time": 1766663052.480351, "phase": "train", "update": 59, "total_env_steps": 188800, "episode_reward": 0.24289904534816742, "value_loss": 0.039504224807024, "policy_loss": -0.010764937011669496, "dist_entropy": 0.815793764591217, "actor_grad_norm": 0.13400399684906006, "critic_grad_norm": 0.09083663672208786, "ratio": 0.9991496205329895, "entropy": 0.815793764591217, "incre_win_rate": 0.11864406779661017, "step": 59}
{"time": 1766663056.6922195, "phase": "train", "update": 60, "total_env_steps": 192000, "episode_reward": 0.2254105508327484, "value_loss": 0.035798605034748715, "policy_loss": -0.01071954174709641, "dist_entropy": 0.8147513310114542, "actor_grad_norm": 0.17724482715129852, "critic_grad_norm": 0.07803424447774887, "ratio": 0.9999404549598694, "entropy": 0.8147513310114542, "incre_win_rate": 0.08, "step": 60}
{"time": 1766663060.9026747, "phase": "train", "update": 61, "total_env_steps": 195200, "episode_reward": 0.24158930778503418, "value_loss": 0.03998655950029691, "policy_loss": -0.010425069271583235, "dist_entropy": 0.8102990945180257, "actor_grad_norm": 0.21946315467357635, "critic_grad_norm": 0.033468104898929596, "ratio": 0.9986434578895569, "entropy": 0.8102990945180257, "incre_win_rate": 0.16071428571428573, "step": 61}
{"time": 1766663068.9744668, "phase": "eval", "update": 61, "total_env_steps": 195200, "eval_win_rate": 0.40625, "eval_episode_reward": 16.76937806372549, "step": 61}
{"time": 1766663073.1992497, "phase": "train", "update": 62, "total_env_steps": 198400, "episode_reward": 0.2584390640258789, "value_loss": 0.04292805716395378, "policy_loss": -0.009577541717234083, "dist_entropy": 0.779849112033844, "actor_grad_norm": 0.21230719983577728, "critic_grad_norm": 0.06709276139736176, "ratio": 0.998715877532959, "entropy": 0.779849112033844, "incre_win_rate": 0.15517241379310345, "step": 62}
{"time": 1766663077.482716, "phase": "train", "update": 63, "total_env_steps": 201600, "episode_reward": 0.2549295425415039, "value_loss": 0.041308205823103586, "policy_loss": -0.010133800190607072, "dist_entropy": 0.7767888307571411, "actor_grad_norm": 0.21838846802711487, "critic_grad_norm": 0.10927759110927582, "ratio": 0.9999412894248962, "entropy": 0.7767888307571411, "incre_win_rate": 0.19642857142857142, "step": 63}
{"time": 1766663081.7031627, "phase": "train", "update": 64, "total_env_steps": 204800, "episode_reward": 0.26415055990219116, "value_loss": 0.05216075753172238, "policy_loss": -0.009510960499058403, "dist_entropy": 0.7506255626678466, "actor_grad_norm": 0.14250439405441284, "critic_grad_norm": 0.0734662115573883, "ratio": 0.9990687966346741, "entropy": 0.7506255626678466, "incre_win_rate": 0.2631578947368421, "step": 64}
{"time": 1766663085.9057689, "phase": "train", "update": 65, "total_env_steps": 208000, "episode_reward": 0.232421875, "value_loss": 0.03646192476153374, "policy_loss": -0.010572443508716549, "dist_entropy": 0.7952702760696411, "actor_grad_norm": 0.19991131126880646, "critic_grad_norm": 0.05461104214191437, "ratio": 0.9991271495819092, "entropy": 0.7952702760696411, "incre_win_rate": 0.1836734693877551, "step": 65}
{"time": 1766663090.1446006, "phase": "train", "update": 66, "total_env_steps": 211200, "episode_reward": 0.2329695224761963, "value_loss": 0.03391588752468427, "policy_loss": -0.010632652927751944, "dist_entropy": 0.7880406061808268, "actor_grad_norm": 0.15941938757896423, "critic_grad_norm": 0.1382295787334442, "ratio": 0.9995654225349426, "entropy": 0.7880406061808268, "incre_win_rate": 0.13725490196078433, "step": 66}
{"time": 1766663094.5988803, "phase": "train", "update": 67, "total_env_steps": 214400, "episode_reward": 0.2629925012588501, "value_loss": 0.04000868399937948, "policy_loss": -0.009757171421428741, "dist_entropy": 0.7487801949183146, "actor_grad_norm": 0.16405154764652252, "critic_grad_norm": 0.10168945044279099, "ratio": 0.9990748167037964, "entropy": 0.7487801949183146, "incre_win_rate": 0.22413793103448276, "step": 67}
{"time": 1766663098.8086483, "phase": "train", "update": 68, "total_env_steps": 217600, "episode_reward": 0.24443013966083527, "value_loss": 0.03452827235062917, "policy_loss": -0.01119937751230656, "dist_entropy": 0.7616508920987447, "actor_grad_norm": 0.1907435655593872, "critic_grad_norm": 0.07920626550912857, "ratio": 0.9986037015914917, "entropy": 0.7616508920987447, "incre_win_rate": 0.1320754716981132, "step": 68}
{"time": 1766663102.9598804, "phase": "train", "update": 69, "total_env_steps": 220800, "episode_reward": 0.24365578591823578, "value_loss": 0.0371136466662089, "policy_loss": -0.009113136593804446, "dist_entropy": 0.7424605369567872, "actor_grad_norm": 0.1511564403772354, "critic_grad_norm": 0.18523100018501282, "ratio": 0.9996722936630249, "entropy": 0.7424605369567872, "incre_win_rate": 0.2857142857142857, "step": 69}
{"time": 1766663107.1883862, "phase": "train", "update": 70, "total_env_steps": 224000, "episode_reward": 0.2756640613079071, "value_loss": 0.03983401333292325, "policy_loss": -0.01019211926238152, "dist_entropy": 0.7085768063863118, "actor_grad_norm": 0.18280762434005737, "critic_grad_norm": 0.09531021863222122, "ratio": 0.9985664486885071, "entropy": 0.7085768063863118, "incre_win_rate": 0.3448275862068966, "step": 70}
{"time": 1766663111.315898, "phase": "train", "update": 71, "total_env_steps": 227200, "episode_reward": 0.2322801798582077, "value_loss": 0.044407474746306734, "policy_loss": -0.01103566658352193, "dist_entropy": 0.7239594499270121, "actor_grad_norm": 0.1580003947019577, "critic_grad_norm": 0.13390479981899261, "ratio": 0.9980039000511169, "entropy": 0.7239594499270121, "incre_win_rate": 0.25, "step": 71}
{"time": 1766663115.5410724, "phase": "train", "update": 72, "total_env_steps": 230400, "episode_reward": 0.2446729689836502, "value_loss": 0.03955072487394015, "policy_loss": -0.010635283741556716, "dist_entropy": 0.726975683371226, "actor_grad_norm": 0.19772444665431976, "critic_grad_norm": 0.09255041182041168, "ratio": 1.00006902217865, "entropy": 0.726975683371226, "incre_win_rate": 0.2692307692307692, "step": 72}
{"time": 1766663119.7345986, "phase": "train", "update": 73, "total_env_steps": 233600, "episode_reward": 0.2403094321489334, "value_loss": 0.03607990543047587, "policy_loss": -0.010265868091752376, "dist_entropy": 0.7556174079577128, "actor_grad_norm": 0.15698319673538208, "critic_grad_norm": 0.0819016546010971, "ratio": 0.9994697570800781, "entropy": 0.7556174079577128, "incre_win_rate": 0.24, "step": 73}
{"time": 1766663123.8969057, "phase": "train", "update": 74, "total_env_steps": 236800, "episode_reward": 0.21463465690612793, "value_loss": 0.03819774091243744, "policy_loss": -0.010541227887746748, "dist_entropy": 0.753796398639679, "actor_grad_norm": 0.21188640594482422, "critic_grad_norm": 0.05326969549059868, "ratio": 0.9989664554595947, "entropy": 0.753796398639679, "incre_win_rate": 0.16666666666666666, "step": 74}
{"time": 1766663128.1002645, "phase": "train", "update": 75, "total_env_steps": 240000, "episode_reward": 0.21494561433792114, "value_loss": 0.035567487279574074, "policy_loss": -0.011011195338833582, "dist_entropy": 0.7554332971572876, "actor_grad_norm": 0.1632014662027359, "critic_grad_norm": 0.04420354217290878, "ratio": 0.998843252658844, "entropy": 0.7554332971572876, "incre_win_rate": 0.1702127659574468, "step": 75}
{"time": 1766663132.30285, "phase": "train", "update": 76, "total_env_steps": 243200, "episode_reward": 0.24115504324436188, "value_loss": 0.04026163245240847, "policy_loss": -0.01045683651541296, "dist_entropy": 0.7437305490175883, "actor_grad_norm": 0.1884690225124359, "critic_grad_norm": 0.1717575639486313, "ratio": 0.998471736907959, "entropy": 0.7437305490175883, "incre_win_rate": 0.2916666666666667, "step": 76}
{"time": 1766663136.5686743, "phase": "train", "update": 77, "total_env_steps": 246400, "episode_reward": 0.24127069115638733, "value_loss": 0.03746109778682391, "policy_loss": -0.0107797867958066, "dist_entropy": 0.6998876849810283, "actor_grad_norm": 0.1568305641412735, "critic_grad_norm": 0.05182034149765968, "ratio": 0.9987800121307373, "entropy": 0.6998876849810283, "incre_win_rate": 0.23076923076923078, "step": 77}
{"time": 1766663140.728391, "phase": "train", "update": 78, "total_env_steps": 249600, "episode_reward": 0.24053692817687988, "value_loss": 0.03858435700337092, "policy_loss": -0.010614772992379546, "dist_entropy": 0.704862380027771, "actor_grad_norm": 0.21273629367351532, "critic_grad_norm": 0.14898602664470673, "ratio": 0.9991610646247864, "entropy": 0.704862380027771, "incre_win_rate": 0.19230769230769232, "step": 78}
{"time": 1766663144.9552708, "phase": "train", "update": 79, "total_env_steps": 252800, "episode_reward": 0.2584972679615021, "value_loss": 0.03643467575311661, "policy_loss": -0.010810861720382429, "dist_entropy": 0.6918027400970459, "actor_grad_norm": 0.17677606642246246, "critic_grad_norm": 0.157225102186203, "ratio": 0.999552845954895, "entropy": 0.6918027400970459, "incre_win_rate": 0.3333333333333333, "step": 79}
{"time": 1766663149.2321446, "phase": "train", "update": 80, "total_env_steps": 256000, "episode_reward": 0.27713543176651, "value_loss": 0.04004758919278781, "policy_loss": -0.009883055941459417, "dist_entropy": 0.674622639020284, "actor_grad_norm": 0.1638345867395401, "critic_grad_norm": 0.12884803116321564, "ratio": 0.9999455809593201, "entropy": 0.674622639020284, "incre_win_rate": 0.35714285714285715, "step": 80}
{"time": 1766663153.4230475, "phase": "train", "update": 81, "total_env_steps": 259200, "episode_reward": 0.23831112682819366, "value_loss": 0.03963615323106448, "policy_loss": -0.010734846422009526, "dist_entropy": 0.7239399790763855, "actor_grad_norm": 0.15838147699832916, "critic_grad_norm": 0.06257341802120209, "ratio": 0.9987203478813171, "entropy": 0.7239399790763855, "incre_win_rate": 0.28846153846153844, "step": 81}
{"time": 1766663161.4878366, "phase": "eval", "update": 81, "total_env_steps": 259200, "eval_win_rate": 0.5, "eval_episode_reward": 17.186887254901958, "step": 81}
{"time": 1766663165.6844423, "phase": "train", "update": 82, "total_env_steps": 262400, "episode_reward": 0.25102558732032776, "value_loss": 0.040994609147310256, "policy_loss": -0.010081558975293111, "dist_entropy": 0.6806007742881774, "actor_grad_norm": 0.16604208946228027, "critic_grad_norm": 0.13340052962303162, "ratio": 0.9989379644393921, "entropy": 0.6806007742881774, "incre_win_rate": 0.20754716981132076, "step": 82}
{"time": 1766663169.8707452, "phase": "train", "update": 83, "total_env_steps": 265600, "episode_reward": 0.28205347061157227, "value_loss": 0.04132801319162051, "policy_loss": -0.009661440870491351, "dist_entropy": 0.644837749004364, "actor_grad_norm": 0.2071855068206787, "critic_grad_norm": 0.08492812514305115, "ratio": 0.9995284676551819, "entropy": 0.644837749004364, "incre_win_rate": 0.3508771929824561, "step": 83}
{"time": 1766663174.0596352, "phase": "train", "update": 84, "total_env_steps": 268800, "episode_reward": 0.28005361557006836, "value_loss": 0.040082351118326184, "policy_loss": -0.010999293257289603, "dist_entropy": 0.6573060512542724, "actor_grad_norm": 0.16525322198867798, "critic_grad_norm": 0.08087366074323654, "ratio": 0.9988321661949158, "entropy": 0.6573060512542724, "incre_win_rate": 0.4, "step": 84}
{"time": 1766663178.258412, "phase": "train", "update": 85, "total_env_steps": 272000, "episode_reward": 0.25477251410484314, "value_loss": 0.036646108826001486, "policy_loss": -0.011359564208825054, "dist_entropy": 0.6897794524828593, "actor_grad_norm": 0.18135668337345123, "critic_grad_norm": 0.06761067360639572, "ratio": 0.9996355175971985, "entropy": 0.6897794524828593, "incre_win_rate": 0.35294117647058826, "step": 85}
{"time": 1766663182.528225, "phase": "train", "update": 86, "total_env_steps": 275200, "episode_reward": 0.2743382453918457, "value_loss": 0.038538922121127445, "policy_loss": -0.010578043362382534, "dist_entropy": 0.6592255075772603, "actor_grad_norm": 0.20000490546226501, "critic_grad_norm": 0.18940916657447815, "ratio": 0.9993339776992798, "entropy": 0.6592255075772603, "incre_win_rate": 0.3090909090909091, "step": 86}
{"time": 1766663186.7899666, "phase": "train", "update": 87, "total_env_steps": 278400, "episode_reward": 0.2597648501396179, "value_loss": 0.0336238627632459, "policy_loss": -0.011285609424880268, "dist_entropy": 0.6719504197438558, "actor_grad_norm": 0.16808147728443146, "critic_grad_norm": 0.08912674337625504, "ratio": 0.9994136095046997, "entropy": 0.6719504197438558, "incre_win_rate": 0.2545454545454545, "step": 87}
{"time": 1766663190.9946363, "phase": "train", "update": 88, "total_env_steps": 281600, "episode_reward": 0.29314494132995605, "value_loss": 0.03391483811040719, "policy_loss": -0.01012743762696052, "dist_entropy": 0.6350991169611613, "actor_grad_norm": 0.15943367779254913, "critic_grad_norm": 0.14154846966266632, "ratio": 0.99944007396698, "entropy": 0.6350991169611613, "incre_win_rate": 0.43859649122807015, "step": 88}
{"time": 1766663195.226942, "phase": "train", "update": 89, "total_env_steps": 284800, "episode_reward": 0.29158318042755127, "value_loss": 0.0333293866366148, "policy_loss": -0.010532504043917848, "dist_entropy": 0.6322792371114095, "actor_grad_norm": 0.15728427469730377, "critic_grad_norm": 0.05908740684390068, "ratio": 0.9982681274414062, "entropy": 0.6322792371114095, "incre_win_rate": 0.3333333333333333, "step": 89}
{"time": 1766663199.4283876, "phase": "train", "update": 90, "total_env_steps": 288000, "episode_reward": 0.241913303732872, "value_loss": 0.03443019762635231, "policy_loss": -0.011634079959783605, "dist_entropy": 0.6554575125376384, "actor_grad_norm": 0.18724429607391357, "critic_grad_norm": 0.17210687696933746, "ratio": 0.9991949200630188, "entropy": 0.6554575125376384, "incre_win_rate": 0.18867924528301888, "step": 90}
{"time": 1766663203.6249552, "phase": "train", "update": 91, "total_env_steps": 291200, "episode_reward": 0.25847581028938293, "value_loss": 0.03378829297920068, "policy_loss": -0.011058068008191905, "dist_entropy": 0.6602090001106262, "actor_grad_norm": 0.2336001992225647, "critic_grad_norm": 0.06451653689146042, "ratio": 0.9992832541465759, "entropy": 0.6602090001106262, "incre_win_rate": 0.2962962962962963, "step": 91}
{"time": 1766663207.904472, "phase": "train", "update": 92, "total_env_steps": 294400, "episode_reward": 0.28086626529693604, "value_loss": 0.03532472401857376, "policy_loss": -0.011112833249226621, "dist_entropy": 0.6262349168459574, "actor_grad_norm": 0.2713194489479065, "critic_grad_norm": 0.10703641921281815, "ratio": 1.0001949071884155, "entropy": 0.6262349168459574, "incre_win_rate": 0.3448275862068966, "step": 92}
{"time": 1766663212.0382206, "phase": "train", "update": 93, "total_env_steps": 297600, "episode_reward": 0.25984758138656616, "value_loss": 0.04374758576353391, "policy_loss": -0.010507452993914985, "dist_entropy": 0.6055468916893005, "actor_grad_norm": 0.2277475744485855, "critic_grad_norm": 0.04800068214535713, "ratio": 0.9982284307479858, "entropy": 0.6055468916893005, "incre_win_rate": 0.3269230769230769, "step": 93}
{"time": 1766663216.2947989, "phase": "train", "update": 94, "total_env_steps": 300800, "episode_reward": 0.26908624172210693, "value_loss": 0.03880670964717865, "policy_loss": -0.010604723918734274, "dist_entropy": 0.6169712464014689, "actor_grad_norm": 0.18922270834445953, "critic_grad_norm": 0.14640820026397705, "ratio": 0.9986609220504761, "entropy": 0.6169712464014689, "incre_win_rate": 0.38596491228070173, "step": 94}
{"time": 1766663220.5327058, "phase": "train", "update": 95, "total_env_steps": 304000, "episode_reward": 0.2538250684738159, "value_loss": 0.03406800180673599, "policy_loss": -0.011444689100149352, "dist_entropy": 0.627230433622996, "actor_grad_norm": 0.18092061579227448, "critic_grad_norm": 0.06701892614364624, "ratio": 0.9985917210578918, "entropy": 0.627230433622996, "incre_win_rate": 0.3673469387755102, "step": 95}
{"time": 1766663224.6953828, "phase": "train", "update": 96, "total_env_steps": 307200, "episode_reward": 0.2723322808742523, "value_loss": 0.03265558915833632, "policy_loss": -0.010225105429969024, "dist_entropy": 0.5869178533554077, "actor_grad_norm": 0.19944971799850464, "critic_grad_norm": 0.030565477907657623, "ratio": 0.9993629455566406, "entropy": 0.5869178533554077, "incre_win_rate": 0.4444444444444444, "step": 96}
{"time": 1766663228.9456136, "phase": "train", "update": 97, "total_env_steps": 310400, "episode_reward": 0.2614315152168274, "value_loss": 0.03873442932963371, "policy_loss": -0.009998585084091852, "dist_entropy": 0.6279801726341248, "actor_grad_norm": 0.17930753529071808, "critic_grad_norm": 0.05281845107674599, "ratio": 0.9999960064888, "entropy": 0.6279801726341248, "incre_win_rate": 0.3584905660377358, "step": 97}
{"time": 1766663233.132636, "phase": "train", "update": 98, "total_env_steps": 313600, "episode_reward": 0.28122931718826294, "value_loss": 0.03378129278620084, "policy_loss": -0.010822712725443277, "dist_entropy": 0.6049444715181986, "actor_grad_norm": 0.18241126835346222, "critic_grad_norm": 0.1447683572769165, "ratio": 0.9987305402755737, "entropy": 0.6049444715181986, "incre_win_rate": 0.45454545454545453, "step": 98}
{"time": 1766663237.3137686, "phase": "train", "update": 99, "total_env_steps": 316800, "episode_reward": 0.272268682718277, "value_loss": 0.035868148257335024, "policy_loss": -0.010413663314577567, "dist_entropy": 0.6027573307355245, "actor_grad_norm": 0.12631815671920776, "critic_grad_norm": 0.04378889873623848, "ratio": 0.9985517859458923, "entropy": 0.6027573307355245, "incre_win_rate": 0.4528301886792453, "step": 99}
{"time": 1766663241.597201, "phase": "train", "update": 100, "total_env_steps": 320000, "episode_reward": 0.2795519530773163, "value_loss": 0.03322170525789261, "policy_loss": -0.010421995539900308, "dist_entropy": 0.6136775573094686, "actor_grad_norm": 0.20032379031181335, "critic_grad_norm": 0.04565955325961113, "ratio": 0.9997818470001221, "entropy": 0.6136775573094686, "incre_win_rate": 0.4807692307692308, "step": 100}
{"time": 1766663245.8329744, "phase": "train", "update": 101, "total_env_steps": 323200, "episode_reward": 0.27491116523742676, "value_loss": 0.0393064558506012, "policy_loss": -0.010857488873065554, "dist_entropy": 0.5949000398317973, "actor_grad_norm": 0.15387389063835144, "critic_grad_norm": 0.11647285521030426, "ratio": 0.9990788102149963, "entropy": 0.5949000398317973, "incre_win_rate": 0.3793103448275862, "step": 101}
{"time": 1766663252.90242, "phase": "eval", "update": 101, "total_env_steps": 323200, "eval_win_rate": 0.65625, "eval_episode_reward": 17.734757965686278, "step": 101}
{"time": 1766663257.087589, "phase": "train", "update": 102, "total_env_steps": 326400, "episode_reward": 0.2781985402107239, "value_loss": 0.027228058129549027, "policy_loss": -0.010995866611701407, "dist_entropy": 0.5848160505294799, "actor_grad_norm": 0.17763029038906097, "critic_grad_norm": 0.07457584887742996, "ratio": 0.9990407228469849, "entropy": 0.5848160505294799, "incre_win_rate": 0.42592592592592593, "step": 102}
{"time": 1766663261.3064108, "phase": "train", "update": 103, "total_env_steps": 329600, "episode_reward": 0.2629963159561157, "value_loss": 0.03090194289882978, "policy_loss": -0.010257442458232428, "dist_entropy": 0.6097519278526307, "actor_grad_norm": 0.1793019324541092, "critic_grad_norm": 0.0550021231174469, "ratio": 1.000434160232544, "entropy": 0.6097519278526307, "incre_win_rate": 0.39215686274509803, "step": 103}
{"time": 1766663265.5210595, "phase": "train", "update": 104, "total_env_steps": 332800, "episode_reward": 0.3061964213848114, "value_loss": 0.028953004876772562, "policy_loss": -0.010528316675927367, "dist_entropy": 0.6159643451372783, "actor_grad_norm": 0.27590739727020264, "critic_grad_norm": 0.15889303386211395, "ratio": 0.9993340969085693, "entropy": 0.6159643451372783, "incre_win_rate": 0.5892857142857143, "step": 104}
{"time": 1766663269.7291768, "phase": "train", "update": 105, "total_env_steps": 336000, "episode_reward": 0.2603638172149658, "value_loss": 0.030255947510401407, "policy_loss": -0.010884741087489639, "dist_entropy": 0.6184770663579305, "actor_grad_norm": 0.16828419268131256, "critic_grad_norm": 0.08175333589315414, "ratio": 0.9989467263221741, "entropy": 0.6184770663579305, "incre_win_rate": 0.40384615384615385, "step": 105}
{"time": 1766663274.0483282, "phase": "train", "update": 106, "total_env_steps": 339200, "episode_reward": 0.26387178897857666, "value_loss": 0.030907711510856948, "policy_loss": -0.011352071167887582, "dist_entropy": 0.6215879082679748, "actor_grad_norm": 0.19492436945438385, "critic_grad_norm": 0.06191069260239601, "ratio": 0.9992104768753052, "entropy": 0.6215879082679748, "incre_win_rate": 0.40384615384615385, "step": 106}
{"time": 1766663278.319452, "phase": "train", "update": 107, "total_env_steps": 342400, "episode_reward": 0.29877758026123047, "value_loss": 0.03235822282731533, "policy_loss": -0.010598881474226355, "dist_entropy": 0.596810229619344, "actor_grad_norm": 0.22653961181640625, "critic_grad_norm": 0.04087070748209953, "ratio": 0.9998395442962646, "entropy": 0.596810229619344, "incre_win_rate": 0.49122807017543857, "step": 107}
{"time": 1766663282.518567, "phase": "train", "update": 108, "total_env_steps": 345600, "episode_reward": 0.26442787051200867, "value_loss": 0.032661236077547076, "policy_loss": -0.010810668970485911, "dist_entropy": 0.602297842502594, "actor_grad_norm": 0.1907726377248764, "critic_grad_norm": 0.12237943708896637, "ratio": 0.9985835552215576, "entropy": 0.602297842502594, "incre_win_rate": 0.33962264150943394, "step": 108}
{"time": 1766663286.7852619, "phase": "train", "update": 109, "total_env_steps": 348800, "episode_reward": 0.26899048686027527, "value_loss": 0.024652573217948278, "policy_loss": -0.010526177590296963, "dist_entropy": 0.6205019076665242, "actor_grad_norm": 0.22704651951789856, "critic_grad_norm": 0.07855459302663803, "ratio": 0.9990032911300659, "entropy": 0.6205019076665242, "incre_win_rate": 0.5, "step": 109}
{"time": 1766663291.0424337, "phase": "train", "update": 110, "total_env_steps": 352000, "episode_reward": 0.28924328088760376, "value_loss": 0.030416324610511462, "policy_loss": -0.01098327781770081, "dist_entropy": 0.6031871676445008, "actor_grad_norm": 0.16828322410583496, "critic_grad_norm": 0.11333383619785309, "ratio": 0.9994950294494629, "entropy": 0.6031871676445008, "incre_win_rate": 0.4807692307692308, "step": 110}
{"time": 1766663295.1814878, "phase": "train", "update": 111, "total_env_steps": 355200, "episode_reward": 0.2554542124271393, "value_loss": 0.027943883587916694, "policy_loss": -0.011583377929017995, "dist_entropy": 0.6255259871482849, "actor_grad_norm": 0.1514916568994522, "critic_grad_norm": 0.0536346510052681, "ratio": 0.9996196627616882, "entropy": 0.6255259871482849, "incre_win_rate": 0.39215686274509803, "step": 111}
{"time": 1766663299.4116013, "phase": "train", "update": 112, "total_env_steps": 358400, "episode_reward": 0.27501606941223145, "value_loss": 0.02729961226383845, "policy_loss": -0.010111729823836886, "dist_entropy": 0.6182296673456827, "actor_grad_norm": 0.15998730063438416, "critic_grad_norm": 0.03360982984304428, "ratio": 0.9997981190681458, "entropy": 0.6182296673456827, "incre_win_rate": 0.43636363636363634, "step": 112}
{"time": 1766663304.1641765, "phase": "train", "update": 113, "total_env_steps": 361600, "episode_reward": 0.28616729378700256, "value_loss": 0.029795002316435178, "policy_loss": -0.010884476358586899, "dist_entropy": 0.6187735478083293, "actor_grad_norm": 0.17743805050849915, "critic_grad_norm": 0.03683866560459137, "ratio": 1.0001113414764404, "entropy": 0.6187735478083293, "incre_win_rate": 0.4444444444444444, "step": 113}
{"time": 1766663310.193141, "phase": "train", "update": 114, "total_env_steps": 364800, "episode_reward": 0.2848031520843506, "value_loss": 0.025491698707143465, "policy_loss": -0.00961271434611414, "dist_entropy": 0.5845171014467875, "actor_grad_norm": 0.14899465441703796, "critic_grad_norm": 0.03532140329480171, "ratio": 0.9994274377822876, "entropy": 0.5845171014467875, "incre_win_rate": 0.4727272727272727, "step": 114}
{"time": 1766663314.8301563, "phase": "train", "update": 115, "total_env_steps": 368000, "episode_reward": 0.2641092538833618, "value_loss": 0.028332128251592318, "policy_loss": -0.011736898478078217, "dist_entropy": 0.6322890281677246, "actor_grad_norm": 0.23102906346321106, "critic_grad_norm": 0.05975133925676346, "ratio": 0.9984925389289856, "entropy": 0.6322890281677246, "incre_win_rate": 0.46, "step": 115}
{"time": 1766663319.6043856, "phase": "train", "update": 116, "total_env_steps": 371200, "episode_reward": 0.28759804368019104, "value_loss": 0.027836204196015995, "policy_loss": -0.011125768509824259, "dist_entropy": 0.6114558180173238, "actor_grad_norm": 0.21013540029525757, "critic_grad_norm": 0.11202825605869293, "ratio": 0.9990885853767395, "entropy": 0.6114558180173238, "incre_win_rate": 0.5849056603773585, "step": 116}
{"time": 1766663323.7578218, "phase": "train", "update": 117, "total_env_steps": 374400, "episode_reward": 0.25736597180366516, "value_loss": 0.027208689972758292, "policy_loss": -0.012063851051439064, "dist_entropy": 0.6325766166051229, "actor_grad_norm": 0.18607072532176971, "critic_grad_norm": 0.07657665759325027, "ratio": 1.0000834465026855, "entropy": 0.6325766166051229, "incre_win_rate": 0.5, "step": 117}
{"time": 1766663327.9158728, "phase": "train", "update": 118, "total_env_steps": 377600, "episode_reward": 0.261082261800766, "value_loss": 0.022913123046358428, "policy_loss": -0.011089876285504847, "dist_entropy": 0.625433353583018, "actor_grad_norm": 0.1682237982749939, "critic_grad_norm": 0.04180632904171944, "ratio": 0.9990424513816833, "entropy": 0.625433353583018, "incre_win_rate": 0.42, "step": 118}
{"time": 1766663332.1685445, "phase": "train", "update": 119, "total_env_steps": 380800, "episode_reward": 0.2767876982688904, "value_loss": 0.024096967900792757, "policy_loss": -0.011703570967140269, "dist_entropy": 0.6485576232274374, "actor_grad_norm": 0.1709173023700714, "critic_grad_norm": 0.041342705488204956, "ratio": 0.99977046251297, "entropy": 0.6485576232274374, "incre_win_rate": 0.49019607843137253, "step": 119}
{"time": 1766663336.300699, "phase": "train", "update": 120, "total_env_steps": 384000, "episode_reward": 0.2414177507162094, "value_loss": 0.025890294834971427, "policy_loss": -0.011815707546399778, "dist_entropy": 0.6589164058367412, "actor_grad_norm": 0.18752680718898773, "critic_grad_norm": 0.0986652746796608, "ratio": 1.0001132488250732, "entropy": 0.6589164058367412, "incre_win_rate": 0.3541666666666667, "step": 120}
{"time": 1766663340.5905325, "phase": "train", "update": 121, "total_env_steps": 387200, "episode_reward": 0.27444392442703247, "value_loss": 0.023775425429145496, "policy_loss": -0.01006188338339058, "dist_entropy": 0.6138074278831482, "actor_grad_norm": 0.17267628014087677, "critic_grad_norm": 0.061788544058799744, "ratio": 0.9992702603340149, "entropy": 0.6138074278831482, "incre_win_rate": 0.49056603773584906, "step": 121}
{"time": 1766663348.2686234, "phase": "eval", "update": 121, "total_env_steps": 387200, "eval_win_rate": 0.75, "eval_episode_reward": 18.418811274509807, "step": 121}
{"time": 1766663352.6016629, "phase": "train", "update": 122, "total_env_steps": 390400, "episode_reward": 0.2711688280105591, "value_loss": 0.027934252470731735, "policy_loss": -0.010399315359299522, "dist_entropy": 0.6030245423316956, "actor_grad_norm": 0.1944773644208908, "critic_grad_norm": 0.047144100069999695, "ratio": 0.9995397329330444, "entropy": 0.6030245423316956, "incre_win_rate": 0.4117647058823529, "step": 122}
{"time": 1766663356.8037035, "phase": "train", "update": 123, "total_env_steps": 393600, "episode_reward": 0.29878368973731995, "value_loss": 0.023618042469024658, "policy_loss": -0.010709588942277826, "dist_entropy": 0.6221967657407125, "actor_grad_norm": 0.24276597797870636, "critic_grad_norm": 0.13421401381492615, "ratio": 0.9995555877685547, "entropy": 0.6221967657407125, "incre_win_rate": 0.6415094339622641, "step": 123}
{"time": 1766663361.0621815, "phase": "train", "update": 124, "total_env_steps": 396800, "episode_reward": 0.25951364636421204, "value_loss": 0.031542303040623665, "policy_loss": -0.010514374060285074, "dist_entropy": 0.6102708498636882, "actor_grad_norm": 0.2424178570508957, "critic_grad_norm": 0.13075873255729675, "ratio": 0.9987587928771973, "entropy": 0.6102708498636882, "incre_win_rate": 0.38461538461538464, "step": 124}
{"time": 1766663365.2863922, "phase": "train", "update": 125, "total_env_steps": 400000, "episode_reward": 0.2786588668823242, "value_loss": 0.02975063237051169, "policy_loss": -0.009578737064292337, "dist_entropy": 0.6009244243303935, "actor_grad_norm": 0.22154274582862854, "critic_grad_norm": 0.12768396735191345, "ratio": 0.9998688697814941, "entropy": 0.6009244243303935, "incre_win_rate": 0.5, "step": 125}
{"time": 1766663369.7244585, "phase": "train", "update": 126, "total_env_steps": 403200, "episode_reward": 0.2827880084514618, "value_loss": 0.024538866057991982, "policy_loss": -0.010409729815386962, "dist_entropy": 0.5981474637985229, "actor_grad_norm": 0.24311451613903046, "critic_grad_norm": 0.05678384751081467, "ratio": 1.0000543594360352, "entropy": 0.5981474637985229, "incre_win_rate": 0.5098039215686274, "step": 126}
{"time": 1766663374.001105, "phase": "train", "update": 127, "total_env_steps": 406400, "episode_reward": 0.29467064142227173, "value_loss": 0.03122680845359961, "policy_loss": -0.010844140784476035, "dist_entropy": 0.585646124680837, "actor_grad_norm": 0.20505110919475555, "critic_grad_norm": 0.06603348255157471, "ratio": 0.9995916485786438, "entropy": 0.585646124680837, "incre_win_rate": 0.5263157894736842, "step": 127}
{"time": 1766663378.2410512, "phase": "train", "update": 128, "total_env_steps": 409600, "episode_reward": 0.2902841866016388, "value_loss": 0.027816365907589593, "policy_loss": -0.010465223285366676, "dist_entropy": 0.6009669740994771, "actor_grad_norm": 0.17093808948993683, "critic_grad_norm": 0.036868609488010406, "ratio": 0.999422550201416, "entropy": 0.6009669740994771, "incre_win_rate": 0.48214285714285715, "step": 128}
{"time": 1766663382.546776, "phase": "train", "update": 129, "total_env_steps": 412800, "episode_reward": 0.2958555221557617, "value_loss": 0.028967681154608727, "policy_loss": -0.010984209245317325, "dist_entropy": 0.6184414505958558, "actor_grad_norm": 0.18707288801670074, "critic_grad_norm": 0.06697176396846771, "ratio": 0.9979710578918457, "entropy": 0.6184414505958558, "incre_win_rate": 0.5, "step": 129}
{"time": 1766663386.7277927, "phase": "train", "update": 130, "total_env_steps": 416000, "episode_reward": 0.2782552242279053, "value_loss": 0.03205365277826786, "policy_loss": -0.011641646711055624, "dist_entropy": 0.6196072340011597, "actor_grad_norm": 0.16719579696655273, "critic_grad_norm": 0.04302347078919411, "ratio": 1.0006277561187744, "entropy": 0.6196072340011597, "incre_win_rate": 0.41818181818181815, "step": 130}
{"time": 1766663390.959487, "phase": "train", "update": 131, "total_env_steps": 419200, "episode_reward": 0.2900375425815582, "value_loss": 0.025827789306640626, "policy_loss": -0.010907337335438664, "dist_entropy": 0.6079710324605306, "actor_grad_norm": 0.1629217267036438, "critic_grad_norm": 0.058064788579940796, "ratio": 1.000311255455017, "entropy": 0.6079710324605306, "incre_win_rate": 0.5272727272727272, "step": 131}
{"time": 1766663395.133858, "phase": "train", "update": 132, "total_env_steps": 422400, "episode_reward": 0.27732232213020325, "value_loss": 0.024322377145290376, "policy_loss": -0.011425467186707767, "dist_entropy": 0.6016743222872416, "actor_grad_norm": 0.18353575468063354, "critic_grad_norm": 0.04229794070124626, "ratio": 0.9993080496788025, "entropy": 0.6016743222872416, "incre_win_rate": 0.49056603773584906, "step": 132}
{"time": 1766663399.361817, "phase": "train", "update": 133, "total_env_steps": 425600, "episode_reward": 0.3053845167160034, "value_loss": 0.027387097105383874, "policy_loss": -0.011038458806061632, "dist_entropy": 0.5881323138872783, "actor_grad_norm": 0.21732483804225922, "critic_grad_norm": 0.031043406575918198, "ratio": 0.998896598815918, "entropy": 0.5881323138872783, "incre_win_rate": 0.5818181818181818, "step": 133}
{"time": 1766663403.650413, "phase": "train", "update": 134, "total_env_steps": 428800, "episode_reward": 0.3020327687263489, "value_loss": 0.022846215094129246, "policy_loss": -0.01094097072283732, "dist_entropy": 0.5957205692927042, "actor_grad_norm": 0.18766172230243683, "critic_grad_norm": 0.05434008315205574, "ratio": 1.0003318786621094, "entropy": 0.5957205692927042, "incre_win_rate": 0.6296296296296297, "step": 134}
{"time": 1766663407.8938704, "phase": "train", "update": 135, "total_env_steps": 432000, "episode_reward": 0.2874578833580017, "value_loss": 0.02052731973429521, "policy_loss": -0.011631077885337031, "dist_entropy": 0.6274049838383993, "actor_grad_norm": 0.15647253394126892, "critic_grad_norm": 0.05679212138056755, "ratio": 0.998622715473175, "entropy": 0.6274049838383993, "incre_win_rate": 0.44642857142857145, "step": 135}
{"time": 1766663412.2123077, "phase": "train", "update": 136, "total_env_steps": 435200, "episode_reward": 0.28998851776123047, "value_loss": 0.02554975983997186, "policy_loss": -0.010821186798362702, "dist_entropy": 0.6497949004173279, "actor_grad_norm": 0.24691297113895416, "critic_grad_norm": 0.0739007294178009, "ratio": 0.9990851879119873, "entropy": 0.6497949004173279, "incre_win_rate": 0.6111111111111112, "step": 136}
{"time": 1766663416.4077349, "phase": "train", "update": 137, "total_env_steps": 438400, "episode_reward": 0.2805943489074707, "value_loss": 0.025613182658950486, "policy_loss": -0.01066669920856403, "dist_entropy": 0.5984625538190206, "actor_grad_norm": 0.22938774526119232, "critic_grad_norm": 0.039028070867061615, "ratio": 1.0001723766326904, "entropy": 0.5984625538190206, "incre_win_rate": 0.52, "step": 137}
{"time": 1766663420.6031816, "phase": "train", "update": 138, "total_env_steps": 441600, "episode_reward": 0.2752833962440491, "value_loss": 0.020047191406289737, "policy_loss": -0.011392061366549673, "dist_entropy": 0.6206087112426758, "actor_grad_norm": 0.1776256263256073, "critic_grad_norm": 0.07022235542535782, "ratio": 0.9990823268890381, "entropy": 0.6206087112426758, "incre_win_rate": 0.6, "step": 138}
{"time": 1766663424.8972542, "phase": "train", "update": 139, "total_env_steps": 444800, "episode_reward": 0.29474878311157227, "value_loss": 0.026447175691525143, "policy_loss": -0.011023599786100628, "dist_entropy": 0.602520779768626, "actor_grad_norm": 0.17328603565692902, "critic_grad_norm": 0.18524259328842163, "ratio": 0.9995601773262024, "entropy": 0.602520779768626, "incre_win_rate": 0.5178571428571429, "step": 139}
{"time": 1766663429.1238875, "phase": "train", "update": 140, "total_env_steps": 448000, "episode_reward": 0.31115424633026123, "value_loss": 0.024808535476525624, "policy_loss": -0.01098941516581533, "dist_entropy": 0.5991725325584412, "actor_grad_norm": 0.19704855978488922, "critic_grad_norm": 0.07321175932884216, "ratio": 0.998807430267334, "entropy": 0.5991725325584412, "incre_win_rate": 0.625, "step": 140}
{"time": 1766663433.376658, "phase": "train", "update": 141, "total_env_steps": 451200, "episode_reward": 0.28771519660949707, "value_loss": 0.025421121343970298, "policy_loss": -0.011273709794355113, "dist_entropy": 0.6025911053021749, "actor_grad_norm": 0.16622081398963928, "critic_grad_norm": 0.03168533742427826, "ratio": 1.0011391639709473, "entropy": 0.6025911053021749, "incre_win_rate": 0.5, "step": 141}
{"time": 1766663440.7981727, "phase": "eval", "update": 141, "total_env_steps": 451200, "eval_win_rate": 0.8125, "eval_episode_reward": 18.755361519607845, "step": 141}
{"time": 1766663445.0586915, "phase": "train", "update": 142, "total_env_steps": 454400, "episode_reward": 0.2858547866344452, "value_loss": 0.02896992601454258, "policy_loss": -0.011443213001207415, "dist_entropy": 0.6306113958358764, "actor_grad_norm": 0.2427317053079605, "critic_grad_norm": 0.04015874117612839, "ratio": 0.9991336464881897, "entropy": 0.6306113958358764, "incre_win_rate": 0.5740740740740741, "step": 142}
{"time": 1766663449.3150449, "phase": "train", "update": 143, "total_env_steps": 457600, "episode_reward": 0.29891544580459595, "value_loss": 0.023239940901597343, "policy_loss": -0.01125871847555923, "dist_entropy": 0.610788893699646, "actor_grad_norm": 0.17728467285633087, "critic_grad_norm": 0.044970814138650894, "ratio": 0.9985902905464172, "entropy": 0.610788893699646, "incre_win_rate": 0.6, "step": 143}
{"time": 1766663453.579232, "phase": "train", "update": 144, "total_env_steps": 460800, "episode_reward": 0.3046354353427887, "value_loss": 0.02285003401339054, "policy_loss": -0.010981772809554613, "dist_entropy": 0.624826447168986, "actor_grad_norm": 0.14986652135849, "critic_grad_norm": 0.0892387107014656, "ratio": 0.9991946220397949, "entropy": 0.624826447168986, "incre_win_rate": 0.6981132075471698, "step": 144}
{"time": 1766663457.8248777, "phase": "train", "update": 145, "total_env_steps": 464000, "episode_reward": 0.2926202416419983, "value_loss": 0.024473941574494045, "policy_loss": -0.010918244486258761, "dist_entropy": 0.6244738340377808, "actor_grad_norm": 0.17327705025672913, "critic_grad_norm": 0.10853630304336548, "ratio": 1.000548005104065, "entropy": 0.6244738340377808, "incre_win_rate": 0.48214285714285715, "step": 145}
{"time": 1766663462.0430224, "phase": "train", "update": 146, "total_env_steps": 467200, "episode_reward": 0.2725321650505066, "value_loss": 0.02576660600801309, "policy_loss": -0.012161111685162495, "dist_entropy": 0.6096769293149312, "actor_grad_norm": 0.1784127801656723, "critic_grad_norm": 0.11532334238290787, "ratio": 0.9999427795410156, "entropy": 0.6096769293149312, "incre_win_rate": 0.46, "step": 146}
{"time": 1766663466.3020782, "phase": "train", "update": 147, "total_env_steps": 470400, "episode_reward": 0.28991958498954773, "value_loss": 0.026436415935556092, "policy_loss": -0.01042407146509774, "dist_entropy": 0.6188207070032755, "actor_grad_norm": 0.17847904562950134, "critic_grad_norm": 0.037813398987054825, "ratio": 0.9987890720367432, "entropy": 0.6188207070032755, "incre_win_rate": 0.43859649122807015, "step": 147}
{"time": 1766663470.4888003, "phase": "train", "update": 148, "total_env_steps": 473600, "episode_reward": 0.28238433599472046, "value_loss": 0.02270659034450849, "policy_loss": -0.011670004595486698, "dist_entropy": 0.6412912050882975, "actor_grad_norm": 0.2525685131549835, "critic_grad_norm": 0.06844507902860641, "ratio": 0.99899822473526, "entropy": 0.6412912050882975, "incre_win_rate": 0.46153846153846156, "step": 148}
{"time": 1766663474.7327614, "phase": "train", "update": 149, "total_env_steps": 476800, "episode_reward": 0.2965249717235565, "value_loss": 0.024334604168931642, "policy_loss": -0.011772461247165111, "dist_entropy": 0.6156388799349467, "actor_grad_norm": 0.20851436257362366, "critic_grad_norm": 0.04152873903512955, "ratio": 1.0002989768981934, "entropy": 0.6156388799349467, "incre_win_rate": 0.5454545454545454, "step": 149}
{"time": 1766663478.9720008, "phase": "train", "update": 150, "total_env_steps": 480000, "episode_reward": 0.29733148217201233, "value_loss": 0.02000291533768177, "policy_loss": -0.01180051857655385, "dist_entropy": 0.6398779114087423, "actor_grad_norm": 0.15099230408668518, "critic_grad_norm": 0.05704346299171448, "ratio": 0.9992847442626953, "entropy": 0.6398779114087423, "incre_win_rate": 0.6071428571428571, "step": 150}
{"time": 1766663483.2468472, "phase": "train", "update": 151, "total_env_steps": 483200, "episode_reward": 0.2749287784099579, "value_loss": 0.023509934296210608, "policy_loss": -0.0121581520362439, "dist_entropy": 0.615685760974884, "actor_grad_norm": 0.17815043032169342, "critic_grad_norm": 0.14287133514881134, "ratio": 0.9993615746498108, "entropy": 0.615685760974884, "incre_win_rate": 0.41509433962264153, "step": 151}
{"time": 1766663487.4522753, "phase": "train", "update": 152, "total_env_steps": 486400, "episode_reward": 0.2819339632987976, "value_loss": 0.02374160885810852, "policy_loss": -0.012335239268753639, "dist_entropy": 0.6490111708641052, "actor_grad_norm": 0.2177330106496811, "critic_grad_norm": 0.06155913695693016, "ratio": 0.9993818998336792, "entropy": 0.6490111708641052, "incre_win_rate": 0.5185185185185185, "step": 152}
{"time": 1766663491.6806078, "phase": "train", "update": 153, "total_env_steps": 489600, "episode_reward": 0.29774972796440125, "value_loss": 0.024874976153175035, "policy_loss": -0.01190483913974134, "dist_entropy": 0.5920918663342793, "actor_grad_norm": 0.1884259134531021, "critic_grad_norm": 0.03763524815440178, "ratio": 0.9982990622520447, "entropy": 0.5920918663342793, "incre_win_rate": 0.4642857142857143, "step": 153}
{"time": 1766663495.9824998, "phase": "train", "update": 154, "total_env_steps": 492800, "episode_reward": 0.3004166781902313, "value_loss": 0.023604155580202738, "policy_loss": -0.011498116612449394, "dist_entropy": 0.6192072788874309, "actor_grad_norm": 0.16621561348438263, "critic_grad_norm": 0.04429294168949127, "ratio": 0.9996507167816162, "entropy": 0.6192072788874309, "incre_win_rate": 0.5636363636363636, "step": 154}
{"time": 1766663500.2134688, "phase": "train", "update": 155, "total_env_steps": 496000, "episode_reward": 0.29283013939857483, "value_loss": 0.02583538753290971, "policy_loss": -0.01213933185862288, "dist_entropy": 0.6132716099421184, "actor_grad_norm": 0.22885139286518097, "critic_grad_norm": 0.03323707729578018, "ratio": 0.9984105229377747, "entropy": 0.6132716099421184, "incre_win_rate": 0.5087719298245614, "step": 155}
{"time": 1766663504.5118413, "phase": "train", "update": 156, "total_env_steps": 499200, "episode_reward": 0.3096117079257965, "value_loss": 0.020492241407434147, "policy_loss": -0.011281919707158512, "dist_entropy": 0.6156899412473043, "actor_grad_norm": 0.1565166562795639, "critic_grad_norm": 0.11704542487859726, "ratio": 0.9989124536514282, "entropy": 0.6156899412473043, "incre_win_rate": 0.5818181818181818, "step": 156}
{"time": 1766663508.7661371, "phase": "train", "update": 157, "total_env_steps": 502400, "episode_reward": 0.27541741728782654, "value_loss": 0.024705787127216657, "policy_loss": -0.011483847239549405, "dist_entropy": 0.6463685909907023, "actor_grad_norm": 0.1640227735042572, "critic_grad_norm": 0.08456713706254959, "ratio": 0.999154806137085, "entropy": 0.6463685909907023, "incre_win_rate": 0.4528301886792453, "step": 157}
{"time": 1766663512.963898, "phase": "train", "update": 158, "total_env_steps": 505600, "episode_reward": 0.2883310616016388, "value_loss": 0.021460115909576416, "policy_loss": -0.0123411024102919, "dist_entropy": 0.6254272937774659, "actor_grad_norm": 0.15941159427165985, "critic_grad_norm": 0.06925065070390701, "ratio": 0.9982206225395203, "entropy": 0.6254272937774659, "incre_win_rate": 0.5740740740740741, "step": 158}
{"time": 1766663517.2837791, "phase": "train", "update": 159, "total_env_steps": 508800, "episode_reward": 0.28850415349006653, "value_loss": 0.020619110390543937, "policy_loss": -0.011902360426539834, "dist_entropy": 0.6182665983835857, "actor_grad_norm": 0.17894406616687775, "critic_grad_norm": 0.04408997669816017, "ratio": 0.9982892870903015, "entropy": 0.6182665983835857, "incre_win_rate": 0.5555555555555556, "step": 159}
{"time": 1766663521.5134292, "phase": "train", "update": 160, "total_env_steps": 512000, "episode_reward": 0.28135034441947937, "value_loss": 0.02431097663938999, "policy_loss": -0.011544507718960102, "dist_entropy": 0.6128232638041179, "actor_grad_norm": 0.18861131370067596, "critic_grad_norm": 0.029125463217496872, "ratio": 0.9986105561256409, "entropy": 0.6128232638041179, "incre_win_rate": 0.5, "step": 160}
{"time": 1766663526.077243, "phase": "train", "update": 161, "total_env_steps": 515200, "episode_reward": 0.2905943691730499, "value_loss": 0.019926094139615696, "policy_loss": -0.010896673213689211, "dist_entropy": 0.6181503971417744, "actor_grad_norm": 0.16963762044906616, "critic_grad_norm": 0.03138817474246025, "ratio": 1.0004380941390991, "entropy": 0.6181503971417744, "incre_win_rate": 0.5660377358490566, "step": 161}
{"time": 1766663534.221756, "phase": "eval", "update": 161, "total_env_steps": 515200, "eval_win_rate": 0.625, "eval_episode_reward": 17.71484375, "step": 161}
{"time": 1766663538.6320662, "phase": "train", "update": 162, "total_env_steps": 518400, "episode_reward": 0.2684359848499298, "value_loss": 0.026614854236443837, "policy_loss": -0.01152848202933588, "dist_entropy": 0.5982630530993144, "actor_grad_norm": 0.19670574367046356, "critic_grad_norm": 0.07876676321029663, "ratio": 1.0008732080459595, "entropy": 0.5982630530993144, "incre_win_rate": 0.4117647058823529, "step": 162}
{"time": 1766663543.18441, "phase": "train", "update": 163, "total_env_steps": 521600, "episode_reward": 0.3086734414100647, "value_loss": 0.022601606821020446, "policy_loss": -0.011106259866361748, "dist_entropy": 0.6125109354654948, "actor_grad_norm": 0.15972891449928284, "critic_grad_norm": 0.15937000513076782, "ratio": 0.9984232187271118, "entropy": 0.6125109354654948, "incre_win_rate": 0.625, "step": 163}
{"time": 1766663578.369635, "phase": "train", "update": 164, "total_env_steps": 524800, "episode_reward": 0.2729281485080719, "value_loss": 0.056156713018814725, "policy_loss": -0.010549384440050364, "dist_entropy": 0.6069512883822124, "actor_grad_norm": 0.16757355630397797, "critic_grad_norm": 0.2969798445701599, "ratio": 1.0012030601501465, "entropy": 0.6069512883822124, "incre_win_rate": 0.4166666666666667, "step": 164}
{"time": 1766663582.6786876, "phase": "train", "update": 165, "total_env_steps": 528000, "episode_reward": 0.2911626994609833, "value_loss": 0.027340007325013477, "policy_loss": -0.011657412808199296, "dist_entropy": 0.6206145882606506, "actor_grad_norm": 0.18896441161632538, "critic_grad_norm": 0.10800928622484207, "ratio": 1.0003559589385986, "entropy": 0.6206145882606506, "incre_win_rate": 0.4909090909090909, "step": 165}
{"time": 1766663586.9020433, "phase": "train", "update": 166, "total_env_steps": 531200, "episode_reward": 0.2723621129989624, "value_loss": 0.024370919416348138, "policy_loss": -0.012512451460185847, "dist_entropy": 0.6362022717793783, "actor_grad_norm": 0.17683111131191254, "critic_grad_norm": 0.07241843640804291, "ratio": 0.9995723366737366, "entropy": 0.6362022717793783, "incre_win_rate": 0.49056603773584906, "step": 166}
{"time": 1766663591.3118308, "phase": "train", "update": 167, "total_env_steps": 534400, "episode_reward": 0.29161688685417175, "value_loss": 0.024449204901854198, "policy_loss": -0.011313372656376448, "dist_entropy": 0.6093832492828369, "actor_grad_norm": 0.19052882492542267, "critic_grad_norm": 0.12194889783859253, "ratio": 0.9989778995513916, "entropy": 0.6093832492828369, "incre_win_rate": 0.5769230769230769, "step": 167}
{"time": 1766663595.7057855, "phase": "train", "update": 168, "total_env_steps": 537600, "episode_reward": 0.30265626311302185, "value_loss": 0.026179901386300723, "policy_loss": -0.010971861080111011, "dist_entropy": 0.6215254147847493, "actor_grad_norm": 0.1874859631061554, "critic_grad_norm": 0.06807748973369598, "ratio": 0.9987841844558716, "entropy": 0.6215254147847493, "incre_win_rate": 0.5862068965517241, "step": 168}
{"time": 1766663599.8863423, "phase": "train", "update": 169, "total_env_steps": 540800, "episode_reward": 0.2909497618675232, "value_loss": 0.02378599395354589, "policy_loss": -0.012039546516234623, "dist_entropy": 0.6311497410138448, "actor_grad_norm": 0.2155652642250061, "critic_grad_norm": 0.05090876668691635, "ratio": 1.0001776218414307, "entropy": 0.6311497410138448, "incre_win_rate": 0.6153846153846154, "step": 169}
{"time": 1766663604.0990288, "phase": "train", "update": 170, "total_env_steps": 544000, "episode_reward": 0.30441558361053467, "value_loss": 0.021299355725447337, "policy_loss": -0.010727708038318913, "dist_entropy": 0.6070656617482503, "actor_grad_norm": 0.22945787012577057, "critic_grad_norm": 0.03153962641954422, "ratio": 1.0001819133758545, "entropy": 0.6070656617482503, "incre_win_rate": 0.6181818181818182, "step": 170}
{"time": 1766663608.3508441, "phase": "train", "update": 171, "total_env_steps": 547200, "episode_reward": 0.28378522396087646, "value_loss": 0.020424301673968633, "policy_loss": -0.011652325881229568, "dist_entropy": 0.6236084620157878, "actor_grad_norm": 0.15702912211418152, "critic_grad_norm": 0.02916575036942959, "ratio": 0.9988259077072144, "entropy": 0.6236084620157878, "incre_win_rate": 0.5660377358490566, "step": 171}
{"time": 1766663612.5446274, "phase": "train", "update": 172, "total_env_steps": 550400, "episode_reward": 0.2897847890853882, "value_loss": 0.02377659479777018, "policy_loss": -0.01229939275504582, "dist_entropy": 0.6264211098353069, "actor_grad_norm": 0.209283709526062, "critic_grad_norm": 0.026389043778181076, "ratio": 1.0004631280899048, "entropy": 0.6264211098353069, "incre_win_rate": 0.5454545454545454, "step": 172}
{"time": 1766663616.8550727, "phase": "train", "update": 173, "total_env_steps": 553600, "episode_reward": 0.3029932677745819, "value_loss": 0.028712837646404903, "policy_loss": -0.011368275964642294, "dist_entropy": 0.6218347628911336, "actor_grad_norm": 0.18485775589942932, "critic_grad_norm": 0.03417843580245972, "ratio": 0.9994681477546692, "entropy": 0.6218347628911336, "incre_win_rate": 0.6, "step": 173}
{"time": 1766663621.0975358, "phase": "train", "update": 174, "total_env_steps": 556800, "episode_reward": 0.28794652223587036, "value_loss": 0.025641414647301037, "policy_loss": -0.012546997224654532, "dist_entropy": 0.62612357934316, "actor_grad_norm": 0.17618206143379211, "critic_grad_norm": 0.05944551154971123, "ratio": 0.9988642930984497, "entropy": 0.62612357934316, "incre_win_rate": 0.4528301886792453, "step": 174}
{"time": 1766663625.3392432, "phase": "train", "update": 175, "total_env_steps": 560000, "episode_reward": 0.2900773584842682, "value_loss": 0.02807604099313418, "policy_loss": -0.011815491280724188, "dist_entropy": 0.6453520655632019, "actor_grad_norm": 0.152234748005867, "critic_grad_norm": 0.05483463034033775, "ratio": 1.0000674724578857, "entropy": 0.6453520655632019, "incre_win_rate": 0.5925925925925926, "step": 175}
{"time": 1766663629.5297697, "phase": "train", "update": 176, "total_env_steps": 563200, "episode_reward": 0.2694355249404907, "value_loss": 0.028008819992343583, "policy_loss": -0.011801343404808524, "dist_entropy": 0.6364583293596904, "actor_grad_norm": 0.20289579033851624, "critic_grad_norm": 0.09820057451725006, "ratio": 0.9996747374534607, "entropy": 0.6364583293596904, "incre_win_rate": 0.4716981132075472, "step": 176}
{"time": 1766663633.7402246, "phase": "train", "update": 177, "total_env_steps": 566400, "episode_reward": 0.289002001285553, "value_loss": 0.023688872655232746, "policy_loss": -0.011568214713972846, "dist_entropy": 0.6100118120511373, "actor_grad_norm": 0.29031816124916077, "critic_grad_norm": 0.03692888468503952, "ratio": 0.9994283318519592, "entropy": 0.6100118120511373, "incre_win_rate": 0.46296296296296297, "step": 177}
{"time": 1766663637.9948328, "phase": "train", "update": 178, "total_env_steps": 569600, "episode_reward": 0.29637330770492554, "value_loss": 0.019845375046133994, "policy_loss": -0.012147669014258611, "dist_entropy": 0.645029628276825, "actor_grad_norm": 0.17122027277946472, "critic_grad_norm": 0.12535424530506134, "ratio": 0.9997751712799072, "entropy": 0.645029628276825, "incre_win_rate": 0.6538461538461539, "step": 178}
{"time": 1766663642.2607207, "phase": "train", "update": 179, "total_env_steps": 572800, "episode_reward": 0.28414368629455566, "value_loss": 0.02202575293680032, "policy_loss": -0.010973104716460114, "dist_entropy": 0.6094324469566346, "actor_grad_norm": 0.21394817531108856, "critic_grad_norm": 0.0765298455953598, "ratio": 0.9995211958885193, "entropy": 0.6094324469566346, "incre_win_rate": 0.5370370370370371, "step": 179}
{"time": 1766663646.5056965, "phase": "train", "update": 180, "total_env_steps": 576000, "episode_reward": 0.27484530210494995, "value_loss": 0.022029364109039308, "policy_loss": -0.013191777427863371, "dist_entropy": 0.6617814779281617, "actor_grad_norm": 0.20619021356105804, "critic_grad_norm": 0.025048747658729553, "ratio": 0.9988231658935547, "entropy": 0.6617814779281617, "incre_win_rate": 0.4807692307692308, "step": 180}
{"time": 1766663650.698181, "phase": "train", "update": 181, "total_env_steps": 579200, "episode_reward": 0.29672718048095703, "value_loss": 0.022444038838148116, "policy_loss": -0.011120204276311203, "dist_entropy": 0.6140435973803202, "actor_grad_norm": 0.19829373061656952, "critic_grad_norm": 0.03768208250403404, "ratio": 0.9992941617965698, "entropy": 0.6140435973803202, "incre_win_rate": 0.5555555555555556, "step": 181}
{"time": 1766663657.811244, "phase": "eval", "update": 181, "total_env_steps": 579200, "eval_win_rate": 0.71875, "eval_episode_reward": 18.084022671568626, "step": 181}
{"time": 1766663662.0233774, "phase": "train", "update": 182, "total_env_steps": 582400, "episode_reward": 0.29283013939857483, "value_loss": 0.023893304045001666, "policy_loss": -0.011493024219633696, "dist_entropy": 0.6261593103408813, "actor_grad_norm": 0.1834048479795456, "critic_grad_norm": 0.03835740312933922, "ratio": 1.0001498460769653, "entropy": 0.6261593103408813, "incre_win_rate": 0.5357142857142857, "step": 182}
{"time": 1766663666.3158243, "phase": "train", "update": 183, "total_env_steps": 585600, "episode_reward": 0.3096400201320648, "value_loss": 0.024149469286203384, "policy_loss": -0.01075703694865524, "dist_entropy": 0.6345157384872436, "actor_grad_norm": 0.19444864988327026, "critic_grad_norm": 0.054930783808231354, "ratio": 0.9993507862091064, "entropy": 0.6345157384872436, "incre_win_rate": 0.6666666666666666, "step": 183}
{"time": 1766663670.5898373, "phase": "train", "update": 184, "total_env_steps": 588800, "episode_reward": 0.28510722517967224, "value_loss": 0.021040329709649086, "policy_loss": -0.011569423011523364, "dist_entropy": 0.6421552737553914, "actor_grad_norm": 0.20058980584144592, "critic_grad_norm": 0.05904232710599899, "ratio": 1.0001909732818604, "entropy": 0.6421552737553914, "incre_win_rate": 0.5370370370370371, "step": 184}
{"time": 1766663674.8278065, "phase": "train", "update": 185, "total_env_steps": 592000, "episode_reward": 0.2948146462440491, "value_loss": 0.026541365683078764, "policy_loss": -0.012610273765834753, "dist_entropy": 0.6306298057238261, "actor_grad_norm": 0.1832195222377777, "critic_grad_norm": 0.051998913288116455, "ratio": 1.0008602142333984, "entropy": 0.6306298057238261, "incre_win_rate": 0.5961538461538461, "step": 185}
{"time": 1766663679.1452472, "phase": "train", "update": 186, "total_env_steps": 595200, "episode_reward": 0.289194256067276, "value_loss": 0.02527966412405173, "policy_loss": -0.012167427687788054, "dist_entropy": 0.6181135972340902, "actor_grad_norm": 0.23102302849292755, "critic_grad_norm": 0.05096745118498802, "ratio": 0.9996803998947144, "entropy": 0.6181135972340902, "incre_win_rate": 0.5185185185185185, "step": 186}
{"time": 1766663683.3625772, "phase": "train", "update": 187, "total_env_steps": 598400, "episode_reward": 0.28776654601097107, "value_loss": 0.025955296183625857, "policy_loss": -0.013034363276660344, "dist_entropy": 0.6239853024482727, "actor_grad_norm": 0.21515192091464996, "critic_grad_norm": 0.10649538785219193, "ratio": 0.9991006255149841, "entropy": 0.6239853024482727, "incre_win_rate": 0.509090909090909, "step": 187}
{"time": 1766663687.7056737, "phase": "train", "update": 188, "total_env_steps": 601600, "episode_reward": 0.2763564884662628, "value_loss": 0.027818760027488072, "policy_loss": -0.012484600089963275, "dist_entropy": 0.6423007686932881, "actor_grad_norm": 0.18249192833900452, "critic_grad_norm": 0.071901336312294, "ratio": 0.9998152852058411, "entropy": 0.6423007686932881, "incre_win_rate": 0.48148148148148145, "step": 188}
{"time": 1766663691.9399571, "phase": "train", "update": 189, "total_env_steps": 604800, "episode_reward": 0.2856525778770447, "value_loss": 0.017858430246512094, "policy_loss": -0.011697430237985884, "dist_entropy": 0.6190973917643229, "actor_grad_norm": 0.16830840706825256, "critic_grad_norm": 0.0384061224758625, "ratio": 0.9991104006767273, "entropy": 0.6190973917643229, "incre_win_rate": 0.6, "step": 189}
{"time": 1766663696.1866527, "phase": "train", "update": 190, "total_env_steps": 608000, "episode_reward": 0.3022572100162506, "value_loss": 0.02473637300233046, "policy_loss": -0.010782504417872001, "dist_entropy": 0.6506109992663066, "actor_grad_norm": 0.17239055037498474, "critic_grad_norm": 0.06937714666128159, "ratio": 0.9998781085014343, "entropy": 0.6506109992663066, "incre_win_rate": 0.6545454545454545, "step": 190}
{"time": 1766663700.5363576, "phase": "train", "update": 191, "total_env_steps": 611200, "episode_reward": 0.2946576476097107, "value_loss": 0.022831880673766135, "policy_loss": -0.013245939283196624, "dist_entropy": 0.6314891775449117, "actor_grad_norm": 0.17983640730381012, "critic_grad_norm": 0.0511237308382988, "ratio": 0.9994421601295471, "entropy": 0.6314891775449117, "incre_win_rate": 0.5272727272727272, "step": 191}
{"time": 1766663705.1991334, "phase": "train", "update": 192, "total_env_steps": 614400, "episode_reward": 0.29238665103912354, "value_loss": 0.02115369898577531, "policy_loss": -0.011035152137954984, "dist_entropy": 0.6358595569928487, "actor_grad_norm": 0.20348738133907318, "critic_grad_norm": 0.04505264014005661, "ratio": 1.0003619194030762, "entropy": 0.6358595569928487, "incre_win_rate": 0.5660377358490566, "step": 192}
{"time": 1766663709.758641, "phase": "train", "update": 193, "total_env_steps": 617600, "episode_reward": 0.3093627393245697, "value_loss": 0.021445213009913762, "policy_loss": -0.01134053602619307, "dist_entropy": 0.6258728543917338, "actor_grad_norm": 0.21103152632713318, "critic_grad_norm": 0.13418401777744293, "ratio": 0.999804675579071, "entropy": 0.6258728543917338, "incre_win_rate": 0.6909090909090909, "step": 193}
{"time": 1766663714.0935028, "phase": "train", "update": 194, "total_env_steps": 620800, "episode_reward": 0.27355697751045227, "value_loss": 0.02394278993209203, "policy_loss": -0.013253206248636691, "dist_entropy": 0.6363222002983093, "actor_grad_norm": 0.177534818649292, "critic_grad_norm": 0.07171676307916641, "ratio": 0.9972833395004272, "entropy": 0.6363222002983093, "incre_win_rate": 0.5102040816326531, "step": 194}
{"time": 1766663718.647096, "phase": "train", "update": 195, "total_env_steps": 624000, "episode_reward": 0.28110140562057495, "value_loss": 0.02080068439245224, "policy_loss": -0.012820823801301154, "dist_entropy": 0.6140550255775452, "actor_grad_norm": 0.2124386429786682, "critic_grad_norm": 0.05173105746507645, "ratio": 1.0003267526626587, "entropy": 0.6140550255775452, "incre_win_rate": 0.5098039215686274, "step": 195}
{"time": 1766663723.1625526, "phase": "train", "update": 196, "total_env_steps": 627200, "episode_reward": 0.3038756251335144, "value_loss": 0.018733014290531477, "policy_loss": -0.011765739474973695, "dist_entropy": 0.6259071866671244, "actor_grad_norm": 0.15988484025001526, "critic_grad_norm": 0.03846462443470955, "ratio": 1.0004143714904785, "entropy": 0.6259071866671244, "incre_win_rate": 0.7017543859649122, "step": 196}
{"time": 1766663727.7643538, "phase": "train", "update": 197, "total_env_steps": 630400, "episode_reward": 0.29314568638801575, "value_loss": 0.015320358859996, "policy_loss": -0.012525946566612826, "dist_entropy": 0.6519020001093546, "actor_grad_norm": 0.17394472658634186, "critic_grad_norm": 0.061822425574064255, "ratio": 0.9999208450317383, "entropy": 0.6519020001093546, "incre_win_rate": 0.6862745098039216, "step": 197}
{"time": 1766663732.3399167, "phase": "train", "update": 198, "total_env_steps": 633600, "episode_reward": 0.30361443758010864, "value_loss": 0.023629145820935567, "policy_loss": -0.012249812296930902, "dist_entropy": 0.6155392249425252, "actor_grad_norm": 0.23064623773097992, "critic_grad_norm": 0.10296226292848587, "ratio": 0.9986252784729004, "entropy": 0.6155392249425252, "incre_win_rate": 0.6111111111111112, "step": 198}
{"time": 1766663737.0341074, "phase": "train", "update": 199, "total_env_steps": 636800, "episode_reward": 0.29385340213775635, "value_loss": 0.02655455159644286, "policy_loss": -0.011513497422557369, "dist_entropy": 0.5963558395703633, "actor_grad_norm": 0.18195794522762299, "critic_grad_norm": 0.12856940925121307, "ratio": 1.0011928081512451, "entropy": 0.5963558395703633, "incre_win_rate": 0.49122807017543857, "step": 199}
{"time": 1766663741.6625206, "phase": "train", "update": 200, "total_env_steps": 640000, "episode_reward": 0.30178844928741455, "value_loss": 0.021283606191476186, "policy_loss": -0.011336115155417777, "dist_entropy": 0.6270252029101054, "actor_grad_norm": 0.16910438239574432, "critic_grad_norm": 0.06730137020349503, "ratio": 0.9985883235931396, "entropy": 0.6270252029101054, "incre_win_rate": 0.6226415094339622, "step": 200}
{"time": 1766663746.1835632, "phase": "train", "update": 201, "total_env_steps": 643200, "episode_reward": 0.2941988408565521, "value_loss": 0.0248106653491656, "policy_loss": -0.012328607767666236, "dist_entropy": 0.6205187280972798, "actor_grad_norm": 0.16835133731365204, "critic_grad_norm": 0.08994936943054199, "ratio": 0.9999922513961792, "entropy": 0.6205187280972798, "incre_win_rate": 0.5454545454545454, "step": 201}
{"time": 1766663754.6318626, "phase": "eval", "update": 201, "total_env_steps": 643200, "eval_win_rate": 0.71875, "eval_episode_reward": 18.51516544117647, "step": 201}
{"time": 1766663759.0902038, "phase": "train", "update": 202, "total_env_steps": 646400, "episode_reward": 0.2853217124938965, "value_loss": 0.025852074598272642, "policy_loss": -0.012636310858756161, "dist_entropy": 0.6297627409299215, "actor_grad_norm": 0.20081683993339539, "critic_grad_norm": 0.12969793379306793, "ratio": 0.9988281726837158, "entropy": 0.6297627409299215, "incre_win_rate": 0.6078431372549019, "step": 202}
{"time": 1766663763.2799425, "phase": "train", "update": 203, "total_env_steps": 649600, "episode_reward": 0.28349339962005615, "value_loss": 0.02398501771191756, "policy_loss": -0.01194293183696343, "dist_entropy": 0.6095028519630432, "actor_grad_norm": 0.18542903661727905, "critic_grad_norm": 0.06001788005232811, "ratio": 0.9989156126976013, "entropy": 0.6095028519630432, "incre_win_rate": 0.4716981132075472, "step": 203}
{"time": 1766663767.6246266, "phase": "train", "update": 204, "total_env_steps": 652800, "episode_reward": 0.285792738199234, "value_loss": 0.021935787548621497, "policy_loss": -0.013731860907501907, "dist_entropy": 0.6259180108706156, "actor_grad_norm": 0.2321196347475052, "critic_grad_norm": 0.047243669629096985, "ratio": 0.9995145797729492, "entropy": 0.6259180108706156, "incre_win_rate": 0.48148148148148145, "step": 204}
{"time": 1766663772.0748105, "phase": "train", "update": 205, "total_env_steps": 656000, "episode_reward": 0.2877121567726135, "value_loss": 0.016422052308917044, "policy_loss": -0.011921783217347107, "dist_entropy": 0.6011743625005086, "actor_grad_norm": 0.20205733180046082, "critic_grad_norm": 0.05462774634361267, "ratio": 0.9995817542076111, "entropy": 0.6011743625005086, "incre_win_rate": 0.5185185185185185, "step": 205}
{"time": 1766663776.54645, "phase": "train", "update": 206, "total_env_steps": 659200, "episode_reward": 0.3007950484752655, "value_loss": 0.02007498232026895, "policy_loss": -0.011510510165723886, "dist_entropy": 0.581162671248118, "actor_grad_norm": 0.19566266238689423, "critic_grad_norm": 0.054998498409986496, "ratio": 0.9994372725486755, "entropy": 0.581162671248118, "incre_win_rate": 0.6415094339622641, "step": 206}
{"time": 1766663781.3237348, "phase": "train", "update": 207, "total_env_steps": 662400, "episode_reward": 0.29593291878700256, "value_loss": 0.02132996221383413, "policy_loss": -0.01194039073956598, "dist_entropy": 0.5993633310000102, "actor_grad_norm": 0.1729806810617447, "critic_grad_norm": 0.034856416285037994, "ratio": 0.9997943639755249, "entropy": 0.5993633310000102, "incre_win_rate": 0.5454545454545454, "step": 207}
{"time": 1766663785.8747873, "phase": "train", "update": 208, "total_env_steps": 665600, "episode_reward": 0.2946239411830902, "value_loss": 0.02138927566508452, "policy_loss": -0.011386619201516623, "dist_entropy": 0.6077581842740377, "actor_grad_norm": 0.1945500671863556, "critic_grad_norm": 0.03521672263741493, "ratio": 1.0006752014160156, "entropy": 0.6077581842740377, "incre_win_rate": 0.6071428571428571, "step": 208}
{"time": 1766663790.5510354, "phase": "train", "update": 209, "total_env_steps": 668800, "episode_reward": 0.29432213306427, "value_loss": 0.022559179613987606, "policy_loss": -0.01256054988245765, "dist_entropy": 0.604552960395813, "actor_grad_norm": 0.16306869685649872, "critic_grad_norm": 0.032940175384283066, "ratio": 0.9998369216918945, "entropy": 0.604552960395813, "incre_win_rate": 0.5740740740740741, "step": 209}
{"time": 1766663795.0802255, "phase": "train", "update": 210, "total_env_steps": 672000, "episode_reward": 0.2990579307079315, "value_loss": 0.021662724763154985, "policy_loss": -0.012106376370055827, "dist_entropy": 0.6191934704780578, "actor_grad_norm": 0.2192429155111313, "critic_grad_norm": 0.022366920486092567, "ratio": 0.9992360472679138, "entropy": 0.6191934704780578, "incre_win_rate": 0.6346153846153846, "step": 210}
{"time": 1766663799.526924, "phase": "train", "update": 211, "total_env_steps": 675200, "episode_reward": 0.3049571216106415, "value_loss": 0.019739051163196564, "policy_loss": -0.01217678455487506, "dist_entropy": 0.6321018775304158, "actor_grad_norm": 0.21668633818626404, "critic_grad_norm": 0.02122355066239834, "ratio": 0.9994521737098694, "entropy": 0.6321018775304158, "incre_win_rate": 0.6792452830188679, "step": 211}
{"time": 1766663803.8463817, "phase": "train", "update": 212, "total_env_steps": 678400, "episode_reward": 0.2941161096096039, "value_loss": 0.020531523724397024, "policy_loss": -0.011820154446523172, "dist_entropy": 0.609998079140981, "actor_grad_norm": 0.16396057605743408, "critic_grad_norm": 0.03725666180253029, "ratio": 0.998345136642456, "entropy": 0.609998079140981, "incre_win_rate": 0.6981132075471698, "step": 212}
{"time": 1766663808.1493723, "phase": "train", "update": 213, "total_env_steps": 681600, "episode_reward": 0.2919975519180298, "value_loss": 0.026373221228520077, "policy_loss": -0.01216300643891941, "dist_entropy": 0.6098961273829142, "actor_grad_norm": 0.1838279366493225, "critic_grad_norm": 0.0827522799372673, "ratio": 1.0005030632019043, "entropy": 0.6098961273829142, "incre_win_rate": 0.5925925925925926, "step": 213}
{"time": 1766663812.4450474, "phase": "train", "update": 214, "total_env_steps": 684800, "episode_reward": 0.2950528562068939, "value_loss": 0.019434667006134988, "policy_loss": -0.013372093300658841, "dist_entropy": 0.5933791637420655, "actor_grad_norm": 0.17336608469486237, "critic_grad_norm": 0.0513291172683239, "ratio": 0.998992919921875, "entropy": 0.5933791637420655, "incre_win_rate": 0.5272727272727272, "step": 214}
{"time": 1766663816.713351, "phase": "train", "update": 215, "total_env_steps": 688000, "episode_reward": 0.3016720414161682, "value_loss": 0.0202797652532657, "policy_loss": -0.012007656694416368, "dist_entropy": 0.6142233570416769, "actor_grad_norm": 0.22121162712574005, "critic_grad_norm": 0.03470936790108681, "ratio": 0.9997560381889343, "entropy": 0.6142233570416769, "incre_win_rate": 0.625, "step": 215}
{"time": 1766663821.0602522, "phase": "train", "update": 216, "total_env_steps": 691200, "episode_reward": 0.29861903190612793, "value_loss": 0.01960765744249026, "policy_loss": -0.012242884915286823, "dist_entropy": 0.6072639306386312, "actor_grad_norm": 0.2094639539718628, "critic_grad_norm": 0.07518181949853897, "ratio": 0.9994885921478271, "entropy": 0.6072639306386312, "incre_win_rate": 0.5892857142857143, "step": 216}
{"time": 1766663825.3136995, "phase": "train", "update": 217, "total_env_steps": 694400, "episode_reward": 0.30006512999534607, "value_loss": 0.022074035555124282, "policy_loss": -0.01214250136977597, "dist_entropy": 0.5871880531311036, "actor_grad_norm": 0.1960064023733139, "critic_grad_norm": 0.05181116983294487, "ratio": 0.9993894100189209, "entropy": 0.5871880531311036, "incre_win_rate": 0.5740740740740741, "step": 217}
{"time": 1766663829.618323, "phase": "train", "update": 218, "total_env_steps": 697600, "episode_reward": 0.2925582230091095, "value_loss": 0.021312189102172852, "policy_loss": -0.012598059210114816, "dist_entropy": 0.5842451731363932, "actor_grad_norm": 0.16812655329704285, "critic_grad_norm": 0.03928671032190323, "ratio": 0.998272180557251, "entropy": 0.5842451731363932, "incre_win_rate": 0.46296296296296297, "step": 218}
{"time": 1766663833.877727, "phase": "train", "update": 219, "total_env_steps": 700800, "episode_reward": 0.3060286343097687, "value_loss": 0.019818974037965138, "policy_loss": -0.01318182640523015, "dist_entropy": 0.6267742474873861, "actor_grad_norm": 0.17266397178173065, "critic_grad_norm": 0.09124315530061722, "ratio": 0.9976514577865601, "entropy": 0.6267742474873861, "incre_win_rate": 0.6607142857142857, "step": 219}
{"time": 1766663838.142223, "phase": "train", "update": 220, "total_env_steps": 704000, "episode_reward": 0.2962714433670044, "value_loss": 0.021150085081656774, "policy_loss": -0.012943011693428966, "dist_entropy": 0.6200833121935526, "actor_grad_norm": 0.18694914877414703, "critic_grad_norm": 0.03890199586749077, "ratio": 0.9987371563911438, "entropy": 0.6200833121935526, "incre_win_rate": 0.6226415094339622, "step": 220}
{"time": 1766663842.4402926, "phase": "train", "update": 221, "total_env_steps": 707200, "episode_reward": 0.31570541858673096, "value_loss": 0.01744652489821116, "policy_loss": -0.0120448739051857, "dist_entropy": 0.5913102388381958, "actor_grad_norm": 0.16252395510673523, "critic_grad_norm": 0.07725126296281815, "ratio": 0.99945467710495, "entropy": 0.5913102388381958, "incre_win_rate": 0.7592592592592593, "step": 221}
{"time": 1766663850.625161, "phase": "eval", "update": 221, "total_env_steps": 707200, "eval_win_rate": 0.71875, "eval_episode_reward": 18.473575367647058, "step": 221}
{"time": 1766663854.8752244, "phase": "train", "update": 222, "total_env_steps": 710400, "episode_reward": 0.2968841791152954, "value_loss": 0.016519376325110594, "policy_loss": -0.01159186749513689, "dist_entropy": 0.6431575258572896, "actor_grad_norm": 0.15887068212032318, "critic_grad_norm": 0.028328927233815193, "ratio": 1.0002721548080444, "entropy": 0.6431575258572896, "incre_win_rate": 0.72, "step": 222}
{"time": 1766663859.1497505, "phase": "train", "update": 223, "total_env_steps": 713600, "episode_reward": 0.302866131067276, "value_loss": 0.02364492987593015, "policy_loss": -0.012928720168957852, "dist_entropy": 0.6108428637186686, "actor_grad_norm": 0.18606525659561157, "critic_grad_norm": 0.12795187532901764, "ratio": 0.9993851184844971, "entropy": 0.6108428637186686, "incre_win_rate": 0.6071428571428571, "step": 223}
{"time": 1766663863.485558, "phase": "train", "update": 224, "total_env_steps": 716800, "episode_reward": 0.28820696473121643, "value_loss": 0.021356298277775448, "policy_loss": -0.01287740007656429, "dist_entropy": 0.6113980968793233, "actor_grad_norm": 0.17802506685256958, "critic_grad_norm": 0.07312433421611786, "ratio": 0.9995088577270508, "entropy": 0.6113980968793233, "incre_win_rate": 0.5272727272727272, "step": 224}
{"time": 1766663867.7388554, "phase": "train", "update": 225, "total_env_steps": 720000, "episode_reward": 0.28723883628845215, "value_loss": 0.019157216077049573, "policy_loss": -0.01341670923277339, "dist_entropy": 0.6391818881034851, "actor_grad_norm": 0.20052692294120789, "critic_grad_norm": 0.05936901643872261, "ratio": 1.0005364418029785, "entropy": 0.6391818881034851, "incre_win_rate": 0.6037735849056604, "step": 225}
{"time": 1766663872.2956514, "phase": "train", "update": 226, "total_env_steps": 723200, "episode_reward": 0.28486213088035583, "value_loss": 0.022561430061856905, "policy_loss": -0.012711154565777368, "dist_entropy": 0.6416906356811524, "actor_grad_norm": 0.17554190754890442, "critic_grad_norm": 0.08788043260574341, "ratio": 0.9996820092201233, "entropy": 0.6416906356811524, "incre_win_rate": 0.46296296296296297, "step": 226}
{"time": 1766663876.5816963, "phase": "train", "update": 227, "total_env_steps": 726400, "episode_reward": 0.304267019033432, "value_loss": 0.02092171981930733, "policy_loss": -0.011751612467552993, "dist_entropy": 0.6099232355753581, "actor_grad_norm": 0.19373643398284912, "critic_grad_norm": 0.06198432296514511, "ratio": 1.000731110572815, "entropy": 0.6099232355753581, "incre_win_rate": 0.5849056603773585, "step": 227}
{"time": 1766663880.9190505, "phase": "train", "update": 228, "total_env_steps": 729600, "episode_reward": 0.2979136109352112, "value_loss": 0.020514223227898278, "policy_loss": -0.013450469860112927, "dist_entropy": 0.6287505706151326, "actor_grad_norm": 0.21657142043113708, "critic_grad_norm": 0.0696265697479248, "ratio": 0.9994025826454163, "entropy": 0.6287505706151326, "incre_win_rate": 0.5789473684210527, "step": 228}
{"time": 1766663885.2429256, "phase": "train", "update": 229, "total_env_steps": 732800, "episode_reward": 0.30265167355537415, "value_loss": 0.02155569555858771, "policy_loss": -0.012271023620810222, "dist_entropy": 0.6171025077501933, "actor_grad_norm": 0.190359964966774, "critic_grad_norm": 0.09843768924474716, "ratio": 0.998696506023407, "entropy": 0.6171025077501933, "incre_win_rate": 0.625, "step": 229}
{"time": 1766663889.5404286, "phase": "train", "update": 230, "total_env_steps": 736000, "episode_reward": 0.2981005311012268, "value_loss": 0.01869785785675049, "policy_loss": -0.012135820859835651, "dist_entropy": 0.6337956627209981, "actor_grad_norm": 0.21413196623325348, "critic_grad_norm": 0.05191236734390259, "ratio": 1.0004336833953857, "entropy": 0.6337956627209981, "incre_win_rate": 0.5925925925925926, "step": 230}
{"time": 1766663893.8325927, "phase": "train", "update": 231, "total_env_steps": 739200, "episode_reward": 0.29925933480262756, "value_loss": 0.020254220068454742, "policy_loss": -0.012418134682512042, "dist_entropy": 0.6024123549461364, "actor_grad_norm": 0.13712897896766663, "critic_grad_norm": 0.05164491385221481, "ratio": 0.9991804361343384, "entropy": 0.6024123549461364, "incre_win_rate": 0.5925925925925926, "step": 231}
{"time": 1766663898.0986712, "phase": "train", "update": 232, "total_env_steps": 742400, "episode_reward": 0.289486825466156, "value_loss": 0.022287119055787723, "policy_loss": -0.012005021413485414, "dist_entropy": 0.6016562263170878, "actor_grad_norm": 0.23000960052013397, "critic_grad_norm": 0.05005267634987831, "ratio": 0.9988858699798584, "entropy": 0.6016562263170878, "incre_win_rate": 0.509090909090909, "step": 232}
{"time": 1766663902.3997836, "phase": "train", "update": 233, "total_env_steps": 745600, "episode_reward": 0.29328277707099915, "value_loss": 0.022115197529395423, "policy_loss": -0.01248703619526168, "dist_entropy": 0.62734082142512, "actor_grad_norm": 0.24177056550979614, "critic_grad_norm": 0.03880719095468521, "ratio": 0.9992476105690002, "entropy": 0.62734082142512, "incre_win_rate": 0.5892857142857143, "step": 233}
{"time": 1766663906.647277, "phase": "train", "update": 234, "total_env_steps": 748800, "episode_reward": 0.2986312806606293, "value_loss": 0.02380844901005427, "policy_loss": -0.01239368144949727, "dist_entropy": 0.6130207777023315, "actor_grad_norm": 0.22961805760860443, "critic_grad_norm": 0.03414038568735123, "ratio": 0.999710202217102, "entropy": 0.6130207777023315, "incre_win_rate": 0.5961538461538461, "step": 234}
{"time": 1766663910.9543252, "phase": "train", "update": 235, "total_env_steps": 752000, "episode_reward": 0.3020457923412323, "value_loss": 0.019660126542051633, "policy_loss": -0.01262233189611477, "dist_entropy": 0.6193667491277058, "actor_grad_norm": 0.17346560955047607, "critic_grad_norm": 0.035129744559526443, "ratio": 0.9991124868392944, "entropy": 0.6193667491277058, "incre_win_rate": 0.6181818181818182, "step": 235}
{"time": 1766663915.2819257, "phase": "train", "update": 236, "total_env_steps": 755200, "episode_reward": 0.297078013420105, "value_loss": 0.01966927337149779, "policy_loss": -0.013090252152037962, "dist_entropy": 0.6190344413121541, "actor_grad_norm": 0.16868777573108673, "critic_grad_norm": 0.04065752401947975, "ratio": 0.9992489814758301, "entropy": 0.6190344413121541, "incre_win_rate": 0.6792452830188679, "step": 236}
{"time": 1766663919.4963033, "phase": "train", "update": 237, "total_env_steps": 758400, "episode_reward": 0.29287609457969666, "value_loss": 0.021527877946694692, "policy_loss": -0.012612596671887388, "dist_entropy": 0.6121994018554687, "actor_grad_norm": 0.203363299369812, "critic_grad_norm": 0.09441664814949036, "ratio": 0.9987468123435974, "entropy": 0.6121994018554687, "incre_win_rate": 0.5849056603773585, "step": 237}
{"time": 1766663923.8456366, "phase": "train", "update": 238, "total_env_steps": 761600, "episode_reward": 0.30724188685417175, "value_loss": 0.016074437896410623, "policy_loss": -0.013324142048470596, "dist_entropy": 0.6230406880378723, "actor_grad_norm": 0.19240453839302063, "critic_grad_norm": 0.0459502637386322, "ratio": 1.0019848346710205, "entropy": 0.6230406880378723, "incre_win_rate": 0.6909090909090909, "step": 238}
{"time": 1766663928.09551, "phase": "train", "update": 239, "total_env_steps": 764800, "episode_reward": 0.281886488199234, "value_loss": 0.021826991935571034, "policy_loss": -0.012309107364286831, "dist_entropy": 0.6032081325848897, "actor_grad_norm": 0.24347391724586487, "critic_grad_norm": 0.14960721135139465, "ratio": 1.00115966796875, "entropy": 0.6032081325848897, "incre_win_rate": 0.5, "step": 239}
{"time": 1766663932.3408687, "phase": "train", "update": 240, "total_env_steps": 768000, "episode_reward": 0.28687959909439087, "value_loss": 0.019135731582840283, "policy_loss": -0.014329163581756888, "dist_entropy": 0.6078328609466552, "actor_grad_norm": 0.2130100131034851, "critic_grad_norm": 0.10269611328840256, "ratio": 0.9995024800300598, "entropy": 0.6078328609466552, "incre_win_rate": 0.5740740740740741, "step": 240}
{"time": 1766663936.6354923, "phase": "train", "update": 241, "total_env_steps": 771200, "episode_reward": 0.316413938999176, "value_loss": 0.013108027167618275, "policy_loss": -0.012427840416539482, "dist_entropy": 0.6104428370793661, "actor_grad_norm": 0.18873439729213715, "critic_grad_norm": 0.07172616571187973, "ratio": 0.9994339346885681, "entropy": 0.6104428370793661, "incre_win_rate": 0.8269230769230769, "step": 241}
{"time": 1766663944.3208876, "phase": "eval", "update": 241, "total_env_steps": 771200, "eval_win_rate": 0.84375, "eval_episode_reward": 19.15954350490196, "step": 241}
{"time": 1766663948.5199804, "phase": "train", "update": 242, "total_env_steps": 774400, "episode_reward": 0.2932766377925873, "value_loss": 0.022774089003602664, "policy_loss": -0.013592450477657773, "dist_entropy": 0.5813078443209331, "actor_grad_norm": 0.245085209608078, "critic_grad_norm": 0.12879136204719543, "ratio": 0.998814582824707, "entropy": 0.5813078443209331, "incre_win_rate": 0.5370370370370371, "step": 242}
{"time": 1766663952.8157606, "phase": "train", "update": 243, "total_env_steps": 777600, "episode_reward": 0.31312885880470276, "value_loss": 0.017320866386095684, "policy_loss": -0.01198188717090242, "dist_entropy": 0.5813012043635051, "actor_grad_norm": 0.18188481032848358, "critic_grad_norm": 0.0421040877699852, "ratio": 0.9993411302566528, "entropy": 0.5813012043635051, "incre_win_rate": 0.7037037037037037, "step": 243}
{"time": 1766663957.0759082, "phase": "train", "update": 244, "total_env_steps": 780800, "episode_reward": 0.3130039870738983, "value_loss": 0.016992615287502608, "policy_loss": -0.011710815178445995, "dist_entropy": 0.5715158104896545, "actor_grad_norm": 0.17451238632202148, "critic_grad_norm": 0.030644522979855537, "ratio": 0.999014675617218, "entropy": 0.5715158104896545, "incre_win_rate": 0.6964285714285714, "step": 244}
{"time": 1766663961.3413236, "phase": "train", "update": 245, "total_env_steps": 784000, "episode_reward": 0.29694703221321106, "value_loss": 0.019405231128136316, "policy_loss": -0.012731701204651695, "dist_entropy": 0.5704682151476542, "actor_grad_norm": 0.17366759479045868, "critic_grad_norm": 0.09047175943851471, "ratio": 0.9994234442710876, "entropy": 0.5704682151476542, "incre_win_rate": 0.5660377358490566, "step": 245}
{"time": 1766663965.58017, "phase": "train", "update": 246, "total_env_steps": 787200, "episode_reward": 0.2841513454914093, "value_loss": 0.019169065604607263, "policy_loss": -0.012806227260189, "dist_entropy": 0.5868220885594686, "actor_grad_norm": 0.18221189081668854, "critic_grad_norm": 0.061849795281887054, "ratio": 0.9994946122169495, "entropy": 0.5868220885594686, "incre_win_rate": 0.6274509803921569, "step": 246}
{"time": 1766663969.8296802, "phase": "train", "update": 247, "total_env_steps": 790400, "episode_reward": 0.3010263741016388, "value_loss": 0.017053880915045738, "policy_loss": -0.012033791218296603, "dist_entropy": 0.5502464334170024, "actor_grad_norm": 0.1728481501340866, "critic_grad_norm": 0.030225582420825958, "ratio": 0.9986999034881592, "entropy": 0.5502464334170024, "incre_win_rate": 0.6181818181818182, "step": 247}
{"time": 1766663974.1557865, "phase": "train", "update": 248, "total_env_steps": 793600, "episode_reward": 0.28026044368743896, "value_loss": 0.020402292038003603, "policy_loss": -0.01281705827438202, "dist_entropy": 0.5424751122792562, "actor_grad_norm": 0.19782909750938416, "critic_grad_norm": 0.04064687713980675, "ratio": 0.9994224309921265, "entropy": 0.5424751122792562, "incre_win_rate": 0.6274509803921569, "step": 248}
{"time": 1766663978.404956, "phase": "train", "update": 249, "total_env_steps": 796800, "episode_reward": 0.298224538564682, "value_loss": 0.01932065685590108, "policy_loss": -0.012191738847758416, "dist_entropy": 0.5701294342676798, "actor_grad_norm": 0.18635012209415436, "critic_grad_norm": 0.034731023013591766, "ratio": 0.9982856512069702, "entropy": 0.5701294342676798, "incre_win_rate": 0.6296296296296297, "step": 249}
{"time": 1766663982.6887567, "phase": "train", "update": 250, "total_env_steps": 800000, "episode_reward": 0.30267542600631714, "value_loss": 0.018370234966278078, "policy_loss": -0.011337360612804303, "dist_entropy": 0.5620801369349162, "actor_grad_norm": 0.1815590262413025, "critic_grad_norm": 0.04167582467198372, "ratio": 0.9993025064468384, "entropy": 0.5620801369349162, "incre_win_rate": 0.6666666666666666, "step": 250}
{"time": 1766663986.9625216, "phase": "train", "update": 251, "total_env_steps": 803200, "episode_reward": 0.29590076208114624, "value_loss": 0.017217603077491126, "policy_loss": -0.011830960736518393, "dist_entropy": 0.5636351029078166, "actor_grad_norm": 0.16852658987045288, "critic_grad_norm": 0.021620457991957664, "ratio": 0.9997815489768982, "entropy": 0.5636351029078166, "incre_win_rate": 0.64, "step": 251}
{"time": 1766663991.190549, "phase": "train", "update": 252, "total_env_steps": 806400, "episode_reward": 0.296538770198822, "value_loss": 0.019383479903141657, "policy_loss": -0.012925692085023855, "dist_entropy": 0.5707878430684408, "actor_grad_norm": 0.16073881089687347, "critic_grad_norm": 0.018759222701191902, "ratio": 1.000013828277588, "entropy": 0.5707878430684408, "incre_win_rate": 0.6851851851851852, "step": 252}
{"time": 1766663995.5028126, "phase": "train", "update": 253, "total_env_steps": 809600, "episode_reward": 0.301573246717453, "value_loss": 0.019953339422742526, "policy_loss": -0.012397499129355083, "dist_entropy": 0.5832139492034912, "actor_grad_norm": 0.190230131149292, "critic_grad_norm": 0.05765710398554802, "ratio": 0.9993361830711365, "entropy": 0.5832139492034912, "incre_win_rate": 0.6666666666666666, "step": 253}
{"time": 1766663999.7718961, "phase": "train", "update": 254, "total_env_steps": 812800, "episode_reward": 0.30878448486328125, "value_loss": 0.016453049952785175, "policy_loss": -0.0119680080434307, "dist_entropy": 0.5677651087443034, "actor_grad_norm": 0.19511820375919342, "critic_grad_norm": 0.06627762317657471, "ratio": 1.000188946723938, "entropy": 0.5677651087443034, "incre_win_rate": 0.7169811320754716, "step": 254}
{"time": 1766664004.0490088, "phase": "train", "update": 255, "total_env_steps": 816000, "episode_reward": 0.3048200011253357, "value_loss": 0.015949049033224583, "policy_loss": -0.012451113296477937, "dist_entropy": 0.585153857866923, "actor_grad_norm": 0.1504179984331131, "critic_grad_norm": 0.04932595044374466, "ratio": 0.9991495013237, "entropy": 0.585153857866923, "incre_win_rate": 0.6981132075471698, "step": 255}
{"time": 1766664008.3118908, "phase": "train", "update": 256, "total_env_steps": 819200, "episode_reward": 0.29540595412254333, "value_loss": 0.019472151001294454, "policy_loss": -0.013617996789352323, "dist_entropy": 0.5687759439150493, "actor_grad_norm": 0.21722982823848724, "critic_grad_norm": 0.06535662710666656, "ratio": 0.9993777275085449, "entropy": 0.5687759439150493, "incre_win_rate": 0.6792452830188679, "step": 256}
{"time": 1766664012.6224208, "phase": "train", "update": 257, "total_env_steps": 822400, "episode_reward": 0.30264556407928467, "value_loss": 0.021825895830988883, "policy_loss": -0.012028407080233212, "dist_entropy": 0.5659162799517313, "actor_grad_norm": 0.1590627133846283, "critic_grad_norm": 0.10438062250614166, "ratio": 1.0003812313079834, "entropy": 0.5659162799517313, "incre_win_rate": 0.6181818181818182, "step": 257}
{"time": 1766664016.8939369, "phase": "train", "update": 258, "total_env_steps": 825600, "episode_reward": 0.29381588101387024, "value_loss": 0.021493542566895486, "policy_loss": -0.012911697262967436, "dist_entropy": 0.5699078361193339, "actor_grad_norm": 0.21437442302703857, "critic_grad_norm": 0.06425043195486069, "ratio": 0.9978629946708679, "entropy": 0.5699078361193339, "incre_win_rate": 0.72, "step": 258}
{"time": 1766664021.1836631, "phase": "train", "update": 259, "total_env_steps": 828800, "episode_reward": 0.30269455909729004, "value_loss": 0.02148416874309381, "policy_loss": -0.012081814680724771, "dist_entropy": 0.5773167133331298, "actor_grad_norm": 0.17976315319538116, "critic_grad_norm": 0.037767745554447174, "ratio": 0.998620867729187, "entropy": 0.5773167133331298, "incre_win_rate": 0.6666666666666666, "step": 259}
{"time": 1766664025.9644606, "phase": "train", "update": 260, "total_env_steps": 832000, "episode_reward": 0.2966145873069763, "value_loss": 0.019307694708307583, "policy_loss": -0.012740009021056646, "dist_entropy": 0.5705383102099101, "actor_grad_norm": 0.16747495532035828, "critic_grad_norm": 0.027731606736779213, "ratio": 0.9989300966262817, "entropy": 0.5705383102099101, "incre_win_rate": 0.6862745098039216, "step": 260}
{"time": 1766664030.1858325, "phase": "train", "update": 261, "total_env_steps": 835200, "episode_reward": 0.2985248267650604, "value_loss": 0.019974027574062348, "policy_loss": -0.011237826187620037, "dist_entropy": 0.5619075139363606, "actor_grad_norm": 0.16282765567302704, "critic_grad_norm": 0.02115795947611332, "ratio": 0.9984897375106812, "entropy": 0.5619075139363606, "incre_win_rate": 0.6730769230769231, "step": 261}
{"time": 1766664037.99778, "phase": "eval", "update": 261, "total_env_steps": 835200, "eval_win_rate": 0.84375, "eval_episode_reward": 19.08517156862745, "step": 261}
{"time": 1766664042.2568488, "phase": "train", "update": 262, "total_env_steps": 838400, "episode_reward": 0.30550092458724976, "value_loss": 0.019306725387771926, "policy_loss": -0.01212252051339912, "dist_entropy": 0.570744522412618, "actor_grad_norm": 0.16314256191253662, "critic_grad_norm": 0.045662231743335724, "ratio": 0.9992886185646057, "entropy": 0.570744522412618, "incre_win_rate": 0.625, "step": 262}
{"time": 1766664046.5823667, "phase": "train", "update": 263, "total_env_steps": 841600, "episode_reward": 0.2993328869342804, "value_loss": 0.020468063031633694, "policy_loss": -0.012867737239121387, "dist_entropy": 0.5663190762201945, "actor_grad_norm": 0.19221796095371246, "critic_grad_norm": 0.03360403701663017, "ratio": 0.9996443390846252, "entropy": 0.5663190762201945, "incre_win_rate": 0.6, "step": 263}
{"time": 1766664050.8071187, "phase": "train", "update": 264, "total_env_steps": 844800, "episode_reward": 0.2957988977432251, "value_loss": 0.02002162846426169, "policy_loss": -0.012960791591484147, "dist_entropy": 0.5948993961016337, "actor_grad_norm": 0.1876179426908493, "critic_grad_norm": 0.043409544974565506, "ratio": 0.999247133731842, "entropy": 0.5948993961016337, "incre_win_rate": 0.6226415094339622, "step": 264}
{"time": 1766664055.109759, "phase": "train", "update": 265, "total_env_steps": 848000, "episode_reward": 0.30732613801956177, "value_loss": 0.017408050845066705, "policy_loss": -0.01229873132137224, "dist_entropy": 0.579473594824473, "actor_grad_norm": 0.1905643343925476, "critic_grad_norm": 0.036963362246751785, "ratio": 0.9985835552215576, "entropy": 0.579473594824473, "incre_win_rate": 0.7407407407407407, "step": 265}
{"time": 1766664059.3715208, "phase": "train", "update": 266, "total_env_steps": 851200, "episode_reward": 0.30482080578804016, "value_loss": 0.018003658577799796, "policy_loss": -0.01328361658415839, "dist_entropy": 0.589954388141632, "actor_grad_norm": 0.18293312191963196, "critic_grad_norm": 0.05924097076058388, "ratio": 0.9995134472846985, "entropy": 0.589954388141632, "incre_win_rate": 0.7169811320754716, "step": 266}
{"time": 1766664063.655819, "phase": "train", "update": 267, "total_env_steps": 854400, "episode_reward": 0.29689568281173706, "value_loss": 0.020480556165178618, "policy_loss": -0.012955583855235394, "dist_entropy": 0.6069043517112732, "actor_grad_norm": 0.1972644329071045, "critic_grad_norm": 0.05886221304535866, "ratio": 0.9992229342460632, "entropy": 0.6069043517112732, "incre_win_rate": 0.6981132075471698, "step": 267}
{"time": 1766664067.9260385, "phase": "train", "update": 268, "total_env_steps": 857600, "episode_reward": 0.28051164746284485, "value_loss": 0.01897627698878447, "policy_loss": -0.01187734788300503, "dist_entropy": 0.588324761390686, "actor_grad_norm": 0.15876337885856628, "critic_grad_norm": 0.09284016489982605, "ratio": 1.000022530555725, "entropy": 0.588324761390686, "incre_win_rate": 0.5, "step": 268}
{"time": 1766664072.1346111, "phase": "train", "update": 269, "total_env_steps": 860800, "episode_reward": 0.29593902826309204, "value_loss": 0.018699147924780845, "policy_loss": -0.013416728894831446, "dist_entropy": 0.5793160359064738, "actor_grad_norm": 0.20531828701496124, "critic_grad_norm": 0.06051050126552582, "ratio": 0.9987810254096985, "entropy": 0.5793160359064738, "incre_win_rate": 0.6346153846153846, "step": 269}
{"time": 1766664076.456117, "phase": "train", "update": 270, "total_env_steps": 864000, "episode_reward": 0.29062652587890625, "value_loss": 0.01717600499590238, "policy_loss": -0.012656236655323975, "dist_entropy": 0.5634708285331727, "actor_grad_norm": 0.16579009592533112, "critic_grad_norm": 0.032955512404441833, "ratio": 0.999223530292511, "entropy": 0.5634708285331727, "incre_win_rate": 0.5660377358490566, "step": 270}
{"time": 1766664080.7259576, "phase": "train", "update": 271, "total_env_steps": 867200, "episode_reward": 0.2932858467102051, "value_loss": 0.019688599432508152, "policy_loss": -0.012714258670445193, "dist_entropy": 0.5787307818730673, "actor_grad_norm": 0.206436887383461, "critic_grad_norm": 0.03436027094721794, "ratio": 0.9983635544776917, "entropy": 0.5787307818730673, "incre_win_rate": 0.5636363636363636, "step": 271}
{"time": 1766664084.9931512, "phase": "train", "update": 272, "total_env_steps": 870400, "episode_reward": 0.3121093809604645, "value_loss": 0.01700412780046463, "policy_loss": -0.013005908376518516, "dist_entropy": 0.5680377244949341, "actor_grad_norm": 0.18585650622844696, "critic_grad_norm": 0.08113671839237213, "ratio": 1.0001404285430908, "entropy": 0.5680377244949341, "incre_win_rate": 0.7358490566037735, "step": 272}
{"time": 1766664089.2228012, "phase": "train", "update": 273, "total_env_steps": 873600, "episode_reward": 0.2960026264190674, "value_loss": 0.01718585304915905, "policy_loss": -0.012934090520212748, "dist_entropy": 0.579377281665802, "actor_grad_norm": 0.17155490815639496, "critic_grad_norm": 0.0741264671087265, "ratio": 0.998063862323761, "entropy": 0.579377281665802, "incre_win_rate": 0.660377358490566, "step": 273}
{"time": 1766664093.532448, "phase": "train", "update": 274, "total_env_steps": 876800, "episode_reward": 0.3153201639652252, "value_loss": 0.01927496132751306, "policy_loss": -0.01232624478881945, "dist_entropy": 0.5735402425130208, "actor_grad_norm": 0.16341844201087952, "critic_grad_norm": 0.044200945645570755, "ratio": 0.99982750415802, "entropy": 0.5735402425130208, "incre_win_rate": 0.6666666666666666, "step": 274}
{"time": 1766664097.7844057, "phase": "train", "update": 275, "total_env_steps": 880000, "episode_reward": 0.29219672083854675, "value_loss": 0.021741113066673277, "policy_loss": -0.01315043646299993, "dist_entropy": 0.5720088839530945, "actor_grad_norm": 0.19618916511535645, "critic_grad_norm": 0.0673714131116867, "ratio": 0.9999511241912842, "entropy": 0.5720088839530945, "incre_win_rate": 0.5272727272727272, "step": 275}
{"time": 1766664102.0384026, "phase": "train", "update": 276, "total_env_steps": 883200, "episode_reward": 0.2909007668495178, "value_loss": 0.014298899844288827, "policy_loss": -0.01316184714766706, "dist_entropy": 0.5828758358955384, "actor_grad_norm": 0.21711896359920502, "critic_grad_norm": 0.08345533162355423, "ratio": 0.9995481967926025, "entropy": 0.5828758358955384, "incre_win_rate": 0.6730769230769231, "step": 276}
{"time": 1766664106.3710186, "phase": "train", "update": 277, "total_env_steps": 886400, "episode_reward": 0.28773897886276245, "value_loss": 0.02198709559937318, "policy_loss": -0.01368152288885085, "dist_entropy": 0.6012807965278626, "actor_grad_norm": 0.19111642241477966, "critic_grad_norm": 0.0638122409582138, "ratio": 1.0008654594421387, "entropy": 0.6012807965278626, "incre_win_rate": 0.6346153846153846, "step": 277}
{"time": 1766664110.6563735, "phase": "train", "update": 278, "total_env_steps": 889600, "episode_reward": 0.30275049805641174, "value_loss": 0.01654792403181394, "policy_loss": -0.012605443773842732, "dist_entropy": 0.5736845215161641, "actor_grad_norm": 0.18865232169628143, "critic_grad_norm": 0.05514581501483917, "ratio": 0.9990723729133606, "entropy": 0.5736845215161641, "incre_win_rate": 0.660377358490566, "step": 278}
{"time": 1766664114.9223883, "phase": "train", "update": 279, "total_env_steps": 892800, "episode_reward": 0.2924731969833374, "value_loss": 0.017673113693793614, "policy_loss": -0.013165759955400346, "dist_entropy": 0.5891559958457947, "actor_grad_norm": 0.20580066740512848, "critic_grad_norm": 0.04724995419383049, "ratio": 0.9992498159408569, "entropy": 0.5891559958457947, "incre_win_rate": 0.7058823529411765, "step": 279}
{"time": 1766664119.2901113, "phase": "train", "update": 280, "total_env_steps": 896000, "episode_reward": 0.29893383383750916, "value_loss": 0.019281392296155293, "policy_loss": -0.013387803447329816, "dist_entropy": 0.5877944231033325, "actor_grad_norm": 0.1770152449607849, "critic_grad_norm": 0.05575838312506676, "ratio": 0.9995557069778442, "entropy": 0.5877944231033325, "incre_win_rate": 0.6226415094339622, "step": 280}
{"time": 1766664123.5625448, "phase": "train", "update": 281, "total_env_steps": 899200, "episode_reward": 0.29732462763786316, "value_loss": 0.018350356444716453, "policy_loss": -0.012383134648900788, "dist_entropy": 0.5864295164744059, "actor_grad_norm": 0.16276945173740387, "critic_grad_norm": 0.05004844069480896, "ratio": 1.0000115633010864, "entropy": 0.5864295164744059, "incre_win_rate": 0.543859649122807, "step": 281}
{"time": 1766664131.4424527, "phase": "eval", "update": 281, "total_env_steps": 899200, "eval_win_rate": 0.78125, "eval_episode_reward": 18.868183210784316, "step": 281}
{"time": 1766664135.6849055, "phase": "train", "update": 282, "total_env_steps": 902400, "episode_reward": 0.2783118784427643, "value_loss": 0.023517681906620663, "policy_loss": -0.01406488068129465, "dist_entropy": 0.5955724438031514, "actor_grad_norm": 0.22172582149505615, "critic_grad_norm": 0.08464919030666351, "ratio": 0.9998328685760498, "entropy": 0.5955724438031514, "incre_win_rate": 0.5384615384615384, "step": 282}
{"time": 1766664139.9822786, "phase": "train", "update": 283, "total_env_steps": 905600, "episode_reward": 0.29952511191368103, "value_loss": 0.01551028254131476, "policy_loss": -0.01261257949200143, "dist_entropy": 0.5645268479983012, "actor_grad_norm": 0.2435765564441681, "critic_grad_norm": 0.0433465912938118, "ratio": 0.9999380111694336, "entropy": 0.5645268479983012, "incre_win_rate": 0.6111111111111112, "step": 283}
{"time": 1766664144.2282412, "phase": "train", "update": 284, "total_env_steps": 908800, "episode_reward": 0.28443092107772827, "value_loss": 0.022087227180600168, "policy_loss": -0.014384508355540681, "dist_entropy": 0.5741112947463989, "actor_grad_norm": 0.18172717094421387, "critic_grad_norm": 0.04524659737944603, "ratio": 0.9981061220169067, "entropy": 0.5741112947463989, "incre_win_rate": 0.5660377358490566, "step": 284}
{"time": 1766664148.487128, "phase": "train", "update": 285, "total_env_steps": 912000, "episode_reward": 0.3061274588108063, "value_loss": 0.01910367471476396, "policy_loss": -0.012909265956347345, "dist_entropy": 0.5781857331593832, "actor_grad_norm": 0.17853127419948578, "critic_grad_norm": 0.04223980754613876, "ratio": 0.9988496899604797, "entropy": 0.5781857331593832, "incre_win_rate": 0.6851851851851852, "step": 285}
{"time": 1766664152.7357404, "phase": "train", "update": 286, "total_env_steps": 915200, "episode_reward": 0.29745787382125854, "value_loss": 0.018595596651236217, "policy_loss": -0.01332493962902402, "dist_entropy": 0.5727786660194397, "actor_grad_norm": 0.2041141390800476, "critic_grad_norm": 0.0319802463054657, "ratio": 1.0002222061157227, "entropy": 0.5727786660194397, "incre_win_rate": 0.6296296296296297, "step": 286}
{"time": 1766664157.0609396, "phase": "train", "update": 287, "total_env_steps": 918400, "episode_reward": 0.31182295083999634, "value_loss": 0.014161993501087029, "policy_loss": -0.012025849935814393, "dist_entropy": 0.5696322361628214, "actor_grad_norm": 0.1583574414253235, "critic_grad_norm": 0.06704401969909668, "ratio": 0.998746395111084, "entropy": 0.5696322361628214, "incre_win_rate": 0.7735849056603774, "step": 287}
{"time": 1766664161.3057723, "phase": "train", "update": 288, "total_env_steps": 921600, "episode_reward": 0.3012959659099579, "value_loss": 0.015393836982548236, "policy_loss": -0.012297419024636724, "dist_entropy": 0.5818401217460633, "actor_grad_norm": 0.17538884282112122, "critic_grad_norm": 0.025604823604226112, "ratio": 1.000032901763916, "entropy": 0.5818401217460633, "incre_win_rate": 0.7307692307692307, "step": 288}
{"time": 1766664165.6030269, "phase": "train", "update": 289, "total_env_steps": 924800, "episode_reward": 0.2901708483695984, "value_loss": 0.018390724311272304, "policy_loss": -0.013047107707191448, "dist_entropy": 0.5786393404006958, "actor_grad_norm": 0.22327682375907898, "critic_grad_norm": 0.07216659933328629, "ratio": 0.9998673796653748, "entropy": 0.5786393404006958, "incre_win_rate": 0.6346153846153846, "step": 289}
{"time": 1766664169.8550768, "phase": "train", "update": 290, "total_env_steps": 928000, "episode_reward": 0.29613053798675537, "value_loss": 0.012911710391441981, "policy_loss": -0.01257523032801231, "dist_entropy": 0.5787369132041931, "actor_grad_norm": 0.18963445723056793, "critic_grad_norm": 0.0339014008641243, "ratio": 0.999902069568634, "entropy": 0.5787369132041931, "incre_win_rate": 0.74, "step": 290}
{"time": 1766664174.1253145, "phase": "train", "update": 291, "total_env_steps": 931200, "episode_reward": 0.30695006251335144, "value_loss": 0.015993735256294408, "policy_loss": -0.012232872672367516, "dist_entropy": 0.5721609354019165, "actor_grad_norm": 0.21520686149597168, "critic_grad_norm": 0.03318938612937927, "ratio": 0.9992874264717102, "entropy": 0.5721609354019165, "incre_win_rate": 0.6909090909090909, "step": 291}
{"time": 1766664178.460201, "phase": "train", "update": 292, "total_env_steps": 934400, "episode_reward": 0.2912369966506958, "value_loss": 0.015255802993973095, "policy_loss": -0.012565746289509032, "dist_entropy": 0.595678706963857, "actor_grad_norm": 0.2221834361553192, "critic_grad_norm": 0.026158440858125687, "ratio": 1.0002504587173462, "entropy": 0.595678706963857, "incre_win_rate": 0.6296296296296297, "step": 292}
{"time": 1766664182.6773076, "phase": "train", "update": 293, "total_env_steps": 937600, "episode_reward": 0.2918941378593445, "value_loss": 0.01721197118361791, "policy_loss": -0.012819195273150778, "dist_entropy": 0.5872896750768025, "actor_grad_norm": 0.22153045237064362, "critic_grad_norm": 0.028155727311968803, "ratio": 0.9998202323913574, "entropy": 0.5872896750768025, "incre_win_rate": 0.6346153846153846, "step": 293}
{"time": 1766664186.9409792, "phase": "train", "update": 294, "total_env_steps": 940800, "episode_reward": 0.29058513045310974, "value_loss": 0.018989064420262974, "policy_loss": -0.012140926331559498, "dist_entropy": 0.571962304910024, "actor_grad_norm": 0.15236257016658783, "critic_grad_norm": 0.0353737398982048, "ratio": 0.9997977614402771, "entropy": 0.571962304910024, "incre_win_rate": 0.5283018867924528, "step": 294}
{"time": 1766664191.2646925, "phase": "train", "update": 295, "total_env_steps": 944000, "episode_reward": 0.29867419600486755, "value_loss": 0.015863092181583247, "policy_loss": -0.013026982431271724, "dist_entropy": 0.5887032111485799, "actor_grad_norm": 0.2269400656223297, "critic_grad_norm": 0.06533540040254593, "ratio": 0.99936842918396, "entropy": 0.5887032111485799, "incre_win_rate": 0.7169811320754716, "step": 295}
{"time": 1766664195.4825065, "phase": "train", "update": 296, "total_env_steps": 947200, "episode_reward": 0.3014231026172638, "value_loss": 0.017631103843450548, "policy_loss": -0.012365219978728229, "dist_entropy": 0.5739816387494405, "actor_grad_norm": 0.1926695555448532, "critic_grad_norm": 0.051928337663412094, "ratio": 0.9993812441825867, "entropy": 0.5739816387494405, "incre_win_rate": 0.6923076923076923, "step": 296}
{"time": 1766664199.7681692, "phase": "train", "update": 297, "total_env_steps": 950400, "episode_reward": 0.2881142497062683, "value_loss": 0.018823850651582083, "policy_loss": -0.012701719326804195, "dist_entropy": 0.5730786959330241, "actor_grad_norm": 0.18379825353622437, "critic_grad_norm": 0.02894948236644268, "ratio": 1.0002344846725464, "entropy": 0.5730786959330241, "incre_win_rate": 0.6666666666666666, "step": 297}
{"time": 1766664204.0021303, "phase": "train", "update": 298, "total_env_steps": 953600, "episode_reward": 0.29364582896232605, "value_loss": 0.014095608827968438, "policy_loss": -0.012369015660156416, "dist_entropy": 0.5596847256024678, "actor_grad_norm": 0.23427344858646393, "critic_grad_norm": 0.0895732194185257, "ratio": 0.998731255531311, "entropy": 0.5596847256024678, "incre_win_rate": 0.7142857142857143, "step": 298}
{"time": 1766664208.256384, "phase": "train", "update": 299, "total_env_steps": 956800, "episode_reward": 0.29750385880470276, "value_loss": 0.017835016548633575, "policy_loss": -0.011901203071274343, "dist_entropy": 0.5838023702303569, "actor_grad_norm": 0.17802445590496063, "critic_grad_norm": 0.04255083203315735, "ratio": 0.9979501962661743, "entropy": 0.5838023702303569, "incre_win_rate": 0.6851851851851852, "step": 299}
{"time": 1766664212.5327117, "phase": "train", "update": 300, "total_env_steps": 960000, "episode_reward": 0.2851662039756775, "value_loss": 0.019917651265859603, "policy_loss": -0.012953842730958816, "dist_entropy": 0.5878027121225993, "actor_grad_norm": 0.20357349514961243, "critic_grad_norm": 0.09066326916217804, "ratio": 0.9996320009231567, "entropy": 0.5878027121225993, "incre_win_rate": 0.5576923076923077, "step": 300}
{"time": 1766664216.8288183, "phase": "train", "update": 301, "total_env_steps": 963200, "episode_reward": 0.2903936803340912, "value_loss": 0.01559462770819664, "policy_loss": -0.01376298834116767, "dist_entropy": 0.5836905241012573, "actor_grad_norm": 0.20424893498420715, "critic_grad_norm": 0.04810953512787819, "ratio": 0.9985347390174866, "entropy": 0.5836905241012573, "incre_win_rate": 0.5660377358490566, "step": 301}
{"time": 1766664224.7033558, "phase": "eval", "update": 301, "total_env_steps": 963200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.92401960784314, "step": 301}
{"time": 1766664228.9441729, "phase": "train", "update": 302, "total_env_steps": 966400, "episode_reward": 0.29852941632270813, "value_loss": 0.012779959539572398, "policy_loss": -0.013486646661830193, "dist_entropy": 0.5739201386769612, "actor_grad_norm": 0.20674239099025726, "critic_grad_norm": 0.04319239780306816, "ratio": 0.9994792342185974, "entropy": 0.5739201386769612, "incre_win_rate": 0.75, "step": 302}
{"time": 1766664233.1913524, "phase": "train", "update": 303, "total_env_steps": 969600, "episode_reward": 0.2872273325920105, "value_loss": 0.016893666858474415, "policy_loss": -0.012999133337409792, "dist_entropy": 0.5652512232462565, "actor_grad_norm": 0.17417240142822266, "critic_grad_norm": 0.05464298650622368, "ratio": 0.9992000460624695, "entropy": 0.5652512232462565, "incre_win_rate": 0.6153846153846154, "step": 303}
{"time": 1766664237.467625, "phase": "train", "update": 304, "total_env_steps": 972800, "episode_reward": 0.30815717577934265, "value_loss": 0.016979728514949482, "policy_loss": -0.011118877899377821, "dist_entropy": 0.5512858748435974, "actor_grad_norm": 0.2506644129753113, "critic_grad_norm": 0.05740128085017204, "ratio": 1.000343918800354, "entropy": 0.5512858748435974, "incre_win_rate": 0.7547169811320755, "step": 304}
{"time": 1766664241.749113, "phase": "train", "update": 305, "total_env_steps": 976000, "episode_reward": 0.30402496457099915, "value_loss": 0.01627146601676941, "policy_loss": -0.012196637733088522, "dist_entropy": 0.5456623633702596, "actor_grad_norm": 0.19614703953266144, "critic_grad_norm": 0.026345061138272285, "ratio": 0.999969482421875, "entropy": 0.5456623633702596, "incre_win_rate": 0.6851851851851852, "step": 305}
{"time": 1766664246.0330713, "phase": "train", "update": 306, "total_env_steps": 979200, "episode_reward": 0.30878064036369324, "value_loss": 0.015529638715088367, "policy_loss": -0.012016729983881192, "dist_entropy": 0.5519167820612589, "actor_grad_norm": 0.17625585198402405, "critic_grad_norm": 0.031308457255363464, "ratio": 0.9995647072792053, "entropy": 0.5519167820612589, "incre_win_rate": 0.7169811320754716, "step": 306}
{"time": 1766664250.3240306, "phase": "train", "update": 307, "total_env_steps": 982400, "episode_reward": 0.31018152832984924, "value_loss": 0.017138926188151042, "policy_loss": -0.01315352699802806, "dist_entropy": 0.557910680770874, "actor_grad_norm": 0.17434854805469513, "critic_grad_norm": 0.03575962409377098, "ratio": 0.999047040939331, "entropy": 0.557910680770874, "incre_win_rate": 0.6909090909090909, "step": 307}
{"time": 1766664254.5388076, "phase": "train", "update": 308, "total_env_steps": 985600, "episode_reward": 0.3083241283893585, "value_loss": 0.01953172336022059, "policy_loss": -0.011978334077316433, "dist_entropy": 0.555437695980072, "actor_grad_norm": 0.15177111327648163, "critic_grad_norm": 0.02594522200524807, "ratio": 0.9996967315673828, "entropy": 0.555437695980072, "incre_win_rate": 0.6428571428571429, "step": 308}
{"time": 1766664258.820174, "phase": "train", "update": 309, "total_env_steps": 988800, "episode_reward": 0.3039078116416931, "value_loss": 0.017265206202864647, "policy_loss": -0.012843839042170183, "dist_entropy": 0.5526113033294677, "actor_grad_norm": 0.18527401983737946, "critic_grad_norm": 0.02238919399678707, "ratio": 0.998562753200531, "entropy": 0.5526113033294677, "incre_win_rate": 0.6666666666666666, "step": 309}
{"time": 1766664263.103506, "phase": "train", "update": 310, "total_env_steps": 992000, "episode_reward": 0.30251532793045044, "value_loss": 0.0170783095061779, "policy_loss": -0.013720319116184883, "dist_entropy": 0.5556147178014119, "actor_grad_norm": 0.19547565281391144, "critic_grad_norm": 0.046044837683439255, "ratio": 0.9991855025291443, "entropy": 0.5556147178014119, "incre_win_rate": 0.6545454545454545, "step": 310}
{"time": 1766664267.4870992, "phase": "train", "update": 311, "total_env_steps": 995200, "episode_reward": 0.30317094922065735, "value_loss": 0.014476670138537883, "policy_loss": -0.013492743689005238, "dist_entropy": 0.5720776637395223, "actor_grad_norm": 0.22349320352077484, "critic_grad_norm": 0.03213442862033844, "ratio": 0.9996556043624878, "entropy": 0.5720776637395223, "incre_win_rate": 0.7115384615384616, "step": 311}
{"time": 1766664271.8695445, "phase": "train", "update": 312, "total_env_steps": 998400, "episode_reward": 0.31848347187042236, "value_loss": 0.015092443798979123, "policy_loss": -0.01263735741341634, "dist_entropy": 0.568246595064799, "actor_grad_norm": 0.17385618388652802, "critic_grad_norm": 0.016841819509863853, "ratio": 0.9992996454238892, "entropy": 0.568246595064799, "incre_win_rate": 0.7592592592592593, "step": 312}
{"time": 1766664276.1588867, "phase": "train", "update": 313, "total_env_steps": 1001600, "episode_reward": 0.2932697832584381, "value_loss": 0.01566365088025729, "policy_loss": -0.012512246740533564, "dist_entropy": 0.5867581168810526, "actor_grad_norm": 0.19356228411197662, "critic_grad_norm": 0.02509475313127041, "ratio": 1.0003447532653809, "entropy": 0.5867581168810526, "incre_win_rate": 0.6923076923076923, "step": 313}
{"time": 1766664280.4441, "phase": "train", "update": 314, "total_env_steps": 1004800, "episode_reward": 0.3086320459842682, "value_loss": 0.0136152150730292, "policy_loss": -0.012981672938456038, "dist_entropy": 0.572957980632782, "actor_grad_norm": 0.15204522013664246, "critic_grad_norm": 0.05304083600640297, "ratio": 0.9977964162826538, "entropy": 0.572957980632782, "incre_win_rate": 0.6545454545454545, "step": 314}
{"time": 1766664284.718368, "phase": "train", "update": 315, "total_env_steps": 1008000, "episode_reward": 0.30721431970596313, "value_loss": 0.014976945395270983, "policy_loss": -0.011814645197936121, "dist_entropy": 0.5620635906855266, "actor_grad_norm": 0.18736854195594788, "critic_grad_norm": 0.027066398411989212, "ratio": 0.9996200203895569, "entropy": 0.5620635906855266, "incre_win_rate": 0.6851851851851852, "step": 315}
{"time": 1766664289.066685, "phase": "train", "update": 316, "total_env_steps": 1011200, "episode_reward": 0.3276240825653076, "value_loss": 0.009683775715529919, "policy_loss": -0.011910396648309056, "dist_entropy": 0.5690927465756734, "actor_grad_norm": 0.16035684943199158, "critic_grad_norm": 0.05460403487086296, "ratio": 0.9986392855644226, "entropy": 0.5690927465756734, "incre_win_rate": 0.8392857142857143, "step": 316}
{"time": 1766664293.3666475, "phase": "train", "update": 317, "total_env_steps": 1014400, "episode_reward": 0.31964075565338135, "value_loss": 0.0132092522457242, "policy_loss": -0.012243154414160528, "dist_entropy": 0.5602451999982198, "actor_grad_norm": 0.21414320170879364, "critic_grad_norm": 0.04987764358520508, "ratio": 1.0001444816589355, "entropy": 0.5602451999982198, "incre_win_rate": 0.8301886792452831, "step": 317}
{"time": 1766664297.660959, "phase": "train", "update": 318, "total_env_steps": 1017600, "episode_reward": 0.308829665184021, "value_loss": 0.01532344880203406, "policy_loss": -0.013102147562635953, "dist_entropy": 0.5764073689778646, "actor_grad_norm": 0.18646074831485748, "critic_grad_norm": 0.05638524889945984, "ratio": 0.9975588321685791, "entropy": 0.5764073689778646, "incre_win_rate": 0.6964285714285714, "step": 318}
{"time": 1766664301.9404423, "phase": "train", "update": 319, "total_env_steps": 1020800, "episode_reward": 0.2980537712574005, "value_loss": 0.01683957055211067, "policy_loss": -0.012946381315616347, "dist_entropy": 0.5676697492599487, "actor_grad_norm": 0.18397870659828186, "critic_grad_norm": 0.05236411839723587, "ratio": 1.00115966796875, "entropy": 0.5676697492599487, "incre_win_rate": 0.6153846153846154, "step": 319}
{"time": 1766664306.1290746, "phase": "train", "update": 320, "total_env_steps": 1024000, "episode_reward": 0.2903224527835846, "value_loss": 0.018575683484474817, "policy_loss": -0.012996015802044998, "dist_entropy": 0.561931844552358, "actor_grad_norm": 0.19906429946422577, "critic_grad_norm": 0.03934932500123978, "ratio": 1.0001274347305298, "entropy": 0.561931844552358, "incre_win_rate": 0.6470588235294118, "step": 320}
{"time": 1766664310.4250789, "phase": "train", "update": 321, "total_env_steps": 1027200, "episode_reward": 0.2948514223098755, "value_loss": 0.014738831482827664, "policy_loss": -0.01227818117151737, "dist_entropy": 0.5721863309542338, "actor_grad_norm": 0.1985558420419693, "critic_grad_norm": 0.024690762162208557, "ratio": 1.0001322031021118, "entropy": 0.5721863309542338, "incre_win_rate": 0.6363636363636364, "step": 321}
{"time": 1766664317.7624683, "phase": "eval", "update": 321, "total_env_steps": 1027200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.223728553921568, "step": 321}
{"time": 1766664322.0591774, "phase": "train", "update": 322, "total_env_steps": 1030400, "episode_reward": 0.3106594979763031, "value_loss": 0.013347356207668781, "policy_loss": -0.01323756921883102, "dist_entropy": 0.5800865133603413, "actor_grad_norm": 0.15541444718837738, "critic_grad_norm": 0.05213772878050804, "ratio": 0.9986823201179504, "entropy": 0.5800865133603413, "incre_win_rate": 0.6851851851851852, "step": 322}
{"time": 1766664326.3051474, "phase": "train", "update": 323, "total_env_steps": 1033600, "episode_reward": 0.2993083894252777, "value_loss": 0.018788057565689086, "policy_loss": -0.012624958931442857, "dist_entropy": 0.572539496421814, "actor_grad_norm": 0.17016319930553436, "critic_grad_norm": 0.073860302567482, "ratio": 0.9984328746795654, "entropy": 0.572539496421814, "incre_win_rate": 0.6428571428571429, "step": 323}
{"time": 1766664330.62884, "phase": "train", "update": 324, "total_env_steps": 1036800, "episode_reward": 0.2911014258861542, "value_loss": 0.01797275518377622, "policy_loss": -0.01338960971880283, "dist_entropy": 0.593148410320282, "actor_grad_norm": 0.17355138063430786, "critic_grad_norm": 0.024220915511250496, "ratio": 0.9997132420539856, "entropy": 0.593148410320282, "incre_win_rate": 0.5849056603773585, "step": 324}
{"time": 1766664334.9737363, "phase": "train", "update": 325, "total_env_steps": 1040000, "episode_reward": 0.29718291759490967, "value_loss": 0.01877729408442974, "policy_loss": -0.01303019406733957, "dist_entropy": 0.5690548300743103, "actor_grad_norm": 0.2260260432958603, "critic_grad_norm": 0.048050299286842346, "ratio": 0.9993107318878174, "entropy": 0.5690548300743103, "incre_win_rate": 0.5925925925925926, "step": 325}
{"time": 1766664339.2444174, "phase": "train", "update": 326, "total_env_steps": 1043200, "episode_reward": 0.29237285256385803, "value_loss": 0.014306184525291124, "policy_loss": -0.012741734631712612, "dist_entropy": 0.570337998867035, "actor_grad_norm": 0.2005419135093689, "critic_grad_norm": 0.04409162327647209, "ratio": 0.9995942115783691, "entropy": 0.570337998867035, "incre_win_rate": 0.5925925925925926, "step": 326}
{"time": 1766664364.066967, "phase": "train", "update": 327, "total_env_steps": 1046400, "episode_reward": 0.2747074365615845, "value_loss": 0.05513504569729169, "policy_loss": -0.011499538137015482, "dist_entropy": 0.5815145572026571, "actor_grad_norm": 0.15835706889629364, "critic_grad_norm": 0.17921555042266846, "ratio": 0.9999423027038574, "entropy": 0.5815145572026571, "incre_win_rate": 0.46, "step": 327}
{"time": 1766664368.2849565, "phase": "train", "update": 328, "total_env_steps": 1049600, "episode_reward": 0.290251225233078, "value_loss": 0.015953431837260723, "policy_loss": -0.013497744384815746, "dist_entropy": 0.5884130160013835, "actor_grad_norm": 0.21129459142684937, "critic_grad_norm": 0.11599819362163544, "ratio": 0.9988458752632141, "entropy": 0.5884130160013835, "incre_win_rate": 0.6346153846153846, "step": 328}
{"time": 1766664372.537198, "phase": "train", "update": 329, "total_env_steps": 1052800, "episode_reward": 0.3013893961906433, "value_loss": 0.018634818121790887, "policy_loss": -0.012689432849712527, "dist_entropy": 0.5989977876345317, "actor_grad_norm": 0.1974315047264099, "critic_grad_norm": 0.08613032102584839, "ratio": 0.9998717308044434, "entropy": 0.5989977876345317, "incre_win_rate": 0.7037037037037037, "step": 329}
{"time": 1766664376.7810884, "phase": "train", "update": 330, "total_env_steps": 1056000, "episode_reward": 0.2794201970100403, "value_loss": 0.0219666950404644, "policy_loss": -0.01321980565022424, "dist_entropy": 0.6008394400278727, "actor_grad_norm": 0.22843541204929352, "critic_grad_norm": 0.05182048678398132, "ratio": 0.9989994168281555, "entropy": 0.6008394400278727, "incre_win_rate": 0.5490196078431373, "step": 330}
{"time": 1766664381.032907, "phase": "train", "update": 331, "total_env_steps": 1059200, "episode_reward": 0.27070698142051697, "value_loss": 0.015510877470175426, "policy_loss": -0.013434670342713137, "dist_entropy": 0.6110737562179566, "actor_grad_norm": 0.2056945264339447, "critic_grad_norm": 0.035184964537620544, "ratio": 0.9984079003334045, "entropy": 0.6110737562179566, "incre_win_rate": 0.6170212765957447, "step": 331}
{"time": 1766664385.3319702, "phase": "train", "update": 332, "total_env_steps": 1062400, "episode_reward": 0.2960072457790375, "value_loss": 0.018482863530516626, "policy_loss": -0.013336934480410238, "dist_entropy": 0.5915454506874085, "actor_grad_norm": 0.18621112406253815, "critic_grad_norm": 0.05667503923177719, "ratio": 0.9994779825210571, "entropy": 0.5915454506874085, "incre_win_rate": 0.660377358490566, "step": 332}
{"time": 1766664389.6045668, "phase": "train", "update": 333, "total_env_steps": 1065600, "episode_reward": 0.2843765318393707, "value_loss": 0.016508591671784718, "policy_loss": -0.01296496003627586, "dist_entropy": 0.5845102747281392, "actor_grad_norm": 0.16939811408519745, "critic_grad_norm": 0.06076402589678764, "ratio": 1.0006481409072876, "entropy": 0.5845102747281392, "incre_win_rate": 0.5849056603773585, "step": 333}
{"time": 1766664393.8543997, "phase": "train", "update": 334, "total_env_steps": 1068800, "episode_reward": 0.2899578809738159, "value_loss": 0.017952762668331464, "policy_loss": -0.013853814199976, "dist_entropy": 0.5856602509816488, "actor_grad_norm": 0.22490890324115753, "critic_grad_norm": 0.035825926810503006, "ratio": 0.9989186525344849, "entropy": 0.5856602509816488, "incre_win_rate": 0.5740740740740741, "step": 334}
{"time": 1766664398.104052, "phase": "train", "update": 335, "total_env_steps": 1072000, "episode_reward": 0.2894592881202698, "value_loss": 0.014601807110011578, "policy_loss": -0.012587740380989013, "dist_entropy": 0.5762920697530111, "actor_grad_norm": 0.18366986513137817, "critic_grad_norm": 0.03181027993559837, "ratio": 0.9987169504165649, "entropy": 0.5762920697530111, "incre_win_rate": 0.5769230769230769, "step": 335}
{"time": 1766664402.3746004, "phase": "train", "update": 336, "total_env_steps": 1075200, "episode_reward": 0.28636646270751953, "value_loss": 0.016813936891655126, "policy_loss": -0.012999391122744775, "dist_entropy": 0.5916972200075785, "actor_grad_norm": 0.16429778933525085, "critic_grad_norm": 0.08376436680555344, "ratio": 0.9992982149124146, "entropy": 0.5916972200075785, "incre_win_rate": 0.7115384615384616, "step": 336}
{"time": 1766664406.6494033, "phase": "train", "update": 337, "total_env_steps": 1078400, "episode_reward": 0.30071768164634705, "value_loss": 0.017369607215126356, "policy_loss": -0.012469748315586553, "dist_entropy": 0.6005659461021423, "actor_grad_norm": 0.20939524471759796, "critic_grad_norm": 0.06065578758716583, "ratio": 1.0000710487365723, "entropy": 0.6005659461021423, "incre_win_rate": 0.6981132075471698, "step": 337}
{"time": 1766664410.9925644, "phase": "train", "update": 338, "total_env_steps": 1081600, "episode_reward": 0.3037163019180298, "value_loss": 0.01912641463180383, "policy_loss": -0.012142180072291826, "dist_entropy": 0.5764619628588359, "actor_grad_norm": 0.21451126039028168, "critic_grad_norm": 0.06812015920877457, "ratio": 0.9994669556617737, "entropy": 0.5764619628588359, "incre_win_rate": 0.75, "step": 338}
{"time": 1766664415.2544646, "phase": "train", "update": 339, "total_env_steps": 1084800, "episode_reward": 0.30285388231277466, "value_loss": 0.015441473449269931, "policy_loss": -0.01346068068347807, "dist_entropy": 0.5866421262423197, "actor_grad_norm": 0.15792809426784515, "critic_grad_norm": 0.0768284946680069, "ratio": 0.9994043707847595, "entropy": 0.5866421262423197, "incre_win_rate": 0.7358490566037735, "step": 339}
{"time": 1766664419.6406145, "phase": "train", "update": 340, "total_env_steps": 1088000, "episode_reward": 0.29330116510391235, "value_loss": 0.017729911332329113, "policy_loss": -0.013419332024648385, "dist_entropy": 0.5660630702972412, "actor_grad_norm": 0.18421776592731476, "critic_grad_norm": 0.09369702637195587, "ratio": 1.000389814376831, "entropy": 0.5660630702972412, "incre_win_rate": 0.6346153846153846, "step": 340}
{"time": 1766664423.893343, "phase": "train", "update": 341, "total_env_steps": 1091200, "episode_reward": 0.3036067485809326, "value_loss": 0.01448115340123574, "policy_loss": -0.012837361015939307, "dist_entropy": 0.5734409332275391, "actor_grad_norm": 0.16713936626911163, "critic_grad_norm": 0.0743199959397316, "ratio": 0.9983547925949097, "entropy": 0.5734409332275391, "incre_win_rate": 0.7692307692307693, "step": 341}
{"time": 1766664431.5337179, "phase": "eval", "update": 341, "total_env_steps": 1091200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.740349264705884, "step": 341}
{"time": 1766664435.78127, "phase": "train", "update": 342, "total_env_steps": 1094400, "episode_reward": 0.3156127631664276, "value_loss": 0.008545674942433834, "policy_loss": -0.013116734395666185, "dist_entropy": 0.5901288628578186, "actor_grad_norm": 0.19937469065189362, "critic_grad_norm": 0.07495605200529099, "ratio": 1.0002796649932861, "entropy": 0.5901288628578186, "incre_win_rate": 0.8490566037735849, "step": 342}
{"time": 1766664440.0791821, "phase": "train", "update": 343, "total_env_steps": 1097600, "episode_reward": 0.3120090663433075, "value_loss": 0.012134393180410067, "policy_loss": -0.012541001346020646, "dist_entropy": 0.5792087475458781, "actor_grad_norm": 0.1785236895084381, "critic_grad_norm": 0.04317663982510567, "ratio": 0.9994502067565918, "entropy": 0.5792087475458781, "incre_win_rate": 0.7777777777777778, "step": 343}
{"time": 1766664444.3376489, "phase": "train", "update": 344, "total_env_steps": 1100800, "episode_reward": 0.317867636680603, "value_loss": 0.008920182287693024, "policy_loss": -0.01216492326047008, "dist_entropy": 0.5794385234514873, "actor_grad_norm": 0.18322055041790009, "critic_grad_norm": 0.032204367220401764, "ratio": 0.9996328949928284, "entropy": 0.5794385234514873, "incre_win_rate": 0.9019607843137255, "step": 344}
{"time": 1766664448.6011803, "phase": "train", "update": 345, "total_env_steps": 1104000, "episode_reward": 0.3053048849105835, "value_loss": 0.012665630380312601, "policy_loss": -0.012343332935508045, "dist_entropy": 0.5766200582186382, "actor_grad_norm": 0.19572411477565765, "critic_grad_norm": 0.028760064393281937, "ratio": 0.999567985534668, "entropy": 0.5766200582186382, "incre_win_rate": 0.8235294117647058, "step": 345}
{"time": 1766664452.8547866, "phase": "train", "update": 346, "total_env_steps": 1107200, "episode_reward": 0.3033126890659332, "value_loss": 0.010804143423835436, "policy_loss": -0.012643149888208426, "dist_entropy": 0.6081713199615478, "actor_grad_norm": 0.180267333984375, "critic_grad_norm": 0.013787005096673965, "ratio": 0.9993547201156616, "entropy": 0.6081713199615478, "incre_win_rate": 0.8235294117647058, "step": 346}
{"time": 1766664457.1673744, "phase": "train", "update": 347, "total_env_steps": 1110400, "episode_reward": 0.29660844802856445, "value_loss": 0.013998881913721561, "policy_loss": -0.012802804813411702, "dist_entropy": 0.598703666528066, "actor_grad_norm": 0.1865403950214386, "critic_grad_norm": 0.072856605052948, "ratio": 1.0001554489135742, "entropy": 0.598703666528066, "incre_win_rate": 0.6792452830188679, "step": 347}
{"time": 1766664461.4432747, "phase": "train", "update": 348, "total_env_steps": 1113600, "episode_reward": 0.2936818301677704, "value_loss": 0.011458695804079374, "policy_loss": -0.01291722628471934, "dist_entropy": 0.5855008999506632, "actor_grad_norm": 0.18924295902252197, "critic_grad_norm": 0.035297803580760956, "ratio": 0.9991644620895386, "entropy": 0.5855008999506632, "incre_win_rate": 0.7, "step": 348}
{"time": 1766664465.7411933, "phase": "train", "update": 349, "total_env_steps": 1116800, "episode_reward": 0.3070979118347168, "value_loss": 0.014368746305505435, "policy_loss": -0.01281939765526848, "dist_entropy": 0.5730633815129598, "actor_grad_norm": 0.17612324655056, "critic_grad_norm": 0.07411530613899231, "ratio": 0.9999092221260071, "entropy": 0.5730633815129598, "incre_win_rate": 0.7407407407407407, "step": 349}
{"time": 1766664469.9978018, "phase": "train", "update": 350, "total_env_steps": 1120000, "episode_reward": 0.30134421586990356, "value_loss": 0.013699068563679855, "policy_loss": -0.01381515331549584, "dist_entropy": 0.6035218795140584, "actor_grad_norm": 0.22961308062076569, "critic_grad_norm": 0.037905190140008926, "ratio": 0.9986934661865234, "entropy": 0.6035218795140584, "incre_win_rate": 0.6981132075471698, "step": 350}
{"time": 1766664474.291745, "phase": "train", "update": 351, "total_env_steps": 1123200, "episode_reward": 0.29571691155433655, "value_loss": 0.01941613480448723, "policy_loss": -0.013580979728944934, "dist_entropy": 0.57539089123408, "actor_grad_norm": 0.20498588681221008, "critic_grad_norm": 0.05853020399808884, "ratio": 0.9997373223304749, "entropy": 0.57539089123408, "incre_win_rate": 0.6, "step": 351}
{"time": 1766664478.578741, "phase": "train", "update": 352, "total_env_steps": 1126400, "episode_reward": 0.2972564399242401, "value_loss": 0.015711781630913416, "policy_loss": -0.013075841722278507, "dist_entropy": 0.6048586408297221, "actor_grad_norm": 0.2136908322572708, "critic_grad_norm": 0.04271949455142021, "ratio": 0.9983814358711243, "entropy": 0.6048586408297221, "incre_win_rate": 0.6111111111111112, "step": 352}
{"time": 1766664482.8728395, "phase": "train", "update": 353, "total_env_steps": 1129600, "episode_reward": 0.2982896864414215, "value_loss": 0.017115033914645514, "policy_loss": -0.013032764204424296, "dist_entropy": 0.5985249439875285, "actor_grad_norm": 0.17063897848129272, "critic_grad_norm": 0.06512460857629776, "ratio": 0.999971866607666, "entropy": 0.5985249439875285, "incre_win_rate": 0.6666666666666666, "step": 353}
{"time": 1766664487.186403, "phase": "train", "update": 354, "total_env_steps": 1132800, "episode_reward": 0.30023670196533203, "value_loss": 0.015825484630962214, "policy_loss": -0.01257705329203939, "dist_entropy": 0.5927834788958232, "actor_grad_norm": 0.20993854105472565, "critic_grad_norm": 0.046328362077474594, "ratio": 0.9991883039474487, "entropy": 0.5927834788958232, "incre_win_rate": 0.7037037037037037, "step": 354}
{"time": 1766664491.4639733, "phase": "train", "update": 355, "total_env_steps": 1136000, "episode_reward": 0.29153186082839966, "value_loss": 0.01580091696232557, "policy_loss": -0.013208141495433286, "dist_entropy": 0.6122274001439413, "actor_grad_norm": 0.2313927859067917, "critic_grad_norm": 0.04198100417852402, "ratio": 0.9984021782875061, "entropy": 0.6122274001439413, "incre_win_rate": 0.6538461538461539, "step": 355}
{"time": 1766664495.6559074, "phase": "train", "update": 356, "total_env_steps": 1139200, "episode_reward": 0.2934030592441559, "value_loss": 0.01877318633099397, "policy_loss": -0.012173268756259148, "dist_entropy": 0.6017752051353454, "actor_grad_norm": 0.18176163733005524, "critic_grad_norm": 0.04027640074491501, "ratio": 0.9984684586524963, "entropy": 0.6017752051353454, "incre_win_rate": 0.6923076923076923, "step": 356}
{"time": 1766664499.8921812, "phase": "train", "update": 357, "total_env_steps": 1142400, "episode_reward": 0.2742854058742523, "value_loss": 0.01621464577813943, "policy_loss": -0.014786385600241658, "dist_entropy": 0.6016776522000631, "actor_grad_norm": 0.24100223183631897, "critic_grad_norm": 0.08542734384536743, "ratio": 0.9992442727088928, "entropy": 0.6016776522000631, "incre_win_rate": 0.6326530612244898, "step": 357}
{"time": 1766664504.1754699, "phase": "train", "update": 358, "total_env_steps": 1145600, "episode_reward": 0.28823912143707275, "value_loss": 0.01263317484408617, "policy_loss": -0.01171241512159232, "dist_entropy": 0.6218740781148274, "actor_grad_norm": 0.1753784418106079, "critic_grad_norm": 0.042870260775089264, "ratio": 0.9995772838592529, "entropy": 0.6218740781148274, "incre_win_rate": 0.7254901960784313, "step": 358}
{"time": 1766664508.423003, "phase": "train", "update": 359, "total_env_steps": 1148800, "episode_reward": 0.29188498854637146, "value_loss": 0.014723062328994275, "policy_loss": -0.013046420115879205, "dist_entropy": 0.5906340837478637, "actor_grad_norm": 0.1981802135705948, "critic_grad_norm": 0.06917469203472137, "ratio": 0.9994781017303467, "entropy": 0.5906340837478637, "incre_win_rate": 0.6938775510204082, "step": 359}
{"time": 1766664512.7122517, "phase": "train", "update": 360, "total_env_steps": 1152000, "episode_reward": 0.2975068986415863, "value_loss": 0.012498079674939315, "policy_loss": -0.012056336095045594, "dist_entropy": 0.5939953764279683, "actor_grad_norm": 0.1729377955198288, "critic_grad_norm": 0.04639420285820961, "ratio": 1.0004240274429321, "entropy": 0.5939953764279683, "incre_win_rate": 0.6851851851851852, "step": 360}
{"time": 1766664517.0098898, "phase": "train", "update": 361, "total_env_steps": 1155200, "episode_reward": 0.28839921951293945, "value_loss": 0.012773294436434905, "policy_loss": -0.012676781814192021, "dist_entropy": 0.6060556530952453, "actor_grad_norm": 0.21098217368125916, "critic_grad_norm": 0.05181564763188362, "ratio": 1.0002555847167969, "entropy": 0.6060556530952453, "incre_win_rate": 0.7551020408163265, "step": 361}
{"time": 1766664525.1131198, "phase": "eval", "update": 361, "total_env_steps": 1155200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.766467524509803, "step": 361}
{"time": 1766664529.336358, "phase": "train", "update": 362, "total_env_steps": 1158400, "episode_reward": 0.2877374589443207, "value_loss": 0.014368559171756109, "policy_loss": -0.013388348292637886, "dist_entropy": 0.5767821431159973, "actor_grad_norm": 0.1845806986093521, "critic_grad_norm": 0.06365495175123215, "ratio": 1.0009781122207642, "entropy": 0.5767821431159973, "incre_win_rate": 0.6274509803921569, "step": 362}
{"time": 1766664533.6028233, "phase": "train", "update": 363, "total_env_steps": 1161600, "episode_reward": 0.2987867593765259, "value_loss": 0.011906010533372561, "policy_loss": -0.013466931243515272, "dist_entropy": 0.6020871162414551, "actor_grad_norm": 0.20847657322883606, "critic_grad_norm": 0.040559541434049606, "ratio": 1.0008596181869507, "entropy": 0.6020871162414551, "incre_win_rate": 0.7307692307692307, "step": 363}
{"time": 1766664537.8749359, "phase": "train", "update": 364, "total_env_steps": 1164800, "episode_reward": 0.3045167326927185, "value_loss": 0.00954854004085064, "policy_loss": -0.012963822876952117, "dist_entropy": 0.5935497204462687, "actor_grad_norm": 0.19278205931186676, "critic_grad_norm": 0.020623134449124336, "ratio": 0.9998199343681335, "entropy": 0.5935497204462687, "incre_win_rate": 0.8269230769230769, "step": 364}
{"time": 1766664542.1457722, "phase": "train", "update": 365, "total_env_steps": 1168000, "episode_reward": 0.2998230755329132, "value_loss": 0.016873442071179547, "policy_loss": -0.013003695236527573, "dist_entropy": 0.5576252420743306, "actor_grad_norm": 0.20474457740783691, "critic_grad_norm": 0.04305695742368698, "ratio": 0.9994872808456421, "entropy": 0.5576252420743306, "incre_win_rate": 0.7307692307692307, "step": 365}
{"time": 1766664546.4329116, "phase": "train", "update": 366, "total_env_steps": 1171200, "episode_reward": 0.29877525568008423, "value_loss": 0.010455230064690114, "policy_loss": -0.01283404879382412, "dist_entropy": 0.5935990770657857, "actor_grad_norm": 0.18373093008995056, "critic_grad_norm": 0.09507197141647339, "ratio": 0.9987664222717285, "entropy": 0.5935990770657857, "incre_win_rate": 0.7916666666666666, "step": 366}
{"time": 1766664550.6251607, "phase": "train", "update": 367, "total_env_steps": 1174400, "episode_reward": 0.2589215636253357, "value_loss": 0.014395501216252644, "policy_loss": -0.014116011924468808, "dist_entropy": 0.5876798907915751, "actor_grad_norm": 0.19529151916503906, "critic_grad_norm": 0.06493969261646271, "ratio": 0.9994088411331177, "entropy": 0.5876798907915751, "incre_win_rate": 0.5714285714285714, "step": 367}
{"time": 1766664554.8696322, "phase": "train", "update": 368, "total_env_steps": 1177600, "episode_reward": 0.294898122549057, "value_loss": 0.01213237748791774, "policy_loss": -0.013109793703921468, "dist_entropy": 0.5756285945574443, "actor_grad_norm": 0.17079535126686096, "critic_grad_norm": 0.022370517253875732, "ratio": 0.9978495836257935, "entropy": 0.5756285945574443, "incre_win_rate": 0.6666666666666666, "step": 368}
{"time": 1766664559.1558318, "phase": "train", "update": 369, "total_env_steps": 1180800, "episode_reward": 0.3033800721168518, "value_loss": 0.01697091901053985, "policy_loss": -0.011961424011558582, "dist_entropy": 0.5722764611244202, "actor_grad_norm": 0.19466105103492737, "critic_grad_norm": 0.039842795580625534, "ratio": 0.9991329908370972, "entropy": 0.5722764611244202, "incre_win_rate": 0.7169811320754716, "step": 369}
{"time": 1766664563.3885982, "phase": "train", "update": 370, "total_env_steps": 1184000, "episode_reward": 0.30843061208724976, "value_loss": 0.012148914486169815, "policy_loss": -0.012934537335896341, "dist_entropy": 0.5864807446797689, "actor_grad_norm": 0.19444943964481354, "critic_grad_norm": 0.05542740598320961, "ratio": 1.0003607273101807, "entropy": 0.5864807446797689, "incre_win_rate": 0.8113207547169812, "step": 370}
{"time": 1766664567.6932185, "phase": "train", "update": 371, "total_env_steps": 1187200, "episode_reward": 0.29855623841285706, "value_loss": 0.013561345202227433, "policy_loss": -0.013885002815763414, "dist_entropy": 0.594896650314331, "actor_grad_norm": 0.19581295549869537, "critic_grad_norm": 0.0319790318608284, "ratio": 1.0003957748413086, "entropy": 0.594896650314331, "incre_win_rate": 0.8125, "step": 371}
{"time": 1766664571.9925008, "phase": "train", "update": 372, "total_env_steps": 1190400, "episode_reward": 0.300289511680603, "value_loss": 0.010166379809379577, "policy_loss": -0.012344977522435368, "dist_entropy": 0.5957656423250834, "actor_grad_norm": 0.19174516201019287, "critic_grad_norm": 0.017943480983376503, "ratio": 0.999859631061554, "entropy": 0.5957656423250834, "incre_win_rate": 0.8461538461538461, "step": 372}
{"time": 1766664576.5341744, "phase": "train", "update": 373, "total_env_steps": 1193600, "episode_reward": 0.286001056432724, "value_loss": 0.015411979767183464, "policy_loss": -0.012289708300330915, "dist_entropy": 0.5915007670720418, "actor_grad_norm": 0.16200613975524902, "critic_grad_norm": 0.06351673603057861, "ratio": 0.9996265769004822, "entropy": 0.5915007670720418, "incre_win_rate": 0.6470588235294118, "step": 373}
{"time": 1766664581.0354264, "phase": "train", "update": 374, "total_env_steps": 1196800, "episode_reward": 0.28767693042755127, "value_loss": 0.014246372506022453, "policy_loss": -0.013590233564445952, "dist_entropy": 0.5900723814964295, "actor_grad_norm": 0.21385431289672852, "critic_grad_norm": 0.05576322227716446, "ratio": 1.0009139776229858, "entropy": 0.5900723814964295, "incre_win_rate": 0.6862745098039216, "step": 374}
{"time": 1766664585.39529, "phase": "train", "update": 375, "total_env_steps": 1200000, "episode_reward": 0.30959179997444153, "value_loss": 0.010613802261650563, "policy_loss": -0.012688465128792832, "dist_entropy": 0.5948831041653951, "actor_grad_norm": 0.18185082077980042, "critic_grad_norm": 0.0252796970307827, "ratio": 0.9998301863670349, "entropy": 0.5948831041653951, "incre_win_rate": 0.7924528301886793, "step": 375}
{"time": 1766664589.6488342, "phase": "train", "update": 376, "total_env_steps": 1203200, "episode_reward": 0.2976018786430359, "value_loss": 0.012350309702257315, "policy_loss": -0.013399110104710014, "dist_entropy": 0.5828290939331054, "actor_grad_norm": 0.1759709268808365, "critic_grad_norm": 0.014018225483596325, "ratio": 0.999509334564209, "entropy": 0.5828290939331054, "incre_win_rate": 0.7755102040816326, "step": 376}
{"time": 1766664593.9410067, "phase": "train", "update": 377, "total_env_steps": 1206400, "episode_reward": 0.3071208894252777, "value_loss": 0.013557146737972895, "policy_loss": -0.01249688023566217, "dist_entropy": 0.5840932408968608, "actor_grad_norm": 0.21122094988822937, "critic_grad_norm": 0.031420279294252396, "ratio": 0.9999046921730042, "entropy": 0.5840932408968608, "incre_win_rate": 0.8113207547169812, "step": 377}
{"time": 1766664598.2608073, "phase": "train", "update": 378, "total_env_steps": 1209600, "episode_reward": 0.3097503185272217, "value_loss": 0.011546457558870316, "policy_loss": -0.012553059755848394, "dist_entropy": 0.5825107336044312, "actor_grad_norm": 0.16551607847213745, "critic_grad_norm": 0.02582220733165741, "ratio": 0.9993736743927002, "entropy": 0.5825107336044312, "incre_win_rate": 0.7735849056603774, "step": 378}
{"time": 1766664602.5212343, "phase": "train", "update": 379, "total_env_steps": 1212800, "episode_reward": 0.30432751774787903, "value_loss": 0.009478405428429445, "policy_loss": -0.012276828402930089, "dist_entropy": 0.5926823933919271, "actor_grad_norm": 0.170918807387352, "critic_grad_norm": 0.01932682655751705, "ratio": 0.9993857741355896, "entropy": 0.5926823933919271, "incre_win_rate": 0.8367346938775511, "step": 379}
{"time": 1766664606.9025767, "phase": "train", "update": 380, "total_env_steps": 1216000, "episode_reward": 0.30132582783699036, "value_loss": 0.01137332475433747, "policy_loss": -0.012858503679664561, "dist_entropy": 0.6113486647605896, "actor_grad_norm": 0.17614704370498657, "critic_grad_norm": 0.04008795693516731, "ratio": 1.000101089477539, "entropy": 0.6113486647605896, "incre_win_rate": 0.7735849056603774, "step": 380}
{"time": 1766664611.162888, "phase": "train", "update": 381, "total_env_steps": 1219200, "episode_reward": 0.29639169573783875, "value_loss": 0.014753441823025544, "policy_loss": -0.0124904352828068, "dist_entropy": 0.6062876502672832, "actor_grad_norm": 0.17621056735515594, "critic_grad_norm": 0.06553398817777634, "ratio": 1.0006468296051025, "entropy": 0.6062876502672832, "incre_win_rate": 0.7450980392156863, "step": 381}
{"time": 1766664618.895317, "phase": "eval", "update": 381, "total_env_steps": 1219200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.590073529411768, "step": 381}
{"time": 1766664623.151192, "phase": "train", "update": 382, "total_env_steps": 1222400, "episode_reward": 0.2872602641582489, "value_loss": 0.016467800612250963, "policy_loss": -0.014038074411315667, "dist_entropy": 0.580645724137624, "actor_grad_norm": 0.1624966412782669, "critic_grad_norm": 0.08269935846328735, "ratio": 0.9985294342041016, "entropy": 0.580645724137624, "incre_win_rate": 0.5576923076923077, "step": 382}
{"time": 1766664627.4240353, "phase": "train", "update": 383, "total_env_steps": 1225600, "episode_reward": 0.29914215207099915, "value_loss": 0.01305955486992995, "policy_loss": -0.012010477857232141, "dist_entropy": 0.6006654183069865, "actor_grad_norm": 0.18364794552326202, "critic_grad_norm": 0.04355102777481079, "ratio": 1.0007450580596924, "entropy": 0.6006654183069865, "incre_win_rate": 0.7169811320754716, "step": 383}
{"time": 1766664631.7026393, "phase": "train", "update": 384, "total_env_steps": 1228800, "episode_reward": 0.3045121133327484, "value_loss": 0.013173710430661838, "policy_loss": -0.013490534206558399, "dist_entropy": 0.6055480003356933, "actor_grad_norm": 0.17798329889774323, "critic_grad_norm": 0.05310065299272537, "ratio": 0.9993360638618469, "entropy": 0.6055480003356933, "incre_win_rate": 0.75, "step": 384}
{"time": 1766664636.010687, "phase": "train", "update": 385, "total_env_steps": 1232000, "episode_reward": 0.28597965836524963, "value_loss": 0.0128681896875302, "policy_loss": -0.013153781462484797, "dist_entropy": 0.6063927412033081, "actor_grad_norm": 0.18735814094543457, "critic_grad_norm": 0.06435225158929825, "ratio": 1.0000159740447998, "entropy": 0.6063927412033081, "incre_win_rate": 0.6470588235294118, "step": 385}
{"time": 1766664640.3205464, "phase": "train", "update": 386, "total_env_steps": 1235200, "episode_reward": 0.3076508641242981, "value_loss": 0.009823497322698434, "policy_loss": -0.012205954863774574, "dist_entropy": 0.6091824730237325, "actor_grad_norm": 0.17975983023643494, "critic_grad_norm": 0.07582899183034897, "ratio": 0.9996559023857117, "entropy": 0.6091824730237325, "incre_win_rate": 0.8076923076923077, "step": 386}
{"time": 1766664644.611729, "phase": "train", "update": 387, "total_env_steps": 1238400, "episode_reward": 0.28798791766166687, "value_loss": 0.014436105700830619, "policy_loss": -0.012998166484184519, "dist_entropy": 0.6011403242746989, "actor_grad_norm": 0.17342376708984375, "critic_grad_norm": 0.05805860087275505, "ratio": 0.9989365935325623, "entropy": 0.6011403242746989, "incre_win_rate": 0.6470588235294118, "step": 387}
{"time": 1766664649.1278093, "phase": "train", "update": 388, "total_env_steps": 1241600, "episode_reward": 0.3040127158164978, "value_loss": 0.016059264354407788, "policy_loss": -0.013798574084671836, "dist_entropy": 0.6186008930206299, "actor_grad_norm": 0.1781148612499237, "critic_grad_norm": 0.033398207277059555, "ratio": 0.9997658133506775, "entropy": 0.6186008930206299, "incre_win_rate": 0.7254901960784313, "step": 388}
{"time": 1766664653.609299, "phase": "train", "update": 389, "total_env_steps": 1244800, "episode_reward": 0.3034198582172394, "value_loss": 0.012671483680605888, "policy_loss": -0.013454011295026665, "dist_entropy": 0.5955832163492839, "actor_grad_norm": 0.1844327449798584, "critic_grad_norm": 0.028817839920520782, "ratio": 0.9997659921646118, "entropy": 0.5955832163492839, "incre_win_rate": 0.6363636363636364, "step": 389}
{"time": 1766664657.8947728, "phase": "train", "update": 390, "total_env_steps": 1248000, "episode_reward": 0.2913641333580017, "value_loss": 0.013911163869003455, "policy_loss": -0.014122730446178384, "dist_entropy": 0.6055238008499145, "actor_grad_norm": 0.17195017635822296, "critic_grad_norm": 0.06830969452857971, "ratio": 1.000157356262207, "entropy": 0.6055238008499145, "incre_win_rate": 0.5818181818181818, "step": 390}
{"time": 1766664662.1434948, "phase": "train", "update": 391, "total_env_steps": 1251200, "episode_reward": 0.3092110753059387, "value_loss": 0.015262209189434847, "policy_loss": -0.013274858268700503, "dist_entropy": 0.6038630962371826, "actor_grad_norm": 0.163395956158638, "critic_grad_norm": 0.03994133695960045, "ratio": 0.9995246529579163, "entropy": 0.6038630962371826, "incre_win_rate": 0.6792452830188679, "step": 391}
{"time": 1766664666.4336755, "phase": "train", "update": 392, "total_env_steps": 1254400, "episode_reward": 0.3059788942337036, "value_loss": 0.016093272777895132, "policy_loss": -0.012694809581157547, "dist_entropy": 0.6134204347928365, "actor_grad_norm": 0.1585400402545929, "critic_grad_norm": 0.0526927188038826, "ratio": 0.9990472793579102, "entropy": 0.6134204347928365, "incre_win_rate": 0.7169811320754716, "step": 392}
{"time": 1766664670.7189465, "phase": "train", "update": 393, "total_env_steps": 1257600, "episode_reward": 0.30366116762161255, "value_loss": 0.011349013696114222, "policy_loss": -0.012988970418484413, "dist_entropy": 0.5941716829935709, "actor_grad_norm": 0.20040854811668396, "critic_grad_norm": 0.10672926157712936, "ratio": 0.9991684556007385, "entropy": 0.5941716829935709, "incre_win_rate": 0.7692307692307693, "step": 393}
{"time": 1766664674.9657485, "phase": "train", "update": 394, "total_env_steps": 1260800, "episode_reward": 0.30560433864593506, "value_loss": 0.01134892279903094, "policy_loss": -0.012126791674198027, "dist_entropy": 0.6007296085357666, "actor_grad_norm": 0.16968350112438202, "critic_grad_norm": 0.041208285838365555, "ratio": 1.0004711151123047, "entropy": 0.6007296085357666, "incre_win_rate": 0.8076923076923077, "step": 394}
{"time": 1766664679.2229447, "phase": "train", "update": 395, "total_env_steps": 1264000, "episode_reward": 0.27728864550590515, "value_loss": 0.01671992999811967, "policy_loss": -0.012706481576454702, "dist_entropy": 0.5950263778368632, "actor_grad_norm": 0.21343331038951874, "critic_grad_norm": 0.09418690204620361, "ratio": 1.0002467632293701, "entropy": 0.5950263778368632, "incre_win_rate": 0.5833333333333334, "step": 395}
{"time": 1766664683.4672358, "phase": "train", "update": 396, "total_env_steps": 1267200, "episode_reward": 0.2949639856815338, "value_loss": 0.014766986606021722, "policy_loss": -0.012923683087844159, "dist_entropy": 0.6024782498677571, "actor_grad_norm": 0.16961021721363068, "critic_grad_norm": 0.06248510256409645, "ratio": 1.0002888441085815, "entropy": 0.6024782498677571, "incre_win_rate": 0.7222222222222222, "step": 396}
{"time": 1766664687.7114944, "phase": "train", "update": 397, "total_env_steps": 1270400, "episode_reward": 0.3001731336116791, "value_loss": 0.014984962592522303, "policy_loss": -0.013498448013738814, "dist_entropy": 0.6123867829640707, "actor_grad_norm": 0.16318874061107635, "critic_grad_norm": 0.07240432500839233, "ratio": 0.9985902309417725, "entropy": 0.6123867829640707, "incre_win_rate": 0.7551020408163265, "step": 397}
{"time": 1766664692.0227702, "phase": "train", "update": 398, "total_env_steps": 1273600, "episode_reward": 0.2878163456916809, "value_loss": 0.016986907521883646, "policy_loss": -0.013399430142739751, "dist_entropy": 0.6173233111699422, "actor_grad_norm": 0.1852475255727768, "critic_grad_norm": 0.059975456446409225, "ratio": 0.9993237853050232, "entropy": 0.6173233111699422, "incre_win_rate": 0.5925925925925926, "step": 398}
{"time": 1766664696.3250308, "phase": "train", "update": 399, "total_env_steps": 1276800, "episode_reward": 0.29758578538894653, "value_loss": 0.011528988555073737, "policy_loss": -0.01344146066390787, "dist_entropy": 0.618911349773407, "actor_grad_norm": 0.1902104616165161, "critic_grad_norm": 0.022824103012681007, "ratio": 0.9991538524627686, "entropy": 0.618911349773407, "incre_win_rate": 0.6792452830188679, "step": 399}
{"time": 1766664700.5912342, "phase": "train", "update": 400, "total_env_steps": 1280000, "episode_reward": 0.2829381227493286, "value_loss": 0.014247588689128558, "policy_loss": -0.014592589788715552, "dist_entropy": 0.6351094643274943, "actor_grad_norm": 0.22364401817321777, "critic_grad_norm": 0.07698230445384979, "ratio": 0.9990077018737793, "entropy": 0.6351094643274943, "incre_win_rate": 0.6326530612244898, "step": 400}
{"time": 1766664704.8686728, "phase": "train", "update": 401, "total_env_steps": 1283200, "episode_reward": 0.2756165862083435, "value_loss": 0.014178825045625369, "policy_loss": -0.014204738334198908, "dist_entropy": 0.6147623380025228, "actor_grad_norm": 0.18983443081378937, "critic_grad_norm": 0.035167545080184937, "ratio": 0.9988272190093994, "entropy": 0.6147623380025228, "incre_win_rate": 0.56, "step": 401}
{"time": 1766664713.0861847, "phase": "eval", "update": 401, "total_env_steps": 1283200, "eval_win_rate": 0.84375, "eval_episode_reward": 19.151271446078432, "step": 401}
{"time": 1766664717.3893335, "phase": "train", "update": 402, "total_env_steps": 1286400, "episode_reward": 0.2766444683074951, "value_loss": 0.01961966554323832, "policy_loss": -0.013732441171464889, "dist_entropy": 0.6028053800264994, "actor_grad_norm": 0.25393569469451904, "critic_grad_norm": 0.06634741276502609, "ratio": 0.999817967414856, "entropy": 0.6028053800264994, "incre_win_rate": 0.5283018867924528, "step": 402}
{"time": 1766664721.7010229, "phase": "train", "update": 403, "total_env_steps": 1289600, "episode_reward": 0.2943466901779175, "value_loss": 0.012492500493923824, "policy_loss": -0.013506751432123565, "dist_entropy": 0.6146182179450989, "actor_grad_norm": 0.18424445390701294, "critic_grad_norm": 0.0967612937092781, "ratio": 0.9997958540916443, "entropy": 0.6146182179450989, "incre_win_rate": 0.72, "step": 403}
{"time": 1766664725.965083, "phase": "train", "update": 404, "total_env_steps": 1292800, "episode_reward": 0.2801662087440491, "value_loss": 0.013416140774885814, "policy_loss": -0.013918732961568262, "dist_entropy": 0.6112392902374267, "actor_grad_norm": 0.22191785275936127, "critic_grad_norm": 0.027857204899191856, "ratio": 0.9993571043014526, "entropy": 0.6112392902374267, "incre_win_rate": 0.7083333333333334, "step": 404}
{"time": 1766664730.221878, "phase": "train", "update": 405, "total_env_steps": 1296000, "episode_reward": 0.2872663736343384, "value_loss": 0.012296575369934242, "policy_loss": -0.013034544335937426, "dist_entropy": 0.6007771412531535, "actor_grad_norm": 0.21471388638019562, "critic_grad_norm": 0.02526930905878544, "ratio": 0.9997357726097107, "entropy": 0.6007771412531535, "incre_win_rate": 0.7346938775510204, "step": 405}
{"time": 1766664734.4267716, "phase": "train", "update": 406, "total_env_steps": 1299200, "episode_reward": 0.28484758734703064, "value_loss": 0.016622559539973734, "policy_loss": -0.014106700507543124, "dist_entropy": 0.5925232291221618, "actor_grad_norm": 0.18689921498298645, "critic_grad_norm": 0.07042108476161957, "ratio": 0.9993239641189575, "entropy": 0.5925232291221618, "incre_win_rate": 0.6346153846153846, "step": 406}
{"time": 1766664738.7186494, "phase": "train", "update": 407, "total_env_steps": 1302400, "episode_reward": 0.2929411828517914, "value_loss": 0.013625022831062476, "policy_loss": -0.012372931668177973, "dist_entropy": 0.5973025679588317, "actor_grad_norm": 0.17463354766368866, "critic_grad_norm": 0.047322459518909454, "ratio": 1.000129222869873, "entropy": 0.5973025679588317, "incre_win_rate": 0.6481481481481481, "step": 407}
{"time": 1766664743.040484, "phase": "train", "update": 408, "total_env_steps": 1305600, "episode_reward": 0.2843972146511078, "value_loss": 0.015546031855046749, "policy_loss": -0.013267743235328549, "dist_entropy": 0.598917011419932, "actor_grad_norm": 0.1821400672197342, "critic_grad_norm": 0.028966525569558144, "ratio": 0.9998661279678345, "entropy": 0.598917011419932, "incre_win_rate": 0.6122448979591837, "step": 408}
{"time": 1766664747.2981095, "phase": "train", "update": 409, "total_env_steps": 1308800, "episode_reward": 0.3096967041492462, "value_loss": 0.01359382097919782, "policy_loss": -0.0123364678547451, "dist_entropy": 0.5956855694452922, "actor_grad_norm": 0.17848314344882965, "critic_grad_norm": 0.03583507984876633, "ratio": 0.9999656081199646, "entropy": 0.5956855694452922, "incre_win_rate": 0.7777777777777778, "step": 409}
{"time": 1766664751.5370543, "phase": "train", "update": 410, "total_env_steps": 1312000, "episode_reward": 0.2920764684677124, "value_loss": 0.014843474018077056, "policy_loss": -0.012853723940491358, "dist_entropy": 0.5872181614240011, "actor_grad_norm": 0.17914815247058868, "critic_grad_norm": 0.060063574463129044, "ratio": 0.9990782737731934, "entropy": 0.5872181614240011, "incre_win_rate": 0.660377358490566, "step": 410}
{"time": 1766664755.8478584, "phase": "train", "update": 411, "total_env_steps": 1315200, "episode_reward": 0.2941192090511322, "value_loss": 0.017242757603526115, "policy_loss": -0.012556677849304284, "dist_entropy": 0.6007457534472148, "actor_grad_norm": 0.19754983484745026, "critic_grad_norm": 0.029545575380325317, "ratio": 1.0001235008239746, "entropy": 0.6007457534472148, "incre_win_rate": 0.6470588235294118, "step": 411}
{"time": 1766664760.0752969, "phase": "train", "update": 412, "total_env_steps": 1318400, "episode_reward": 0.2979886531829834, "value_loss": 0.014054953493177891, "policy_loss": -0.013327040508270235, "dist_entropy": 0.6179486672083537, "actor_grad_norm": 0.188651904463768, "critic_grad_norm": 0.09243171662092209, "ratio": 0.9992581009864807, "entropy": 0.6179486672083537, "incre_win_rate": 0.75, "step": 412}
{"time": 1766664764.3263056, "phase": "train", "update": 413, "total_env_steps": 1321600, "episode_reward": 0.3016107678413391, "value_loss": 0.015680547741552194, "policy_loss": -0.013117698542157542, "dist_entropy": 0.6025914231936137, "actor_grad_norm": 0.177179753780365, "critic_grad_norm": 0.041362661868333817, "ratio": 0.9991441369056702, "entropy": 0.6025914231936137, "incre_win_rate": 0.7115384615384616, "step": 413}
{"time": 1766664768.6377192, "phase": "train", "update": 414, "total_env_steps": 1324800, "episode_reward": 0.2943849563598633, "value_loss": 0.017035230000813802, "policy_loss": -0.013242486407720714, "dist_entropy": 0.5944296002388001, "actor_grad_norm": 0.19975727796554565, "critic_grad_norm": 0.08766087144613266, "ratio": 0.9999030828475952, "entropy": 0.5944296002388001, "incre_win_rate": 0.5636363636363636, "step": 414}
{"time": 1766664772.940281, "phase": "train", "update": 415, "total_env_steps": 1328000, "episode_reward": 0.2975582182407379, "value_loss": 0.013102316608031591, "policy_loss": -0.013307910942531734, "dist_entropy": 0.6140103419621785, "actor_grad_norm": 0.1994469314813614, "critic_grad_norm": 0.049183886498212814, "ratio": 0.9992706775665283, "entropy": 0.6140103419621785, "incre_win_rate": 0.7115384615384616, "step": 415}
{"time": 1766664777.259889, "phase": "train", "update": 416, "total_env_steps": 1331200, "episode_reward": 0.2863748371601105, "value_loss": 0.018714753662546477, "policy_loss": -0.01373578377007713, "dist_entropy": 0.586479123433431, "actor_grad_norm": 0.1771460473537445, "critic_grad_norm": 0.06055185943841934, "ratio": 0.9997485280036926, "entropy": 0.586479123433431, "incre_win_rate": 0.5769230769230769, "step": 416}
{"time": 1766664781.559445, "phase": "train", "update": 417, "total_env_steps": 1334400, "episode_reward": 0.2931518256664276, "value_loss": 0.01917226624985536, "policy_loss": -0.013766373162770051, "dist_entropy": 0.5831847429275513, "actor_grad_norm": 0.16776923835277557, "critic_grad_norm": 0.059119537472724915, "ratio": 0.9995126724243164, "entropy": 0.5831847429275513, "incre_win_rate": 0.6666666666666666, "step": 417}
{"time": 1766664785.8154967, "phase": "train", "update": 418, "total_env_steps": 1337600, "episode_reward": 0.3113258481025696, "value_loss": 0.01219266994545857, "policy_loss": -0.013606687280988202, "dist_entropy": 0.6157864332199097, "actor_grad_norm": 0.178188756108284, "critic_grad_norm": 0.07400044798851013, "ratio": 0.9990436434745789, "entropy": 0.6157864332199097, "incre_win_rate": 0.8518518518518519, "step": 418}
{"time": 1766664790.0921013, "phase": "train", "update": 419, "total_env_steps": 1340800, "episode_reward": 0.2891773581504822, "value_loss": 0.016144522900382676, "policy_loss": -0.01248016774764551, "dist_entropy": 0.5746911565462748, "actor_grad_norm": 0.18336622416973114, "critic_grad_norm": 0.09985728561878204, "ratio": 0.9998398423194885, "entropy": 0.5746911565462748, "incre_win_rate": 0.6078431372549019, "step": 419}
{"time": 1766664794.3355439, "phase": "train", "update": 420, "total_env_steps": 1344000, "episode_reward": 0.30116114020347595, "value_loss": 0.011421779232720534, "policy_loss": -0.011683901092317702, "dist_entropy": 0.6009018739064534, "actor_grad_norm": 0.1980312168598175, "critic_grad_norm": 0.06083732470870018, "ratio": 0.9988864660263062, "entropy": 0.6009018739064534, "incre_win_rate": 0.8431372549019608, "step": 420}
{"time": 1766664798.627431, "phase": "train", "update": 421, "total_env_steps": 1347200, "episode_reward": 0.28231391310691833, "value_loss": 0.013521631310383479, "policy_loss": -0.01373889164819578, "dist_entropy": 0.5809979875882466, "actor_grad_norm": 0.1947697550058365, "critic_grad_norm": 0.05254432186484337, "ratio": 0.998432993888855, "entropy": 0.5809979875882466, "incre_win_rate": 0.5686274509803921, "step": 421}
{"time": 1766664806.9039717, "phase": "eval", "update": 421, "total_env_steps": 1347200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.500382965686278, "step": 421}
{"time": 1766664811.1373105, "phase": "train", "update": 422, "total_env_steps": 1350400, "episode_reward": 0.302097886800766, "value_loss": 0.00981724268446366, "policy_loss": -0.013345707948891613, "dist_entropy": 0.6258962949117025, "actor_grad_norm": 0.20058377087116241, "critic_grad_norm": 0.04988197237253189, "ratio": 0.9988725781440735, "entropy": 0.6258962949117025, "incre_win_rate": 0.7959183673469388, "step": 422}
{"time": 1766664815.3575318, "phase": "train", "update": 423, "total_env_steps": 1353600, "episode_reward": 0.3025375306606293, "value_loss": 0.013323861298461755, "policy_loss": -0.012475200488978544, "dist_entropy": 0.6038321455319723, "actor_grad_norm": 0.15926754474639893, "critic_grad_norm": 0.02976163849234581, "ratio": 0.9990935325622559, "entropy": 0.6038321455319723, "incre_win_rate": 0.7636363636363637, "step": 423}
{"time": 1766664819.6336968, "phase": "train", "update": 424, "total_env_steps": 1356800, "episode_reward": 0.29826825857162476, "value_loss": 0.017664781709512075, "policy_loss": -0.01261231669468567, "dist_entropy": 0.5870635430018107, "actor_grad_norm": 0.1776476800441742, "critic_grad_norm": 0.0841539278626442, "ratio": 1.000872254371643, "entropy": 0.5870635430018107, "incre_win_rate": 0.6346153846153846, "step": 424}
{"time": 1766664823.916458, "phase": "train", "update": 425, "total_env_steps": 1360000, "episode_reward": 0.30753985047340393, "value_loss": 0.013487159522871177, "policy_loss": -0.012517186083869663, "dist_entropy": 0.5881089011828105, "actor_grad_norm": 0.23020215332508087, "critic_grad_norm": 0.03991078585386276, "ratio": 0.9999554753303528, "entropy": 0.5881089011828105, "incre_win_rate": 0.7843137254901961, "step": 425}
{"time": 1766664828.1867764, "phase": "train", "update": 426, "total_env_steps": 1363200, "episode_reward": 0.30043962597846985, "value_loss": 0.01239043486615022, "policy_loss": -0.012587939620293061, "dist_entropy": 0.5827330549558004, "actor_grad_norm": 0.22497139871120453, "critic_grad_norm": 0.023907558992505074, "ratio": 0.9987975358963013, "entropy": 0.5827330549558004, "incre_win_rate": 0.8, "step": 426}
{"time": 1766664832.452222, "phase": "train", "update": 427, "total_env_steps": 1366400, "episode_reward": 0.29858916997909546, "value_loss": 0.010478689521551132, "policy_loss": -0.011844899273692514, "dist_entropy": 0.6043166359265645, "actor_grad_norm": 0.16517426073551178, "critic_grad_norm": 0.019329076632857323, "ratio": 0.9995609521865845, "entropy": 0.6043166359265645, "incre_win_rate": 0.7692307692307693, "step": 427}
{"time": 1766664836.7105901, "phase": "train", "update": 428, "total_env_steps": 1369600, "episode_reward": 0.31419500708580017, "value_loss": 0.007194272894412279, "policy_loss": -0.011445778034697913, "dist_entropy": 0.6181586782137553, "actor_grad_norm": 0.17036223411560059, "critic_grad_norm": 0.037217069417238235, "ratio": 0.9985668659210205, "entropy": 0.6181586782137553, "incre_win_rate": 0.9411764705882353, "step": 428}
{"time": 1766664841.0212915, "phase": "train", "update": 429, "total_env_steps": 1372800, "episode_reward": 0.3004886507987976, "value_loss": 0.014922813636561234, "policy_loss": -0.011019005729785173, "dist_entropy": 0.591647207736969, "actor_grad_norm": 0.15528877079486847, "critic_grad_norm": 0.053293850272893906, "ratio": 0.9987832903862, "entropy": 0.591647207736969, "incre_win_rate": 0.7692307692307693, "step": 429}
{"time": 1766664845.2700548, "phase": "train", "update": 430, "total_env_steps": 1376000, "episode_reward": 0.30256280303001404, "value_loss": 0.01750789036353429, "policy_loss": -0.01180902790739727, "dist_entropy": 0.583611011505127, "actor_grad_norm": 0.1573752611875534, "critic_grad_norm": 0.08397012203931808, "ratio": 0.9985485076904297, "entropy": 0.583611011505127, "incre_win_rate": 0.7169811320754716, "step": 430}
{"time": 1766664849.571768, "phase": "train", "update": 431, "total_env_steps": 1379200, "episode_reward": 0.2967042028903961, "value_loss": 0.013723051982621352, "policy_loss": -0.012574997407147256, "dist_entropy": 0.5913920203844706, "actor_grad_norm": 0.19234588742256165, "critic_grad_norm": 0.05913860350847244, "ratio": 1.0001200437545776, "entropy": 0.5913920203844706, "incre_win_rate": 0.7358490566037735, "step": 431}
{"time": 1766664853.8732884, "phase": "train", "update": 432, "total_env_steps": 1382400, "episode_reward": 0.2941092550754547, "value_loss": 0.015080378825465838, "policy_loss": -0.012680620053955257, "dist_entropy": 0.5808756907780965, "actor_grad_norm": 0.24000921845436096, "critic_grad_norm": 0.04869185388088226, "ratio": 0.9992543458938599, "entropy": 0.5808756907780965, "incre_win_rate": 0.6862745098039216, "step": 432}
{"time": 1766664858.098898, "phase": "train", "update": 433, "total_env_steps": 1385600, "episode_reward": 0.2929595708847046, "value_loss": 0.013691316234568755, "policy_loss": -0.011905626303887591, "dist_entropy": 0.5505130449930827, "actor_grad_norm": 0.2046043872833252, "critic_grad_norm": 0.05167887732386589, "ratio": 0.9986727237701416, "entropy": 0.5505130449930827, "incre_win_rate": 0.5849056603773585, "step": 433}
{"time": 1766664862.3453922, "phase": "train", "update": 434, "total_env_steps": 1388800, "episode_reward": 0.2906985580921173, "value_loss": 0.013538490608334541, "policy_loss": -0.013248089449405616, "dist_entropy": 0.5655288179715474, "actor_grad_norm": 0.1754346787929535, "critic_grad_norm": 0.02567908726632595, "ratio": 0.9989500045776367, "entropy": 0.5655288179715474, "incre_win_rate": 0.6274509803921569, "step": 434}
{"time": 1766664866.5935943, "phase": "train", "update": 435, "total_env_steps": 1392000, "episode_reward": 0.29177698493003845, "value_loss": 0.012647667340934277, "policy_loss": -0.013128425077468482, "dist_entropy": 0.5955056190490723, "actor_grad_norm": 0.17323079705238342, "critic_grad_norm": 0.06156101077795029, "ratio": 0.9993565082550049, "entropy": 0.5955056190490723, "incre_win_rate": 0.7, "step": 435}
{"time": 1766664870.8284793, "phase": "train", "update": 436, "total_env_steps": 1395200, "episode_reward": 0.2914177477359772, "value_loss": 0.01497768002251784, "policy_loss": -0.011434625097010098, "dist_entropy": 0.569226864973704, "actor_grad_norm": 0.18273113667964935, "critic_grad_norm": 0.026345275342464447, "ratio": 0.9990885257720947, "entropy": 0.569226864973704, "incre_win_rate": 0.6981132075471698, "step": 436}
{"time": 1766664875.063496, "phase": "train", "update": 437, "total_env_steps": 1398400, "episode_reward": 0.29198533296585083, "value_loss": 0.013754232662419479, "policy_loss": -0.011385433606765598, "dist_entropy": 0.5625184535980224, "actor_grad_norm": 0.22715000808238983, "critic_grad_norm": 0.01616537570953369, "ratio": 0.9990773797035217, "entropy": 0.5625184535980224, "incre_win_rate": 0.7142857142857143, "step": 437}
{"time": 1766664879.3435006, "phase": "train", "update": 438, "total_env_steps": 1401600, "episode_reward": 0.287085622549057, "value_loss": 0.014158730829755465, "policy_loss": -0.013025612027924183, "dist_entropy": 0.5608689586321512, "actor_grad_norm": 0.18055324256420135, "critic_grad_norm": 0.030919086188077927, "ratio": 0.9984737038612366, "entropy": 0.5608689586321512, "incre_win_rate": 0.6538461538461539, "step": 438}
{"time": 1766664883.6037438, "phase": "train", "update": 439, "total_env_steps": 1404800, "episode_reward": 0.3019378185272217, "value_loss": 0.014772450737655162, "policy_loss": -0.011605502673839396, "dist_entropy": 0.574720291296641, "actor_grad_norm": 0.16828562319278717, "critic_grad_norm": 0.06449733674526215, "ratio": 0.9991692900657654, "entropy": 0.574720291296641, "incre_win_rate": 0.7843137254901961, "step": 439}
{"time": 1766664887.9825969, "phase": "train", "update": 440, "total_env_steps": 1408000, "episode_reward": 0.28836703300476074, "value_loss": 0.01254112838457028, "policy_loss": -0.012566867833637236, "dist_entropy": 0.5567055463790893, "actor_grad_norm": 0.2300763875246048, "critic_grad_norm": 0.028414160013198853, "ratio": 0.999230146408081, "entropy": 0.5567055463790893, "incre_win_rate": 0.6470588235294118, "step": 440}
{"time": 1766664892.5381203, "phase": "train", "update": 441, "total_env_steps": 1411200, "episode_reward": 0.2917042076587677, "value_loss": 0.012930552661418914, "policy_loss": -0.01283660495926758, "dist_entropy": 0.5814926783243816, "actor_grad_norm": 0.2004334181547165, "critic_grad_norm": 0.024695703759789467, "ratio": 0.9988213181495667, "entropy": 0.5814926783243816, "incre_win_rate": 0.74, "step": 441}
{"time": 1766664900.4402614, "phase": "eval", "update": 441, "total_env_steps": 1411200, "eval_win_rate": 0.84375, "eval_episode_reward": 19.202742034313722, "step": 441}
{"time": 1766664904.6451397, "phase": "train", "update": 442, "total_env_steps": 1414400, "episode_reward": 0.28999462723731995, "value_loss": 0.01168872540195783, "policy_loss": -0.012911290196635032, "dist_entropy": 0.572643268108368, "actor_grad_norm": 0.17448413372039795, "critic_grad_norm": 0.015457459725439548, "ratio": 0.9994650483131409, "entropy": 0.572643268108368, "incre_win_rate": 0.76, "step": 442}
{"time": 1766664908.8913817, "phase": "train", "update": 443, "total_env_steps": 1417600, "episode_reward": 0.2905192971229553, "value_loss": 0.01501877394815286, "policy_loss": -0.011568227167023793, "dist_entropy": 0.5559566617012024, "actor_grad_norm": 0.18607309460639954, "critic_grad_norm": 0.052486032247543335, "ratio": 1.0012149810791016, "entropy": 0.5559566617012024, "incre_win_rate": 0.6415094339622641, "step": 443}
{"time": 1766664913.1307542, "phase": "train", "update": 444, "total_env_steps": 1420800, "episode_reward": 0.300101101398468, "value_loss": 0.013277700978020827, "policy_loss": -0.012397730602741438, "dist_entropy": 0.5701151172320048, "actor_grad_norm": 0.1862950176000595, "critic_grad_norm": 0.05171886458992958, "ratio": 0.9978585243225098, "entropy": 0.5701151172320048, "incre_win_rate": 0.7058823529411765, "step": 444}
{"time": 1766664917.3349218, "phase": "train", "update": 445, "total_env_steps": 1424000, "episode_reward": 0.28860601782798767, "value_loss": 0.013773482168714206, "policy_loss": -0.012529932884342542, "dist_entropy": 0.5840207695960998, "actor_grad_norm": 0.17021618783473969, "critic_grad_norm": 0.027628784999251366, "ratio": 0.9994764924049377, "entropy": 0.5840207695960998, "incre_win_rate": 0.6481481481481481, "step": 445}
{"time": 1766664921.6358056, "phase": "train", "update": 446, "total_env_steps": 1427200, "episode_reward": 0.30480238795280457, "value_loss": 0.011238935900231202, "policy_loss": -0.012673886291747986, "dist_entropy": 0.5801656723022461, "actor_grad_norm": 0.19944816827774048, "critic_grad_norm": 0.023186644539237022, "ratio": 1.0000691413879395, "entropy": 0.5801656723022461, "incre_win_rate": 0.7647058823529411, "step": 446}
{"time": 1766664925.882024, "phase": "train", "update": 447, "total_env_steps": 1430400, "episode_reward": 0.27766546607017517, "value_loss": 0.015987767030795415, "policy_loss": -0.013498562828014352, "dist_entropy": 0.5860905369122823, "actor_grad_norm": 0.18296656012535095, "critic_grad_norm": 0.08608309179544449, "ratio": 0.9986374974250793, "entropy": 0.5860905369122823, "incre_win_rate": 0.6122448979591837, "step": 447}
{"time": 1766664930.143038, "phase": "train", "update": 448, "total_env_steps": 1433600, "episode_reward": 0.2812208831310272, "value_loss": 0.016902508586645125, "policy_loss": -0.013598272332017795, "dist_entropy": 0.5659021178881327, "actor_grad_norm": 0.16089360415935516, "critic_grad_norm": 0.07489779591560364, "ratio": 1.00041925907135, "entropy": 0.5659021178881327, "incre_win_rate": 0.5769230769230769, "step": 448}
{"time": 1766664934.447607, "phase": "train", "update": 449, "total_env_steps": 1436800, "episode_reward": 0.29290056228637695, "value_loss": 0.015869913871089616, "policy_loss": -0.013192407702026307, "dist_entropy": 0.5389875928560893, "actor_grad_norm": 0.2003474086523056, "critic_grad_norm": 0.04967401176691055, "ratio": 1.0006325244903564, "entropy": 0.5389875928560893, "incre_win_rate": 0.68, "step": 449}
{"time": 1766664938.6990774, "phase": "train", "update": 450, "total_env_steps": 1440000, "episode_reward": 0.297006756067276, "value_loss": 0.015699982829391956, "policy_loss": -0.013518654752844365, "dist_entropy": 0.572741440931956, "actor_grad_norm": 0.17859403789043427, "critic_grad_norm": 0.07280131429433823, "ratio": 0.9983684420585632, "entropy": 0.572741440931956, "incre_win_rate": 0.7222222222222222, "step": 450}
{"time": 1766664942.9746866, "phase": "train", "update": 451, "total_env_steps": 1443200, "episode_reward": 0.3070504069328308, "value_loss": 0.013512982365985712, "policy_loss": -0.012431561542499026, "dist_entropy": 0.5636934717496236, "actor_grad_norm": 0.19130295515060425, "critic_grad_norm": 0.07438095659017563, "ratio": 1.0003951787948608, "entropy": 0.5636934717496236, "incre_win_rate": 0.7843137254901961, "step": 451}
{"time": 1766664947.2862377, "phase": "train", "update": 452, "total_env_steps": 1446400, "episode_reward": 0.2890532910823822, "value_loss": 0.01793679632246494, "policy_loss": -0.014011009510872441, "dist_entropy": 0.5882485508918762, "actor_grad_norm": 0.2156914472579956, "critic_grad_norm": 0.04015851393342018, "ratio": 0.999754786491394, "entropy": 0.5882485508918762, "incre_win_rate": 0.6415094339622641, "step": 452}
{"time": 1766664951.6029637, "phase": "train", "update": 453, "total_env_steps": 1449600, "episode_reward": 0.28914523124694824, "value_loss": 0.016512211039662363, "policy_loss": -0.013454192164447912, "dist_entropy": 0.5737525820732117, "actor_grad_norm": 0.18108084797859192, "critic_grad_norm": 0.0643192008137703, "ratio": 1.000052809715271, "entropy": 0.5737525820732117, "incre_win_rate": 0.5961538461538461, "step": 453}
{"time": 1766664955.815566, "phase": "train", "update": 454, "total_env_steps": 1452800, "episode_reward": 0.2937553822994232, "value_loss": 0.013377994174758594, "policy_loss": -0.014308975958221382, "dist_entropy": 0.5944595654805501, "actor_grad_norm": 0.1772228330373764, "critic_grad_norm": 0.03323943540453911, "ratio": 0.9985666275024414, "entropy": 0.5944595654805501, "incre_win_rate": 0.7115384615384616, "step": 454}
{"time": 1766664960.0832503, "phase": "train", "update": 455, "total_env_steps": 1456000, "episode_reward": 0.29910844564437866, "value_loss": 0.01314869529257218, "policy_loss": -0.013051403623612146, "dist_entropy": 0.577511747678121, "actor_grad_norm": 0.18969564139842987, "critic_grad_norm": 0.0528983473777771, "ratio": 0.9997672438621521, "entropy": 0.577511747678121, "incre_win_rate": 0.8, "step": 455}
{"time": 1766664964.3527846, "phase": "train", "update": 456, "total_env_steps": 1459200, "episode_reward": 0.297827810049057, "value_loss": 0.012402311029533545, "policy_loss": -0.012990623963946745, "dist_entropy": 0.5970590313275655, "actor_grad_norm": 0.18651127815246582, "critic_grad_norm": 0.04437704756855965, "ratio": 0.9998780488967896, "entropy": 0.5970590313275655, "incre_win_rate": 0.6981132075471698, "step": 456}
{"time": 1766664968.5913274, "phase": "train", "update": 457, "total_env_steps": 1462400, "episode_reward": 0.29263633489608765, "value_loss": 0.012765163121124109, "policy_loss": -0.012413934091944157, "dist_entropy": 0.5899885614713033, "actor_grad_norm": 0.20639672875404358, "critic_grad_norm": 0.03372476249933243, "ratio": 0.9999736547470093, "entropy": 0.5899885614713033, "incre_win_rate": 0.76, "step": 457}
{"time": 1766664972.9187295, "phase": "train", "update": 458, "total_env_steps": 1465600, "episode_reward": 0.2880239188671112, "value_loss": 0.014439639262855053, "policy_loss": -0.013266403601826227, "dist_entropy": 0.5712048292160035, "actor_grad_norm": 0.166128009557724, "critic_grad_norm": 0.026790039613842964, "ratio": 0.9993274211883545, "entropy": 0.5712048292160035, "incre_win_rate": 0.6274509803921569, "step": 458}
{"time": 1766664977.171941, "phase": "train", "update": 459, "total_env_steps": 1468800, "episode_reward": 0.2868022322654724, "value_loss": 0.01346615372846524, "policy_loss": -0.014030891856255324, "dist_entropy": 0.5797009905179341, "actor_grad_norm": 0.16527009010314941, "critic_grad_norm": 0.019259069114923477, "ratio": 1.000016450881958, "entropy": 0.5797009905179341, "incre_win_rate": 0.6346153846153846, "step": 459}
{"time": 1766664981.4449759, "phase": "train", "update": 460, "total_env_steps": 1472000, "episode_reward": 0.2865487337112427, "value_loss": 0.013588994989792507, "policy_loss": -0.013804725621618866, "dist_entropy": 0.5697094202041626, "actor_grad_norm": 0.20532119274139404, "critic_grad_norm": 0.027974378317594528, "ratio": 0.9987719655036926, "entropy": 0.5697094202041626, "incre_win_rate": 0.6326530612244898, "step": 460}
{"time": 1766664985.7503622, "phase": "train", "update": 461, "total_env_steps": 1475200, "episode_reward": 0.291840523481369, "value_loss": 0.010690760736664136, "policy_loss": -0.013233436951759122, "dist_entropy": 0.5779550830523174, "actor_grad_norm": 0.18978719413280487, "critic_grad_norm": 0.04440945386886597, "ratio": 0.9986889362335205, "entropy": 0.5779550830523174, "incre_win_rate": 0.7450980392156863, "step": 461}
{"time": 1766664993.7961147, "phase": "eval", "update": 461, "total_env_steps": 1475200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.553002450980394, "step": 461}
{"time": 1766664998.1191144, "phase": "train", "update": 462, "total_env_steps": 1478400, "episode_reward": 0.3035079836845398, "value_loss": 0.011626082224150498, "policy_loss": -0.012645703704705961, "dist_entropy": 0.6000860214233399, "actor_grad_norm": 0.16788095235824585, "critic_grad_norm": 0.03391876816749573, "ratio": 0.9992857575416565, "entropy": 0.6000860214233399, "incre_win_rate": 0.7884615384615384, "step": 462}
{"time": 1766665002.3566678, "phase": "train", "update": 463, "total_env_steps": 1481600, "episode_reward": 0.28557518124580383, "value_loss": 0.013651717267930508, "policy_loss": -0.01426843075715567, "dist_entropy": 0.5792083064715068, "actor_grad_norm": 0.18602325022220612, "critic_grad_norm": 0.09860095381736755, "ratio": 1.001737117767334, "entropy": 0.5792083064715068, "incre_win_rate": 0.74, "step": 463}
{"time": 1766665006.6178224, "phase": "train", "update": 464, "total_env_steps": 1484800, "episode_reward": 0.28444623947143555, "value_loss": 0.012694501938919226, "policy_loss": -0.012480156273549406, "dist_entropy": 0.5681825677553812, "actor_grad_norm": 0.21838632225990295, "critic_grad_norm": 0.039502181112766266, "ratio": 1.0003527402877808, "entropy": 0.5681825677553812, "incre_win_rate": 0.673469387755102, "step": 464}
{"time": 1766665010.902081, "phase": "train", "update": 465, "total_env_steps": 1488000, "episode_reward": 0.2991589903831482, "value_loss": 0.012733264019091924, "policy_loss": -0.012949187147479316, "dist_entropy": 0.5684606790542602, "actor_grad_norm": 0.19681428372859955, "critic_grad_norm": 0.03845156729221344, "ratio": 0.9995696544647217, "entropy": 0.5684606790542602, "incre_win_rate": 0.7307692307692307, "step": 465}
{"time": 1766665015.1134396, "phase": "train", "update": 466, "total_env_steps": 1491200, "episode_reward": 0.2989353537559509, "value_loss": 0.010098630686601003, "policy_loss": -0.013008036229041408, "dist_entropy": 0.5811608632405599, "actor_grad_norm": 0.25298577547073364, "critic_grad_norm": 0.053610995411872864, "ratio": 0.9979974031448364, "entropy": 0.5811608632405599, "incre_win_rate": 0.82, "step": 466}
{"time": 1766665019.3745646, "phase": "train", "update": 467, "total_env_steps": 1494400, "episode_reward": 0.30030789971351624, "value_loss": 0.011075691630442938, "policy_loss": -0.012040048076406018, "dist_entropy": 0.5812690615653991, "actor_grad_norm": 0.17888015508651733, "critic_grad_norm": 0.026367299258708954, "ratio": 0.9999151229858398, "entropy": 0.5812690615653991, "incre_win_rate": 0.803921568627451, "step": 467}
{"time": 1766665024.3221135, "phase": "train", "update": 468, "total_env_steps": 1497600, "episode_reward": 0.29819703102111816, "value_loss": 0.012229757693906626, "policy_loss": -0.012350623656011332, "dist_entropy": 0.5726398984591167, "actor_grad_norm": 0.21493324637413025, "critic_grad_norm": 0.054609768092632294, "ratio": 0.9998227953910828, "entropy": 0.5726398984591167, "incre_win_rate": 0.75, "step": 468}
{"time": 1766665028.7787867, "phase": "train", "update": 469, "total_env_steps": 1500800, "episode_reward": 0.30440258979797363, "value_loss": 0.011351700065036614, "policy_loss": -0.012152085121540306, "dist_entropy": 0.5612199942270915, "actor_grad_norm": 0.159353107213974, "critic_grad_norm": 0.012661892920732498, "ratio": 0.9998342990875244, "entropy": 0.5612199942270915, "incre_win_rate": 0.7692307692307693, "step": 469}
{"time": 1766665033.0493994, "phase": "train", "update": 470, "total_env_steps": 1504000, "episode_reward": 0.29448530077934265, "value_loss": 0.011876628858347733, "policy_loss": -0.012564256150113806, "dist_entropy": 0.5790259877840678, "actor_grad_norm": 0.2501050531864166, "critic_grad_norm": 0.041407886892557144, "ratio": 1.000888705253601, "entropy": 0.5790259877840678, "incre_win_rate": 0.72, "step": 470}
{"time": 1766665037.3360062, "phase": "train", "update": 471, "total_env_steps": 1507200, "episode_reward": 0.29670265316963196, "value_loss": 0.013095919663707415, "policy_loss": -0.0133664802132652, "dist_entropy": 0.5860341350237529, "actor_grad_norm": 0.21019822359085083, "critic_grad_norm": 0.03475051745772362, "ratio": 1.000357985496521, "entropy": 0.5860341350237529, "incre_win_rate": 0.7843137254901961, "step": 471}
{"time": 1766665041.5931208, "phase": "train", "update": 472, "total_env_steps": 1510400, "episode_reward": 0.2793673574924469, "value_loss": 0.013585372579594452, "policy_loss": -0.013727500313550679, "dist_entropy": 0.5794405817985535, "actor_grad_norm": 0.16048972308635712, "critic_grad_norm": 0.01692115142941475, "ratio": 1.0002046823501587, "entropy": 0.5794405817985535, "incre_win_rate": 0.6326530612244898, "step": 472}
{"time": 1766665045.8194928, "phase": "train", "update": 473, "total_env_steps": 1513600, "episode_reward": 0.2887094020843506, "value_loss": 0.012587801118691762, "policy_loss": -0.013482661161614591, "dist_entropy": 0.5674439231554668, "actor_grad_norm": 0.1800171285867691, "critic_grad_norm": 0.022889701649546623, "ratio": 0.998515248298645, "entropy": 0.5674439231554668, "incre_win_rate": 0.6923076923076923, "step": 473}
{"time": 1766665050.0873682, "phase": "train", "update": 474, "total_env_steps": 1516800, "episode_reward": 0.3009459376335144, "value_loss": 0.010137567669153214, "policy_loss": -0.013500143383090328, "dist_entropy": 0.5866171518961588, "actor_grad_norm": 0.20679813623428345, "critic_grad_norm": 0.02395605854690075, "ratio": 1.0007351636886597, "entropy": 0.5866171518961588, "incre_win_rate": 0.78, "step": 474}
{"time": 1766665054.3620367, "phase": "train", "update": 475, "total_env_steps": 1520000, "episode_reward": 0.2942325472831726, "value_loss": 0.013698317483067513, "policy_loss": -0.013946854571860475, "dist_entropy": 0.5627620021502177, "actor_grad_norm": 0.22539721429347992, "critic_grad_norm": 0.032437656074762344, "ratio": 0.9989863634109497, "entropy": 0.5627620021502177, "incre_win_rate": 0.660377358490566, "step": 475}
{"time": 1766665058.7097135, "phase": "train", "update": 476, "total_env_steps": 1523200, "episode_reward": 0.3097832500934601, "value_loss": 0.011307321799298128, "policy_loss": -0.012790953145578736, "dist_entropy": 0.5728984912236531, "actor_grad_norm": 0.20197834074497223, "critic_grad_norm": 0.07215259224176407, "ratio": 0.9990399479866028, "entropy": 0.5728984912236531, "incre_win_rate": 0.8076923076923077, "step": 476}
{"time": 1766665062.976801, "phase": "train", "update": 477, "total_env_steps": 1526400, "episode_reward": 0.29497700929641724, "value_loss": 0.01449624157200257, "policy_loss": -0.011891231976892177, "dist_entropy": 0.5518758376439412, "actor_grad_norm": 0.229912668466568, "critic_grad_norm": 0.031104572117328644, "ratio": 0.9989885091781616, "entropy": 0.5518758376439412, "incre_win_rate": 0.7307692307692307, "step": 477}
{"time": 1766665067.2056136, "phase": "train", "update": 478, "total_env_steps": 1529600, "episode_reward": 0.2920480966567993, "value_loss": 0.01244388942917188, "policy_loss": -0.013128907746179645, "dist_entropy": 0.5670202533404033, "actor_grad_norm": 0.21174776554107666, "critic_grad_norm": 0.014916446059942245, "ratio": 0.9992169141769409, "entropy": 0.5670202533404033, "incre_win_rate": 0.72, "step": 478}
{"time": 1766665071.450152, "phase": "train", "update": 479, "total_env_steps": 1532800, "episode_reward": 0.3058049976825714, "value_loss": 0.014472125905255477, "policy_loss": -0.012389644166303053, "dist_entropy": 0.5576258540153504, "actor_grad_norm": 0.17416635155677795, "critic_grad_norm": 0.026261596009135246, "ratio": 0.9992201924324036, "entropy": 0.5576258540153504, "incre_win_rate": 0.6785714285714286, "step": 479}
{"time": 1766665075.5986125, "phase": "train", "update": 480, "total_env_steps": 1536000, "episode_reward": 0.2982146143913269, "value_loss": 0.01142215405901273, "policy_loss": -0.013244712409575261, "dist_entropy": 0.577829651037852, "actor_grad_norm": 0.1909705400466919, "critic_grad_norm": 0.024447515606880188, "ratio": 0.9996473789215088, "entropy": 0.577829651037852, "incre_win_rate": 0.7291666666666666, "step": 480}
{"time": 1766665079.860441, "phase": "train", "update": 481, "total_env_steps": 1539200, "episode_reward": 0.3020212948322296, "value_loss": 0.011150571083029111, "policy_loss": -0.012007654708116888, "dist_entropy": 0.5962433099746705, "actor_grad_norm": 0.2370983511209488, "critic_grad_norm": 0.02391851134598255, "ratio": 1.0000178813934326, "entropy": 0.5962433099746705, "incre_win_rate": 0.8181818181818182, "step": 481}
{"time": 1766665087.571383, "phase": "eval", "update": 481, "total_env_steps": 1539200, "eval_win_rate": 0.78125, "eval_episode_reward": 18.78462009803922, "step": 481}
{"time": 1766665091.7844255, "phase": "train", "update": 482, "total_env_steps": 1542400, "episode_reward": 0.2961435317993164, "value_loss": 0.01826196735103925, "policy_loss": -0.012655494607258315, "dist_entropy": 0.5543718179066975, "actor_grad_norm": 0.16646899282932281, "critic_grad_norm": 0.04232309013605118, "ratio": 0.9996706247329712, "entropy": 0.5543718179066975, "incre_win_rate": 0.5882352941176471, "step": 482}
{"time": 1766665095.9751735, "phase": "train", "update": 483, "total_env_steps": 1545600, "episode_reward": 0.2983371615409851, "value_loss": 0.013325505206982296, "policy_loss": -0.013408574839968898, "dist_entropy": 0.5916960636774699, "actor_grad_norm": 0.16772569715976715, "critic_grad_norm": 0.057814061641693115, "ratio": 0.998111367225647, "entropy": 0.5916960636774699, "incre_win_rate": 0.7222222222222222, "step": 483}
{"time": 1766665100.2014914, "phase": "train", "update": 484, "total_env_steps": 1548800, "episode_reward": 0.2931862771511078, "value_loss": 0.015141552562514942, "policy_loss": -0.011978720559133176, "dist_entropy": 0.5905149459838868, "actor_grad_norm": 0.2083885669708252, "critic_grad_norm": 0.03847317397594452, "ratio": 1.000219702720642, "entropy": 0.5905149459838868, "incre_win_rate": 0.6862745098039216, "step": 484}
{"time": 1766665104.4583147, "phase": "train", "update": 485, "total_env_steps": 1552000, "episode_reward": 0.29198530316352844, "value_loss": 0.015867101214826106, "policy_loss": -0.01336053881202351, "dist_entropy": 0.6054911692937215, "actor_grad_norm": 0.21043337881565094, "critic_grad_norm": 0.040772050619125366, "ratio": 1.0005686283111572, "entropy": 0.6054911692937215, "incre_win_rate": 0.6730769230769231, "step": 485}
{"time": 1766665108.73747, "phase": "train", "update": 486, "total_env_steps": 1555200, "episode_reward": 0.29689568281173706, "value_loss": 0.015745631977915765, "policy_loss": -0.012997925135647393, "dist_entropy": 0.5910333196322123, "actor_grad_norm": 0.2489360123872757, "critic_grad_norm": 0.07013997435569763, "ratio": 0.9995197653770447, "entropy": 0.5910333196322123, "incre_win_rate": 0.6415094339622641, "step": 486}
{"time": 1766665112.939155, "phase": "train", "update": 487, "total_env_steps": 1558400, "episode_reward": 0.2991306781768799, "value_loss": 0.01468874334047238, "policy_loss": -0.014189327378068129, "dist_entropy": 0.6031397064526876, "actor_grad_norm": 0.18168069422245026, "critic_grad_norm": 0.06317568570375443, "ratio": 1.0005810260772705, "entropy": 0.6031397064526876, "incre_win_rate": 0.7647058823529411, "step": 487}
{"time": 1766665117.1374373, "phase": "train", "update": 488, "total_env_steps": 1561600, "episode_reward": 0.28323298692703247, "value_loss": 0.01324699241667986, "policy_loss": -0.014127085929366482, "dist_entropy": 0.6044060349464416, "actor_grad_norm": 0.184760183095932, "critic_grad_norm": 0.02687761001288891, "ratio": 0.9987531304359436, "entropy": 0.6044060349464416, "incre_win_rate": 0.7142857142857143, "step": 488}
{"time": 1766665121.3671644, "phase": "train", "update": 489, "total_env_steps": 1564800, "episode_reward": 0.30724266171455383, "value_loss": 0.01280966866761446, "policy_loss": -0.01437237585605023, "dist_entropy": 0.5909829338391622, "actor_grad_norm": 0.16987058520317078, "critic_grad_norm": 0.024871915578842163, "ratio": 0.9986094832420349, "entropy": 0.5909829338391622, "incre_win_rate": 0.7222222222222222, "step": 489}
{"time": 1766665141.4694612, "phase": "train", "update": 490, "total_env_steps": 1568000, "episode_reward": 0.29407551884651184, "value_loss": 0.06017208422223727, "policy_loss": -0.012176509081457235, "dist_entropy": 0.6106685837109883, "actor_grad_norm": 0.1692459136247635, "critic_grad_norm": 0.23720695078372955, "ratio": 0.999885618686676, "entropy": 0.6106685837109883, "incre_win_rate": 0.6666666666666666, "step": 490}
{"time": 1766665145.7385585, "phase": "train", "update": 491, "total_env_steps": 1571200, "episode_reward": 0.29815489053726196, "value_loss": 0.013738902285695076, "policy_loss": -0.013651094020882699, "dist_entropy": 0.6084840854008993, "actor_grad_norm": 0.1851835995912552, "critic_grad_norm": 0.10283712297677994, "ratio": 0.999203622341156, "entropy": 0.6084840854008993, "incre_win_rate": 0.7115384615384616, "step": 491}
{"time": 1766665149.9974804, "phase": "train", "update": 492, "total_env_steps": 1574400, "episode_reward": 0.2822181284427643, "value_loss": 0.014995126364131769, "policy_loss": -0.013920396976004668, "dist_entropy": 0.6148405154546102, "actor_grad_norm": 0.21249020099639893, "critic_grad_norm": 0.05679966136813164, "ratio": 0.9983492493629456, "entropy": 0.6148405154546102, "incre_win_rate": 0.6037735849056604, "step": 492}
{"time": 1766665154.1954348, "phase": "train", "update": 493, "total_env_steps": 1577600, "episode_reward": 0.2842792570590973, "value_loss": 0.0132552952816089, "policy_loss": -0.01363765242416406, "dist_entropy": 0.6213766773541768, "actor_grad_norm": 0.20647631585597992, "critic_grad_norm": 0.029251405969262123, "ratio": 1.0004045963287354, "entropy": 0.6213766773541768, "incre_win_rate": 0.75, "step": 493}
{"time": 1766665158.4314647, "phase": "train", "update": 494, "total_env_steps": 1580800, "episode_reward": 0.30926623940467834, "value_loss": 0.016176477633416654, "policy_loss": -0.014530090631237159, "dist_entropy": 0.6060269395510356, "actor_grad_norm": 0.1927490532398224, "critic_grad_norm": 0.055618587881326675, "ratio": 0.9993958473205566, "entropy": 0.6060269395510356, "incre_win_rate": 0.7454545454545455, "step": 494}
{"time": 1766665162.669695, "phase": "train", "update": 495, "total_env_steps": 1584000, "episode_reward": 0.2892210781574249, "value_loss": 0.013560699423154195, "policy_loss": -0.014370409602483274, "dist_entropy": 0.601647428671519, "actor_grad_norm": 0.1693764328956604, "critic_grad_norm": 0.03072589635848999, "ratio": 1.0005676746368408, "entropy": 0.601647428671519, "incre_win_rate": 0.7083333333333334, "step": 495}
{"time": 1766665166.964159, "phase": "train", "update": 496, "total_env_steps": 1587200, "episode_reward": 0.2947235107421875, "value_loss": 0.012803309472898643, "policy_loss": -0.013484656231774276, "dist_entropy": 0.5995298743247985, "actor_grad_norm": 0.1707679033279419, "critic_grad_norm": 0.059272732585668564, "ratio": 0.9996116161346436, "entropy": 0.5995298743247985, "incre_win_rate": 0.7358490566037735, "step": 496}
{"time": 1766665171.1542666, "phase": "train", "update": 497, "total_env_steps": 1590400, "episode_reward": 0.2809045910835266, "value_loss": 0.014105201015869777, "policy_loss": -0.014840335269033745, "dist_entropy": 0.604418937365214, "actor_grad_norm": 0.2354610115289688, "critic_grad_norm": 0.03059868887066841, "ratio": 1.000077724456787, "entropy": 0.604418937365214, "incre_win_rate": 0.6078431372549019, "step": 497}
{"time": 1766665175.3534725, "phase": "train", "update": 498, "total_env_steps": 1593600, "episode_reward": 0.2984558641910553, "value_loss": 0.00989863413075606, "policy_loss": -0.013114977684123612, "dist_entropy": 0.6370223164558411, "actor_grad_norm": 0.227028951048851, "critic_grad_norm": 0.07666964828968048, "ratio": 0.9993236660957336, "entropy": 0.6370223164558411, "incre_win_rate": 0.8541666666666666, "step": 498}
{"time": 1766665179.6014657, "phase": "train", "update": 499, "total_env_steps": 1596800, "episode_reward": 0.3119761049747467, "value_loss": 0.011007841986914476, "policy_loss": -0.012608294333790581, "dist_entropy": 0.6337586959203084, "actor_grad_norm": 0.25183480978012085, "critic_grad_norm": 0.0396379679441452, "ratio": 0.9994584321975708, "entropy": 0.6337586959203084, "incre_win_rate": 0.7962962962962963, "step": 499}
{"time": 1766665183.8454921, "phase": "train", "update": 500, "total_env_steps": 1600000, "episode_reward": 0.30145296454429626, "value_loss": 0.014147198013961314, "policy_loss": -0.01310010657001707, "dist_entropy": 0.604064400990804, "actor_grad_norm": 0.19246357679367065, "critic_grad_norm": 0.05305531620979309, "ratio": 1.0009312629699707, "entropy": 0.604064400990804, "incre_win_rate": 0.7307692307692307, "step": 500}
{"time": 1766665188.0672324, "phase": "train", "update": 501, "total_env_steps": 1603200, "episode_reward": 0.31207796931266785, "value_loss": 0.00876866914331913, "policy_loss": -0.012953529921303187, "dist_entropy": 0.6186707337697347, "actor_grad_norm": 0.1964714527130127, "critic_grad_norm": 0.03415357694029808, "ratio": 1.0004115104675293, "entropy": 0.6186707337697347, "incre_win_rate": 0.8363636363636363, "step": 501}
{"time": 1766665195.985608, "phase": "eval", "update": 501, "total_env_steps": 1603200, "eval_win_rate": 0.84375, "eval_episode_reward": 19.22778799019608, "step": 501}
{"time": 1766665200.2909043, "phase": "train", "update": 502, "total_env_steps": 1606400, "episode_reward": 0.30560970306396484, "value_loss": 0.012141602610548337, "policy_loss": -0.012757363939749666, "dist_entropy": 0.6136907974878947, "actor_grad_norm": 0.19104114174842834, "critic_grad_norm": 0.022334024310112, "ratio": 0.999000608921051, "entropy": 0.6136907974878947, "incre_win_rate": 0.7450980392156863, "step": 502}
{"time": 1766665204.5255284, "phase": "train", "update": 503, "total_env_steps": 1609600, "episode_reward": 0.3029036223888397, "value_loss": 0.012888454273343087, "policy_loss": -0.01304840692484106, "dist_entropy": 0.5919658780097962, "actor_grad_norm": 0.21820692718029022, "critic_grad_norm": 0.044323086738586426, "ratio": 1.0001168251037598, "entropy": 0.5919658780097962, "incre_win_rate": 0.7037037037037037, "step": 503}
{"time": 1766665208.7530882, "phase": "train", "update": 504, "total_env_steps": 1612800, "episode_reward": 0.3172181248664856, "value_loss": 0.007571161755671104, "policy_loss": -0.012958860604451653, "dist_entropy": 0.6125825683275858, "actor_grad_norm": 0.16258612275123596, "critic_grad_norm": 0.06843941658735275, "ratio": 0.9997493028640747, "entropy": 0.6125825683275858, "incre_win_rate": 0.8679245283018868, "step": 504}
{"time": 1766665212.9496865, "phase": "train", "update": 505, "total_env_steps": 1616000, "episode_reward": 0.3031502962112427, "value_loss": 0.010467746543387573, "policy_loss": -0.012748740496329939, "dist_entropy": 0.623877207438151, "actor_grad_norm": 0.15769082307815552, "critic_grad_norm": 0.03483470901846886, "ratio": 0.9996616840362549, "entropy": 0.623877207438151, "incre_win_rate": 0.8, "step": 505}
{"time": 1766665217.200508, "phase": "train", "update": 506, "total_env_steps": 1619200, "episode_reward": 0.3048912286758423, "value_loss": 0.010665607204039891, "policy_loss": -0.012754293915900423, "dist_entropy": 0.6230690956115723, "actor_grad_norm": 0.20194204151630402, "critic_grad_norm": 0.05054255574941635, "ratio": 1.000058889389038, "entropy": 0.6230690956115723, "incre_win_rate": 0.7692307692307693, "step": 506}
{"time": 1766665221.4381013, "phase": "train", "update": 507, "total_env_steps": 1622400, "episode_reward": 0.29652267694473267, "value_loss": 0.012946683168411254, "policy_loss": -0.013563195444092457, "dist_entropy": 0.6286036849021912, "actor_grad_norm": 0.20253720879554749, "critic_grad_norm": 0.04174139350652695, "ratio": 0.9996904134750366, "entropy": 0.6286036849021912, "incre_win_rate": 0.6862745098039216, "step": 507}
{"time": 1766665225.6816823, "phase": "train", "update": 508, "total_env_steps": 1625600, "episode_reward": 0.28551167249679565, "value_loss": 0.01749757267534733, "policy_loss": -0.013739660838599833, "dist_entropy": 0.6291176795959472, "actor_grad_norm": 0.1730593889951706, "critic_grad_norm": 0.11405732482671738, "ratio": 0.9992015957832336, "entropy": 0.6291176795959472, "incre_win_rate": 0.5740740740740741, "step": 508}
{"time": 1766665229.943668, "phase": "train", "update": 509, "total_env_steps": 1628800, "episode_reward": 0.2820603549480438, "value_loss": 0.014334975990156333, "policy_loss": -0.013654504905340066, "dist_entropy": 0.626387894153595, "actor_grad_norm": 0.21998870372772217, "critic_grad_norm": 0.03761336952447891, "ratio": 1.0001325607299805, "entropy": 0.626387894153595, "incre_win_rate": 0.6122448979591837, "step": 509}
{"time": 1766665234.2065716, "phase": "train", "update": 510, "total_env_steps": 1632000, "episode_reward": 0.29799020290374756, "value_loss": 0.012763442968328794, "policy_loss": -0.012442947868233507, "dist_entropy": 0.6230586926142375, "actor_grad_norm": 0.17746347188949585, "critic_grad_norm": 0.022784940898418427, "ratio": 0.9992132782936096, "entropy": 0.6230586926142375, "incre_win_rate": 0.7222222222222222, "step": 510}
{"time": 1766665238.4476202, "phase": "train", "update": 511, "total_env_steps": 1635200, "episode_reward": 0.30602556467056274, "value_loss": 0.01109171360731125, "policy_loss": -0.01335020475476559, "dist_entropy": 0.630668572584788, "actor_grad_norm": 0.19696834683418274, "critic_grad_norm": 0.07739585638046265, "ratio": 0.9979099631309509, "entropy": 0.630668572584788, "incre_win_rate": 0.8235294117647058, "step": 511}
{"time": 1766665242.7160232, "phase": "train", "update": 512, "total_env_steps": 1638400, "episode_reward": 0.31658780574798584, "value_loss": 0.011449490363399187, "policy_loss": -0.014141911368058875, "dist_entropy": 0.6103595455487569, "actor_grad_norm": 0.18667268753051758, "critic_grad_norm": 0.06316645443439484, "ratio": 0.9995409250259399, "entropy": 0.6103595455487569, "incre_win_rate": 0.8461538461538461, "step": 512}
{"time": 1766665246.9713638, "phase": "train", "update": 513, "total_env_steps": 1641600, "episode_reward": 0.31706878542900085, "value_loss": 0.012481284389893214, "policy_loss": -0.014103817507696684, "dist_entropy": 0.5959658145904541, "actor_grad_norm": 0.1643964797258377, "critic_grad_norm": 0.0400637611746788, "ratio": 0.9996365308761597, "entropy": 0.5959658145904541, "incre_win_rate": 0.8148148148148148, "step": 513}
{"time": 1766665251.1944695, "phase": "train", "update": 514, "total_env_steps": 1644800, "episode_reward": 0.3042815625667572, "value_loss": 0.014977101298669974, "policy_loss": -0.012990069916095118, "dist_entropy": 0.5985981782277425, "actor_grad_norm": 0.1804789900779724, "critic_grad_norm": 0.052516452968120575, "ratio": 1.0009466409683228, "entropy": 0.5985981782277425, "incre_win_rate": 0.7169811320754716, "step": 514}
{"time": 1766665255.5068593, "phase": "train", "update": 515, "total_env_steps": 1648000, "episode_reward": 0.3200727701187134, "value_loss": 0.009586246870458125, "policy_loss": -0.011651618690634299, "dist_entropy": 0.607711668809255, "actor_grad_norm": 0.2106691300868988, "critic_grad_norm": 0.01730482093989849, "ratio": 0.9998271465301514, "entropy": 0.607711668809255, "incre_win_rate": 0.8301886792452831, "step": 515}
{"time": 1766665259.7881765, "phase": "train", "update": 516, "total_env_steps": 1651200, "episode_reward": 0.3140089213848114, "value_loss": 0.015317395143210889, "policy_loss": -0.012498252316689691, "dist_entropy": 0.5974395076433817, "actor_grad_norm": 0.1936756819486618, "critic_grad_norm": 0.02181796357035637, "ratio": 1.0004327297210693, "entropy": 0.5974395076433817, "incre_win_rate": 0.75, "step": 516}
{"time": 1766665264.0221126, "phase": "train", "update": 517, "total_env_steps": 1654400, "episode_reward": 0.3097012937068939, "value_loss": 0.010738187469542027, "policy_loss": -0.011890111873860102, "dist_entropy": 0.616533080736796, "actor_grad_norm": 0.22172997891902924, "critic_grad_norm": 0.030324969440698624, "ratio": 0.9995334148406982, "entropy": 0.616533080736796, "incre_win_rate": 0.7735849056603774, "step": 517}
{"time": 1766665268.3312418, "phase": "train", "update": 518, "total_env_steps": 1657600, "episode_reward": 0.32902345061302185, "value_loss": 0.008764399401843547, "policy_loss": -0.012535212560383495, "dist_entropy": 0.6087983647982279, "actor_grad_norm": 0.20400239527225494, "critic_grad_norm": 0.03887610137462616, "ratio": 0.9987025260925293, "entropy": 0.6087983647982279, "incre_win_rate": 0.8703703703703703, "step": 518}
{"time": 1766665272.597266, "phase": "train", "update": 519, "total_env_steps": 1660800, "episode_reward": 0.308045357465744, "value_loss": 0.008433800625304381, "policy_loss": -0.012819285949551803, "dist_entropy": 0.5978410959243774, "actor_grad_norm": 0.16581442952156067, "critic_grad_norm": 0.020843716338276863, "ratio": 0.9998869895935059, "entropy": 0.5978410959243774, "incre_win_rate": 0.8235294117647058, "step": 519}
{"time": 1766665276.8959327, "phase": "train", "update": 520, "total_env_steps": 1664000, "episode_reward": 0.3308195471763611, "value_loss": 0.010282934705416361, "policy_loss": -0.012104425636320333, "dist_entropy": 0.6148283759752909, "actor_grad_norm": 0.1679275929927826, "critic_grad_norm": 0.013762756250798702, "ratio": 0.9993806481361389, "entropy": 0.6148283759752909, "incre_win_rate": 0.8571428571428571, "step": 520}
{"time": 1766665281.1893618, "phase": "train", "update": 521, "total_env_steps": 1667200, "episode_reward": 0.33517926931381226, "value_loss": 0.0063433409358064335, "policy_loss": -0.0113341276462909, "dist_entropy": 0.6139265616734823, "actor_grad_norm": 0.17161092162132263, "critic_grad_norm": 0.05656546726822853, "ratio": 0.999349057674408, "entropy": 0.6139265616734823, "incre_win_rate": 0.9454545454545454, "step": 521}
{"time": 1766665288.724065, "phase": "eval", "update": 521, "total_env_steps": 1667200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.634114583333332, "step": 521}
{"time": 1766665293.032389, "phase": "train", "update": 522, "total_env_steps": 1670400, "episode_reward": 0.3212186396121979, "value_loss": 0.00696483018497626, "policy_loss": -0.01198900539313783, "dist_entropy": 0.5976837038993835, "actor_grad_norm": 0.18533402681350708, "critic_grad_norm": 0.044001977890729904, "ratio": 1.0007846355438232, "entropy": 0.5976837038993835, "incre_win_rate": 0.8113207547169812, "step": 522}
{"time": 1766665297.2565758, "phase": "train", "update": 523, "total_env_steps": 1673600, "episode_reward": 0.3219600319862366, "value_loss": 0.009121498713890711, "policy_loss": -0.01215404078023011, "dist_entropy": 0.6044970750808716, "actor_grad_norm": 0.1859106421470642, "critic_grad_norm": 0.04000096023082733, "ratio": 1.0004758834838867, "entropy": 0.6044970750808716, "incre_win_rate": 0.8363636363636363, "step": 523}
{"time": 1766665301.5232675, "phase": "train", "update": 524, "total_env_steps": 1676800, "episode_reward": 0.3148100674152374, "value_loss": 0.009865606514116129, "policy_loss": -0.012534728093886354, "dist_entropy": 0.5889308651288351, "actor_grad_norm": 0.19441655278205872, "critic_grad_norm": 0.02184569090604782, "ratio": 0.9994921684265137, "entropy": 0.5889308651288351, "incre_win_rate": 0.8301886792452831, "step": 524}
{"time": 1766665305.8257227, "phase": "train", "update": 525, "total_env_steps": 1680000, "episode_reward": 0.3253883123397827, "value_loss": 0.006861539340267579, "policy_loss": -0.01225083821793002, "dist_entropy": 0.5961891253789265, "actor_grad_norm": 0.1562645584344864, "critic_grad_norm": 0.04063691198825836, "ratio": 0.9989699721336365, "entropy": 0.5961891253789265, "incre_win_rate": 0.8703703703703703, "step": 525}
{"time": 1766665310.0236924, "phase": "train", "update": 526, "total_env_steps": 1683200, "episode_reward": 0.32852253317832947, "value_loss": 0.011548229244848092, "policy_loss": -0.012248158467113334, "dist_entropy": 0.592251968383789, "actor_grad_norm": 0.1785689741373062, "critic_grad_norm": 0.021419137716293335, "ratio": 0.9996022582054138, "entropy": 0.592251968383789, "incre_win_rate": 0.8518518518518519, "step": 526}
{"time": 1766665314.3350892, "phase": "train", "update": 527, "total_env_steps": 1686400, "episode_reward": 0.3216230273246765, "value_loss": 0.011793454239765803, "policy_loss": -0.012229121835706755, "dist_entropy": 0.5722744425137838, "actor_grad_norm": 0.196119025349617, "critic_grad_norm": 0.047524068504571915, "ratio": 1.0005922317504883, "entropy": 0.5722744425137838, "incre_win_rate": 0.7818181818181819, "step": 527}
{"time": 1766665318.6195564, "phase": "train", "update": 528, "total_env_steps": 1689600, "episode_reward": 0.33435511589050293, "value_loss": 0.008480434243877729, "policy_loss": -0.01249513580508174, "dist_entropy": 0.6047844529151917, "actor_grad_norm": 0.17663875222206116, "critic_grad_norm": 0.02977561578154564, "ratio": 0.9993165135383606, "entropy": 0.6047844529151917, "incre_win_rate": 0.8928571428571429, "step": 528}
{"time": 1766665322.9219766, "phase": "train", "update": 529, "total_env_steps": 1692800, "episode_reward": 0.3333387076854706, "value_loss": 0.012409440676371257, "policy_loss": -0.010743771753651762, "dist_entropy": 0.5887407739957173, "actor_grad_norm": 0.15918852388858795, "critic_grad_norm": 0.028832824900746346, "ratio": 0.9989715814590454, "entropy": 0.5887407739957173, "incre_win_rate": 0.8035714285714286, "step": 529}
{"time": 1766665327.2165902, "phase": "train", "update": 530, "total_env_steps": 1696000, "episode_reward": 0.33157554268836975, "value_loss": 0.011816670186817646, "policy_loss": -0.012776278899906639, "dist_entropy": 0.5946671565373739, "actor_grad_norm": 0.23709560930728912, "critic_grad_norm": 0.02028830535709858, "ratio": 0.998211681842804, "entropy": 0.5946671565373739, "incre_win_rate": 0.8392857142857143, "step": 530}
{"time": 1766665331.456545, "phase": "train", "update": 531, "total_env_steps": 1699200, "episode_reward": 0.3233226239681244, "value_loss": 0.012279329759379228, "policy_loss": -0.01146807782543912, "dist_entropy": 0.6024627844492595, "actor_grad_norm": 0.21820104122161865, "critic_grad_norm": 0.03833309933543205, "ratio": 1.0009334087371826, "entropy": 0.6024627844492595, "incre_win_rate": 0.8, "step": 531}
{"time": 1766665335.6987982, "phase": "train", "update": 532, "total_env_steps": 1702400, "episode_reward": 0.3215770423412323, "value_loss": 0.01168758242080609, "policy_loss": -0.012405841987433537, "dist_entropy": 0.5855138063430786, "actor_grad_norm": 0.20041851699352264, "critic_grad_norm": 0.033887267112731934, "ratio": 0.9984313249588013, "entropy": 0.5855138063430786, "incre_win_rate": 0.75, "step": 532}
{"time": 1766665339.9711976, "phase": "train", "update": 533, "total_env_steps": 1705600, "episode_reward": 0.33324146270751953, "value_loss": 0.010246925366421541, "policy_loss": -0.012218584949627598, "dist_entropy": 0.6017770806948344, "actor_grad_norm": 0.16653375327587128, "critic_grad_norm": 0.026523001492023468, "ratio": 0.999298632144928, "entropy": 0.6017770806948344, "incre_win_rate": 0.9090909090909091, "step": 533}
{"time": 1766665344.243059, "phase": "train", "update": 534, "total_env_steps": 1708800, "episode_reward": 0.3184873163700104, "value_loss": 0.011826071329414845, "policy_loss": -0.012320506225017406, "dist_entropy": 0.6195428649584452, "actor_grad_norm": 0.17117705941200256, "critic_grad_norm": 0.03752490505576134, "ratio": 1.0006394386291504, "entropy": 0.6195428649584452, "incre_win_rate": 0.7692307692307693, "step": 534}
{"time": 1766665348.510943, "phase": "train", "update": 535, "total_env_steps": 1712000, "episode_reward": 0.3052780032157898, "value_loss": 0.013199288832644622, "policy_loss": -0.012805132079551917, "dist_entropy": 0.6121945858001709, "actor_grad_norm": 0.15936718881130219, "critic_grad_norm": 0.09500641375780106, "ratio": 0.9997884631156921, "entropy": 0.6121945858001709, "incre_win_rate": 0.7272727272727273, "step": 535}
{"time": 1766665352.7981477, "phase": "train", "update": 536, "total_env_steps": 1715200, "episode_reward": 0.30244180560112, "value_loss": 0.015010255575180053, "policy_loss": -0.01268036195598275, "dist_entropy": 0.6103837728500366, "actor_grad_norm": 0.162401482462883, "critic_grad_norm": 0.05800216272473335, "ratio": 1.0002272129058838, "entropy": 0.6103837728500366, "incre_win_rate": 0.6415094339622641, "step": 536}
{"time": 1766665357.0687037, "phase": "train", "update": 537, "total_env_steps": 1718400, "episode_reward": 0.31615501642227173, "value_loss": 0.01680877370138963, "policy_loss": -0.012684291930277425, "dist_entropy": 0.5931383570035299, "actor_grad_norm": 0.18282531201839447, "critic_grad_norm": 0.04871644079685211, "ratio": 0.9987115859985352, "entropy": 0.5931383570035299, "incre_win_rate": 0.7454545454545455, "step": 537}
{"time": 1766665361.3180256, "phase": "train", "update": 538, "total_env_steps": 1721600, "episode_reward": 0.306512713432312, "value_loss": 0.014346969313919544, "policy_loss": -0.013536107082120451, "dist_entropy": 0.6143834114074707, "actor_grad_norm": 0.17753008008003235, "critic_grad_norm": 0.030355919152498245, "ratio": 0.9988523125648499, "entropy": 0.6143834114074707, "incre_win_rate": 0.6909090909090909, "step": 538}
{"time": 1766665365.5977106, "phase": "train", "update": 539, "total_env_steps": 1724800, "episode_reward": 0.31605854630470276, "value_loss": 0.012139266356825829, "policy_loss": -0.013043752066744692, "dist_entropy": 0.6002325773239136, "actor_grad_norm": 0.17144063115119934, "critic_grad_norm": 0.09960658848285675, "ratio": 1.0009102821350098, "entropy": 0.6002325773239136, "incre_win_rate": 0.7735849056603774, "step": 539}
{"time": 1766665369.8440337, "phase": "train", "update": 540, "total_env_steps": 1728000, "episode_reward": 0.3174264430999756, "value_loss": 0.011985484759012859, "policy_loss": -0.013214434336849065, "dist_entropy": 0.5936518351236979, "actor_grad_norm": 0.18237820267677307, "critic_grad_norm": 0.0475887805223465, "ratio": 1.000078797340393, "entropy": 0.5936518351236979, "incre_win_rate": 0.8148148148148148, "step": 540}
{"time": 1766665374.1195922, "phase": "train", "update": 541, "total_env_steps": 1731200, "episode_reward": 0.296010285615921, "value_loss": 0.012548376681903999, "policy_loss": -0.013465730471810862, "dist_entropy": 0.596709938844045, "actor_grad_norm": 0.1782614141702652, "critic_grad_norm": 0.05967135727405548, "ratio": 0.9998143911361694, "entropy": 0.596709938844045, "incre_win_rate": 0.660377358490566, "step": 541}
{"time": 1766665381.4101613, "phase": "eval", "update": 541, "total_env_steps": 1731200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.28982843137255, "step": 541}
{"time": 1766665385.694527, "phase": "train", "update": 542, "total_env_steps": 1734400, "episode_reward": 0.31107842922210693, "value_loss": 0.013166244824727375, "policy_loss": -0.013272131182637755, "dist_entropy": 0.6150261004765828, "actor_grad_norm": 0.17731724679470062, "critic_grad_norm": 0.020845020189881325, "ratio": 1.0006219148635864, "entropy": 0.6150261004765828, "incre_win_rate": 0.7547169811320755, "step": 542}
{"time": 1766665389.9285839, "phase": "train", "update": 543, "total_env_steps": 1737600, "episode_reward": 0.319515198469162, "value_loss": 0.011796679285665353, "policy_loss": -0.012048138341401208, "dist_entropy": 0.5883044560750326, "actor_grad_norm": 0.17044873535633087, "critic_grad_norm": 0.03280662000179291, "ratio": 0.9992856383323669, "entropy": 0.5883044560750326, "incre_win_rate": 0.7777777777777778, "step": 543}
{"time": 1766665394.2016947, "phase": "train", "update": 544, "total_env_steps": 1740800, "episode_reward": 0.3315418064594269, "value_loss": 0.011545974078277748, "policy_loss": -0.013411277072079978, "dist_entropy": 0.6015177011489868, "actor_grad_norm": 0.16138695180416107, "critic_grad_norm": 0.018759053200483322, "ratio": 0.9998767375946045, "entropy": 0.6015177011489868, "incre_win_rate": 0.8571428571428571, "step": 544}
{"time": 1766665398.4458587, "phase": "train", "update": 545, "total_env_steps": 1744000, "episode_reward": 0.30494868755340576, "value_loss": 0.01537201851606369, "policy_loss": -0.012971390146500046, "dist_entropy": 0.6132747809092204, "actor_grad_norm": 0.204440638422966, "critic_grad_norm": 0.06692830473184586, "ratio": 1.0000861883163452, "entropy": 0.6132747809092204, "incre_win_rate": 0.7358490566037735, "step": 545}
{"time": 1766665402.6929667, "phase": "train", "update": 546, "total_env_steps": 1747200, "episode_reward": 0.31716835498809814, "value_loss": 0.013928261833886306, "policy_loss": -0.013372985919510446, "dist_entropy": 0.6104605078697205, "actor_grad_norm": 0.18943704664707184, "critic_grad_norm": 0.061207160353660583, "ratio": 0.9998800158500671, "entropy": 0.6104605078697205, "incre_win_rate": 0.8301886792452831, "step": 546}
{"time": 1766665406.99452, "phase": "train", "update": 547, "total_env_steps": 1750400, "episode_reward": 0.31891775131225586, "value_loss": 0.01201861867060264, "policy_loss": -0.011581588034826496, "dist_entropy": 0.6016387581825257, "actor_grad_norm": 0.1898653358221054, "critic_grad_norm": 0.031916555017232895, "ratio": 0.9997565746307373, "entropy": 0.6016387581825257, "incre_win_rate": 0.7321428571428571, "step": 547}
{"time": 1766665411.264232, "phase": "train", "update": 548, "total_env_steps": 1753600, "episode_reward": 0.3091046214103699, "value_loss": 0.014133072892824809, "policy_loss": -0.012592483608698047, "dist_entropy": 0.6049853642781575, "actor_grad_norm": 0.20252074301242828, "critic_grad_norm": 0.030498646199703217, "ratio": 0.9995471239089966, "entropy": 0.6049853642781575, "incre_win_rate": 0.7358490566037735, "step": 548}
{"time": 1766665415.5368934, "phase": "train", "update": 549, "total_env_steps": 1756800, "episode_reward": 0.3089675307273865, "value_loss": 0.015566824687023957, "policy_loss": -0.013492180588310986, "dist_entropy": 0.6188328305880229, "actor_grad_norm": 0.18011800944805145, "critic_grad_norm": 0.018967648968100548, "ratio": 0.9995943307876587, "entropy": 0.6188328305880229, "incre_win_rate": 0.75, "step": 549}
{"time": 1766665419.8348062, "phase": "train", "update": 550, "total_env_steps": 1760000, "episode_reward": 0.31597575545310974, "value_loss": 0.01572997830808163, "policy_loss": -0.01322069004360884, "dist_entropy": 0.5906837503115336, "actor_grad_norm": 0.2454521805047989, "critic_grad_norm": 0.057079724967479706, "ratio": 0.9991069436073303, "entropy": 0.5906837503115336, "incre_win_rate": 0.6896551724137931, "step": 550}
{"time": 1766665424.0734315, "phase": "train", "update": 551, "total_env_steps": 1763200, "episode_reward": 0.29906556010246277, "value_loss": 0.017545323198040325, "policy_loss": -0.013701521170384486, "dist_entropy": 0.5740652044614156, "actor_grad_norm": 0.2621682584285736, "critic_grad_norm": 0.03435574844479561, "ratio": 0.9994252920150757, "entropy": 0.5740652044614156, "incre_win_rate": 0.6415094339622641, "step": 551}
{"time": 1766665428.3239868, "phase": "train", "update": 552, "total_env_steps": 1766400, "episode_reward": 0.31824755668640137, "value_loss": 0.012850962517162164, "policy_loss": -0.012847852802409439, "dist_entropy": 0.5845749139785766, "actor_grad_norm": 0.21207165718078613, "critic_grad_norm": 0.018141556531190872, "ratio": 0.9982317090034485, "entropy": 0.5845749139785766, "incre_win_rate": 0.7090909090909091, "step": 552}
{"time": 1766665432.5628016, "phase": "train", "update": 553, "total_env_steps": 1769600, "episode_reward": 0.3052918016910553, "value_loss": 0.017450616384545963, "policy_loss": -0.013811791134650283, "dist_entropy": 0.5964495658874511, "actor_grad_norm": 0.190969318151474, "critic_grad_norm": 0.03225964307785034, "ratio": 0.9993763566017151, "entropy": 0.5964495658874511, "incre_win_rate": 0.7090909090909091, "step": 553}
{"time": 1766665436.835427, "phase": "train", "update": 554, "total_env_steps": 1772800, "episode_reward": 0.29984989762306213, "value_loss": 0.020136514926950136, "policy_loss": -0.013631259793115191, "dist_entropy": 0.5837803681691488, "actor_grad_norm": 0.19183306396007538, "critic_grad_norm": 0.032507043331861496, "ratio": 0.9998764395713806, "entropy": 0.5837803681691488, "incre_win_rate": 0.6226415094339622, "step": 554}
{"time": 1766665441.1203434, "phase": "train", "update": 555, "total_env_steps": 1776000, "episode_reward": 0.32373467087745667, "value_loss": 0.011388370705147585, "policy_loss": -0.01321542496077092, "dist_entropy": 0.5800463239351908, "actor_grad_norm": 0.2183624804019928, "critic_grad_norm": 0.07461945712566376, "ratio": 0.9998067617416382, "entropy": 0.5800463239351908, "incre_win_rate": 0.8214285714285714, "step": 555}
{"time": 1766665445.385403, "phase": "train", "update": 556, "total_env_steps": 1779200, "episode_reward": 0.31790977716445923, "value_loss": 0.01309168419490258, "policy_loss": -0.013069278073635242, "dist_entropy": 0.5765701413154602, "actor_grad_norm": 0.1587304174900055, "critic_grad_norm": 0.033328235149383545, "ratio": 0.999424934387207, "entropy": 0.5765701413154602, "incre_win_rate": 0.7636363636363637, "step": 556}
{"time": 1766665449.6097682, "phase": "train", "update": 557, "total_env_steps": 1782400, "episode_reward": 0.31511643528938293, "value_loss": 0.012555227925380072, "policy_loss": -0.013284632410522098, "dist_entropy": 0.5836111426353454, "actor_grad_norm": 0.15652047097682953, "critic_grad_norm": 0.019993823021650314, "ratio": 1.0004613399505615, "entropy": 0.5836111426353454, "incre_win_rate": 0.7962962962962963, "step": 557}
{"time": 1766665453.808557, "phase": "train", "update": 558, "total_env_steps": 1785600, "episode_reward": 0.318844199180603, "value_loss": 0.008743850824733576, "policy_loss": -0.013930300754984516, "dist_entropy": 0.5980826179186504, "actor_grad_norm": 0.17273768782615662, "critic_grad_norm": 0.020410427823662758, "ratio": 1.0001263618469238, "entropy": 0.5980826179186504, "incre_win_rate": 0.7924528301886793, "step": 558}
{"time": 1766665458.0754602, "phase": "train", "update": 559, "total_env_steps": 1788800, "episode_reward": 0.3134244978427887, "value_loss": 0.014274037381013235, "policy_loss": -0.012860582316668949, "dist_entropy": 0.5617730458577473, "actor_grad_norm": 0.17873862385749817, "critic_grad_norm": 0.05301787704229355, "ratio": 1.0004878044128418, "entropy": 0.5617730458577473, "incre_win_rate": 0.7017543859649122, "step": 559}
{"time": 1766665462.3164046, "phase": "train", "update": 560, "total_env_steps": 1792000, "episode_reward": 0.3156985342502594, "value_loss": 0.0120480020220081, "policy_loss": -0.012826831653728731, "dist_entropy": 0.5660833875338237, "actor_grad_norm": 0.17398831248283386, "critic_grad_norm": 0.01869768276810646, "ratio": 0.9992543458938599, "entropy": 0.5660833875338237, "incre_win_rate": 0.7547169811320755, "step": 560}
{"time": 1766665466.67446, "phase": "train", "update": 561, "total_env_steps": 1795200, "episode_reward": 0.3181227147579193, "value_loss": 0.011056186879674594, "policy_loss": -0.01162654162895033, "dist_entropy": 0.5829365213712057, "actor_grad_norm": 0.15035566687583923, "critic_grad_norm": 0.06174842268228531, "ratio": 1.0001147985458374, "entropy": 0.5829365213712057, "incre_win_rate": 0.7777777777777778, "step": 561}
{"time": 1766665473.8652341, "phase": "eval", "update": 561, "total_env_steps": 1795200, "eval_win_rate": 0.875, "eval_episode_reward": 19.223651960784316, "step": 561}
{"time": 1766665478.153111, "phase": "train", "update": 562, "total_env_steps": 1798400, "episode_reward": 0.3302198350429535, "value_loss": 0.008602164437373478, "policy_loss": -0.01223280989056074, "dist_entropy": 0.5818002303441365, "actor_grad_norm": 0.1717265397310257, "critic_grad_norm": 0.030604049563407898, "ratio": 0.9993655681610107, "entropy": 0.5818002303441365, "incre_win_rate": 0.8867924528301887, "step": 562}
{"time": 1766665482.4722574, "phase": "train", "update": 563, "total_env_steps": 1801600, "episode_reward": 0.3172740340232849, "value_loss": 0.011537088329593341, "policy_loss": -0.012114339632754914, "dist_entropy": 0.5772317926088969, "actor_grad_norm": 0.16485820710659027, "critic_grad_norm": 0.022804241627454758, "ratio": 0.9987614750862122, "entropy": 0.5772317926088969, "incre_win_rate": 0.7678571428571429, "step": 563}
{"time": 1766665486.7276237, "phase": "train", "update": 564, "total_env_steps": 1804800, "episode_reward": 0.2927711606025696, "value_loss": 0.012786563734213512, "policy_loss": -0.013731790010999844, "dist_entropy": 0.5927605430285136, "actor_grad_norm": 0.19252946972846985, "critic_grad_norm": 0.04905838146805763, "ratio": 0.9994127154350281, "entropy": 0.5927605430285136, "incre_win_rate": 0.6862745098039216, "step": 564}
{"time": 1766665491.0125082, "phase": "train", "update": 565, "total_env_steps": 1808000, "episode_reward": 0.3168956935405731, "value_loss": 0.012314791356523832, "policy_loss": -0.011824720259420473, "dist_entropy": 0.5842846870422364, "actor_grad_norm": 0.22164058685302734, "critic_grad_norm": 0.015624468214809895, "ratio": 0.9999766945838928, "entropy": 0.5842846870422364, "incre_win_rate": 0.7454545454545455, "step": 565}
{"time": 1766665495.265588, "phase": "train", "update": 566, "total_env_steps": 1811200, "episode_reward": 0.3138335049152374, "value_loss": 0.014583025376001995, "policy_loss": -0.012776686089078974, "dist_entropy": 0.591486926873525, "actor_grad_norm": 0.16858553886413574, "critic_grad_norm": 0.024142855778336525, "ratio": 1.0007973909378052, "entropy": 0.591486926873525, "incre_win_rate": 0.7407407407407407, "step": 566}
{"time": 1766665499.553876, "phase": "train", "update": 567, "total_env_steps": 1814400, "episode_reward": 0.32110297679901123, "value_loss": 0.013256467382113139, "policy_loss": -0.012012776778864994, "dist_entropy": 0.5688725272814433, "actor_grad_norm": 0.14000999927520752, "critic_grad_norm": 0.021996337920427322, "ratio": 0.9990768432617188, "entropy": 0.5688725272814433, "incre_win_rate": 0.75, "step": 567}
{"time": 1766665503.7816832, "phase": "train", "update": 568, "total_env_steps": 1817600, "episode_reward": 0.31010952591896057, "value_loss": 0.015540848237772782, "policy_loss": -0.012433981527782124, "dist_entropy": 0.5818624695142111, "actor_grad_norm": 0.16552318632602692, "critic_grad_norm": 0.01942540518939495, "ratio": 0.9999626278877258, "entropy": 0.5818624695142111, "incre_win_rate": 0.7636363636363637, "step": 568}
{"time": 1766665508.0319207, "phase": "train", "update": 569, "total_env_steps": 1820800, "episode_reward": 0.31950217485427856, "value_loss": 0.012798314727842808, "policy_loss": -0.011470794683141132, "dist_entropy": 0.5868578275044759, "actor_grad_norm": 0.14743870496749878, "critic_grad_norm": 0.03390027582645416, "ratio": 0.9979362487792969, "entropy": 0.5868578275044759, "incre_win_rate": 0.7777777777777778, "step": 569}
{"time": 1766665512.295778, "phase": "train", "update": 570, "total_env_steps": 1824000, "episode_reward": 0.30882203578948975, "value_loss": 0.012019150952498118, "policy_loss": -0.012679607537904758, "dist_entropy": 0.5906989932060241, "actor_grad_norm": 0.1564311385154724, "critic_grad_norm": 0.015473204664885998, "ratio": 0.9989603757858276, "entropy": 0.5906989932060241, "incre_win_rate": 0.75, "step": 570}
{"time": 1766665516.6103597, "phase": "train", "update": 571, "total_env_steps": 1827200, "episode_reward": 0.31457260251045227, "value_loss": 0.014988466600577037, "policy_loss": -0.01409907770386667, "dist_entropy": 0.5968396425247192, "actor_grad_norm": 0.18365013599395752, "critic_grad_norm": 0.024761782959103584, "ratio": 0.9989942312240601, "entropy": 0.5968396425247192, "incre_win_rate": 0.7142857142857143, "step": 571}
{"time": 1766665520.8437088, "phase": "train", "update": 572, "total_env_steps": 1830400, "episode_reward": 0.30483075976371765, "value_loss": 0.011905043137570221, "policy_loss": -0.013989391407012402, "dist_entropy": 0.5863162597020467, "actor_grad_norm": 0.1859726458787918, "critic_grad_norm": 0.019278686493635178, "ratio": 0.9999198913574219, "entropy": 0.5863162597020467, "incre_win_rate": 0.7647058823529411, "step": 572}
{"time": 1766665525.1157315, "phase": "train", "update": 573, "total_env_steps": 1833600, "episode_reward": 0.3171851933002472, "value_loss": 0.01612835346410672, "policy_loss": -0.0128118151341902, "dist_entropy": 0.5654550115267436, "actor_grad_norm": 0.20699799060821533, "critic_grad_norm": 0.03219729661941528, "ratio": 1.0002901554107666, "entropy": 0.5654550115267436, "incre_win_rate": 0.7272727272727273, "step": 573}
{"time": 1766665529.4065084, "phase": "train", "update": 574, "total_env_steps": 1836800, "episode_reward": 0.3132414221763611, "value_loss": 0.011217969159285227, "policy_loss": -0.013174005621775583, "dist_entropy": 0.5841547727584839, "actor_grad_norm": 0.15600484609603882, "critic_grad_norm": 0.02410191111266613, "ratio": 0.9999334812164307, "entropy": 0.5841547727584839, "incre_win_rate": 0.7924528301886793, "step": 574}
{"time": 1766665533.6935163, "phase": "train", "update": 575, "total_env_steps": 1840000, "episode_reward": 0.3121874928474426, "value_loss": 0.01063262199362119, "policy_loss": -0.013221061408146067, "dist_entropy": 0.6036919196446736, "actor_grad_norm": 0.19031724333763123, "critic_grad_norm": 0.017968596890568733, "ratio": 1.000760793685913, "entropy": 0.6036919196446736, "incre_win_rate": 0.7818181818181819, "step": 575}
{"time": 1766665538.0204718, "phase": "train", "update": 576, "total_env_steps": 1843200, "episode_reward": 0.30453968048095703, "value_loss": 0.014028435821334522, "policy_loss": -0.013424306482562069, "dist_entropy": 0.6046060919761658, "actor_grad_norm": 0.1867356151342392, "critic_grad_norm": 0.05406546965241432, "ratio": 1.000086784362793, "entropy": 0.6046060919761658, "incre_win_rate": 0.7307692307692307, "step": 576}
{"time": 1766665542.306274, "phase": "train", "update": 577, "total_env_steps": 1846400, "episode_reward": 0.30410081148147583, "value_loss": 0.012933584488928318, "policy_loss": -0.011930175163867792, "dist_entropy": 0.5767745892206828, "actor_grad_norm": 0.1574871987104416, "critic_grad_norm": 0.025284307077527046, "ratio": 0.999411940574646, "entropy": 0.5767745892206828, "incre_win_rate": 0.7037037037037037, "step": 577}
{"time": 1766665546.5637226, "phase": "train", "update": 578, "total_env_steps": 1849600, "episode_reward": 0.3069133162498474, "value_loss": 0.013319649981955688, "policy_loss": -0.01350068527397544, "dist_entropy": 0.5847757379213969, "actor_grad_norm": 0.18446916341781616, "critic_grad_norm": 0.020672494545578957, "ratio": 0.9995813965797424, "entropy": 0.5847757379213969, "incre_win_rate": 0.6923076923076923, "step": 578}
{"time": 1766665550.8308582, "phase": "train", "update": 579, "total_env_steps": 1852800, "episode_reward": 0.29509270191192627, "value_loss": 0.014558942367633184, "policy_loss": -0.013869155513115553, "dist_entropy": 0.5899664680163066, "actor_grad_norm": 0.18087904155254364, "critic_grad_norm": 0.03052506223320961, "ratio": 0.9995326399803162, "entropy": 0.5899664680163066, "incre_win_rate": 0.7307692307692307, "step": 579}
{"time": 1766665555.0866446, "phase": "train", "update": 580, "total_env_steps": 1856000, "episode_reward": 0.310230553150177, "value_loss": 0.014665730235477289, "policy_loss": -0.013706974434300415, "dist_entropy": 0.5731084028879802, "actor_grad_norm": 0.17272266745567322, "critic_grad_norm": 0.027007250115275383, "ratio": 0.9988045692443848, "entropy": 0.5731084028879802, "incre_win_rate": 0.7592592592592593, "step": 580}
{"time": 1766665559.35144, "phase": "train", "update": 581, "total_env_steps": 1859200, "episode_reward": 0.30516546964645386, "value_loss": 0.012497104580203693, "policy_loss": -0.01321421722596104, "dist_entropy": 0.5932625810305278, "actor_grad_norm": 0.2217896282672882, "critic_grad_norm": 0.03716641291975975, "ratio": 0.9992263913154602, "entropy": 0.5932625810305278, "incre_win_rate": 0.7777777777777778, "step": 581}
{"time": 1766665566.8936532, "phase": "eval", "update": 581, "total_env_steps": 1859200, "eval_win_rate": 0.875, "eval_episode_reward": 19.351179534313722, "step": 581}
{"time": 1766665571.1505136, "phase": "train", "update": 582, "total_env_steps": 1862400, "episode_reward": 0.3092164695262909, "value_loss": 0.011930008791387081, "policy_loss": -0.011765902463884004, "dist_entropy": 0.5731195171674093, "actor_grad_norm": 0.15776830911636353, "critic_grad_norm": 0.02858368121087551, "ratio": 0.9996330738067627, "entropy": 0.5731195171674093, "incre_win_rate": 0.75, "step": 582}
{"time": 1766665575.3912585, "phase": "train", "update": 583, "total_env_steps": 1865600, "episode_reward": 0.3034130036830902, "value_loss": 0.019054067383209864, "policy_loss": -0.01351732496648168, "dist_entropy": 0.564353597164154, "actor_grad_norm": 0.17278213798999786, "critic_grad_norm": 0.04438186436891556, "ratio": 0.999883770942688, "entropy": 0.564353597164154, "incre_win_rate": 0.6415094339622641, "step": 583}
{"time": 1766665579.7080498, "phase": "train", "update": 584, "total_env_steps": 1868800, "episode_reward": 0.3178538680076599, "value_loss": 0.012410981580615044, "policy_loss": -0.013157212361855386, "dist_entropy": 0.5646032571792603, "actor_grad_norm": 0.1657017469406128, "critic_grad_norm": 0.08930971473455429, "ratio": 0.9998942017555237, "entropy": 0.5646032571792603, "incre_win_rate": 0.7636363636363637, "step": 584}
{"time": 1766665584.0548322, "phase": "train", "update": 585, "total_env_steps": 1872000, "episode_reward": 0.3306150436401367, "value_loss": 0.007835790856430928, "policy_loss": -0.012321898503442223, "dist_entropy": 0.585225252310435, "actor_grad_norm": 0.17308409512043, "critic_grad_norm": 0.04461889714002609, "ratio": 0.9996535778045654, "entropy": 0.585225252310435, "incre_win_rate": 0.8928571428571429, "step": 585}
{"time": 1766665588.3523035, "phase": "train", "update": 586, "total_env_steps": 1875200, "episode_reward": 0.3134099245071411, "value_loss": 0.011926085874438285, "policy_loss": -0.013424049953785063, "dist_entropy": 0.5680607994397481, "actor_grad_norm": 0.19820985198020935, "critic_grad_norm": 0.06302039325237274, "ratio": 0.9994367957115173, "entropy": 0.5680607994397481, "incre_win_rate": 0.7169811320754716, "step": 586}
{"time": 1766665592.6169662, "phase": "train", "update": 587, "total_env_steps": 1878400, "episode_reward": 0.30734145641326904, "value_loss": 0.012896623524526755, "policy_loss": -0.01301188243732625, "dist_entropy": 0.5883859833081563, "actor_grad_norm": 0.21711401641368866, "critic_grad_norm": 0.04892067238688469, "ratio": 1.0012226104736328, "entropy": 0.5883859833081563, "incre_win_rate": 0.7407407407407407, "step": 587}
{"time": 1766665596.8916478, "phase": "train", "update": 588, "total_env_steps": 1881600, "episode_reward": 0.3068612217903137, "value_loss": 0.017381502191225688, "policy_loss": -0.013441100537817382, "dist_entropy": 0.575672964255015, "actor_grad_norm": 0.17743732035160065, "critic_grad_norm": 0.03778436779975891, "ratio": 0.9994500279426575, "entropy": 0.575672964255015, "incre_win_rate": 0.6981132075471698, "step": 588}
{"time": 1766665601.216962, "phase": "train", "update": 589, "total_env_steps": 1884800, "episode_reward": 0.31075823307037354, "value_loss": 0.014884219008187453, "policy_loss": -0.013469719018704989, "dist_entropy": 0.5737099051475525, "actor_grad_norm": 0.16175577044487, "critic_grad_norm": 0.030788874253630638, "ratio": 0.9999885559082031, "entropy": 0.5737099051475525, "incre_win_rate": 0.6785714285714286, "step": 589}
{"time": 1766665605.560375, "phase": "train", "update": 590, "total_env_steps": 1888000, "episode_reward": 0.29516851902008057, "value_loss": 0.018100972225268682, "policy_loss": -0.014303513510979353, "dist_entropy": 0.5716021021207174, "actor_grad_norm": 0.16326922178268433, "critic_grad_norm": 0.04387974739074707, "ratio": 0.9999041557312012, "entropy": 0.5716021021207174, "incre_win_rate": 0.6226415094339622, "step": 590}
{"time": 1766665609.9169831, "phase": "train", "update": 591, "total_env_steps": 1891200, "episode_reward": 0.2949027419090271, "value_loss": 0.013705357350409031, "policy_loss": -0.013393662733088736, "dist_entropy": 0.5609826644261678, "actor_grad_norm": 0.20313838124275208, "critic_grad_norm": 0.02002619579434395, "ratio": 0.9995658993721008, "entropy": 0.5609826644261678, "incre_win_rate": 0.5961538461538461, "step": 591}
{"time": 1766665614.2514982, "phase": "train", "update": 592, "total_env_steps": 1894400, "episode_reward": 0.3122541606426239, "value_loss": 0.014311490145822366, "policy_loss": -0.013336318258847039, "dist_entropy": 0.5795232017834981, "actor_grad_norm": 0.18335740268230438, "critic_grad_norm": 0.040997158735990524, "ratio": 1.0003752708435059, "entropy": 0.5795232017834981, "incre_win_rate": 0.7454545454545455, "step": 592}
{"time": 1766665618.4989057, "phase": "train", "update": 593, "total_env_steps": 1897600, "episode_reward": 0.30862975120544434, "value_loss": 0.01396525204181671, "policy_loss": -0.014043836800371304, "dist_entropy": 0.5862759908040365, "actor_grad_norm": 0.17388688027858734, "critic_grad_norm": 0.039144422858953476, "ratio": 0.9980835318565369, "entropy": 0.5862759908040365, "incre_win_rate": 0.8461538461538461, "step": 593}
{"time": 1766665622.8259943, "phase": "train", "update": 594, "total_env_steps": 1900800, "episode_reward": 0.31412073969841003, "value_loss": 0.013225870206952095, "policy_loss": -0.012763012820048896, "dist_entropy": 0.5744693716367085, "actor_grad_norm": 0.214450404047966, "critic_grad_norm": 0.05519788712263107, "ratio": 1.000935435295105, "entropy": 0.5744693716367085, "incre_win_rate": 0.7547169811320755, "step": 594}
{"time": 1766665627.1194403, "phase": "train", "update": 595, "total_env_steps": 1904000, "episode_reward": 0.33128678798675537, "value_loss": 0.011904582443336646, "policy_loss": -0.01168097543190072, "dist_entropy": 0.5684029420216878, "actor_grad_norm": 0.18186640739440918, "critic_grad_norm": 0.04559391736984253, "ratio": 0.9999963641166687, "entropy": 0.5684029420216878, "incre_win_rate": 0.8545454545454545, "step": 595}
{"time": 1766665631.4666467, "phase": "train", "update": 596, "total_env_steps": 1907200, "episode_reward": 0.33162301778793335, "value_loss": 0.010235297804077467, "policy_loss": -0.012877732174888952, "dist_entropy": 0.5680277268091838, "actor_grad_norm": 0.1704535037279129, "critic_grad_norm": 0.02815115451812744, "ratio": 0.9990620017051697, "entropy": 0.5680277268091838, "incre_win_rate": 0.8596491228070176, "step": 596}
{"time": 1766665635.7451136, "phase": "train", "update": 597, "total_env_steps": 1910400, "episode_reward": 0.30687883496284485, "value_loss": 0.015110521018505097, "policy_loss": -0.01362277799171944, "dist_entropy": 0.5731720685958862, "actor_grad_norm": 0.1578969806432724, "critic_grad_norm": 0.056779444217681885, "ratio": 1.0014591217041016, "entropy": 0.5731720685958862, "incre_win_rate": 0.7843137254901961, "step": 597}
{"time": 1766665640.1227345, "phase": "train", "update": 598, "total_env_steps": 1913600, "episode_reward": 0.297670841217041, "value_loss": 0.017379806190729142, "policy_loss": -0.013965906471829234, "dist_entropy": 0.5877033511797587, "actor_grad_norm": 0.20284302532672882, "critic_grad_norm": 0.07760198414325714, "ratio": 1.0000439882278442, "entropy": 0.5877033511797587, "incre_win_rate": 0.6851851851851852, "step": 598}
{"time": 1766665644.4332142, "phase": "train", "update": 599, "total_env_steps": 1916800, "episode_reward": 0.3125084638595581, "value_loss": 0.014211107852558295, "policy_loss": -0.011970857639138188, "dist_entropy": 0.5763704856236775, "actor_grad_norm": 0.1503431499004364, "critic_grad_norm": 0.04043477401137352, "ratio": 1.0012825727462769, "entropy": 0.5763704856236775, "incre_win_rate": 0.7924528301886793, "step": 599}
{"time": 1766665648.7311323, "phase": "train", "update": 600, "total_env_steps": 1920000, "episode_reward": 0.3062630295753479, "value_loss": 0.015528846097489198, "policy_loss": -0.012313347166321856, "dist_entropy": 0.5518305857976278, "actor_grad_norm": 0.2060537189245224, "critic_grad_norm": 0.05531062185764313, "ratio": 1.0011875629425049, "entropy": 0.5518305857976278, "incre_win_rate": 0.6981132075471698, "step": 600}
{"time": 1766665652.9985123, "phase": "train", "update": 601, "total_env_steps": 1923200, "episode_reward": 0.3066980838775635, "value_loss": 0.011172046201924484, "policy_loss": -0.01393364918800728, "dist_entropy": 0.5767403205235799, "actor_grad_norm": 0.16682757437229156, "critic_grad_norm": 0.031146232038736343, "ratio": 0.9995149970054626, "entropy": 0.5767403205235799, "incre_win_rate": 0.7358490566037735, "step": 601}
{"time": 1766665660.3381493, "phase": "eval", "update": 601, "total_env_steps": 1923200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.565104166666668, "step": 601}
{"time": 1766665664.5820348, "phase": "train", "update": 602, "total_env_steps": 1926400, "episode_reward": 0.30955421924591064, "value_loss": 0.013748828259607156, "policy_loss": -0.012297394112282707, "dist_entropy": 0.5887844562530518, "actor_grad_norm": 0.16465649008750916, "critic_grad_norm": 0.05330485850572586, "ratio": 0.9989922046661377, "entropy": 0.5887844562530518, "incre_win_rate": 0.7735849056603774, "step": 602}
{"time": 1766665668.8328738, "phase": "train", "update": 603, "total_env_steps": 1929600, "episode_reward": 0.3135286569595337, "value_loss": 0.010433257495363554, "policy_loss": -0.014074237230111445, "dist_entropy": 0.5908186435699463, "actor_grad_norm": 0.18038208782672882, "critic_grad_norm": 0.018993934616446495, "ratio": 0.9994258284568787, "entropy": 0.5908186435699463, "incre_win_rate": 0.8653846153846154, "step": 603}
{"time": 1766665673.099748, "phase": "train", "update": 604, "total_env_steps": 1932800, "episode_reward": 0.30425935983657837, "value_loss": 0.015018175914883613, "policy_loss": -0.011507363899581454, "dist_entropy": 0.5565501729647319, "actor_grad_norm": 0.19659197330474854, "critic_grad_norm": 0.05161888152360916, "ratio": 1.0005207061767578, "entropy": 0.5565501729647319, "incre_win_rate": 0.7090909090909091, "step": 604}
{"time": 1766665677.3036487, "phase": "train", "update": 605, "total_env_steps": 1936000, "episode_reward": 0.293396919965744, "value_loss": 0.01436815969645977, "policy_loss": -0.01355952663001349, "dist_entropy": 0.5777572751045227, "actor_grad_norm": 0.1613861322402954, "critic_grad_norm": 0.07389583438634872, "ratio": 0.9997096061706543, "entropy": 0.5777572751045227, "incre_win_rate": 0.64, "step": 605}
{"time": 1766665681.5634797, "phase": "train", "update": 606, "total_env_steps": 1939200, "episode_reward": 0.29859453439712524, "value_loss": 0.01325935535132885, "policy_loss": -0.01307141128767384, "dist_entropy": 0.5728551785151164, "actor_grad_norm": 0.16940225660800934, "critic_grad_norm": 0.055866777896881104, "ratio": 1.0006147623062134, "entropy": 0.5728551785151164, "incre_win_rate": 0.7547169811320755, "step": 606}
{"time": 1766665685.8336012, "phase": "train", "update": 607, "total_env_steps": 1942400, "episode_reward": 0.30876073241233826, "value_loss": 0.012840238275627296, "policy_loss": -0.013368306932462323, "dist_entropy": 0.590021566549937, "actor_grad_norm": 0.1626836061477661, "critic_grad_norm": 0.04180430620908737, "ratio": 0.9997526407241821, "entropy": 0.590021566549937, "incre_win_rate": 0.8235294117647058, "step": 607}
{"time": 1766665690.0743973, "phase": "train", "update": 608, "total_env_steps": 1945600, "episode_reward": 0.28374236822128296, "value_loss": 0.018241341784596445, "policy_loss": -0.01414335025254682, "dist_entropy": 0.5706694881121318, "actor_grad_norm": 0.19575266540050507, "critic_grad_norm": 0.12723475694656372, "ratio": 0.999586820602417, "entropy": 0.5706694881121318, "incre_win_rate": 0.5660377358490566, "step": 608}
{"time": 1766665694.3189876, "phase": "train", "update": 609, "total_env_steps": 1948800, "episode_reward": 0.29611676931381226, "value_loss": 0.016726718594630558, "policy_loss": -0.013204441440795614, "dist_entropy": 0.5738311092058818, "actor_grad_norm": 0.2593421936035156, "critic_grad_norm": 0.05924089998006821, "ratio": 1.0001647472381592, "entropy": 0.5738311092058818, "incre_win_rate": 0.7115384615384616, "step": 609}
{"time": 1766665698.5441139, "phase": "train", "update": 610, "total_env_steps": 1952000, "episode_reward": 0.312112420797348, "value_loss": 0.012368907779455185, "policy_loss": -0.01271479481423133, "dist_entropy": 0.5981493314107259, "actor_grad_norm": 0.16638261079788208, "critic_grad_norm": 0.04712674021720886, "ratio": 0.9997209906578064, "entropy": 0.5981493314107259, "incre_win_rate": 0.8627450980392157, "step": 610}
{"time": 1766665702.8224607, "phase": "train", "update": 611, "total_env_steps": 1955200, "episode_reward": 0.2972801923751831, "value_loss": 0.014957623121639093, "policy_loss": -0.012576564184030541, "dist_entropy": 0.589260458946228, "actor_grad_norm": 0.16865988075733185, "critic_grad_norm": 0.0656985342502594, "ratio": 0.9994440674781799, "entropy": 0.589260458946228, "incre_win_rate": 0.7115384615384616, "step": 611}
{"time": 1766665707.080508, "phase": "train", "update": 612, "total_env_steps": 1958400, "episode_reward": 0.3032483160495758, "value_loss": 0.013080625360210736, "policy_loss": -0.012003521844824878, "dist_entropy": 0.5920629064242046, "actor_grad_norm": 0.1677236258983612, "critic_grad_norm": 0.021832799538969994, "ratio": 0.999484658241272, "entropy": 0.5920629064242046, "incre_win_rate": 0.7037037037037037, "step": 612}
{"time": 1766665711.3220499, "phase": "train", "update": 613, "total_env_steps": 1961600, "episode_reward": 0.30822765827178955, "value_loss": 0.014981209797163804, "policy_loss": -0.01271107482504282, "dist_entropy": 0.5911020000775655, "actor_grad_norm": 0.19326519966125488, "critic_grad_norm": 0.019698020070791245, "ratio": 0.9996291399002075, "entropy": 0.5911020000775655, "incre_win_rate": 0.6666666666666666, "step": 613}
{"time": 1766665715.582238, "phase": "train", "update": 614, "total_env_steps": 1964800, "episode_reward": 0.3090288043022156, "value_loss": 0.012207950092852115, "policy_loss": -0.012323650616243262, "dist_entropy": 0.6008740981419881, "actor_grad_norm": 0.17222632467746735, "critic_grad_norm": 0.04030168801546097, "ratio": 0.9996247291564941, "entropy": 0.6008740981419881, "incre_win_rate": 0.8076923076923077, "step": 614}
{"time": 1766665719.8113608, "phase": "train", "update": 615, "total_env_steps": 1968000, "episode_reward": 0.29203662276268005, "value_loss": 0.014031540043652058, "policy_loss": -0.012724689379330793, "dist_entropy": 0.5909029920895894, "actor_grad_norm": 0.15239498019218445, "critic_grad_norm": 0.023934753611683846, "ratio": 1.0003259181976318, "entropy": 0.5909029920895894, "incre_win_rate": 0.6666666666666666, "step": 615}
{"time": 1766665724.0671167, "phase": "train", "update": 616, "total_env_steps": 1971200, "episode_reward": 0.31062427163124084, "value_loss": 0.013200472046931585, "policy_loss": -0.013475568984662326, "dist_entropy": 0.5849634965260824, "actor_grad_norm": 0.15913096070289612, "critic_grad_norm": 0.03415786474943161, "ratio": 0.9986844062805176, "entropy": 0.5849634965260824, "incre_win_rate": 0.7924528301886793, "step": 616}
{"time": 1766665728.3224566, "phase": "train", "update": 617, "total_env_steps": 1974400, "episode_reward": 0.30367571115493774, "value_loss": 0.01130757046242555, "policy_loss": -0.01277011904479437, "dist_entropy": 0.591953190167745, "actor_grad_norm": 0.15568965673446655, "critic_grad_norm": 0.014946356415748596, "ratio": 0.9995062351226807, "entropy": 0.591953190167745, "incre_win_rate": 0.7450980392156863, "step": 617}
{"time": 1766665732.6164148, "phase": "train", "update": 618, "total_env_steps": 1977600, "episode_reward": 0.31234070658683777, "value_loss": 0.014161063047746817, "policy_loss": -0.011679614792794743, "dist_entropy": 0.5994189063707988, "actor_grad_norm": 0.1337679624557495, "critic_grad_norm": 0.01915747858583927, "ratio": 0.999693751335144, "entropy": 0.5994189063707988, "incre_win_rate": 0.8035714285714286, "step": 618}
{"time": 1766665736.8330162, "phase": "train", "update": 619, "total_env_steps": 1980800, "episode_reward": 0.3075704276561737, "value_loss": 0.013847430609166623, "policy_loss": -0.013777524449056007, "dist_entropy": 0.5820882797241211, "actor_grad_norm": 0.18397091329097748, "critic_grad_norm": 0.01950911246240139, "ratio": 1.0008716583251953, "entropy": 0.5820882797241211, "incre_win_rate": 0.7884615384615384, "step": 619}
{"time": 1766665741.0949914, "phase": "train", "update": 620, "total_env_steps": 1984000, "episode_reward": 0.29739508032798767, "value_loss": 0.010873895014325778, "policy_loss": -0.014021513670595216, "dist_entropy": 0.6027205387751261, "actor_grad_norm": 0.19513067603111267, "critic_grad_norm": 0.02515857294201851, "ratio": 0.9984678626060486, "entropy": 0.6027205387751261, "incre_win_rate": 0.78, "step": 620}
{"time": 1766665745.3467607, "phase": "train", "update": 621, "total_env_steps": 1987200, "episode_reward": 0.3057482838630676, "value_loss": 0.012352972850203514, "policy_loss": -0.012497842720237648, "dist_entropy": 0.593188468615214, "actor_grad_norm": 0.14719770848751068, "critic_grad_norm": 0.015367879532277584, "ratio": 0.9992786049842834, "entropy": 0.593188468615214, "incre_win_rate": 0.7692307692307693, "step": 621}
{"time": 1766665753.1665127, "phase": "eval", "update": 621, "total_env_steps": 1987200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.75857843137255, "step": 621}
{"time": 1766665757.3769443, "phase": "train", "update": 622, "total_env_steps": 1990400, "episode_reward": 0.3137798607349396, "value_loss": 0.010401348769664764, "policy_loss": -0.012131574635146573, "dist_entropy": 0.5863875826199849, "actor_grad_norm": 0.161089226603508, "critic_grad_norm": 0.03272134065628052, "ratio": 0.9992770552635193, "entropy": 0.5863875826199849, "incre_win_rate": 0.8301886792452831, "step": 622}
{"time": 1766665761.6267433, "phase": "train", "update": 623, "total_env_steps": 1993600, "episode_reward": 0.3059191405773163, "value_loss": 0.010000870004296303, "policy_loss": -0.012983538290317636, "dist_entropy": 0.5977513392766317, "actor_grad_norm": 0.14155016839504242, "critic_grad_norm": 0.021964017301797867, "ratio": 0.9991819858551025, "entropy": 0.5977513392766317, "incre_win_rate": 0.8431372549019608, "step": 623}
{"time": 1766665765.9007099, "phase": "train", "update": 624, "total_env_steps": 1996800, "episode_reward": 0.30750614404678345, "value_loss": 0.010804105550050735, "policy_loss": -0.012384597866105906, "dist_entropy": 0.5825557629267375, "actor_grad_norm": 0.17686885595321655, "critic_grad_norm": 0.03329773619771004, "ratio": 0.9993732571601868, "entropy": 0.5825557629267375, "incre_win_rate": 0.8076923076923077, "step": 624}
{"time": 1766665770.1166854, "phase": "train", "update": 625, "total_env_steps": 2000000, "episode_reward": 0.3025880753993988, "value_loss": 0.010424198458592097, "policy_loss": -0.012461048120526877, "dist_entropy": 0.6019213596979777, "actor_grad_norm": 0.15937212109565735, "critic_grad_norm": 0.013552483171224594, "ratio": 0.9991614818572998, "entropy": 0.6019213596979777, "incre_win_rate": 0.82, "step": 625}
{"time": 1766665774.4051547, "phase": "train", "update": 626, "total_env_steps": 2003200, "episode_reward": 0.29255589842796326, "value_loss": 0.01264782939106226, "policy_loss": -0.012940652180361193, "dist_entropy": 0.5640125791231791, "actor_grad_norm": 0.15106768906116486, "critic_grad_norm": 0.07031135261058807, "ratio": 1.0010547637939453, "entropy": 0.5640125791231791, "incre_win_rate": 0.6730769230769231, "step": 626}
{"time": 1766665778.5902305, "phase": "train", "update": 627, "total_env_steps": 2006400, "episode_reward": 0.30537837743759155, "value_loss": 0.014250159325699011, "policy_loss": -0.014278935566678778, "dist_entropy": 0.5961489955584208, "actor_grad_norm": 0.20167112350463867, "critic_grad_norm": 0.04804275557398796, "ratio": 0.9993351697921753, "entropy": 0.5961489955584208, "incre_win_rate": 0.7843137254901961, "step": 627}
{"time": 1766665782.8265493, "phase": "train", "update": 628, "total_env_steps": 2009600, "episode_reward": 0.30039137601852417, "value_loss": 0.009318219684064388, "policy_loss": -0.013343173871086123, "dist_entropy": 0.610411012172699, "actor_grad_norm": 0.22292496263980865, "critic_grad_norm": 0.05073601379990578, "ratio": 0.9990020394325256, "entropy": 0.610411012172699, "incre_win_rate": 0.8301886792452831, "step": 628}
{"time": 1766665787.0610085, "phase": "train", "update": 629, "total_env_steps": 2012800, "episode_reward": 0.29214614629745483, "value_loss": 0.011554780726631483, "policy_loss": -0.01267454396717606, "dist_entropy": 0.6184610009193421, "actor_grad_norm": 0.20570339262485504, "critic_grad_norm": 0.035958487540483475, "ratio": 0.9999231100082397, "entropy": 0.6184610009193421, "incre_win_rate": 0.851063829787234, "step": 629}
{"time": 1766665791.2991042, "phase": "train", "update": 630, "total_env_steps": 2016000, "episode_reward": 0.29928311705589294, "value_loss": 0.01185202623407046, "policy_loss": -0.012761821536216663, "dist_entropy": 0.604653251171112, "actor_grad_norm": 0.1649927794933319, "critic_grad_norm": 0.05065396800637245, "ratio": 1.000038743019104, "entropy": 0.604653251171112, "incre_win_rate": 0.75, "step": 630}
{"time": 1766665795.5434256, "phase": "train", "update": 631, "total_env_steps": 2019200, "episode_reward": 0.3082980811595917, "value_loss": 0.012198443648715813, "policy_loss": -0.014460825565659736, "dist_entropy": 0.6024423201878866, "actor_grad_norm": 0.17492124438285828, "critic_grad_norm": 0.036780018359422684, "ratio": 0.9991989731788635, "entropy": 0.6024423201878866, "incre_win_rate": 0.7735849056603774, "step": 631}
{"time": 1766665799.8307621, "phase": "train", "update": 632, "total_env_steps": 2022400, "episode_reward": 0.28539368510246277, "value_loss": 0.020905859023332595, "policy_loss": -0.01515581180086715, "dist_entropy": 0.6359165072441101, "actor_grad_norm": 0.17651431262493134, "critic_grad_norm": 0.05345633625984192, "ratio": 0.9988952279090881, "entropy": 0.6359165072441101, "incre_win_rate": 0.6470588235294118, "step": 632}
{"time": 1766665804.0732973, "phase": "train", "update": 633, "total_env_steps": 2025600, "episode_reward": 0.2861703634262085, "value_loss": 0.016755973858137926, "policy_loss": -0.014441699591874151, "dist_entropy": 0.6027581254641216, "actor_grad_norm": 0.1635657548904419, "critic_grad_norm": 0.02678888663649559, "ratio": 1.0013401508331299, "entropy": 0.6027581254641216, "incre_win_rate": 0.7142857142857143, "step": 633}
{"time": 1766665808.2867994, "phase": "train", "update": 634, "total_env_steps": 2028800, "episode_reward": 0.27035462856292725, "value_loss": 0.020110780745744704, "policy_loss": -0.015121560334426931, "dist_entropy": 0.6215343038241069, "actor_grad_norm": 0.20316654443740845, "critic_grad_norm": 0.09726545959711075, "ratio": 0.9992287158966064, "entropy": 0.6215343038241069, "incre_win_rate": 0.48148148148148145, "step": 634}
{"time": 1766665812.523974, "phase": "train", "update": 635, "total_env_steps": 2032000, "episode_reward": 0.28340455889701843, "value_loss": 0.01490744948387146, "policy_loss": -0.013872952806599415, "dist_entropy": 0.6143293142318725, "actor_grad_norm": 0.18191450834274292, "critic_grad_norm": 0.06603054702281952, "ratio": 0.9993885159492493, "entropy": 0.6143293142318725, "incre_win_rate": 0.5471698113207547, "step": 635}
{"time": 1766665816.7625208, "phase": "train", "update": 636, "total_env_steps": 2035200, "episode_reward": 0.29846736788749695, "value_loss": 0.013881741898755233, "policy_loss": -0.015010604975974692, "dist_entropy": 0.6129449367523193, "actor_grad_norm": 0.2024257630109787, "critic_grad_norm": 0.038506247103214264, "ratio": 0.9989231824874878, "entropy": 0.6129449367523193, "incre_win_rate": 0.7115384615384616, "step": 636}
{"time": 1766665820.9403672, "phase": "train", "update": 637, "total_env_steps": 2038400, "episode_reward": 0.2828638255596161, "value_loss": 0.015416651405394078, "policy_loss": -0.014161080300820217, "dist_entropy": 0.6269546270370483, "actor_grad_norm": 0.16612108051776886, "critic_grad_norm": 0.03703516349196434, "ratio": 0.9991315007209778, "entropy": 0.6269546270370483, "incre_win_rate": 0.66, "step": 637}
{"time": 1766665825.3954668, "phase": "train", "update": 638, "total_env_steps": 2041600, "episode_reward": 0.2920664846897125, "value_loss": 0.01693026106804609, "policy_loss": -0.01407691615120162, "dist_entropy": 0.6097224156061808, "actor_grad_norm": 0.19710992276668549, "critic_grad_norm": 0.04969678819179535, "ratio": 0.9990407824516296, "entropy": 0.6097224156061808, "incre_win_rate": 0.5849056603773585, "step": 638}
{"time": 1766665829.659932, "phase": "train", "update": 639, "total_env_steps": 2044800, "episode_reward": 0.29433441162109375, "value_loss": 0.014431499938170115, "policy_loss": -0.0143044638448373, "dist_entropy": 0.6131528735160827, "actor_grad_norm": 0.16600832343101501, "critic_grad_norm": 0.06062230467796326, "ratio": 0.9987529516220093, "entropy": 0.6131528735160827, "incre_win_rate": 0.6792452830188679, "step": 639}
{"time": 1766665833.9397511, "phase": "train", "update": 640, "total_env_steps": 2048000, "episode_reward": 0.3063955307006836, "value_loss": 0.01433416772633791, "policy_loss": -0.013458248024302222, "dist_entropy": 0.6065635840098064, "actor_grad_norm": 0.14081886410713196, "critic_grad_norm": 0.03946248069405556, "ratio": 0.9993575215339661, "entropy": 0.6065635840098064, "incre_win_rate": 0.7692307692307693, "step": 640}
{"time": 1766665838.2214882, "phase": "train", "update": 641, "total_env_steps": 2051200, "episode_reward": 0.2888649106025696, "value_loss": 0.018979758520921073, "policy_loss": -0.01495472683319387, "dist_entropy": 0.5971157948176066, "actor_grad_norm": 0.20009146630764008, "critic_grad_norm": 0.07789751887321472, "ratio": 0.9991741180419922, "entropy": 0.5971157948176066, "incre_win_rate": 0.5471698113207547, "step": 641}
{"time": 1766665845.76525, "phase": "eval", "update": 641, "total_env_steps": 2051200, "eval_win_rate": 0.875, "eval_episode_reward": 19.319316789215687, "step": 641}
{"time": 1766665849.9581296, "phase": "train", "update": 642, "total_env_steps": 2054400, "episode_reward": 0.2801592946052551, "value_loss": 0.019013835613926253, "policy_loss": -0.014836929448646667, "dist_entropy": 0.6112212260564168, "actor_grad_norm": 0.1793726533651352, "critic_grad_norm": 0.04087574779987335, "ratio": 0.9998739361763, "entropy": 0.6112212260564168, "incre_win_rate": 0.5471698113207547, "step": 642}
{"time": 1766665854.2126672, "phase": "train", "update": 643, "total_env_steps": 2057600, "episode_reward": 0.3119899034500122, "value_loss": 0.012305649432043235, "policy_loss": -0.013900738100596754, "dist_entropy": 0.6034409483273824, "actor_grad_norm": 0.16961823403835297, "critic_grad_norm": 0.07599781453609467, "ratio": 0.9996087551116943, "entropy": 0.6034409483273824, "incre_win_rate": 0.7272727272727273, "step": 643}
{"time": 1766665858.453659, "phase": "train", "update": 644, "total_env_steps": 2060800, "episode_reward": 0.30402496457099915, "value_loss": 0.010835966219504674, "policy_loss": -0.014417340895406501, "dist_entropy": 0.6075202306111653, "actor_grad_norm": 0.1837754249572754, "critic_grad_norm": 0.07536844909191132, "ratio": 0.9987596273422241, "entropy": 0.6075202306111653, "incre_win_rate": 0.82, "step": 644}
{"time": 1766665862.6688359, "phase": "train", "update": 645, "total_env_steps": 2064000, "episode_reward": 0.3105928301811218, "value_loss": 0.012768556860586007, "policy_loss": -0.013366543032445104, "dist_entropy": 0.5666818817456564, "actor_grad_norm": 0.15956248342990875, "critic_grad_norm": 0.03524026274681091, "ratio": 1.0004488229751587, "entropy": 0.5666818817456564, "incre_win_rate": 0.7407407407407407, "step": 645}
{"time": 1766665866.9033096, "phase": "train", "update": 646, "total_env_steps": 2067200, "episode_reward": 0.3166229724884033, "value_loss": 0.009502054254213969, "policy_loss": -0.011973172606912878, "dist_entropy": 0.5946429212888081, "actor_grad_norm": 0.17981691658496857, "critic_grad_norm": 0.05930459126830101, "ratio": 1.0004699230194092, "entropy": 0.5946429212888081, "incre_win_rate": 0.8363636363636363, "step": 646}
{"time": 1766665871.149406, "phase": "train", "update": 647, "total_env_steps": 2070400, "episode_reward": 0.2910347878932953, "value_loss": 0.01380341009547313, "policy_loss": -0.014584413726905629, "dist_entropy": 0.6025588591893514, "actor_grad_norm": 0.1806384176015854, "critic_grad_norm": 0.06019177660346031, "ratio": 0.9999919533729553, "entropy": 0.6025588591893514, "incre_win_rate": 0.66, "step": 647}
{"time": 1766665875.4019408, "phase": "train", "update": 648, "total_env_steps": 2073600, "episode_reward": 0.30023902654647827, "value_loss": 0.012249745366473993, "policy_loss": -0.014999810558353251, "dist_entropy": 0.6248093287150065, "actor_grad_norm": 0.20750421285629272, "critic_grad_norm": 0.033403195440769196, "ratio": 0.9997315406799316, "entropy": 0.6248093287150065, "incre_win_rate": 0.8113207547169812, "step": 648}
{"time": 1766665879.6009867, "phase": "train", "update": 649, "total_env_steps": 2076800, "episode_reward": 0.30576521158218384, "value_loss": 0.010563464524845282, "policy_loss": -0.013199272196082272, "dist_entropy": 0.5811410109202068, "actor_grad_norm": 0.16625596582889557, "critic_grad_norm": 0.030657025054097176, "ratio": 0.9996998310089111, "entropy": 0.5811410109202068, "incre_win_rate": 0.8163265306122449, "step": 649}
{"time": 1766665884.0926383, "phase": "train", "update": 650, "total_env_steps": 2080000, "episode_reward": 0.3034505248069763, "value_loss": 0.017457095657785734, "policy_loss": -0.013003695201243677, "dist_entropy": 0.5884494543075561, "actor_grad_norm": 0.2081013321876526, "critic_grad_norm": 0.12331147491931915, "ratio": 1.001137614250183, "entropy": 0.5884494543075561, "incre_win_rate": 0.625, "step": 650}
{"time": 1766665888.33909, "phase": "train", "update": 651, "total_env_steps": 2083200, "episode_reward": 0.30148518085479736, "value_loss": 0.012613140419125557, "policy_loss": -0.013379055462489948, "dist_entropy": 0.5928514679272969, "actor_grad_norm": 0.2289990484714508, "critic_grad_norm": 0.01606747880578041, "ratio": 1.0004440546035767, "entropy": 0.5928514679272969, "incre_win_rate": 0.6981132075471698, "step": 651}
{"time": 1766665892.5557997, "phase": "train", "update": 652, "total_env_steps": 2086400, "episode_reward": 0.3026769459247589, "value_loss": 0.01383159328252077, "policy_loss": -0.013776156235749681, "dist_entropy": 0.5882585565249125, "actor_grad_norm": 0.1575661301612854, "critic_grad_norm": 0.019430847838521004, "ratio": 0.9989114999771118, "entropy": 0.5882585565249125, "incre_win_rate": 0.7450980392156863, "step": 652}
{"time": 1766665931.7981892, "phase": "train", "update": 653, "total_env_steps": 2089600, "episode_reward": 0.2998100519180298, "value_loss": 0.0504058671494325, "policy_loss": -0.01016964456482583, "dist_entropy": 0.6012688040733337, "actor_grad_norm": 0.1366521567106247, "critic_grad_norm": 0.07544565945863724, "ratio": 0.9998750686645508, "entropy": 0.6012688040733337, "incre_win_rate": 0.6938775510204082, "step": 653}
{"time": 1766665936.1120064, "phase": "train", "update": 654, "total_env_steps": 2092800, "episode_reward": 0.30160847306251526, "value_loss": 0.014127754730482896, "policy_loss": -0.013725979944149695, "dist_entropy": 0.5912257035573324, "actor_grad_norm": 0.17407137155532837, "critic_grad_norm": 0.043754350394010544, "ratio": 0.9983131289482117, "entropy": 0.5912257035573324, "incre_win_rate": 0.6727272727272727, "step": 654}
{"time": 1766665940.3198442, "phase": "train", "update": 655, "total_env_steps": 2096000, "episode_reward": 0.30458104610443115, "value_loss": 0.010916647563378016, "policy_loss": -0.01268656719569729, "dist_entropy": 0.5659774422645569, "actor_grad_norm": 0.17417185008525848, "critic_grad_norm": 0.05054372549057007, "ratio": 0.9995551705360413, "entropy": 0.5659774422645569, "incre_win_rate": 0.803921568627451, "step": 655}
{"time": 1766665944.5896647, "phase": "train", "update": 656, "total_env_steps": 2099200, "episode_reward": 0.2996300756931305, "value_loss": 0.013399197782079379, "policy_loss": -0.012661891516044932, "dist_entropy": 0.5808417479197184, "actor_grad_norm": 0.1413399875164032, "critic_grad_norm": 0.026615172624588013, "ratio": 0.9997648000717163, "entropy": 0.5808417479197184, "incre_win_rate": 0.6981132075471698, "step": 656}
{"time": 1766665948.8971388, "phase": "train", "update": 657, "total_env_steps": 2102400, "episode_reward": 0.3155744671821594, "value_loss": 0.011416413572927315, "policy_loss": -0.013959069872451716, "dist_entropy": 0.585652748743693, "actor_grad_norm": 0.14937056601047516, "critic_grad_norm": 0.03121638298034668, "ratio": 1.0002977848052979, "entropy": 0.585652748743693, "incre_win_rate": 0.7407407407407407, "step": 657}
{"time": 1766665953.1339283, "phase": "train", "update": 658, "total_env_steps": 2105600, "episode_reward": 0.31915518641471863, "value_loss": 0.008343066771825154, "policy_loss": -0.012286283452473394, "dist_entropy": 0.6160702427228292, "actor_grad_norm": 0.15481775999069214, "critic_grad_norm": 0.05463807284832001, "ratio": 0.9986841678619385, "entropy": 0.6160702427228292, "incre_win_rate": 0.8679245283018868, "step": 658}
{"time": 1766665957.469496, "phase": "train", "update": 659, "total_env_steps": 2108800, "episode_reward": 0.3265165388584137, "value_loss": 0.0085496892221272, "policy_loss": -0.012017857197302343, "dist_entropy": 0.598236350218455, "actor_grad_norm": 0.1410984843969345, "critic_grad_norm": 0.04083395004272461, "ratio": 0.9988728165626526, "entropy": 0.598236350218455, "incre_win_rate": 0.8888888888888888, "step": 659}
{"time": 1766665961.7357068, "phase": "train", "update": 660, "total_env_steps": 2112000, "episode_reward": 0.30096355080604553, "value_loss": 0.010411484291156133, "policy_loss": -0.012950258969919066, "dist_entropy": 0.6058777332305908, "actor_grad_norm": 0.15690702199935913, "critic_grad_norm": 0.04723167419433594, "ratio": 0.999297559261322, "entropy": 0.6058777332305908, "incre_win_rate": 0.7884615384615384, "step": 660}
{"time": 1766665966.0178556, "phase": "train", "update": 661, "total_env_steps": 2115200, "episode_reward": 0.3085278868675232, "value_loss": 0.010958166730900606, "policy_loss": -0.012133051388128516, "dist_entropy": 0.5960203687349955, "actor_grad_norm": 0.17493599653244019, "critic_grad_norm": 0.03062671609222889, "ratio": 0.9985873699188232, "entropy": 0.5960203687349955, "incre_win_rate": 0.7962962962962963, "step": 661}
{"time": 1766665979.22435, "phase": "eval", "update": 661, "total_env_steps": 2115200, "eval_win_rate": 0.875, "eval_episode_reward": 19.03921568627451, "step": 661}
{"time": 1766665983.4661064, "phase": "train", "update": 662, "total_env_steps": 2118400, "episode_reward": 0.3095411956310272, "value_loss": 0.009504185058176517, "policy_loss": -0.012821591821428531, "dist_entropy": 0.624579656124115, "actor_grad_norm": 0.16401366889476776, "critic_grad_norm": 0.015504639595746994, "ratio": 0.9993933439254761, "entropy": 0.624579656124115, "incre_win_rate": 0.8, "step": 662}
{"time": 1766665987.8186505, "phase": "train", "update": 663, "total_env_steps": 2121600, "episode_reward": 0.3162308633327484, "value_loss": 0.010972823761403561, "policy_loss": -0.012556165223372655, "dist_entropy": 0.617523988087972, "actor_grad_norm": 0.14635954797267914, "critic_grad_norm": 0.019484149292111397, "ratio": 0.9998950362205505, "entropy": 0.617523988087972, "incre_win_rate": 0.7962962962962963, "step": 663}
{"time": 1766665992.1026251, "phase": "train", "update": 664, "total_env_steps": 2124800, "episode_reward": 0.3084888160228729, "value_loss": 0.013663671414057414, "policy_loss": -0.012890430872325236, "dist_entropy": 0.604747211933136, "actor_grad_norm": 0.1570073962211609, "critic_grad_norm": 0.04344571754336357, "ratio": 0.9997729659080505, "entropy": 0.604747211933136, "incre_win_rate": 0.7924528301886793, "step": 664}
{"time": 1766665996.6679795, "phase": "train", "update": 665, "total_env_steps": 2128000, "episode_reward": 0.30389171838760376, "value_loss": 0.012779047774771849, "policy_loss": -0.012567210598579475, "dist_entropy": 0.5959128141403198, "actor_grad_norm": 0.1557285189628601, "critic_grad_norm": 0.022546622902154922, "ratio": 0.9996744394302368, "entropy": 0.5959128141403198, "incre_win_rate": 0.7547169811320755, "step": 665}
{"time": 1766666001.4166915, "phase": "train", "update": 666, "total_env_steps": 2131200, "episode_reward": 0.30482611060142517, "value_loss": 0.008935291940967241, "policy_loss": -0.01363118217181049, "dist_entropy": 0.5885143081347147, "actor_grad_norm": 0.16427449882030487, "critic_grad_norm": 0.05047597363591194, "ratio": 0.9999094009399414, "entropy": 0.5885143081347147, "incre_win_rate": 0.7692307692307693, "step": 666}
{"time": 1766666005.6274898, "phase": "train", "update": 667, "total_env_steps": 2134400, "episode_reward": 0.3188886344432831, "value_loss": 0.008950188507636387, "policy_loss": -0.012264622613863215, "dist_entropy": 0.6157415469487508, "actor_grad_norm": 0.1495777815580368, "critic_grad_norm": 0.03232370316982269, "ratio": 1.0002262592315674, "entropy": 0.6157415469487508, "incre_win_rate": 0.8846153846153846, "step": 667}
{"time": 1766666009.9137943, "phase": "train", "update": 668, "total_env_steps": 2137600, "episode_reward": 0.3146216571331024, "value_loss": 0.011875750745336216, "policy_loss": -0.012057359751406694, "dist_entropy": 0.6015595237414042, "actor_grad_norm": 0.2010832577943802, "critic_grad_norm": 0.05360955744981766, "ratio": 1.0008901357650757, "entropy": 0.6015595237414042, "incre_win_rate": 0.8035714285714286, "step": 668}
{"time": 1766666014.1472254, "phase": "train", "update": 669, "total_env_steps": 2140800, "episode_reward": 0.3108394742012024, "value_loss": 0.007604528777301311, "policy_loss": -0.012864533308677059, "dist_entropy": 0.6042253692944844, "actor_grad_norm": 0.18061400949954987, "critic_grad_norm": 0.030754897743463516, "ratio": 1.0001096725463867, "entropy": 0.6042253692944844, "incre_win_rate": 0.8431372549019608, "step": 669}
{"time": 1766666018.4550352, "phase": "train", "update": 670, "total_env_steps": 2144000, "episode_reward": 0.3325352072715759, "value_loss": 0.00490025437126557, "policy_loss": -0.011429753981092479, "dist_entropy": 0.6084216793378194, "actor_grad_norm": 0.1423192322254181, "critic_grad_norm": 0.05371653288602829, "ratio": 0.999945878982544, "entropy": 0.6084216793378194, "incre_win_rate": 0.9811320754716981, "step": 670}
{"time": 1766666022.7185173, "phase": "train", "update": 671, "total_env_steps": 2147200, "episode_reward": 0.308125764131546, "value_loss": 0.012190982202688853, "policy_loss": -0.012628755725776486, "dist_entropy": 0.5956018845240275, "actor_grad_norm": 0.18456849455833435, "critic_grad_norm": 0.03615275025367737, "ratio": 0.9997169971466064, "entropy": 0.5956018845240275, "incre_win_rate": 0.7962962962962963, "step": 671}
{"time": 1766666027.0513268, "phase": "train", "update": 672, "total_env_steps": 2150400, "episode_reward": 0.3191429078578949, "value_loss": 0.013097590518494446, "policy_loss": -0.013156962152559496, "dist_entropy": 0.5894164045651754, "actor_grad_norm": 0.1923295259475708, "critic_grad_norm": 0.022661961615085602, "ratio": 0.9997937679290771, "entropy": 0.5894164045651754, "incre_win_rate": 0.7777777777777778, "step": 672}
{"time": 1766666031.324758, "phase": "train", "update": 673, "total_env_steps": 2153600, "episode_reward": 0.3146798312664032, "value_loss": 0.008987922469774883, "policy_loss": -0.011554125009722327, "dist_entropy": 0.6054938912391663, "actor_grad_norm": 0.16370250284671783, "critic_grad_norm": 0.024373194202780724, "ratio": 1.0000674724578857, "entropy": 0.6054938912391663, "incre_win_rate": 0.8076923076923077, "step": 673}
{"time": 1766666035.9005103, "phase": "train", "update": 674, "total_env_steps": 2156800, "episode_reward": 0.33176928758621216, "value_loss": 0.0059176372364163395, "policy_loss": -0.012169304948798754, "dist_entropy": 0.6179487427075704, "actor_grad_norm": 0.17713937163352966, "critic_grad_norm": 0.026868661865592003, "ratio": 0.9990848898887634, "entropy": 0.6179487427075704, "incre_win_rate": 0.9107142857142857, "step": 674}
{"time": 1766666040.4364045, "phase": "train", "update": 675, "total_env_steps": 2160000, "episode_reward": 0.31091684103012085, "value_loss": 0.01579961975415548, "policy_loss": -0.013276889987315599, "dist_entropy": 0.5964772423108419, "actor_grad_norm": 0.16145257651805878, "critic_grad_norm": 0.09336849302053452, "ratio": 0.9996758103370667, "entropy": 0.5964772423108419, "incre_win_rate": 0.7169811320754716, "step": 675}
{"time": 1766666044.687346, "phase": "train", "update": 676, "total_env_steps": 2163200, "episode_reward": 0.29504597187042236, "value_loss": 0.012592033483088017, "policy_loss": -0.013445007931678058, "dist_entropy": 0.5890429337819417, "actor_grad_norm": 0.16170991957187653, "critic_grad_norm": 0.06607263535261154, "ratio": 0.9995322823524475, "entropy": 0.5890429337819417, "incre_win_rate": 0.6923076923076923, "step": 676}
{"time": 1766666049.0310187, "phase": "train", "update": 677, "total_env_steps": 2166400, "episode_reward": 0.2974095940589905, "value_loss": 0.012494696180025737, "policy_loss": -0.01376236317323105, "dist_entropy": 0.6110629518826802, "actor_grad_norm": 0.16449768841266632, "critic_grad_norm": 0.031622737646102905, "ratio": 0.9987655878067017, "entropy": 0.6110629518826802, "incre_win_rate": 0.6792452830188679, "step": 677}
{"time": 1766666053.3529882, "phase": "train", "update": 678, "total_env_steps": 2169600, "episode_reward": 0.31032782793045044, "value_loss": 0.0103402949248751, "policy_loss": -0.013218573833803286, "dist_entropy": 0.6341957012812297, "actor_grad_norm": 0.16326022148132324, "critic_grad_norm": 0.06609943509101868, "ratio": 0.9982241988182068, "entropy": 0.6341957012812297, "incre_win_rate": 0.8076923076923077, "step": 678}
{"time": 1766666057.6421595, "phase": "train", "update": 679, "total_env_steps": 2172800, "episode_reward": 0.2975176274776459, "value_loss": 0.013495760348935923, "policy_loss": -0.012948498867801087, "dist_entropy": 0.6259965737660725, "actor_grad_norm": 0.1633850634098053, "critic_grad_norm": 0.03159143403172493, "ratio": 1.0000866651535034, "entropy": 0.6259965737660725, "incre_win_rate": 0.7647058823529411, "step": 679}
{"time": 1766666061.9457383, "phase": "train", "update": 680, "total_env_steps": 2176000, "episode_reward": 0.30608993768692017, "value_loss": 0.010946606720487277, "policy_loss": -0.013032983802152388, "dist_entropy": 0.6252161264419556, "actor_grad_norm": 0.15766826272010803, "critic_grad_norm": 0.018721360713243484, "ratio": 1.0004523992538452, "entropy": 0.6252161264419556, "incre_win_rate": 0.7924528301886793, "step": 680}
{"time": 1766666066.1913044, "phase": "train", "update": 681, "total_env_steps": 2179200, "episode_reward": 0.3014315366744995, "value_loss": 0.013676973742743332, "policy_loss": -0.01383486353133776, "dist_entropy": 0.6198164860407511, "actor_grad_norm": 0.13919363915920258, "critic_grad_norm": 0.052282754331827164, "ratio": 1.000198483467102, "entropy": 0.6198164860407511, "incre_win_rate": 0.7450980392156863, "step": 681}
{"time": 1766666074.5105429, "phase": "eval", "update": 681, "total_env_steps": 2179200, "eval_win_rate": 0.875, "eval_episode_reward": 19.256050857843135, "step": 681}
{"time": 1766666079.0917277, "phase": "train", "update": 682, "total_env_steps": 2182400, "episode_reward": 0.31377607583999634, "value_loss": 0.009945908623437087, "policy_loss": -0.012860815782913922, "dist_entropy": 0.6199004888534546, "actor_grad_norm": 0.15201573073863983, "critic_grad_norm": 0.034846141934394836, "ratio": 0.99970543384552, "entropy": 0.6199004888534546, "incre_win_rate": 0.8113207547169812, "step": 682}
{"time": 1766666083.5439272, "phase": "train", "update": 683, "total_env_steps": 2185600, "episode_reward": 0.3089292347431183, "value_loss": 0.012179618328809738, "policy_loss": -0.013129934683179082, "dist_entropy": 0.6277557293574015, "actor_grad_norm": 0.14943721890449524, "critic_grad_norm": 0.027454808354377747, "ratio": 0.9991430044174194, "entropy": 0.6277557293574015, "incre_win_rate": 0.7962962962962963, "step": 683}
{"time": 1766666088.2332344, "phase": "train", "update": 684, "total_env_steps": 2188800, "episode_reward": 0.2931724786758423, "value_loss": 0.013955553931494554, "policy_loss": -0.012632640018095269, "dist_entropy": 0.6187610983848572, "actor_grad_norm": 0.13468404114246368, "critic_grad_norm": 0.01538184192031622, "ratio": 0.9976525902748108, "entropy": 0.6187610983848572, "incre_win_rate": 0.6538461538461539, "step": 684}
{"time": 1766666092.8276093, "phase": "train", "update": 685, "total_env_steps": 2192000, "episode_reward": 0.30641698837280273, "value_loss": 0.009723427519202233, "policy_loss": -0.013191624681828528, "dist_entropy": 0.6470639189084371, "actor_grad_norm": 0.14227817952632904, "critic_grad_norm": 0.033293548971414566, "ratio": 1.0003818273544312, "entropy": 0.6470639189084371, "incre_win_rate": 0.8269230769230769, "step": 685}
{"time": 1766666097.2780616, "phase": "train", "update": 686, "total_env_steps": 2195200, "episode_reward": 0.31297793984413147, "value_loss": 0.011412214984496434, "policy_loss": -0.013217693642574583, "dist_entropy": 0.6225044409434001, "actor_grad_norm": 0.15180425345897675, "critic_grad_norm": 0.02862212248146534, "ratio": 1.000680685043335, "entropy": 0.6225044409434001, "incre_win_rate": 0.7735849056603774, "step": 686}
{"time": 1766666101.6931293, "phase": "train", "update": 687, "total_env_steps": 2198400, "episode_reward": 0.30257201194763184, "value_loss": 0.012135755953689415, "policy_loss": -0.01365313124153289, "dist_entropy": 0.6236505111058553, "actor_grad_norm": 0.15582039952278137, "critic_grad_norm": 0.027288002893328667, "ratio": 0.9986492395401001, "entropy": 0.6236505111058553, "incre_win_rate": 0.7924528301886793, "step": 687}
{"time": 1766666106.069783, "phase": "train", "update": 688, "total_env_steps": 2201600, "episode_reward": 0.3021155297756195, "value_loss": 0.011456966896851857, "policy_loss": -0.014817859063894368, "dist_entropy": 0.6067121624946594, "actor_grad_norm": 0.16098670661449432, "critic_grad_norm": 0.01730448752641678, "ratio": 0.9994394183158875, "entropy": 0.6067121624946594, "incre_win_rate": 0.75, "step": 688}
{"time": 1766666110.5472608, "phase": "train", "update": 689, "total_env_steps": 2204800, "episode_reward": 0.2926149070262909, "value_loss": 0.011074842947224776, "policy_loss": -0.014566443906367492, "dist_entropy": 0.5982038140296936, "actor_grad_norm": 0.15921060740947723, "critic_grad_norm": 0.03393331915140152, "ratio": 0.9984005093574524, "entropy": 0.5982038140296936, "incre_win_rate": 0.74, "step": 689}
{"time": 1766666115.3054807, "phase": "train", "update": 690, "total_env_steps": 2208000, "episode_reward": 0.304903507232666, "value_loss": 0.009609385455648104, "policy_loss": -0.014041349332891665, "dist_entropy": 0.6153329610824585, "actor_grad_norm": 0.1942158043384552, "critic_grad_norm": 0.019882557913661003, "ratio": 0.9992610812187195, "entropy": 0.6153329610824585, "incre_win_rate": 0.7037037037037037, "step": 690}
{"time": 1766666119.9035077, "phase": "train", "update": 691, "total_env_steps": 2211200, "episode_reward": 0.2972487807273865, "value_loss": 0.011961024999618531, "policy_loss": -0.013604599025512224, "dist_entropy": 0.6085516611735026, "actor_grad_norm": 0.1669662445783615, "critic_grad_norm": 0.030734781175851822, "ratio": 0.9993110299110413, "entropy": 0.6085516611735026, "incre_win_rate": 0.68, "step": 691}
{"time": 1766666124.311498, "phase": "train", "update": 692, "total_env_steps": 2214400, "episode_reward": 0.30879899859428406, "value_loss": 0.0092252471173803, "policy_loss": -0.013912421464093445, "dist_entropy": 0.6068803707758585, "actor_grad_norm": 0.16398769617080688, "critic_grad_norm": 0.034622110426425934, "ratio": 0.998177707195282, "entropy": 0.6068803707758585, "incre_win_rate": 0.8, "step": 692}
{"time": 1766666128.6129434, "phase": "train", "update": 693, "total_env_steps": 2217600, "episode_reward": 0.30502986907958984, "value_loss": 0.012214921787381173, "policy_loss": -0.013318367603275049, "dist_entropy": 0.6071812987327576, "actor_grad_norm": 0.16838888823986053, "critic_grad_norm": 0.030340127646923065, "ratio": 0.9992150664329529, "entropy": 0.6071812987327576, "incre_win_rate": 0.8, "step": 693}
{"time": 1766666132.999699, "phase": "train", "update": 694, "total_env_steps": 2220800, "episode_reward": 0.302121639251709, "value_loss": 0.009271053907771906, "policy_loss": -0.013228121287377803, "dist_entropy": 0.6248064597447713, "actor_grad_norm": 0.16960540413856506, "critic_grad_norm": 0.03618614748120308, "ratio": 0.9988905191421509, "entropy": 0.6248064597447713, "incre_win_rate": 0.7547169811320755, "step": 694}
{"time": 1766666137.291491, "phase": "train", "update": 695, "total_env_steps": 2224000, "episode_reward": 0.3176371157169342, "value_loss": 0.007562643041213354, "policy_loss": -0.013562270240778199, "dist_entropy": 0.6174057483673095, "actor_grad_norm": 0.14545544981956482, "critic_grad_norm": 0.030459696426987648, "ratio": 0.9988815784454346, "entropy": 0.6174057483673095, "incre_win_rate": 0.9230769230769231, "step": 695}
{"time": 1766666141.6124907, "phase": "train", "update": 696, "total_env_steps": 2227200, "episode_reward": 0.29043737053871155, "value_loss": 0.010116652647654215, "policy_loss": -0.013671643711428061, "dist_entropy": 0.6038355072339375, "actor_grad_norm": 0.2040129005908966, "critic_grad_norm": 0.07296831905841827, "ratio": 0.9987564086914062, "entropy": 0.6038355072339375, "incre_win_rate": 0.6666666666666666, "step": 696}
{"time": 1766666145.912224, "phase": "train", "update": 697, "total_env_steps": 2230400, "episode_reward": 0.30689722299575806, "value_loss": 0.01025350031753381, "policy_loss": -0.012586398153199951, "dist_entropy": 0.6015388051668803, "actor_grad_norm": 0.1712190806865692, "critic_grad_norm": 0.033122263848781586, "ratio": 0.9986203908920288, "entropy": 0.6015388051668803, "incre_win_rate": 0.75, "step": 697}
{"time": 1766666150.160636, "phase": "train", "update": 698, "total_env_steps": 2233600, "episode_reward": 0.30470356345176697, "value_loss": 0.008176325882474581, "policy_loss": -0.013968879486914521, "dist_entropy": 0.5979905128479004, "actor_grad_norm": 0.20664259791374207, "critic_grad_norm": 0.04685233533382416, "ratio": 0.9980998635292053, "entropy": 0.5979905128479004, "incre_win_rate": 0.8, "step": 698}
{"time": 1766666154.4745088, "phase": "train", "update": 699, "total_env_steps": 2236800, "episode_reward": 0.3094653785228729, "value_loss": 0.009533263618747394, "policy_loss": -0.011867593008752427, "dist_entropy": 0.6027711629867554, "actor_grad_norm": 0.16780908405780792, "critic_grad_norm": 0.02415476180613041, "ratio": 1.0002731084823608, "entropy": 0.6027711629867554, "incre_win_rate": 0.7454545454545455, "step": 699}
{"time": 1766666158.7509203, "phase": "train", "update": 700, "total_env_steps": 2240000, "episode_reward": 0.3115862309932709, "value_loss": 0.010084462848802407, "policy_loss": -0.014529400261858724, "dist_entropy": 0.6104449073473612, "actor_grad_norm": 0.1537475287914276, "critic_grad_norm": 0.018478848040103912, "ratio": 0.998078465461731, "entropy": 0.6104449073473612, "incre_win_rate": 0.7924528301886793, "step": 700}
{"time": 1766666163.0550232, "phase": "train", "update": 701, "total_env_steps": 2243200, "episode_reward": 0.3142532408237457, "value_loss": 0.011815423270066579, "policy_loss": -0.012199571476323948, "dist_entropy": 0.5967223922411601, "actor_grad_norm": 0.1739881932735443, "critic_grad_norm": 0.012951905839145184, "ratio": 0.9989529252052307, "entropy": 0.5967223922411601, "incre_win_rate": 0.7592592592592593, "step": 701}
{"time": 1766666171.0003695, "phase": "eval", "update": 701, "total_env_steps": 2243200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.498544730392158, "step": 701}
{"time": 1766666175.5668879, "phase": "train", "update": 702, "total_env_steps": 2246400, "episode_reward": 0.33188343048095703, "value_loss": 0.006731350844105085, "policy_loss": -0.01315240632219267, "dist_entropy": 0.6126487890879313, "actor_grad_norm": 0.17123492062091827, "critic_grad_norm": 0.03997301310300827, "ratio": 0.9994691610336304, "entropy": 0.6126487890879313, "incre_win_rate": 0.9074074074074074, "step": 702}
{"time": 1766666180.0565143, "phase": "train", "update": 703, "total_env_steps": 2249600, "episode_reward": 0.3175390660762787, "value_loss": 0.007553911178062359, "policy_loss": -0.012453601433055066, "dist_entropy": 0.6111492395401001, "actor_grad_norm": 0.17303431034088135, "critic_grad_norm": 0.023077834397554398, "ratio": 1.0001561641693115, "entropy": 0.6111492395401001, "incre_win_rate": 0.8703703703703703, "step": 703}
{"time": 1766666184.4514084, "phase": "train", "update": 704, "total_env_steps": 2252800, "episode_reward": 0.3251608610153198, "value_loss": 0.00989643254627784, "policy_loss": -0.012461081460880763, "dist_entropy": 0.5949553688367207, "actor_grad_norm": 0.20955759286880493, "critic_grad_norm": 0.01912720687687397, "ratio": 0.9983182549476624, "entropy": 0.5949553688367207, "incre_win_rate": 0.8518518518518519, "step": 704}
{"time": 1766666188.8675117, "phase": "train", "update": 705, "total_env_steps": 2256000, "episode_reward": 0.3222510814666748, "value_loss": 0.009187546434501807, "policy_loss": -0.012314697904582773, "dist_entropy": 0.5898328622182211, "actor_grad_norm": 0.16149424016475677, "critic_grad_norm": 0.015835817903280258, "ratio": 1.0002143383026123, "entropy": 0.5898328622182211, "incre_win_rate": 0.7857142857142857, "step": 705}
{"time": 1766666193.3446712, "phase": "train", "update": 706, "total_env_steps": 2259200, "episode_reward": 0.31748393177986145, "value_loss": 0.008990925053755443, "policy_loss": -0.013472975289777386, "dist_entropy": 0.6120378295580546, "actor_grad_norm": 0.1443336308002472, "critic_grad_norm": 0.019702976569533348, "ratio": 1.000580072402954, "entropy": 0.6120378295580546, "incre_win_rate": 0.7884615384615384, "step": 706}
{"time": 1766666197.756454, "phase": "train", "update": 707, "total_env_steps": 2262400, "episode_reward": 0.31394150853157043, "value_loss": 0.010933493574460348, "policy_loss": -0.012688313156344578, "dist_entropy": 0.6153002341588338, "actor_grad_norm": 0.1433439403772354, "critic_grad_norm": 0.014326638542115688, "ratio": 0.999184250831604, "entropy": 0.6153002341588338, "incre_win_rate": 0.8490566037735849, "step": 707}
{"time": 1766666202.321714, "phase": "train", "update": 708, "total_env_steps": 2265600, "episode_reward": 0.34038832783699036, "value_loss": 0.0058658404586215815, "policy_loss": -0.0121916786519319, "dist_entropy": 0.595088263352712, "actor_grad_norm": 0.1480679214000702, "critic_grad_norm": 0.022966966032981873, "ratio": 0.9988387823104858, "entropy": 0.595088263352712, "incre_win_rate": 0.8793103448275862, "step": 708}
{"time": 1766666206.808769, "phase": "train", "update": 709, "total_env_steps": 2268800, "episode_reward": 0.31918734312057495, "value_loss": 0.010172019898891448, "policy_loss": -0.012599083978162657, "dist_entropy": 0.5956712245941163, "actor_grad_norm": 0.1348705142736435, "critic_grad_norm": 0.040260836482048035, "ratio": 0.9995130896568298, "entropy": 0.5956712245941163, "incre_win_rate": 0.8113207547169812, "step": 709}
{"time": 1766666211.41492, "phase": "train", "update": 710, "total_env_steps": 2272000, "episode_reward": 0.33157476782798767, "value_loss": 0.007759277864048879, "policy_loss": -0.01200658981496332, "dist_entropy": 0.5937405983606975, "actor_grad_norm": 0.1390518993139267, "critic_grad_norm": 0.020433606579899788, "ratio": 0.9998502731323242, "entropy": 0.5937405983606975, "incre_win_rate": 0.8703703703703703, "step": 710}
{"time": 1766666216.006507, "phase": "train", "update": 711, "total_env_steps": 2275200, "episode_reward": 0.3284183442592621, "value_loss": 0.010189263646801313, "policy_loss": -0.012221321406995618, "dist_entropy": 0.5857584675153097, "actor_grad_norm": 0.15431731939315796, "critic_grad_norm": 0.013603931292891502, "ratio": 1.0012357234954834, "entropy": 0.5857584675153097, "incre_win_rate": 0.8245614035087719, "step": 711}
{"time": 1766666220.4869857, "phase": "train", "update": 712, "total_env_steps": 2278400, "episode_reward": 0.31438571214675903, "value_loss": 0.009998536358277002, "policy_loss": -0.012365333603915474, "dist_entropy": 0.5724857608477275, "actor_grad_norm": 0.15566286444664001, "critic_grad_norm": 0.03019612841308117, "ratio": 0.9997799396514893, "entropy": 0.5724857608477275, "incre_win_rate": 0.8301886792452831, "step": 712}
{"time": 1766666225.0258565, "phase": "train", "update": 713, "total_env_steps": 2281600, "episode_reward": 0.3256426453590393, "value_loss": 0.009328849179049333, "policy_loss": -0.012333486466180755, "dist_entropy": 0.5969573775927226, "actor_grad_norm": 0.16804401576519012, "critic_grad_norm": 0.020527023822069168, "ratio": 0.9992978572845459, "entropy": 0.5969573775927226, "incre_win_rate": 0.8518518518518519, "step": 713}
{"time": 1766666229.5015905, "phase": "train", "update": 714, "total_env_steps": 2284800, "episode_reward": 0.32441025972366333, "value_loss": 0.009206064728399117, "policy_loss": -0.011938473495276014, "dist_entropy": 0.6005673170089721, "actor_grad_norm": 0.14131608605384827, "critic_grad_norm": 0.027406763285398483, "ratio": 0.9988164901733398, "entropy": 0.6005673170089721, "incre_win_rate": 0.8363636363636363, "step": 714}
{"time": 1766666234.122203, "phase": "train", "update": 715, "total_env_steps": 2288000, "episode_reward": 0.3010309338569641, "value_loss": 0.010114418404797713, "policy_loss": -0.012269573451565445, "dist_entropy": 0.596943978468577, "actor_grad_norm": 0.17366115748882294, "critic_grad_norm": 0.02380038984119892, "ratio": 1.0004937648773193, "entropy": 0.596943978468577, "incre_win_rate": 0.7450980392156863, "step": 715}
{"time": 1766666238.5681791, "phase": "train", "update": 716, "total_env_steps": 2291200, "episode_reward": 0.3151355981826782, "value_loss": 0.009279281956454118, "policy_loss": -0.011796209236523698, "dist_entropy": 0.5874820907910665, "actor_grad_norm": 0.1700948029756546, "critic_grad_norm": 0.016354642808437347, "ratio": 0.9996697902679443, "entropy": 0.5874820907910665, "incre_win_rate": 0.8269230769230769, "step": 716}
{"time": 1766666243.1639001, "phase": "train", "update": 717, "total_env_steps": 2294400, "episode_reward": 0.3076118230819702, "value_loss": 0.011275343596935272, "policy_loss": -0.013365001484376516, "dist_entropy": 0.607437523206075, "actor_grad_norm": 0.15245138108730316, "critic_grad_norm": 0.07519441097974777, "ratio": 1.0006482601165771, "entropy": 0.607437523206075, "incre_win_rate": 0.6666666666666666, "step": 717}
{"time": 1766666247.7357934, "phase": "train", "update": 718, "total_env_steps": 2297600, "episode_reward": 0.31684282422065735, "value_loss": 0.01184425720324119, "policy_loss": -0.012087950373476512, "dist_entropy": 0.5921778559684754, "actor_grad_norm": 0.13309480249881744, "critic_grad_norm": 0.024091096594929695, "ratio": 1.0001381635665894, "entropy": 0.5921778559684754, "incre_win_rate": 0.7543859649122807, "step": 718}
{"time": 1766666252.307866, "phase": "train", "update": 719, "total_env_steps": 2300800, "episode_reward": 0.31074678897857666, "value_loss": 0.00859682507192095, "policy_loss": -0.011670309800794598, "dist_entropy": 0.5672012646993001, "actor_grad_norm": 0.14656370878219604, "critic_grad_norm": 0.042070090770721436, "ratio": 0.9988494515419006, "entropy": 0.5672012646993001, "incre_win_rate": 0.7924528301886793, "step": 719}
{"time": 1766666256.7900124, "phase": "train", "update": 720, "total_env_steps": 2304000, "episode_reward": 0.33680760860443115, "value_loss": 0.007067149722327789, "policy_loss": -0.011876161217684474, "dist_entropy": 0.5654956062634786, "actor_grad_norm": 0.15671072900295258, "critic_grad_norm": 0.04044688865542412, "ratio": 0.9982495903968811, "entropy": 0.5654956062634786, "incre_win_rate": 0.8727272727272727, "step": 720}
{"time": 1766666261.4432588, "phase": "train", "update": 721, "total_env_steps": 2307200, "episode_reward": 0.3233593702316284, "value_loss": 0.010865132696926594, "policy_loss": -0.012110694069495054, "dist_entropy": 0.5668119510014852, "actor_grad_norm": 0.18547196686267853, "critic_grad_norm": 0.03440939635038376, "ratio": 0.9985073804855347, "entropy": 0.5668119510014852, "incre_win_rate": 0.7592592592592593, "step": 721}
{"time": 1766666269.5909762, "phase": "eval", "update": 721, "total_env_steps": 2307200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.70626531862745, "step": 721}
{"time": 1766666274.160189, "phase": "train", "update": 722, "total_env_steps": 2310400, "episode_reward": 0.33166590332984924, "value_loss": 0.0068647417550285654, "policy_loss": -0.01223574121205644, "dist_entropy": 0.5858208775520325, "actor_grad_norm": 0.22872641682624817, "critic_grad_norm": 0.041509971022605896, "ratio": 0.9991092681884766, "entropy": 0.5858208775520325, "incre_win_rate": 0.8214285714285714, "step": 722}
{"time": 1766666278.637872, "phase": "train", "update": 723, "total_env_steps": 2313600, "episode_reward": 0.33115270733833313, "value_loss": 0.011081760004162788, "policy_loss": -0.012655416856264997, "dist_entropy": 0.575500508149465, "actor_grad_norm": 0.1701248586177826, "critic_grad_norm": 0.026590894907712936, "ratio": 0.9987471103668213, "entropy": 0.575500508149465, "incre_win_rate": 0.8545454545454545, "step": 723}
{"time": 1766666283.260565, "phase": "train", "update": 724, "total_env_steps": 2316800, "episode_reward": 0.3310508728027344, "value_loss": 0.009787275207539399, "policy_loss": -0.011617123907557906, "dist_entropy": 0.5800947268803914, "actor_grad_norm": 0.15313223004341125, "critic_grad_norm": 0.02029235288500786, "ratio": 0.9998310804367065, "entropy": 0.5800947268803914, "incre_win_rate": 0.8245614035087719, "step": 724}
{"time": 1766666287.8670318, "phase": "train", "update": 725, "total_env_steps": 2320000, "episode_reward": 0.3205997347831726, "value_loss": 0.009213358660538991, "policy_loss": -0.012744440286313363, "dist_entropy": 0.582210652033488, "actor_grad_norm": 0.13786156475543976, "critic_grad_norm": 0.017750753089785576, "ratio": 0.9989579319953918, "entropy": 0.582210652033488, "incre_win_rate": 0.8461538461538461, "step": 725}
{"time": 1766666292.4032743, "phase": "train", "update": 726, "total_env_steps": 2323200, "episode_reward": 0.32330426573753357, "value_loss": 0.008893737072745959, "policy_loss": -0.012615259263049457, "dist_entropy": 0.5784427205721537, "actor_grad_norm": 0.14294379949569702, "critic_grad_norm": 0.016351474449038506, "ratio": 1.0014342069625854, "entropy": 0.5784427205721537, "incre_win_rate": 0.8, "step": 726}
{"time": 1766666297.002238, "phase": "train", "update": 727, "total_env_steps": 2326400, "episode_reward": 0.33048102259635925, "value_loss": 0.006768123153597117, "policy_loss": -0.011794280885025899, "dist_entropy": 0.5859094937642415, "actor_grad_norm": 0.15368439257144928, "critic_grad_norm": 0.045062676072120667, "ratio": 0.9990370869636536, "entropy": 0.5859094937642415, "incre_win_rate": 0.9107142857142857, "step": 727}
{"time": 1766666301.6089654, "phase": "train", "update": 728, "total_env_steps": 2329600, "episode_reward": 0.3193359375, "value_loss": 0.011691576180358728, "policy_loss": -0.012385547213758367, "dist_entropy": 0.5687581737836201, "actor_grad_norm": 0.19310131669044495, "critic_grad_norm": 0.05691011995077133, "ratio": 1.0006722211837769, "entropy": 0.5687581737836201, "incre_win_rate": 0.7407407407407407, "step": 728}
{"time": 1766666306.1545827, "phase": "train", "update": 729, "total_env_steps": 2332800, "episode_reward": 0.3078163266181946, "value_loss": 0.010520982121427854, "policy_loss": -0.012110700394293872, "dist_entropy": 0.5816822250684103, "actor_grad_norm": 0.18086758255958557, "critic_grad_norm": 0.029761865735054016, "ratio": 1.0016573667526245, "entropy": 0.5816822250684103, "incre_win_rate": 0.7547169811320755, "step": 729}
{"time": 1766666310.6594176, "phase": "train", "update": 730, "total_env_steps": 2336000, "episode_reward": 0.2968596816062927, "value_loss": 0.014670896095534165, "policy_loss": -0.012577956093625886, "dist_entropy": 0.5698246916135152, "actor_grad_norm": 0.15047341585159302, "critic_grad_norm": 0.06759095191955566, "ratio": 1.0002450942993164, "entropy": 0.5698246916135152, "incre_win_rate": 0.6363636363636364, "step": 730}
{"time": 1766666315.210985, "phase": "train", "update": 731, "total_env_steps": 2339200, "episode_reward": 0.3179871439933777, "value_loss": 0.010570979677140713, "policy_loss": -0.011672357471571597, "dist_entropy": 0.5878840684890747, "actor_grad_norm": 0.14426317811012268, "critic_grad_norm": 0.0723176896572113, "ratio": 1.0012214183807373, "entropy": 0.5878840684890747, "incre_win_rate": 0.8076923076923077, "step": 731}
{"time": 1766666319.7822165, "phase": "train", "update": 732, "total_env_steps": 2342400, "episode_reward": 0.32101866602897644, "value_loss": 0.010937725690503915, "policy_loss": -0.012971080965766647, "dist_entropy": 0.5833488742510478, "actor_grad_norm": 0.15633787214756012, "critic_grad_norm": 0.031096259132027626, "ratio": 1.0005310773849487, "entropy": 0.5833488742510478, "incre_win_rate": 0.7962962962962963, "step": 732}
{"time": 1766666324.4405673, "phase": "train", "update": 733, "total_env_steps": 2345600, "episode_reward": 0.32458871603012085, "value_loss": 0.011356277391314507, "policy_loss": -0.013195371473163202, "dist_entropy": 0.5833451430002848, "actor_grad_norm": 0.14469534158706665, "critic_grad_norm": 0.030015580356121063, "ratio": 0.999297559261322, "entropy": 0.5833451430002848, "incre_win_rate": 0.7818181818181819, "step": 733}
{"time": 1766666328.9527612, "phase": "train", "update": 734, "total_env_steps": 2348800, "episode_reward": 0.3205438256263733, "value_loss": 0.014473513886332511, "policy_loss": -0.01245967302604356, "dist_entropy": 0.5741865515708924, "actor_grad_norm": 0.16247877478599548, "critic_grad_norm": 0.056497395038604736, "ratio": 0.9994246959686279, "entropy": 0.5741865515708924, "incre_win_rate": 0.7543859649122807, "step": 734}
{"time": 1766666333.5726454, "phase": "train", "update": 735, "total_env_steps": 2352000, "episode_reward": 0.3216414153575897, "value_loss": 0.011232067768772443, "policy_loss": -0.012215980384101854, "dist_entropy": 0.567512857913971, "actor_grad_norm": 0.15711577236652374, "critic_grad_norm": 0.0178049486130476, "ratio": 0.9991412162780762, "entropy": 0.567512857913971, "incre_win_rate": 0.7857142857142857, "step": 735}
{"time": 1766666338.1988885, "phase": "train", "update": 736, "total_env_steps": 2355200, "episode_reward": 0.329469233751297, "value_loss": 0.01202458490928014, "policy_loss": -0.012746318734199728, "dist_entropy": 0.5667820572853088, "actor_grad_norm": 0.16265974938869476, "critic_grad_norm": 0.016788501292467117, "ratio": 1.001103401184082, "entropy": 0.5667820572853088, "incre_win_rate": 0.7857142857142857, "step": 736}
{"time": 1766666342.6587048, "phase": "train", "update": 737, "total_env_steps": 2358400, "episode_reward": 0.31228014826774597, "value_loss": 0.013252817901472251, "policy_loss": -0.013012900536720743, "dist_entropy": 0.5739549358685812, "actor_grad_norm": 0.1406916379928589, "critic_grad_norm": 0.027933550998568535, "ratio": 0.9995840191841125, "entropy": 0.5739549358685812, "incre_win_rate": 0.6981132075471698, "step": 737}
{"time": 1766666347.0984426, "phase": "train", "update": 738, "total_env_steps": 2361600, "episode_reward": 0.3190471827983856, "value_loss": 0.015146979441245398, "policy_loss": -0.011870133337294912, "dist_entropy": 0.5676327188809712, "actor_grad_norm": 0.1308560073375702, "critic_grad_norm": 0.03733351081609726, "ratio": 0.9994144439697266, "entropy": 0.5676327188809712, "incre_win_rate": 0.6607142857142857, "step": 738}
{"time": 1766666351.8541603, "phase": "train", "update": 739, "total_env_steps": 2364800, "episode_reward": 0.31599417328834534, "value_loss": 0.011904903935889404, "policy_loss": -0.013808650112167224, "dist_entropy": 0.5921358823776245, "actor_grad_norm": 0.16397272050380707, "critic_grad_norm": 0.03347128629684448, "ratio": 0.9985194206237793, "entropy": 0.5921358823776245, "incre_win_rate": 0.7818181818181819, "step": 739}
{"time": 1766666356.7818234, "phase": "train", "update": 740, "total_env_steps": 2368000, "episode_reward": 0.3321583867073059, "value_loss": 0.00903747770935297, "policy_loss": -0.012363977706457755, "dist_entropy": 0.5922621568044026, "actor_grad_norm": 0.15388326346874237, "critic_grad_norm": 0.07095438241958618, "ratio": 1.0002533197402954, "entropy": 0.5922621568044026, "incre_win_rate": 0.8363636363636363, "step": 740}
{"time": 1766666361.4161673, "phase": "train", "update": 741, "total_env_steps": 2371200, "episode_reward": 0.3192983865737915, "value_loss": 0.011637223636110623, "policy_loss": -0.012563928230027758, "dist_entropy": 0.6004939158757527, "actor_grad_norm": 0.15298907458782196, "critic_grad_norm": 0.0304104071110487, "ratio": 0.9990982413291931, "entropy": 0.6004939158757527, "incre_win_rate": 0.8, "step": 741}
{"time": 1766666369.6779835, "phase": "eval", "update": 741, "total_env_steps": 2371200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.49938725490196, "step": 741}
{"time": 1766666374.1399004, "phase": "train", "update": 742, "total_env_steps": 2374400, "episode_reward": 0.30431294441223145, "value_loss": 0.010596039767066637, "policy_loss": -0.013849752988558232, "dist_entropy": 0.5909957488377889, "actor_grad_norm": 0.17536745965480804, "critic_grad_norm": 0.013863876461982727, "ratio": 0.9986047148704529, "entropy": 0.5909957488377889, "incre_win_rate": 0.7450980392156863, "step": 742}
{"time": 1766666378.5341563, "phase": "train", "update": 743, "total_env_steps": 2377600, "episode_reward": 0.31588849425315857, "value_loss": 0.008663272112607956, "policy_loss": -0.014028267329641627, "dist_entropy": 0.5851948539415995, "actor_grad_norm": 0.16964009404182434, "critic_grad_norm": 0.02360581047832966, "ratio": 1.0008915662765503, "entropy": 0.5851948539415995, "incre_win_rate": 0.8333333333333334, "step": 743}
{"time": 1766666382.9166365, "phase": "train", "update": 744, "total_env_steps": 2380800, "episode_reward": 0.30802544951438904, "value_loss": 0.015028312678138415, "policy_loss": -0.013893415910938718, "dist_entropy": 0.5812799334526062, "actor_grad_norm": 0.17999255657196045, "critic_grad_norm": 0.07924965023994446, "ratio": 1.0014039278030396, "entropy": 0.5812799334526062, "incre_win_rate": 0.6981132075471698, "step": 744}
{"time": 1766666387.303928, "phase": "train", "update": 745, "total_env_steps": 2384000, "episode_reward": 0.3027780055999756, "value_loss": 0.01131727813432614, "policy_loss": -0.01361778815858076, "dist_entropy": 0.6000363906224568, "actor_grad_norm": 0.1810929924249649, "critic_grad_norm": 0.04168039932847023, "ratio": 1.000185489654541, "entropy": 0.6000363906224568, "incre_win_rate": 0.8431372549019608, "step": 745}
{"time": 1766666391.6172225, "phase": "train", "update": 746, "total_env_steps": 2387200, "episode_reward": 0.3015923798084259, "value_loss": 0.012299264470736185, "policy_loss": -0.014282102202054859, "dist_entropy": 0.5871420462926229, "actor_grad_norm": 0.16381724178791046, "critic_grad_norm": 0.02517854794859886, "ratio": 0.9985182285308838, "entropy": 0.5871420462926229, "incre_win_rate": 0.7547169811320755, "step": 746}
{"time": 1766666396.0537553, "phase": "train", "update": 747, "total_env_steps": 2390400, "episode_reward": 0.3037676215171814, "value_loss": 0.010558885646363099, "policy_loss": -0.01428557778163313, "dist_entropy": 0.5977284987767537, "actor_grad_norm": 0.15396307408809662, "critic_grad_norm": 0.02250276692211628, "ratio": 0.999036967754364, "entropy": 0.5977284987767537, "incre_win_rate": 0.7647058823529411, "step": 747}
{"time": 1766666400.3874822, "phase": "train", "update": 748, "total_env_steps": 2393600, "episode_reward": 0.314264714717865, "value_loss": 0.013201152471204599, "policy_loss": -0.013201993013571212, "dist_entropy": 0.5895426750183106, "actor_grad_norm": 0.181147962808609, "critic_grad_norm": 0.06786346435546875, "ratio": 0.9988734722137451, "entropy": 0.5895426750183106, "incre_win_rate": 0.6964285714285714, "step": 748}
{"time": 1766666404.7629879, "phase": "train", "update": 749, "total_env_steps": 2396800, "episode_reward": 0.30848807096481323, "value_loss": 0.015004607786734899, "policy_loss": -0.013372222433580145, "dist_entropy": 0.5894703984260559, "actor_grad_norm": 0.16639085114002228, "critic_grad_norm": 0.02493343874812126, "ratio": 1.0005605220794678, "entropy": 0.5894703984260559, "incre_win_rate": 0.7115384615384616, "step": 749}
{"time": 1766666409.140151, "phase": "train", "update": 750, "total_env_steps": 2400000, "episode_reward": 0.2903692126274109, "value_loss": 0.01670279030998548, "policy_loss": -0.012594612673149541, "dist_entropy": 0.60204017162323, "actor_grad_norm": 0.18523791432380676, "critic_grad_norm": 0.06195349618792534, "ratio": 1.0007493495941162, "entropy": 0.60204017162323, "incre_win_rate": 0.6545454545454545, "step": 750}
{"time": 1766666413.4767678, "phase": "train", "update": 751, "total_env_steps": 2403200, "episode_reward": 0.3190150260925293, "value_loss": 0.010150084768732389, "policy_loss": -0.012971807192554745, "dist_entropy": 0.5885432600975037, "actor_grad_norm": 0.16821599006652832, "critic_grad_norm": 0.09012797474861145, "ratio": 0.998737633228302, "entropy": 0.5885432600975037, "incre_win_rate": 0.8679245283018868, "step": 751}
{"time": 1766666417.8502953, "phase": "train", "update": 752, "total_env_steps": 2406400, "episode_reward": 0.2967202663421631, "value_loss": 0.009993173616627852, "policy_loss": -0.013740432182580283, "dist_entropy": 0.605318299929301, "actor_grad_norm": 0.1540592908859253, "critic_grad_norm": 0.05227336660027504, "ratio": 0.9996187090873718, "entropy": 0.605318299929301, "incre_win_rate": 0.8085106382978723, "step": 752}
{"time": 1766666422.2268322, "phase": "train", "update": 753, "total_env_steps": 2409600, "episode_reward": 0.31144073605537415, "value_loss": 0.008959037065505982, "policy_loss": -0.01345171029290313, "dist_entropy": 0.5814645409584045, "actor_grad_norm": 0.16673384606838226, "critic_grad_norm": 0.025456923991441727, "ratio": 0.9998153448104858, "entropy": 0.5814645409584045, "incre_win_rate": 0.8333333333333334, "step": 753}
{"time": 1766666426.6259718, "phase": "train", "update": 754, "total_env_steps": 2412800, "episode_reward": 0.28892770409584045, "value_loss": 0.011648623272776604, "policy_loss": -0.014833903747209831, "dist_entropy": 0.5890645305315654, "actor_grad_norm": 0.1567014753818512, "critic_grad_norm": 0.06126316636800766, "ratio": 0.9996612668037415, "entropy": 0.5890645305315654, "incre_win_rate": 0.72, "step": 754}
{"time": 1766666430.9444587, "phase": "train", "update": 755, "total_env_steps": 2416000, "episode_reward": 0.31307750940322876, "value_loss": 0.007839251247545084, "policy_loss": -0.01378863174725969, "dist_entropy": 0.5978398482004802, "actor_grad_norm": 0.13710430264472961, "critic_grad_norm": 0.03346472606062889, "ratio": 0.9984138607978821, "entropy": 0.5978398482004802, "incre_win_rate": 0.8627450980392157, "step": 755}
{"time": 1766666435.3456178, "phase": "train", "update": 756, "total_env_steps": 2419200, "episode_reward": 0.32253140211105347, "value_loss": 0.006491285252074401, "policy_loss": -0.013554980078631236, "dist_entropy": 0.5971560915311177, "actor_grad_norm": 0.14215517044067383, "critic_grad_norm": 0.03429167717695236, "ratio": 0.9994292259216309, "entropy": 0.5971560915311177, "incre_win_rate": 0.9038461538461539, "step": 756}
{"time": 1766666439.7230775, "phase": "train", "update": 757, "total_env_steps": 2422400, "episode_reward": 0.3157077133655548, "value_loss": 0.009488695363203684, "policy_loss": -0.013150002422693773, "dist_entropy": 0.5911692102750142, "actor_grad_norm": 0.15397508442401886, "critic_grad_norm": 0.030821286141872406, "ratio": 1.0004425048828125, "entropy": 0.5911692102750142, "incre_win_rate": 0.8679245283018868, "step": 757}
{"time": 1766666444.087003, "phase": "train", "update": 758, "total_env_steps": 2425600, "episode_reward": 0.31117647886276245, "value_loss": 0.010591109842061996, "policy_loss": -0.013355868450052337, "dist_entropy": 0.5846241474151611, "actor_grad_norm": 0.12547335028648376, "critic_grad_norm": 0.02328467182815075, "ratio": 0.9984243512153625, "entropy": 0.5846241474151611, "incre_win_rate": 0.7924528301886793, "step": 758}
{"time": 1766666448.5072436, "phase": "train", "update": 759, "total_env_steps": 2428800, "episode_reward": 0.3111695945262909, "value_loss": 0.00890796563277642, "policy_loss": -0.013826948046127541, "dist_entropy": 0.5822069684664408, "actor_grad_norm": 0.14480265974998474, "critic_grad_norm": 0.026136495172977448, "ratio": 0.9999380111694336, "entropy": 0.5822069684664408, "incre_win_rate": 0.7962962962962963, "step": 759}
{"time": 1766666452.9643934, "phase": "train", "update": 760, "total_env_steps": 2432000, "episode_reward": 0.31651273369789124, "value_loss": 0.009317485491434734, "policy_loss": -0.013581666409225571, "dist_entropy": 0.5822323520978292, "actor_grad_norm": 0.1647622138261795, "critic_grad_norm": 0.0167723186314106, "ratio": 1.0007743835449219, "entropy": 0.5822323520978292, "incre_win_rate": 0.8269230769230769, "step": 760}
{"time": 1766666457.6660311, "phase": "train", "update": 761, "total_env_steps": 2435200, "episode_reward": 0.30100488662719727, "value_loss": 0.015141369961202144, "policy_loss": -0.013542753213827452, "dist_entropy": 0.5631603876749675, "actor_grad_norm": 0.17421048879623413, "critic_grad_norm": 0.06728988140821457, "ratio": 1.0003154277801514, "entropy": 0.5631603876749675, "incre_win_rate": 0.6923076923076923, "step": 761}
{"time": 1766666465.6399121, "phase": "eval", "update": 761, "total_env_steps": 2435200, "eval_win_rate": 0.875, "eval_episode_reward": 19.236443014705884, "step": 761}
{"time": 1766666470.0228384, "phase": "train", "update": 762, "total_env_steps": 2438400, "episode_reward": 0.3067547678947449, "value_loss": 0.0142532538001736, "policy_loss": -0.013274926062619367, "dist_entropy": 0.5774197220802307, "actor_grad_norm": 0.1794794350862503, "critic_grad_norm": 0.03962745517492294, "ratio": 0.9991809725761414, "entropy": 0.5774197220802307, "incre_win_rate": 0.8, "step": 762}
{"time": 1766666474.308664, "phase": "train", "update": 763, "total_env_steps": 2441600, "episode_reward": 0.2966444790363312, "value_loss": 0.010516689841945965, "policy_loss": -0.013959565515639838, "dist_entropy": 0.5787309845288594, "actor_grad_norm": 0.16357095539569855, "critic_grad_norm": 0.046697136014699936, "ratio": 0.9984312057495117, "entropy": 0.5787309845288594, "incre_win_rate": 0.7755102040816326, "step": 763}
{"time": 1766666478.6224496, "phase": "train", "update": 764, "total_env_steps": 2444800, "episode_reward": 0.30419808626174927, "value_loss": 0.009931298159062862, "policy_loss": -0.012995943120006596, "dist_entropy": 0.5701028267542522, "actor_grad_norm": 0.1416630744934082, "critic_grad_norm": 0.032953038811683655, "ratio": 0.9991755485534668, "entropy": 0.5701028267542522, "incre_win_rate": 0.7884615384615384, "step": 764}
{"time": 1766666482.8946614, "phase": "train", "update": 765, "total_env_steps": 2448000, "episode_reward": 0.30407172441482544, "value_loss": 0.010517607318858306, "policy_loss": -0.012689229121953123, "dist_entropy": 0.5757336020469666, "actor_grad_norm": 0.1516743302345276, "critic_grad_norm": 0.04519306495785713, "ratio": 1.0003578662872314, "entropy": 0.5757336020469666, "incre_win_rate": 0.7735849056603774, "step": 765}
{"time": 1766666487.124869, "phase": "train", "update": 766, "total_env_steps": 2451200, "episode_reward": 0.26857998967170715, "value_loss": 0.014245661286016306, "policy_loss": -0.01379678211701029, "dist_entropy": 0.5664662798245748, "actor_grad_norm": 0.13934169709682465, "critic_grad_norm": 0.09540066868066788, "ratio": 0.9989832043647766, "entropy": 0.5664662798245748, "incre_win_rate": 0.6086956521739131, "step": 766}
{"time": 1766666491.346865, "phase": "train", "update": 767, "total_env_steps": 2454400, "episode_reward": 0.30220282077789307, "value_loss": 0.013944808517893155, "policy_loss": -0.013569830971311111, "dist_entropy": 0.5723427732785543, "actor_grad_norm": 0.15207287669181824, "critic_grad_norm": 0.04989156126976013, "ratio": 0.9998915195465088, "entropy": 0.5723427732785543, "incre_win_rate": 0.7307692307692307, "step": 767}
{"time": 1766666495.6132793, "phase": "train", "update": 768, "total_env_steps": 2457600, "episode_reward": 0.30617114901542664, "value_loss": 0.01229055126508077, "policy_loss": -0.014216133616556211, "dist_entropy": 0.5782350063323974, "actor_grad_norm": 0.15222173929214478, "critic_grad_norm": 0.08285532891750336, "ratio": 0.9994964599609375, "entropy": 0.5782350063323974, "incre_win_rate": 0.7358490566037735, "step": 768}
{"time": 1766666499.9332008, "phase": "train", "update": 769, "total_env_steps": 2460800, "episode_reward": 0.28395068645477295, "value_loss": 0.010867317890127499, "policy_loss": -0.015605319291586284, "dist_entropy": 0.5887281775474549, "actor_grad_norm": 0.15594248473644257, "critic_grad_norm": 0.04611008241772652, "ratio": 0.9995308518409729, "entropy": 0.5887281775474549, "incre_win_rate": 0.6862745098039216, "step": 769}
{"time": 1766666504.2090232, "phase": "train", "update": 770, "total_env_steps": 2464000, "episode_reward": 0.3098544776439667, "value_loss": 0.007462623498092095, "policy_loss": -0.013831298161322062, "dist_entropy": 0.5911680340766907, "actor_grad_norm": 0.18547725677490234, "critic_grad_norm": 0.06748437136411667, "ratio": 1.000024437904358, "entropy": 0.5911680340766907, "incre_win_rate": 0.8431372549019608, "step": 770}
{"time": 1766666508.5901575, "phase": "train", "update": 771, "total_env_steps": 2467200, "episode_reward": 0.31083181500434875, "value_loss": 0.011211806163191795, "policy_loss": -0.014141800377776311, "dist_entropy": 0.577522091070811, "actor_grad_norm": 0.1761610060930252, "critic_grad_norm": 0.02729012258350849, "ratio": 0.9999812245368958, "entropy": 0.577522091070811, "incre_win_rate": 0.8461538461538461, "step": 771}
{"time": 1766666512.8164926, "phase": "train", "update": 772, "total_env_steps": 2470400, "episode_reward": 0.2811037302017212, "value_loss": 0.015684012261529764, "policy_loss": -0.014743834835533912, "dist_entropy": 0.5648054599761962, "actor_grad_norm": 0.19913871586322784, "critic_grad_norm": 0.047071948647499084, "ratio": 0.9996297359466553, "entropy": 0.5648054599761962, "incre_win_rate": 0.6, "step": 772}
{"time": 1766666517.0388076, "phase": "train", "update": 773, "total_env_steps": 2473600, "episode_reward": 0.3104289174079895, "value_loss": 0.009838554635643959, "policy_loss": -0.013818189956410739, "dist_entropy": 0.5788272221883138, "actor_grad_norm": 0.16034719347953796, "critic_grad_norm": 0.07348981499671936, "ratio": 0.999489426612854, "entropy": 0.5788272221883138, "incre_win_rate": 0.7962962962962963, "step": 773}
{"time": 1766666521.3018706, "phase": "train", "update": 774, "total_env_steps": 2476800, "episode_reward": 0.2935118079185486, "value_loss": 0.01309589600811402, "policy_loss": -0.015233930238376795, "dist_entropy": 0.5874910434087117, "actor_grad_norm": 0.16200131177902222, "critic_grad_norm": 0.05231253430247307, "ratio": 1.0007799863815308, "entropy": 0.5874910434087117, "incre_win_rate": 0.7, "step": 774}
{"time": 1766666525.6032245, "phase": "train", "update": 775, "total_env_steps": 2480000, "episode_reward": 0.3191390931606293, "value_loss": 0.010377980582416058, "policy_loss": -0.013548341199910396, "dist_entropy": 0.5695648550987243, "actor_grad_norm": 0.14088688790798187, "critic_grad_norm": 0.01784353516995907, "ratio": 1.000341773033142, "entropy": 0.5695648550987243, "incre_win_rate": 0.7818181818181819, "step": 775}
{"time": 1766666529.9109921, "phase": "train", "update": 776, "total_env_steps": 2483200, "episode_reward": 0.3131617605686188, "value_loss": 0.010325300134718418, "policy_loss": -0.013983055409770866, "dist_entropy": 0.5722493171691895, "actor_grad_norm": 0.15055887401103973, "critic_grad_norm": 0.018258824944496155, "ratio": 1.0002104043960571, "entropy": 0.5722493171691895, "incre_win_rate": 0.8333333333333334, "step": 776}
{"time": 1766666534.191933, "phase": "train", "update": 777, "total_env_steps": 2486400, "episode_reward": 0.29608455300331116, "value_loss": 0.010956329169372718, "policy_loss": -0.014403623126397728, "dist_entropy": 0.587883456548055, "actor_grad_norm": 0.15238796174526215, "critic_grad_norm": 0.015243293717503548, "ratio": 1.0005451440811157, "entropy": 0.587883456548055, "incre_win_rate": 0.74, "step": 777}
{"time": 1766666538.527653, "phase": "train", "update": 778, "total_env_steps": 2489600, "episode_reward": 0.29901039600372314, "value_loss": 0.010527467541396617, "policy_loss": -0.013546974825476354, "dist_entropy": 0.5710700670878093, "actor_grad_norm": 0.1529204398393631, "critic_grad_norm": 0.017037350684404373, "ratio": 0.9988417625427246, "entropy": 0.5710700670878093, "incre_win_rate": 0.76, "step": 778}
{"time": 1766666542.791845, "phase": "train", "update": 779, "total_env_steps": 2492800, "episode_reward": 0.305691659450531, "value_loss": 0.014408621874948343, "policy_loss": -0.014609510304425536, "dist_entropy": 0.5749121507008871, "actor_grad_norm": 0.15216392278671265, "critic_grad_norm": 0.02563248947262764, "ratio": 1.001590609550476, "entropy": 0.5749121507008871, "incre_win_rate": 0.75, "step": 779}
{"time": 1766666547.1060026, "phase": "train", "update": 780, "total_env_steps": 2496000, "episode_reward": 0.304875910282135, "value_loss": 0.013148077887793382, "policy_loss": -0.014753743936600472, "dist_entropy": 0.5730818827946981, "actor_grad_norm": 0.18833975493907928, "critic_grad_norm": 0.02707209251821041, "ratio": 0.9992755651473999, "entropy": 0.5730818827946981, "incre_win_rate": 0.7547169811320755, "step": 780}
{"time": 1766666551.3562593, "phase": "train", "update": 781, "total_env_steps": 2499200, "episode_reward": 0.3004940152168274, "value_loss": 0.010920353047549725, "policy_loss": -0.013421012720407315, "dist_entropy": 0.5857385317484538, "actor_grad_norm": 0.1678483635187149, "critic_grad_norm": 0.027107732370495796, "ratio": 0.9986603856086731, "entropy": 0.5857385317484538, "incre_win_rate": 0.7647058823529411, "step": 781}
{"time": 1766666558.9836376, "phase": "eval", "update": 781, "total_env_steps": 2499200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.498697916666668, "step": 781}
{"time": 1766666563.224965, "phase": "train", "update": 782, "total_env_steps": 2502400, "episode_reward": 0.30609455704689026, "value_loss": 0.011771990917623043, "policy_loss": -0.014018667647234414, "dist_entropy": 0.5997159679730734, "actor_grad_norm": 0.1606377363204956, "critic_grad_norm": 0.027408163994550705, "ratio": 0.9994627237319946, "entropy": 0.5997159679730734, "incre_win_rate": 0.7924528301886793, "step": 782}
{"time": 1766666567.481812, "phase": "train", "update": 783, "total_env_steps": 2505600, "episode_reward": 0.3069140613079071, "value_loss": 0.011790180392563344, "policy_loss": -0.013834346641280604, "dist_entropy": 0.5734694759051006, "actor_grad_norm": 0.1559372842311859, "critic_grad_norm": 0.0197294931858778, "ratio": 1.0003184080123901, "entropy": 0.5734694759051006, "incre_win_rate": 0.8269230769230769, "step": 783}
{"time": 1766666571.7831502, "phase": "train", "update": 784, "total_env_steps": 2508800, "episode_reward": 0.2962324023246765, "value_loss": 0.014999265472094217, "policy_loss": -0.014446885872255422, "dist_entropy": 0.5845325231552124, "actor_grad_norm": 0.14763088524341583, "critic_grad_norm": 0.05348990485072136, "ratio": 1.000196933746338, "entropy": 0.5845325231552124, "incre_win_rate": 0.660377358490566, "step": 784}
{"time": 1766666576.0463307, "phase": "train", "update": 785, "total_env_steps": 2512000, "episode_reward": 0.29480621218681335, "value_loss": 0.012183861869076888, "policy_loss": -0.014731338878078759, "dist_entropy": 0.6014634807904561, "actor_grad_norm": 0.15211880207061768, "critic_grad_norm": 0.04390594735741615, "ratio": 1.000396728515625, "entropy": 0.6014634807904561, "incre_win_rate": 0.6538461538461539, "step": 785}
{"time": 1766666580.349748, "phase": "train", "update": 786, "total_env_steps": 2515200, "episode_reward": 0.3089231252670288, "value_loss": 0.012344573065638543, "policy_loss": -0.015035306658570845, "dist_entropy": 0.5910246888796489, "actor_grad_norm": 0.1825913041830063, "critic_grad_norm": 0.03390417620539665, "ratio": 1.0008301734924316, "entropy": 0.5910246888796489, "incre_win_rate": 0.7924528301886793, "step": 786}
{"time": 1766666584.5486007, "phase": "train", "update": 787, "total_env_steps": 2518400, "episode_reward": 0.29987287521362305, "value_loss": 0.009187284049888451, "policy_loss": -0.01383660457012373, "dist_entropy": 0.5985944231351217, "actor_grad_norm": 0.17105212807655334, "critic_grad_norm": 0.053606413304805756, "ratio": 0.9982417821884155, "entropy": 0.5985944231351217, "incre_win_rate": 0.8367346938775511, "step": 787}
{"time": 1766666588.772945, "phase": "train", "update": 788, "total_env_steps": 2521600, "episode_reward": 0.3098292350769043, "value_loss": 0.009170888115962346, "policy_loss": -0.013401056056376603, "dist_entropy": 0.5829648971557617, "actor_grad_norm": 0.16896720230579376, "critic_grad_norm": 0.034758370369672775, "ratio": 0.9986273050308228, "entropy": 0.5829648971557617, "incre_win_rate": 0.7272727272727273, "step": 788}
{"time": 1766666593.0536144, "phase": "train", "update": 789, "total_env_steps": 2524800, "episode_reward": 0.3037109375, "value_loss": 0.008106012890736262, "policy_loss": -0.013570213201455772, "dist_entropy": 0.6125801006952921, "actor_grad_norm": 0.1557995080947876, "critic_grad_norm": 0.043291233479976654, "ratio": 0.9999603629112244, "entropy": 0.6125801006952921, "incre_win_rate": 0.8367346938775511, "step": 789}
{"time": 1766666597.3057625, "phase": "train", "update": 790, "total_env_steps": 2528000, "episode_reward": 0.30973729491233826, "value_loss": 0.008495877683162689, "policy_loss": -0.013867683817220684, "dist_entropy": 0.5953214764595032, "actor_grad_norm": 0.18804965913295746, "critic_grad_norm": 0.036249421536922455, "ratio": 1.0002734661102295, "entropy": 0.5953214764595032, "incre_win_rate": 0.8301886792452831, "step": 790}
{"time": 1766666601.6342704, "phase": "train", "update": 791, "total_env_steps": 2531200, "episode_reward": 0.3162691593170166, "value_loss": 0.007477226667106152, "policy_loss": -0.013901419143949548, "dist_entropy": 0.574709157148997, "actor_grad_norm": 0.15345405042171478, "critic_grad_norm": 0.03390457108616829, "ratio": 0.9986449480056763, "entropy": 0.574709157148997, "incre_win_rate": 0.8679245283018868, "step": 791}
{"time": 1766666605.8964038, "phase": "train", "update": 792, "total_env_steps": 2534400, "episode_reward": 0.29352253675460815, "value_loss": 0.013881987084945042, "policy_loss": -0.014345950847568645, "dist_entropy": 0.5968119303385416, "actor_grad_norm": 0.13256758451461792, "critic_grad_norm": 0.051788702607154846, "ratio": 0.9994283318519592, "entropy": 0.5968119303385416, "incre_win_rate": 0.72, "step": 792}
{"time": 1766666610.1967373, "phase": "train", "update": 793, "total_env_steps": 2537600, "episode_reward": 0.29571080207824707, "value_loss": 0.011154506355524063, "policy_loss": -0.014109151056641404, "dist_entropy": 0.6078768928845724, "actor_grad_norm": 0.16795936226844788, "critic_grad_norm": 0.033053040504455566, "ratio": 0.9999589323997498, "entropy": 0.6078768928845724, "incre_win_rate": 0.7547169811320755, "step": 793}
{"time": 1766666614.4439907, "phase": "train", "update": 794, "total_env_steps": 2540800, "episode_reward": 0.3197993040084839, "value_loss": 0.010145428528388341, "policy_loss": -0.01156536182774867, "dist_entropy": 0.5879750331242879, "actor_grad_norm": 0.1501581221818924, "critic_grad_norm": 0.019299184903502464, "ratio": 0.999832272529602, "entropy": 0.5879750331242879, "incre_win_rate": 0.8490566037735849, "step": 794}
{"time": 1766666618.7415776, "phase": "train", "update": 795, "total_env_steps": 2544000, "episode_reward": 0.3113909363746643, "value_loss": 0.015491194215913613, "policy_loss": -0.013842274190403714, "dist_entropy": 0.5818386554718018, "actor_grad_norm": 0.14641810953617096, "critic_grad_norm": 0.048491545021533966, "ratio": 0.9991455078125, "entropy": 0.5818386554718018, "incre_win_rate": 0.7547169811320755, "step": 795}
{"time": 1766666622.9962273, "phase": "train", "update": 796, "total_env_steps": 2547200, "episode_reward": 0.3093167841434479, "value_loss": 0.015168673731386662, "policy_loss": -0.012507123550849287, "dist_entropy": 0.598490035533905, "actor_grad_norm": 0.15568886697292328, "critic_grad_norm": 0.08296453952789307, "ratio": 0.9985764026641846, "entropy": 0.598490035533905, "incre_win_rate": 0.8333333333333334, "step": 796}
{"time": 1766666627.2425172, "phase": "train", "update": 797, "total_env_steps": 2550400, "episode_reward": 0.31361982226371765, "value_loss": 0.011156310016910235, "policy_loss": -0.014148729805439094, "dist_entropy": 0.5910588939984639, "actor_grad_norm": 0.14380615949630737, "critic_grad_norm": 0.0272496547549963, "ratio": 1.0001190900802612, "entropy": 0.5910588939984639, "incre_win_rate": 0.7843137254901961, "step": 797}
{"time": 1766666631.8259623, "phase": "train", "update": 798, "total_env_steps": 2553600, "episode_reward": 0.3147227168083191, "value_loss": 0.01123683260132869, "policy_loss": -0.013842212885743757, "dist_entropy": 0.5881090521812439, "actor_grad_norm": 0.19197994470596313, "critic_grad_norm": 0.023529144003987312, "ratio": 0.9997773170471191, "entropy": 0.5881090521812439, "incre_win_rate": 0.7962962962962963, "step": 798}
{"time": 1766666636.0704231, "phase": "train", "update": 799, "total_env_steps": 2556800, "episode_reward": 0.3120902478694916, "value_loss": 0.012257108154396215, "policy_loss": -0.013213343282752513, "dist_entropy": 0.5901233474413554, "actor_grad_norm": 0.16696009039878845, "critic_grad_norm": 0.04181434214115143, "ratio": 1.0006170272827148, "entropy": 0.5901233474413554, "incre_win_rate": 0.7090909090909091, "step": 799}
{"time": 1766666640.3592243, "phase": "train", "update": 800, "total_env_steps": 2560000, "episode_reward": 0.30938807129859924, "value_loss": 0.009917129452029863, "policy_loss": -0.01358104402508052, "dist_entropy": 0.582197388013204, "actor_grad_norm": 0.15077143907546997, "critic_grad_norm": 0.020996063947677612, "ratio": 1.0004569292068481, "entropy": 0.582197388013204, "incre_win_rate": 0.7547169811320755, "step": 800}
{"time": 1766666644.6346133, "phase": "train", "update": 801, "total_env_steps": 2563200, "episode_reward": 0.31328967213630676, "value_loss": 0.009184200130403043, "policy_loss": -0.012649902578870827, "dist_entropy": 0.5919196089108785, "actor_grad_norm": 0.1367868334054947, "critic_grad_norm": 0.01336491946130991, "ratio": 0.9998273253440857, "entropy": 0.5919196089108785, "incre_win_rate": 0.7735849056603774, "step": 801}
{"time": 1766666652.1123044, "phase": "eval", "update": 801, "total_env_steps": 2563200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.88687193627451, "step": 801}
{"time": 1766666656.3734195, "phase": "train", "update": 802, "total_env_steps": 2566400, "episode_reward": 0.304347425699234, "value_loss": 0.012205191267033419, "policy_loss": -0.013688085911396778, "dist_entropy": 0.595044489701589, "actor_grad_norm": 0.1575116664171219, "critic_grad_norm": 0.03957394137978554, "ratio": 0.9997278451919556, "entropy": 0.595044489701589, "incre_win_rate": 0.6792452830188679, "step": 802}
{"time": 1766666660.6657617, "phase": "train", "update": 803, "total_env_steps": 2569600, "episode_reward": 0.31422334909439087, "value_loss": 0.008884278467545907, "policy_loss": -0.013778809413181037, "dist_entropy": 0.6149807373682658, "actor_grad_norm": 0.18291513621807098, "critic_grad_norm": 0.07475657761096954, "ratio": 0.9972547888755798, "entropy": 0.6149807373682658, "incre_win_rate": 0.8490566037735849, "step": 803}
{"time": 1766666664.907037, "phase": "train", "update": 804, "total_env_steps": 2572800, "episode_reward": 0.3238403797149658, "value_loss": 0.007145956127593915, "policy_loss": -0.013247845244889807, "dist_entropy": 0.6089925209681193, "actor_grad_norm": 0.15482181310653687, "critic_grad_norm": 0.029466498643159866, "ratio": 1.0001026391983032, "entropy": 0.6089925209681193, "incre_win_rate": 0.8703703703703703, "step": 804}
{"time": 1766666669.1540232, "phase": "train", "update": 805, "total_env_steps": 2576000, "episode_reward": 0.31996551156044006, "value_loss": 0.010595589069028695, "policy_loss": -0.01355390242158876, "dist_entropy": 0.5978480100631713, "actor_grad_norm": 0.15495941042900085, "critic_grad_norm": 0.04324587062001228, "ratio": 0.9995763897895813, "entropy": 0.5978480100631713, "incre_win_rate": 0.8148148148148148, "step": 805}
{"time": 1766666673.4438126, "phase": "train", "update": 806, "total_env_steps": 2579200, "episode_reward": 0.3145527243614197, "value_loss": 0.008114292100071908, "policy_loss": -0.012612245901415046, "dist_entropy": 0.6130873004595438, "actor_grad_norm": 0.15095645189285278, "critic_grad_norm": 0.020659858360886574, "ratio": 1.0000613927841187, "entropy": 0.6130873004595438, "incre_win_rate": 0.8148148148148148, "step": 806}
{"time": 1766666677.7087495, "phase": "train", "update": 807, "total_env_steps": 2582400, "episode_reward": 0.32351332902908325, "value_loss": 0.008839709808429082, "policy_loss": -0.012579941834441163, "dist_entropy": 0.6126813888549805, "actor_grad_norm": 0.13141822814941406, "critic_grad_norm": 0.01526976190507412, "ratio": 1.0006194114685059, "entropy": 0.6126813888549805, "incre_win_rate": 0.8461538461538461, "step": 807}
{"time": 1766666682.0002022, "phase": "train", "update": 808, "total_env_steps": 2585600, "episode_reward": 0.3187737464904785, "value_loss": 0.008604988890389602, "policy_loss": -0.012439120259468457, "dist_entropy": 0.6017188350359599, "actor_grad_norm": 0.14921386539936066, "critic_grad_norm": 0.012487580999732018, "ratio": 0.9997332096099854, "entropy": 0.6017188350359599, "incre_win_rate": 0.8181818181818182, "step": 808}
{"time": 1766666686.282225, "phase": "train", "update": 809, "total_env_steps": 2588800, "episode_reward": 0.3085278868675232, "value_loss": 0.009417561069130897, "policy_loss": -0.012707035188780936, "dist_entropy": 0.6243056337038676, "actor_grad_norm": 0.1307363212108612, "critic_grad_norm": 0.020810212939977646, "ratio": 0.9993460774421692, "entropy": 0.6243056337038676, "incre_win_rate": 0.7843137254901961, "step": 809}
{"time": 1766666690.550415, "phase": "train", "update": 810, "total_env_steps": 2592000, "episode_reward": 0.3033195436000824, "value_loss": 0.013009175409873326, "policy_loss": -0.0140849719595631, "dist_entropy": 0.6106392105420431, "actor_grad_norm": 0.13870687782764435, "critic_grad_norm": 0.05122365057468414, "ratio": 1.000265121459961, "entropy": 0.6106392105420431, "incre_win_rate": 0.75, "step": 810}
{"time": 1766666694.8241413, "phase": "train", "update": 811, "total_env_steps": 2595200, "episode_reward": 0.3173023760318756, "value_loss": 0.012822318511704603, "policy_loss": -0.013544490891581992, "dist_entropy": 0.5987350861231486, "actor_grad_norm": 0.18632303178310394, "critic_grad_norm": 0.027521468698978424, "ratio": 0.9994816184043884, "entropy": 0.5987350861231486, "incre_win_rate": 0.7636363636363637, "step": 811}
{"time": 1766666699.1025095, "phase": "train", "update": 812, "total_env_steps": 2598400, "episode_reward": 0.31128907203674316, "value_loss": 0.013938114543755849, "policy_loss": -0.012831832088477194, "dist_entropy": 0.5912078658739726, "actor_grad_norm": 0.16923737525939941, "critic_grad_norm": 0.018784161657094955, "ratio": 0.9995672702789307, "entropy": 0.5912078658739726, "incre_win_rate": 0.7407407407407407, "step": 812}
{"time": 1766666703.446282, "phase": "train", "update": 813, "total_env_steps": 2601600, "episode_reward": 0.3096499741077423, "value_loss": 0.009468883089721204, "policy_loss": -0.012847668285630694, "dist_entropy": 0.6031216581662496, "actor_grad_norm": 0.15824870765209198, "critic_grad_norm": 0.03306552395224571, "ratio": 0.9997968077659607, "entropy": 0.6031216581662496, "incre_win_rate": 0.7884615384615384, "step": 813}
{"time": 1766666707.691735, "phase": "train", "update": 814, "total_env_steps": 2604800, "episode_reward": 0.3245442807674408, "value_loss": 0.00987146000067393, "policy_loss": -0.012440438241705938, "dist_entropy": 0.5950141032536824, "actor_grad_norm": 0.14945031702518463, "critic_grad_norm": 0.037272270768880844, "ratio": 0.9992800354957581, "entropy": 0.5950141032536824, "incre_win_rate": 0.8181818181818182, "step": 814}
{"time": 1766666712.2525675, "phase": "train", "update": 815, "total_env_steps": 2608000, "episode_reward": 0.3154388964176178, "value_loss": 0.0121028537551562, "policy_loss": -0.013689412977890924, "dist_entropy": 0.6002610127131144, "actor_grad_norm": 0.16693934798240662, "critic_grad_norm": 0.03568512946367264, "ratio": 1.0011955499649048, "entropy": 0.6002610127131144, "incre_win_rate": 0.7636363636363637, "step": 815}
{"time": 1766666751.469468, "phase": "train", "update": 816, "total_env_steps": 2611200, "episode_reward": 0.32226258516311646, "value_loss": 0.06216129461924235, "policy_loss": -0.011208516267458416, "dist_entropy": 0.5851700743039449, "actor_grad_norm": 0.13876715302467346, "critic_grad_norm": 0.1342955380678177, "ratio": 1.0006593465805054, "entropy": 0.5851700743039449, "incre_win_rate": 0.86, "step": 816}
{"time": 1766666755.7609677, "phase": "train", "update": 817, "total_env_steps": 2614400, "episode_reward": 0.3147411048412323, "value_loss": 0.013606077867249648, "policy_loss": -0.012404032329741929, "dist_entropy": 0.5827576120694479, "actor_grad_norm": 0.15802818536758423, "critic_grad_norm": 0.05244855210185051, "ratio": 1.000093936920166, "entropy": 0.5827576120694479, "incre_win_rate": 0.7321428571428571, "step": 817}
{"time": 1766666759.9885402, "phase": "train", "update": 818, "total_env_steps": 2617600, "episode_reward": 0.3160944879055023, "value_loss": 0.009920193379124006, "policy_loss": -0.012815581922891303, "dist_entropy": 0.6051681836446127, "actor_grad_norm": 0.14502669870853424, "critic_grad_norm": 0.08214545994997025, "ratio": 0.998205304145813, "entropy": 0.6051681836446127, "incre_win_rate": 0.8301886792452831, "step": 818}
{"time": 1766666764.3264253, "phase": "train", "update": 819, "total_env_steps": 2620800, "episode_reward": 0.31713542342185974, "value_loss": 0.012600368509689966, "policy_loss": -0.013792766000411898, "dist_entropy": 0.6165580709775289, "actor_grad_norm": 0.15869884192943573, "critic_grad_norm": 0.03673955798149109, "ratio": 1.000451922416687, "entropy": 0.6165580709775289, "incre_win_rate": 0.7777777777777778, "step": 819}
{"time": 1766666768.5776846, "phase": "train", "update": 820, "total_env_steps": 2624000, "episode_reward": 0.32413986325263977, "value_loss": 0.010752802776793639, "policy_loss": -0.012940180691706379, "dist_entropy": 0.5889623959859213, "actor_grad_norm": 0.17922700941562653, "critic_grad_norm": 0.03771580383181572, "ratio": 0.9993322491645813, "entropy": 0.5889623959859213, "incre_win_rate": 0.8301886792452831, "step": 820}
{"time": 1766666772.8308477, "phase": "train", "update": 821, "total_env_steps": 2627200, "episode_reward": 0.31832030415534973, "value_loss": 0.008441305284698804, "policy_loss": -0.013526735807123321, "dist_entropy": 0.6192322969436646, "actor_grad_norm": 0.15049198269844055, "critic_grad_norm": 0.0568448081612587, "ratio": 0.9986610412597656, "entropy": 0.6192322969436646, "incre_win_rate": 0.8490566037735849, "step": 821}
{"time": 1766666780.442344, "phase": "eval", "update": 821, "total_env_steps": 2627200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.895373774509807, "step": 821}
{"time": 1766666784.7627687, "phase": "train", "update": 822, "total_env_steps": 2630400, "episode_reward": 0.32062652707099915, "value_loss": 0.009471340849995614, "policy_loss": -0.012373595904392805, "dist_entropy": 0.6163660367329915, "actor_grad_norm": 0.13184884190559387, "critic_grad_norm": 0.03832530230283737, "ratio": 1.000434160232544, "entropy": 0.6163660367329915, "incre_win_rate": 0.8070175438596491, "step": 822}
{"time": 1766666789.0202727, "phase": "train", "update": 823, "total_env_steps": 2633600, "episode_reward": 0.31112897396087646, "value_loss": 0.011176012145976225, "policy_loss": -0.0136495787011692, "dist_entropy": 0.6124720613161723, "actor_grad_norm": 0.16568797826766968, "critic_grad_norm": 0.027260567992925644, "ratio": 1.001236915588379, "entropy": 0.6124720613161723, "incre_win_rate": 0.8235294117647058, "step": 823}
{"time": 1766666793.2355156, "phase": "train", "update": 824, "total_env_steps": 2636800, "episode_reward": 0.3008953928947449, "value_loss": 0.011081225114564101, "policy_loss": -0.013341699159611172, "dist_entropy": 0.6104998588562012, "actor_grad_norm": 0.1791827231645584, "critic_grad_norm": 0.027247583493590355, "ratio": 1.0001596212387085, "entropy": 0.6104998588562012, "incre_win_rate": 0.7692307692307693, "step": 824}
{"time": 1766666797.4931622, "phase": "train", "update": 825, "total_env_steps": 2640000, "episode_reward": 0.29972660541534424, "value_loss": 0.012510019664963087, "policy_loss": -0.014309753044801235, "dist_entropy": 0.601936690012614, "actor_grad_norm": 0.2038717418909073, "critic_grad_norm": 0.03277811408042908, "ratio": 0.9989872574806213, "entropy": 0.601936690012614, "incre_win_rate": 0.76, "step": 825}
{"time": 1766666801.8149798, "phase": "train", "update": 826, "total_env_steps": 2643200, "episode_reward": 0.3124326169490814, "value_loss": 0.010185379845400652, "policy_loss": -0.013781894926346183, "dist_entropy": 0.6061293363571167, "actor_grad_norm": 0.15063750743865967, "critic_grad_norm": 0.025880876928567886, "ratio": 0.9996405839920044, "entropy": 0.6061293363571167, "incre_win_rate": 0.7924528301886793, "step": 826}
{"time": 1766666806.1271467, "phase": "train", "update": 827, "total_env_steps": 2646400, "episode_reward": 0.2896653115749359, "value_loss": 0.015069057978689671, "policy_loss": -0.014570775816525838, "dist_entropy": 0.6167405923207601, "actor_grad_norm": 0.17761312425136566, "critic_grad_norm": 0.06764792650938034, "ratio": 0.9995908737182617, "entropy": 0.6167405923207601, "incre_win_rate": 0.6538461538461539, "step": 827}
{"time": 1766666810.42344, "phase": "train", "update": 828, "total_env_steps": 2649600, "episode_reward": 0.3105936348438263, "value_loss": 0.013456506406267483, "policy_loss": -0.013860742866838827, "dist_entropy": 0.6199398954709371, "actor_grad_norm": 0.1730317622423172, "critic_grad_norm": 0.02723000943660736, "ratio": 0.9997732639312744, "entropy": 0.6199398954709371, "incre_win_rate": 0.7358490566037735, "step": 828}
{"time": 1766666814.7357392, "phase": "train", "update": 829, "total_env_steps": 2652800, "episode_reward": 0.30198222398757935, "value_loss": 0.01366775253166755, "policy_loss": -0.014225739537610119, "dist_entropy": 0.6112271825472514, "actor_grad_norm": 0.1473744511604309, "critic_grad_norm": 0.03460659086704254, "ratio": 0.9997423887252808, "entropy": 0.6112271825472514, "incre_win_rate": 0.6792452830188679, "step": 829}
{"time": 1766666818.961781, "phase": "train", "update": 830, "total_env_steps": 2656000, "episode_reward": 0.3029220700263977, "value_loss": 0.014801675640046596, "policy_loss": -0.013528185245455404, "dist_entropy": 0.6167548020680745, "actor_grad_norm": 0.14767661690711975, "critic_grad_norm": 0.020424121990799904, "ratio": 0.9995012283325195, "entropy": 0.6167548020680745, "incre_win_rate": 0.6981132075471698, "step": 830}
{"time": 1766666823.219343, "phase": "train", "update": 831, "total_env_steps": 2659200, "episode_reward": 0.30782783031463623, "value_loss": 0.013033179504175981, "policy_loss": -0.013771604551124502, "dist_entropy": 0.6253492156664531, "actor_grad_norm": 0.14386969804763794, "critic_grad_norm": 0.01769622042775154, "ratio": 0.9992091655731201, "entropy": 0.6253492156664531, "incre_win_rate": 0.75, "step": 831}
{"time": 1766666827.5222888, "phase": "train", "update": 832, "total_env_steps": 2662400, "episode_reward": 0.2980744540691376, "value_loss": 0.011371031713982424, "policy_loss": -0.014180249904805464, "dist_entropy": 0.624313747882843, "actor_grad_norm": 0.1482136845588684, "critic_grad_norm": 0.01107777189463377, "ratio": 1.0006611347198486, "entropy": 0.624313747882843, "incre_win_rate": 0.7222222222222222, "step": 832}
{"time": 1766666831.7654364, "phase": "train", "update": 833, "total_env_steps": 2665600, "episode_reward": 0.31108149886131287, "value_loss": 0.0107355664173762, "policy_loss": -0.014010096970929453, "dist_entropy": 0.6039962490399678, "actor_grad_norm": 0.16757073998451233, "critic_grad_norm": 0.015303941443562508, "ratio": 1.0002527236938477, "entropy": 0.6039962490399678, "incre_win_rate": 0.7692307692307693, "step": 833}
{"time": 1766666836.0834022, "phase": "train", "update": 834, "total_env_steps": 2668800, "episode_reward": 0.3095282018184662, "value_loss": 0.01407548679659764, "policy_loss": -0.013935627903943981, "dist_entropy": 0.5999602198600769, "actor_grad_norm": 0.15697625279426575, "critic_grad_norm": 0.025914179161190987, "ratio": 1.0002063512802124, "entropy": 0.5999602198600769, "incre_win_rate": 0.7884615384615384, "step": 834}
{"time": 1766666840.3586843, "phase": "train", "update": 835, "total_env_steps": 2672000, "episode_reward": 0.30827435851097107, "value_loss": 0.012272874700526397, "policy_loss": -0.013716587532862453, "dist_entropy": 0.5953831354777018, "actor_grad_norm": 0.158868670463562, "critic_grad_norm": 0.043593715876340866, "ratio": 0.9991593360900879, "entropy": 0.5953831354777018, "incre_win_rate": 0.7358490566037735, "step": 835}
{"time": 1766666844.6465704, "phase": "train", "update": 836, "total_env_steps": 2675200, "episode_reward": 0.3148307204246521, "value_loss": 0.007591883496691783, "policy_loss": -0.01484507083397381, "dist_entropy": 0.6036464691162109, "actor_grad_norm": 0.20072877407073975, "critic_grad_norm": 0.04795810952782631, "ratio": 0.9989269971847534, "entropy": 0.6036464691162109, "incre_win_rate": 0.8148148148148148, "step": 836}
{"time": 1766666848.9014208, "phase": "train", "update": 837, "total_env_steps": 2678400, "episode_reward": 0.30284085869789124, "value_loss": 0.011158615909516811, "policy_loss": -0.01405560282103219, "dist_entropy": 0.6087957104047139, "actor_grad_norm": 0.15814679861068726, "critic_grad_norm": 0.025711512193083763, "ratio": 0.9992099404335022, "entropy": 0.6087957104047139, "incre_win_rate": 0.7450980392156863, "step": 837}
{"time": 1766666853.160695, "phase": "train", "update": 838, "total_env_steps": 2681600, "episode_reward": 0.32417434453964233, "value_loss": 0.008218751506259043, "policy_loss": -0.013853782022986157, "dist_entropy": 0.606352953116099, "actor_grad_norm": 0.19819523394107819, "critic_grad_norm": 0.03197170048952103, "ratio": 1.000071406364441, "entropy": 0.606352953116099, "incre_win_rate": 0.8867924528301887, "step": 838}
{"time": 1766666857.4265842, "phase": "train", "update": 839, "total_env_steps": 2684800, "episode_reward": 0.30595049262046814, "value_loss": 0.009245870883266132, "policy_loss": -0.014130257953540592, "dist_entropy": 0.6143128236134847, "actor_grad_norm": 0.16780124604701996, "critic_grad_norm": 0.03080788254737854, "ratio": 1.0001674890518188, "entropy": 0.6143128236134847, "incre_win_rate": 0.8301886792452831, "step": 839}
{"time": 1766666861.6590717, "phase": "train", "update": 840, "total_env_steps": 2688000, "episode_reward": 0.3180897831916809, "value_loss": 0.008714563958346844, "policy_loss": -0.012611522428593957, "dist_entropy": 0.601087220509847, "actor_grad_norm": 0.16429659724235535, "critic_grad_norm": 0.01741681434214115, "ratio": 0.9985087513923645, "entropy": 0.601087220509847, "incre_win_rate": 0.8679245283018868, "step": 840}
{"time": 1766666865.9540691, "phase": "train", "update": 841, "total_env_steps": 2691200, "episode_reward": 0.31856462359428406, "value_loss": 0.011645470559597016, "policy_loss": -0.012876256084676166, "dist_entropy": 0.6156326572100321, "actor_grad_norm": 0.16938574612140656, "critic_grad_norm": 0.019797716289758682, "ratio": 0.9997044801712036, "entropy": 0.6156326572100321, "incre_win_rate": 0.8113207547169812, "step": 841}
{"time": 1766666873.3861182, "phase": "eval", "update": 841, "total_env_steps": 2691200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.89468443627451, "step": 841}
{"time": 1766666877.6503067, "phase": "train", "update": 842, "total_env_steps": 2694400, "episode_reward": 0.31962546706199646, "value_loss": 0.007368882900724808, "policy_loss": -0.012149038901087768, "dist_entropy": 0.6188940525054931, "actor_grad_norm": 0.1550978124141693, "critic_grad_norm": 0.021774543449282646, "ratio": 1.000556230545044, "entropy": 0.6188940525054931, "incre_win_rate": 0.8679245283018868, "step": 842}
{"time": 1766666881.909968, "phase": "train", "update": 843, "total_env_steps": 2697600, "episode_reward": 0.3030882179737091, "value_loss": 0.013889836706221103, "policy_loss": -0.013918074238250118, "dist_entropy": 0.6349823514620463, "actor_grad_norm": 0.15529660880565643, "critic_grad_norm": 0.05548079311847687, "ratio": 0.999821662902832, "entropy": 0.6349823514620463, "incre_win_rate": 0.7358490566037735, "step": 843}
{"time": 1766666886.2185347, "phase": "train", "update": 844, "total_env_steps": 2700800, "episode_reward": 0.3081648349761963, "value_loss": 0.008410649622480075, "policy_loss": -0.012485252977598312, "dist_entropy": 0.6371160427729289, "actor_grad_norm": 0.14796550571918488, "critic_grad_norm": 0.019439062103629112, "ratio": 1.0007961988449097, "entropy": 0.6371160427729289, "incre_win_rate": 0.8490566037735849, "step": 844}
{"time": 1766666890.4429655, "phase": "train", "update": 845, "total_env_steps": 2704000, "episode_reward": 0.3083800673484802, "value_loss": 0.011301917334397634, "policy_loss": -0.013376014388770468, "dist_entropy": 0.6122088352839152, "actor_grad_norm": 0.170294851064682, "critic_grad_norm": 0.018717681989073753, "ratio": 0.9992750287055969, "entropy": 0.6122088352839152, "incre_win_rate": 0.7, "step": 845}
{"time": 1766666894.6839726, "phase": "train", "update": 846, "total_env_steps": 2707200, "episode_reward": 0.31222960352897644, "value_loss": 0.009952386282384396, "policy_loss": -0.014431797220189916, "dist_entropy": 0.6522388100624085, "actor_grad_norm": 0.17243468761444092, "critic_grad_norm": 0.024833928793668747, "ratio": 0.9991054534912109, "entropy": 0.6522388100624085, "incre_win_rate": 0.8490566037735849, "step": 846}
{"time": 1766666898.9499445, "phase": "train", "update": 847, "total_env_steps": 2710400, "episode_reward": 0.31301242113113403, "value_loss": 0.011714920463661353, "policy_loss": -0.013307864610950067, "dist_entropy": 0.639987313747406, "actor_grad_norm": 0.16425687074661255, "critic_grad_norm": 0.03324973210692406, "ratio": 1.0004132986068726, "entropy": 0.639987313747406, "incre_win_rate": 0.7777777777777778, "step": 847}
{"time": 1766666903.4572692, "phase": "train", "update": 848, "total_env_steps": 2713600, "episode_reward": 0.2987706959247589, "value_loss": 0.01171467782308658, "policy_loss": -0.013812431105210975, "dist_entropy": 0.6169519941012065, "actor_grad_norm": 0.16258621215820312, "critic_grad_norm": 0.01634751819074154, "ratio": 0.999927282333374, "entropy": 0.6169519941012065, "incre_win_rate": 0.75, "step": 848}
{"time": 1766666909.4849741, "phase": "train", "update": 849, "total_env_steps": 2716800, "episode_reward": 0.3044324219226837, "value_loss": 0.013078089679280917, "policy_loss": -0.013091197887492474, "dist_entropy": 0.6295392155647278, "actor_grad_norm": 0.15204380452632904, "critic_grad_norm": 0.030807914212346077, "ratio": 1.0001626014709473, "entropy": 0.6295392155647278, "incre_win_rate": 0.75, "step": 849}
{"time": 1766666914.206757, "phase": "train", "update": 850, "total_env_steps": 2720000, "episode_reward": 0.31798255443573, "value_loss": 0.007641526373724143, "policy_loss": -0.014303208071447197, "dist_entropy": 0.6188795089721679, "actor_grad_norm": 0.13906072080135345, "critic_grad_norm": 0.055497076362371445, "ratio": 1.0004937648773193, "entropy": 0.6188795089721679, "incre_win_rate": 0.8679245283018868, "step": 850}
{"time": 1766666919.239054, "phase": "train", "update": 851, "total_env_steps": 2723200, "episode_reward": 0.30831727385520935, "value_loss": 0.009578490691880385, "policy_loss": -0.013978634229315882, "dist_entropy": 0.635961671670278, "actor_grad_norm": 0.15800464153289795, "critic_grad_norm": 0.021753093227744102, "ratio": 1.0003541707992554, "entropy": 0.635961671670278, "incre_win_rate": 0.8113207547169812, "step": 851}
{"time": 1766666923.4656794, "phase": "train", "update": 852, "total_env_steps": 2726400, "episode_reward": 0.3163648843765259, "value_loss": 0.009398950760563215, "policy_loss": -0.01416313272268989, "dist_entropy": 0.6312174797058105, "actor_grad_norm": 0.16693367063999176, "critic_grad_norm": 0.03599794954061508, "ratio": 0.9986550807952881, "entropy": 0.6312174797058105, "incre_win_rate": 0.8461538461538461, "step": 852}
{"time": 1766666927.9755845, "phase": "train", "update": 853, "total_env_steps": 2729600, "episode_reward": 0.30327820777893066, "value_loss": 0.010100272856652737, "policy_loss": -0.014124231384994346, "dist_entropy": 0.6447107434272766, "actor_grad_norm": 0.1698864996433258, "critic_grad_norm": 0.014932743273675442, "ratio": 1.000428557395935, "entropy": 0.6447107434272766, "incre_win_rate": 0.7592592592592593, "step": 853}
{"time": 1766666932.3748894, "phase": "train", "update": 854, "total_env_steps": 2732800, "episode_reward": 0.30936047434806824, "value_loss": 0.009431545063853264, "policy_loss": -0.013617492340595541, "dist_entropy": 0.6521051327387491, "actor_grad_norm": 0.13637720048427582, "critic_grad_norm": 0.010889670811593533, "ratio": 1.0007684230804443, "entropy": 0.6521051327387491, "incre_win_rate": 0.84, "step": 854}
{"time": 1766666936.7073286, "phase": "train", "update": 855, "total_env_steps": 2736000, "episode_reward": 0.3157176673412323, "value_loss": 0.009731183697779974, "policy_loss": -0.013605681989328862, "dist_entropy": 0.6486446102460225, "actor_grad_norm": 0.13938294351100922, "critic_grad_norm": 0.016453318297863007, "ratio": 0.9997938275337219, "entropy": 0.6486446102460225, "incre_win_rate": 0.8214285714285714, "step": 855}
{"time": 1766666941.05142, "phase": "train", "update": 856, "total_env_steps": 2739200, "episode_reward": 0.29974573850631714, "value_loss": 0.014176881064971288, "policy_loss": -0.013224806155542978, "dist_entropy": 0.6287748297055562, "actor_grad_norm": 0.14752477407455444, "critic_grad_norm": 0.04733527451753616, "ratio": 1.0007832050323486, "entropy": 0.6287748297055562, "incre_win_rate": 0.6938775510204082, "step": 856}
{"time": 1766666945.3572297, "phase": "train", "update": 857, "total_env_steps": 2742400, "episode_reward": 0.29385876655578613, "value_loss": 0.014039671048521996, "policy_loss": -0.014261083121076486, "dist_entropy": 0.6526490449905396, "actor_grad_norm": 0.16411590576171875, "critic_grad_norm": 0.03622416406869888, "ratio": 0.9999924302101135, "entropy": 0.6526490449905396, "incre_win_rate": 0.6981132075471698, "step": 857}
{"time": 1766666949.7429502, "phase": "train", "update": 858, "total_env_steps": 2745600, "episode_reward": 0.30493032932281494, "value_loss": 0.01387653723359108, "policy_loss": -0.013573154770085694, "dist_entropy": 0.6305093248685201, "actor_grad_norm": 0.16732241213321686, "critic_grad_norm": 0.01720816269516945, "ratio": 1.000377893447876, "entropy": 0.6305093248685201, "incre_win_rate": 0.7692307692307693, "step": 858}
{"time": 1766666954.0207422, "phase": "train", "update": 859, "total_env_steps": 2748800, "episode_reward": 0.3135133683681488, "value_loss": 0.01224950049072504, "policy_loss": -0.01373832451929644, "dist_entropy": 0.6353644251823425, "actor_grad_norm": 0.17078956961631775, "critic_grad_norm": 0.03189875930547714, "ratio": 1.000115990638733, "entropy": 0.6353644251823425, "incre_win_rate": 0.7777777777777778, "step": 859}
{"time": 1766666958.4547563, "phase": "train", "update": 860, "total_env_steps": 2752000, "episode_reward": 0.3029465675354004, "value_loss": 0.007454548279444377, "policy_loss": -0.012907952571882753, "dist_entropy": 0.6312232931454976, "actor_grad_norm": 0.1595734804868698, "critic_grad_norm": 0.046698346734046936, "ratio": 0.9996455907821655, "entropy": 0.6312232931454976, "incre_win_rate": 0.8269230769230769, "step": 860}
{"time": 1766666962.7438908, "phase": "train", "update": 861, "total_env_steps": 2755200, "episode_reward": 0.3133876919746399, "value_loss": 0.009720527939498425, "policy_loss": -0.013041472581501286, "dist_entropy": 0.6235400120417277, "actor_grad_norm": 0.1587877720594406, "critic_grad_norm": 0.02523203380405903, "ratio": 1.000213861465454, "entropy": 0.6235400120417277, "incre_win_rate": 0.7547169811320755, "step": 861}
{"time": 1766666970.5506244, "phase": "eval", "update": 861, "total_env_steps": 2755200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.86764705882353, "step": 861}
{"time": 1766666974.7862542, "phase": "train", "update": 862, "total_env_steps": 2758400, "episode_reward": 0.3143458962440491, "value_loss": 0.0072803124164541565, "policy_loss": -0.012888127591137888, "dist_entropy": 0.6326401392618816, "actor_grad_norm": 0.1599172204732895, "critic_grad_norm": 0.018599243834614754, "ratio": 1.0000925064086914, "entropy": 0.6326401392618816, "incre_win_rate": 0.8490566037735849, "step": 862}
{"time": 1766666979.148303, "phase": "train", "update": 863, "total_env_steps": 2761600, "episode_reward": 0.31953510642051697, "value_loss": 0.009917325216035049, "policy_loss": -0.013168456829834696, "dist_entropy": 0.637528129418691, "actor_grad_norm": 0.14489015936851501, "critic_grad_norm": 0.03753640875220299, "ratio": 1.000003457069397, "entropy": 0.637528129418691, "incre_win_rate": 0.8148148148148148, "step": 863}
{"time": 1766666983.4099545, "phase": "train", "update": 864, "total_env_steps": 2764800, "episode_reward": 0.3092394471168518, "value_loss": 0.011802617522577444, "policy_loss": -0.013726687529054498, "dist_entropy": 0.6365822116533916, "actor_grad_norm": 0.15533186495304108, "critic_grad_norm": 0.044326238334178925, "ratio": 0.9999480247497559, "entropy": 0.6365822116533916, "incre_win_rate": 0.7735849056603774, "step": 864}
{"time": 1766666987.666098, "phase": "train", "update": 865, "total_env_steps": 2768000, "episode_reward": 0.3090946674346924, "value_loss": 0.009251504453519981, "policy_loss": -0.013915893770029204, "dist_entropy": 0.6317051569620769, "actor_grad_norm": 0.13141776621341705, "critic_grad_norm": 0.020756224170327187, "ratio": 0.998894989490509, "entropy": 0.6317051569620769, "incre_win_rate": 0.8076923076923077, "step": 865}
{"time": 1766666991.9382603, "phase": "train", "update": 866, "total_env_steps": 2771200, "episode_reward": 0.32513096928596497, "value_loss": 0.00645201684286197, "policy_loss": -0.01331936685115475, "dist_entropy": 0.6352701505025228, "actor_grad_norm": 0.1383359134197235, "critic_grad_norm": 0.03500215336680412, "ratio": 0.9993895888328552, "entropy": 0.6352701505025228, "incre_win_rate": 0.8653846153846154, "step": 866}
{"time": 1766666996.3443599, "phase": "train", "update": 867, "total_env_steps": 2774400, "episode_reward": 0.3113725483417511, "value_loss": 0.009598545543849469, "policy_loss": -0.01289955488196739, "dist_entropy": 0.6408182700475057, "actor_grad_norm": 0.13359969854354858, "critic_grad_norm": 0.02506670542061329, "ratio": 1.000176191329956, "entropy": 0.6408182700475057, "incre_win_rate": 0.7777777777777778, "step": 867}
{"time": 1766667000.7422187, "phase": "train", "update": 868, "total_env_steps": 2777600, "episode_reward": 0.3150888681411743, "value_loss": 0.009111966130634148, "policy_loss": -0.013242885804456251, "dist_entropy": 0.628336755434672, "actor_grad_norm": 0.1440311074256897, "critic_grad_norm": 0.029954083263874054, "ratio": 0.9992678165435791, "entropy": 0.628336755434672, "incre_win_rate": 0.8490566037735849, "step": 868}
{"time": 1766667005.0091164, "phase": "train", "update": 869, "total_env_steps": 2780800, "episode_reward": 0.2940388023853302, "value_loss": 0.01592227773120006, "policy_loss": -0.014799822538504278, "dist_entropy": 0.6253846685091654, "actor_grad_norm": 0.18153643608093262, "critic_grad_norm": 0.0918903574347496, "ratio": 0.9994518756866455, "entropy": 0.6253846685091654, "incre_win_rate": 0.6792452830188679, "step": 869}
{"time": 1766667009.3234138, "phase": "train", "update": 870, "total_env_steps": 2784000, "episode_reward": 0.3046737015247345, "value_loss": 0.014576795821388563, "policy_loss": -0.0146880820354923, "dist_entropy": 0.6322317242622375, "actor_grad_norm": 0.16484470665454865, "critic_grad_norm": 0.02661917731165886, "ratio": 0.9999548196792603, "entropy": 0.6322317242622375, "incre_win_rate": 0.76, "step": 870}
{"time": 1766667013.6041968, "phase": "train", "update": 871, "total_env_steps": 2787200, "episode_reward": 0.30727100372314453, "value_loss": 0.012089450905720393, "policy_loss": -0.01479213094725651, "dist_entropy": 0.6200274348258972, "actor_grad_norm": 0.17061515152454376, "critic_grad_norm": 0.03203685209155083, "ratio": 0.999152421951294, "entropy": 0.6200274348258972, "incre_win_rate": 0.7407407407407407, "step": 871}
{"time": 1766667017.8963482, "phase": "train", "update": 872, "total_env_steps": 2790400, "episode_reward": 0.3123950660228729, "value_loss": 0.010764086060225964, "policy_loss": -0.014191177536377116, "dist_entropy": 0.6316215952237447, "actor_grad_norm": 0.18001005053520203, "critic_grad_norm": 0.014917281456291676, "ratio": 0.9998841285705566, "entropy": 0.6316215952237447, "incre_win_rate": 0.7777777777777778, "step": 872}
{"time": 1766667022.202411, "phase": "train", "update": 873, "total_env_steps": 2793600, "episode_reward": 0.32513707876205444, "value_loss": 0.010384515797098478, "policy_loss": -0.01376150119018765, "dist_entropy": 0.6243014494578044, "actor_grad_norm": 0.1678401231765747, "critic_grad_norm": 0.026580920442938805, "ratio": 0.9990543127059937, "entropy": 0.6243014494578044, "incre_win_rate": 0.8333333333333334, "step": 873}
{"time": 1766667026.5461977, "phase": "train", "update": 874, "total_env_steps": 2796800, "episode_reward": 0.30361369252204895, "value_loss": 0.013393299033244451, "policy_loss": -0.013746624142027979, "dist_entropy": 0.6399439652760823, "actor_grad_norm": 0.15839308500289917, "critic_grad_norm": 0.027336489409208298, "ratio": 0.9999096393585205, "entropy": 0.6399439652760823, "incre_win_rate": 0.7222222222222222, "step": 874}
{"time": 1766667030.9061427, "phase": "train", "update": 875, "total_env_steps": 2800000, "episode_reward": 0.3143030107021332, "value_loss": 0.00900887002547582, "policy_loss": -0.012807113201980276, "dist_entropy": 0.6305334766705831, "actor_grad_norm": 0.13628514111042023, "critic_grad_norm": 0.027147112414240837, "ratio": 0.9997856616973877, "entropy": 0.6305334766705831, "incre_win_rate": 0.8431372549019608, "step": 875}
{"time": 1766667035.180428, "phase": "train", "update": 876, "total_env_steps": 2803200, "episode_reward": 0.299612432718277, "value_loss": 0.014080785152812799, "policy_loss": -0.013556457429615303, "dist_entropy": 0.6351930777231852, "actor_grad_norm": 0.14580462872982025, "critic_grad_norm": 0.020463062450289726, "ratio": 0.9988304376602173, "entropy": 0.6351930777231852, "incre_win_rate": 0.7358490566037735, "step": 876}
{"time": 1766667039.6919508, "phase": "train", "update": 877, "total_env_steps": 2806400, "episode_reward": 0.29334557056427, "value_loss": 0.01449205589791139, "policy_loss": -0.0155077623833221, "dist_entropy": 0.6360803683598836, "actor_grad_norm": 0.16519595682621002, "critic_grad_norm": 0.07053191214799881, "ratio": 0.998954713344574, "entropy": 0.6360803683598836, "incre_win_rate": 0.6153846153846154, "step": 877}
{"time": 1766667043.9142046, "phase": "train", "update": 878, "total_env_steps": 2809600, "episode_reward": 0.30296337604522705, "value_loss": 0.00957119216521581, "policy_loss": -0.013854772046950832, "dist_entropy": 0.6266941587130229, "actor_grad_norm": 0.15148866176605225, "critic_grad_norm": 0.03572695702314377, "ratio": 0.9996928572654724, "entropy": 0.6266941587130229, "incre_win_rate": 0.7592592592592593, "step": 878}
{"time": 1766667048.1311326, "phase": "train", "update": 879, "total_env_steps": 2812800, "episode_reward": 0.30768993496894836, "value_loss": 0.007788690365850925, "policy_loss": -0.014762221851994658, "dist_entropy": 0.6233372767766316, "actor_grad_norm": 0.1647743582725525, "critic_grad_norm": 0.06017712503671646, "ratio": 0.9998676776885986, "entropy": 0.6233372767766316, "incre_win_rate": 0.8775510204081632, "step": 879}
{"time": 1766667052.4465525, "phase": "train", "update": 880, "total_env_steps": 2816000, "episode_reward": 0.2868267595767975, "value_loss": 0.013021576777100563, "policy_loss": -0.01475993200254493, "dist_entropy": 0.643862803777059, "actor_grad_norm": 0.15977905690670013, "critic_grad_norm": 0.03539229929447174, "ratio": 0.9986206293106079, "entropy": 0.643862803777059, "incre_win_rate": 0.7, "step": 880}
{"time": 1766667056.7056758, "phase": "train", "update": 881, "total_env_steps": 2819200, "episode_reward": 0.3088197112083435, "value_loss": 0.009561761282384396, "policy_loss": -0.014266501730118838, "dist_entropy": 0.6377057075500489, "actor_grad_norm": 0.17669619619846344, "critic_grad_norm": 0.03194160386919975, "ratio": 1.0005128383636475, "entropy": 0.6377057075500489, "incre_win_rate": 0.7735849056603774, "step": 881}
{"time": 1766667064.6256294, "phase": "eval", "update": 881, "total_env_steps": 2819200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.667279411764707, "step": 881}
{"time": 1766667068.9914844, "phase": "train", "update": 882, "total_env_steps": 2822400, "episode_reward": 0.2921346426010132, "value_loss": 0.011763737288614113, "policy_loss": -0.014903627255571905, "dist_entropy": 0.6291784524917603, "actor_grad_norm": 0.14370165765285492, "critic_grad_norm": 0.028035342693328857, "ratio": 0.9981694221496582, "entropy": 0.6291784524917603, "incre_win_rate": 0.72, "step": 882}
{"time": 1766667073.2585967, "phase": "train", "update": 883, "total_env_steps": 2825600, "episode_reward": 0.303121954202652, "value_loss": 0.009780664493640264, "policy_loss": -0.014987335257672403, "dist_entropy": 0.640396789709727, "actor_grad_norm": 0.15006396174430847, "critic_grad_norm": 0.01657383143901825, "ratio": 0.9991840124130249, "entropy": 0.640396789709727, "incre_win_rate": 0.7647058823529411, "step": 883}
{"time": 1766667077.5494893, "phase": "train", "update": 884, "total_env_steps": 2828800, "episode_reward": 0.31440410017967224, "value_loss": 0.0073536228078107035, "policy_loss": -0.014303605717767216, "dist_entropy": 0.6488102753957112, "actor_grad_norm": 0.15093736350536346, "critic_grad_norm": 0.010437265038490295, "ratio": 0.9995844960212708, "entropy": 0.6488102753957112, "incre_win_rate": 0.8301886792452831, "step": 884}
{"time": 1766667081.8445067, "phase": "train", "update": 885, "total_env_steps": 2832000, "episode_reward": 0.3074800968170166, "value_loss": 0.008390871124962966, "policy_loss": -0.014054776047191098, "dist_entropy": 0.638129715124766, "actor_grad_norm": 0.15001703798770905, "critic_grad_norm": 0.013366942293941975, "ratio": 0.9981785416603088, "entropy": 0.638129715124766, "incre_win_rate": 0.7924528301886793, "step": 885}
{"time": 1766667086.1410704, "phase": "train", "update": 886, "total_env_steps": 2835200, "episode_reward": 0.31256434321403503, "value_loss": 0.010501307621598243, "policy_loss": -0.015382512028926007, "dist_entropy": 0.644665273030599, "actor_grad_norm": 0.17111973464488983, "critic_grad_norm": 0.015075234696269035, "ratio": 0.999210774898529, "entropy": 0.644665273030599, "incre_win_rate": 0.8627450980392157, "step": 886}
{"time": 1766667090.4670084, "phase": "train", "update": 887, "total_env_steps": 2838400, "episode_reward": 0.31241270899772644, "value_loss": 0.009449700762828191, "policy_loss": -0.014399206869308992, "dist_entropy": 0.6263384024302164, "actor_grad_norm": 0.14973828196525574, "critic_grad_norm": 0.017820531502366066, "ratio": 0.999131977558136, "entropy": 0.6263384024302164, "incre_win_rate": 0.7692307692307693, "step": 887}
{"time": 1766667094.7216856, "phase": "train", "update": 888, "total_env_steps": 2841600, "episode_reward": 0.3004074692726135, "value_loss": 0.010992392400900523, "policy_loss": -0.014643519043330382, "dist_entropy": 0.6444494009017945, "actor_grad_norm": 0.15771272778511047, "critic_grad_norm": 0.020685866475105286, "ratio": 0.9986751675605774, "entropy": 0.6444494009017945, "incre_win_rate": 0.7592592592592593, "step": 888}
{"time": 1766667098.9995651, "phase": "train", "update": 889, "total_env_steps": 2844800, "episode_reward": 0.30924248695373535, "value_loss": 0.01269153809795777, "policy_loss": -0.014648893660422383, "dist_entropy": 0.6276130159695943, "actor_grad_norm": 0.16681939363479614, "critic_grad_norm": 0.024299584329128265, "ratio": 0.9999421238899231, "entropy": 0.6276130159695943, "incre_win_rate": 0.7692307692307693, "step": 889}
{"time": 1766667103.3130856, "phase": "train", "update": 890, "total_env_steps": 2848000, "episode_reward": 0.3038955628871918, "value_loss": 0.010835069169600805, "policy_loss": -0.014050635354599687, "dist_entropy": 0.6354251980781556, "actor_grad_norm": 0.15031377971172333, "critic_grad_norm": 0.020763874053955078, "ratio": 1.000311255455017, "entropy": 0.6354251980781556, "incre_win_rate": 0.7843137254901961, "step": 890}
{"time": 1766667107.5816638, "phase": "train", "update": 891, "total_env_steps": 2851200, "episode_reward": 0.29798561334609985, "value_loss": 0.011408177701135476, "policy_loss": -0.014698574102792843, "dist_entropy": 0.6386086543401083, "actor_grad_norm": 0.17206770181655884, "critic_grad_norm": 0.036017682403326035, "ratio": 1.0009061098098755, "entropy": 0.6386086543401083, "incre_win_rate": 0.7592592592592593, "step": 891}
{"time": 1766667111.8897917, "phase": "train", "update": 892, "total_env_steps": 2854400, "episode_reward": 0.29895222187042236, "value_loss": 0.012553690498073896, "policy_loss": -0.01445110173795996, "dist_entropy": 0.643352480729421, "actor_grad_norm": 0.20448477566242218, "critic_grad_norm": 0.02555018849670887, "ratio": 0.9983625411987305, "entropy": 0.643352480729421, "incre_win_rate": 0.7959183673469388, "step": 892}
{"time": 1766667116.1662867, "phase": "train", "update": 893, "total_env_steps": 2857600, "episode_reward": 0.3172258138656616, "value_loss": 0.00862135567391912, "policy_loss": -0.014123555538011583, "dist_entropy": 0.6152444879213969, "actor_grad_norm": 0.19305163621902466, "critic_grad_norm": 0.03693344071507454, "ratio": 0.9988377690315247, "entropy": 0.6152444879213969, "incre_win_rate": 0.7592592592592593, "step": 893}
{"time": 1766667120.45674, "phase": "train", "update": 894, "total_env_steps": 2860800, "episode_reward": 0.3291391134262085, "value_loss": 0.007260667470594247, "policy_loss": -0.013173336081593826, "dist_entropy": 0.6151970664660136, "actor_grad_norm": 0.15187355875968933, "critic_grad_norm": 0.03397241234779358, "ratio": 0.999004602432251, "entropy": 0.6151970664660136, "incre_win_rate": 0.8571428571428571, "step": 894}
{"time": 1766667124.767285, "phase": "train", "update": 895, "total_env_steps": 2864000, "episode_reward": 0.33067479729652405, "value_loss": 0.008185266827543577, "policy_loss": -0.01289757318574516, "dist_entropy": 0.6073878685633342, "actor_grad_norm": 0.15670982003211975, "critic_grad_norm": 0.02479749731719494, "ratio": 1.0003888607025146, "entropy": 0.6073878685633342, "incre_win_rate": 0.8703703703703703, "step": 895}
{"time": 1766667129.04856, "phase": "train", "update": 896, "total_env_steps": 2867200, "episode_reward": 0.3285408914089203, "value_loss": 0.008436497797568639, "policy_loss": -0.012117894226232669, "dist_entropy": 0.6196288585662841, "actor_grad_norm": 0.14069002866744995, "critic_grad_norm": 0.024045346304774284, "ratio": 0.998852014541626, "entropy": 0.6196288585662841, "incre_win_rate": 0.8888888888888888, "step": 896}
{"time": 1766667133.331866, "phase": "train", "update": 897, "total_env_steps": 2870400, "episode_reward": 0.3084528148174286, "value_loss": 0.012368422622481981, "policy_loss": -0.014646640569543479, "dist_entropy": 0.6275097846984863, "actor_grad_norm": 0.1450948417186737, "critic_grad_norm": 0.044549137353897095, "ratio": 0.9995664358139038, "entropy": 0.6275097846984863, "incre_win_rate": 0.8113207547169812, "step": 897}
{"time": 1766667137.6311984, "phase": "train", "update": 898, "total_env_steps": 2873600, "episode_reward": 0.31210631132125854, "value_loss": 0.012153141821424166, "policy_loss": -0.012326991190321716, "dist_entropy": 0.6120365023612976, "actor_grad_norm": 0.1778344213962555, "critic_grad_norm": 0.022951476275920868, "ratio": 0.9998595714569092, "entropy": 0.6120365023612976, "incre_win_rate": 0.8076923076923077, "step": 898}
{"time": 1766667141.9683003, "phase": "train", "update": 899, "total_env_steps": 2876800, "episode_reward": 0.3284543454647064, "value_loss": 0.005879381950944662, "policy_loss": -0.014086447292854132, "dist_entropy": 0.6023842652638753, "actor_grad_norm": 0.15509067475795746, "critic_grad_norm": 0.04483224079012871, "ratio": 0.9979360103607178, "entropy": 0.6023842652638753, "incre_win_rate": 0.9074074074074074, "step": 899}
{"time": 1766667146.2311566, "phase": "train", "update": 900, "total_env_steps": 2880000, "episode_reward": 0.31429535150527954, "value_loss": 0.008002879687895377, "policy_loss": -0.012444688976232972, "dist_entropy": 0.6088205297787984, "actor_grad_norm": 0.15838119387626648, "critic_grad_norm": 0.021673662588000298, "ratio": 0.9997773170471191, "entropy": 0.6088205297787984, "incre_win_rate": 0.8490566037735849, "step": 900}
{"time": 1766667150.5703752, "phase": "train", "update": 901, "total_env_steps": 2883200, "episode_reward": 0.3256579637527466, "value_loss": 0.008454206803192695, "policy_loss": -0.013230896121607575, "dist_entropy": 0.6048584739367168, "actor_grad_norm": 0.13762167096138, "critic_grad_norm": 0.01336176972836256, "ratio": 0.999313235282898, "entropy": 0.6048584739367168, "incre_win_rate": 0.8518518518518519, "step": 901}
{"time": 1766667158.0725245, "phase": "eval", "update": 901, "total_env_steps": 2883200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.883808210784316, "step": 901}
{"time": 1766667162.3819408, "phase": "train", "update": 902, "total_env_steps": 2886400, "episode_reward": 0.3237951993942261, "value_loss": 0.007985075128575166, "policy_loss": -0.01244023784304676, "dist_entropy": 0.6221470435460409, "actor_grad_norm": 0.14258714020252228, "critic_grad_norm": 0.013223690912127495, "ratio": 1.0003485679626465, "entropy": 0.6221470435460409, "incre_win_rate": 0.9056603773584906, "step": 902}
{"time": 1766667166.5815482, "phase": "train", "update": 903, "total_env_steps": 2889600, "episode_reward": 0.29079732298851013, "value_loss": 0.010231689239541689, "policy_loss": -0.013986380821060606, "dist_entropy": 0.6040294647216797, "actor_grad_norm": 0.13626731932163239, "critic_grad_norm": 0.032061900943517685, "ratio": 1.0001840591430664, "entropy": 0.6040294647216797, "incre_win_rate": 0.6666666666666666, "step": 903}
{"time": 1766667170.8792984, "phase": "train", "update": 904, "total_env_steps": 2892800, "episode_reward": 0.33288756012916565, "value_loss": 0.0064980033474663895, "policy_loss": -0.012194073963649998, "dist_entropy": 0.6267380396525065, "actor_grad_norm": 0.12577687203884125, "critic_grad_norm": 0.04012080281972885, "ratio": 0.9992184638977051, "entropy": 0.6267380396525065, "incre_win_rate": 0.9259259259259259, "step": 904}
{"time": 1766667175.1316032, "phase": "train", "update": 905, "total_env_steps": 2896000, "episode_reward": 0.3077198266983032, "value_loss": 0.007030063526084026, "policy_loss": -0.01304635809527254, "dist_entropy": 0.6469640771547953, "actor_grad_norm": 0.15138386189937592, "critic_grad_norm": 0.02112213522195816, "ratio": 0.9995969533920288, "entropy": 0.6469640771547953, "incre_win_rate": 0.8653846153846154, "step": 905}
{"time": 1766667179.3649566, "phase": "train", "update": 906, "total_env_steps": 2899200, "episode_reward": 0.30647748708724976, "value_loss": 0.009058145185311636, "policy_loss": -0.013343580579409793, "dist_entropy": 0.630713701248169, "actor_grad_norm": 0.14600595831871033, "critic_grad_norm": 0.03211177885532379, "ratio": 1.0009150505065918, "entropy": 0.630713701248169, "incre_win_rate": 0.8113207547169812, "step": 906}
{"time": 1766667183.6410015, "phase": "train", "update": 907, "total_env_steps": 2902400, "episode_reward": 0.2989805340766907, "value_loss": 0.009935551757613818, "policy_loss": -0.014567744531224966, "dist_entropy": 0.6233478625615437, "actor_grad_norm": 0.14808228611946106, "critic_grad_norm": 0.02706235460937023, "ratio": 0.9994889497756958, "entropy": 0.6233478625615437, "incre_win_rate": 0.7708333333333334, "step": 907}
{"time": 1766667187.8684032, "phase": "train", "update": 908, "total_env_steps": 2905600, "episode_reward": 0.3223552405834198, "value_loss": 0.007126628203938405, "policy_loss": -0.013939175319948541, "dist_entropy": 0.6289255221684774, "actor_grad_norm": 0.1529303789138794, "critic_grad_norm": 0.035428449511528015, "ratio": 0.9982734322547913, "entropy": 0.6289255221684774, "incre_win_rate": 0.8867924528301887, "step": 908}
{"time": 1766667192.107046, "phase": "train", "update": 909, "total_env_steps": 2908800, "episode_reward": 0.3148215413093567, "value_loss": 0.009333344424764316, "policy_loss": -0.015164533080471188, "dist_entropy": 0.6393427570660909, "actor_grad_norm": 0.16286985576152802, "critic_grad_norm": 0.02408255822956562, "ratio": 1.0008140802383423, "entropy": 0.6393427570660909, "incre_win_rate": 0.8363636363636363, "step": 909}
{"time": 1766667196.327153, "phase": "train", "update": 910, "total_env_steps": 2912000, "episode_reward": 0.3062545657157898, "value_loss": 0.010464801825582981, "policy_loss": -0.014034919023691828, "dist_entropy": 0.6222273786862691, "actor_grad_norm": 0.14073725044727325, "critic_grad_norm": 0.029621044173836708, "ratio": 0.9995489120483398, "entropy": 0.6222273786862691, "incre_win_rate": 0.7307692307692307, "step": 910}
{"time": 1766667200.5209544, "phase": "train", "update": 911, "total_env_steps": 2915200, "episode_reward": 0.3058770000934601, "value_loss": 0.007806634933998188, "policy_loss": -0.013388449977137003, "dist_entropy": 0.6111316243807475, "actor_grad_norm": 0.13502199947834015, "critic_grad_norm": 0.013905739411711693, "ratio": 0.9991448521614075, "entropy": 0.6111316243807475, "incre_win_rate": 0.8269230769230769, "step": 911}
{"time": 1766667204.789827, "phase": "train", "update": 912, "total_env_steps": 2918400, "episode_reward": 0.3254687488079071, "value_loss": 0.009002714231610299, "policy_loss": -0.012450226155398288, "dist_entropy": 0.6089183767636617, "actor_grad_norm": 0.16889002919197083, "critic_grad_norm": 0.037599869072437286, "ratio": 0.9995103478431702, "entropy": 0.6089183767636617, "incre_win_rate": 0.8181818181818182, "step": 912}
{"time": 1766667209.0346951, "phase": "train", "update": 913, "total_env_steps": 2921600, "episode_reward": 0.31608685851097107, "value_loss": 0.010835884387294452, "policy_loss": -0.013747116298397562, "dist_entropy": 0.6051740288734436, "actor_grad_norm": 0.1593754142522812, "critic_grad_norm": 0.026529153808951378, "ratio": 0.9988794326782227, "entropy": 0.6051740288734436, "incre_win_rate": 0.7592592592592593, "step": 913}
{"time": 1766667213.2971842, "phase": "train", "update": 914, "total_env_steps": 2924800, "episode_reward": 0.31938037276268005, "value_loss": 0.009211007133126259, "policy_loss": -0.012202169089362277, "dist_entropy": 0.6226656635602316, "actor_grad_norm": 0.13954558968544006, "critic_grad_norm": 0.016784658655524254, "ratio": 1.0004193782806396, "entropy": 0.6226656635602316, "incre_win_rate": 0.8888888888888888, "step": 914}
{"time": 1766667217.5126019, "phase": "train", "update": 915, "total_env_steps": 2928000, "episode_reward": 0.31585705280303955, "value_loss": 0.01023920780668656, "policy_loss": -0.01270395289653076, "dist_entropy": 0.626239546140035, "actor_grad_norm": 0.14456886053085327, "critic_grad_norm": 0.019990306347608566, "ratio": 1.0006191730499268, "entropy": 0.626239546140035, "incre_win_rate": 0.8431372549019608, "step": 915}
{"time": 1766667221.8038175, "phase": "train", "update": 916, "total_env_steps": 2931200, "episode_reward": 0.32128143310546875, "value_loss": 0.006168407574295998, "policy_loss": -0.012420076760194357, "dist_entropy": 0.6224955002466838, "actor_grad_norm": 0.14551129937171936, "critic_grad_norm": 0.027454623952507973, "ratio": 0.9995717406272888, "entropy": 0.6224955002466838, "incre_win_rate": 0.8846153846153846, "step": 916}
{"time": 1766667226.0858252, "phase": "train", "update": 917, "total_env_steps": 2934400, "episode_reward": 0.32587316632270813, "value_loss": 0.007755112585922082, "policy_loss": -0.012130247830534084, "dist_entropy": 0.6125397364298503, "actor_grad_norm": 0.1401466280221939, "critic_grad_norm": 0.015167386271059513, "ratio": 1.0002837181091309, "entropy": 0.6125397364298503, "incre_win_rate": 0.875, "step": 917}
{"time": 1766667230.2939484, "phase": "train", "update": 918, "total_env_steps": 2937600, "episode_reward": 0.28683826327323914, "value_loss": 0.010386228933930397, "policy_loss": -0.013452724995158387, "dist_entropy": 0.6220271547635396, "actor_grad_norm": 0.17588847875595093, "critic_grad_norm": 0.027159156277775764, "ratio": 0.9999667406082153, "entropy": 0.6220271547635396, "incre_win_rate": 0.7708333333333334, "step": 918}
{"time": 1766667234.5782278, "phase": "train", "update": 919, "total_env_steps": 2940800, "episode_reward": 0.3190762996673584, "value_loss": 0.008311641278366248, "policy_loss": -0.012243163608052518, "dist_entropy": 0.6262056390444438, "actor_grad_norm": 0.13469259440898895, "critic_grad_norm": 0.020711107179522514, "ratio": 0.9987089037895203, "entropy": 0.6262056390444438, "incre_win_rate": 0.8148148148148148, "step": 919}
{"time": 1766667238.7990425, "phase": "train", "update": 920, "total_env_steps": 2944000, "episode_reward": 0.3023230731487274, "value_loss": 0.009620697361727555, "policy_loss": -0.013566289663095196, "dist_entropy": 0.6368205626805623, "actor_grad_norm": 0.13987751305103302, "critic_grad_norm": 0.030779466032981873, "ratio": 0.9993686676025391, "entropy": 0.6368205626805623, "incre_win_rate": 0.7547169811320755, "step": 920}
{"time": 1766667243.07285, "phase": "train", "update": 921, "total_env_steps": 2947200, "episode_reward": 0.30528876185417175, "value_loss": 0.010790727411707243, "policy_loss": -0.014162365689736412, "dist_entropy": 0.6143634557723999, "actor_grad_norm": 0.142160102725029, "critic_grad_norm": 0.03276336193084717, "ratio": 0.9998425841331482, "entropy": 0.6143634557723999, "incre_win_rate": 0.7843137254901961, "step": 921}
{"time": 1766667250.9194772, "phase": "eval", "update": 921, "total_env_steps": 2947200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.742800245098042, "step": 921}
{"time": 1766667255.2078483, "phase": "train", "update": 922, "total_env_steps": 2950400, "episode_reward": 0.3214024007320404, "value_loss": 0.008345878931383293, "policy_loss": -0.013910627595297716, "dist_entropy": 0.6360711336135865, "actor_grad_norm": 0.16194288432598114, "critic_grad_norm": 0.030413780361413956, "ratio": 0.9993429780006409, "entropy": 0.6360711336135865, "incre_win_rate": 0.8679245283018868, "step": 922}
{"time": 1766667259.4360328, "phase": "train", "update": 923, "total_env_steps": 2953600, "episode_reward": 0.3125505745410919, "value_loss": 0.008949110346535841, "policy_loss": -0.014640277100610888, "dist_entropy": 0.6361303846041362, "actor_grad_norm": 0.14270733296871185, "critic_grad_norm": 0.023200295865535736, "ratio": 0.9988007545471191, "entropy": 0.6361303846041362, "incre_win_rate": 0.7962962962962963, "step": 923}
{"time": 1766667263.7352185, "phase": "train", "update": 924, "total_env_steps": 2956800, "episode_reward": 0.3055882453918457, "value_loss": 0.010374966139594714, "policy_loss": -0.013386296708185105, "dist_entropy": 0.6388533035914103, "actor_grad_norm": 0.14943058788776398, "critic_grad_norm": 0.018175611272454262, "ratio": 1.0014251470565796, "entropy": 0.6388533035914103, "incre_win_rate": 0.8076923076923077, "step": 924}
{"time": 1766667267.997595, "phase": "train", "update": 925, "total_env_steps": 2960000, "episode_reward": 0.32174405455589294, "value_loss": 0.006905656183759371, "policy_loss": -0.012982823333229969, "dist_entropy": 0.6193747003873189, "actor_grad_norm": 0.15312319993972778, "critic_grad_norm": 0.012777440249919891, "ratio": 0.9994458556175232, "entropy": 0.6193747003873189, "incre_win_rate": 0.8461538461538461, "step": 925}
{"time": 1766667272.2480903, "phase": "train", "update": 926, "total_env_steps": 2963200, "episode_reward": 0.3194431662559509, "value_loss": 0.007023090682923794, "policy_loss": -0.013666554183128454, "dist_entropy": 0.6305486400922139, "actor_grad_norm": 0.15054520964622498, "critic_grad_norm": 0.013096900656819344, "ratio": 1.0013363361358643, "entropy": 0.6305486400922139, "incre_win_rate": 0.8653846153846154, "step": 926}
{"time": 1766667276.52437, "phase": "train", "update": 927, "total_env_steps": 2966400, "episode_reward": 0.3063817620277405, "value_loss": 0.007570457489540179, "policy_loss": -0.012658509329629909, "dist_entropy": 0.6331192334493001, "actor_grad_norm": 0.139618918299675, "critic_grad_norm": 0.020978588610887527, "ratio": 1.0000346899032593, "entropy": 0.6331192334493001, "incre_win_rate": 0.8461538461538461, "step": 927}
{"time": 1766667280.8011525, "phase": "train", "update": 928, "total_env_steps": 2969600, "episode_reward": 0.3082199692726135, "value_loss": 0.009632203541696072, "policy_loss": -0.014120394341847486, "dist_entropy": 0.5985405643781027, "actor_grad_norm": 0.14870277047157288, "critic_grad_norm": 0.031890757381916046, "ratio": 0.9995424151420593, "entropy": 0.5985405643781027, "incre_win_rate": 0.75, "step": 928}
{"time": 1766667285.121016, "phase": "train", "update": 929, "total_env_steps": 2972800, "episode_reward": 0.3104135990142822, "value_loss": 0.008424929343163967, "policy_loss": -0.013326017881718855, "dist_entropy": 0.6238098065058391, "actor_grad_norm": 0.16639181971549988, "critic_grad_norm": 0.01731923595070839, "ratio": 0.9990481734275818, "entropy": 0.6238098065058391, "incre_win_rate": 0.8490566037735849, "step": 929}
{"time": 1766667289.393157, "phase": "train", "update": 930, "total_env_steps": 2976000, "episode_reward": 0.3274739682674408, "value_loss": 0.005168169302244981, "policy_loss": -0.0148210806154097, "dist_entropy": 0.5963351806004842, "actor_grad_norm": 0.16319698095321655, "critic_grad_norm": 0.03303520008921623, "ratio": 0.9981127977371216, "entropy": 0.5963351806004842, "incre_win_rate": 0.8703703703703703, "step": 930}
{"time": 1766667293.7193556, "phase": "train", "update": 931, "total_env_steps": 2979200, "episode_reward": 0.3025926649570465, "value_loss": 0.010187885848184426, "policy_loss": -0.013861628654783745, "dist_entropy": 0.6272385636965434, "actor_grad_norm": 0.13875482976436615, "critic_grad_norm": 0.04774521291255951, "ratio": 0.9988681674003601, "entropy": 0.6272385636965434, "incre_win_rate": 0.7777777777777778, "step": 931}
{"time": 1766667298.0199883, "phase": "train", "update": 932, "total_env_steps": 2982400, "episode_reward": 0.3255078196525574, "value_loss": 0.010621708631515504, "policy_loss": -0.012975761243867604, "dist_entropy": 0.5974389712015787, "actor_grad_norm": 0.13905425369739532, "critic_grad_norm": 0.04399000480771065, "ratio": 0.9992286562919617, "entropy": 0.5974389712015787, "incre_win_rate": 0.7962962962962963, "step": 932}
{"time": 1766667302.424517, "phase": "train", "update": 933, "total_env_steps": 2985600, "episode_reward": 0.33288219571113586, "value_loss": 0.007974758123358091, "policy_loss": -0.01250989240756617, "dist_entropy": 0.6151670336723327, "actor_grad_norm": 0.13133402168750763, "critic_grad_norm": 0.04098329693078995, "ratio": 1.0001672506332397, "entropy": 0.6151670336723327, "incre_win_rate": 0.9038461538461539, "step": 933}
{"time": 1766667306.7145815, "phase": "train", "update": 934, "total_env_steps": 2988800, "episode_reward": 0.31393077969551086, "value_loss": 0.010537588658432165, "policy_loss": -0.013411349748005582, "dist_entropy": 0.6037134329477946, "actor_grad_norm": 0.14535467326641083, "critic_grad_norm": 0.036611225455999374, "ratio": 0.9992870688438416, "entropy": 0.6037134329477946, "incre_win_rate": 0.7818181818181819, "step": 934}
{"time": 1766667310.9212313, "phase": "train", "update": 935, "total_env_steps": 2992000, "episode_reward": 0.32747015357017517, "value_loss": 0.007348914879063765, "policy_loss": -0.012503084240535145, "dist_entropy": 0.6198035081227621, "actor_grad_norm": 0.17835171520709991, "critic_grad_norm": 0.02369712106883526, "ratio": 1.0005431175231934, "entropy": 0.6198035081227621, "incre_win_rate": 0.8181818181818182, "step": 935}
{"time": 1766667315.244166, "phase": "train", "update": 936, "total_env_steps": 2995200, "episode_reward": 0.3297242522239685, "value_loss": 0.008194502349942923, "policy_loss": -0.013715331046791353, "dist_entropy": 0.6002247373263041, "actor_grad_norm": 0.1628393530845642, "critic_grad_norm": 0.022882286459207535, "ratio": 0.9993963241577148, "entropy": 0.6002247373263041, "incre_win_rate": 0.8392857142857143, "step": 936}
{"time": 1766667319.5105784, "phase": "train", "update": 937, "total_env_steps": 2998400, "episode_reward": 0.3252841830253601, "value_loss": 0.011053077628215153, "policy_loss": -0.012687474249090277, "dist_entropy": 0.617209506034851, "actor_grad_norm": 0.16128787398338318, "critic_grad_norm": 0.0203800518065691, "ratio": 0.9997518062591553, "entropy": 0.617209506034851, "incre_win_rate": 0.8214285714285714, "step": 937}
{"time": 1766667323.830313, "phase": "train", "update": 938, "total_env_steps": 3001600, "episode_reward": 0.31748393177986145, "value_loss": 0.010818333054582277, "policy_loss": -0.01259449157601864, "dist_entropy": 0.6114396055539449, "actor_grad_norm": 0.15512065589427948, "critic_grad_norm": 0.018220920115709305, "ratio": 0.997918963432312, "entropy": 0.6114396055539449, "incre_win_rate": 0.7884615384615384, "step": 938}
{"time": 1766667328.1416473, "phase": "train", "update": 939, "total_env_steps": 3004800, "episode_reward": 0.3190609812736511, "value_loss": 0.009248374650875727, "policy_loss": -0.01383132628420943, "dist_entropy": 0.6261388778686523, "actor_grad_norm": 0.1546957939863205, "critic_grad_norm": 0.01565883867442608, "ratio": 0.9988936185836792, "entropy": 0.6261388778686523, "incre_win_rate": 0.8518518518518519, "step": 939}
{"time": 1766667332.4020085, "phase": "train", "update": 940, "total_env_steps": 3008000, "episode_reward": 0.32290980219841003, "value_loss": 0.009356261727710565, "policy_loss": -0.013467561893525234, "dist_entropy": 0.607412322362264, "actor_grad_norm": 0.13722240924835205, "critic_grad_norm": 0.02335163950920105, "ratio": 0.9997057914733887, "entropy": 0.607412322362264, "incre_win_rate": 0.8, "step": 940}
{"time": 1766667336.7653124, "phase": "train", "update": 941, "total_env_steps": 3011200, "episode_reward": 0.31944701075553894, "value_loss": 0.007685248274356127, "policy_loss": -0.01284662711318513, "dist_entropy": 0.6154409050941467, "actor_grad_norm": 0.13069714605808258, "critic_grad_norm": 0.024985507130622864, "ratio": 1.0002565383911133, "entropy": 0.6154409050941467, "incre_win_rate": 0.8679245283018868, "step": 941}
{"time": 1766667344.3461142, "phase": "eval", "update": 941, "total_env_steps": 3011200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.895526960784313, "step": 941}
{"time": 1766667348.5991251, "phase": "train", "update": 942, "total_env_steps": 3014400, "episode_reward": 0.31471431255340576, "value_loss": 0.009636666687826315, "policy_loss": -0.014214009616644792, "dist_entropy": 0.6177343924840292, "actor_grad_norm": 0.1351790726184845, "critic_grad_norm": 0.01670362800359726, "ratio": 0.9997729659080505, "entropy": 0.6177343924840292, "incre_win_rate": 0.7222222222222222, "step": 942}
{"time": 1766667352.8426168, "phase": "train", "update": 943, "total_env_steps": 3017600, "episode_reward": 0.32403111457824707, "value_loss": 0.008155359731366238, "policy_loss": -0.014968461680906901, "dist_entropy": 0.6193408648173014, "actor_grad_norm": 0.1494125872850418, "critic_grad_norm": 0.01684645563364029, "ratio": 0.9999630451202393, "entropy": 0.6193408648173014, "incre_win_rate": 0.8148148148148148, "step": 943}
{"time": 1766667357.0843422, "phase": "train", "update": 944, "total_env_steps": 3020800, "episode_reward": 0.32917967438697815, "value_loss": 0.0087703217441837, "policy_loss": -0.014168701743723961, "dist_entropy": 0.6356930375099182, "actor_grad_norm": 0.14081595838069916, "critic_grad_norm": 0.0186038576066494, "ratio": 1.0002096891403198, "entropy": 0.6356930375099182, "incre_win_rate": 0.8363636363636363, "step": 944}
{"time": 1766667361.383099, "phase": "train", "update": 945, "total_env_steps": 3024000, "episode_reward": 0.32927849888801575, "value_loss": 0.008090254633376997, "policy_loss": -0.011844386440931014, "dist_entropy": 0.6278442660967509, "actor_grad_norm": 0.13720153272151947, "critic_grad_norm": 0.020261278375983238, "ratio": 1.0006375312805176, "entropy": 0.6278442660967509, "incre_win_rate": 0.8909090909090909, "step": 945}
{"time": 1766667365.6878257, "phase": "train", "update": 946, "total_env_steps": 3027200, "episode_reward": 0.3207758963108063, "value_loss": 0.012006465283532938, "policy_loss": -0.014081504563022425, "dist_entropy": 0.6246381878852845, "actor_grad_norm": 0.14723189175128937, "critic_grad_norm": 0.02958977036178112, "ratio": 1.0007127523422241, "entropy": 0.6246381878852845, "incre_win_rate": 0.7962962962962963, "step": 946}
{"time": 1766667370.0583477, "phase": "train", "update": 947, "total_env_steps": 3030400, "episode_reward": 0.3326148986816406, "value_loss": 0.008118740127732357, "policy_loss": -0.013062789078815721, "dist_entropy": 0.6282919406890869, "actor_grad_norm": 0.14366880059242249, "critic_grad_norm": 0.026626314967870712, "ratio": 0.9985008239746094, "entropy": 0.6282919406890869, "incre_win_rate": 0.9285714285714286, "step": 947}
{"time": 1766667374.534607, "phase": "train", "update": 948, "total_env_steps": 3033600, "episode_reward": 0.3224601745605469, "value_loss": 0.006627583441634973, "policy_loss": -0.012792516985568152, "dist_entropy": 0.602941902478536, "actor_grad_norm": 0.14479796588420868, "critic_grad_norm": 0.017603261396288872, "ratio": 0.9997531771659851, "entropy": 0.602941902478536, "incre_win_rate": 0.8867924528301887, "step": 948}
{"time": 1766667379.1840236, "phase": "train", "update": 949, "total_env_steps": 3036800, "episode_reward": 0.29947149753570557, "value_loss": 0.00841509560123086, "policy_loss": -0.01450221052518046, "dist_entropy": 0.6130265355110168, "actor_grad_norm": 0.14265866577625275, "critic_grad_norm": 0.028484968468546867, "ratio": 1.0006417036056519, "entropy": 0.6130265355110168, "incre_win_rate": 0.7551020408163265, "step": 949}
{"time": 1766667384.051426, "phase": "train", "update": 950, "total_env_steps": 3040000, "episode_reward": 0.3201899528503418, "value_loss": 0.010086037715276082, "policy_loss": -0.01253798138110156, "dist_entropy": 0.6240586439768473, "actor_grad_norm": 0.13429546356201172, "critic_grad_norm": 0.025179622694849968, "ratio": 0.9986677169799805, "entropy": 0.6240586439768473, "incre_win_rate": 0.8333333333333334, "step": 950}
{"time": 1766667388.6586506, "phase": "train", "update": 951, "total_env_steps": 3043200, "episode_reward": 0.3180277347564697, "value_loss": 0.007996300049126149, "policy_loss": -0.014576935903484885, "dist_entropy": 0.6105339328447977, "actor_grad_norm": 0.1523391455411911, "critic_grad_norm": 0.014498510397970676, "ratio": 0.9989914298057556, "entropy": 0.6105339328447977, "incre_win_rate": 0.8333333333333334, "step": 951}
{"time": 1766667394.1754, "phase": "train", "update": 952, "total_env_steps": 3046400, "episode_reward": 0.32430610060691833, "value_loss": 0.008436243049800396, "policy_loss": -0.01272875819258464, "dist_entropy": 0.6193379561106364, "actor_grad_norm": 0.15027081966400146, "critic_grad_norm": 0.015509440563619137, "ratio": 0.9989122152328491, "entropy": 0.6193379561106364, "incre_win_rate": 0.8571428571428571, "step": 952}
{"time": 1766667398.6225436, "phase": "train", "update": 953, "total_env_steps": 3049600, "episode_reward": 0.3318099081516266, "value_loss": 0.0050420506236453855, "policy_loss": -0.013353822299652051, "dist_entropy": 0.5969168702761333, "actor_grad_norm": 0.12665972113609314, "critic_grad_norm": 0.02655204012989998, "ratio": 0.9989448189735413, "entropy": 0.5969168702761333, "incre_win_rate": 0.9259259259259259, "step": 953}
{"time": 1766667402.922409, "phase": "train", "update": 954, "total_env_steps": 3052800, "episode_reward": 0.3379036784172058, "value_loss": 0.00410572273346285, "policy_loss": -0.013299096931222701, "dist_entropy": 0.5872194449106852, "actor_grad_norm": 0.13393208384513855, "critic_grad_norm": 0.023997880518436432, "ratio": 0.9994344115257263, "entropy": 0.5872194449106852, "incre_win_rate": 0.9444444444444444, "step": 954}
{"time": 1766667407.360002, "phase": "train", "update": 955, "total_env_steps": 3056000, "episode_reward": 0.34796568751335144, "value_loss": 0.003211369862159093, "policy_loss": -0.011849600630245878, "dist_entropy": 0.5905729134877523, "actor_grad_norm": 0.12882328033447266, "critic_grad_norm": 0.016664603725075722, "ratio": 0.9991204738616943, "entropy": 0.5905729134877523, "incre_win_rate": 1.0, "step": 955}
{"time": 1766667411.7120738, "phase": "train", "update": 956, "total_env_steps": 3059200, "episode_reward": 0.3466850519180298, "value_loss": 0.0035896543723841507, "policy_loss": -0.01064299849220139, "dist_entropy": 0.5968600432078044, "actor_grad_norm": 0.12064440548419952, "critic_grad_norm": 0.012156405486166477, "ratio": 0.9991026520729065, "entropy": 0.5968600432078044, "incre_win_rate": 0.9464285714285714, "step": 956}
{"time": 1766667416.046814, "phase": "train", "update": 957, "total_env_steps": 3062400, "episode_reward": 0.3492662310600281, "value_loss": 0.005139321616540352, "policy_loss": -0.013142091396198907, "dist_entropy": 0.5835910479227702, "actor_grad_norm": 0.13239213824272156, "critic_grad_norm": 0.017141234129667282, "ratio": 1.0006307363510132, "entropy": 0.5835910479227702, "incre_win_rate": 0.9298245614035088, "step": 957}
{"time": 1766667420.4320302, "phase": "train", "update": 958, "total_env_steps": 3065600, "episode_reward": 0.33912914991378784, "value_loss": 0.008697253496696552, "policy_loss": -0.011815454350652507, "dist_entropy": 0.5659505963325501, "actor_grad_norm": 0.12877751886844635, "critic_grad_norm": 0.060550183057785034, "ratio": 1.000268578529358, "entropy": 0.5659505963325501, "incre_win_rate": 0.847457627118644, "step": 958}
{"time": 1766667424.7913182, "phase": "train", "update": 959, "total_env_steps": 3068800, "episode_reward": 0.3325467109680176, "value_loss": 0.006215432348350684, "policy_loss": -0.012301935935654266, "dist_entropy": 0.5962648232777913, "actor_grad_norm": 0.14262837171554565, "critic_grad_norm": 0.042020346969366074, "ratio": 1.000562310218811, "entropy": 0.5962648232777913, "incre_win_rate": 0.8727272727272727, "step": 959}
{"time": 1766667429.1971025, "phase": "train", "update": 960, "total_env_steps": 3072000, "episode_reward": 0.33008426427841187, "value_loss": 0.009156482542554538, "policy_loss": -0.012130553487044438, "dist_entropy": 0.5926748911539713, "actor_grad_norm": 0.1403399258852005, "critic_grad_norm": 0.04657772183418274, "ratio": 0.9995883107185364, "entropy": 0.5926748911539713, "incre_win_rate": 0.8035714285714286, "step": 960}
{"time": 1766667433.4943302, "phase": "train", "update": 961, "total_env_steps": 3075200, "episode_reward": 0.33839771151542664, "value_loss": 0.006110322879006465, "policy_loss": -0.01196255913096517, "dist_entropy": 0.5880324165026347, "actor_grad_norm": 0.15093892812728882, "critic_grad_norm": 0.04145453870296478, "ratio": 0.9988765716552734, "entropy": 0.5880324165026347, "incre_win_rate": 0.8947368421052632, "step": 961}
{"time": 1766667440.8670712, "phase": "eval", "update": 961, "total_env_steps": 3075200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.49984681372549, "step": 961}
{"time": 1766667445.192265, "phase": "train", "update": 962, "total_env_steps": 3078400, "episode_reward": 0.3226516842842102, "value_loss": 0.009456444655855496, "policy_loss": -0.012349983357786224, "dist_entropy": 0.5945102373758951, "actor_grad_norm": 0.1426791399717331, "critic_grad_norm": 0.02337179332971573, "ratio": 0.9998947381973267, "entropy": 0.5945102373758951, "incre_win_rate": 0.8235294117647058, "step": 962}
{"time": 1766667449.470217, "phase": "train", "update": 963, "total_env_steps": 3081600, "episode_reward": 0.33606085181236267, "value_loss": 0.008012718179573615, "policy_loss": -0.012279307382998657, "dist_entropy": 0.5835822621981303, "actor_grad_norm": 0.17384955286979675, "critic_grad_norm": 0.016369109973311424, "ratio": 1.000573754310608, "entropy": 0.5835822621981303, "incre_win_rate": 0.8275862068965517, "step": 963}
{"time": 1766667453.7713594, "phase": "train", "update": 964, "total_env_steps": 3084800, "episode_reward": 0.32011258602142334, "value_loss": 0.00877604279667139, "policy_loss": -0.013136943605331434, "dist_entropy": 0.5900144020716349, "actor_grad_norm": 0.14395152032375336, "critic_grad_norm": 0.017363648861646652, "ratio": 0.9997113347053528, "entropy": 0.5900144020716349, "incre_win_rate": 0.8490566037735849, "step": 964}
{"time": 1766667458.1748219, "phase": "train", "update": 965, "total_env_steps": 3088000, "episode_reward": 0.34476104378700256, "value_loss": 0.006417873781174421, "policy_loss": -0.01256610478227221, "dist_entropy": 0.603732681274414, "actor_grad_norm": 0.12881571054458618, "critic_grad_norm": 0.03003227896988392, "ratio": 0.9988377094268799, "entropy": 0.603732681274414, "incre_win_rate": 0.9285714285714286, "step": 965}
{"time": 1766667462.4990983, "phase": "train", "update": 966, "total_env_steps": 3091200, "episode_reward": 0.3452167809009552, "value_loss": 0.00652209222316742, "policy_loss": -0.012825248704804912, "dist_entropy": 0.6146780371665954, "actor_grad_norm": 0.1287747621536255, "critic_grad_norm": 0.01225260365754366, "ratio": 0.9995198249816895, "entropy": 0.6146780371665954, "incre_win_rate": 0.896551724137931, "step": 966}
{"time": 1766667466.8349185, "phase": "train", "update": 967, "total_env_steps": 3094400, "episode_reward": 0.34060049057006836, "value_loss": 0.010509743044773737, "policy_loss": -0.012693592973892009, "dist_entropy": 0.6174917499224345, "actor_grad_norm": 0.1440633237361908, "critic_grad_norm": 0.054523736238479614, "ratio": 1.0014705657958984, "entropy": 0.6174917499224345, "incre_win_rate": 0.8103448275862069, "step": 967}
{"time": 1766667471.1619866, "phase": "train", "update": 968, "total_env_steps": 3097600, "episode_reward": 0.3341881036758423, "value_loss": 0.006877500905344883, "policy_loss": -0.012742423043999196, "dist_entropy": 0.604870331287384, "actor_grad_norm": 0.12982970476150513, "critic_grad_norm": 0.0626896396279335, "ratio": 0.9973651170730591, "entropy": 0.604870331287384, "incre_win_rate": 0.8888888888888888, "step": 968}
{"time": 1766667475.4685078, "phase": "train", "update": 969, "total_env_steps": 3100800, "episode_reward": 0.33378297090530396, "value_loss": 0.005951189529150724, "policy_loss": -0.013455766364976777, "dist_entropy": 0.623405110836029, "actor_grad_norm": 0.1328590214252472, "critic_grad_norm": 0.022916529327630997, "ratio": 0.9991111755371094, "entropy": 0.623405110836029, "incre_win_rate": 0.9272727272727272, "step": 969}
{"time": 1766667479.7899776, "phase": "train", "update": 970, "total_env_steps": 3104000, "episode_reward": 0.32935357093811035, "value_loss": 0.006395777594298125, "policy_loss": -0.011914814549971335, "dist_entropy": 0.6076958219210307, "actor_grad_norm": 0.11548735946416855, "critic_grad_norm": 0.016050290316343307, "ratio": 0.9990941882133484, "entropy": 0.6076958219210307, "incre_win_rate": 0.8703703703703703, "step": 970}
{"time": 1766667484.095178, "phase": "train", "update": 971, "total_env_steps": 3107200, "episode_reward": 0.328997403383255, "value_loss": 0.006348447905232509, "policy_loss": -0.013200943549443877, "dist_entropy": 0.6195415536562602, "actor_grad_norm": 0.13453982770442963, "critic_grad_norm": 0.014337211847305298, "ratio": 1.0004668235778809, "entropy": 0.6195415536562602, "incre_win_rate": 0.9074074074074074, "step": 971}
{"time": 1766667488.4062986, "phase": "train", "update": 972, "total_env_steps": 3110400, "episode_reward": 0.31713157892227173, "value_loss": 0.012637735965351263, "policy_loss": -0.012557585281356864, "dist_entropy": 0.6097475210825603, "actor_grad_norm": 0.14065873622894287, "critic_grad_norm": 0.06203305348753929, "ratio": 1.0004125833511353, "entropy": 0.6097475210825603, "incre_win_rate": 0.7090909090909091, "step": 972}
{"time": 1766667492.7175121, "phase": "train", "update": 973, "total_env_steps": 3113600, "episode_reward": 0.3328332006931305, "value_loss": 0.008052936227371296, "policy_loss": -0.012601418054011522, "dist_entropy": 0.6208575050036113, "actor_grad_norm": 0.1481238156557083, "critic_grad_norm": 0.031286075711250305, "ratio": 1.0011959075927734, "entropy": 0.6208575050036113, "incre_win_rate": 0.9285714285714286, "step": 973}
{"time": 1766667497.073848, "phase": "train", "update": 974, "total_env_steps": 3116800, "episode_reward": 0.3404771685600281, "value_loss": 0.005279043565193812, "policy_loss": -0.013343835510449983, "dist_entropy": 0.6136685450871785, "actor_grad_norm": 0.13655683398246765, "critic_grad_norm": 0.059981830418109894, "ratio": 0.9996312260627747, "entropy": 0.6136685450871785, "incre_win_rate": 0.9107142857142857, "step": 974}
{"time": 1766667501.4147651, "phase": "train", "update": 975, "total_env_steps": 3120000, "episode_reward": 0.3203071355819702, "value_loss": 0.008904164532820384, "policy_loss": -0.01415094976002346, "dist_entropy": 0.6180515964825948, "actor_grad_norm": 0.15616987645626068, "critic_grad_norm": 0.030952103435993195, "ratio": 1.0002740621566772, "entropy": 0.6180515964825948, "incre_win_rate": 0.8490566037735849, "step": 975}
{"time": 1766667505.7453632, "phase": "train", "update": 976, "total_env_steps": 3123200, "episode_reward": 0.32314184308052063, "value_loss": 0.009167584031820298, "policy_loss": -0.01378680964204193, "dist_entropy": 0.5900582114855448, "actor_grad_norm": 0.1468985676765442, "critic_grad_norm": 0.016290811821818352, "ratio": 1.0007418394088745, "entropy": 0.5900582114855448, "incre_win_rate": 0.8, "step": 976}
{"time": 1766667510.0940788, "phase": "train", "update": 977, "total_env_steps": 3126400, "episode_reward": 0.3220994472503662, "value_loss": 0.008839400485157967, "policy_loss": -0.012247758586613837, "dist_entropy": 0.6203164855639139, "actor_grad_norm": 0.14780165255069733, "critic_grad_norm": 0.032076042145490646, "ratio": 1.0002835988998413, "entropy": 0.6203164855639139, "incre_win_rate": 0.8333333333333334, "step": 977}
{"time": 1766667514.3947432, "phase": "train", "update": 978, "total_env_steps": 3129600, "episode_reward": 0.3284313976764679, "value_loss": 0.007988298187653224, "policy_loss": -0.012338646471572663, "dist_entropy": 0.6183558980623881, "actor_grad_norm": 0.13354721665382385, "critic_grad_norm": 0.037672754377126694, "ratio": 0.998528242111206, "entropy": 0.6183558980623881, "incre_win_rate": 0.9433962264150944, "step": 978}
{"time": 1766667553.816108, "phase": "train", "update": 979, "total_env_steps": 3132800, "episode_reward": 0.31985294818878174, "value_loss": 0.04373707224925359, "policy_loss": -0.010632346983717867, "dist_entropy": 0.6072877844174703, "actor_grad_norm": 0.13546858727931976, "critic_grad_norm": 0.09635317325592041, "ratio": 1.0006103515625, "entropy": 0.6072877844174703, "incre_win_rate": 0.7884615384615384, "step": 979}
{"time": 1766667558.1429746, "phase": "train", "update": 980, "total_env_steps": 3136000, "episode_reward": 0.3241513669490814, "value_loss": 0.007235705107450485, "policy_loss": -0.01323348605301362, "dist_entropy": 0.6043794790903727, "actor_grad_norm": 0.16084572672843933, "critic_grad_norm": 0.06891398876905441, "ratio": 0.999980092048645, "entropy": 0.6043794790903727, "incre_win_rate": 0.8545454545454545, "step": 980}
{"time": 1766667562.4708219, "phase": "train", "update": 981, "total_env_steps": 3139200, "episode_reward": 0.32259729504585266, "value_loss": 0.006788216779629389, "policy_loss": -0.013067613187703752, "dist_entropy": 0.6161974350611369, "actor_grad_norm": 0.1319480538368225, "critic_grad_norm": 0.06948395818471909, "ratio": 0.9997519850730896, "entropy": 0.6161974350611369, "incre_win_rate": 0.9019607843137255, "step": 981}
{"time": 1766667570.4087186, "phase": "eval", "update": 981, "total_env_steps": 3139200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.9906556372549, "step": 981}
{"time": 1766667574.967569, "phase": "train", "update": 982, "total_env_steps": 3142400, "episode_reward": 0.3260355591773987, "value_loss": 0.009557930752635002, "policy_loss": -0.012421642835164448, "dist_entropy": 0.6027926802635193, "actor_grad_norm": 0.1383143663406372, "critic_grad_norm": 0.0313197560608387, "ratio": 1.0002434253692627, "entropy": 0.6027926802635193, "incre_win_rate": 0.8363636363636363, "step": 982}
{"time": 1766667579.6026382, "phase": "train", "update": 983, "total_env_steps": 3145600, "episode_reward": 0.3199111521244049, "value_loss": 0.010084471913675468, "policy_loss": -0.013563867585837386, "dist_entropy": 0.628437054157257, "actor_grad_norm": 0.152348130941391, "critic_grad_norm": 0.019895700737833977, "ratio": 0.998585045337677, "entropy": 0.628437054157257, "incre_win_rate": 0.7777777777777778, "step": 983}
{"time": 1766667584.3277962, "phase": "train", "update": 984, "total_env_steps": 3148800, "episode_reward": 0.3139468729496002, "value_loss": 0.009274803039928278, "policy_loss": -0.013426105178002483, "dist_entropy": 0.5999076088269552, "actor_grad_norm": 0.15008679032325745, "critic_grad_norm": 0.012731867842376232, "ratio": 1.0002962350845337, "entropy": 0.5999076088269552, "incre_win_rate": 0.7962962962962963, "step": 984}
{"time": 1766667589.167458, "phase": "train", "update": 985, "total_env_steps": 3152000, "episode_reward": 0.32557371258735657, "value_loss": 0.009099065388242403, "policy_loss": -0.01317118168165147, "dist_entropy": 0.6208159923553467, "actor_grad_norm": 0.13443678617477417, "critic_grad_norm": 0.019162481650710106, "ratio": 1.0007716417312622, "entropy": 0.6208159923553467, "incre_win_rate": 0.8703703703703703, "step": 985}
{"time": 1766667593.9673378, "phase": "train", "update": 986, "total_env_steps": 3155200, "episode_reward": 0.3251325190067291, "value_loss": 0.0083575915855666, "policy_loss": -0.013772619729396259, "dist_entropy": 0.6164971232414246, "actor_grad_norm": 0.15920987725257874, "critic_grad_norm": 0.014937016181647778, "ratio": 0.9996922016143799, "entropy": 0.6164971232414246, "incre_win_rate": 0.8181818181818182, "step": 986}
{"time": 1766667598.8530142, "phase": "train", "update": 987, "total_env_steps": 3158400, "episode_reward": 0.33446305990219116, "value_loss": 0.0074588022194802765, "policy_loss": -0.014695508162387702, "dist_entropy": 0.6150646487871806, "actor_grad_norm": 0.14186729490756989, "critic_grad_norm": 0.024114368483424187, "ratio": 0.9977198243141174, "entropy": 0.6150646487871806, "incre_win_rate": 0.9107142857142857, "step": 987}
{"time": 1766667603.392601, "phase": "train", "update": 988, "total_env_steps": 3161600, "episode_reward": 0.33466145396232605, "value_loss": 0.00893944688141346, "policy_loss": -0.014167845429418928, "dist_entropy": 0.6239237626393636, "actor_grad_norm": 0.13220831751823425, "critic_grad_norm": 0.018959520384669304, "ratio": 1.0002578496932983, "entropy": 0.6239237626393636, "incre_win_rate": 0.8545454545454545, "step": 988}
{"time": 1766667607.835983, "phase": "train", "update": 989, "total_env_steps": 3164800, "episode_reward": 0.3311213254928589, "value_loss": 0.007338620877514283, "policy_loss": -0.013040740554837763, "dist_entropy": 0.5935565670331319, "actor_grad_norm": 0.15936239063739777, "critic_grad_norm": 0.02009264938533306, "ratio": 1.000779390335083, "entropy": 0.5935565670331319, "incre_win_rate": 0.8703703703703703, "step": 989}
{"time": 1766667612.2402685, "phase": "train", "update": 990, "total_env_steps": 3168000, "episode_reward": 0.332303911447525, "value_loss": 0.008494183545311292, "policy_loss": -0.012659813774255587, "dist_entropy": 0.6056057095527649, "actor_grad_norm": 0.16622646152973175, "critic_grad_norm": 0.05186115950345993, "ratio": 1.0004284381866455, "entropy": 0.6056057095527649, "incre_win_rate": 0.8275862068965517, "step": 990}
{"time": 1766667616.8603837, "phase": "train", "update": 991, "total_env_steps": 3171200, "episode_reward": 0.33667048811912537, "value_loss": 0.007977988322575886, "policy_loss": -0.012414305603985732, "dist_entropy": 0.6144386529922485, "actor_grad_norm": 0.12565262615680695, "critic_grad_norm": 0.019593480974435806, "ratio": 1.0002436637878418, "entropy": 0.6144386529922485, "incre_win_rate": 0.9056603773584906, "step": 991}
{"time": 1766667621.505759, "phase": "train", "update": 992, "total_env_steps": 3174400, "episode_reward": 0.33396828174591064, "value_loss": 0.008097997059424718, "policy_loss": -0.014919739324795955, "dist_entropy": 0.6286061922709147, "actor_grad_norm": 0.15409347414970398, "critic_grad_norm": 0.014519457705318928, "ratio": 0.9990173578262329, "entropy": 0.6286061922709147, "incre_win_rate": 0.8596491228070176, "step": 992}
{"time": 1766667625.8640924, "phase": "train", "update": 993, "total_env_steps": 3177600, "episode_reward": 0.3180530369281769, "value_loss": 0.008099290200819571, "policy_loss": -0.012897435300031172, "dist_entropy": 0.6110063234965006, "actor_grad_norm": 0.13670021295547485, "critic_grad_norm": 0.02307993546128273, "ratio": 0.9989582300186157, "entropy": 0.6110063234965006, "incre_win_rate": 0.8235294117647058, "step": 993}
{"time": 1766667630.1908956, "phase": "train", "update": 994, "total_env_steps": 3180800, "episode_reward": 0.30910083651542664, "value_loss": 0.008996774380405744, "policy_loss": -0.013763094898803275, "dist_entropy": 0.606828236579895, "actor_grad_norm": 0.14700065553188324, "critic_grad_norm": 0.03644343465566635, "ratio": 0.9992173910140991, "entropy": 0.606828236579895, "incre_win_rate": 0.7592592592592593, "step": 994}
{"time": 1766667634.5701168, "phase": "train", "update": 995, "total_env_steps": 3184000, "episode_reward": 0.32378602027893066, "value_loss": 0.010520638277133306, "policy_loss": -0.013011388974526502, "dist_entropy": 0.609385081132253, "actor_grad_norm": 0.14519727230072021, "critic_grad_norm": 0.03675629198551178, "ratio": 0.9983738660812378, "entropy": 0.609385081132253, "incre_win_rate": 0.8363636363636363, "step": 995}
{"time": 1766667638.8984015, "phase": "train", "update": 996, "total_env_steps": 3187200, "episode_reward": 0.31716838479042053, "value_loss": 0.009292403298119704, "policy_loss": -0.014292905189329493, "dist_entropy": 0.6051537275314331, "actor_grad_norm": 0.14987237751483917, "critic_grad_norm": 0.022912761196494102, "ratio": 1.0009644031524658, "entropy": 0.6051537275314331, "incre_win_rate": 0.8148148148148148, "step": 996}
{"time": 1766667643.2346587, "phase": "train", "update": 997, "total_env_steps": 3190400, "episode_reward": 0.3218259811401367, "value_loss": 0.00754323514799277, "policy_loss": -0.013382823291085326, "dist_entropy": 0.6030048688252767, "actor_grad_norm": 0.14037247002124786, "critic_grad_norm": 0.019140155985951424, "ratio": 1.0021966695785522, "entropy": 0.6030048688252767, "incre_win_rate": 0.8269230769230769, "step": 997}
{"time": 1766667647.866226, "phase": "train", "update": 998, "total_env_steps": 3193600, "episode_reward": 0.3351960778236389, "value_loss": 0.007966991048306227, "policy_loss": -0.014819155732359708, "dist_entropy": 0.6154240051905314, "actor_grad_norm": 0.14906182885169983, "critic_grad_norm": 0.010806684382259846, "ratio": 0.9986072778701782, "entropy": 0.6154240051905314, "incre_win_rate": 0.8620689655172413, "step": 998}
{"time": 1766667652.2685928, "phase": "train", "update": 999, "total_env_steps": 3196800, "episode_reward": 0.3267141580581665, "value_loss": 0.010336468803385894, "policy_loss": -0.013994806791069436, "dist_entropy": 0.618839967250824, "actor_grad_norm": 0.15512295067310333, "critic_grad_norm": 0.03532699868083, "ratio": 1.0000462532043457, "entropy": 0.618839967250824, "incre_win_rate": 0.7454545454545455, "step": 999}
{"time": 1766667656.5628211, "phase": "train", "update": 1000, "total_env_steps": 3200000, "episode_reward": 0.33621326088905334, "value_loss": 0.007280413589129845, "policy_loss": -0.013040239441798463, "dist_entropy": 0.6193279345830282, "actor_grad_norm": 0.1233120709657669, "critic_grad_norm": 0.02252715267241001, "ratio": 0.9999072551727295, "entropy": 0.6193279345830282, "incre_win_rate": 0.8421052631578947, "step": 1000}
{"time": 1766667661.352737, "phase": "train", "update": 1001, "total_env_steps": 3203200, "episode_reward": 0.32505589723587036, "value_loss": 0.01128631941974163, "policy_loss": -0.012798466991770377, "dist_entropy": 0.6161964535713196, "actor_grad_norm": 0.13059960305690765, "critic_grad_norm": 0.04143522307276726, "ratio": 1.000765085220337, "entropy": 0.6161964535713196, "incre_win_rate": 0.8070175438596491, "step": 1001}
{"time": 1766667669.2702768, "phase": "eval", "update": 1001, "total_env_steps": 3203200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.686810661764707, "step": 1001}
{"time": 1766667673.9918, "phase": "train", "update": 1002, "total_env_steps": 3206400, "episode_reward": 0.3278171122074127, "value_loss": 0.01298621582488219, "policy_loss": -0.014545994936240921, "dist_entropy": 0.6396042545636494, "actor_grad_norm": 0.1534837782382965, "critic_grad_norm": 0.030795959755778313, "ratio": 0.9980767369270325, "entropy": 0.6396042545636494, "incre_win_rate": 0.7818181818181819, "step": 1002}
{"time": 1766667678.5605872, "phase": "train", "update": 1003, "total_env_steps": 3209600, "episode_reward": 0.3344416618347168, "value_loss": 0.011899014189839362, "policy_loss": -0.012928254371396027, "dist_entropy": 0.6169225096702575, "actor_grad_norm": 0.14409878849983215, "critic_grad_norm": 0.029422542080283165, "ratio": 0.9997364282608032, "entropy": 0.6169225096702575, "incre_win_rate": 0.8070175438596491, "step": 1003}
{"time": 1766667683.1609108, "phase": "train", "update": 1004, "total_env_steps": 3212800, "episode_reward": 0.3466850519180298, "value_loss": 0.006775243238856395, "policy_loss": -0.012803919291627016, "dist_entropy": 0.6108776370684306, "actor_grad_norm": 0.15243938565254211, "critic_grad_norm": 0.033383388072252274, "ratio": 0.9993575215339661, "entropy": 0.6108776370684306, "incre_win_rate": 0.9137931034482759, "step": 1004}
{"time": 1766667687.6868927, "phase": "train", "update": 1005, "total_env_steps": 3216000, "episode_reward": 0.34234222769737244, "value_loss": 0.008397759435077508, "policy_loss": -0.01376815655890849, "dist_entropy": 0.6045361240704854, "actor_grad_norm": 0.16930696368217468, "critic_grad_norm": 0.019675252959132195, "ratio": 0.9988599419593811, "entropy": 0.6045361240704854, "incre_win_rate": 0.8392857142857143, "step": 1005}
{"time": 1766667692.1235535, "phase": "train", "update": 1006, "total_env_steps": 3219200, "episode_reward": 0.3417624235153198, "value_loss": 0.008008859027177096, "policy_loss": -0.013530700106700995, "dist_entropy": 0.6111097892125448, "actor_grad_norm": 0.1511092633008957, "critic_grad_norm": 0.028011785820126534, "ratio": 1.0009206533432007, "entropy": 0.6111097892125448, "incre_win_rate": 0.8392857142857143, "step": 1006}
{"time": 1766667696.5723507, "phase": "train", "update": 1007, "total_env_steps": 3222400, "episode_reward": 0.3339943587779999, "value_loss": 0.010628593402604263, "policy_loss": -0.01426447014561821, "dist_entropy": 0.6086392919222514, "actor_grad_norm": 0.1727447211742401, "critic_grad_norm": 0.06788798421621323, "ratio": 0.999134361743927, "entropy": 0.6086392919222514, "incre_win_rate": 0.8035714285714286, "step": 1007}
{"time": 1766667701.008999, "phase": "train", "update": 1008, "total_env_steps": 3225600, "episode_reward": 0.32304996252059937, "value_loss": 0.011843429133296012, "policy_loss": -0.014858792102047384, "dist_entropy": 0.5991541703542074, "actor_grad_norm": 0.16425184905529022, "critic_grad_norm": 0.06081380322575569, "ratio": 0.9987670183181763, "entropy": 0.5991541703542074, "incre_win_rate": 0.7543859649122807, "step": 1008}
{"time": 1766667705.5300364, "phase": "train", "update": 1009, "total_env_steps": 3228800, "episode_reward": 0.33876073360443115, "value_loss": 0.009810901122788589, "policy_loss": -0.014227935718110629, "dist_entropy": 0.6130766630172729, "actor_grad_norm": 0.18140685558319092, "critic_grad_norm": 0.036977846175432205, "ratio": 0.9989739060401917, "entropy": 0.6130766630172729, "incre_win_rate": 0.7796610169491526, "step": 1009}
{"time": 1766667709.958226, "phase": "train", "update": 1010, "total_env_steps": 3232000, "episode_reward": 0.35254979133605957, "value_loss": 0.007340674536923567, "policy_loss": -0.01238195332419707, "dist_entropy": 0.6168298681577047, "actor_grad_norm": 0.17147265374660492, "critic_grad_norm": 0.033394452184438705, "ratio": 1.000480055809021, "entropy": 0.6168298681577047, "incre_win_rate": 0.864406779661017, "step": 1010}
{"time": 1766667714.4307544, "phase": "train", "update": 1011, "total_env_steps": 3235200, "episode_reward": 0.31002146005630493, "value_loss": 0.013091591373085975, "policy_loss": -0.015205266924875597, "dist_entropy": 0.6337193131446839, "actor_grad_norm": 0.15195851027965546, "critic_grad_norm": 0.05655396357178688, "ratio": 1.000136137008667, "entropy": 0.6337193131446839, "incre_win_rate": 0.6, "step": 1011}
{"time": 1766667718.850945, "phase": "train", "update": 1012, "total_env_steps": 3238400, "episode_reward": 0.32407552003860474, "value_loss": 0.011399619343380133, "policy_loss": -0.015052610187133079, "dist_entropy": 0.6337810476620992, "actor_grad_norm": 0.14380976557731628, "critic_grad_norm": 0.021001771092414856, "ratio": 1.0001353025436401, "entropy": 0.6337810476620992, "incre_win_rate": 0.7454545454545455, "step": 1012}
{"time": 1766667723.2765293, "phase": "train", "update": 1013, "total_env_steps": 3241600, "episode_reward": 0.3428921401500702, "value_loss": 0.01126139871776104, "policy_loss": -0.013274111719944888, "dist_entropy": 0.6166709820429485, "actor_grad_norm": 0.13731876015663147, "critic_grad_norm": 0.027974870055913925, "ratio": 0.9986403584480286, "entropy": 0.6166709820429485, "incre_win_rate": 0.819672131147541, "step": 1013}
{"time": 1766667727.723924, "phase": "train", "update": 1014, "total_env_steps": 3244800, "episode_reward": 0.3364101052284241, "value_loss": 0.011560163150231043, "policy_loss": -0.013898333589983736, "dist_entropy": 0.6289201895395915, "actor_grad_norm": 0.16874749958515167, "critic_grad_norm": 0.01614130660891533, "ratio": 0.9995886087417603, "entropy": 0.6289201895395915, "incre_win_rate": 0.7818181818181819, "step": 1014}
{"time": 1766667732.1109867, "phase": "train", "update": 1015, "total_env_steps": 3248000, "episode_reward": 0.3333057463169098, "value_loss": 0.010946784603099028, "policy_loss": -0.014464193437472605, "dist_entropy": 0.6309885342915853, "actor_grad_norm": 0.18438324332237244, "critic_grad_norm": 0.021381819620728493, "ratio": 0.9988208413124084, "entropy": 0.6309885342915853, "incre_win_rate": 0.7833333333333333, "step": 1015}
{"time": 1766667736.5343874, "phase": "train", "update": 1016, "total_env_steps": 3251200, "episode_reward": 0.32560276985168457, "value_loss": 0.011630812473595143, "policy_loss": -0.014753073625598745, "dist_entropy": 0.6270417849222819, "actor_grad_norm": 0.16071763634681702, "critic_grad_norm": 0.023159317672252655, "ratio": 1.0003151893615723, "entropy": 0.6270417849222819, "incre_win_rate": 0.7818181818181819, "step": 1016}
{"time": 1766667741.0396562, "phase": "train", "update": 1017, "total_env_steps": 3254400, "episode_reward": 0.3366123139858246, "value_loss": 0.010574737191200256, "policy_loss": -0.013363601929333413, "dist_entropy": 0.6150123476982117, "actor_grad_norm": 0.13993941247463226, "critic_grad_norm": 0.029485931620001793, "ratio": 1.0008918046951294, "entropy": 0.6150123476982117, "incre_win_rate": 0.7931034482758621, "step": 1017}
{"time": 1766667745.514319, "phase": "train", "update": 1018, "total_env_steps": 3257600, "episode_reward": 0.33719438314437866, "value_loss": 0.007696883815030257, "policy_loss": -0.01362185609572748, "dist_entropy": 0.6193522731463115, "actor_grad_norm": 0.16030630469322205, "critic_grad_norm": 0.01138327643275261, "ratio": 0.9997438788414001, "entropy": 0.6193522731463115, "incre_win_rate": 0.8392857142857143, "step": 1018}
{"time": 1766667749.899981, "phase": "train", "update": 1019, "total_env_steps": 3260800, "episode_reward": 0.30837318301200867, "value_loss": 0.010427270084619522, "policy_loss": -0.01456461757485575, "dist_entropy": 0.6199498931566875, "actor_grad_norm": 0.14252962172031403, "critic_grad_norm": 0.015393286943435669, "ratio": 0.9997375011444092, "entropy": 0.6199498931566875, "incre_win_rate": 0.7358490566037735, "step": 1019}
{"time": 1766667754.3146222, "phase": "train", "update": 1020, "total_env_steps": 3264000, "episode_reward": 0.33966606855392456, "value_loss": 0.0066749955217043555, "policy_loss": -0.014129581280616794, "dist_entropy": 0.6323420286178589, "actor_grad_norm": 0.14320294559001923, "critic_grad_norm": 0.025189589709043503, "ratio": 0.9988059401512146, "entropy": 0.6323420286178589, "incre_win_rate": 0.8928571428571429, "step": 1020}
{"time": 1766667758.7416356, "phase": "train", "update": 1021, "total_env_steps": 3267200, "episode_reward": 0.3431854844093323, "value_loss": 0.006627049917976062, "policy_loss": -0.012563150116688248, "dist_entropy": 0.6247529784838358, "actor_grad_norm": 0.14003965258598328, "critic_grad_norm": 0.01670905016362667, "ratio": 1.0007261037826538, "entropy": 0.6247529784838358, "incre_win_rate": 0.8596491228070176, "step": 1021}
{"time": 1766667766.1718435, "phase": "eval", "update": 1021, "total_env_steps": 3267200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.802466299019606, "step": 1021}
{"time": 1766667770.602416, "phase": "train", "update": 1022, "total_env_steps": 3270400, "episode_reward": 0.32025429606437683, "value_loss": 0.00642675713946422, "policy_loss": -0.01547522560590977, "dist_entropy": 0.636014747619629, "actor_grad_norm": 0.1312071681022644, "critic_grad_norm": 0.014395970851182938, "ratio": 1.0004923343658447, "entropy": 0.636014747619629, "incre_win_rate": 0.8490566037735849, "step": 1022}
{"time": 1766667775.0146987, "phase": "train", "update": 1023, "total_env_steps": 3273600, "episode_reward": 0.3371729850769043, "value_loss": 0.0059353030907611055, "policy_loss": -0.013093300031439981, "dist_entropy": 0.6197182814280192, "actor_grad_norm": 0.16379080712795258, "critic_grad_norm": 0.010444849729537964, "ratio": 0.9993122220039368, "entropy": 0.6197182814280192, "incre_win_rate": 0.8909090909090909, "step": 1023}
{"time": 1766667779.4084768, "phase": "train", "update": 1024, "total_env_steps": 3276800, "episode_reward": 0.32661765813827515, "value_loss": 0.007379750472803911, "policy_loss": -0.014859313842197725, "dist_entropy": 0.6340812722841899, "actor_grad_norm": 0.14053428173065186, "critic_grad_norm": 0.013232957571744919, "ratio": 0.9999464154243469, "entropy": 0.6340812722841899, "incre_win_rate": 0.8392857142857143, "step": 1024}
{"time": 1766667783.8061028, "phase": "train", "update": 1025, "total_env_steps": 3280000, "episode_reward": 0.3361404836177826, "value_loss": 0.009733661822974683, "policy_loss": -0.014674332731002219, "dist_entropy": 0.6196913520495096, "actor_grad_norm": 0.14559407532215118, "critic_grad_norm": 0.06280428171157837, "ratio": 1.0000088214874268, "entropy": 0.6196913520495096, "incre_win_rate": 0.7894736842105263, "step": 1025}
{"time": 1766667788.2072172, "phase": "train", "update": 1026, "total_env_steps": 3283200, "episode_reward": 0.32971277832984924, "value_loss": 0.011335534850756328, "policy_loss": -0.014514766461814096, "dist_entropy": 0.6215149203936259, "actor_grad_norm": 0.1679365038871765, "critic_grad_norm": 0.03352449834346771, "ratio": 0.9994992613792419, "entropy": 0.6215149203936259, "incre_win_rate": 0.7818181818181819, "step": 1026}
{"time": 1766667792.644534, "phase": "train", "update": 1027, "total_env_steps": 3286400, "episode_reward": 0.33165672421455383, "value_loss": 0.013843430082003276, "policy_loss": -0.014718576025905842, "dist_entropy": 0.6336156050364177, "actor_grad_norm": 0.1645311862230301, "critic_grad_norm": 0.029201839119195938, "ratio": 0.9988487958908081, "entropy": 0.6336156050364177, "incre_win_rate": 0.7857142857142857, "step": 1027}
{"time": 1766667797.011068, "phase": "train", "update": 1028, "total_env_steps": 3289600, "episode_reward": 0.3426263928413391, "value_loss": 0.00792806406194965, "policy_loss": -0.014204495548280457, "dist_entropy": 0.6326046903928121, "actor_grad_norm": 0.15376530587673187, "critic_grad_norm": 0.08193052560091019, "ratio": 0.9998514652252197, "entropy": 0.6326046903928121, "incre_win_rate": 0.847457627118644, "step": 1028}
{"time": 1766667801.5767806, "phase": "train", "update": 1029, "total_env_steps": 3292800, "episode_reward": 0.32404106855392456, "value_loss": 0.010489157214760781, "policy_loss": -0.013951721010306055, "dist_entropy": 0.6272936503092448, "actor_grad_norm": 0.1470787227153778, "critic_grad_norm": 0.047178108245134354, "ratio": 1.0016121864318848, "entropy": 0.6272936503092448, "incre_win_rate": 0.8148148148148148, "step": 1029}
{"time": 1766667806.0115108, "phase": "train", "update": 1030, "total_env_steps": 3296000, "episode_reward": 0.3387492299079895, "value_loss": 0.011901164799928666, "policy_loss": -0.01424243817506176, "dist_entropy": 0.6367168108622233, "actor_grad_norm": 0.16634230315685272, "critic_grad_norm": 0.03433885797858238, "ratio": 0.9990681409835815, "entropy": 0.6367168108622233, "incre_win_rate": 0.7796610169491526, "step": 1030}
{"time": 1766667810.4114916, "phase": "train", "update": 1031, "total_env_steps": 3299200, "episode_reward": 0.3321959376335144, "value_loss": 0.016392994051178295, "policy_loss": -0.015029533551075976, "dist_entropy": 0.6378798524538676, "actor_grad_norm": 0.14351041615009308, "critic_grad_norm": 0.03794165328145027, "ratio": 1.0011556148529053, "entropy": 0.6378798524538676, "incre_win_rate": 0.7857142857142857, "step": 1031}
{"time": 1766667814.8001146, "phase": "train", "update": 1032, "total_env_steps": 3302400, "episode_reward": 0.3064238727092743, "value_loss": 0.015812720047930877, "policy_loss": -0.015224724612346622, "dist_entropy": 0.6230963468551636, "actor_grad_norm": 0.17606739699840546, "critic_grad_norm": 0.04485151544213295, "ratio": 0.9996160864830017, "entropy": 0.6230963468551636, "incre_win_rate": 0.6909090909090909, "step": 1032}
{"time": 1766667819.2271585, "phase": "train", "update": 1033, "total_env_steps": 3305600, "episode_reward": 0.31659162044525146, "value_loss": 0.014265894144773483, "policy_loss": -0.014254478010892295, "dist_entropy": 0.6399532357851664, "actor_grad_norm": 0.14952582120895386, "critic_grad_norm": 0.032947227358818054, "ratio": 0.9996210336685181, "entropy": 0.6399532357851664, "incre_win_rate": 0.7272727272727273, "step": 1033}
{"time": 1766667823.6262853, "phase": "train", "update": 1034, "total_env_steps": 3308800, "episode_reward": 0.3191620707511902, "value_loss": 0.012735483733316262, "policy_loss": -0.014815758746324074, "dist_entropy": 0.6287049214045207, "actor_grad_norm": 0.14758317172527313, "critic_grad_norm": 0.025393465533852577, "ratio": 0.9989653825759888, "entropy": 0.6287049214045207, "incre_win_rate": 0.7142857142857143, "step": 1034}
{"time": 1766667828.033234, "phase": "train", "update": 1035, "total_env_steps": 3312000, "episode_reward": 0.33335861563682556, "value_loss": 0.009022328009208044, "policy_loss": -0.01460071254748622, "dist_entropy": 0.6487704674402873, "actor_grad_norm": 0.1568545699119568, "critic_grad_norm": 0.04444572329521179, "ratio": 0.9999279379844666, "entropy": 0.6487704674402873, "incre_win_rate": 0.9074074074074074, "step": 1035}
{"time": 1766667832.4331377, "phase": "train", "update": 1036, "total_env_steps": 3315200, "episode_reward": 0.3280537724494934, "value_loss": 0.010960014412800471, "policy_loss": -0.014100114674282812, "dist_entropy": 0.6481301228205363, "actor_grad_norm": 0.137872576713562, "critic_grad_norm": 0.02530682645738125, "ratio": 1.0006515979766846, "entropy": 0.6481301228205363, "incre_win_rate": 0.8727272727272727, "step": 1036}
{"time": 1766667836.8317213, "phase": "train", "update": 1037, "total_env_steps": 3318400, "episode_reward": 0.32771754264831543, "value_loss": 0.011816522168616454, "policy_loss": -0.015331061640869356, "dist_entropy": 0.6361839214960734, "actor_grad_norm": 0.17265450954437256, "critic_grad_norm": 0.018301507458090782, "ratio": 0.9994879364967346, "entropy": 0.6361839214960734, "incre_win_rate": 0.7719298245614035, "step": 1037}
{"time": 1766667841.2807224, "phase": "train", "update": 1038, "total_env_steps": 3321600, "episode_reward": 0.31568244099617004, "value_loss": 0.018341791133085886, "policy_loss": -0.015646087721450166, "dist_entropy": 0.6406642436981201, "actor_grad_norm": 0.20699124038219452, "critic_grad_norm": 0.06881482154130936, "ratio": 1.0006725788116455, "entropy": 0.6406642436981201, "incre_win_rate": 0.6909090909090909, "step": 1038}
{"time": 1766667845.7540019, "phase": "train", "update": 1039, "total_env_steps": 3324800, "episode_reward": 0.3291911780834198, "value_loss": 0.014091630652546882, "policy_loss": -0.015368782469752299, "dist_entropy": 0.6444105664889018, "actor_grad_norm": 0.15906015038490295, "critic_grad_norm": 0.039087455719709396, "ratio": 0.9984589219093323, "entropy": 0.6444105664889018, "incre_win_rate": 0.7818181818181819, "step": 1039}
{"time": 1766667850.16904, "phase": "train", "update": 1040, "total_env_steps": 3328000, "episode_reward": 0.34203124046325684, "value_loss": 0.010213115500907104, "policy_loss": -0.013782024386687415, "dist_entropy": 0.6404558936754863, "actor_grad_norm": 0.16865119338035583, "critic_grad_norm": 0.04622296988964081, "ratio": 0.9991207122802734, "entropy": 0.6404558936754863, "incre_win_rate": 0.8833333333333333, "step": 1040}
{"time": 1766667854.526805, "phase": "train", "update": 1041, "total_env_steps": 3331200, "episode_reward": 0.3103010356426239, "value_loss": 0.011733566721280416, "policy_loss": -0.015357100086446944, "dist_entropy": 0.6553464611371358, "actor_grad_norm": 0.15436552464962006, "critic_grad_norm": 0.030201608315110207, "ratio": 1.0005862712860107, "entropy": 0.6553464611371358, "incre_win_rate": 0.78, "step": 1041}
{"time": 1766667862.164771, "phase": "eval", "update": 1041, "total_env_steps": 3331200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.707567401960784, "step": 1041}
{"time": 1766667866.571906, "phase": "train", "update": 1042, "total_env_steps": 3334400, "episode_reward": 0.334672212600708, "value_loss": 0.00990120843052864, "policy_loss": -0.014344053664327798, "dist_entropy": 0.6441958109537761, "actor_grad_norm": 0.17969563603401184, "critic_grad_norm": 0.0170761588960886, "ratio": 0.9994344711303711, "entropy": 0.6441958109537761, "incre_win_rate": 0.8596491228070176, "step": 1042}
{"time": 1766667870.9644482, "phase": "train", "update": 1043, "total_env_steps": 3337600, "episode_reward": 0.32386720180511475, "value_loss": 0.010779253890117009, "policy_loss": -0.014804406645617026, "dist_entropy": 0.6423620780309042, "actor_grad_norm": 0.1616610288619995, "critic_grad_norm": 0.04222750663757324, "ratio": 1.0001169443130493, "entropy": 0.6423620780309042, "incre_win_rate": 0.7894736842105263, "step": 1043}
{"time": 1766667875.3772357, "phase": "train", "update": 1044, "total_env_steps": 3340800, "episode_reward": 0.32065871357917786, "value_loss": 0.011936473039289316, "policy_loss": -0.015179426841341126, "dist_entropy": 0.6326820691426595, "actor_grad_norm": 0.16478173434734344, "critic_grad_norm": 0.05955316126346588, "ratio": 0.9995460510253906, "entropy": 0.6326820691426595, "incre_win_rate": 0.7454545454545455, "step": 1044}
{"time": 1766667879.7982798, "phase": "train", "update": 1045, "total_env_steps": 3344000, "episode_reward": 0.34100645780563354, "value_loss": 0.008555994555354118, "policy_loss": -0.013852808197696475, "dist_entropy": 0.6319857597351074, "actor_grad_norm": 0.1649201363325119, "critic_grad_norm": 0.037814412266016006, "ratio": 0.9989500641822815, "entropy": 0.6319857597351074, "incre_win_rate": 0.8771929824561403, "step": 1045}
{"time": 1766667884.2361398, "phase": "train", "update": 1046, "total_env_steps": 3347200, "episode_reward": 0.3365119695663452, "value_loss": 0.012253994680941105, "policy_loss": -0.015016479725277065, "dist_entropy": 0.6391223430633545, "actor_grad_norm": 0.14650355279445648, "critic_grad_norm": 0.02481536753475666, "ratio": 0.9988386034965515, "entropy": 0.6391223430633545, "incre_win_rate": 0.8392857142857143, "step": 1046}
{"time": 1766667888.6287892, "phase": "train", "update": 1047, "total_env_steps": 3350400, "episode_reward": 0.32431986927986145, "value_loss": 0.009092774366339047, "policy_loss": -0.015680372240832224, "dist_entropy": 0.6305847048759461, "actor_grad_norm": 0.15206943452358246, "critic_grad_norm": 0.025555355474352837, "ratio": 0.9995865821838379, "entropy": 0.6305847048759461, "incre_win_rate": 0.7678571428571429, "step": 1047}
{"time": 1766667892.9815278, "phase": "train", "update": 1048, "total_env_steps": 3353600, "episode_reward": 0.31437501311302185, "value_loss": 0.013748389792939027, "policy_loss": -0.01477824917099421, "dist_entropy": 0.647173015276591, "actor_grad_norm": 0.15302932262420654, "critic_grad_norm": 0.046829819679260254, "ratio": 1.0003385543823242, "entropy": 0.647173015276591, "incre_win_rate": 0.7924528301886793, "step": 1048}
{"time": 1766667897.4312816, "phase": "train", "update": 1049, "total_env_steps": 3356800, "episode_reward": 0.332846999168396, "value_loss": 0.009663589795430501, "policy_loss": -0.013770841086310763, "dist_entropy": 0.6478575865427653, "actor_grad_norm": 0.1479973942041397, "critic_grad_norm": 0.023983357474207878, "ratio": 1.0003187656402588, "entropy": 0.6478575865427653, "incre_win_rate": 0.8392857142857143, "step": 1049}
{"time": 1766667901.8027453, "phase": "train", "update": 1050, "total_env_steps": 3360000, "episode_reward": 0.31463006138801575, "value_loss": 0.012961266872783503, "policy_loss": -0.014023709157511277, "dist_entropy": 0.6388556639353434, "actor_grad_norm": 0.1364414095878601, "critic_grad_norm": 0.02749098464846611, "ratio": 0.9998434782028198, "entropy": 0.6388556639353434, "incre_win_rate": 0.7924528301886793, "step": 1050}
{"time": 1766667906.237951, "phase": "train", "update": 1051, "total_env_steps": 3363200, "episode_reward": 0.3150987923145294, "value_loss": 0.01258245042214791, "policy_loss": -0.015624419156627786, "dist_entropy": 0.6526483019193013, "actor_grad_norm": 0.1689331978559494, "critic_grad_norm": 0.035937462002038956, "ratio": 0.9990619421005249, "entropy": 0.6526483019193013, "incre_win_rate": 0.75, "step": 1051}
{"time": 1766667910.9247098, "phase": "train", "update": 1052, "total_env_steps": 3366400, "episode_reward": 0.3204572796821594, "value_loss": 0.009230708392957846, "policy_loss": -0.01431958818822352, "dist_entropy": 0.6413372317949931, "actor_grad_norm": 0.16438831388950348, "critic_grad_norm": 0.020523713901638985, "ratio": 0.9990345239639282, "entropy": 0.6413372317949931, "incre_win_rate": 0.7924528301886793, "step": 1052}
{"time": 1766667915.518449, "phase": "train", "update": 1053, "total_env_steps": 3369600, "episode_reward": 0.3373330235481262, "value_loss": 0.010917970910668373, "policy_loss": -0.014286066527846704, "dist_entropy": 0.6582878112792969, "actor_grad_norm": 0.14433611929416656, "critic_grad_norm": 0.0265954602509737, "ratio": 0.9999105334281921, "entropy": 0.6582878112792969, "incre_win_rate": 0.8421052631578947, "step": 1053}
{"time": 1766667920.1832216, "phase": "train", "update": 1054, "total_env_steps": 3372800, "episode_reward": 0.32650506496429443, "value_loss": 0.007613249123096466, "policy_loss": -0.01462590733951572, "dist_entropy": 0.6399959842363994, "actor_grad_norm": 0.1467299908399582, "critic_grad_norm": 0.03338732197880745, "ratio": 0.9994394183158875, "entropy": 0.6399959842363994, "incre_win_rate": 0.8846153846153846, "step": 1054}
{"time": 1766667924.8403735, "phase": "train", "update": 1055, "total_env_steps": 3376000, "episode_reward": 0.3329503834247589, "value_loss": 0.008899281670649847, "policy_loss": -0.014890803851982545, "dist_entropy": 0.6577288866043091, "actor_grad_norm": 0.14499887824058533, "critic_grad_norm": 0.014434073120355606, "ratio": 0.9996761679649353, "entropy": 0.6577288866043091, "incre_win_rate": 0.8392857142857143, "step": 1055}
{"time": 1766667929.372211, "phase": "train", "update": 1056, "total_env_steps": 3379200, "episode_reward": 0.3286902606487274, "value_loss": 0.012909058046837648, "policy_loss": -0.014004722652730568, "dist_entropy": 0.6607585271199544, "actor_grad_norm": 0.12848027050495148, "critic_grad_norm": 0.03689084202051163, "ratio": 1.0000780820846558, "entropy": 0.6607585271199544, "incre_win_rate": 0.8392857142857143, "step": 1056}
{"time": 1766667933.8079262, "phase": "train", "update": 1057, "total_env_steps": 3382400, "episode_reward": 0.3229166865348816, "value_loss": 0.011931208955744902, "policy_loss": -0.014587105252517555, "dist_entropy": 0.6623315850893656, "actor_grad_norm": 0.13680815696716309, "critic_grad_norm": 0.023241182789206505, "ratio": 0.9986132979393005, "entropy": 0.6623315850893656, "incre_win_rate": 0.8035714285714286, "step": 1057}
{"time": 1766667938.1379235, "phase": "train", "update": 1058, "total_env_steps": 3385600, "episode_reward": 0.3232314884662628, "value_loss": 0.010746720309058825, "policy_loss": -0.01340447980605178, "dist_entropy": 0.6471879998842875, "actor_grad_norm": 0.1456337571144104, "critic_grad_norm": 0.01248096488416195, "ratio": 1.0005247592926025, "entropy": 0.6471879998842875, "incre_win_rate": 0.8490566037735849, "step": 1058}
{"time": 1766667942.5564551, "phase": "train", "update": 1059, "total_env_steps": 3388800, "episode_reward": 0.33377987146377563, "value_loss": 0.009716932413478692, "policy_loss": -0.014683850874246219, "dist_entropy": 0.6552964766820272, "actor_grad_norm": 0.1668238788843155, "critic_grad_norm": 0.038151368498802185, "ratio": 1.000110149383545, "entropy": 0.6552964766820272, "incre_win_rate": 0.8392857142857143, "step": 1059}
{"time": 1766667946.8567138, "phase": "train", "update": 1060, "total_env_steps": 3392000, "episode_reward": 0.3299961984157562, "value_loss": 0.008097086939960719, "policy_loss": -0.014269774149697411, "dist_entropy": 0.6411890427271525, "actor_grad_norm": 0.16252058744430542, "critic_grad_norm": 0.02536807581782341, "ratio": 1.000035047531128, "entropy": 0.6411890427271525, "incre_win_rate": 0.8035714285714286, "step": 1060}
{"time": 1766667951.1168935, "phase": "train", "update": 1061, "total_env_steps": 3395200, "episode_reward": 0.31781482696533203, "value_loss": 0.009929642205437024, "policy_loss": -0.0143338494963776, "dist_entropy": 0.6653133630752563, "actor_grad_norm": 0.1505584567785263, "critic_grad_norm": 0.03302520141005516, "ratio": 0.9999027252197266, "entropy": 0.6653133630752563, "incre_win_rate": 0.7924528301886793, "step": 1061}
{"time": 1766667958.5603752, "phase": "eval", "update": 1061, "total_env_steps": 3395200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.863970588235293, "step": 1061}
{"time": 1766667962.8655388, "phase": "train", "update": 1062, "total_env_steps": 3398400, "episode_reward": 0.31418272852897644, "value_loss": 0.011620915681123733, "policy_loss": -0.015654682964113438, "dist_entropy": 0.6580463886260987, "actor_grad_norm": 0.15068064630031586, "critic_grad_norm": 0.04054363816976547, "ratio": 0.9999983906745911, "entropy": 0.6580463886260987, "incre_win_rate": 0.7454545454545455, "step": 1062}
{"time": 1766667967.175325, "phase": "train", "update": 1063, "total_env_steps": 3401600, "episode_reward": 0.3226011395454407, "value_loss": 0.00919950877626737, "policy_loss": -0.014465401197032672, "dist_entropy": 0.6629014531771342, "actor_grad_norm": 0.14153426885604858, "critic_grad_norm": 0.022964421659708023, "ratio": 1.0002777576446533, "entropy": 0.6629014531771342, "incre_win_rate": 0.7962962962962963, "step": 1063}
{"time": 1766667971.6711533, "phase": "train", "update": 1064, "total_env_steps": 3404800, "episode_reward": 0.31592217087745667, "value_loss": 0.012372852489352226, "policy_loss": -0.013963907930504622, "dist_entropy": 0.6571766018867493, "actor_grad_norm": 0.1516231894493103, "critic_grad_norm": 0.01549573615193367, "ratio": 0.9981570839881897, "entropy": 0.6571766018867493, "incre_win_rate": 0.8269230769230769, "step": 1064}
{"time": 1766667976.1399765, "phase": "train", "update": 1065, "total_env_steps": 3408000, "episode_reward": 0.3295726180076599, "value_loss": 0.009097862554093202, "policy_loss": -0.0151411891134894, "dist_entropy": 0.6576609969139099, "actor_grad_norm": 0.14964184165000916, "critic_grad_norm": 0.018086327239871025, "ratio": 0.999123215675354, "entropy": 0.6576609969139099, "incre_win_rate": 0.8571428571428571, "step": 1065}
{"time": 1766667980.7406683, "phase": "train", "update": 1066, "total_env_steps": 3411200, "episode_reward": 0.32309743762016296, "value_loss": 0.010376787247757117, "policy_loss": -0.014227721919198189, "dist_entropy": 0.6623958587646485, "actor_grad_norm": 0.13582748174667358, "critic_grad_norm": 0.015374122187495232, "ratio": 1.00055992603302, "entropy": 0.6623958587646485, "incre_win_rate": 0.8, "step": 1066}
{"time": 1766667985.0003507, "phase": "train", "update": 1067, "total_env_steps": 3414400, "episode_reward": 0.3275245130062103, "value_loss": 0.011142801928023497, "policy_loss": -0.014752235359158542, "dist_entropy": 0.6715381741523743, "actor_grad_norm": 0.1364453136920929, "critic_grad_norm": 0.00946267694234848, "ratio": 1.0017927885055542, "entropy": 0.6715381741523743, "incre_win_rate": 0.8181818181818182, "step": 1067}
{"time": 1766667989.2405171, "phase": "train", "update": 1068, "total_env_steps": 3417600, "episode_reward": 0.3212745487689972, "value_loss": 0.013910073786973953, "policy_loss": -0.01479845092574384, "dist_entropy": 0.6833855668703716, "actor_grad_norm": 0.1423475593328476, "critic_grad_norm": 0.011015255935490131, "ratio": 1.0003172159194946, "entropy": 0.6833855668703716, "incre_win_rate": 0.7678571428571429, "step": 1068}
{"time": 1766667993.3981097, "phase": "train", "update": 1069, "total_env_steps": 3420800, "episode_reward": 0.29563573002815247, "value_loss": 0.01488954791178306, "policy_loss": -0.017536384438528785, "dist_entropy": 0.6704145669937134, "actor_grad_norm": 0.16476640105247498, "critic_grad_norm": 0.032731134444475174, "ratio": 0.9996851682662964, "entropy": 0.6704145669937134, "incre_win_rate": 0.7115384615384616, "step": 1069}
{"time": 1766667997.80279, "phase": "train", "update": 1070, "total_env_steps": 3424000, "episode_reward": 0.3116697371006012, "value_loss": 0.013921014716227849, "policy_loss": -0.016065210569126975, "dist_entropy": 0.6709524313608806, "actor_grad_norm": 0.17531216144561768, "critic_grad_norm": 0.01915075071156025, "ratio": 1.0007556676864624, "entropy": 0.6709524313608806, "incre_win_rate": 0.7037037037037037, "step": 1070}
{"time": 1766668002.2695522, "phase": "train", "update": 1071, "total_env_steps": 3427200, "episode_reward": 0.32836320996284485, "value_loss": 0.01191776388635238, "policy_loss": -0.014438449344243053, "dist_entropy": 0.6635692278544109, "actor_grad_norm": 0.14306063950061798, "critic_grad_norm": 0.0767853781580925, "ratio": 0.9993802905082703, "entropy": 0.6635692278544109, "incre_win_rate": 0.8181818181818182, "step": 1071}
{"time": 1766668006.7193744, "phase": "train", "update": 1072, "total_env_steps": 3430400, "episode_reward": 0.3115655779838562, "value_loss": 0.009184853173792362, "policy_loss": -0.016152135761470277, "dist_entropy": 0.6740334947903951, "actor_grad_norm": 0.16048721969127655, "critic_grad_norm": 0.03642955422401428, "ratio": 0.9986856579780579, "entropy": 0.6740334947903951, "incre_win_rate": 0.7924528301886793, "step": 1072}
{"time": 1766668011.2723958, "phase": "train", "update": 1073, "total_env_steps": 3433600, "episode_reward": 0.3190916180610657, "value_loss": 0.012359740088383357, "policy_loss": -0.014804317301274258, "dist_entropy": 0.6615942597389222, "actor_grad_norm": 0.14859583973884583, "critic_grad_norm": 0.030116980895400047, "ratio": 0.9992275834083557, "entropy": 0.6615942597389222, "incre_win_rate": 0.8148148148148148, "step": 1073}
{"time": 1766668016.0675137, "phase": "train", "update": 1074, "total_env_steps": 3436800, "episode_reward": 0.32016316056251526, "value_loss": 0.010493707408507665, "policy_loss": -0.014807174297401578, "dist_entropy": 0.6513635039329528, "actor_grad_norm": 0.17469003796577454, "critic_grad_norm": 0.027975616976618767, "ratio": 1.0000797510147095, "entropy": 0.6513635039329528, "incre_win_rate": 0.8301886792452831, "step": 1074}
{"time": 1766668020.3422358, "phase": "train", "update": 1075, "total_env_steps": 3440000, "episode_reward": 0.30987748503685, "value_loss": 0.009522086444000403, "policy_loss": -0.015044888011652565, "dist_entropy": 0.6453790624936422, "actor_grad_norm": 0.19021780788898468, "critic_grad_norm": 0.02267969772219658, "ratio": 0.998727560043335, "entropy": 0.6453790624936422, "incre_win_rate": 0.8269230769230769, "step": 1075}
{"time": 1766668024.541704, "phase": "train", "update": 1076, "total_env_steps": 3443200, "episode_reward": 0.32545727491378784, "value_loss": 0.00727328301096956, "policy_loss": -0.014217406372330644, "dist_entropy": 0.6464774211247762, "actor_grad_norm": 0.174555703997612, "critic_grad_norm": 0.019006066024303436, "ratio": 0.998684823513031, "entropy": 0.6464774211247762, "incre_win_rate": 0.8727272727272727, "step": 1076}
{"time": 1766668028.8814554, "phase": "train", "update": 1077, "total_env_steps": 3446400, "episode_reward": 0.32549482583999634, "value_loss": 0.00637330108632644, "policy_loss": -0.014408656970802743, "dist_entropy": 0.63051438331604, "actor_grad_norm": 0.17045357823371887, "critic_grad_norm": 0.019315190613269806, "ratio": 0.9993312954902649, "entropy": 0.63051438331604, "incre_win_rate": 0.8867924528301887, "step": 1077}
{"time": 1766668033.2504108, "phase": "train", "update": 1078, "total_env_steps": 3449600, "episode_reward": 0.33238208293914795, "value_loss": 0.006697485006103913, "policy_loss": -0.014010887821411681, "dist_entropy": 0.6417182167371114, "actor_grad_norm": 0.17821697890758514, "critic_grad_norm": 0.028306569904088974, "ratio": 0.9993705749511719, "entropy": 0.6417182167371114, "incre_win_rate": 0.9090909090909091, "step": 1078}
{"time": 1766668037.8110404, "phase": "train", "update": 1079, "total_env_steps": 3452800, "episode_reward": 0.3305353820323944, "value_loss": 0.009123653235534827, "policy_loss": -0.014541243974496373, "dist_entropy": 0.6165816386540731, "actor_grad_norm": 0.1530611664056778, "critic_grad_norm": 0.045167405158281326, "ratio": 1.0010002851486206, "entropy": 0.6165816386540731, "incre_win_rate": 0.8490566037735849, "step": 1079}
{"time": 1766668042.0940623, "phase": "train", "update": 1080, "total_env_steps": 3456000, "episode_reward": 0.3242601156234741, "value_loss": 0.009643220032254854, "policy_loss": -0.014481793630735259, "dist_entropy": 0.6167226910591126, "actor_grad_norm": 0.176172137260437, "critic_grad_norm": 0.03377280384302139, "ratio": 0.9994828701019287, "entropy": 0.6167226910591126, "incre_win_rate": 0.8518518518518519, "step": 1080}
{"time": 1766668046.389327, "phase": "train", "update": 1081, "total_env_steps": 3459200, "episode_reward": 0.3251769542694092, "value_loss": 0.008032642211765051, "policy_loss": -0.013240297083343459, "dist_entropy": 0.6310818195343018, "actor_grad_norm": 0.15073075890541077, "critic_grad_norm": 0.016730990260839462, "ratio": 0.9981815218925476, "entropy": 0.6310818195343018, "incre_win_rate": 0.8928571428571429, "step": 1081}
{"time": 1766668053.6003807, "phase": "eval", "update": 1081, "total_env_steps": 3459200, "eval_win_rate": 1.0, "eval_episode_reward": 20.023131127450984, "step": 1081}
{"time": 1766668057.8995955, "phase": "train", "update": 1082, "total_env_steps": 3462400, "episode_reward": 0.3415709137916565, "value_loss": 0.00551857544730107, "policy_loss": -0.01466224587798545, "dist_entropy": 0.6307761708895365, "actor_grad_norm": 0.14274363219738007, "critic_grad_norm": 0.03652258962392807, "ratio": 0.997952401638031, "entropy": 0.6307761708895365, "incre_win_rate": 0.9642857142857143, "step": 1082}
{"time": 1766668062.3436646, "phase": "train", "update": 1083, "total_env_steps": 3465600, "episode_reward": 0.31662073731422424, "value_loss": 0.007571266094843546, "policy_loss": -0.014619646915361677, "dist_entropy": 0.6263192454973857, "actor_grad_norm": 0.13593238592147827, "critic_grad_norm": 0.02818894200026989, "ratio": 0.9983086585998535, "entropy": 0.6263192454973857, "incre_win_rate": 0.8269230769230769, "step": 1083}
{"time": 1766668066.702539, "phase": "train", "update": 1084, "total_env_steps": 3468800, "episode_reward": 0.31884652376174927, "value_loss": 0.0068834377142290275, "policy_loss": -0.01198914723395698, "dist_entropy": 0.6314074317614238, "actor_grad_norm": 0.14759700000286102, "critic_grad_norm": 0.013518779538571835, "ratio": 1.0003507137298584, "entropy": 0.6314074317614238, "incre_win_rate": 0.9215686274509803, "step": 1084}
{"time": 1766668071.0679736, "phase": "train", "update": 1085, "total_env_steps": 3472000, "episode_reward": 0.32680609822273254, "value_loss": 0.006874491864194473, "policy_loss": -0.013399859836324642, "dist_entropy": 0.6196618556976319, "actor_grad_norm": 0.14038535952568054, "critic_grad_norm": 0.01173179317265749, "ratio": 0.9981646537780762, "entropy": 0.6196618556976319, "incre_win_rate": 0.8888888888888888, "step": 1085}
{"time": 1766668075.4121253, "phase": "train", "update": 1086, "total_env_steps": 3475200, "episode_reward": 0.3383907973766327, "value_loss": 0.005186088848859072, "policy_loss": -0.013409186162705448, "dist_entropy": 0.641455086072286, "actor_grad_norm": 0.13584494590759277, "critic_grad_norm": 0.015496385283768177, "ratio": 0.9992168545722961, "entropy": 0.641455086072286, "incre_win_rate": 0.9272727272727272, "step": 1086}
{"time": 1766668079.9904325, "phase": "train", "update": 1087, "total_env_steps": 3478400, "episode_reward": 0.3346101641654968, "value_loss": 0.004534336862464746, "policy_loss": -0.013263194548394116, "dist_entropy": 0.6396787524223327, "actor_grad_norm": 0.16047553718090057, "critic_grad_norm": 0.023114508017897606, "ratio": 0.9989192485809326, "entropy": 0.6396787524223327, "incre_win_rate": 0.9272727272727272, "step": 1087}
{"time": 1766668084.8178957, "phase": "train", "update": 1088, "total_env_steps": 3481600, "episode_reward": 0.31974878907203674, "value_loss": 0.00741069366534551, "policy_loss": -0.013637293325192939, "dist_entropy": 0.6329440077145895, "actor_grad_norm": 0.14326241612434387, "critic_grad_norm": 0.05461185425519943, "ratio": 0.9997779726982117, "entropy": 0.6329440077145895, "incre_win_rate": 0.8148148148148148, "step": 1088}
{"time": 1766668089.7292013, "phase": "train", "update": 1089, "total_env_steps": 3484800, "episode_reward": 0.32628369331359863, "value_loss": 0.008590153294305007, "policy_loss": -0.013971739723738826, "dist_entropy": 0.6406822284062703, "actor_grad_norm": 0.15628191828727722, "critic_grad_norm": 0.06817152351140976, "ratio": 0.9990836977958679, "entropy": 0.6406822284062703, "incre_win_rate": 0.8545454545454545, "step": 1089}
{"time": 1766668094.5150714, "phase": "train", "update": 1090, "total_env_steps": 3488000, "episode_reward": 0.3132360577583313, "value_loss": 0.015304909646511078, "policy_loss": -0.015674005282201146, "dist_entropy": 0.6516115069389343, "actor_grad_norm": 0.15635350346565247, "critic_grad_norm": 0.1013069674372673, "ratio": 0.9991602301597595, "entropy": 0.6516115069389343, "incre_win_rate": 0.7592592592592593, "step": 1090}
{"time": 1766668099.272461, "phase": "train", "update": 1091, "total_env_steps": 3491200, "episode_reward": 0.3194431662559509, "value_loss": 0.008090894296765327, "policy_loss": -0.013814913329035743, "dist_entropy": 0.6482262929280599, "actor_grad_norm": 0.1554661989212036, "critic_grad_norm": 0.04638434574007988, "ratio": 0.9994633793830872, "entropy": 0.6482262929280599, "incre_win_rate": 0.7777777777777778, "step": 1091}
{"time": 1766668104.1598022, "phase": "train", "update": 1092, "total_env_steps": 3494400, "episode_reward": 0.32273975014686584, "value_loss": 0.007967953290790319, "policy_loss": -0.01420064465258335, "dist_entropy": 0.6532665332158406, "actor_grad_norm": 0.17143838107585907, "critic_grad_norm": 0.04791868105530739, "ratio": 0.9981663823127747, "entropy": 0.6532665332158406, "incre_win_rate": 0.8333333333333334, "step": 1092}
{"time": 1766668109.074058, "phase": "train", "update": 1093, "total_env_steps": 3497600, "episode_reward": 0.337570458650589, "value_loss": 0.008009131563206514, "policy_loss": -0.013341280106125926, "dist_entropy": 0.6555996894836426, "actor_grad_norm": 0.1459374725818634, "critic_grad_norm": 0.04055781662464142, "ratio": 0.9998491406440735, "entropy": 0.6555996894836426, "incre_win_rate": 0.8571428571428571, "step": 1093}
{"time": 1766668113.9873881, "phase": "train", "update": 1094, "total_env_steps": 3500800, "episode_reward": 0.3289782404899597, "value_loss": 0.007698535950233539, "policy_loss": -0.013823199727337492, "dist_entropy": 0.6519982933998107, "actor_grad_norm": 0.13450287282466888, "critic_grad_norm": 0.01973833702504635, "ratio": 0.9990540742874146, "entropy": 0.6519982933998107, "incre_win_rate": 0.8888888888888888, "step": 1094}
{"time": 1766668118.9551117, "phase": "train", "update": 1095, "total_env_steps": 3504000, "episode_reward": 0.3225819766521454, "value_loss": 0.009142236473659674, "policy_loss": -0.014042809367287863, "dist_entropy": 0.6612669150034587, "actor_grad_norm": 0.13107889890670776, "critic_grad_norm": 0.023685483261942863, "ratio": 0.9993639588356018, "entropy": 0.6612669150034587, "incre_win_rate": 0.8148148148148148, "step": 1095}
{"time": 1766668123.9849353, "phase": "train", "update": 1096, "total_env_steps": 3507200, "episode_reward": 0.33295804262161255, "value_loss": 0.008741925718883674, "policy_loss": -0.013666075120770433, "dist_entropy": 0.6401232202847799, "actor_grad_norm": 0.15276211500167847, "critic_grad_norm": 0.030866218730807304, "ratio": 0.999569296836853, "entropy": 0.6401232202847799, "incre_win_rate": 0.8909090909090909, "step": 1096}
{"time": 1766668129.108111, "phase": "train", "update": 1097, "total_env_steps": 3510400, "episode_reward": 0.3343864679336548, "value_loss": 0.006219107254097859, "policy_loss": -0.014354256356412283, "dist_entropy": 0.6378028194109598, "actor_grad_norm": 0.13236694037914276, "critic_grad_norm": 0.027996154502034187, "ratio": 0.9993545413017273, "entropy": 0.6378028194109598, "incre_win_rate": 0.8793103448275862, "step": 1097}
{"time": 1766668134.041209, "phase": "train", "update": 1098, "total_env_steps": 3513600, "episode_reward": 0.3243933618068695, "value_loss": 0.008290039127071698, "policy_loss": -0.013820874150846407, "dist_entropy": 0.6548403024673461, "actor_grad_norm": 0.1429436057806015, "critic_grad_norm": 0.015536115504801273, "ratio": 0.9995812177658081, "entropy": 0.6548403024673461, "incre_win_rate": 0.8148148148148148, "step": 1098}
{"time": 1766668138.8293731, "phase": "train", "update": 1099, "total_env_steps": 3516800, "episode_reward": 0.3266099989414215, "value_loss": 0.008679320694257815, "policy_loss": -0.012902437837444818, "dist_entropy": 0.6596454342206319, "actor_grad_norm": 0.12609021365642548, "critic_grad_norm": 0.012311636470258236, "ratio": 0.999402642250061, "entropy": 0.6596454342206319, "incre_win_rate": 0.8679245283018868, "step": 1099}
{"time": 1766668143.6824052, "phase": "train", "update": 1100, "total_env_steps": 3520000, "episode_reward": 0.34344977140426636, "value_loss": 0.0046352296757201355, "policy_loss": -0.01230997618524133, "dist_entropy": 0.6543605367342631, "actor_grad_norm": 0.12482228130102158, "critic_grad_norm": 0.017550399526953697, "ratio": 1.0005494356155396, "entropy": 0.6543605367342631, "incre_win_rate": 0.9473684210526315, "step": 1100}
{"time": 1766668147.9504309, "phase": "train", "update": 1101, "total_env_steps": 3523200, "episode_reward": 0.340551495552063, "value_loss": 0.003126701231425007, "policy_loss": -0.013365328737614845, "dist_entropy": 0.6614466110865275, "actor_grad_norm": 0.13423454761505127, "critic_grad_norm": 0.015214378014206886, "ratio": 0.9995789527893066, "entropy": 0.6614466110865275, "incre_win_rate": 0.9629629629629629, "step": 1101}
{"time": 1766668155.2530918, "phase": "eval", "update": 1101, "total_env_steps": 3523200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.737208946078432, "step": 1101}
{"time": 1766668159.575946, "phase": "train", "update": 1102, "total_env_steps": 3526400, "episode_reward": 0.328097403049469, "value_loss": 0.006836268988748392, "policy_loss": -0.013045301060900271, "dist_entropy": 0.6496287624041239, "actor_grad_norm": 0.1416439563035965, "critic_grad_norm": 0.018207041546702385, "ratio": 1.0001920461654663, "entropy": 0.6496287624041239, "incre_win_rate": 0.8909090909090909, "step": 1102}
{"time": 1766668163.9486947, "phase": "train", "update": 1103, "total_env_steps": 3529600, "episode_reward": 0.3165510296821594, "value_loss": 0.008201324567198753, "policy_loss": -0.014286016657704674, "dist_entropy": 0.6702994743982951, "actor_grad_norm": 0.16263052821159363, "critic_grad_norm": 0.041976653039455414, "ratio": 1.000338077545166, "entropy": 0.6702994743982951, "incre_win_rate": 0.8113207547169812, "step": 1103}
{"time": 1766668168.2696648, "phase": "train", "update": 1104, "total_env_steps": 3532800, "episode_reward": 0.3273177146911621, "value_loss": 0.0075803575726846855, "policy_loss": -0.01342098988454694, "dist_entropy": 0.6601815938949585, "actor_grad_norm": 0.15381059050559998, "critic_grad_norm": 0.02349649928510189, "ratio": 1.000230312347412, "entropy": 0.6601815938949585, "incre_win_rate": 0.8679245283018868, "step": 1104}
{"time": 1766668172.6145093, "phase": "train", "update": 1105, "total_env_steps": 3536000, "episode_reward": 0.3215150237083435, "value_loss": 0.006164986081421376, "policy_loss": -0.014061059320723027, "dist_entropy": 0.6584500551223755, "actor_grad_norm": 0.14984551072120667, "critic_grad_norm": 0.0334523506462574, "ratio": 0.9988041520118713, "entropy": 0.6584500551223755, "incre_win_rate": 0.8888888888888888, "step": 1105}
{"time": 1766668177.0054033, "phase": "train", "update": 1106, "total_env_steps": 3539200, "episode_reward": 0.30860525369644165, "value_loss": 0.01019445937126875, "policy_loss": -0.014379844892297022, "dist_entropy": 0.6464574019114177, "actor_grad_norm": 0.17302334308624268, "critic_grad_norm": 0.010080275125801563, "ratio": 0.9995506405830383, "entropy": 0.6464574019114177, "incre_win_rate": 0.7884615384615384, "step": 1106}
{"time": 1766668181.4090447, "phase": "train", "update": 1107, "total_env_steps": 3542400, "episode_reward": 0.3303048312664032, "value_loss": 0.00599845073496302, "policy_loss": -0.014901092283491598, "dist_entropy": 0.647710911432902, "actor_grad_norm": 0.1590663492679596, "critic_grad_norm": 0.039428699761629105, "ratio": 0.9984750151634216, "entropy": 0.647710911432902, "incre_win_rate": 0.875, "step": 1107}
{"time": 1766668185.7845259, "phase": "train", "update": 1108, "total_env_steps": 3545600, "episode_reward": 0.33427390456199646, "value_loss": 0.007075328069428603, "policy_loss": -0.01399007658138108, "dist_entropy": 0.6374247789382934, "actor_grad_norm": 0.14728984236717224, "critic_grad_norm": 0.017171943560242653, "ratio": 0.9992372393608093, "entropy": 0.6374247789382934, "incre_win_rate": 0.8888888888888888, "step": 1108}
{"time": 1766668190.0606265, "phase": "train", "update": 1109, "total_env_steps": 3548800, "episode_reward": 0.33449065685272217, "value_loss": 0.0076630624321599805, "policy_loss": -0.012424214850460658, "dist_entropy": 0.6377003987630209, "actor_grad_norm": 0.13334597647190094, "critic_grad_norm": 0.014094105921685696, "ratio": 1.0003321170806885, "entropy": 0.6377003987630209, "incre_win_rate": 0.8727272727272727, "step": 1109}
{"time": 1766668194.3847961, "phase": "train", "update": 1110, "total_env_steps": 3552000, "episode_reward": 0.3401026427745819, "value_loss": 0.005492600550254186, "policy_loss": -0.013718050941923821, "dist_entropy": 0.6397201259930928, "actor_grad_norm": 0.14030501246452332, "critic_grad_norm": 0.012065558694303036, "ratio": 1.0004589557647705, "entropy": 0.6397201259930928, "incre_win_rate": 0.9285714285714286, "step": 1110}
{"time": 1766668199.0709007, "phase": "train", "update": 1111, "total_env_steps": 3555200, "episode_reward": 0.31839463114738464, "value_loss": 0.007937261803696553, "policy_loss": -0.014144399523487946, "dist_entropy": 0.6349480112393697, "actor_grad_norm": 0.14513514935970306, "critic_grad_norm": 0.025863299146294594, "ratio": 0.9996105432510376, "entropy": 0.6349480112393697, "incre_win_rate": 0.8490566037735849, "step": 1111}
{"time": 1766668203.6814024, "phase": "train", "update": 1112, "total_env_steps": 3558400, "episode_reward": 0.3319852948188782, "value_loss": 0.006500944371024767, "policy_loss": -0.013301207589853922, "dist_entropy": 0.6385695179303487, "actor_grad_norm": 0.14128869771957397, "critic_grad_norm": 0.026555493474006653, "ratio": 0.9999765157699585, "entropy": 0.6385695179303487, "incre_win_rate": 0.9056603773584906, "step": 1112}
{"time": 1766668208.6801264, "phase": "train", "update": 1113, "total_env_steps": 3561600, "episode_reward": 0.3385975658893585, "value_loss": 0.005777536736180385, "policy_loss": -0.014078701287533116, "dist_entropy": 0.6373852332433064, "actor_grad_norm": 0.1322368085384369, "critic_grad_norm": 0.015061882324516773, "ratio": 0.9995154142379761, "entropy": 0.6373852332433064, "incre_win_rate": 0.9272727272727272, "step": 1113}
{"time": 1766668213.2727478, "phase": "train", "update": 1114, "total_env_steps": 3564800, "episode_reward": 0.34145987033843994, "value_loss": 0.005464247396836678, "policy_loss": -0.012547387625995773, "dist_entropy": 0.6514553666114807, "actor_grad_norm": 0.14874154329299927, "critic_grad_norm": 0.023605171591043472, "ratio": 1.001010775566101, "entropy": 0.6514553666114807, "incre_win_rate": 0.896551724137931, "step": 1114}
{"time": 1766668218.058165, "phase": "train", "update": 1115, "total_env_steps": 3568000, "episode_reward": 0.3230246603488922, "value_loss": 0.007810582996656498, "policy_loss": -0.013477352606102973, "dist_entropy": 0.6337741851806641, "actor_grad_norm": 0.13884149491786957, "critic_grad_norm": 0.049101706594228745, "ratio": 1.000504970550537, "entropy": 0.6337741851806641, "incre_win_rate": 0.8, "step": 1115}
{"time": 1766668222.702514, "phase": "train", "update": 1116, "total_env_steps": 3571200, "episode_reward": 0.32188189029693604, "value_loss": 0.0073028546447555225, "policy_loss": -0.014671644491478257, "dist_entropy": 0.6448619763056437, "actor_grad_norm": 0.1620226949453354, "critic_grad_norm": 0.03863193839788437, "ratio": 0.9994673132896423, "entropy": 0.6448619763056437, "incre_win_rate": 0.8461538461538461, "step": 1116}
{"time": 1766668227.444332, "phase": "train", "update": 1117, "total_env_steps": 3574400, "episode_reward": 0.3354901969432831, "value_loss": 0.008085750633229812, "policy_loss": -0.013327186795188102, "dist_entropy": 0.6519003868103027, "actor_grad_norm": 0.15314044058322906, "critic_grad_norm": 0.024898117408156395, "ratio": 0.9994086623191833, "entropy": 0.6519003868103027, "incre_win_rate": 0.8596491228070176, "step": 1117}
{"time": 1766668232.2026432, "phase": "train", "update": 1118, "total_env_steps": 3577600, "episode_reward": 0.3281518220901489, "value_loss": 0.0070989288700123625, "policy_loss": -0.012878753909593381, "dist_entropy": 0.6355984210968018, "actor_grad_norm": 0.15119268000125885, "critic_grad_norm": 0.015549706295132637, "ratio": 1.0005285739898682, "entropy": 0.6355984210968018, "incre_win_rate": 0.8545454545454545, "step": 1118}
{"time": 1766668237.0434344, "phase": "train", "update": 1119, "total_env_steps": 3580800, "episode_reward": 0.32274970412254333, "value_loss": 0.006823230907320977, "policy_loss": -0.015493745342207413, "dist_entropy": 0.6550153613090515, "actor_grad_norm": 0.14027975499629974, "critic_grad_norm": 0.011603809893131256, "ratio": 0.9987536072731018, "entropy": 0.6550153613090515, "incre_win_rate": 0.8490566037735849, "step": 1119}
{"time": 1766668242.0400853, "phase": "train", "update": 1120, "total_env_steps": 3584000, "episode_reward": 0.3277811110019684, "value_loss": 0.008601976123948892, "policy_loss": -0.013213714190286888, "dist_entropy": 0.648559057712555, "actor_grad_norm": 0.13529273867607117, "critic_grad_norm": 0.022607531398534775, "ratio": 0.9996281862258911, "entropy": 0.648559057712555, "incre_win_rate": 0.8545454545454545, "step": 1120}
{"time": 1766668247.027491, "phase": "train", "update": 1121, "total_env_steps": 3587200, "episode_reward": 0.30933135747909546, "value_loss": 0.009647136429945628, "policy_loss": -0.015357202260847675, "dist_entropy": 0.6553422093391419, "actor_grad_norm": 0.14320333302021027, "critic_grad_norm": 0.029817288741469383, "ratio": 1.0000081062316895, "entropy": 0.6553422093391419, "incre_win_rate": 0.7407407407407407, "step": 1121}
{"time": 1766668255.7191017, "phase": "eval", "update": 1121, "total_env_steps": 3587200, "eval_win_rate": 1.0, "eval_episode_reward": 20.01348039215686, "step": 1121}
{"time": 1766668260.7603965, "phase": "train", "update": 1122, "total_env_steps": 3590400, "episode_reward": 0.3224456310272217, "value_loss": 0.008199245327462752, "policy_loss": -0.014231069895995081, "dist_entropy": 0.6652691642443339, "actor_grad_norm": 0.1590472161769867, "critic_grad_norm": 0.033812250941991806, "ratio": 0.9995256662368774, "entropy": 0.6652691642443339, "incre_win_rate": 0.8679245283018868, "step": 1122}
{"time": 1766668265.6927311, "phase": "train", "update": 1123, "total_env_steps": 3593600, "episode_reward": 0.3360562026500702, "value_loss": 0.008153263355294864, "policy_loss": -0.015099661690206052, "dist_entropy": 0.6585052609443665, "actor_grad_norm": 0.14343081414699554, "critic_grad_norm": 0.021248050034046173, "ratio": 0.9988664984703064, "entropy": 0.6585052609443665, "incre_win_rate": 0.8421052631578947, "step": 1123}
{"time": 1766668270.6427367, "phase": "train", "update": 1124, "total_env_steps": 3596800, "episode_reward": 0.33654797077178955, "value_loss": 0.00727643050874273, "policy_loss": -0.014580667496547524, "dist_entropy": 0.6532359719276428, "actor_grad_norm": 0.14785948395729065, "critic_grad_norm": 0.013188261538743973, "ratio": 0.9975627064704895, "entropy": 0.6532359719276428, "incre_win_rate": 0.8545454545454545, "step": 1124}
{"time": 1766668275.6561332, "phase": "train", "update": 1125, "total_env_steps": 3600000, "episode_reward": 0.317954957485199, "value_loss": 0.007683910119036834, "policy_loss": -0.01477953162919287, "dist_entropy": 0.6652780572573344, "actor_grad_norm": 0.13038253784179688, "critic_grad_norm": 0.024825116619467735, "ratio": 1.000004768371582, "entropy": 0.6652780572573344, "incre_win_rate": 0.8113207547169812, "step": 1125}
{"time": 1766668280.8355834, "phase": "train", "update": 1126, "total_env_steps": 3603200, "episode_reward": 0.33412763476371765, "value_loss": 0.006928928134342035, "policy_loss": -0.013867269021445002, "dist_entropy": 0.675475005308787, "actor_grad_norm": 0.1568334996700287, "critic_grad_norm": 0.014016092754900455, "ratio": 0.9999022483825684, "entropy": 0.675475005308787, "incre_win_rate": 0.9074074074074074, "step": 1126}
{"time": 1766668285.933607, "phase": "train", "update": 1127, "total_env_steps": 3606400, "episode_reward": 0.33236443996429443, "value_loss": 0.007357777530948321, "policy_loss": -0.0130255284692538, "dist_entropy": 0.6486297130584717, "actor_grad_norm": 0.13158856332302094, "critic_grad_norm": 0.008016766980290413, "ratio": 0.9996200799942017, "entropy": 0.6486297130584717, "incre_win_rate": 0.8421052631578947, "step": 1127}
{"time": 1766668291.1608098, "phase": "train", "update": 1128, "total_env_steps": 3609600, "episode_reward": 0.31611981987953186, "value_loss": 0.00783865616346399, "policy_loss": -0.014590786290983714, "dist_entropy": 0.6561241189638773, "actor_grad_norm": 0.16193044185638428, "critic_grad_norm": 0.02499093860387802, "ratio": 0.999565601348877, "entropy": 0.6561241189638773, "incre_win_rate": 0.7962962962962963, "step": 1128}
{"time": 1766668296.1634395, "phase": "train", "update": 1129, "total_env_steps": 3612800, "episode_reward": 0.3250398635864258, "value_loss": 0.011538217527170975, "policy_loss": -0.01368589045430421, "dist_entropy": 0.6519616127014161, "actor_grad_norm": 0.15455465018749237, "critic_grad_norm": 0.024018140509724617, "ratio": 0.9999163746833801, "entropy": 0.6519616127014161, "incre_win_rate": 0.8518518518518519, "step": 1129}
{"time": 1766668301.0124054, "phase": "train", "update": 1130, "total_env_steps": 3616000, "episode_reward": 0.32879748940467834, "value_loss": 0.00795920869956414, "policy_loss": -0.014716095828098711, "dist_entropy": 0.6504339893658956, "actor_grad_norm": 0.12849196791648865, "critic_grad_norm": 0.018228210508823395, "ratio": 0.9989477396011353, "entropy": 0.6504339893658956, "incre_win_rate": 0.8703703703703703, "step": 1130}
{"time": 1766668305.566895, "phase": "train", "update": 1131, "total_env_steps": 3619200, "episode_reward": 0.3385983407497406, "value_loss": 0.008203810111929973, "policy_loss": -0.013691294322246132, "dist_entropy": 0.6576813817024231, "actor_grad_norm": 0.13553526997566223, "critic_grad_norm": 0.015970928594470024, "ratio": 1.0011168718338013, "entropy": 0.6576813817024231, "incre_win_rate": 0.896551724137931, "step": 1131}
{"time": 1766668310.2242835, "phase": "train", "update": 1132, "total_env_steps": 3622400, "episode_reward": 0.3228936791419983, "value_loss": 0.008151310651252667, "policy_loss": -0.012659717091254427, "dist_entropy": 0.6408757130304973, "actor_grad_norm": 0.15319345891475677, "critic_grad_norm": 0.019680283963680267, "ratio": 1.0001599788665771, "entropy": 0.6408757130304973, "incre_win_rate": 0.8490566037735849, "step": 1132}
{"time": 1766668314.7542467, "phase": "train", "update": 1133, "total_env_steps": 3625600, "episode_reward": 0.32688188552856445, "value_loss": 0.005895605155577262, "policy_loss": -0.014603847193471964, "dist_entropy": 0.6449711203575135, "actor_grad_norm": 0.12708711624145508, "critic_grad_norm": 0.013029898516833782, "ratio": 0.9997748732566833, "entropy": 0.6449711203575135, "incre_win_rate": 0.8545454545454545, "step": 1133}
{"time": 1766668319.276993, "phase": "train", "update": 1134, "total_env_steps": 3628800, "episode_reward": 0.3304312229156494, "value_loss": 0.007956898926446835, "policy_loss": -0.01325693932939771, "dist_entropy": 0.6414513905843099, "actor_grad_norm": 0.13814187049865723, "critic_grad_norm": 0.010972432792186737, "ratio": 1.0016359090805054, "entropy": 0.6414513905843099, "incre_win_rate": 0.8909090909090909, "step": 1134}
{"time": 1766668323.7451105, "phase": "train", "update": 1135, "total_env_steps": 3632000, "episode_reward": 0.32627835869789124, "value_loss": 0.011090376041829586, "policy_loss": -0.013409164217786144, "dist_entropy": 0.6480140328407288, "actor_grad_norm": 0.1413181722164154, "critic_grad_norm": 0.03806938976049423, "ratio": 1.0012370347976685, "entropy": 0.6480140328407288, "incre_win_rate": 0.7818181818181819, "step": 1135}
{"time": 1766668328.155711, "phase": "train", "update": 1136, "total_env_steps": 3635200, "episode_reward": 0.34047412872314453, "value_loss": 0.007821198552846909, "policy_loss": -0.013116478049881645, "dist_entropy": 0.6543034712473551, "actor_grad_norm": 0.12682750821113586, "critic_grad_norm": 0.030232103541493416, "ratio": 0.9974162578582764, "entropy": 0.6543034712473551, "incre_win_rate": 0.9137931034482759, "step": 1136}
{"time": 1766668332.6855001, "phase": "train", "update": 1137, "total_env_steps": 3638400, "episode_reward": 0.33358457684516907, "value_loss": 0.005829141226907571, "policy_loss": -0.012362261231440167, "dist_entropy": 0.6431918025016785, "actor_grad_norm": 0.13228657841682434, "critic_grad_norm": 0.01895746774971485, "ratio": 1.0007504224777222, "entropy": 0.6431918025016785, "incre_win_rate": 0.8867924528301887, "step": 1137}
{"time": 1766668337.0781617, "phase": "train", "update": 1138, "total_env_steps": 3641600, "episode_reward": 0.32334253191947937, "value_loss": 0.0053778832157452905, "policy_loss": -0.012390724349027, "dist_entropy": 0.6461943507194519, "actor_grad_norm": 0.1238054558634758, "critic_grad_norm": 0.01912773959338665, "ratio": 1.000655174255371, "entropy": 0.6461943507194519, "incre_win_rate": 0.8703703703703703, "step": 1138}
{"time": 1766668341.4988842, "phase": "train", "update": 1139, "total_env_steps": 3644800, "episode_reward": 0.3223452866077423, "value_loss": 0.0043315285040686526, "policy_loss": -0.013716990076165558, "dist_entropy": 0.6635785619417827, "actor_grad_norm": 0.1440591961145401, "critic_grad_norm": 0.009614817798137665, "ratio": 0.9991391897201538, "entropy": 0.6635785619417827, "incre_win_rate": 0.94, "step": 1139}
{"time": 1766668345.9727888, "phase": "train", "update": 1140, "total_env_steps": 3648000, "episode_reward": 0.3127267062664032, "value_loss": 0.009006267413496971, "policy_loss": -0.013568104677561147, "dist_entropy": 0.6380286971728008, "actor_grad_norm": 0.1771569401025772, "critic_grad_norm": 0.027004500851035118, "ratio": 0.9995989799499512, "entropy": 0.6380286971728008, "incre_win_rate": 0.8333333333333334, "step": 1140}
{"time": 1766668350.4035678, "phase": "train", "update": 1141, "total_env_steps": 3651200, "episode_reward": 0.3325038552284241, "value_loss": 0.006304539243380229, "policy_loss": -0.013898123241213985, "dist_entropy": 0.6452582756678263, "actor_grad_norm": 0.1353500932455063, "critic_grad_norm": 0.050489477813243866, "ratio": 0.9977667927742004, "entropy": 0.6452582756678263, "incre_win_rate": 0.9107142857142857, "step": 1141}
{"time": 1766668357.939692, "phase": "eval", "update": 1141, "total_env_steps": 3651200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.4609375, "step": 1141}
{"time": 1766668362.3169289, "phase": "train", "update": 1142, "total_env_steps": 3654400, "episode_reward": 0.319575697183609, "value_loss": 0.006330336319903532, "policy_loss": -0.014580691396794047, "dist_entropy": 0.6473811070124308, "actor_grad_norm": 0.16695818305015564, "critic_grad_norm": 0.0288527999073267, "ratio": 0.9986791610717773, "entropy": 0.6473811070124308, "incre_win_rate": 0.8301886792452831, "step": 1142}
{"time": 1766668397.2209253, "phase": "train", "update": 1143, "total_env_steps": 3657600, "episode_reward": 0.31444549560546875, "value_loss": 0.05337277725338936, "policy_loss": -0.012478432882186752, "dist_entropy": 0.6599412123362224, "actor_grad_norm": 0.12599030137062073, "critic_grad_norm": 0.20127248764038086, "ratio": 1.0018891096115112, "entropy": 0.6599412123362224, "incre_win_rate": 0.6730769230769231, "step": 1143}
{"time": 1766668401.6701066, "phase": "train", "update": 1144, "total_env_steps": 3660800, "episode_reward": 0.31291669607162476, "value_loss": 0.008389132531980674, "policy_loss": -0.015330999533359584, "dist_entropy": 0.6771852890650432, "actor_grad_norm": 0.13799528777599335, "critic_grad_norm": 0.08005250245332718, "ratio": 0.9987597465515137, "entropy": 0.6771852890650432, "incre_win_rate": 0.8269230769230769, "step": 1144}
{"time": 1766668406.0945163, "phase": "train", "update": 1145, "total_env_steps": 3664000, "episode_reward": 0.33180227875709534, "value_loss": 0.005791407202680906, "policy_loss": -0.015009111161585527, "dist_entropy": 0.6912742098172505, "actor_grad_norm": 0.14443856477737427, "critic_grad_norm": 0.06451524049043655, "ratio": 0.9992656111717224, "entropy": 0.6912742098172505, "incre_win_rate": 0.8888888888888888, "step": 1145}
{"time": 1766668410.5040882, "phase": "train", "update": 1146, "total_env_steps": 3667200, "episode_reward": 0.3189261853694916, "value_loss": 0.009633191178242366, "policy_loss": -0.014735667096676982, "dist_entropy": 0.6754960298538208, "actor_grad_norm": 0.15791894495487213, "critic_grad_norm": 0.032306745648384094, "ratio": 0.998660683631897, "entropy": 0.6754960298538208, "incre_win_rate": 0.8301886792452831, "step": 1146}
{"time": 1766668414.8923354, "phase": "train", "update": 1147, "total_env_steps": 3670400, "episode_reward": 0.3266727924346924, "value_loss": 0.00951487353692452, "policy_loss": -0.014907209954155102, "dist_entropy": 0.6769717971483866, "actor_grad_norm": 0.12689657509326935, "critic_grad_norm": 0.02015293948352337, "ratio": 0.998642086982727, "entropy": 0.6769717971483866, "incre_win_rate": 0.8596491228070176, "step": 1147}
{"time": 1766668419.3308742, "phase": "train", "update": 1148, "total_env_steps": 3673600, "episode_reward": 0.3266390860080719, "value_loss": 0.007083240834375223, "policy_loss": -0.013372556883845673, "dist_entropy": 0.6811827023824056, "actor_grad_norm": 0.14407536387443542, "critic_grad_norm": 0.028891904279589653, "ratio": 0.9985564947128296, "entropy": 0.6811827023824056, "incre_win_rate": 0.8301886792452831, "step": 1148}
{"time": 1766668423.8447278, "phase": "train", "update": 1149, "total_env_steps": 3676800, "episode_reward": 0.32515090703964233, "value_loss": 0.008312137207637231, "policy_loss": -0.01498469961924703, "dist_entropy": 0.6790065368016561, "actor_grad_norm": 0.16246463358402252, "critic_grad_norm": 0.03258625417947769, "ratio": 0.9985679984092712, "entropy": 0.6790065368016561, "incre_win_rate": 0.8703703703703703, "step": 1149}
{"time": 1766668428.224642, "phase": "train", "update": 1150, "total_env_steps": 3680000, "episode_reward": 0.3213541805744171, "value_loss": 0.009006838376323382, "policy_loss": -0.014187883719407069, "dist_entropy": 0.6901661157608032, "actor_grad_norm": 0.14117741584777832, "critic_grad_norm": 0.03910594433546066, "ratio": 1.0008963346481323, "entropy": 0.6901661157608032, "incre_win_rate": 0.8867924528301887, "step": 1150}
{"time": 1766668432.617192, "phase": "train", "update": 1151, "total_env_steps": 3683200, "episode_reward": 0.3233785331249237, "value_loss": 0.007144180374840895, "policy_loss": -0.01394911820971411, "dist_entropy": 0.6831780751546224, "actor_grad_norm": 0.13355062901973724, "critic_grad_norm": 0.03019765578210354, "ratio": 1.000791311264038, "entropy": 0.6831780751546224, "incre_win_rate": 0.9056603773584906, "step": 1151}
{"time": 1766668437.0011451, "phase": "train", "update": 1152, "total_env_steps": 3686400, "episode_reward": 0.32809051871299744, "value_loss": 0.008842859355111917, "policy_loss": -0.012991141375745722, "dist_entropy": 0.6990331808725992, "actor_grad_norm": 0.13174207508563995, "critic_grad_norm": 0.019620485603809357, "ratio": 1.0001355409622192, "entropy": 0.6990331808725992, "incre_win_rate": 0.8545454545454545, "step": 1152}
{"time": 1766668441.391185, "phase": "train", "update": 1153, "total_env_steps": 3689600, "episode_reward": 0.3216414153575897, "value_loss": 0.007907150592654944, "policy_loss": -0.01417313068086609, "dist_entropy": 0.7103626767794291, "actor_grad_norm": 0.1468202769756317, "critic_grad_norm": 0.016994459554553032, "ratio": 0.9992007613182068, "entropy": 0.7103626767794291, "incre_win_rate": 0.8727272727272727, "step": 1153}
{"time": 1766668445.8181007, "phase": "train", "update": 1154, "total_env_steps": 3692800, "episode_reward": 0.3228515684604645, "value_loss": 0.007976618967950344, "policy_loss": -0.014700626387693205, "dist_entropy": 0.7091191450754801, "actor_grad_norm": 0.1472991406917572, "critic_grad_norm": 0.01222390029579401, "ratio": 1.0001195669174194, "entropy": 0.7091191450754801, "incre_win_rate": 0.8181818181818182, "step": 1154}
{"time": 1766668450.5171406, "phase": "train", "update": 1155, "total_env_steps": 3696000, "episode_reward": 0.3051309883594513, "value_loss": 0.010660875961184502, "policy_loss": -0.014005244400840692, "dist_entropy": 0.6734958132108052, "actor_grad_norm": 0.15004703402519226, "critic_grad_norm": 0.031437408179044724, "ratio": 1.0009500980377197, "entropy": 0.6734958132108052, "incre_win_rate": 0.76, "step": 1155}
{"time": 1766668455.4831474, "phase": "train", "update": 1156, "total_env_steps": 3699200, "episode_reward": 0.30356234312057495, "value_loss": 0.008753828269739946, "policy_loss": -0.014672389584510863, "dist_entropy": 0.6984412034352621, "actor_grad_norm": 0.13733802735805511, "critic_grad_norm": 0.027356278151273727, "ratio": 1.0000077486038208, "entropy": 0.6984412034352621, "incre_win_rate": 0.7735849056603774, "step": 1156}
{"time": 1766668459.8612602, "phase": "train", "update": 1157, "total_env_steps": 3702400, "episode_reward": 0.3163764178752899, "value_loss": 0.012371503065029781, "policy_loss": -0.01586995929379782, "dist_entropy": 0.6931266546249389, "actor_grad_norm": 0.14756867289543152, "critic_grad_norm": 0.047498203814029694, "ratio": 0.9985629320144653, "entropy": 0.6931266546249389, "incre_win_rate": 0.8076923076923077, "step": 1157}
{"time": 1766668464.0817451, "phase": "train", "update": 1158, "total_env_steps": 3705600, "episode_reward": 0.31439492106437683, "value_loss": 0.009497531813879807, "policy_loss": -0.015021282527055865, "dist_entropy": 0.7124584158261617, "actor_grad_norm": 0.15809987485408783, "critic_grad_norm": 0.021120727062225342, "ratio": 0.9990175366401672, "entropy": 0.7124584158261617, "incre_win_rate": 0.7678571428571429, "step": 1158}
{"time": 1766668468.4169364, "phase": "train", "update": 1159, "total_env_steps": 3708800, "episode_reward": 0.3271070718765259, "value_loss": 0.008139675327887138, "policy_loss": -0.014660115649191615, "dist_entropy": 0.6988349318504333, "actor_grad_norm": 0.13886293768882751, "critic_grad_norm": 0.017714638262987137, "ratio": 0.9989599585533142, "entropy": 0.6988349318504333, "incre_win_rate": 0.875, "step": 1159}
{"time": 1766668472.65411, "phase": "train", "update": 1160, "total_env_steps": 3712000, "episode_reward": 0.3135562241077423, "value_loss": 0.010505713832875093, "policy_loss": -0.015141174901033594, "dist_entropy": 0.6780136823654175, "actor_grad_norm": 0.1526193767786026, "critic_grad_norm": 0.016954507678747177, "ratio": 0.9987620711326599, "entropy": 0.6780136823654175, "incre_win_rate": 0.803921568627451, "step": 1160}
{"time": 1766668476.8713164, "phase": "train", "update": 1161, "total_env_steps": 3715200, "episode_reward": 0.30377069115638733, "value_loss": 0.011277741131683191, "policy_loss": -0.015184261043083324, "dist_entropy": 0.708899708588918, "actor_grad_norm": 0.14708276093006134, "critic_grad_norm": 0.030577046796679497, "ratio": 1.0005732774734497, "entropy": 0.708899708588918, "incre_win_rate": 0.6981132075471698, "step": 1161}
{"time": 1766668484.579163, "phase": "eval", "update": 1161, "total_env_steps": 3715200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.399662990196077, "step": 1161}
{"time": 1766668489.09181, "phase": "train", "update": 1162, "total_env_steps": 3718400, "episode_reward": 0.3181755542755127, "value_loss": 0.007723543699830771, "policy_loss": -0.015382291191904093, "dist_entropy": 0.6964013497034709, "actor_grad_norm": 0.19207726418972015, "critic_grad_norm": 0.026969093829393387, "ratio": 1.000868558883667, "entropy": 0.6964013497034709, "incre_win_rate": 0.8679245283018868, "step": 1162}
{"time": 1766668493.5698106, "phase": "train", "update": 1163, "total_env_steps": 3721600, "episode_reward": 0.2975827157497406, "value_loss": 0.014539346098899841, "policy_loss": -0.016517529574623067, "dist_entropy": 0.7091117779413859, "actor_grad_norm": 0.15246805548667908, "critic_grad_norm": 0.04947670176625252, "ratio": 0.999387264251709, "entropy": 0.7091117779413859, "incre_win_rate": 0.7647058823529411, "step": 1163}
{"time": 1766668497.7387302, "phase": "train", "update": 1164, "total_env_steps": 3724800, "episode_reward": 0.28834253549575806, "value_loss": 0.009682124232252438, "policy_loss": -0.01544862018551451, "dist_entropy": 0.7044638276100159, "actor_grad_norm": 0.18925416469573975, "critic_grad_norm": 0.03479279577732086, "ratio": 0.999678909778595, "entropy": 0.7044638276100159, "incre_win_rate": 0.7115384615384616, "step": 1164}
{"time": 1766668501.9833257, "phase": "train", "update": 1165, "total_env_steps": 3728000, "episode_reward": 0.3016643822193146, "value_loss": 0.010459436972935995, "policy_loss": -0.014818687766070345, "dist_entropy": 0.6933581789334615, "actor_grad_norm": 0.17905649542808533, "critic_grad_norm": 0.020816998556256294, "ratio": 0.9999950528144836, "entropy": 0.6933581789334615, "incre_win_rate": 0.7450980392156863, "step": 1165}
{"time": 1766668506.1944964, "phase": "train", "update": 1166, "total_env_steps": 3731200, "episode_reward": 0.31420421600341797, "value_loss": 0.011670458068450292, "policy_loss": -0.01582406102912633, "dist_entropy": 0.6834974368413289, "actor_grad_norm": 0.18343046307563782, "critic_grad_norm": 0.032494038343429565, "ratio": 1.000190019607544, "entropy": 0.6834974368413289, "incre_win_rate": 0.7735849056603774, "step": 1166}
{"time": 1766668510.4349184, "phase": "train", "update": 1167, "total_env_steps": 3734400, "episode_reward": 0.322549045085907, "value_loss": 0.009275807067751884, "policy_loss": -0.013777699366401445, "dist_entropy": 0.6899616320927938, "actor_grad_norm": 0.14658726751804352, "critic_grad_norm": 0.029278136789798737, "ratio": 1.0002517700195312, "entropy": 0.6899616320927938, "incre_win_rate": 0.8545454545454545, "step": 1167}
{"time": 1766668514.6510649, "phase": "train", "update": 1168, "total_env_steps": 3737600, "episode_reward": 0.30994561314582825, "value_loss": 0.008726360493650038, "policy_loss": -0.014174443005857995, "dist_entropy": 0.6953381458918254, "actor_grad_norm": 0.13447104394435883, "critic_grad_norm": 0.01869327761232853, "ratio": 0.9992331862449646, "entropy": 0.6953381458918254, "incre_win_rate": 0.8113207547169812, "step": 1168}
{"time": 1766668518.8473284, "phase": "train", "update": 1169, "total_env_steps": 3740800, "episode_reward": 0.3099479377269745, "value_loss": 0.009196552510062853, "policy_loss": -0.014881591146950276, "dist_entropy": 0.6791467507680257, "actor_grad_norm": 0.16189487278461456, "critic_grad_norm": 0.045211486518383026, "ratio": 0.9989350438117981, "entropy": 0.6791467507680257, "incre_win_rate": 0.7222222222222222, "step": 1169}
{"time": 1766668523.1043944, "phase": "train", "update": 1170, "total_env_steps": 3744000, "episode_reward": 0.3277183175086975, "value_loss": 0.007757093260685603, "policy_loss": -0.014999096551265249, "dist_entropy": 0.6852708180745443, "actor_grad_norm": 0.16256634891033173, "critic_grad_norm": 0.017905907705426216, "ratio": 0.9992678165435791, "entropy": 0.6852708180745443, "incre_win_rate": 0.9056603773584906, "step": 1170}
{"time": 1766668527.3440049, "phase": "train", "update": 1171, "total_env_steps": 3747200, "episode_reward": 0.30712392926216125, "value_loss": 0.009774577928086121, "policy_loss": -0.014000572606678929, "dist_entropy": 0.6919355273246766, "actor_grad_norm": 0.13065345585346222, "critic_grad_norm": 0.03294641152024269, "ratio": 0.9989984035491943, "entropy": 0.6919355273246766, "incre_win_rate": 0.8431372549019608, "step": 1171}
{"time": 1766668531.6004384, "phase": "train", "update": 1172, "total_env_steps": 3750400, "episode_reward": 0.3138059377670288, "value_loss": 0.009072452783584595, "policy_loss": -0.014667792743665586, "dist_entropy": 0.6680988033612569, "actor_grad_norm": 0.13785433769226074, "critic_grad_norm": 0.026719331741333008, "ratio": 0.9989127516746521, "entropy": 0.6680988033612569, "incre_win_rate": 0.8461538461538461, "step": 1172}
{"time": 1766668535.934995, "phase": "train", "update": 1173, "total_env_steps": 3753600, "episode_reward": 0.3195327818393707, "value_loss": 0.005836105408767859, "policy_loss": -0.014906469014505793, "dist_entropy": 0.6827807585398357, "actor_grad_norm": 0.15938369929790497, "critic_grad_norm": 0.03597802296280861, "ratio": 0.9985564351081848, "entropy": 0.6827807585398357, "incre_win_rate": 0.8703703703703703, "step": 1173}
{"time": 1766668540.1747952, "phase": "train", "update": 1174, "total_env_steps": 3756800, "episode_reward": 0.3133969008922577, "value_loss": 0.008814809223016104, "policy_loss": -0.0156310288205295, "dist_entropy": 0.6727652152379354, "actor_grad_norm": 0.14774714410305023, "critic_grad_norm": 0.01981169730424881, "ratio": 1.0002849102020264, "entropy": 0.6727652152379354, "incre_win_rate": 0.7924528301886793, "step": 1174}
{"time": 1766668544.4295943, "phase": "train", "update": 1175, "total_env_steps": 3760000, "episode_reward": 0.3185562491416931, "value_loss": 0.005241559011240801, "policy_loss": -0.014901065571399386, "dist_entropy": 0.6790389855702718, "actor_grad_norm": 0.18102522194385529, "critic_grad_norm": 0.016346879303455353, "ratio": 0.9989760518074036, "entropy": 0.6790389855702718, "incre_win_rate": 0.8653846153846154, "step": 1175}
{"time": 1766668548.7015421, "phase": "train", "update": 1176, "total_env_steps": 3763200, "episode_reward": 0.32811352610588074, "value_loss": 0.006885968986898661, "policy_loss": -0.014066783939240206, "dist_entropy": 0.6764069477717082, "actor_grad_norm": 0.14679358899593353, "critic_grad_norm": 0.014760873280465603, "ratio": 0.9981539249420166, "entropy": 0.6764069477717082, "incre_win_rate": 0.8545454545454545, "step": 1176}
{"time": 1766668552.9397783, "phase": "train", "update": 1177, "total_env_steps": 3766400, "episode_reward": 0.3228262960910797, "value_loss": 0.00836645026380817, "policy_loss": -0.013228880031722194, "dist_entropy": 0.6901129722595215, "actor_grad_norm": 0.1469116359949112, "critic_grad_norm": 0.015487443655729294, "ratio": 1.0004326105117798, "entropy": 0.6901129722595215, "incre_win_rate": 0.8867924528301887, "step": 1177}
{"time": 1766668557.1661432, "phase": "train", "update": 1178, "total_env_steps": 3769600, "episode_reward": 0.32137179374694824, "value_loss": 0.0077137205439309275, "policy_loss": -0.013875266571761812, "dist_entropy": 0.6753037333488464, "actor_grad_norm": 0.14891047775745392, "critic_grad_norm": 0.012885067611932755, "ratio": 0.9990715980529785, "entropy": 0.6753037333488464, "incre_win_rate": 0.8679245283018868, "step": 1178}
{"time": 1766668561.371363, "phase": "train", "update": 1179, "total_env_steps": 3772800, "episode_reward": 0.30246326327323914, "value_loss": 0.009077365634342034, "policy_loss": -0.014717746879542895, "dist_entropy": 0.6791142185529073, "actor_grad_norm": 0.14534147083759308, "critic_grad_norm": 0.032799653708934784, "ratio": 1.0004191398620605, "entropy": 0.6791142185529073, "incre_win_rate": 0.7592592592592593, "step": 1179}
{"time": 1766668565.6551769, "phase": "train", "update": 1180, "total_env_steps": 3776000, "episode_reward": 0.3148353397846222, "value_loss": 0.008189913723617792, "policy_loss": -0.014745949670781518, "dist_entropy": 0.6904888391494751, "actor_grad_norm": 0.1356080025434494, "critic_grad_norm": 0.012521566823124886, "ratio": 0.999301016330719, "entropy": 0.6904888391494751, "incre_win_rate": 0.8076923076923077, "step": 1180}
{"time": 1766668569.9130535, "phase": "train", "update": 1181, "total_env_steps": 3779200, "episode_reward": 0.3152420222759247, "value_loss": 0.007967197460432847, "policy_loss": -0.01576002573279472, "dist_entropy": 0.6973264892896016, "actor_grad_norm": 0.14136438071727753, "critic_grad_norm": 0.011329914443194866, "ratio": 0.9998390674591064, "entropy": 0.6973264892896016, "incre_win_rate": 0.8269230769230769, "step": 1181}
{"time": 1766668577.807177, "phase": "eval", "update": 1181, "total_env_steps": 3779200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.83264399509804, "step": 1181}
{"time": 1766668582.3199368, "phase": "train", "update": 1182, "total_env_steps": 3782400, "episode_reward": 0.318147212266922, "value_loss": 0.008287749656786522, "policy_loss": -0.014444772143655154, "dist_entropy": 0.6933438499768575, "actor_grad_norm": 0.1503424197435379, "critic_grad_norm": 0.01228609960526228, "ratio": 1.0011526346206665, "entropy": 0.6933438499768575, "incre_win_rate": 0.8888888888888888, "step": 1182}
{"time": 1766668586.6475687, "phase": "train", "update": 1183, "total_env_steps": 3785600, "episode_reward": 0.32194164395332336, "value_loss": 0.0052479415821532404, "policy_loss": -0.01433800842220047, "dist_entropy": 0.6901729345321655, "actor_grad_norm": 0.1517454981803894, "critic_grad_norm": 0.026072822511196136, "ratio": 0.999879777431488, "entropy": 0.6901729345321655, "incre_win_rate": 0.9038461538461539, "step": 1183}
{"time": 1766668590.9601154, "phase": "train", "update": 1184, "total_env_steps": 3788800, "episode_reward": 0.3173169493675232, "value_loss": 0.00731476383904616, "policy_loss": -0.0162787618015102, "dist_entropy": 0.6870465755462647, "actor_grad_norm": 0.1533517688512802, "critic_grad_norm": 0.01442031655460596, "ratio": 1.000165343284607, "entropy": 0.6870465755462647, "incre_win_rate": 0.8518518518518519, "step": 1184}
{"time": 1766668595.3026612, "phase": "train", "update": 1185, "total_env_steps": 3792000, "episode_reward": 0.30752912163734436, "value_loss": 0.008475463899473349, "policy_loss": -0.015322951579238027, "dist_entropy": 0.6908009092013041, "actor_grad_norm": 0.13883846998214722, "critic_grad_norm": 0.01134366076439619, "ratio": 1.0015712976455688, "entropy": 0.6908009092013041, "incre_win_rate": 0.84, "step": 1185}
{"time": 1766668599.5997055, "phase": "train", "update": 1186, "total_env_steps": 3795200, "episode_reward": 0.3167562782764435, "value_loss": 0.007792415966590246, "policy_loss": -0.015507391936385773, "dist_entropy": 0.6904191374778748, "actor_grad_norm": 0.16274701058864594, "critic_grad_norm": 0.00713784946128726, "ratio": 1.0004668235778809, "entropy": 0.6904191374778748, "incre_win_rate": 0.8461538461538461, "step": 1186}
{"time": 1766668603.9359758, "phase": "train", "update": 1187, "total_env_steps": 3798400, "episode_reward": 0.31011489033699036, "value_loss": 0.010584125109016896, "policy_loss": -0.015476991048876699, "dist_entropy": 0.6827431519826254, "actor_grad_norm": 0.1516771912574768, "critic_grad_norm": 0.03206842392683029, "ratio": 1.0004706382751465, "entropy": 0.6827431519826254, "incre_win_rate": 0.7818181818181819, "step": 1187}
{"time": 1766668608.2680829, "phase": "train", "update": 1188, "total_env_steps": 3801600, "episode_reward": 0.317514568567276, "value_loss": 0.008564577313760917, "policy_loss": -0.015126882734615302, "dist_entropy": 0.678775445620219, "actor_grad_norm": 0.14772658050060272, "critic_grad_norm": 0.010756946168839931, "ratio": 0.9999869465827942, "entropy": 0.678775445620219, "incre_win_rate": 0.8333333333333334, "step": 1188}
{"time": 1766668612.4727314, "phase": "train", "update": 1189, "total_env_steps": 3804800, "episode_reward": 0.3135654330253601, "value_loss": 0.006295777733127276, "policy_loss": -0.014866331531644761, "dist_entropy": 0.6776285131772359, "actor_grad_norm": 0.15702320635318756, "critic_grad_norm": 0.03988305479288101, "ratio": 0.9995642900466919, "entropy": 0.6776285131772359, "incre_win_rate": 0.92, "step": 1189}
{"time": 1766668617.1165917, "phase": "train", "update": 1190, "total_env_steps": 3808000, "episode_reward": 0.31007274985313416, "value_loss": 0.00762829032416145, "policy_loss": -0.015169270111174409, "dist_entropy": 0.6809859673182169, "actor_grad_norm": 0.14550776779651642, "critic_grad_norm": 0.020158343017101288, "ratio": 0.9997111558914185, "entropy": 0.6809859673182169, "incre_win_rate": 0.8431372549019608, "step": 1190}
{"time": 1766668621.3906062, "phase": "train", "update": 1191, "total_env_steps": 3811200, "episode_reward": 0.3138350248336792, "value_loss": 0.006991926270226638, "policy_loss": -0.01488877757613949, "dist_entropy": 0.6702098290125529, "actor_grad_norm": 0.2079383283853531, "critic_grad_norm": 0.02059316821396351, "ratio": 0.9995335936546326, "entropy": 0.6702098290125529, "incre_win_rate": 0.8113207547169812, "step": 1191}
{"time": 1766668625.891951, "phase": "train", "update": 1192, "total_env_steps": 3814400, "episode_reward": 0.32775431871414185, "value_loss": 0.007152049833287795, "policy_loss": -0.013158605116623789, "dist_entropy": 0.6801036715507507, "actor_grad_norm": 0.16372664272785187, "critic_grad_norm": 0.015834124758839607, "ratio": 1.0008386373519897, "entropy": 0.6801036715507507, "incre_win_rate": 0.8909090909090909, "step": 1192}
{"time": 1766668630.366991, "phase": "train", "update": 1193, "total_env_steps": 3817600, "episode_reward": 0.3033609092235565, "value_loss": 0.009239734771351019, "policy_loss": -0.014796409460301873, "dist_entropy": 0.6804369211196899, "actor_grad_norm": 0.178134486079216, "critic_grad_norm": 0.03264553099870682, "ratio": 0.99947190284729, "entropy": 0.6804369211196899, "incre_win_rate": 0.84, "step": 1193}
{"time": 1766668634.982713, "phase": "train", "update": 1194, "total_env_steps": 3820800, "episode_reward": 0.32950136065483093, "value_loss": 0.004946842572341363, "policy_loss": -0.01368472041252519, "dist_entropy": 0.6756289919217427, "actor_grad_norm": 0.16410963237285614, "critic_grad_norm": 0.03370489180088043, "ratio": 0.9989799857139587, "entropy": 0.6756289919217427, "incre_win_rate": 0.9285714285714286, "step": 1194}
{"time": 1766668639.2302375, "phase": "train", "update": 1195, "total_env_steps": 3824000, "episode_reward": 0.31672948598861694, "value_loss": 0.007124716695398092, "policy_loss": -0.016150856106995567, "dist_entropy": 0.6930595835049947, "actor_grad_norm": 0.13356883823871613, "critic_grad_norm": 0.021831972524523735, "ratio": 1.000120759010315, "entropy": 0.6930595835049947, "incre_win_rate": 0.8823529411764706, "step": 1195}
{"time": 1766668643.4330251, "phase": "train", "update": 1196, "total_env_steps": 3827200, "episode_reward": 0.3202788233757019, "value_loss": 0.006839479288707177, "policy_loss": -0.014647054392398218, "dist_entropy": 0.7019343535105388, "actor_grad_norm": 0.153494730591774, "critic_grad_norm": 0.010099952109158039, "ratio": 0.9990256428718567, "entropy": 0.7019343535105388, "incre_win_rate": 0.8888888888888888, "step": 1196}
{"time": 1766668647.6444998, "phase": "train", "update": 1197, "total_env_steps": 3830400, "episode_reward": 0.2970312535762787, "value_loss": 0.010761824809014798, "policy_loss": -0.014841827602845114, "dist_entropy": 0.6859540502230327, "actor_grad_norm": 0.13403353095054626, "critic_grad_norm": 0.04353109002113342, "ratio": 1.0004100799560547, "entropy": 0.6859540502230327, "incre_win_rate": 0.7551020408163265, "step": 1197}
{"time": 1766668651.8770251, "phase": "train", "update": 1198, "total_env_steps": 3833600, "episode_reward": 0.3111082911491394, "value_loss": 0.008969544246792794, "policy_loss": -0.015079128575969018, "dist_entropy": 0.6900381326675415, "actor_grad_norm": 0.1806650161743164, "critic_grad_norm": 0.026134375482797623, "ratio": 0.9992053508758545, "entropy": 0.6900381326675415, "incre_win_rate": 0.7962962962962963, "step": 1198}
{"time": 1766668656.131842, "phase": "train", "update": 1199, "total_env_steps": 3836800, "episode_reward": 0.31161460280418396, "value_loss": 0.009519120305776596, "policy_loss": -0.014856750493612481, "dist_entropy": 0.682595690091451, "actor_grad_norm": 0.14678601920604706, "critic_grad_norm": 0.022171681746840477, "ratio": 1.0007179975509644, "entropy": 0.682595690091451, "incre_win_rate": 0.8113207547169812, "step": 1199}
{"time": 1766668660.379298, "phase": "train", "update": 1200, "total_env_steps": 3840000, "episode_reward": 0.31217601895332336, "value_loss": 0.008884931914508343, "policy_loss": -0.014588070385856137, "dist_entropy": 0.6942245046297709, "actor_grad_norm": 0.13753752410411835, "critic_grad_norm": 0.021559489890933037, "ratio": 1.001035213470459, "entropy": 0.6942245046297709, "incre_win_rate": 0.8113207547169812, "step": 1200}
{"time": 1766668664.707043, "phase": "train", "update": 1201, "total_env_steps": 3843200, "episode_reward": 0.3183164596557617, "value_loss": 0.007639969636996587, "policy_loss": -0.015230497117394748, "dist_entropy": 0.6713573257128398, "actor_grad_norm": 0.1322198361158371, "critic_grad_norm": 0.011081653647124767, "ratio": 0.9997978806495667, "entropy": 0.6713573257128398, "incre_win_rate": 0.8461538461538461, "step": 1201}
{"time": 1766668672.6522903, "phase": "eval", "update": 1201, "total_env_steps": 3843200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.733532475490197, "step": 1201}
{"time": 1766668676.8749075, "phase": "train", "update": 1202, "total_env_steps": 3846400, "episode_reward": 0.3295641839504242, "value_loss": 0.006470122002065181, "policy_loss": -0.015209690331419286, "dist_entropy": 0.6593749086062114, "actor_grad_norm": 0.15595224499702454, "critic_grad_norm": 0.04643125832080841, "ratio": 0.9983549118041992, "entropy": 0.6593749086062114, "incre_win_rate": 0.9622641509433962, "step": 1202}
{"time": 1766668681.0934265, "phase": "train", "update": 1203, "total_env_steps": 3849600, "episode_reward": 0.3157590627670288, "value_loss": 0.008540666103363037, "policy_loss": -0.014589979980534433, "dist_entropy": 0.6747278889020284, "actor_grad_norm": 0.15202561020851135, "critic_grad_norm": 0.03138982132077217, "ratio": 0.9996959567070007, "entropy": 0.6747278889020284, "incre_win_rate": 0.8181818181818182, "step": 1203}
{"time": 1766668685.3603547, "phase": "train", "update": 1204, "total_env_steps": 3852800, "episode_reward": 0.3187974989414215, "value_loss": 0.00619782501210769, "policy_loss": -0.014250589846954516, "dist_entropy": 0.6761883894602457, "actor_grad_norm": 0.1392950862646103, "critic_grad_norm": 0.022844381630420685, "ratio": 1.0004053115844727, "entropy": 0.6761883894602457, "incre_win_rate": 0.8653846153846154, "step": 1204}
{"time": 1766668689.6032763, "phase": "train", "update": 1205, "total_env_steps": 3856000, "episode_reward": 0.32049939036369324, "value_loss": 0.009850671763221424, "policy_loss": -0.015185333387957673, "dist_entropy": 0.6728843887646992, "actor_grad_norm": 0.1874220371246338, "critic_grad_norm": 0.021015064790844917, "ratio": 1.0005565881729126, "entropy": 0.6728843887646992, "incre_win_rate": 0.8148148148148148, "step": 1205}
{"time": 1766668693.8016539, "phase": "train", "update": 1206, "total_env_steps": 3859200, "episode_reward": 0.31707414984703064, "value_loss": 0.008450492937117814, "policy_loss": -0.013216884020483615, "dist_entropy": 0.6528974533081054, "actor_grad_norm": 0.1385667622089386, "critic_grad_norm": 0.0115314656868577, "ratio": 1.0006057024002075, "entropy": 0.6528974533081054, "incre_win_rate": 0.8461538461538461, "step": 1206}
{"time": 1766668698.0890775, "phase": "train", "update": 1207, "total_env_steps": 3862400, "episode_reward": 0.3203538656234741, "value_loss": 0.008016722463071346, "policy_loss": -0.012872142275541402, "dist_entropy": 0.6590035359064738, "actor_grad_norm": 0.1543806791305542, "critic_grad_norm": 0.02112884260714054, "ratio": 1.0008931159973145, "entropy": 0.6590035359064738, "incre_win_rate": 0.8148148148148148, "step": 1207}
{"time": 1766668702.2904093, "phase": "train", "update": 1208, "total_env_steps": 3865600, "episode_reward": 0.3290058374404907, "value_loss": 0.005795523524284363, "policy_loss": -0.014776695172308034, "dist_entropy": 0.6690999031066894, "actor_grad_norm": 0.13825452327728271, "critic_grad_norm": 0.01623721234500408, "ratio": 0.9985047578811646, "entropy": 0.6690999031066894, "incre_win_rate": 0.9444444444444444, "step": 1208}
{"time": 1766668706.5197716, "phase": "train", "update": 1209, "total_env_steps": 3868800, "episode_reward": 0.3243167996406555, "value_loss": 0.008118966532250246, "policy_loss": -0.014725024014388074, "dist_entropy": 0.6683045903841655, "actor_grad_norm": 0.1540747433900833, "critic_grad_norm": 0.011609396897256374, "ratio": 1.000290870666504, "entropy": 0.6683045903841655, "incre_win_rate": 0.8518518518518519, "step": 1209}
{"time": 1766668710.7621467, "phase": "train", "update": 1210, "total_env_steps": 3872000, "episode_reward": 0.3136902451515198, "value_loss": 0.00943907368928194, "policy_loss": -0.014509062667503276, "dist_entropy": 0.6785187085469564, "actor_grad_norm": 0.12856175005435944, "critic_grad_norm": 0.01880369335412979, "ratio": 1.0014110803604126, "entropy": 0.6785187085469564, "incre_win_rate": 0.8363636363636363, "step": 1210}
{"time": 1766668714.9584076, "phase": "train", "update": 1211, "total_env_steps": 3875200, "episode_reward": 0.31316789984703064, "value_loss": 0.007049661533286174, "policy_loss": -0.01461292444914856, "dist_entropy": 0.6709068338076274, "actor_grad_norm": 0.13977429270744324, "critic_grad_norm": 0.011667252518236637, "ratio": 1.000243902206421, "entropy": 0.6709068338076274, "incre_win_rate": 0.9, "step": 1211}
{"time": 1766668719.2272563, "phase": "train", "update": 1212, "total_env_steps": 3878400, "episode_reward": 0.32057446241378784, "value_loss": 0.00641511787349979, "policy_loss": -0.01422261702782066, "dist_entropy": 0.6695793549219767, "actor_grad_norm": 0.13603575527668, "critic_grad_norm": 0.011874515563249588, "ratio": 0.9988474249839783, "entropy": 0.6695793549219767, "incre_win_rate": 0.8679245283018868, "step": 1212}
{"time": 1766668723.7425454, "phase": "train", "update": 1213, "total_env_steps": 3881600, "episode_reward": 0.3270204961299896, "value_loss": 0.006980480874578158, "policy_loss": -0.013421211366702343, "dist_entropy": 0.6738388379414876, "actor_grad_norm": 0.13951855897903442, "critic_grad_norm": 0.010597473941743374, "ratio": 1.0013763904571533, "entropy": 0.6738388379414876, "incre_win_rate": 0.9056603773584906, "step": 1213}
{"time": 1766668728.0283537, "phase": "train", "update": 1214, "total_env_steps": 3884800, "episode_reward": 0.32061272859573364, "value_loss": 0.006381150676558415, "policy_loss": -0.013936298167527639, "dist_entropy": 0.6608990629514059, "actor_grad_norm": 0.14657114446163177, "critic_grad_norm": 0.008128675632178783, "ratio": 1.0003775358200073, "entropy": 0.6608990629514059, "incre_win_rate": 0.8518518518518519, "step": 1214}
{"time": 1766668732.2850611, "phase": "train", "update": 1215, "total_env_steps": 3888000, "episode_reward": 0.3260968029499054, "value_loss": 0.007017036030689875, "policy_loss": -0.014021857739197093, "dist_entropy": 0.6663189093271892, "actor_grad_norm": 0.16546611487865448, "critic_grad_norm": 0.02276233583688736, "ratio": 1.0014855861663818, "entropy": 0.6663189093271892, "incre_win_rate": 0.8703703703703703, "step": 1215}
{"time": 1766668736.511274, "phase": "train", "update": 1216, "total_env_steps": 3891200, "episode_reward": 0.2991406321525574, "value_loss": 0.008529961171249548, "policy_loss": -0.013797376540676016, "dist_entropy": 0.6938686649004618, "actor_grad_norm": 0.17001785337924957, "critic_grad_norm": 0.03555716574192047, "ratio": 1.000258445739746, "entropy": 0.6938686649004618, "incre_win_rate": 0.7307692307692307, "step": 1216}
{"time": 1766668740.7627132, "phase": "train", "update": 1217, "total_env_steps": 3894400, "episode_reward": 0.32819774746894836, "value_loss": 0.005876908948024114, "policy_loss": -0.013827967126729845, "dist_entropy": 0.6678853313128154, "actor_grad_norm": 0.1540537327528, "critic_grad_norm": 0.024772508069872856, "ratio": 0.9986506700515747, "entropy": 0.6678853313128154, "incre_win_rate": 0.8888888888888888, "step": 1217}
{"time": 1766668744.9721246, "phase": "train", "update": 1218, "total_env_steps": 3897600, "episode_reward": 0.32280102372169495, "value_loss": 0.0073022331111133095, "policy_loss": -0.014538810594137886, "dist_entropy": 0.670136304696401, "actor_grad_norm": 0.14086881279945374, "critic_grad_norm": 0.028587911278009415, "ratio": 0.9989949464797974, "entropy": 0.670136304696401, "incre_win_rate": 0.8679245283018868, "step": 1218}
{"time": 1766668749.2484016, "phase": "train", "update": 1219, "total_env_steps": 3900800, "episode_reward": 0.32778647541999817, "value_loss": 0.005273144568006197, "policy_loss": -0.01304169864691526, "dist_entropy": 0.6805821140607198, "actor_grad_norm": 0.13768501579761505, "critic_grad_norm": 0.030336681753396988, "ratio": 0.9988575577735901, "entropy": 0.6805821140607198, "incre_win_rate": 0.9074074074074074, "step": 1219}
{"time": 1766668753.4456165, "phase": "train", "update": 1220, "total_env_steps": 3904000, "episode_reward": 0.33238279819488525, "value_loss": 0.00365601209923625, "policy_loss": -0.012631103816011565, "dist_entropy": 0.672186529636383, "actor_grad_norm": 0.12905143201351166, "critic_grad_norm": 0.02827630564570427, "ratio": 0.9990459680557251, "entropy": 0.672186529636383, "incre_win_rate": 0.9444444444444444, "step": 1220}
{"time": 1766668757.7698843, "phase": "train", "update": 1221, "total_env_steps": 3907200, "episode_reward": 0.3232713043689728, "value_loss": 0.007560447168846925, "policy_loss": -0.013510295769039733, "dist_entropy": 0.6585147619247437, "actor_grad_norm": 0.12382140010595322, "critic_grad_norm": 0.03218979388475418, "ratio": 0.9999486804008484, "entropy": 0.6585147619247437, "incre_win_rate": 0.8490566037735849, "step": 1221}
{"time": 1766668765.2518656, "phase": "eval", "update": 1221, "total_env_steps": 3907200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.85876225490196, "step": 1221}
{"time": 1766668769.5161467, "phase": "train", "update": 1222, "total_env_steps": 3910400, "episode_reward": 0.3212186098098755, "value_loss": 0.006502958076695601, "policy_loss": -0.013002226703574139, "dist_entropy": 0.6664396762847901, "actor_grad_norm": 0.13797113299369812, "critic_grad_norm": 0.00988614372909069, "ratio": 0.9992989301681519, "entropy": 0.6664396762847901, "incre_win_rate": 0.8703703703703703, "step": 1222}
{"time": 1766668773.7164364, "phase": "train", "update": 1223, "total_env_steps": 3913600, "episode_reward": 0.31713464856147766, "value_loss": 0.006555445274959008, "policy_loss": -0.01429969638646303, "dist_entropy": 0.6765146255493164, "actor_grad_norm": 0.15049345791339874, "critic_grad_norm": 0.014219610951840878, "ratio": 1.000102162361145, "entropy": 0.6765146255493164, "incre_win_rate": 0.8490566037735849, "step": 1223}
{"time": 1766668778.0028954, "phase": "train", "update": 1224, "total_env_steps": 3916800, "episode_reward": 0.32945770025253296, "value_loss": 0.004682670688877503, "policy_loss": -0.012346017966504755, "dist_entropy": 0.6648560881614685, "actor_grad_norm": 0.13924717903137207, "critic_grad_norm": 0.0122963422909379, "ratio": 1.0000457763671875, "entropy": 0.6648560881614685, "incre_win_rate": 0.8909090909090909, "step": 1224}
{"time": 1766668782.2064364, "phase": "train", "update": 1225, "total_env_steps": 3920000, "episode_reward": 0.3375551402568817, "value_loss": 0.00431657958154877, "policy_loss": -0.012808044633850576, "dist_entropy": 0.6535216450691224, "actor_grad_norm": 0.13977962732315063, "critic_grad_norm": 0.030036505311727524, "ratio": 0.9986279606819153, "entropy": 0.6535216450691224, "incre_win_rate": 0.9259259259259259, "step": 1225}
{"time": 1766668786.452729, "phase": "train", "update": 1226, "total_env_steps": 3923200, "episode_reward": 0.3355874717235565, "value_loss": 0.004511939268559218, "policy_loss": -0.013396866925630017, "dist_entropy": 0.675210702419281, "actor_grad_norm": 0.14631906151771545, "critic_grad_norm": 0.018089093267917633, "ratio": 0.9998027682304382, "entropy": 0.675210702419281, "incre_win_rate": 0.9090909090909091, "step": 1226}
{"time": 1766668790.732086, "phase": "train", "update": 1227, "total_env_steps": 3926400, "episode_reward": 0.34519532322883606, "value_loss": 0.003915198783700665, "policy_loss": -0.012961392519562765, "dist_entropy": 0.6828082879384358, "actor_grad_norm": 0.1369551122188568, "critic_grad_norm": 0.017246492207050323, "ratio": 1.0006991624832153, "entropy": 0.6828082879384358, "incre_win_rate": 0.9285714285714286, "step": 1227}
{"time": 1766668794.9276597, "phase": "train", "update": 1228, "total_env_steps": 3929600, "episode_reward": 0.34244486689567566, "value_loss": 0.003479194299628337, "policy_loss": -0.012865453353233155, "dist_entropy": 0.6917339444160462, "actor_grad_norm": 0.13344576954841614, "critic_grad_norm": 0.014673421159386635, "ratio": 0.9999678134918213, "entropy": 0.6917339444160462, "incre_win_rate": 0.9642857142857143, "step": 1228}
{"time": 1766668799.170385, "phase": "train", "update": 1229, "total_env_steps": 3932800, "episode_reward": 0.3227313160896301, "value_loss": 0.012962289899587632, "policy_loss": -0.013896975157157954, "dist_entropy": 0.7010943134625752, "actor_grad_norm": 0.12904688715934753, "critic_grad_norm": 0.045788977295160294, "ratio": 1.0007526874542236, "entropy": 0.7010943134625752, "incre_win_rate": 0.8727272727272727, "step": 1229}
{"time": 1766668803.401545, "phase": "train", "update": 1230, "total_env_steps": 3936000, "episode_reward": 0.31679150462150574, "value_loss": 0.007494285857925813, "policy_loss": -0.013150325550136444, "dist_entropy": 0.6811153491338094, "actor_grad_norm": 0.12111669033765793, "critic_grad_norm": 0.036743275821208954, "ratio": 0.9998849630355835, "entropy": 0.6811153491338094, "incre_win_rate": 0.8461538461538461, "step": 1230}
{"time": 1766668807.638379, "phase": "train", "update": 1231, "total_env_steps": 3939200, "episode_reward": 0.3271614611148834, "value_loss": 0.007578622549772263, "policy_loss": -0.013296338130229894, "dist_entropy": 0.6913976947466532, "actor_grad_norm": 0.15687653422355652, "critic_grad_norm": 0.02272234857082367, "ratio": 0.9992167949676514, "entropy": 0.6913976947466532, "incre_win_rate": 0.8679245283018868, "step": 1231}
{"time": 1766668811.8723845, "phase": "train", "update": 1232, "total_env_steps": 3942400, "episode_reward": 0.32396140694618225, "value_loss": 0.008371979556977749, "policy_loss": -0.014399068631634766, "dist_entropy": 0.6890751481056213, "actor_grad_norm": 0.16854052245616913, "critic_grad_norm": 0.011379564180970192, "ratio": 1.0002098083496094, "entropy": 0.6890751481056213, "incre_win_rate": 0.8333333333333334, "step": 1232}
{"time": 1766668816.0467744, "phase": "train", "update": 1233, "total_env_steps": 3945600, "episode_reward": 0.32924097776412964, "value_loss": 0.010651516541838647, "policy_loss": -0.013257879967944556, "dist_entropy": 0.6890597939491272, "actor_grad_norm": 0.13712212443351746, "critic_grad_norm": 0.01626017317175865, "ratio": 0.9998469352722168, "entropy": 0.6890597939491272, "incre_win_rate": 0.8909090909090909, "step": 1233}
{"time": 1766668820.3170614, "phase": "train", "update": 1234, "total_env_steps": 3948800, "episode_reward": 0.32990962266921997, "value_loss": 0.009645638056099415, "policy_loss": -0.014708690686864949, "dist_entropy": 0.6881531119346619, "actor_grad_norm": 0.1422838270664215, "critic_grad_norm": 0.021384337916970253, "ratio": 0.9985659122467041, "entropy": 0.6881531119346619, "incre_win_rate": 0.8392857142857143, "step": 1234}
{"time": 1766668824.5458272, "phase": "train", "update": 1235, "total_env_steps": 3952000, "episode_reward": 0.31261488795280457, "value_loss": 0.011685744362572829, "policy_loss": -0.015338057041334945, "dist_entropy": 0.6912789662679036, "actor_grad_norm": 0.14670680463314056, "critic_grad_norm": 0.03830431401729584, "ratio": 1.0009938478469849, "entropy": 0.6912789662679036, "incre_win_rate": 0.7636363636363637, "step": 1235}
{"time": 1766668829.354136, "phase": "train", "update": 1236, "total_env_steps": 3955200, "episode_reward": 0.3248797655105591, "value_loss": 0.009971910342574119, "policy_loss": -0.015012978947854567, "dist_entropy": 0.6780221541722615, "actor_grad_norm": 0.1457320749759674, "critic_grad_norm": 0.047197531908750534, "ratio": 0.9998073577880859, "entropy": 0.6780221541722615, "incre_win_rate": 0.8363636363636363, "step": 1236}
{"time": 1766668833.7762957, "phase": "train", "update": 1237, "total_env_steps": 3958400, "episode_reward": 0.33084559440612793, "value_loss": 0.0055550568116207915, "policy_loss": -0.01374844180084409, "dist_entropy": 0.6961679975191752, "actor_grad_norm": 0.14178554713726044, "critic_grad_norm": 0.04478057101368904, "ratio": 1.000110387802124, "entropy": 0.6961679975191752, "incre_win_rate": 0.9423076923076923, "step": 1237}
{"time": 1766668838.0748365, "phase": "train", "update": 1238, "total_env_steps": 3961600, "episode_reward": 0.3358563184738159, "value_loss": 0.004099533287808299, "policy_loss": -0.014186213178480027, "dist_entropy": 0.6858798464139303, "actor_grad_norm": 0.15490560233592987, "critic_grad_norm": 0.026603978127241135, "ratio": 0.9985138177871704, "entropy": 0.6858798464139303, "incre_win_rate": 0.9245283018867925, "step": 1238}
{"time": 1766668842.4349802, "phase": "train", "update": 1239, "total_env_steps": 3964800, "episode_reward": 0.329337477684021, "value_loss": 0.007958340955277284, "policy_loss": -0.014058944819040242, "dist_entropy": 0.6782690127690633, "actor_grad_norm": 0.13667163252830505, "critic_grad_norm": 0.032957643270492554, "ratio": 1.0012226104736328, "entropy": 0.6782690127690633, "incre_win_rate": 0.8070175438596491, "step": 1239}
{"time": 1766668846.7018752, "phase": "train", "update": 1240, "total_env_steps": 3968000, "episode_reward": 0.33559972047805786, "value_loss": 0.007049458598097165, "policy_loss": -0.013263875915634108, "dist_entropy": 0.6740058302879334, "actor_grad_norm": 0.16405007243156433, "critic_grad_norm": 0.01610487513244152, "ratio": 0.9986669421195984, "entropy": 0.6740058302879334, "incre_win_rate": 0.9122807017543859, "step": 1240}
{"time": 1766668851.404729, "phase": "train", "update": 1241, "total_env_steps": 3971200, "episode_reward": 0.31439417600631714, "value_loss": 0.006301488789419333, "policy_loss": -0.013370204607679645, "dist_entropy": 0.6782787958780925, "actor_grad_norm": 0.13710221648216248, "critic_grad_norm": 0.007453203666955233, "ratio": 1.0011160373687744, "entropy": 0.6782787958780925, "incre_win_rate": 0.8775510204081632, "step": 1241}
{"time": 1766668859.184688, "phase": "eval", "update": 1241, "total_env_steps": 3971200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.529181985294116, "step": 1241}
{"time": 1766668863.7708411, "phase": "train", "update": 1242, "total_env_steps": 3974400, "episode_reward": 0.33253833651542664, "value_loss": 0.006613564056654771, "policy_loss": -0.014134261404264119, "dist_entropy": 0.6841224431991577, "actor_grad_norm": 0.1324821412563324, "critic_grad_norm": 0.017082441598176956, "ratio": 0.998969316482544, "entropy": 0.6841224431991577, "incre_win_rate": 0.9090909090909091, "step": 1242}
{"time": 1766668868.3641088, "phase": "train", "update": 1243, "total_env_steps": 3977600, "episode_reward": 0.3279894292354584, "value_loss": 0.007824162797381481, "policy_loss": -0.013058675308136003, "dist_entropy": 0.6794912258783976, "actor_grad_norm": 0.15658415853977203, "critic_grad_norm": 0.022651422768831253, "ratio": 0.9999166131019592, "entropy": 0.6794912258783976, "incre_win_rate": 0.875, "step": 1243}
{"time": 1766668872.783738, "phase": "train", "update": 1244, "total_env_steps": 3980800, "episode_reward": 0.32956111431121826, "value_loss": 0.0044233604955176515, "policy_loss": -0.014016942982516411, "dist_entropy": 0.6803884784380595, "actor_grad_norm": 0.15659993886947632, "critic_grad_norm": 0.01902729459106922, "ratio": 1.0009543895721436, "entropy": 0.6803884784380595, "incre_win_rate": 0.9622641509433962, "step": 1244}
{"time": 1766668877.2189157, "phase": "train", "update": 1245, "total_env_steps": 3984000, "episode_reward": 0.33358994126319885, "value_loss": 0.005262207860747973, "policy_loss": -0.013594627032171994, "dist_entropy": 0.6878198623657227, "actor_grad_norm": 0.14148248732089996, "critic_grad_norm": 0.019948206841945648, "ratio": 0.9995607137680054, "entropy": 0.6878198623657227, "incre_win_rate": 0.9444444444444444, "step": 1245}
{"time": 1766668881.7518585, "phase": "train", "update": 1246, "total_env_steps": 3987200, "episode_reward": 0.3225536644458771, "value_loss": 0.008218931282560031, "policy_loss": -0.01613346265774555, "dist_entropy": 0.6870963414510091, "actor_grad_norm": 0.1512259542942047, "critic_grad_norm": 0.03519944101572037, "ratio": 0.9997643232345581, "entropy": 0.6870963414510091, "incre_win_rate": 0.8703703703703703, "step": 1246}
{"time": 1766668886.1657703, "phase": "train", "update": 1247, "total_env_steps": 3990400, "episode_reward": 0.3237454295158386, "value_loss": 0.007934153235207, "policy_loss": -0.013970607847269298, "dist_entropy": 0.6791055083274842, "actor_grad_norm": 0.15996631979942322, "critic_grad_norm": 0.02686266042292118, "ratio": 0.999834418296814, "entropy": 0.6791055083274842, "incre_win_rate": 0.8518518518518519, "step": 1247}
{"time": 1766668890.6621583, "phase": "train", "update": 1248, "total_env_steps": 3993600, "episode_reward": 0.33876916766166687, "value_loss": 0.004970334066698948, "policy_loss": -0.012872471326771518, "dist_entropy": 0.6761831084887187, "actor_grad_norm": 0.12526176869869232, "critic_grad_norm": 0.015941768884658813, "ratio": 0.9989914894104004, "entropy": 0.6761831084887187, "incre_win_rate": 0.9285714285714286, "step": 1248}
{"time": 1766668895.115916, "phase": "train", "update": 1249, "total_env_steps": 3996800, "episode_reward": 0.33438190817832947, "value_loss": 0.006348913193990787, "policy_loss": -0.014574552025179818, "dist_entropy": 0.6825372099876403, "actor_grad_norm": 0.15275220572948456, "critic_grad_norm": 0.006895378232002258, "ratio": 0.9997345209121704, "entropy": 0.6825372099876403, "incre_win_rate": 0.9272727272727272, "step": 1249}
{"time": 1766668899.5363274, "phase": "train", "update": 1250, "total_env_steps": 4000000, "episode_reward": 0.33244794607162476, "value_loss": 0.010596170711020628, "policy_loss": -0.013496045985411343, "dist_entropy": 0.6807869235674541, "actor_grad_norm": 0.1366526037454605, "critic_grad_norm": 0.01769908517599106, "ratio": 0.9999141693115234, "entropy": 0.6807869235674541, "incre_win_rate": 0.8679245283018868, "step": 1250}
{"time": 1766668903.9937878, "phase": "train", "update": 1251, "total_env_steps": 4003200, "episode_reward": 0.31400585174560547, "value_loss": 0.011439958028495312, "policy_loss": -0.014242035248724961, "dist_entropy": 0.6777961015701294, "actor_grad_norm": 0.1277030110359192, "critic_grad_norm": 0.025401771068572998, "ratio": 0.9989157915115356, "entropy": 0.6777961015701294, "incre_win_rate": 0.7777777777777778, "step": 1251}
{"time": 1766668908.436175, "phase": "train", "update": 1252, "total_env_steps": 4006400, "episode_reward": 0.3184382915496826, "value_loss": 0.013566774316132069, "policy_loss": -0.014706719211557365, "dist_entropy": 0.7096624255180359, "actor_grad_norm": 0.142999067902565, "critic_grad_norm": 0.0367770753800869, "ratio": 0.9997949004173279, "entropy": 0.7096624255180359, "incre_win_rate": 0.8, "step": 1252}
{"time": 1766668912.9217384, "phase": "train", "update": 1253, "total_env_steps": 4009600, "episode_reward": 0.3186466097831726, "value_loss": 0.010955605221291383, "policy_loss": -0.015469319290597857, "dist_entropy": 0.7108584602673849, "actor_grad_norm": 0.15867561101913452, "critic_grad_norm": 0.03744253143668175, "ratio": 0.9994730353355408, "entropy": 0.7108584602673849, "incre_win_rate": 0.8490566037735849, "step": 1253}
{"time": 1766668917.3290052, "phase": "train", "update": 1254, "total_env_steps": 4012800, "episode_reward": 0.3173391819000244, "value_loss": 0.007828189587841431, "policy_loss": -0.014399864602406371, "dist_entropy": 0.7044432004292805, "actor_grad_norm": 0.16679902374744415, "critic_grad_norm": 0.022015318274497986, "ratio": 1.0004793405532837, "entropy": 0.7044432004292805, "incre_win_rate": 0.8518518518518519, "step": 1254}
{"time": 1766668921.9321802, "phase": "train", "update": 1255, "total_env_steps": 4016000, "episode_reward": 0.31855854392051697, "value_loss": 0.008257336045304934, "policy_loss": -0.01493220311938496, "dist_entropy": 0.699727737903595, "actor_grad_norm": 0.14081279933452606, "critic_grad_norm": 0.01988261379301548, "ratio": 0.9999321699142456, "entropy": 0.699727737903595, "incre_win_rate": 0.8301886792452831, "step": 1255}
{"time": 1766668926.4013696, "phase": "train", "update": 1256, "total_env_steps": 4019200, "episode_reward": 0.3157843053340912, "value_loss": 0.006663731827090184, "policy_loss": -0.015383320649740047, "dist_entropy": 0.6871835509936015, "actor_grad_norm": 0.15114609897136688, "critic_grad_norm": 0.027955466881394386, "ratio": 0.9982274174690247, "entropy": 0.6871835509936015, "incre_win_rate": 0.8113207547169812, "step": 1256}
{"time": 1766668931.032269, "phase": "train", "update": 1257, "total_env_steps": 4022400, "episode_reward": 0.3318620026111603, "value_loss": 0.008016305975615978, "policy_loss": -0.014048884192537041, "dist_entropy": 0.6883726676305135, "actor_grad_norm": 0.15256807208061218, "critic_grad_norm": 0.020436827093362808, "ratio": 0.9999765753746033, "entropy": 0.6883726676305135, "incre_win_rate": 0.8888888888888888, "step": 1257}
{"time": 1766668935.553452, "phase": "train", "update": 1258, "total_env_steps": 4025600, "episode_reward": 0.3290165364742279, "value_loss": 0.005366254411637783, "policy_loss": -0.013289845390468239, "dist_entropy": 0.6879876216252645, "actor_grad_norm": 0.1283622682094574, "critic_grad_norm": 0.03376172482967377, "ratio": 0.9992595314979553, "entropy": 0.6879876216252645, "incre_win_rate": 0.8909090909090909, "step": 1258}
{"time": 1766668940.12572, "phase": "train", "update": 1259, "total_env_steps": 4028800, "episode_reward": 0.339507520198822, "value_loss": 0.004756570172806581, "policy_loss": -0.014806873448850759, "dist_entropy": 0.6877410968144735, "actor_grad_norm": 0.12888802587985992, "critic_grad_norm": 0.021313102915883064, "ratio": 1.0002621412277222, "entropy": 0.6877410968144735, "incre_win_rate": 0.9636363636363636, "step": 1259}
{"time": 1766668944.5658896, "phase": "train", "update": 1260, "total_env_steps": 4032000, "episode_reward": 0.32754600048065186, "value_loss": 0.008795794347922008, "policy_loss": -0.014018898047252974, "dist_entropy": 0.6738815704981486, "actor_grad_norm": 0.1438302844762802, "critic_grad_norm": 0.06509458273649216, "ratio": 0.9999403953552246, "entropy": 0.6738815704981486, "incre_win_rate": 0.7857142857142857, "step": 1260}
{"time": 1766668949.344551, "phase": "train", "update": 1261, "total_env_steps": 4035200, "episode_reward": 0.3180040121078491, "value_loss": 0.008332914051910242, "policy_loss": -0.014984513100182539, "dist_entropy": 0.6766958435376486, "actor_grad_norm": 0.1492256224155426, "critic_grad_norm": 0.055887822061777115, "ratio": 1.0009527206420898, "entropy": 0.6766958435376486, "incre_win_rate": 0.7592592592592593, "step": 1261}
{"time": 1766668956.8915553, "phase": "eval", "update": 1261, "total_env_steps": 4035200, "eval_win_rate": 0.875, "eval_episode_reward": 19.23016237745098, "step": 1261}
{"time": 1766668961.320352, "phase": "train", "update": 1262, "total_env_steps": 4038400, "episode_reward": 0.3207145929336548, "value_loss": 0.009529394345978897, "policy_loss": -0.014523887422254234, "dist_entropy": 0.6848680059115092, "actor_grad_norm": 0.1481652855873108, "critic_grad_norm": 0.06337373703718185, "ratio": 1.0009384155273438, "entropy": 0.6848680059115092, "incre_win_rate": 0.7592592592592593, "step": 1262}
{"time": 1766668965.7893226, "phase": "train", "update": 1263, "total_env_steps": 4041600, "episode_reward": 0.3295879065990448, "value_loss": 0.010307221797605355, "policy_loss": -0.014768988062521278, "dist_entropy": 0.6934996883074442, "actor_grad_norm": 0.13714121282100677, "critic_grad_norm": 0.0265795961022377, "ratio": 0.9986086487770081, "entropy": 0.6934996883074442, "incre_win_rate": 0.8392857142857143, "step": 1263}
{"time": 1766668970.137739, "phase": "train", "update": 1264, "total_env_steps": 4044800, "episode_reward": 0.31563422083854675, "value_loss": 0.008573158830404281, "policy_loss": -0.016079567410454843, "dist_entropy": 0.7023765842119852, "actor_grad_norm": 0.13503475487232208, "critic_grad_norm": 0.012336409650743008, "ratio": 0.9989612102508545, "entropy": 0.7023765842119852, "incre_win_rate": 0.8490566037735849, "step": 1264}
{"time": 1766668974.5265872, "phase": "train", "update": 1265, "total_env_steps": 4048000, "episode_reward": 0.32669806480407715, "value_loss": 0.009748214607437451, "policy_loss": -0.014606345469836886, "dist_entropy": 0.6876711209615072, "actor_grad_norm": 0.1834569126367569, "critic_grad_norm": 0.009969585575163364, "ratio": 0.9994251132011414, "entropy": 0.6876711209615072, "incre_win_rate": 0.8181818181818182, "step": 1265}
{"time": 1766668978.9095302, "phase": "train", "update": 1266, "total_env_steps": 4051200, "episode_reward": 0.33011412620544434, "value_loss": 0.008686031463245552, "policy_loss": -0.014456579729632945, "dist_entropy": 0.6899229208628337, "actor_grad_norm": 0.15544530749320984, "critic_grad_norm": 0.009981151670217514, "ratio": 0.9993031024932861, "entropy": 0.6899229208628337, "incre_win_rate": 0.8909090909090909, "step": 1266}
{"time": 1766668983.361009, "phase": "train", "update": 1267, "total_env_steps": 4054400, "episode_reward": 0.3200283348560333, "value_loss": 0.012318687265117962, "policy_loss": -0.01459823910673658, "dist_entropy": 0.6813294410705566, "actor_grad_norm": 0.13023202121257782, "critic_grad_norm": 0.028106287121772766, "ratio": 1.0008617639541626, "entropy": 0.6813294410705566, "incre_win_rate": 0.7358490566037735, "step": 1267}
{"time": 1766668987.754363, "phase": "train", "update": 1268, "total_env_steps": 4057600, "episode_reward": 0.3195626437664032, "value_loss": 0.013510105262200037, "policy_loss": -0.014331094020405052, "dist_entropy": 0.7105689962704976, "actor_grad_norm": 0.13822701573371887, "critic_grad_norm": 0.034573353826999664, "ratio": 0.998695433139801, "entropy": 0.7105689962704976, "incre_win_rate": 0.7758620689655172, "step": 1268}
{"time": 1766668992.189521, "phase": "train", "update": 1269, "total_env_steps": 4060800, "episode_reward": 0.3329993784427643, "value_loss": 0.010345657107730706, "policy_loss": -0.01429052296413526, "dist_entropy": 0.6853303829828898, "actor_grad_norm": 0.16632327437400818, "critic_grad_norm": 0.048011716455221176, "ratio": 1.0005983114242554, "entropy": 0.6853303829828898, "incre_win_rate": 0.8333333333333334, "step": 1269}
{"time": 1766668996.6154413, "phase": "train", "update": 1270, "total_env_steps": 4064000, "episode_reward": 0.3304779529571533, "value_loss": 0.010431290542085966, "policy_loss": -0.013698985752500902, "dist_entropy": 0.7004905660947164, "actor_grad_norm": 0.1341685652732849, "critic_grad_norm": 0.058379512280225754, "ratio": 1.000356912612915, "entropy": 0.7004905660947164, "incre_win_rate": 0.9090909090909091, "step": 1270}
{"time": 1766669001.0643513, "phase": "train", "update": 1271, "total_env_steps": 4067200, "episode_reward": 0.3275919258594513, "value_loss": 0.007886963461836179, "policy_loss": -0.014752806561292194, "dist_entropy": 0.6806629776954651, "actor_grad_norm": 0.13778305053710938, "critic_grad_norm": 0.02327522449195385, "ratio": 0.9997588396072388, "entropy": 0.6806629776954651, "incre_win_rate": 0.8727272727272727, "step": 1271}
{"time": 1766669005.4917893, "phase": "train", "update": 1272, "total_env_steps": 4070400, "episode_reward": 0.32104548811912537, "value_loss": 0.010504853663345177, "policy_loss": -0.014732957603609976, "dist_entropy": 0.6760795036951701, "actor_grad_norm": 0.134726881980896, "critic_grad_norm": 0.020679423585534096, "ratio": 0.9996688365936279, "entropy": 0.6760795036951701, "incre_win_rate": 0.8490566037735849, "step": 1272}
{"time": 1766669009.8533237, "phase": "train", "update": 1273, "total_env_steps": 4073600, "episode_reward": 0.31992340087890625, "value_loss": 0.007594719901680947, "policy_loss": -0.015241558716896482, "dist_entropy": 0.6829342007637024, "actor_grad_norm": 0.1437394767999649, "critic_grad_norm": 0.016833608970046043, "ratio": 0.9993634223937988, "entropy": 0.6829342007637024, "incre_win_rate": 0.8679245283018868, "step": 1273}
{"time": 1766669014.3788626, "phase": "train", "update": 1274, "total_env_steps": 4076800, "episode_reward": 0.32583945989608765, "value_loss": 0.005869388921807209, "policy_loss": -0.014861008745938402, "dist_entropy": 0.6917973518371582, "actor_grad_norm": 0.15990804135799408, "critic_grad_norm": 0.05116747319698334, "ratio": 1.0008748769760132, "entropy": 0.6917973518371582, "incre_win_rate": 0.9622641509433962, "step": 1274}
{"time": 1766669019.0394368, "phase": "train", "update": 1275, "total_env_steps": 4080000, "episode_reward": 0.3122403621673584, "value_loss": 0.0068505856208503245, "policy_loss": -0.015456981141376976, "dist_entropy": 0.6705629984537761, "actor_grad_norm": 0.16711628437042236, "critic_grad_norm": 0.03130863979458809, "ratio": 0.9999530911445618, "entropy": 0.6705629984537761, "incre_win_rate": 0.8490566037735849, "step": 1275}
{"time": 1766669023.520628, "phase": "train", "update": 1276, "total_env_steps": 4083200, "episode_reward": 0.3263557255268097, "value_loss": 0.011520852458973725, "policy_loss": -0.015786058287165023, "dist_entropy": 0.678814963499705, "actor_grad_norm": 0.1324918568134308, "critic_grad_norm": 0.01891455613076687, "ratio": 1.0008494853973389, "entropy": 0.678814963499705, "incre_win_rate": 0.8363636363636363, "step": 1276}
{"time": 1766669027.929225, "phase": "train", "update": 1277, "total_env_steps": 4086400, "episode_reward": 0.32738664746284485, "value_loss": 0.007595463624844949, "policy_loss": -0.014708964308915048, "dist_entropy": 0.6853299061457316, "actor_grad_norm": 0.1438068300485611, "critic_grad_norm": 0.031899210065603256, "ratio": 0.998940646648407, "entropy": 0.6853299061457316, "incre_win_rate": 0.8679245283018868, "step": 1277}
{"time": 1766669032.3447108, "phase": "train", "update": 1278, "total_env_steps": 4089600, "episode_reward": 0.3185478150844574, "value_loss": 0.009827046096324921, "policy_loss": -0.015399392336651848, "dist_entropy": 0.6830912272135417, "actor_grad_norm": 0.13971064984798431, "critic_grad_norm": 0.024462074041366577, "ratio": 1.0002177953720093, "entropy": 0.6830912272135417, "incre_win_rate": 0.8333333333333334, "step": 1278}
{"time": 1766669036.7041042, "phase": "train", "update": 1279, "total_env_steps": 4092800, "episode_reward": 0.3027351498603821, "value_loss": 0.016277685202658175, "policy_loss": -0.01529794341989638, "dist_entropy": 0.6908706386884054, "actor_grad_norm": 0.15339349210262299, "critic_grad_norm": 0.07230153679847717, "ratio": 1.0013231039047241, "entropy": 0.6908706386884054, "incre_win_rate": 0.7115384615384616, "step": 1279}
{"time": 1766669041.0733314, "phase": "train", "update": 1280, "total_env_steps": 4096000, "episode_reward": 0.32491421699523926, "value_loss": 0.009665537811815738, "policy_loss": -0.015273187794671609, "dist_entropy": 0.702659014860789, "actor_grad_norm": 0.13760752975940704, "critic_grad_norm": 0.04452502727508545, "ratio": 1.00017249584198, "entropy": 0.702659014860789, "incre_win_rate": 0.8518518518518519, "step": 1280}
{"time": 1766669045.566939, "phase": "train", "update": 1281, "total_env_steps": 4099200, "episode_reward": 0.3074241876602173, "value_loss": 0.013160440822442372, "policy_loss": -0.015089231000167243, "dist_entropy": 0.6861935416857402, "actor_grad_norm": 0.1716557890176773, "critic_grad_norm": 0.020131761208176613, "ratio": 1.0003811120986938, "entropy": 0.6861935416857402, "incre_win_rate": 0.7924528301886793, "step": 1281}
{"time": 1766669053.3143113, "phase": "eval", "update": 1281, "total_env_steps": 4099200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.84329044117647, "step": 1281}
{"time": 1766669057.7454374, "phase": "train", "update": 1282, "total_env_steps": 4102400, "episode_reward": 0.2974448502063751, "value_loss": 0.0166444502150019, "policy_loss": -0.016068959593313538, "dist_entropy": 0.7024404168128967, "actor_grad_norm": 0.14064496755599976, "critic_grad_norm": 0.025669796392321587, "ratio": 0.9997290968894958, "entropy": 0.7024404168128967, "incre_win_rate": 0.7037037037037037, "step": 1282}
{"time": 1766669062.1848717, "phase": "train", "update": 1283, "total_env_steps": 4105600, "episode_reward": 0.3162591755390167, "value_loss": 0.013276522234082221, "policy_loss": -0.016704569008034773, "dist_entropy": 0.701561713218689, "actor_grad_norm": 0.1530831903219223, "critic_grad_norm": 0.017024293541908264, "ratio": 1.0016216039657593, "entropy": 0.701561713218689, "incre_win_rate": 0.7818181818181819, "step": 1283}
{"time": 1766669066.6972752, "phase": "train", "update": 1284, "total_env_steps": 4108800, "episode_reward": 0.2954036295413971, "value_loss": 0.012544407074650129, "policy_loss": -0.01690723112953568, "dist_entropy": 0.7060906052589416, "actor_grad_norm": 0.15412156283855438, "critic_grad_norm": 0.014418670907616615, "ratio": 1.0001896619796753, "entropy": 0.7060906052589416, "incre_win_rate": 0.7142857142857143, "step": 1284}
{"time": 1766669071.0992148, "phase": "train", "update": 1285, "total_env_steps": 4112000, "episode_reward": 0.31506356596946716, "value_loss": 0.014811015191177527, "policy_loss": -0.01550902877520534, "dist_entropy": 0.69831729332606, "actor_grad_norm": 0.16645129024982452, "critic_grad_norm": 0.04327519237995148, "ratio": 1.0001320838928223, "entropy": 0.69831729332606, "incre_win_rate": 0.8, "step": 1285}
{"time": 1766669075.5190382, "phase": "train", "update": 1286, "total_env_steps": 4115200, "episode_reward": 0.31207340955734253, "value_loss": 0.012633132375776767, "policy_loss": -0.01585091170138545, "dist_entropy": 0.677344783147176, "actor_grad_norm": 0.1837708055973053, "critic_grad_norm": 0.04708303138613701, "ratio": 0.999322772026062, "entropy": 0.677344783147176, "incre_win_rate": 0.8627450980392157, "step": 1286}
{"time": 1766669080.0926623, "phase": "train", "update": 1287, "total_env_steps": 4118400, "episode_reward": 0.3114207983016968, "value_loss": 0.01535927684356769, "policy_loss": -0.01612680720765051, "dist_entropy": 0.6732417742411295, "actor_grad_norm": 0.1667541265487671, "critic_grad_norm": 0.03470691666007042, "ratio": 1.000777244567871, "entropy": 0.6732417742411295, "incre_win_rate": 0.7592592592592593, "step": 1287}
{"time": 1766669084.548357, "phase": "train", "update": 1288, "total_env_steps": 4121600, "episode_reward": 0.30306220054626465, "value_loss": 0.015895678102970122, "policy_loss": -0.01611086555910267, "dist_entropy": 0.6617172002792359, "actor_grad_norm": 0.18622224032878876, "critic_grad_norm": 0.03777140751481056, "ratio": 1.0007596015930176, "entropy": 0.6617172002792359, "incre_win_rate": 0.6981132075471698, "step": 1288}
{"time": 1766669088.9442327, "phase": "train", "update": 1289, "total_env_steps": 4124800, "episode_reward": 0.32005518674850464, "value_loss": 0.010594514943659306, "policy_loss": -0.01544970742576197, "dist_entropy": 0.6780771454175313, "actor_grad_norm": 0.1475372463464737, "critic_grad_norm": 0.03209596127271652, "ratio": 0.9994760155677795, "entropy": 0.6780771454175313, "incre_win_rate": 0.8490566037735849, "step": 1289}
{"time": 1766669093.3571796, "phase": "train", "update": 1290, "total_env_steps": 4128000, "episode_reward": 0.30796417593955994, "value_loss": 0.012954109037915865, "policy_loss": -0.014967423738330866, "dist_entropy": 0.6677729964256287, "actor_grad_norm": 0.15786032378673553, "critic_grad_norm": 0.034494783729314804, "ratio": 1.00057053565979, "entropy": 0.6677729964256287, "incre_win_rate": 0.8113207547169812, "step": 1290}
{"time": 1766669097.7982297, "phase": "train", "update": 1291, "total_env_steps": 4131200, "episode_reward": 0.3022288680076599, "value_loss": 0.015561094507575035, "policy_loss": -0.01707251304212273, "dist_entropy": 0.665804938475291, "actor_grad_norm": 0.17492924630641937, "critic_grad_norm": 0.08913428336381912, "ratio": 0.9994337558746338, "entropy": 0.665804938475291, "incre_win_rate": 0.7735849056603774, "step": 1291}
{"time": 1766669102.159094, "phase": "train", "update": 1292, "total_env_steps": 4134400, "episode_reward": 0.3049280047416687, "value_loss": 0.015282188542187214, "policy_loss": -0.016903190199601188, "dist_entropy": 0.6674189368883768, "actor_grad_norm": 0.19675414264202118, "critic_grad_norm": 0.050638023763895035, "ratio": 0.9999912977218628, "entropy": 0.6674189368883768, "incre_win_rate": 0.6923076923076923, "step": 1292}
{"time": 1766669106.6665895, "phase": "train", "update": 1293, "total_env_steps": 4137600, "episode_reward": 0.3112500011920929, "value_loss": 0.016281655927499136, "policy_loss": -0.015793533302143222, "dist_entropy": 0.6661876718203227, "actor_grad_norm": 0.15615710616111755, "critic_grad_norm": 0.07212745398283005, "ratio": 0.9992622137069702, "entropy": 0.6661876718203227, "incre_win_rate": 0.6964285714285714, "step": 1293}
{"time": 1766669111.102142, "phase": "train", "update": 1294, "total_env_steps": 4140800, "episode_reward": 0.31573835015296936, "value_loss": 0.015743997258444626, "policy_loss": -0.016018710106388785, "dist_entropy": 0.6815062522888183, "actor_grad_norm": 0.17367154359817505, "critic_grad_norm": 0.02673931047320366, "ratio": 0.9987102150917053, "entropy": 0.6815062522888183, "incre_win_rate": 0.8301886792452831, "step": 1294}
{"time": 1766669115.5334814, "phase": "train", "update": 1295, "total_env_steps": 4144000, "episode_reward": 0.2965249717235565, "value_loss": 0.0158160254980127, "policy_loss": -0.016261525611852314, "dist_entropy": 0.6639623284339905, "actor_grad_norm": 0.16049179434776306, "critic_grad_norm": 0.04037574306130409, "ratio": 1.0008469820022583, "entropy": 0.6639623284339905, "incre_win_rate": 0.6923076923076923, "step": 1295}
{"time": 1766669119.9433608, "phase": "train", "update": 1296, "total_env_steps": 4147200, "episode_reward": 0.28553080558776855, "value_loss": 0.017416140312949815, "policy_loss": -0.01711166375115643, "dist_entropy": 0.6705909808476765, "actor_grad_norm": 0.15102891623973846, "critic_grad_norm": 0.025858987122774124, "ratio": 1.0001280307769775, "entropy": 0.6705909808476765, "incre_win_rate": 0.6346153846153846, "step": 1296}
{"time": 1766669124.420933, "phase": "train", "update": 1297, "total_env_steps": 4150400, "episode_reward": 0.30607229471206665, "value_loss": 0.01591427146146695, "policy_loss": -0.01643728483544938, "dist_entropy": 0.6655896862347921, "actor_grad_norm": 0.16747035086154938, "critic_grad_norm": 0.020456023514270782, "ratio": 0.9995939135551453, "entropy": 0.6655896862347921, "incre_win_rate": 0.6909090909090909, "step": 1297}
{"time": 1766669128.8683457, "phase": "train", "update": 1298, "total_env_steps": 4153600, "episode_reward": 0.3161366581916809, "value_loss": 0.01315737118323644, "policy_loss": -0.015208173071296235, "dist_entropy": 0.6576796968777975, "actor_grad_norm": 0.1670021265745163, "critic_grad_norm": 0.041975896805524826, "ratio": 1.00044846534729, "entropy": 0.6576796968777975, "incre_win_rate": 0.8113207547169812, "step": 1298}
{"time": 1766669133.2832384, "phase": "train", "update": 1299, "total_env_steps": 4156800, "episode_reward": 0.3108624517917633, "value_loss": 0.014544164575636388, "policy_loss": -0.014911377149693787, "dist_entropy": 0.6621012091636658, "actor_grad_norm": 0.16831453144550323, "critic_grad_norm": 0.01506002712994814, "ratio": 0.9996662735939026, "entropy": 0.6621012091636658, "incre_win_rate": 0.7735849056603774, "step": 1299}
{"time": 1766669137.853126, "phase": "train", "update": 1300, "total_env_steps": 4160000, "episode_reward": 0.3026769459247589, "value_loss": 0.013360788176457087, "policy_loss": -0.01656318082018326, "dist_entropy": 0.6588415384292603, "actor_grad_norm": 0.1469551920890808, "critic_grad_norm": 0.020517850294709206, "ratio": 1.000083565711975, "entropy": 0.6588415384292603, "incre_win_rate": 0.7924528301886793, "step": 1300}
{"time": 1766669142.2505257, "phase": "train", "update": 1301, "total_env_steps": 4163200, "episode_reward": 0.313036173582077, "value_loss": 0.0078818219092985, "policy_loss": -0.016041977554743406, "dist_entropy": 0.6621142427126566, "actor_grad_norm": 0.13921156525611877, "critic_grad_norm": 0.037601739168167114, "ratio": 1.0003504753112793, "entropy": 0.6621142427126566, "incre_win_rate": 0.8461538461538461, "step": 1301}
{"time": 1766669150.2543879, "phase": "eval", "update": 1301, "total_env_steps": 4163200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.385263480392155, "step": 1301}
{"time": 1766669154.6705782, "phase": "train", "update": 1302, "total_env_steps": 4166400, "episode_reward": 0.32227328419685364, "value_loss": 0.008542946353554726, "policy_loss": -0.015240085586232984, "dist_entropy": 0.6497134844462077, "actor_grad_norm": 0.14819160103797913, "critic_grad_norm": 0.03293897584080696, "ratio": 1.0010062456130981, "entropy": 0.6497134844462077, "incre_win_rate": 0.8490566037735849, "step": 1302}
{"time": 1766669159.0759761, "phase": "train", "update": 1303, "total_env_steps": 4169600, "episode_reward": 0.3076018691062927, "value_loss": 0.011490724794566632, "policy_loss": -0.01517960576328316, "dist_entropy": 0.66065673828125, "actor_grad_norm": 0.16527168452739716, "critic_grad_norm": 0.03261302039027214, "ratio": 1.0001674890518188, "entropy": 0.66065673828125, "incre_win_rate": 0.7884615384615384, "step": 1303}
{"time": 1766669163.5404277, "phase": "train", "update": 1304, "total_env_steps": 4172800, "episode_reward": 0.32454046607017517, "value_loss": 0.014313372721274694, "policy_loss": -0.014232984643003732, "dist_entropy": 0.6637999574343364, "actor_grad_norm": 0.1425919383764267, "critic_grad_norm": 0.011446804739534855, "ratio": 0.9994091987609863, "entropy": 0.6637999574343364, "incre_win_rate": 0.8214285714285714, "step": 1304}
{"time": 1766669167.9699671, "phase": "train", "update": 1305, "total_env_steps": 4176000, "episode_reward": 0.29767540097236633, "value_loss": 0.01586790382862091, "policy_loss": -0.01635987138749518, "dist_entropy": 0.667556349436442, "actor_grad_norm": 0.18565116822719574, "critic_grad_norm": 0.046542879194021225, "ratio": 0.9987087845802307, "entropy": 0.667556349436442, "incre_win_rate": 0.7115384615384616, "step": 1305}
{"time": 1766669203.045046, "phase": "train", "update": 1306, "total_env_steps": 4179200, "episode_reward": 0.30089157819747925, "value_loss": 0.06911424696445465, "policy_loss": -0.01424464457137257, "dist_entropy": 0.6940201401710511, "actor_grad_norm": 0.13021719455718994, "critic_grad_norm": 0.21649792790412903, "ratio": 0.99942547082901, "entropy": 0.6940201401710511, "incre_win_rate": 0.7307692307692307, "step": 1306}
{"time": 1766669207.5816011, "phase": "train", "update": 1307, "total_env_steps": 4182400, "episode_reward": 0.3046545386314392, "value_loss": 0.012896659473578135, "policy_loss": -0.015087405998404317, "dist_entropy": 0.6871201992034912, "actor_grad_norm": 0.13484328985214233, "critic_grad_norm": 0.06682512909173965, "ratio": 1.0004442930221558, "entropy": 0.6871201992034912, "incre_win_rate": 0.8, "step": 1307}
{"time": 1766669212.2191095, "phase": "train", "update": 1308, "total_env_steps": 4185600, "episode_reward": 0.29688799381256104, "value_loss": 0.0167090871060888, "policy_loss": -0.017040290685278948, "dist_entropy": 0.6881590684254965, "actor_grad_norm": 0.15034537017345428, "critic_grad_norm": 0.053440432995557785, "ratio": 1.0001401901245117, "entropy": 0.6881590684254965, "incre_win_rate": 0.6545454545454545, "step": 1308}
{"time": 1766669216.6743188, "phase": "train", "update": 1309, "total_env_steps": 4188800, "episode_reward": 0.29969823360443115, "value_loss": 0.014303630217909813, "policy_loss": -0.015524448195042359, "dist_entropy": 0.6824261903762817, "actor_grad_norm": 0.14533731341362, "critic_grad_norm": 0.04619118943810463, "ratio": 1.0000666379928589, "entropy": 0.6824261903762817, "incre_win_rate": 0.7, "step": 1309}
{"time": 1766669221.4013283, "phase": "train", "update": 1310, "total_env_steps": 4192000, "episode_reward": 0.307348370552063, "value_loss": 0.01505309132238229, "policy_loss": -0.015971601916719654, "dist_entropy": 0.6867353836695353, "actor_grad_norm": 0.14104172587394714, "critic_grad_norm": 0.027789445593953133, "ratio": 1.0004303455352783, "entropy": 0.6867353836695353, "incre_win_rate": 0.7142857142857143, "step": 1310}
{"time": 1766669225.98028, "phase": "train", "update": 1311, "total_env_steps": 4195200, "episode_reward": 0.3090609610080719, "value_loss": 0.01590626916537682, "policy_loss": -0.01645522434601882, "dist_entropy": 0.6943778912226359, "actor_grad_norm": 0.15042312443256378, "critic_grad_norm": 0.015126792713999748, "ratio": 0.9996981620788574, "entropy": 0.6943778912226359, "incre_win_rate": 0.7142857142857143, "step": 1311}
{"time": 1766669230.4610722, "phase": "train", "update": 1312, "total_env_steps": 4198400, "episode_reward": 0.2954182028770447, "value_loss": 0.015396328580876192, "policy_loss": -0.016453960745058775, "dist_entropy": 0.6898228446642558, "actor_grad_norm": 0.1455717533826828, "critic_grad_norm": 0.027457615360617638, "ratio": 1.000988483428955, "entropy": 0.6898228446642558, "incre_win_rate": 0.72, "step": 1312}
{"time": 1766669235.0186467, "phase": "train", "update": 1313, "total_env_steps": 4201600, "episode_reward": 0.3059888184070587, "value_loss": 0.015891978703439235, "policy_loss": -0.014841625920778749, "dist_entropy": 0.6710339625676472, "actor_grad_norm": 0.15346305072307587, "critic_grad_norm": 0.01625102385878563, "ratio": 0.9997096061706543, "entropy": 0.6710339625676472, "incre_win_rate": 0.75, "step": 1313}
{"time": 1766669239.7200465, "phase": "train", "update": 1314, "total_env_steps": 4204800, "episode_reward": 0.29804304242134094, "value_loss": 0.012737741010884445, "policy_loss": -0.016992767803283234, "dist_entropy": 0.6678815007209777, "actor_grad_norm": 0.15955843031406403, "critic_grad_norm": 0.029366280883550644, "ratio": 1.0006237030029297, "entropy": 0.6678815007209777, "incre_win_rate": 0.75, "step": 1314}
{"time": 1766669244.267788, "phase": "train", "update": 1315, "total_env_steps": 4208000, "episode_reward": 0.30751532316207886, "value_loss": 0.011971901481350264, "policy_loss": -0.016083169810852383, "dist_entropy": 0.6756846030553182, "actor_grad_norm": 0.17142035067081451, "critic_grad_norm": 0.020949941128492355, "ratio": 0.9991825819015503, "entropy": 0.6756846030553182, "incre_win_rate": 0.7692307692307693, "step": 1315}
{"time": 1766669248.7552989, "phase": "train", "update": 1316, "total_env_steps": 4211200, "episode_reward": 0.3031679093837738, "value_loss": 0.011821475314597289, "policy_loss": -0.015494115590247286, "dist_entropy": 0.678032120068868, "actor_grad_norm": 0.14211170375347137, "critic_grad_norm": 0.017870938405394554, "ratio": 0.999672532081604, "entropy": 0.678032120068868, "incre_win_rate": 0.7037037037037037, "step": 1316}
{"time": 1766669253.094763, "phase": "train", "update": 1317, "total_env_steps": 4214400, "episode_reward": 0.28529489040374756, "value_loss": 0.016423182499905428, "policy_loss": -0.016411460104367847, "dist_entropy": 0.6831655621528625, "actor_grad_norm": 0.1506851464509964, "critic_grad_norm": 0.02582436613738537, "ratio": 0.9989972114562988, "entropy": 0.6831655621528625, "incre_win_rate": 0.6938775510204082, "step": 1317}
{"time": 1766669257.6510756, "phase": "train", "update": 1318, "total_env_steps": 4217600, "episode_reward": 0.30685511231422424, "value_loss": 0.014773955320318539, "policy_loss": -0.015831285349052374, "dist_entropy": 0.6781647006670634, "actor_grad_norm": 0.1504516750574112, "critic_grad_norm": 0.02355031855404377, "ratio": 1.0002007484436035, "entropy": 0.6781647006670634, "incre_win_rate": 0.7454545454545455, "step": 1318}
{"time": 1766669261.9756026, "phase": "train", "update": 1319, "total_env_steps": 4220800, "episode_reward": 0.29898205399513245, "value_loss": 0.013986528664827347, "policy_loss": -0.015727218159011732, "dist_entropy": 0.6717934409777323, "actor_grad_norm": 0.15684887766838074, "critic_grad_norm": 0.027714041993021965, "ratio": 0.9998562335968018, "entropy": 0.6717934409777323, "incre_win_rate": 0.7924528301886793, "step": 1319}
{"time": 1766669266.4570444, "phase": "train", "update": 1320, "total_env_steps": 4224000, "episode_reward": 0.2930813729763031, "value_loss": 0.012551049329340458, "policy_loss": -0.015662708125588173, "dist_entropy": 0.6626424630482991, "actor_grad_norm": 0.21109378337860107, "critic_grad_norm": 0.013401241041719913, "ratio": 1.0003993511199951, "entropy": 0.6626424630482991, "incre_win_rate": 0.6530612244897959, "step": 1320}
{"time": 1766669270.9694507, "phase": "train", "update": 1321, "total_env_steps": 4227200, "episode_reward": 0.30476176738739014, "value_loss": 0.014967824704945088, "policy_loss": -0.015164067644865517, "dist_entropy": 0.6518991430600484, "actor_grad_norm": 0.15386272966861725, "critic_grad_norm": 0.030060486868023872, "ratio": 0.9980006217956543, "entropy": 0.6518991430600484, "incre_win_rate": 0.7924528301886793, "step": 1321}
{"time": 1766669278.7639375, "phase": "eval", "update": 1321, "total_env_steps": 4227200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.531556372549023, "step": 1321}
{"time": 1766669283.5026798, "phase": "train", "update": 1322, "total_env_steps": 4230400, "episode_reward": 0.30852174758911133, "value_loss": 0.011007534650464853, "policy_loss": -0.014945920576730743, "dist_entropy": 0.6557188590367635, "actor_grad_norm": 0.1526833176612854, "critic_grad_norm": 0.032919466495513916, "ratio": 0.9992115497589111, "entropy": 0.6557188590367635, "incre_win_rate": 0.8076923076923077, "step": 1322}
{"time": 1766669288.0540252, "phase": "train", "update": 1323, "total_env_steps": 4233600, "episode_reward": 0.3162224292755127, "value_loss": 0.012067513912916184, "policy_loss": -0.014764468562263744, "dist_entropy": 0.6764978806177775, "actor_grad_norm": 0.15471990406513214, "critic_grad_norm": 0.019142910838127136, "ratio": 1.0009279251098633, "entropy": 0.6764978806177775, "incre_win_rate": 0.8181818181818182, "step": 1323}
{"time": 1766669292.6110919, "phase": "train", "update": 1324, "total_env_steps": 4236800, "episode_reward": 0.3072587251663208, "value_loss": 0.011305817216634751, "policy_loss": -0.016039520230606286, "dist_entropy": 0.686799701054891, "actor_grad_norm": 0.13894899189472198, "critic_grad_norm": 0.04204476997256279, "ratio": 0.9987648129463196, "entropy": 0.686799701054891, "incre_win_rate": 0.7115384615384616, "step": 1324}
{"time": 1766669297.049528, "phase": "train", "update": 1325, "total_env_steps": 4240000, "episode_reward": 0.30490806698799133, "value_loss": 0.01936268856128057, "policy_loss": -0.0159332117837471, "dist_entropy": 0.6781030376752217, "actor_grad_norm": 0.13349704444408417, "critic_grad_norm": 0.059446848928928375, "ratio": 0.9988399147987366, "entropy": 0.6781030376752217, "incre_win_rate": 0.7358490566037735, "step": 1325}
{"time": 1766669301.560984, "phase": "train", "update": 1326, "total_env_steps": 4243200, "episode_reward": 0.3214116096496582, "value_loss": 0.010453328428169092, "policy_loss": -0.014388483862615924, "dist_entropy": 0.6903336922327677, "actor_grad_norm": 0.15038099884986877, "critic_grad_norm": 0.022109873592853546, "ratio": 1.0000507831573486, "entropy": 0.6903336922327677, "incre_win_rate": 0.8888888888888888, "step": 1326}
{"time": 1766669305.9987018, "phase": "train", "update": 1327, "total_env_steps": 4246400, "episode_reward": 0.29990044236183167, "value_loss": 0.016044956818223, "policy_loss": -0.01645959152211418, "dist_entropy": 0.6941912213961283, "actor_grad_norm": 0.16364234685897827, "critic_grad_norm": 0.051311708986759186, "ratio": 0.9997016787528992, "entropy": 0.6941912213961283, "incre_win_rate": 0.7169811320754716, "step": 1327}
{"time": 1766669310.501634, "phase": "train", "update": 1328, "total_env_steps": 4249600, "episode_reward": 0.29222503304481506, "value_loss": 0.014322055193285147, "policy_loss": -0.017613676843337107, "dist_entropy": 0.6979065934816996, "actor_grad_norm": 0.16992272436618805, "critic_grad_norm": 0.07355799525976181, "ratio": 1.0011216402053833, "entropy": 0.6979065934816996, "incre_win_rate": 0.6226415094339622, "step": 1328}
{"time": 1766669314.9485223, "phase": "train", "update": 1329, "total_env_steps": 4252800, "episode_reward": 0.294437050819397, "value_loss": 0.015650432432691257, "policy_loss": -0.016391588178001727, "dist_entropy": 0.6955910483996074, "actor_grad_norm": 0.18189457058906555, "critic_grad_norm": 0.030243422836065292, "ratio": 0.9999975562095642, "entropy": 0.6955910483996074, "incre_win_rate": 0.7358490566037735, "step": 1329}
{"time": 1766669319.4489365, "phase": "train", "update": 1330, "total_env_steps": 4256000, "episode_reward": 0.30518075823783875, "value_loss": 0.011906158427397411, "policy_loss": -0.015148164841028234, "dist_entropy": 0.6958128134409587, "actor_grad_norm": 0.13850153982639313, "critic_grad_norm": 0.028657689690589905, "ratio": 0.9993579387664795, "entropy": 0.6958128134409587, "incre_win_rate": 0.7692307692307693, "step": 1330}
{"time": 1766669323.853096, "phase": "train", "update": 1331, "total_env_steps": 4259200, "episode_reward": 0.3011121451854706, "value_loss": 0.012346422858536243, "policy_loss": -0.015394064543546904, "dist_entropy": 0.6904398441314697, "actor_grad_norm": 0.135773703455925, "critic_grad_norm": 0.014695256017148495, "ratio": 0.9983547329902649, "entropy": 0.6904398441314697, "incre_win_rate": 0.7843137254901961, "step": 1331}
{"time": 1766669328.2624834, "phase": "train", "update": 1332, "total_env_steps": 4262400, "episode_reward": 0.298039972782135, "value_loss": 0.015725219684342543, "policy_loss": -0.016166304747287086, "dist_entropy": 0.6809834520022074, "actor_grad_norm": 0.16191542148590088, "critic_grad_norm": 0.03435753658413887, "ratio": 0.9992249608039856, "entropy": 0.6809834520022074, "incre_win_rate": 0.7450980392156863, "step": 1332}
{"time": 1766669332.67412, "phase": "train", "update": 1333, "total_env_steps": 4265600, "episode_reward": 0.29917511343955994, "value_loss": 0.012245853121081987, "policy_loss": -0.015518378124477768, "dist_entropy": 0.6855526367823283, "actor_grad_norm": 0.14622269570827484, "critic_grad_norm": 0.02119465544819832, "ratio": 0.9997270703315735, "entropy": 0.6855526367823283, "incre_win_rate": 0.7592592592592593, "step": 1333}
{"time": 1766669337.1057396, "phase": "train", "update": 1334, "total_env_steps": 4268800, "episode_reward": 0.3052581250667572, "value_loss": 0.013335506990551948, "policy_loss": -0.015748918740727428, "dist_entropy": 0.6999779144922892, "actor_grad_norm": 0.13997668027877808, "critic_grad_norm": 0.06950102001428604, "ratio": 0.9990404844284058, "entropy": 0.6999779144922892, "incre_win_rate": 0.82, "step": 1334}
{"time": 1766669341.594907, "phase": "train", "update": 1335, "total_env_steps": 4272000, "episode_reward": 0.30772826075553894, "value_loss": 0.008853977421919505, "policy_loss": -0.015125411495259774, "dist_entropy": 0.6789095560709636, "actor_grad_norm": 0.135330468416214, "critic_grad_norm": 0.025574427098035812, "ratio": 0.9984554052352905, "entropy": 0.6789095560709636, "incre_win_rate": 0.7924528301886793, "step": 1335}
{"time": 1766669345.966097, "phase": "train", "update": 1336, "total_env_steps": 4275200, "episode_reward": 0.30420804023742676, "value_loss": 0.010350956333180268, "policy_loss": -0.01527771779806244, "dist_entropy": 0.7018595298131307, "actor_grad_norm": 0.13911259174346924, "critic_grad_norm": 0.011464020237326622, "ratio": 0.9987626671791077, "entropy": 0.7018595298131307, "incre_win_rate": 0.7647058823529411, "step": 1336}
{"time": 1766669350.4040105, "phase": "train", "update": 1337, "total_env_steps": 4278400, "episode_reward": 0.27225261926651, "value_loss": 0.015232614800333976, "policy_loss": -0.0169157756279958, "dist_entropy": 0.7000897804896037, "actor_grad_norm": 0.1464129090309143, "critic_grad_norm": 0.0310506671667099, "ratio": 1.0002886056900024, "entropy": 0.7000897804896037, "incre_win_rate": 0.6666666666666666, "step": 1337}
{"time": 1766669354.847095, "phase": "train", "update": 1338, "total_env_steps": 4281600, "episode_reward": 0.29834020137786865, "value_loss": 0.012146022853751976, "policy_loss": -0.014881592034423836, "dist_entropy": 0.6828376730283101, "actor_grad_norm": 0.157128244638443, "critic_grad_norm": 0.020995624363422394, "ratio": 1.0002580881118774, "entropy": 0.6828376730283101, "incre_win_rate": 0.7272727272727273, "step": 1338}
{"time": 1766669359.294921, "phase": "train", "update": 1339, "total_env_steps": 4284800, "episode_reward": 0.3042493760585785, "value_loss": 0.015759971799949805, "policy_loss": -0.015132087125501433, "dist_entropy": 0.6794028321901957, "actor_grad_norm": 0.1310196816921234, "critic_grad_norm": 0.021243106573820114, "ratio": 0.9998575448989868, "entropy": 0.6794028321901957, "incre_win_rate": 0.7254901960784313, "step": 1339}
{"time": 1766669363.681018, "phase": "train", "update": 1340, "total_env_steps": 4288000, "episode_reward": 0.2966620922088623, "value_loss": 0.011766169654826323, "policy_loss": -0.014866493883152051, "dist_entropy": 0.7068257967631022, "actor_grad_norm": 0.13127437233924866, "critic_grad_norm": 0.025534970685839653, "ratio": 0.9992221593856812, "entropy": 0.7068257967631022, "incre_win_rate": 0.7547169811320755, "step": 1340}
{"time": 1766669368.104185, "phase": "train", "update": 1341, "total_env_steps": 4291200, "episode_reward": 0.30727484822273254, "value_loss": 0.012601957035561403, "policy_loss": -0.014875144387930087, "dist_entropy": 0.6961933334668478, "actor_grad_norm": 0.14894142746925354, "critic_grad_norm": 0.024119839072227478, "ratio": 0.9995191097259521, "entropy": 0.6961933334668478, "incre_win_rate": 0.82, "step": 1341}
{"time": 1766669375.8561962, "phase": "eval", "update": 1341, "total_env_steps": 4291200, "eval_win_rate": 1.0, "eval_episode_reward": 20.028033088235297, "step": 1341}
{"time": 1766669380.2957628, "phase": "train", "update": 1342, "total_env_steps": 4294400, "episode_reward": 0.2945549786090851, "value_loss": 0.013072235075136026, "policy_loss": -0.0158474428819621, "dist_entropy": 0.6856674551963806, "actor_grad_norm": 0.13643799722194672, "critic_grad_norm": 0.017569568008184433, "ratio": 0.9991461038589478, "entropy": 0.6856674551963806, "incre_win_rate": 0.7058823529411765, "step": 1342}
{"time": 1766669384.6883307, "phase": "train", "update": 1343, "total_env_steps": 4297600, "episode_reward": 0.29161766171455383, "value_loss": 0.011839808834095796, "policy_loss": -0.015020385283044864, "dist_entropy": 0.70507439772288, "actor_grad_norm": 0.1371636986732483, "critic_grad_norm": 0.020535871386528015, "ratio": 1.0005018711090088, "entropy": 0.70507439772288, "incre_win_rate": 0.8235294117647058, "step": 1343}
{"time": 1766669389.0759826, "phase": "train", "update": 1344, "total_env_steps": 4300800, "episode_reward": 0.30306142568588257, "value_loss": 0.010855071246623993, "policy_loss": -0.015302093615727586, "dist_entropy": 0.71918199857076, "actor_grad_norm": 0.15542374551296234, "critic_grad_norm": 0.022445155307650566, "ratio": 0.9989104270935059, "entropy": 0.71918199857076, "incre_win_rate": 0.84, "step": 1344}
{"time": 1766669393.5191746, "phase": "train", "update": 1345, "total_env_steps": 4304000, "episode_reward": 0.3009651005268097, "value_loss": 0.011655068335433802, "policy_loss": -0.01546160195870622, "dist_entropy": 0.7082846959431967, "actor_grad_norm": 0.15893462300300598, "critic_grad_norm": 0.014665552414953709, "ratio": 0.9989597797393799, "entropy": 0.7082846959431967, "incre_win_rate": 0.7647058823529411, "step": 1345}
{"time": 1766669397.956744, "phase": "train", "update": 1346, "total_env_steps": 4307200, "episode_reward": 0.30094897747039795, "value_loss": 0.011951493099331856, "policy_loss": -0.015508195542587562, "dist_entropy": 0.6966895341873169, "actor_grad_norm": 0.1404263973236084, "critic_grad_norm": 0.026684096083045006, "ratio": 1.0000056028366089, "entropy": 0.6966895341873169, "incre_win_rate": 0.74, "step": 1346}
{"time": 1766669402.391735, "phase": "train", "update": 1347, "total_env_steps": 4310400, "episode_reward": 0.28317326307296753, "value_loss": 0.015216452193756898, "policy_loss": -0.017129325841927803, "dist_entropy": 0.7243120233217876, "actor_grad_norm": 0.1623726785182953, "critic_grad_norm": 0.0590975396335125, "ratio": 0.999602198600769, "entropy": 0.7243120233217876, "incre_win_rate": 0.7307692307692307, "step": 1347}
{"time": 1766669406.8369138, "phase": "train", "update": 1348, "total_env_steps": 4313600, "episode_reward": 0.3081985414028168, "value_loss": 0.010037734235326449, "policy_loss": -0.016017983668110483, "dist_entropy": 0.7142693758010864, "actor_grad_norm": 0.1579885631799698, "critic_grad_norm": 0.03048134595155716, "ratio": 0.9996618628501892, "entropy": 0.7142693758010864, "incre_win_rate": 0.803921568627451, "step": 1348}
{"time": 1766669411.257258, "phase": "train", "update": 1349, "total_env_steps": 4316800, "episode_reward": 0.2938549518585205, "value_loss": 0.01323135079195102, "policy_loss": -0.016171637146714584, "dist_entropy": 0.7087171196937561, "actor_grad_norm": 0.17307840287685394, "critic_grad_norm": 0.029054049402475357, "ratio": 1.0001499652862549, "entropy": 0.7087171196937561, "incre_win_rate": 0.8367346938775511, "step": 1349}
{"time": 1766669415.6322749, "phase": "train", "update": 1350, "total_env_steps": 4320000, "episode_reward": 0.29248467087745667, "value_loss": 0.01043314728885889, "policy_loss": -0.016206255244397384, "dist_entropy": 0.6944088260332744, "actor_grad_norm": 0.16196677088737488, "critic_grad_norm": 0.024374010041356087, "ratio": 1.0005067586898804, "entropy": 0.6944088260332744, "incre_win_rate": 0.7547169811320755, "step": 1350}
{"time": 1766669420.075104, "phase": "train", "update": 1351, "total_env_steps": 4323200, "episode_reward": 0.30867645144462585, "value_loss": 0.009734355347851912, "policy_loss": -0.014486184170303317, "dist_entropy": 0.693964171409607, "actor_grad_norm": 0.14721082150936127, "critic_grad_norm": 0.054797060787677765, "ratio": 1.0003849267959595, "entropy": 0.693964171409607, "incre_win_rate": 0.8571428571428571, "step": 1351}
{"time": 1766669424.4760258, "phase": "train", "update": 1352, "total_env_steps": 4326400, "episode_reward": 0.3021790683269501, "value_loss": 0.016787445917725564, "policy_loss": -0.016463149710680604, "dist_entropy": 0.6957078456878663, "actor_grad_norm": 0.1444779634475708, "critic_grad_norm": 0.032686904072761536, "ratio": 0.9996860027313232, "entropy": 0.6957078456878663, "incre_win_rate": 0.803921568627451, "step": 1352}
{"time": 1766669428.8926246, "phase": "train", "update": 1353, "total_env_steps": 4329600, "episode_reward": 0.28928083181381226, "value_loss": 0.010579853256543478, "policy_loss": -0.01591311924916165, "dist_entropy": 0.6951696634292602, "actor_grad_norm": 0.15184104442596436, "critic_grad_norm": 0.02288690023124218, "ratio": 1.0002334117889404, "entropy": 0.6951696634292602, "incre_win_rate": 0.6666666666666666, "step": 1353}
{"time": 1766669433.592225, "phase": "train", "update": 1354, "total_env_steps": 4332800, "episode_reward": 0.2948192358016968, "value_loss": 0.016618489101529122, "policy_loss": -0.015738964946304654, "dist_entropy": 0.6906280159950257, "actor_grad_norm": 0.20309990644454956, "critic_grad_norm": 0.03522184118628502, "ratio": 0.9996441006660461, "entropy": 0.6906280159950257, "incre_win_rate": 0.660377358490566, "step": 1354}
{"time": 1766669438.1466196, "phase": "train", "update": 1355, "total_env_steps": 4336000, "episode_reward": 0.3183785378932953, "value_loss": 0.011589241462449234, "policy_loss": -0.015162345412917944, "dist_entropy": 0.6917984207471212, "actor_grad_norm": 0.18941760063171387, "critic_grad_norm": 0.02541673742234707, "ratio": 0.9996286630630493, "entropy": 0.6917984207471212, "incre_win_rate": 0.8181818181818182, "step": 1355}
{"time": 1766669442.4823763, "phase": "train", "update": 1356, "total_env_steps": 4339200, "episode_reward": 0.31357306241989136, "value_loss": 0.00997020366291205, "policy_loss": -0.01613994735265673, "dist_entropy": 0.6825434287389119, "actor_grad_norm": 0.17973937094211578, "critic_grad_norm": 0.02465142495930195, "ratio": 0.9976915717124939, "entropy": 0.6825434287389119, "incre_win_rate": 0.8846153846153846, "step": 1356}
{"time": 1766669446.7309208, "phase": "train", "update": 1357, "total_env_steps": 4342400, "episode_reward": 0.3130430579185486, "value_loss": 0.009711219370365143, "policy_loss": -0.015295349507735997, "dist_entropy": 0.7000326236089071, "actor_grad_norm": 0.171200692653656, "critic_grad_norm": 0.03145746886730194, "ratio": 0.9996816515922546, "entropy": 0.7000326236089071, "incre_win_rate": 0.8269230769230769, "step": 1357}
{"time": 1766669450.9120033, "phase": "train", "update": 1358, "total_env_steps": 4345600, "episode_reward": 0.30605778098106384, "value_loss": 0.010436322415868442, "policy_loss": -0.01643225867731862, "dist_entropy": 0.6918865601221721, "actor_grad_norm": 0.1475674957036972, "critic_grad_norm": 0.05860608071088791, "ratio": 0.9995368719100952, "entropy": 0.6918865601221721, "incre_win_rate": 0.7692307692307693, "step": 1358}
{"time": 1766669455.0968428, "phase": "train", "update": 1359, "total_env_steps": 4348800, "episode_reward": 0.30955731868743896, "value_loss": 0.011923086084425449, "policy_loss": -0.015116195922183332, "dist_entropy": 0.6738167881965638, "actor_grad_norm": 0.13490621745586395, "critic_grad_norm": 0.0325295589864254, "ratio": 1.0006027221679688, "entropy": 0.6738167881965638, "incre_win_rate": 0.7777777777777778, "step": 1359}
{"time": 1766669459.2856226, "phase": "train", "update": 1360, "total_env_steps": 4352000, "episode_reward": 0.3111511766910553, "value_loss": 0.01105224285274744, "policy_loss": -0.014957225306706809, "dist_entropy": 0.6987979133923848, "actor_grad_norm": 0.16877858340740204, "critic_grad_norm": 0.022996043786406517, "ratio": 1.0000089406967163, "entropy": 0.6987979133923848, "incre_win_rate": 0.8431372549019608, "step": 1360}
{"time": 1766669463.5390632, "phase": "train", "update": 1361, "total_env_steps": 4355200, "episode_reward": 0.3055001497268677, "value_loss": 0.009275998733937741, "policy_loss": -0.014444775829070977, "dist_entropy": 0.6880835254987081, "actor_grad_norm": 0.14032720029354095, "critic_grad_norm": 0.012821821495890617, "ratio": 0.9980140924453735, "entropy": 0.6880835254987081, "incre_win_rate": 0.7692307692307693, "step": 1361}
{"time": 1766669470.969289, "phase": "eval", "update": 1361, "total_env_steps": 4355200, "eval_win_rate": 1.0, "eval_episode_reward": 20.01960784313726, "step": 1361}
{"time": 1766669475.1487336, "phase": "train", "update": 1362, "total_env_steps": 4358400, "episode_reward": 0.297639399766922, "value_loss": 0.013936359932025274, "policy_loss": -0.01604619246742516, "dist_entropy": 0.6820438146591187, "actor_grad_norm": 0.16800792515277863, "critic_grad_norm": 0.03986385464668274, "ratio": 1.0013155937194824, "entropy": 0.6820438146591187, "incre_win_rate": 0.7358490566037735, "step": 1362}
{"time": 1766669479.329252, "phase": "train", "update": 1363, "total_env_steps": 4361600, "episode_reward": 0.30326977372169495, "value_loss": 0.01199657345811526, "policy_loss": -0.015296433705241459, "dist_entropy": 0.6834102670351664, "actor_grad_norm": 0.1357879638671875, "critic_grad_norm": 0.018825238570570946, "ratio": 1.0012648105621338, "entropy": 0.6834102670351664, "incre_win_rate": 0.75, "step": 1363}
{"time": 1766669483.5401247, "phase": "train", "update": 1364, "total_env_steps": 4364800, "episode_reward": 0.2908517122268677, "value_loss": 0.014500803872942924, "policy_loss": -0.0160008409481577, "dist_entropy": 0.7070915420850118, "actor_grad_norm": 0.167168527841568, "critic_grad_norm": 0.0682016983628273, "ratio": 0.9999990463256836, "entropy": 0.7070915420850118, "incre_win_rate": 0.6470588235294118, "step": 1364}
{"time": 1766669487.712419, "phase": "train", "update": 1365, "total_env_steps": 4368000, "episode_reward": 0.28907862305641174, "value_loss": 0.016443195628623168, "policy_loss": -0.01677412416349154, "dist_entropy": 0.6944648543993632, "actor_grad_norm": 0.16343797743320465, "critic_grad_norm": 0.030844461172819138, "ratio": 0.99985671043396, "entropy": 0.6944648543993632, "incre_win_rate": 0.72, "step": 1365}
{"time": 1766669491.9475315, "phase": "train", "update": 1366, "total_env_steps": 4371200, "episode_reward": 0.29196539521217346, "value_loss": 0.014609394284586111, "policy_loss": -0.01569648661490343, "dist_entropy": 0.6961715340614318, "actor_grad_norm": 0.14822347462177277, "critic_grad_norm": 0.02227807603776455, "ratio": 1.0012764930725098, "entropy": 0.6961715340614318, "incre_win_rate": 0.7037037037037037, "step": 1366}
{"time": 1766669496.1688032, "phase": "train", "update": 1367, "total_env_steps": 4374400, "episode_reward": 0.30325064063072205, "value_loss": 0.015998249873518944, "policy_loss": -0.014431091498672307, "dist_entropy": 0.6934866070747375, "actor_grad_norm": 0.13951414823532104, "critic_grad_norm": 0.02639024332165718, "ratio": 0.9997767806053162, "entropy": 0.6934866070747375, "incre_win_rate": 0.7058823529411765, "step": 1367}
{"time": 1766669500.3424456, "phase": "train", "update": 1368, "total_env_steps": 4377600, "episode_reward": 0.30230164527893066, "value_loss": 0.0127049100274841, "policy_loss": -0.015465856462978423, "dist_entropy": 0.702261749903361, "actor_grad_norm": 0.14583462476730347, "critic_grad_norm": 0.025234756991267204, "ratio": 0.9995717406272888, "entropy": 0.702261749903361, "incre_win_rate": 0.7647058823529411, "step": 1368}
{"time": 1766669504.5789502, "phase": "train", "update": 1369, "total_env_steps": 4380800, "episode_reward": 0.30212700366973877, "value_loss": 0.009188775594035784, "policy_loss": -0.015112486922017372, "dist_entropy": 0.705559786160787, "actor_grad_norm": 0.14065057039260864, "critic_grad_norm": 0.04033326357603073, "ratio": 0.9989405274391174, "entropy": 0.705559786160787, "incre_win_rate": 0.8518518518518519, "step": 1369}
{"time": 1766669508.8213503, "phase": "train", "update": 1370, "total_env_steps": 4384000, "episode_reward": 0.29765015840530396, "value_loss": 0.013236695155501365, "policy_loss": -0.01578747699740018, "dist_entropy": 0.6920156995455424, "actor_grad_norm": 0.14776548743247986, "critic_grad_norm": 0.03416013717651367, "ratio": 1.0005673170089722, "entropy": 0.6920156995455424, "incre_win_rate": 0.6875, "step": 1370}
{"time": 1766669513.2890098, "phase": "train", "update": 1371, "total_env_steps": 4387200, "episode_reward": 0.3081119954586029, "value_loss": 0.011449657132228215, "policy_loss": -0.014824142133606463, "dist_entropy": 0.6885347922643026, "actor_grad_norm": 0.14802685379981995, "critic_grad_norm": 0.010857302695512772, "ratio": 0.9993818998336792, "entropy": 0.6885347922643026, "incre_win_rate": 0.7962962962962963, "step": 1371}
{"time": 1766669517.566956, "phase": "train", "update": 1372, "total_env_steps": 4390400, "episode_reward": 0.31924328207969666, "value_loss": 0.011831712412337462, "policy_loss": -0.014146862368909297, "dist_entropy": 0.675916071732839, "actor_grad_norm": 0.14520354568958282, "critic_grad_norm": 0.033192869275808334, "ratio": 1.0002492666244507, "entropy": 0.675916071732839, "incre_win_rate": 0.8461538461538461, "step": 1372}
{"time": 1766669522.0325644, "phase": "train", "update": 1373, "total_env_steps": 4393600, "episode_reward": 0.31500303745269775, "value_loss": 0.01251132891823848, "policy_loss": -0.0150634186146218, "dist_entropy": 0.6817866126696269, "actor_grad_norm": 0.14266793429851532, "critic_grad_norm": 0.01802421174943447, "ratio": 1.000832438468933, "entropy": 0.6817866126696269, "incre_win_rate": 0.8181818181818182, "step": 1373}
{"time": 1766669526.7591746, "phase": "train", "update": 1374, "total_env_steps": 4396800, "episode_reward": 0.31841760873794556, "value_loss": 0.007421248064686855, "policy_loss": -0.01440517870745263, "dist_entropy": 0.6881840149561564, "actor_grad_norm": 0.15392795205116272, "critic_grad_norm": 0.05046960338950157, "ratio": 0.9992360472679138, "entropy": 0.6881840149561564, "incre_win_rate": 0.8846153846153846, "step": 1374}
{"time": 1766669531.2063096, "phase": "train", "update": 1375, "total_env_steps": 4400000, "episode_reward": 0.3198353350162506, "value_loss": 0.007628033465395371, "policy_loss": -0.014252440867127566, "dist_entropy": 0.6806686997413636, "actor_grad_norm": 0.1562553197145462, "critic_grad_norm": 0.03192555159330368, "ratio": 0.999629557132721, "entropy": 0.6806686997413636, "incre_win_rate": 0.8703703703703703, "step": 1375}
{"time": 1766669535.868649, "phase": "train", "update": 1376, "total_env_steps": 4403200, "episode_reward": 0.3239453136920929, "value_loss": 0.007423555850982666, "policy_loss": -0.013836299890858566, "dist_entropy": 0.6777827103932699, "actor_grad_norm": 0.1793173849582672, "critic_grad_norm": 0.03003205545246601, "ratio": 1.0000767707824707, "entropy": 0.6777827103932699, "incre_win_rate": 0.9215686274509803, "step": 1376}
{"time": 1766669540.15886, "phase": "train", "update": 1377, "total_env_steps": 4406400, "episode_reward": 0.3298881947994232, "value_loss": 0.005816029229511817, "policy_loss": -0.014117797410412436, "dist_entropy": 0.6720358769098917, "actor_grad_norm": 0.16245712339878082, "critic_grad_norm": 0.018010972067713737, "ratio": 0.9988206028938293, "entropy": 0.6720358769098917, "incre_win_rate": 0.9272727272727272, "step": 1377}
{"time": 1766669544.5872083, "phase": "train", "update": 1378, "total_env_steps": 4409600, "episode_reward": 0.3154718279838562, "value_loss": 0.007211328887691101, "policy_loss": -0.014545268363355983, "dist_entropy": 0.6863231142361959, "actor_grad_norm": 0.14997318387031555, "critic_grad_norm": 0.015433259308338165, "ratio": 0.9993942379951477, "entropy": 0.6863231142361959, "incre_win_rate": 0.8490566037735849, "step": 1378}
{"time": 1766669548.8451772, "phase": "train", "update": 1379, "total_env_steps": 4412800, "episode_reward": 0.3293267488479614, "value_loss": 0.009502310367921988, "policy_loss": -0.014584865347550628, "dist_entropy": 0.6737340648969015, "actor_grad_norm": 0.1661294549703598, "critic_grad_norm": 0.023278197273612022, "ratio": 0.998810350894928, "entropy": 0.6737340648969015, "incre_win_rate": 0.9090909090909091, "step": 1379}
{"time": 1766669553.2730446, "phase": "train", "update": 1380, "total_env_steps": 4416000, "episode_reward": 0.31936734914779663, "value_loss": 0.009441215296586354, "policy_loss": -0.013947997762644111, "dist_entropy": 0.6877224723498027, "actor_grad_norm": 0.14184726774692535, "critic_grad_norm": 0.03102056309580803, "ratio": 1.0022501945495605, "entropy": 0.6877224723498027, "incre_win_rate": 0.8301886792452831, "step": 1380}
{"time": 1766669557.656991, "phase": "train", "update": 1381, "total_env_steps": 4419200, "episode_reward": 0.31455883383750916, "value_loss": 0.014019858029981454, "policy_loss": -0.014959350980907645, "dist_entropy": 0.6879170775413513, "actor_grad_norm": 0.1706608086824417, "critic_grad_norm": 0.032768022269010544, "ratio": 1.0004581212997437, "entropy": 0.6879170775413513, "incre_win_rate": 0.8269230769230769, "step": 1381}
{"time": 1766669570.4796324, "phase": "eval", "update": 1381, "total_env_steps": 4419200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.754595588235297, "step": 1381}
{"time": 1766669574.6896882, "phase": "train", "update": 1382, "total_env_steps": 4422400, "episode_reward": 0.3126738965511322, "value_loss": 0.011230897096296152, "policy_loss": -0.014415488462147626, "dist_entropy": 0.68539004723231, "actor_grad_norm": 0.13573622703552246, "critic_grad_norm": 0.02395554445683956, "ratio": 1.0005004405975342, "entropy": 0.68539004723231, "incre_win_rate": 0.7735849056603774, "step": 1382}
{"time": 1766669578.90116, "phase": "train", "update": 1383, "total_env_steps": 4425600, "episode_reward": 0.3047066628932953, "value_loss": 0.014985615946352481, "policy_loss": -0.015774032940808525, "dist_entropy": 0.6912862857182821, "actor_grad_norm": 0.13556522130966187, "critic_grad_norm": 0.06208603456616402, "ratio": 1.000641107559204, "entropy": 0.6912862857182821, "incre_win_rate": 0.7169811320754716, "step": 1383}
{"time": 1766669583.1556656, "phase": "train", "update": 1384, "total_env_steps": 4428800, "episode_reward": 0.31454965472221375, "value_loss": 0.013612021071215471, "policy_loss": -0.015291292729287894, "dist_entropy": 0.6808414101600647, "actor_grad_norm": 0.1649959832429886, "critic_grad_norm": 0.01622324250638485, "ratio": 0.9995065331459045, "entropy": 0.6808414101600647, "incre_win_rate": 0.8035714285714286, "step": 1384}
{"time": 1766669587.3781338, "phase": "train", "update": 1385, "total_env_steps": 4432000, "episode_reward": 0.3160133361816406, "value_loss": 0.016178276265660922, "policy_loss": -0.016405715516932182, "dist_entropy": 0.6839079221089681, "actor_grad_norm": 0.15624746680259705, "critic_grad_norm": 0.03324460983276367, "ratio": 0.9991260170936584, "entropy": 0.6839079221089681, "incre_win_rate": 0.7358490566037735, "step": 1385}
{"time": 1766669591.5796254, "phase": "train", "update": 1386, "total_env_steps": 4435200, "episode_reward": 0.32875770330429077, "value_loss": 0.007753102201968431, "policy_loss": -0.014169223575522475, "dist_entropy": 0.6813171188036601, "actor_grad_norm": 0.1336575746536255, "critic_grad_norm": 0.049232855439186096, "ratio": 1.0003986358642578, "entropy": 0.6813171188036601, "incre_win_rate": 0.8888888888888888, "step": 1386}
{"time": 1766669595.8635027, "phase": "train", "update": 1387, "total_env_steps": 4438400, "episode_reward": 0.30379366874694824, "value_loss": 0.011652791313827038, "policy_loss": -0.015730813263183544, "dist_entropy": 0.6757038076718648, "actor_grad_norm": 0.13988898694515228, "critic_grad_norm": 0.018006807193160057, "ratio": 0.9996851086616516, "entropy": 0.6757038076718648, "incre_win_rate": 0.8235294117647058, "step": 1387}
{"time": 1766669600.0551167, "phase": "train", "update": 1388, "total_env_steps": 4441600, "episode_reward": 0.31313037872314453, "value_loss": 0.012418550687531631, "policy_loss": -0.014491848384272052, "dist_entropy": 0.667499037583669, "actor_grad_norm": 0.15244735777378082, "critic_grad_norm": 0.03392445668578148, "ratio": 0.9992740154266357, "entropy": 0.667499037583669, "incre_win_rate": 0.8301886792452831, "step": 1388}
{"time": 1766669604.2809649, "phase": "train", "update": 1389, "total_env_steps": 4444800, "episode_reward": 0.3061871826648712, "value_loss": 0.010636547456185023, "policy_loss": -0.015970582123122766, "dist_entropy": 0.6831146677335104, "actor_grad_norm": 0.14500397443771362, "critic_grad_norm": 0.053741440176963806, "ratio": 0.9993557333946228, "entropy": 0.6831146677335104, "incre_win_rate": 0.86, "step": 1389}
{"time": 1766669608.4270163, "phase": "train", "update": 1390, "total_env_steps": 4448000, "episode_reward": 0.306748628616333, "value_loss": 0.009913352193931739, "policy_loss": -0.015723605388432798, "dist_entropy": 0.6648807485898336, "actor_grad_norm": 0.15484081208705902, "critic_grad_norm": 0.026939313858747482, "ratio": 1.0002970695495605, "entropy": 0.6648807485898336, "incre_win_rate": 0.7358490566037735, "step": 1390}
{"time": 1766669612.636795, "phase": "train", "update": 1391, "total_env_steps": 4451200, "episode_reward": 0.32366883754730225, "value_loss": 0.006507621301958959, "policy_loss": -0.015163642790086366, "dist_entropy": 0.6637174646059673, "actor_grad_norm": 0.1495155394077301, "critic_grad_norm": 0.04443797096610069, "ratio": 0.9995908141136169, "entropy": 0.6637174646059673, "incre_win_rate": 0.8867924528301887, "step": 1391}
{"time": 1766669617.2860367, "phase": "train", "update": 1392, "total_env_steps": 4454400, "episode_reward": 0.31941869854927063, "value_loss": 0.010347559737662474, "policy_loss": -0.014164322990940075, "dist_entropy": 0.658837095896403, "actor_grad_norm": 0.12327830493450165, "critic_grad_norm": 0.020715288817882538, "ratio": 0.9998561143875122, "entropy": 0.658837095896403, "incre_win_rate": 0.8727272727272727, "step": 1392}
{"time": 1766669622.3240473, "phase": "train", "update": 1393, "total_env_steps": 4457600, "episode_reward": 0.30915671586990356, "value_loss": 0.010802438730994861, "policy_loss": -0.015501907130704732, "dist_entropy": 0.6614738504091898, "actor_grad_norm": 0.1679145246744156, "critic_grad_norm": 0.013235471211373806, "ratio": 0.9992390275001526, "entropy": 0.6614738504091898, "incre_win_rate": 0.82, "step": 1393}
{"time": 1766669627.222359, "phase": "train", "update": 1394, "total_env_steps": 4460800, "episode_reward": 0.3110286593437195, "value_loss": 0.010271708108484745, "policy_loss": -0.014853307117193518, "dist_entropy": 0.652023720741272, "actor_grad_norm": 0.1638394147157669, "critic_grad_norm": 0.021320467814803123, "ratio": 0.9985239505767822, "entropy": 0.652023720741272, "incre_win_rate": 0.7962962962962963, "step": 1394}
{"time": 1766669632.3720715, "phase": "train", "update": 1395, "total_env_steps": 4464000, "episode_reward": 0.32079657912254333, "value_loss": 0.009671188021699587, "policy_loss": -0.015114412094467629, "dist_entropy": 0.6524235725402832, "actor_grad_norm": 0.14862433075904846, "critic_grad_norm": 0.030692847445607185, "ratio": 0.9987243413925171, "entropy": 0.6524235725402832, "incre_win_rate": 0.9056603773584906, "step": 1395}
{"time": 1766669637.5618732, "phase": "train", "update": 1396, "total_env_steps": 4467200, "episode_reward": 0.31055760383605957, "value_loss": 0.01328026211510102, "policy_loss": -0.015114740171589366, "dist_entropy": 0.6619755029678345, "actor_grad_norm": 0.16989384591579437, "critic_grad_norm": 0.018062030896544456, "ratio": 1.0002436637878418, "entropy": 0.6619755029678345, "incre_win_rate": 0.803921568627451, "step": 1396}
{"time": 1766669642.132591, "phase": "train", "update": 1397, "total_env_steps": 4470400, "episode_reward": 0.31747397780418396, "value_loss": 0.01215002623697122, "policy_loss": -0.015022395021220093, "dist_entropy": 0.6480021993319194, "actor_grad_norm": 0.13823768496513367, "critic_grad_norm": 0.021929403766989708, "ratio": 1.000165343284607, "entropy": 0.6480021993319194, "incre_win_rate": 0.8545454545454545, "step": 1397}
{"time": 1766669647.0227468, "phase": "train", "update": 1398, "total_env_steps": 4473600, "episode_reward": 0.3219600319862366, "value_loss": 0.008484941348433495, "policy_loss": -0.014786221835284627, "dist_entropy": 0.662550671895345, "actor_grad_norm": 0.14690549671649933, "critic_grad_norm": 0.03434525057673454, "ratio": 0.9991698265075684, "entropy": 0.662550671895345, "incre_win_rate": 0.9230769230769231, "step": 1398}
{"time": 1766669652.0164, "phase": "train", "update": 1399, "total_env_steps": 4476800, "episode_reward": 0.3157115578651428, "value_loss": 0.012550115585327148, "policy_loss": -0.015787851756257965, "dist_entropy": 0.6425730347633362, "actor_grad_norm": 0.14690901339054108, "critic_grad_norm": 0.04533591866493225, "ratio": 0.9997075796127319, "entropy": 0.6425730347633362, "incre_win_rate": 0.7735849056603774, "step": 1399}
{"time": 1766669656.9138982, "phase": "train", "update": 1400, "total_env_steps": 4480000, "episode_reward": 0.30974724888801575, "value_loss": 0.012298931181430817, "policy_loss": -0.015684310637720956, "dist_entropy": 0.6589475035667419, "actor_grad_norm": 0.13863243162631989, "critic_grad_norm": 0.020051639527082443, "ratio": 1.000535011291504, "entropy": 0.6589475035667419, "incre_win_rate": 0.8653846153846154, "step": 1400}
{"time": 1766669661.8288229, "phase": "train", "update": 1401, "total_env_steps": 4483200, "episode_reward": 0.32220587134361267, "value_loss": 0.007995552817980449, "policy_loss": -0.01528460903209634, "dist_entropy": 0.6533906817436218, "actor_grad_norm": 0.16938602924346924, "critic_grad_norm": 0.01888466253876686, "ratio": 1.0003329515457153, "entropy": 0.6533906817436218, "incre_win_rate": 0.9038461538461539, "step": 1401}
{"time": 1766669669.9805021, "phase": "eval", "update": 1401, "total_env_steps": 4483200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.60516237745098, "step": 1401}
{"time": 1766669674.8228312, "phase": "train", "update": 1402, "total_env_steps": 4486400, "episode_reward": 0.31203433871269226, "value_loss": 0.012414829184611639, "policy_loss": -0.014800906305828695, "dist_entropy": 0.6519803126653035, "actor_grad_norm": 0.14641503989696503, "critic_grad_norm": 0.03146056830883026, "ratio": 0.9987168908119202, "entropy": 0.6519803126653035, "incre_win_rate": 0.7636363636363637, "step": 1402}
{"time": 1766669679.779217, "phase": "train", "update": 1403, "total_env_steps": 4489600, "episode_reward": 0.31131511926651, "value_loss": 0.009838060848414898, "policy_loss": -0.01482722366315888, "dist_entropy": 0.6492596745491028, "actor_grad_norm": 0.14398451149463654, "critic_grad_norm": 0.0185852088034153, "ratio": 1.0011062622070312, "entropy": 0.6492596745491028, "incre_win_rate": 0.8431372549019608, "step": 1403}
{"time": 1766669684.6366878, "phase": "train", "update": 1404, "total_env_steps": 4492800, "episode_reward": 0.3036358654499054, "value_loss": 0.012009393734236559, "policy_loss": -0.01484754511116743, "dist_entropy": 0.6427982529004415, "actor_grad_norm": 0.16490867733955383, "critic_grad_norm": 0.02040821686387062, "ratio": 1.0004109144210815, "entropy": 0.6427982529004415, "incre_win_rate": 0.803921568627451, "step": 1404}
{"time": 1766669689.561881, "phase": "train", "update": 1405, "total_env_steps": 4496000, "episode_reward": 0.3047204613685608, "value_loss": 0.012067302378515403, "policy_loss": -0.016209688055220304, "dist_entropy": 0.654448660214742, "actor_grad_norm": 0.1514606773853302, "critic_grad_norm": 0.031536683440208435, "ratio": 0.9996413588523865, "entropy": 0.654448660214742, "incre_win_rate": 0.7547169811320755, "step": 1405}
{"time": 1766669694.4837744, "phase": "train", "update": 1406, "total_env_steps": 4499200, "episode_reward": 0.3214032053947449, "value_loss": 0.008414468138168256, "policy_loss": -0.014233678150554378, "dist_entropy": 0.672369925181071, "actor_grad_norm": 0.15243162214756012, "critic_grad_norm": 0.014378285966813564, "ratio": 0.9992436766624451, "entropy": 0.672369925181071, "incre_win_rate": 0.8518518518518519, "step": 1406}
{"time": 1766669699.219043, "phase": "train", "update": 1407, "total_env_steps": 4502400, "episode_reward": 0.3186841309070587, "value_loss": 0.010561985895037651, "policy_loss": -0.016174903673666564, "dist_entropy": 0.6575516064961752, "actor_grad_norm": 0.17016267776489258, "critic_grad_norm": 0.03493605554103851, "ratio": 0.9992451071739197, "entropy": 0.6575516064961752, "incre_win_rate": 0.7962962962962963, "step": 1407}
{"time": 1766669704.1494482, "phase": "train", "update": 1408, "total_env_steps": 4505600, "episode_reward": 0.29813799262046814, "value_loss": 0.012384040219088396, "policy_loss": -0.015491134068611245, "dist_entropy": 0.647448746363322, "actor_grad_norm": 0.1572975218296051, "critic_grad_norm": 0.04061802849173546, "ratio": 0.9997873306274414, "entropy": 0.647448746363322, "incre_win_rate": 0.76, "step": 1408}
{"time": 1766669708.853534, "phase": "train", "update": 1409, "total_env_steps": 4508800, "episode_reward": 0.298440545797348, "value_loss": 0.012056227773427963, "policy_loss": -0.015584867777446713, "dist_entropy": 0.6538186073303223, "actor_grad_norm": 0.14239805936813354, "critic_grad_norm": 0.0360117070376873, "ratio": 0.9990710020065308, "entropy": 0.6538186073303223, "incre_win_rate": 0.78, "step": 1409}
{"time": 1766669713.7216842, "phase": "train", "update": 1410, "total_env_steps": 4512000, "episode_reward": 0.3238128125667572, "value_loss": 0.00964976493269205, "policy_loss": -0.01571169237658025, "dist_entropy": 0.6624261856079101, "actor_grad_norm": 0.14208069443702698, "critic_grad_norm": 0.017647594213485718, "ratio": 0.9983657002449036, "entropy": 0.6624261856079101, "incre_win_rate": 0.8214285714285714, "step": 1410}
{"time": 1766669718.4108431, "phase": "train", "update": 1411, "total_env_steps": 4515200, "episode_reward": 0.3112063705921173, "value_loss": 0.011352867136398952, "policy_loss": -0.014049741395607877, "dist_entropy": 0.651015039285024, "actor_grad_norm": 0.15699660778045654, "critic_grad_norm": 0.008473098278045654, "ratio": 0.999502420425415, "entropy": 0.651015039285024, "incre_win_rate": 0.8, "step": 1411}
{"time": 1766669723.0010977, "phase": "train", "update": 1412, "total_env_steps": 4518400, "episode_reward": 0.3249777853488922, "value_loss": 0.009643159185846647, "policy_loss": -0.014626704849683847, "dist_entropy": 0.6643455465634663, "actor_grad_norm": 0.15137135982513428, "critic_grad_norm": 0.010661366395652294, "ratio": 0.9993211627006531, "entropy": 0.6643455465634663, "incre_win_rate": 0.8909090909090909, "step": 1412}
{"time": 1766669727.6867359, "phase": "train", "update": 1413, "total_env_steps": 4521600, "episode_reward": 0.3243926465511322, "value_loss": 0.008698777109384537, "policy_loss": -0.015144565901116873, "dist_entropy": 0.6594926555951436, "actor_grad_norm": 0.15514175593852997, "critic_grad_norm": 0.024698501452803612, "ratio": 0.9992388486862183, "entropy": 0.6594926555951436, "incre_win_rate": 0.8888888888888888, "step": 1413}
{"time": 1766669731.9240184, "phase": "train", "update": 1414, "total_env_steps": 4524800, "episode_reward": 0.30414676666259766, "value_loss": 0.011687851573030154, "policy_loss": -0.014714593823050966, "dist_entropy": 0.6642606298128764, "actor_grad_norm": 0.16406667232513428, "critic_grad_norm": 0.022437941282987595, "ratio": 1.0000954866409302, "entropy": 0.6642606298128764, "incre_win_rate": 0.86, "step": 1414}
{"time": 1766669736.3359437, "phase": "train", "update": 1415, "total_env_steps": 4528000, "episode_reward": 0.3059091866016388, "value_loss": 0.012879677303135394, "policy_loss": -0.015087976863209935, "dist_entropy": 0.6686155398686727, "actor_grad_norm": 0.1525668054819107, "critic_grad_norm": 0.020695075392723083, "ratio": 1.0007392168045044, "entropy": 0.6686155398686727, "incre_win_rate": 0.7884615384615384, "step": 1415}
{"time": 1766669740.6808968, "phase": "train", "update": 1416, "total_env_steps": 4531200, "episode_reward": 0.30235064029693604, "value_loss": 0.010882139392197131, "policy_loss": -0.01543950840931115, "dist_entropy": 0.6619517246882121, "actor_grad_norm": 0.1628168523311615, "critic_grad_norm": 0.013633925467729568, "ratio": 1.0002248287200928, "entropy": 0.6619517246882121, "incre_win_rate": 0.7692307692307693, "step": 1416}
{"time": 1766669744.87726, "phase": "train", "update": 1417, "total_env_steps": 4534400, "episode_reward": 0.3146882951259613, "value_loss": 0.006877948250621557, "policy_loss": -0.013836407245665327, "dist_entropy": 0.6516934593518575, "actor_grad_norm": 0.13999220728874207, "critic_grad_norm": 0.041012849658727646, "ratio": 0.9986481666564941, "entropy": 0.6516934593518575, "incre_win_rate": 0.8490566037735849, "step": 1417}
{"time": 1766669749.1431556, "phase": "train", "update": 1418, "total_env_steps": 4537600, "episode_reward": 0.3116076588630676, "value_loss": 0.012046458944678307, "policy_loss": -0.015246374431999795, "dist_entropy": 0.6573426882425945, "actor_grad_norm": 0.16889998316764832, "critic_grad_norm": 0.03790493682026863, "ratio": 0.9999849200248718, "entropy": 0.6573426882425945, "incre_win_rate": 0.7777777777777778, "step": 1418}
{"time": 1766669753.3303938, "phase": "train", "update": 1419, "total_env_steps": 4540800, "episode_reward": 0.30554917454719543, "value_loss": 0.01182742410649856, "policy_loss": -0.014575882600255833, "dist_entropy": 0.6464792648951213, "actor_grad_norm": 0.13433592021465302, "critic_grad_norm": 0.0314335860311985, "ratio": 1.000683307647705, "entropy": 0.6464792648951213, "incre_win_rate": 0.82, "step": 1419}
{"time": 1766669757.515705, "phase": "train", "update": 1420, "total_env_steps": 4544000, "episode_reward": 0.3034459352493286, "value_loss": 0.01042099967598915, "policy_loss": -0.014661945803915917, "dist_entropy": 0.6627647916475932, "actor_grad_norm": 0.14202706515789032, "critic_grad_norm": 0.010725868865847588, "ratio": 1.0002315044403076, "entropy": 0.6627647916475932, "incre_win_rate": 0.7884615384615384, "step": 1420}
{"time": 1766669761.7107494, "phase": "train", "update": 1421, "total_env_steps": 4547200, "episode_reward": 0.30808213353157043, "value_loss": 0.014173558043936888, "policy_loss": -0.015335527858356575, "dist_entropy": 0.6722657243410747, "actor_grad_norm": 0.1358521431684494, "critic_grad_norm": 0.03132283687591553, "ratio": 0.9991743564605713, "entropy": 0.6722657243410747, "incre_win_rate": 0.803921568627451, "step": 1421}
{"time": 1766669768.9781175, "phase": "eval", "update": 1421, "total_env_steps": 4547200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.88204656862745, "step": 1421}
{"time": 1766669773.3594494, "phase": "train", "update": 1422, "total_env_steps": 4550400, "episode_reward": 0.2970151901245117, "value_loss": 0.013711198916037877, "policy_loss": -0.015976286259701548, "dist_entropy": 0.6613153696060181, "actor_grad_norm": 0.1672702580690384, "critic_grad_norm": 0.06025170162320137, "ratio": 0.9997750520706177, "entropy": 0.6613153696060181, "incre_win_rate": 0.7735849056603774, "step": 1422}
{"time": 1766669777.5666418, "phase": "train", "update": 1423, "total_env_steps": 4553600, "episode_reward": 0.2987936735153198, "value_loss": 0.011793268906573454, "policy_loss": -0.015472177468816994, "dist_entropy": 0.6740622798601786, "actor_grad_norm": 0.13912883400917053, "critic_grad_norm": 0.01743360422551632, "ratio": 0.9994021058082581, "entropy": 0.6740622798601786, "incre_win_rate": 0.8, "step": 1423}
{"time": 1766669781.8180916, "phase": "train", "update": 1424, "total_env_steps": 4556800, "episode_reward": 0.30482766032218933, "value_loss": 0.011145086959004402, "policy_loss": -0.01482732229782376, "dist_entropy": 0.6658957242965698, "actor_grad_norm": 0.15485122799873352, "critic_grad_norm": 0.030641265213489532, "ratio": 0.9999181032180786, "entropy": 0.6658957242965698, "incre_win_rate": 0.803921568627451, "step": 1424}
{"time": 1766669786.0092428, "phase": "train", "update": 1425, "total_env_steps": 4560000, "episode_reward": 0.3063870966434479, "value_loss": 0.007238036176810662, "policy_loss": -0.014867326685997995, "dist_entropy": 0.6667358756065369, "actor_grad_norm": 0.14055678248405457, "critic_grad_norm": 0.013552099466323853, "ratio": 0.9999280571937561, "entropy": 0.6667358756065369, "incre_win_rate": 0.8113207547169812, "step": 1425}
{"time": 1766669790.238027, "phase": "train", "update": 1426, "total_env_steps": 4563200, "episode_reward": 0.28405332565307617, "value_loss": 0.012198299976686637, "policy_loss": -0.015533202554576539, "dist_entropy": 0.6933072447776795, "actor_grad_norm": 0.14924673736095428, "critic_grad_norm": 0.04994947090744972, "ratio": 1.0016419887542725, "entropy": 0.6933072447776795, "incre_win_rate": 0.7142857142857143, "step": 1426}
{"time": 1766669794.4263127, "phase": "train", "update": 1427, "total_env_steps": 4566400, "episode_reward": 0.29859375953674316, "value_loss": 0.012703580285112063, "policy_loss": -0.01487210125760612, "dist_entropy": 0.6819867451985677, "actor_grad_norm": 0.15802323818206787, "critic_grad_norm": 0.03666812926530838, "ratio": 1.0012508630752563, "entropy": 0.6819867451985677, "incre_win_rate": 0.7450980392156863, "step": 1427}
{"time": 1766669798.6365128, "phase": "train", "update": 1428, "total_env_steps": 4569600, "episode_reward": 0.2867700755596161, "value_loss": 0.013945842037598292, "policy_loss": -0.01522744529269365, "dist_entropy": 0.6810030778249104, "actor_grad_norm": 0.17526589334011078, "critic_grad_norm": 0.024403003975749016, "ratio": 0.9997678995132446, "entropy": 0.6810030778249104, "incre_win_rate": 0.72, "step": 1428}
{"time": 1766669802.823858, "phase": "train", "update": 1429, "total_env_steps": 4572800, "episode_reward": 0.30526500940322876, "value_loss": 0.011045611215134461, "policy_loss": -0.014344735917975034, "dist_entropy": 0.7003536939620971, "actor_grad_norm": 0.17217597365379333, "critic_grad_norm": 0.03855841979384422, "ratio": 1.0002985000610352, "entropy": 0.7003536939620971, "incre_win_rate": 0.8431372549019608, "step": 1429}
{"time": 1766669807.0497205, "phase": "train", "update": 1430, "total_env_steps": 4576000, "episode_reward": 0.29794424772262573, "value_loss": 0.010242334380745888, "policy_loss": -0.016153871042473136, "dist_entropy": 0.6839018185933431, "actor_grad_norm": 0.1619751751422882, "critic_grad_norm": 0.022045820951461792, "ratio": 1.0002272129058838, "entropy": 0.6839018185933431, "incre_win_rate": 0.7307692307692307, "step": 1430}
{"time": 1766669811.2628736, "phase": "train", "update": 1431, "total_env_steps": 4579200, "episode_reward": 0.2967424988746643, "value_loss": 0.011021340327958266, "policy_loss": -0.014265565876812285, "dist_entropy": 0.6933210055033366, "actor_grad_norm": 0.14884786307811737, "critic_grad_norm": 0.011833835393190384, "ratio": 0.9995675683021545, "entropy": 0.6933210055033366, "incre_win_rate": 0.78, "step": 1431}
{"time": 1766669815.419963, "phase": "train", "update": 1432, "total_env_steps": 4582400, "episode_reward": 0.30408167839050293, "value_loss": 0.009768771504362424, "policy_loss": -0.015050184168918198, "dist_entropy": 0.6947695652643839, "actor_grad_norm": 0.14288964867591858, "critic_grad_norm": 0.013237759470939636, "ratio": 1.0001226663589478, "entropy": 0.6947695652643839, "incre_win_rate": 0.803921568627451, "step": 1432}
{"time": 1766669819.6647987, "phase": "train", "update": 1433, "total_env_steps": 4585600, "episode_reward": 0.30345970392227173, "value_loss": 0.01035789834956328, "policy_loss": -0.014092457370730452, "dist_entropy": 0.6874301950136821, "actor_grad_norm": 0.13409048318862915, "critic_grad_norm": 0.027842042967677116, "ratio": 0.9999679923057556, "entropy": 0.6874301950136821, "incre_win_rate": 0.8113207547169812, "step": 1433}
{"time": 1766669823.8661506, "phase": "train", "update": 1434, "total_env_steps": 4588800, "episode_reward": 0.30972737073898315, "value_loss": 0.012259396724402905, "policy_loss": -0.014867674504644886, "dist_entropy": 0.6669929345448812, "actor_grad_norm": 0.1464408040046692, "critic_grad_norm": 0.014149622991681099, "ratio": 0.9996545314788818, "entropy": 0.6669929345448812, "incre_win_rate": 0.8269230769230769, "step": 1434}
{"time": 1766669828.046017, "phase": "train", "update": 1435, "total_env_steps": 4592000, "episode_reward": 0.28854241967201233, "value_loss": 0.00894147101789713, "policy_loss": -0.015262109482309919, "dist_entropy": 0.6621732155481974, "actor_grad_norm": 0.14674635231494904, "critic_grad_norm": 0.024684768170118332, "ratio": 0.999984860420227, "entropy": 0.6621732155481974, "incre_win_rate": 0.75, "step": 1435}
{"time": 1766669832.2851944, "phase": "train", "update": 1436, "total_env_steps": 4595200, "episode_reward": 0.30693018436431885, "value_loss": 0.010930881525079409, "policy_loss": -0.014982578237007497, "dist_entropy": 0.6745170911153158, "actor_grad_norm": 0.1448269933462143, "critic_grad_norm": 0.020740097388625145, "ratio": 0.999211311340332, "entropy": 0.6745170911153158, "incre_win_rate": 0.8113207547169812, "step": 1436}
{"time": 1766669836.5844805, "phase": "train", "update": 1437, "total_env_steps": 4598400, "episode_reward": 0.299404114484787, "value_loss": 0.010206730974217256, "policy_loss": -0.015750046584721154, "dist_entropy": 0.6626448631286621, "actor_grad_norm": 0.13906355202198029, "critic_grad_norm": 0.045319247990846634, "ratio": 0.998908281326294, "entropy": 0.6626448631286621, "incre_win_rate": 0.6923076923076923, "step": 1437}
{"time": 1766669840.9315705, "phase": "train", "update": 1438, "total_env_steps": 4601600, "episode_reward": 0.2948361337184906, "value_loss": 0.011047274681429069, "policy_loss": -0.014688314199769554, "dist_entropy": 0.6649739344914755, "actor_grad_norm": 0.14202293753623962, "critic_grad_norm": 0.04393218085169792, "ratio": 1.0006648302078247, "entropy": 0.6649739344914755, "incre_win_rate": 0.78, "step": 1438}
{"time": 1766669845.0876405, "phase": "train", "update": 1439, "total_env_steps": 4604800, "episode_reward": 0.29059895873069763, "value_loss": 0.009552276941637199, "policy_loss": -0.015758615782007723, "dist_entropy": 0.6900078574816386, "actor_grad_norm": 0.15016897022724152, "critic_grad_norm": 0.01316061895340681, "ratio": 1.00058114528656, "entropy": 0.6900078574816386, "incre_win_rate": 0.82, "step": 1439}
{"time": 1766669849.5648205, "phase": "train", "update": 1440, "total_env_steps": 4608000, "episode_reward": 0.2981870472431183, "value_loss": 0.012493930570781232, "policy_loss": -0.014849108146374116, "dist_entropy": 0.6672313729921977, "actor_grad_norm": 0.15817463397979736, "critic_grad_norm": 0.02599746361374855, "ratio": 0.9984789490699768, "entropy": 0.6672313729921977, "incre_win_rate": 0.7708333333333334, "step": 1440}
{"time": 1766669854.021923, "phase": "train", "update": 1441, "total_env_steps": 4611200, "episode_reward": 0.3000107407569885, "value_loss": 0.006374562438577413, "policy_loss": -0.014735383439143372, "dist_entropy": 0.671677811940511, "actor_grad_norm": 0.13760070502758026, "critic_grad_norm": 0.021110543981194496, "ratio": 1.0009665489196777, "entropy": 0.671677811940511, "incre_win_rate": 0.8627450980392157, "step": 1441}
{"time": 1766669861.796619, "phase": "eval", "update": 1441, "total_env_steps": 4611200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.85500919117647, "step": 1441}
{"time": 1766669865.994855, "phase": "train", "update": 1442, "total_env_steps": 4614400, "episode_reward": 0.3063465356826782, "value_loss": 0.0071584543834129965, "policy_loss": -0.014825466495187812, "dist_entropy": 0.6824905554453532, "actor_grad_norm": 0.1465912014245987, "critic_grad_norm": 0.013239406980574131, "ratio": 0.999428927898407, "entropy": 0.6824905554453532, "incre_win_rate": 0.8269230769230769, "step": 1442}
{"time": 1766669870.2628787, "phase": "train", "update": 1443, "total_env_steps": 4617600, "episode_reward": 0.3233731687068939, "value_loss": 0.007373317424207926, "policy_loss": -0.0130965033019019, "dist_entropy": 0.6559584498405456, "actor_grad_norm": 0.15923698246479034, "critic_grad_norm": 0.023319967091083527, "ratio": 1.0002647638320923, "entropy": 0.6559584498405456, "incre_win_rate": 0.8703703703703703, "step": 1443}
{"time": 1766669874.4470925, "phase": "train", "update": 1444, "total_env_steps": 4620800, "episode_reward": 0.3052014708518982, "value_loss": 0.008839149959385395, "policy_loss": -0.013706881020362023, "dist_entropy": 0.6713147362073263, "actor_grad_norm": 0.1580183357000351, "critic_grad_norm": 0.02384788729250431, "ratio": 0.9997263550758362, "entropy": 0.6713147362073263, "incre_win_rate": 0.8, "step": 1444}
{"time": 1766669878.8584464, "phase": "train", "update": 1445, "total_env_steps": 4624000, "episode_reward": 0.30746936798095703, "value_loss": 0.009561927492419879, "policy_loss": -0.01429759078670448, "dist_entropy": 0.6721442540486654, "actor_grad_norm": 0.1407649964094162, "critic_grad_norm": 0.037052419036626816, "ratio": 0.9999057650566101, "entropy": 0.6721442540486654, "incre_win_rate": 0.7692307692307693, "step": 1445}
{"time": 1766669883.1485236, "phase": "train", "update": 1446, "total_env_steps": 4627200, "episode_reward": 0.3120098412036896, "value_loss": 0.007391238119453192, "policy_loss": -0.014465105688333323, "dist_entropy": 0.6732331037521362, "actor_grad_norm": 0.14841525256633759, "critic_grad_norm": 0.014007402583956718, "ratio": 0.9995844960212708, "entropy": 0.6732331037521362, "incre_win_rate": 0.8679245283018868, "step": 1446}
{"time": 1766669887.5469205, "phase": "train", "update": 1447, "total_env_steps": 4630400, "episode_reward": 0.3041505813598633, "value_loss": 0.011805864547689756, "policy_loss": -0.014509244475208523, "dist_entropy": 0.6634037017822265, "actor_grad_norm": 0.15393099188804626, "critic_grad_norm": 0.03983880579471588, "ratio": 1.0003398656845093, "entropy": 0.6634037017822265, "incre_win_rate": 0.7692307692307693, "step": 1447}
{"time": 1766669891.8425748, "phase": "train", "update": 1448, "total_env_steps": 4633600, "episode_reward": 0.30991193652153015, "value_loss": 0.010978194822867712, "policy_loss": -0.014805518028233185, "dist_entropy": 0.6564740459124248, "actor_grad_norm": 0.14865903556346893, "critic_grad_norm": 0.01363267470151186, "ratio": 1.0009005069732666, "entropy": 0.6564740459124248, "incre_win_rate": 0.8076923076923077, "step": 1448}
{"time": 1766669896.2487767, "phase": "train", "update": 1449, "total_env_steps": 4636800, "episode_reward": 0.30531176924705505, "value_loss": 0.011614103615283967, "policy_loss": -0.014064740241958163, "dist_entropy": 0.6640021721522014, "actor_grad_norm": 0.146220400929451, "critic_grad_norm": 0.015647972002625465, "ratio": 0.9990153908729553, "entropy": 0.6640021721522014, "incre_win_rate": 0.7884615384615384, "step": 1449}
{"time": 1766669900.8770936, "phase": "train", "update": 1450, "total_env_steps": 4640000, "episode_reward": 0.3242233693599701, "value_loss": 0.0057038680029412115, "policy_loss": -0.013297937099488876, "dist_entropy": 0.6716596126556397, "actor_grad_norm": 0.14819630980491638, "critic_grad_norm": 0.04287463426589966, "ratio": 0.999589204788208, "entropy": 0.6716596126556397, "incre_win_rate": 0.9259259259259259, "step": 1450}
{"time": 1766669905.2724564, "phase": "train", "update": 1451, "total_env_steps": 4643200, "episode_reward": 0.3236626982688904, "value_loss": 0.008710873375336329, "policy_loss": -0.01326206831748588, "dist_entropy": 0.6509781082471212, "actor_grad_norm": 0.15020038187503815, "critic_grad_norm": 0.025342503562569618, "ratio": 0.999751627445221, "entropy": 0.6509781082471212, "incre_win_rate": 0.9230769230769231, "step": 1451}
{"time": 1766669909.4571998, "phase": "train", "update": 1452, "total_env_steps": 4646400, "episode_reward": 0.31849420070648193, "value_loss": 0.006932058775176605, "policy_loss": -0.01439333055541366, "dist_entropy": 0.6547718167304992, "actor_grad_norm": 0.1450812965631485, "critic_grad_norm": 0.009516672231256962, "ratio": 0.9996064901351929, "entropy": 0.6547718167304992, "incre_win_rate": 0.8653846153846154, "step": 1452}
{"time": 1766669913.6686614, "phase": "train", "update": 1453, "total_env_steps": 4649600, "episode_reward": 0.29746168851852417, "value_loss": 0.009562739605704943, "policy_loss": -0.013920154331785995, "dist_entropy": 0.6505353967348735, "actor_grad_norm": 0.15243808925151825, "critic_grad_norm": 0.06408969312906265, "ratio": 1.0008301734924316, "entropy": 0.6505353967348735, "incre_win_rate": 0.7843137254901961, "step": 1453}
{"time": 1766669918.2452514, "phase": "train", "update": 1454, "total_env_steps": 4652800, "episode_reward": 0.2984681725502014, "value_loss": 0.010531999294956525, "policy_loss": -0.014553781221609559, "dist_entropy": 0.6556622584660848, "actor_grad_norm": 0.13685911893844604, "critic_grad_norm": 0.06257687509059906, "ratio": 1.0005658864974976, "entropy": 0.6556622584660848, "incre_win_rate": 0.76, "step": 1454}
{"time": 1766669922.4705946, "phase": "train", "update": 1455, "total_env_steps": 4656000, "episode_reward": 0.30993029475212097, "value_loss": 0.009012183733284473, "policy_loss": -0.016023763725418878, "dist_entropy": 0.6645023028055826, "actor_grad_norm": 0.13885173201560974, "critic_grad_norm": 0.02154144085943699, "ratio": 1.0001035928726196, "entropy": 0.6645023028055826, "incre_win_rate": 0.7818181818181819, "step": 1455}
{"time": 1766669926.7221937, "phase": "train", "update": 1456, "total_env_steps": 4659200, "episode_reward": 0.29205194115638733, "value_loss": 0.01451140884310007, "policy_loss": -0.016029461565494785, "dist_entropy": 0.6577014764149983, "actor_grad_norm": 0.14192518591880798, "critic_grad_norm": 0.08327645063400269, "ratio": 0.9983387589454651, "entropy": 0.6577014764149983, "incre_win_rate": 0.6346153846153846, "step": 1456}
{"time": 1766669930.9322171, "phase": "train", "update": 1457, "total_env_steps": 4662400, "episode_reward": 0.29866039752960205, "value_loss": 0.012137311014036338, "policy_loss": -0.015278373824494196, "dist_entropy": 0.6751447916030884, "actor_grad_norm": 0.1384749859571457, "critic_grad_norm": 0.03320159763097763, "ratio": 0.9997716546058655, "entropy": 0.6751447916030884, "incre_win_rate": 0.74, "step": 1457}
{"time": 1766669935.1069276, "phase": "train", "update": 1458, "total_env_steps": 4665600, "episode_reward": 0.30806678533554077, "value_loss": 0.0097320972631375, "policy_loss": -0.015452049189319913, "dist_entropy": 0.6733048597971598, "actor_grad_norm": 0.16575556993484497, "critic_grad_norm": 0.010481277480721474, "ratio": 1.0003212690353394, "entropy": 0.6733048597971598, "incre_win_rate": 0.7962962962962963, "step": 1458}
{"time": 1766669939.2979245, "phase": "train", "update": 1459, "total_env_steps": 4668800, "episode_reward": 0.31022363901138306, "value_loss": 0.009845795792837937, "policy_loss": -0.01587992559964467, "dist_entropy": 0.6594651261965434, "actor_grad_norm": 0.13335907459259033, "critic_grad_norm": 0.009654771536588669, "ratio": 0.9998056292533875, "entropy": 0.6594651261965434, "incre_win_rate": 0.76, "step": 1459}
{"time": 1766669943.5589752, "phase": "train", "update": 1460, "total_env_steps": 4672000, "episode_reward": 0.30518078804016113, "value_loss": 0.011520644401510556, "policy_loss": -0.015177602201327526, "dist_entropy": 0.6529245734214782, "actor_grad_norm": 0.14497792720794678, "critic_grad_norm": 0.03325720503926277, "ratio": 0.9990967512130737, "entropy": 0.6529245734214782, "incre_win_rate": 0.7777777777777778, "step": 1460}
{"time": 1766669947.7515872, "phase": "train", "update": 1461, "total_env_steps": 4675200, "episode_reward": 0.2936565577983856, "value_loss": 0.011148770650227865, "policy_loss": -0.014994574457640889, "dist_entropy": 0.6588143984476725, "actor_grad_norm": 0.13830718398094177, "critic_grad_norm": 0.023880934342741966, "ratio": 0.9998407959938049, "entropy": 0.6588143984476725, "incre_win_rate": 0.6538461538461539, "step": 1461}
{"time": 1766669955.4220724, "phase": "eval", "update": 1461, "total_env_steps": 4675200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.8969056372549, "step": 1461}
{"time": 1766669959.6321914, "phase": "train", "update": 1462, "total_env_steps": 4678400, "episode_reward": 0.2995733916759491, "value_loss": 0.013145311052600544, "policy_loss": -0.015576289506367403, "dist_entropy": 0.6726021567980448, "actor_grad_norm": 0.14048908650875092, "critic_grad_norm": 0.019582010805606842, "ratio": 1.0003230571746826, "entropy": 0.6726021567980448, "incre_win_rate": 0.7058823529411765, "step": 1462}
{"time": 1766669964.1970792, "phase": "train", "update": 1463, "total_env_steps": 4681600, "episode_reward": 0.31881049275398254, "value_loss": 0.008002420701086522, "policy_loss": -0.016403944517012783, "dist_entropy": 0.6834605455398559, "actor_grad_norm": 0.16285791993141174, "critic_grad_norm": 0.04454893618822098, "ratio": 0.9991865158081055, "entropy": 0.6834605455398559, "incre_win_rate": 0.8867924528301887, "step": 1463}
{"time": 1766669968.670918, "phase": "train", "update": 1464, "total_env_steps": 4684800, "episode_reward": 0.30598345398902893, "value_loss": 0.012631613512833912, "policy_loss": -0.01627838009224784, "dist_entropy": 0.6645711143811543, "actor_grad_norm": 0.15421971678733826, "critic_grad_norm": 0.019970571622252464, "ratio": 0.9988157153129578, "entropy": 0.6645711143811543, "incre_win_rate": 0.75, "step": 1464}
{"time": 1766669973.1110206, "phase": "train", "update": 1465, "total_env_steps": 4688000, "episode_reward": 0.30879443883895874, "value_loss": 0.010015848092734814, "policy_loss": -0.01505015206179318, "dist_entropy": 0.6586876670519511, "actor_grad_norm": 0.1274591088294983, "critic_grad_norm": 0.025242812931537628, "ratio": 0.9997162222862244, "entropy": 0.6586876670519511, "incre_win_rate": 0.8113207547169812, "step": 1465}
{"time": 1766669977.5652516, "phase": "train", "update": 1466, "total_env_steps": 4691200, "episode_reward": 0.3109329342842102, "value_loss": 0.010058123121658961, "policy_loss": -0.015232054357782469, "dist_entropy": 0.6520958781242371, "actor_grad_norm": 0.13605573773384094, "critic_grad_norm": 0.026169218122959137, "ratio": 1.0004615783691406, "entropy": 0.6520958781242371, "incre_win_rate": 0.8148148148148148, "step": 1466}
{"time": 1766669982.0191827, "phase": "train", "update": 1467, "total_env_steps": 4694400, "episode_reward": 0.3165333867073059, "value_loss": 0.008499109372496604, "policy_loss": -0.014399016524216298, "dist_entropy": 0.65416921377182, "actor_grad_norm": 0.12474256753921509, "critic_grad_norm": 0.025150485336780548, "ratio": 0.9985414743423462, "entropy": 0.65416921377182, "incre_win_rate": 0.8076923076923077, "step": 1467}
{"time": 1766669986.3171964, "phase": "train", "update": 1468, "total_env_steps": 4697600, "episode_reward": 0.30058977007865906, "value_loss": 0.008841298893094063, "policy_loss": -0.015340311562852094, "dist_entropy": 0.6431109110514323, "actor_grad_norm": 0.14666195213794708, "critic_grad_norm": 0.020808394998311996, "ratio": 0.9994617700576782, "entropy": 0.6431109110514323, "incre_win_rate": 0.7843137254901961, "step": 1468}
{"time": 1766670016.245653, "phase": "train", "update": 1469, "total_env_steps": 4700800, "episode_reward": 0.2927657961845398, "value_loss": 0.06391816288232803, "policy_loss": -0.01200350928728208, "dist_entropy": 0.6764945228894551, "actor_grad_norm": 0.11789952963590622, "critic_grad_norm": 0.12206131219863892, "ratio": 1.001519799232483, "entropy": 0.6764945228894551, "incre_win_rate": 0.6875, "step": 1469}
{"time": 1766670020.6068816, "phase": "train", "update": 1470, "total_env_steps": 4704000, "episode_reward": 0.30154332518577576, "value_loss": 0.011254861516257127, "policy_loss": -0.016078629096157707, "dist_entropy": 0.6687535007794698, "actor_grad_norm": 0.15509936213493347, "critic_grad_norm": 0.026272756978869438, "ratio": 0.9990289211273193, "entropy": 0.6687535007794698, "incre_win_rate": 0.7358490566037735, "step": 1470}
{"time": 1766670025.1445062, "phase": "train", "update": 1471, "total_env_steps": 4707200, "episode_reward": 0.30794423818588257, "value_loss": 0.008248167919615905, "policy_loss": -0.014605828656811325, "dist_entropy": 0.6700368285179138, "actor_grad_norm": 0.13390980660915375, "critic_grad_norm": 0.05420859530568123, "ratio": 1.000025987625122, "entropy": 0.6700368285179138, "incre_win_rate": 0.8431372549019608, "step": 1471}
{"time": 1766670029.5126069, "phase": "train", "update": 1472, "total_env_steps": 4710400, "episode_reward": 0.31945618987083435, "value_loss": 0.007013988091299931, "policy_loss": -0.014602069674319295, "dist_entropy": 0.6546012202898661, "actor_grad_norm": 0.14562734961509705, "critic_grad_norm": 0.03549547120928764, "ratio": 0.9990665912628174, "entropy": 0.6546012202898661, "incre_win_rate": 0.8490566037735849, "step": 1472}
{"time": 1766670033.8164186, "phase": "train", "update": 1473, "total_env_steps": 4713600, "episode_reward": 0.3108953833580017, "value_loss": 0.006744521794219812, "policy_loss": -0.015753124640430844, "dist_entropy": 0.6690015355745952, "actor_grad_norm": 0.16040560603141785, "critic_grad_norm": 0.024672240018844604, "ratio": 0.9978420734405518, "entropy": 0.6690015355745952, "incre_win_rate": 0.8653846153846154, "step": 1473}
{"time": 1766670038.0966935, "phase": "train", "update": 1474, "total_env_steps": 4716800, "episode_reward": 0.2950398623943329, "value_loss": 0.010391403920948505, "policy_loss": -0.014802076046007074, "dist_entropy": 0.6729038238525391, "actor_grad_norm": 0.16060540080070496, "critic_grad_norm": 0.03448976203799248, "ratio": 0.9997630715370178, "entropy": 0.6729038238525391, "incre_win_rate": 0.8, "step": 1474}
{"time": 1766670042.317133, "phase": "train", "update": 1475, "total_env_steps": 4720000, "episode_reward": 0.3059643507003784, "value_loss": 0.008614172165592512, "policy_loss": -0.015413435455544307, "dist_entropy": 0.6641138275464376, "actor_grad_norm": 0.1451045423746109, "critic_grad_norm": 0.029865367338061333, "ratio": 0.9998056888580322, "entropy": 0.6641138275464376, "incre_win_rate": 0.86, "step": 1475}
{"time": 1766670046.6112049, "phase": "train", "update": 1476, "total_env_steps": 4723200, "episode_reward": 0.3076593279838562, "value_loss": 0.00899482990304629, "policy_loss": -0.015720421496902285, "dist_entropy": 0.6974764903386433, "actor_grad_norm": 0.1313859075307846, "critic_grad_norm": 0.015015854500234127, "ratio": 0.9996432065963745, "entropy": 0.6974764903386433, "incre_win_rate": 0.7962962962962963, "step": 1476}
{"time": 1766670050.8554971, "phase": "train", "update": 1477, "total_env_steps": 4726400, "episode_reward": 0.29901883006095886, "value_loss": 0.013571977118651072, "policy_loss": -0.016223391711347783, "dist_entropy": 0.6832839926083882, "actor_grad_norm": 0.13322852551937103, "critic_grad_norm": 0.027720484882593155, "ratio": 1.0008457899093628, "entropy": 0.6832839926083882, "incre_win_rate": 0.7959183673469388, "step": 1477}
{"time": 1766670055.2814693, "phase": "train", "update": 1478, "total_env_steps": 4729600, "episode_reward": 0.3007115423679352, "value_loss": 0.013472142505149047, "policy_loss": -0.014839034139337789, "dist_entropy": 0.6781186779340108, "actor_grad_norm": 0.16409297287464142, "critic_grad_norm": 0.021232230588793755, "ratio": 1.0002223253250122, "entropy": 0.6781186779340108, "incre_win_rate": 0.7735849056603774, "step": 1478}
{"time": 1766670059.5770767, "phase": "train", "update": 1479, "total_env_steps": 4732800, "episode_reward": 0.2995220720767975, "value_loss": 0.009601952135562896, "policy_loss": -0.015791991926372855, "dist_entropy": 0.6974380652109782, "actor_grad_norm": 0.16120335459709167, "critic_grad_norm": 0.029734566807746887, "ratio": 1.0013056993484497, "entropy": 0.6974380652109782, "incre_win_rate": 0.82, "step": 1479}
{"time": 1766670064.046562, "phase": "train", "update": 1480, "total_env_steps": 4736000, "episode_reward": 0.29845666885375977, "value_loss": 0.010448155800501506, "policy_loss": -0.01598395374513141, "dist_entropy": 0.6979982654253641, "actor_grad_norm": 0.13401435315608978, "critic_grad_norm": 0.021192368119955063, "ratio": 0.9999855756759644, "entropy": 0.6979982654253641, "incre_win_rate": 0.7843137254901961, "step": 1480}
{"time": 1766670068.3615553, "phase": "train", "update": 1481, "total_env_steps": 4739200, "episode_reward": 0.3146331310272217, "value_loss": 0.0049692601586381595, "policy_loss": -0.015271989921417154, "dist_entropy": 0.7035038073857626, "actor_grad_norm": 0.1315169781446457, "critic_grad_norm": 0.04225749149918556, "ratio": 1.0002522468566895, "entropy": 0.7035038073857626, "incre_win_rate": 0.92, "step": 1481}
{"time": 1766670076.0941908, "phase": "eval", "update": 1481, "total_env_steps": 4739200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.531939338235297, "step": 1481}
{"time": 1766670080.5173478, "phase": "train", "update": 1482, "total_env_steps": 4742400, "episode_reward": 0.30236363410949707, "value_loss": 0.009988636709749699, "policy_loss": -0.015482611619200762, "dist_entropy": 0.6861889123916626, "actor_grad_norm": 0.13909322023391724, "critic_grad_norm": 0.021516697481274605, "ratio": 0.9997180700302124, "entropy": 0.6861889123916626, "incre_win_rate": 0.7884615384615384, "step": 1482}
{"time": 1766670085.074562, "phase": "train", "update": 1483, "total_env_steps": 4745600, "episode_reward": 0.3094148337841034, "value_loss": 0.008390218764543534, "policy_loss": -0.015244294809836372, "dist_entropy": 0.6988253633181254, "actor_grad_norm": 0.12832781672477722, "critic_grad_norm": 0.009849777445197105, "ratio": 0.9993237257003784, "entropy": 0.6988253633181254, "incre_win_rate": 0.8490566037735849, "step": 1483}
{"time": 1766670089.364516, "phase": "train", "update": 1484, "total_env_steps": 4748800, "episode_reward": 0.29130133986473083, "value_loss": 0.011671828106045723, "policy_loss": -0.015837546262886804, "dist_entropy": 0.6953554511070251, "actor_grad_norm": 0.13959519565105438, "critic_grad_norm": 0.018861224874854088, "ratio": 0.999064564704895, "entropy": 0.6953554511070251, "incre_win_rate": 0.7708333333333334, "step": 1484}
{"time": 1766670093.6371264, "phase": "train", "update": 1485, "total_env_steps": 4752000, "episode_reward": 0.299380362033844, "value_loss": 0.008884126134216786, "policy_loss": -0.015907639472363875, "dist_entropy": 0.6835124015808105, "actor_grad_norm": 0.15531770884990692, "critic_grad_norm": 0.018175659701228142, "ratio": 0.9993390440940857, "entropy": 0.6835124015808105, "incre_win_rate": 0.8, "step": 1485}
{"time": 1766670097.8698797, "phase": "train", "update": 1486, "total_env_steps": 4755200, "episode_reward": 0.30224189162254333, "value_loss": 0.00958202127367258, "policy_loss": -0.015062702884078287, "dist_entropy": 0.6939489086469014, "actor_grad_norm": 0.1380249261856079, "critic_grad_norm": 0.01837324909865856, "ratio": 0.9999381303787231, "entropy": 0.6939489086469014, "incre_win_rate": 0.8235294117647058, "step": 1486}
{"time": 1766670102.2678134, "phase": "train", "update": 1487, "total_env_steps": 4758400, "episode_reward": 0.3075183629989624, "value_loss": 0.010337125696241855, "policy_loss": -0.016170906732907043, "dist_entropy": 0.6997273524602254, "actor_grad_norm": 0.16636933386325836, "critic_grad_norm": 0.00863141380250454, "ratio": 1.0002284049987793, "entropy": 0.6997273524602254, "incre_win_rate": 0.7962962962962963, "step": 1487}
{"time": 1766670106.6262174, "phase": "train", "update": 1488, "total_env_steps": 4761600, "episode_reward": 0.3174908459186554, "value_loss": 0.010831083605686824, "policy_loss": -0.014468640479588164, "dist_entropy": 0.6968662897745769, "actor_grad_norm": 0.15969912707805634, "critic_grad_norm": 0.011116284877061844, "ratio": 0.9995464086532593, "entropy": 0.6968662897745769, "incre_win_rate": 0.7962962962962963, "step": 1488}
{"time": 1766670110.9323864, "phase": "train", "update": 1489, "total_env_steps": 4764800, "episode_reward": 0.30677008628845215, "value_loss": 0.011135584550599258, "policy_loss": -0.016223182183966855, "dist_entropy": 0.7115145683288574, "actor_grad_norm": 0.1411174237728119, "critic_grad_norm": 0.014521915465593338, "ratio": 0.99833083152771, "entropy": 0.7115145683288574, "incre_win_rate": 0.7692307692307693, "step": 1489}
{"time": 1766670115.1868472, "phase": "train", "update": 1490, "total_env_steps": 4768000, "episode_reward": 0.28824371099472046, "value_loss": 0.01209191232919693, "policy_loss": -0.016682964624999387, "dist_entropy": 0.6987886508305867, "actor_grad_norm": 0.1384706348180771, "critic_grad_norm": 0.060389891266822815, "ratio": 1.0003514289855957, "entropy": 0.6987886508305867, "incre_win_rate": 0.72, "step": 1490}
{"time": 1766670119.4261491, "phase": "train", "update": 1491, "total_env_steps": 4771200, "episode_reward": 0.31198301911354065, "value_loss": 0.008017227767656248, "policy_loss": -0.015193346000760262, "dist_entropy": 0.708338459332784, "actor_grad_norm": 0.13617576658725739, "critic_grad_norm": 0.027982359752058983, "ratio": 0.9998669028282166, "entropy": 0.708338459332784, "incre_win_rate": 0.8461538461538461, "step": 1491}
{"time": 1766670123.6617024, "phase": "train", "update": 1492, "total_env_steps": 4774400, "episode_reward": 0.3101555109024048, "value_loss": 0.00974804957707723, "policy_loss": -0.015519884768619659, "dist_entropy": 0.7053077538808187, "actor_grad_norm": 0.1343747228384018, "critic_grad_norm": 0.017600225284695625, "ratio": 0.9998540282249451, "entropy": 0.7053077538808187, "incre_win_rate": 0.8113207547169812, "step": 1492}
{"time": 1766670127.938131, "phase": "train", "update": 1493, "total_env_steps": 4777600, "episode_reward": 0.30456340312957764, "value_loss": 0.010830617820223173, "policy_loss": -0.01471793942138957, "dist_entropy": 0.7181223432223002, "actor_grad_norm": 0.15066823363304138, "critic_grad_norm": 0.016366247087717056, "ratio": 1.0000152587890625, "entropy": 0.7181223432223002, "incre_win_rate": 0.803921568627451, "step": 1493}
{"time": 1766670132.174888, "phase": "train", "update": 1494, "total_env_steps": 4780800, "episode_reward": 0.3094998896121979, "value_loss": 0.012004426928857963, "policy_loss": -0.01514505322183955, "dist_entropy": 0.69367782274882, "actor_grad_norm": 0.13706345856189728, "critic_grad_norm": 0.024636292830109596, "ratio": 0.99991774559021, "entropy": 0.69367782274882, "incre_win_rate": 0.8627450980392157, "step": 1494}
{"time": 1766670136.6530104, "phase": "train", "update": 1495, "total_env_steps": 4784000, "episode_reward": 0.3035562038421631, "value_loss": 0.008610412757843734, "policy_loss": -0.015990162424380887, "dist_entropy": 0.7141287406285604, "actor_grad_norm": 0.14866191148757935, "critic_grad_norm": 0.024844229221343994, "ratio": 0.9992798566818237, "entropy": 0.7141287406285604, "incre_win_rate": 0.8148148148148148, "step": 1495}
{"time": 1766670140.9586675, "phase": "train", "update": 1496, "total_env_steps": 4787200, "episode_reward": 0.30957111716270447, "value_loss": 0.008181965071707964, "policy_loss": -0.015619797186334002, "dist_entropy": 0.7184498866399129, "actor_grad_norm": 0.13094961643218994, "critic_grad_norm": 0.029346099123358727, "ratio": 0.999934196472168, "entropy": 0.7184498866399129, "incre_win_rate": 0.8571428571428571, "step": 1496}
{"time": 1766670145.227166, "phase": "train", "update": 1497, "total_env_steps": 4790400, "episode_reward": 0.2958333194255829, "value_loss": 0.011108282953500748, "policy_loss": -0.01623471723041424, "dist_entropy": 0.6999558091163636, "actor_grad_norm": 0.141836479306221, "critic_grad_norm": 0.018886080011725426, "ratio": 0.9981678128242493, "entropy": 0.6999558091163636, "incre_win_rate": 0.75, "step": 1497}
{"time": 1766670149.5119493, "phase": "train", "update": 1498, "total_env_steps": 4793600, "episode_reward": 0.30396753549575806, "value_loss": 0.011248071367541948, "policy_loss": -0.015353982967061579, "dist_entropy": 0.6997060775756836, "actor_grad_norm": 0.14158110320568085, "critic_grad_norm": 0.021098392084240913, "ratio": 1.000616431236267, "entropy": 0.6997060775756836, "incre_win_rate": 0.7547169811320755, "step": 1498}
{"time": 1766670153.703898, "phase": "train", "update": 1499, "total_env_steps": 4796800, "episode_reward": 0.31197381019592285, "value_loss": 0.010118480026721954, "policy_loss": -0.015015779418669694, "dist_entropy": 0.7096781889597575, "actor_grad_norm": 0.12620674073696136, "critic_grad_norm": 0.01781819760799408, "ratio": 1.000544786453247, "entropy": 0.7096781889597575, "incre_win_rate": 0.8235294117647058, "step": 1499}
{"time": 1766670157.987704, "phase": "train", "update": 1500, "total_env_steps": 4800000, "episode_reward": 0.30797797441482544, "value_loss": 0.015603779815137386, "policy_loss": -0.016931938837921715, "dist_entropy": 0.6979837616284689, "actor_grad_norm": 0.17085039615631104, "critic_grad_norm": 0.10362131148576736, "ratio": 0.9987241625785828, "entropy": 0.6979837616284689, "incre_win_rate": 0.6964285714285714, "step": 1500}
