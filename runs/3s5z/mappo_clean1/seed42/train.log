{"time": 1767077217.1966078, "phase": "train", "update": 1, "total_env_steps": 3200, "episode_reward": 0.08689052611589432, "value_loss": 0.5859985947608948, "policy_loss": -0.0015822266007603503, "dist_entropy": 2.034451627731323, "actor_grad_norm": 0.06768493354320526, "critic_grad_norm": 2.279573678970337, "ratio": 1.0000567436218262, "entropy": 2.034451627731323, "incre_win_rate": 0.0, "step": 1}
{"time": 1767077232.2125146, "phase": "eval", "update": 1, "total_env_steps": 3200, "eval_win_rate": 0.0, "eval_episode_reward": 9.117653145695357, "step": 1}
{"time": 1767077237.3589268, "phase": "train", "update": 2, "total_env_steps": 6400, "episode_reward": 0.09170529246330261, "value_loss": 0.7029145359992981, "policy_loss": -0.000948411038494612, "dist_entropy": 2.0512969493865967, "actor_grad_norm": 0.061184775084257126, "critic_grad_norm": 2.3579657077789307, "ratio": 1.0000356435775757, "entropy": 2.0512969493865967, "incre_win_rate": 0.0, "step": 2}
{"time": 1767077242.0558894, "phase": "train", "update": 3, "total_env_steps": 9600, "episode_reward": 0.08767383545637131, "value_loss": 0.22274129390716552, "policy_loss": -0.0010440846971583539, "dist_entropy": 2.044651222229004, "actor_grad_norm": 0.06675878912210464, "critic_grad_norm": 1.8618786334991455, "ratio": 1.0001001358032227, "entropy": 2.044651222229004, "incre_win_rate": 0.0, "step": 3}
{"time": 1767077246.6573083, "phase": "train", "update": 4, "total_env_steps": 12800, "episode_reward": 0.09514952450990677, "value_loss": 0.12910302281379699, "policy_loss": -0.0008950579971923389, "dist_entropy": 2.0336923122406008, "actor_grad_norm": 0.06508388370275497, "critic_grad_norm": 0.49874114990234375, "ratio": 0.9997079968452454, "entropy": 2.0336923122406008, "incre_win_rate": 0.0, "step": 4}
{"time": 1767077251.2936006, "phase": "train", "update": 5, "total_env_steps": 16000, "episode_reward": 0.09156766533851624, "value_loss": 0.10976138561964036, "policy_loss": -0.000649283464871786, "dist_entropy": 2.002342462539673, "actor_grad_norm": 0.04842847213149071, "critic_grad_norm": 0.5382742285728455, "ratio": 0.9999329447746277, "entropy": 2.002342462539673, "incre_win_rate": 0.0, "step": 5}
{"time": 1767077255.9278002, "phase": "train", "update": 6, "total_env_steps": 19200, "episode_reward": 0.09203848987817764, "value_loss": 0.10408851355314255, "policy_loss": -0.0008951612627810413, "dist_entropy": 1.964546513557434, "actor_grad_norm": 0.05956682190299034, "critic_grad_norm": 0.3561236262321472, "ratio": 0.9999796152114868, "entropy": 1.964546513557434, "incre_win_rate": 0.0, "step": 6}
{"time": 1767077261.6695876, "phase": "train", "update": 7, "total_env_steps": 22400, "episode_reward": 0.08697588741779327, "value_loss": 0.09482697248458863, "policy_loss": -0.0009495718814667598, "dist_entropy": 1.9126219511032105, "actor_grad_norm": 0.08491706103086472, "critic_grad_norm": 0.18534833192825317, "ratio": 0.9997671246528625, "entropy": 1.9126219511032105, "incre_win_rate": 0.0, "step": 7}
{"time": 1767077266.6533804, "phase": "train", "update": 8, "total_env_steps": 25600, "episode_reward": 0.10084851086139679, "value_loss": 0.08229694962501526, "policy_loss": -0.0013958866569373286, "dist_entropy": 1.945905613899231, "actor_grad_norm": 0.0977436751127243, "critic_grad_norm": 0.5412167906761169, "ratio": 1.000137209892273, "entropy": 1.945905613899231, "incre_win_rate": 0.0, "step": 8}
{"time": 1767077271.5703318, "phase": "train", "update": 9, "total_env_steps": 28800, "episode_reward": 0.10502069443464279, "value_loss": 0.07904230803251266, "policy_loss": -0.0014090477661953926, "dist_entropy": 1.94859778881073, "actor_grad_norm": 0.0750659629702568, "critic_grad_norm": 0.3830399513244629, "ratio": 1.0001779794692993, "entropy": 1.94859778881073, "incre_win_rate": 0.0, "step": 9}
{"time": 1767077276.4151874, "phase": "train", "update": 10, "total_env_steps": 32000, "episode_reward": 0.11260969191789627, "value_loss": 0.08558799177408219, "policy_loss": -0.0014978982812177133, "dist_entropy": 1.9578898906707765, "actor_grad_norm": 0.10461027920246124, "critic_grad_norm": 0.218854621052742, "ratio": 0.9999720454216003, "entropy": 1.9578898906707765, "incre_win_rate": 0.0, "step": 10}
{"time": 1767077281.350909, "phase": "train", "update": 11, "total_env_steps": 35200, "episode_reward": 0.1292591094970703, "value_loss": 0.06886505484580993, "policy_loss": -0.0013575828146779934, "dist_entropy": 1.9660871267318725, "actor_grad_norm": 0.06558860093355179, "critic_grad_norm": 0.2741692364215851, "ratio": 1.0004196166992188, "entropy": 1.9660871267318725, "incre_win_rate": 0.0, "step": 11}
{"time": 1767077286.2524362, "phase": "train", "update": 12, "total_env_steps": 38400, "episode_reward": 0.12184344232082367, "value_loss": 0.06491063311696052, "policy_loss": -0.0011764953570106763, "dist_entropy": 1.926091241836548, "actor_grad_norm": 0.0744675025343895, "critic_grad_norm": 0.25764667987823486, "ratio": 0.9999229311943054, "entropy": 1.926091241836548, "incre_win_rate": 0.0, "step": 12}
{"time": 1767077291.67072, "phase": "train", "update": 13, "total_env_steps": 41600, "episode_reward": 0.12923014163970947, "value_loss": 0.059084993600845334, "policy_loss": -0.0005947681144117922, "dist_entropy": 1.892327070236206, "actor_grad_norm": 0.07010103762149811, "critic_grad_norm": 0.17095158994197845, "ratio": 1.000374436378479, "entropy": 1.892327070236206, "incre_win_rate": 0.0, "step": 13}
{"time": 1767077297.949307, "phase": "train", "update": 14, "total_env_steps": 44800, "episode_reward": 0.11784819513559341, "value_loss": 0.06035921648144722, "policy_loss": -0.00099020175978195, "dist_entropy": 1.8476518630981444, "actor_grad_norm": 0.06741326302289963, "critic_grad_norm": 0.14566151797771454, "ratio": 0.9999334216117859, "entropy": 1.8476518630981444, "incre_win_rate": 0.0, "step": 14}
{"time": 1767077303.136068, "phase": "train", "update": 15, "total_env_steps": 48000, "episode_reward": 0.13349752128124237, "value_loss": 0.05971535891294479, "policy_loss": -0.001236641818207529, "dist_entropy": 1.8110825300216675, "actor_grad_norm": 0.07244395464658737, "critic_grad_norm": 0.1900627762079239, "ratio": 1.0001472234725952, "entropy": 1.8110825300216675, "incre_win_rate": 0.0, "step": 15}
{"time": 1767077308.3988461, "phase": "train", "update": 16, "total_env_steps": 51200, "episode_reward": 0.12941277027130127, "value_loss": 0.05683498829603195, "policy_loss": -0.001219583831367288, "dist_entropy": 1.757695698738098, "actor_grad_norm": 0.06821896880865097, "critic_grad_norm": 0.1419561505317688, "ratio": 1.00027596950531, "entropy": 1.757695698738098, "incre_win_rate": 0.0, "step": 16}
{"time": 1767077313.8690658, "phase": "train", "update": 17, "total_env_steps": 54400, "episode_reward": 0.13333143293857574, "value_loss": 0.05851663649082184, "policy_loss": -0.0017352236773765738, "dist_entropy": 1.7303668975830078, "actor_grad_norm": 0.08417735993862152, "critic_grad_norm": 0.08158600330352783, "ratio": 0.9996511340141296, "entropy": 1.7303668975830078, "incre_win_rate": 0.0, "step": 17}
{"time": 1767077319.3499296, "phase": "train", "update": 18, "total_env_steps": 57600, "episode_reward": 0.13189518451690674, "value_loss": 0.05238357707858086, "policy_loss": -0.000857737332603925, "dist_entropy": 1.69768545627594, "actor_grad_norm": 0.05282037332653999, "critic_grad_norm": 0.12733592092990875, "ratio": 1.0000609159469604, "entropy": 1.69768545627594, "incre_win_rate": 0.0, "step": 18}
{"time": 1767077324.8733802, "phase": "train", "update": 19, "total_env_steps": 60800, "episode_reward": 0.14802514016628265, "value_loss": 0.05541564449667931, "policy_loss": -0.001241992241860146, "dist_entropy": 1.7133530616760253, "actor_grad_norm": 0.08449160307645798, "critic_grad_norm": 0.09975282102823257, "ratio": 0.9999357461929321, "entropy": 1.7133530616760253, "incre_win_rate": 0.0, "step": 19}
{"time": 1767077330.2956157, "phase": "train", "update": 20, "total_env_steps": 64000, "episode_reward": 0.14969474077224731, "value_loss": 0.04406572282314301, "policy_loss": -0.0008923620849031977, "dist_entropy": 1.7039658546447753, "actor_grad_norm": 0.05384807661175728, "critic_grad_norm": 0.13026092946529388, "ratio": 1.0001153945922852, "entropy": 1.7039658546447753, "incre_win_rate": 0.0, "step": 20}
{"time": 1767077336.1106715, "phase": "train", "update": 21, "total_env_steps": 67200, "episode_reward": 0.14346958696842194, "value_loss": 0.050141606479883194, "policy_loss": -0.0008807404561999022, "dist_entropy": 1.684266495704651, "actor_grad_norm": 0.06273194402456284, "critic_grad_norm": 0.09227516502141953, "ratio": 1.0000567436218262, "entropy": 1.684266495704651, "incre_win_rate": 0.0, "step": 21}
{"time": 1767077347.0820727, "phase": "eval", "update": 21, "total_env_steps": 67200, "eval_win_rate": 0.0, "eval_episode_reward": 10.132191639072845, "step": 21}
{"time": 1767077352.212401, "phase": "train", "update": 22, "total_env_steps": 70400, "episode_reward": 0.1393217146396637, "value_loss": 0.042786731570959094, "policy_loss": -0.0011349332495433906, "dist_entropy": 1.6726699829101563, "actor_grad_norm": 0.06036914139986038, "critic_grad_norm": 0.13373877108097076, "ratio": 1.0001916885375977, "entropy": 1.6726699829101563, "incre_win_rate": 0.0, "step": 22}
{"time": 1767077357.3002944, "phase": "train", "update": 23, "total_env_steps": 73600, "episode_reward": 0.14409199357032776, "value_loss": 0.03904886543750763, "policy_loss": -0.0013645636966522546, "dist_entropy": 1.6287554502487183, "actor_grad_norm": 0.08025863766670227, "critic_grad_norm": 0.10454247146844864, "ratio": 0.9999575018882751, "entropy": 1.6287554502487183, "incre_win_rate": 0.0, "step": 23}
{"time": 1767077362.3146718, "phase": "train", "update": 24, "total_env_steps": 76800, "episode_reward": 0.1444132924079895, "value_loss": 0.04069153964519501, "policy_loss": -0.0016346979281908424, "dist_entropy": 1.5870047807693481, "actor_grad_norm": 0.07212771475315094, "critic_grad_norm": 0.1769169569015503, "ratio": 0.9998675584793091, "entropy": 1.5870047807693481, "incre_win_rate": 0.0, "step": 24}
{"time": 1767077367.447099, "phase": "train", "update": 25, "total_env_steps": 80000, "episode_reward": 0.14855650067329407, "value_loss": 0.037036805599927905, "policy_loss": -0.0012147872178845276, "dist_entropy": 1.5373138189315796, "actor_grad_norm": 0.07014263421297073, "critic_grad_norm": 0.10338931530714035, "ratio": 0.9996391534805298, "entropy": 1.5373138189315796, "incre_win_rate": 0.0, "step": 25}
{"time": 1767077372.6283035, "phase": "train", "update": 26, "total_env_steps": 83200, "episode_reward": 0.1507207155227661, "value_loss": 0.03894000947475433, "policy_loss": -0.0006858679605551643, "dist_entropy": 1.5326319456100463, "actor_grad_norm": 0.05803028866648674, "critic_grad_norm": 0.09694010019302368, "ratio": 0.99968022108078, "entropy": 1.5326319456100463, "incre_win_rate": 0.0, "step": 26}
{"time": 1767077378.0461743, "phase": "train", "update": 27, "total_env_steps": 86400, "episode_reward": 0.1465599238872528, "value_loss": 0.03715021684765816, "policy_loss": -0.0008958492973501819, "dist_entropy": 1.524470591545105, "actor_grad_norm": 0.04901183024048805, "critic_grad_norm": 0.11799796670675278, "ratio": 0.9997803568840027, "entropy": 1.524470591545105, "incre_win_rate": 0.0, "step": 27}
{"time": 1767077383.5947928, "phase": "train", "update": 28, "total_env_steps": 89600, "episode_reward": 0.14908941090106964, "value_loss": 0.03587699979543686, "policy_loss": -0.0008885990997692161, "dist_entropy": 1.4951932907104493, "actor_grad_norm": 0.09258081018924713, "critic_grad_norm": 0.14528480172157288, "ratio": 1.000092625617981, "entropy": 1.4951932907104493, "incre_win_rate": 0.0, "step": 28}
{"time": 1767077388.725124, "phase": "train", "update": 29, "total_env_steps": 92800, "episode_reward": 0.14771834015846252, "value_loss": 0.03804003521800041, "policy_loss": -0.000797953836445231, "dist_entropy": 1.492165994644165, "actor_grad_norm": 0.09274617582559586, "critic_grad_norm": 0.07146529853343964, "ratio": 1.000013828277588, "entropy": 1.492165994644165, "incre_win_rate": 0.0, "step": 29}
{"time": 1767077393.9053833, "phase": "train", "update": 30, "total_env_steps": 96000, "episode_reward": 0.1550760567188263, "value_loss": 0.039219778031110764, "policy_loss": -0.0011949413378005147, "dist_entropy": 1.4908986568450928, "actor_grad_norm": 0.09733772277832031, "critic_grad_norm": 0.11066827923059464, "ratio": 0.9998565912246704, "entropy": 1.4908986568450928, "incre_win_rate": 0.0, "step": 30}
{"time": 1767077399.1599526, "phase": "train", "update": 31, "total_env_steps": 99200, "episode_reward": 0.1440144032239914, "value_loss": 0.036475295573472975, "policy_loss": -0.00115885714490771, "dist_entropy": 1.4588855028152465, "actor_grad_norm": 0.08169988542795181, "critic_grad_norm": 0.06998106092214584, "ratio": 0.9994921684265137, "entropy": 1.4588855028152465, "incre_win_rate": 0.0, "step": 31}
{"time": 1767077404.4032896, "phase": "train", "update": 32, "total_env_steps": 102400, "episode_reward": 0.15087644755840302, "value_loss": 0.03998527601361275, "policy_loss": -0.0012462177173579558, "dist_entropy": 1.4384419202804566, "actor_grad_norm": 0.07918331772089005, "critic_grad_norm": 0.07330647110939026, "ratio": 0.9994912147521973, "entropy": 1.4384419202804566, "incre_win_rate": 0.0, "step": 32}
{"time": 1767077409.344804, "phase": "train", "update": 33, "total_env_steps": 105600, "episode_reward": 0.14719784259796143, "value_loss": 0.03535367026925087, "policy_loss": -0.0006614422323657609, "dist_entropy": 1.4583508253097535, "actor_grad_norm": 0.07420630007982254, "critic_grad_norm": 0.09987252950668335, "ratio": 1.000167965888977, "entropy": 1.4583508253097535, "incre_win_rate": 0.0, "step": 33}
{"time": 1767077414.332891, "phase": "train", "update": 34, "total_env_steps": 108800, "episode_reward": 0.14924100041389465, "value_loss": 0.03993366882205009, "policy_loss": -0.0009783224174006121, "dist_entropy": 1.4481986999511718, "actor_grad_norm": 0.0813993439078331, "critic_grad_norm": 0.21346250176429749, "ratio": 1.0002448558807373, "entropy": 1.4481986999511718, "incre_win_rate": 0.0, "step": 34}
{"time": 1767077419.521284, "phase": "train", "update": 35, "total_env_steps": 112000, "episode_reward": 0.1458728313446045, "value_loss": 0.03861953169107437, "policy_loss": -0.0010636700480309846, "dist_entropy": 1.473409938812256, "actor_grad_norm": 0.09071183949708939, "critic_grad_norm": 0.22242248058319092, "ratio": 0.9999507069587708, "entropy": 1.473409938812256, "incre_win_rate": 0.0, "step": 35}
{"time": 1767077424.525742, "phase": "train", "update": 36, "total_env_steps": 115200, "episode_reward": 0.15421409904956818, "value_loss": 0.0363906241953373, "policy_loss": -0.000813130986779842, "dist_entropy": 1.4842442274093628, "actor_grad_norm": 0.10558757930994034, "critic_grad_norm": 0.3066690266132355, "ratio": 0.9994986653327942, "entropy": 1.4842442274093628, "incre_win_rate": 0.0, "step": 36}
{"time": 1767077429.5363257, "phase": "train", "update": 37, "total_env_steps": 118400, "episode_reward": 0.15751448273658752, "value_loss": 0.034207599610090254, "policy_loss": -0.0005242129425326425, "dist_entropy": 1.5084780216217042, "actor_grad_norm": 0.09808825701475143, "critic_grad_norm": 0.15002566576004028, "ratio": 0.9999104738235474, "entropy": 1.5084780216217042, "incre_win_rate": 0.0, "step": 37}
{"time": 1767077434.5232964, "phase": "train", "update": 38, "total_env_steps": 121600, "episode_reward": 0.15695208311080933, "value_loss": 0.036879179626703264, "policy_loss": -0.000679508860749678, "dist_entropy": 1.5219695806503295, "actor_grad_norm": 0.09406287223100662, "critic_grad_norm": 0.23688066005706787, "ratio": 1.0000269412994385, "entropy": 1.5219695806503295, "incre_win_rate": 0.0, "step": 38}
{"time": 1767077439.5196853, "phase": "train", "update": 39, "total_env_steps": 124800, "episode_reward": 0.1563374400138855, "value_loss": 0.03246843591332436, "policy_loss": -0.0011709166921022086, "dist_entropy": 1.5235776424407959, "actor_grad_norm": 0.09700832515954971, "critic_grad_norm": 0.11078405380249023, "ratio": 0.9996412396430969, "entropy": 1.5235776424407959, "incre_win_rate": 0.0, "step": 39}
{"time": 1767077444.5212727, "phase": "train", "update": 40, "total_env_steps": 128000, "episode_reward": 0.1507434844970703, "value_loss": 0.03130328878760338, "policy_loss": -0.0010955793292802523, "dist_entropy": 1.4883142471313477, "actor_grad_norm": 0.10571327060461044, "critic_grad_norm": 0.07406061887741089, "ratio": 1.0002825260162354, "entropy": 1.4883142471313477, "incre_win_rate": 0.0, "step": 40}
{"time": 1767077449.5358815, "phase": "train", "update": 41, "total_env_steps": 131200, "episode_reward": 0.15915045142173767, "value_loss": 0.029709823429584503, "policy_loss": -0.0007630594393587487, "dist_entropy": 1.4718023777008056, "actor_grad_norm": 0.10978584736585617, "critic_grad_norm": 0.055329035967588425, "ratio": 1.000083565711975, "entropy": 1.4718023777008056, "incre_win_rate": 0.0, "step": 41}
{"time": 1767077458.3896937, "phase": "eval", "update": 41, "total_env_steps": 131200, "eval_win_rate": 0.0, "eval_episode_reward": 9.681446605960264, "step": 41}
{"time": 1767077463.367645, "phase": "train", "update": 42, "total_env_steps": 134400, "episode_reward": 0.15598508715629578, "value_loss": 0.031168558821082114, "policy_loss": -0.0007661857718197496, "dist_entropy": 1.475250482559204, "actor_grad_norm": 0.10878866910934448, "critic_grad_norm": 0.18774549663066864, "ratio": 1.0001429319381714, "entropy": 1.475250482559204, "incre_win_rate": 0.0, "step": 42}
{"time": 1767077468.3949714, "phase": "train", "update": 43, "total_env_steps": 137600, "episode_reward": 0.1586211621761322, "value_loss": 0.026080787181854248, "policy_loss": -0.0008061387060447345, "dist_entropy": 1.4800816297531127, "actor_grad_norm": 0.09001227468252182, "critic_grad_norm": 0.12103567272424698, "ratio": 1.0000112056732178, "entropy": 1.4800816297531127, "incre_win_rate": 0.0, "step": 43}
{"time": 1767077473.738901, "phase": "train", "update": 44, "total_env_steps": 140800, "episode_reward": 0.15089869499206543, "value_loss": 0.027178621292114256, "policy_loss": -0.0009634439009097662, "dist_entropy": 1.4545793533325195, "actor_grad_norm": 0.1104472279548645, "critic_grad_norm": 0.08393169194459915, "ratio": 1.0004154443740845, "entropy": 1.4545793533325195, "incre_win_rate": 0.0, "step": 44}
{"time": 1767077478.304065, "phase": "train", "update": 45, "total_env_steps": 144000, "episode_reward": 0.1502307504415512, "value_loss": 0.031217562779784203, "policy_loss": -0.0010118093290857999, "dist_entropy": 1.430468487739563, "actor_grad_norm": 0.11340983957052231, "critic_grad_norm": 0.06263168901205063, "ratio": 1.000046968460083, "entropy": 1.430468487739563, "incre_win_rate": 0.0, "step": 45}
{"time": 1767077482.9729743, "phase": "train", "update": 46, "total_env_steps": 147200, "episode_reward": 0.15747517347335815, "value_loss": 0.029189320281147957, "policy_loss": -0.0008656757131351612, "dist_entropy": 1.4375005960464478, "actor_grad_norm": 0.08564834296703339, "critic_grad_norm": 0.06524590402841568, "ratio": 0.9996242523193359, "entropy": 1.4375005960464478, "incre_win_rate": 0.0, "step": 46}
{"time": 1767077487.6734567, "phase": "train", "update": 47, "total_env_steps": 150400, "episode_reward": 0.15493221580982208, "value_loss": 0.03425256162881851, "policy_loss": -0.0006864506543513115, "dist_entropy": 1.4557756662368775, "actor_grad_norm": 0.08167319744825363, "critic_grad_norm": 0.12510856986045837, "ratio": 1.0001475811004639, "entropy": 1.4557756662368775, "incre_win_rate": 0.0, "step": 47}
{"time": 1767077492.3635938, "phase": "train", "update": 48, "total_env_steps": 153600, "episode_reward": 0.15013659000396729, "value_loss": 0.03126373142004013, "policy_loss": -0.0008068900525096013, "dist_entropy": 1.4737815618515016, "actor_grad_norm": 0.11416745185852051, "critic_grad_norm": 0.13235382735729218, "ratio": 1.0001100301742554, "entropy": 1.4737815618515016, "incre_win_rate": 0.0, "step": 48}
{"time": 1767077497.1987784, "phase": "train", "update": 49, "total_env_steps": 156800, "episode_reward": 0.16244103014469147, "value_loss": 0.0259922344237566, "policy_loss": -0.0010725665408987338, "dist_entropy": 1.5097159147262573, "actor_grad_norm": 0.10426528751850128, "critic_grad_norm": 0.0906546339392662, "ratio": 1.0000739097595215, "entropy": 1.5097159147262573, "incre_win_rate": 0.0, "step": 49}
{"time": 1767077501.9855206, "phase": "train", "update": 50, "total_env_steps": 160000, "episode_reward": 0.16108858585357666, "value_loss": 0.030337533727288247, "policy_loss": -0.0011185826784801734, "dist_entropy": 1.4989020824432373, "actor_grad_norm": 0.12679947912693024, "critic_grad_norm": 0.056640710681676865, "ratio": 1.0000919103622437, "entropy": 1.4989020824432373, "incre_win_rate": 0.0, "step": 50}
{"time": 1767077506.694235, "phase": "train", "update": 51, "total_env_steps": 163200, "episode_reward": 0.15799719095230103, "value_loss": 0.029862997680902482, "policy_loss": -0.001133730842420988, "dist_entropy": 1.4826478004455566, "actor_grad_norm": 0.1167532205581665, "critic_grad_norm": 0.1751975268125534, "ratio": 0.9998774528503418, "entropy": 1.4826478004455566, "incre_win_rate": 0.0, "step": 51}
{"time": 1767077511.3411028, "phase": "train", "update": 52, "total_env_steps": 166400, "episode_reward": 0.15595456957817078, "value_loss": 0.03439745455980301, "policy_loss": -0.0008007644969836747, "dist_entropy": 1.497136664390564, "actor_grad_norm": 0.06899110972881317, "critic_grad_norm": 0.14047108590602875, "ratio": 1.0000417232513428, "entropy": 1.497136664390564, "incre_win_rate": 0.0, "step": 52}
{"time": 1767077516.098501, "phase": "train", "update": 53, "total_env_steps": 169600, "episode_reward": 0.16271524131298065, "value_loss": 0.027286817133426667, "policy_loss": -0.00076117798340829, "dist_entropy": 1.4968161582946777, "actor_grad_norm": 0.12021726369857788, "critic_grad_norm": 0.07382921129465103, "ratio": 0.9999876022338867, "entropy": 1.4968161582946777, "incre_win_rate": 0.0, "step": 53}
{"time": 1767077520.8811572, "phase": "train", "update": 54, "total_env_steps": 172800, "episode_reward": 0.15985462069511414, "value_loss": 0.027683895081281662, "policy_loss": -0.0007829006353858858, "dist_entropy": 1.4950252532958985, "actor_grad_norm": 0.11696453392505646, "critic_grad_norm": 0.06635242700576782, "ratio": 0.999890148639679, "entropy": 1.4950252532958985, "incre_win_rate": 0.0, "step": 54}
{"time": 1767077526.2315812, "phase": "train", "update": 55, "total_env_steps": 176000, "episode_reward": 0.166242778301239, "value_loss": 0.027183855324983595, "policy_loss": -0.0011077923001721502, "dist_entropy": 1.5371479034423827, "actor_grad_norm": 0.08853992074728012, "critic_grad_norm": 0.05736125260591507, "ratio": 0.9997227787971497, "entropy": 1.5371479034423827, "incre_win_rate": 0.0, "step": 55}
{"time": 1767077531.5529103, "phase": "train", "update": 56, "total_env_steps": 179200, "episode_reward": 0.16100528836250305, "value_loss": 0.029823965579271316, "policy_loss": -0.0011526057033616865, "dist_entropy": 1.496943187713623, "actor_grad_norm": 0.09841875731945038, "critic_grad_norm": 0.06267346441745758, "ratio": 1.0001720190048218, "entropy": 1.496943187713623, "incre_win_rate": 0.0, "step": 56}
{"time": 1767077536.9374137, "phase": "train", "update": 57, "total_env_steps": 182400, "episode_reward": 0.16023799777030945, "value_loss": 0.02383898161351681, "policy_loss": -0.0011579413020538, "dist_entropy": 1.4851086616516114, "actor_grad_norm": 0.07343651354312897, "critic_grad_norm": 0.12584589421749115, "ratio": 1.000247836112976, "entropy": 1.4851086616516114, "incre_win_rate": 0.0, "step": 57}
{"time": 1767077542.0222666, "phase": "train", "update": 58, "total_env_steps": 185600, "episode_reward": 0.16953538358211517, "value_loss": 0.026307772472500802, "policy_loss": -0.0011895877558188773, "dist_entropy": 1.4487598419189454, "actor_grad_norm": 0.1065068170428276, "critic_grad_norm": 0.11803477257490158, "ratio": 1.000238060951233, "entropy": 1.4487598419189454, "incre_win_rate": 0.0, "step": 58}
{"time": 1767077547.2870457, "phase": "train", "update": 59, "total_env_steps": 188800, "episode_reward": 0.14343492686748505, "value_loss": 0.02963896170258522, "policy_loss": -0.0013710103996700696, "dist_entropy": 1.4306751489639282, "actor_grad_norm": 0.17246727645397186, "critic_grad_norm": 0.08356068283319473, "ratio": 1.0002329349517822, "entropy": 1.4306751489639282, "incre_win_rate": 0.0, "step": 59}
{"time": 1767077552.5165608, "phase": "train", "update": 60, "total_env_steps": 192000, "episode_reward": 0.1624736189842224, "value_loss": 0.02651458904147148, "policy_loss": -0.00044885293340293233, "dist_entropy": 1.4429950714111328, "actor_grad_norm": 0.09339231997728348, "critic_grad_norm": 0.08119253069162369, "ratio": 1.0003578662872314, "entropy": 1.4429950714111328, "incre_win_rate": 0.0, "step": 60}
{"time": 1767077557.5392122, "phase": "train", "update": 61, "total_env_steps": 195200, "episode_reward": 0.15255847573280334, "value_loss": 0.02615618221461773, "policy_loss": -0.0008374663688865524, "dist_entropy": 1.4389426946640014, "actor_grad_norm": 0.1271321177482605, "critic_grad_norm": 0.12905558943748474, "ratio": 0.9998553395271301, "entropy": 1.4389426946640014, "incre_win_rate": 0.0, "step": 61}
{"time": 1767077566.7383604, "phase": "eval", "update": 61, "total_env_steps": 195200, "eval_win_rate": 0.0, "eval_episode_reward": 9.90857822847682, "step": 61}
{"time": 1767077571.8616958, "phase": "train", "update": 62, "total_env_steps": 198400, "episode_reward": 0.15383380651474, "value_loss": 0.02808355651795864, "policy_loss": -0.0010314008365302386, "dist_entropy": 1.4176341056823731, "actor_grad_norm": 0.12888212502002716, "critic_grad_norm": 0.15637610852718353, "ratio": 0.9999284148216248, "entropy": 1.4176341056823731, "incre_win_rate": 0.0, "step": 62}
{"time": 1767077576.9709928, "phase": "train", "update": 63, "total_env_steps": 201600, "episode_reward": 0.15901336073875427, "value_loss": 0.03141982480883598, "policy_loss": -0.0008424373528411522, "dist_entropy": 1.4157060146331788, "actor_grad_norm": 0.10974510759115219, "critic_grad_norm": 0.16714495420455933, "ratio": 1.0001939535140991, "entropy": 1.4157060146331788, "incre_win_rate": 0.0, "step": 63}
{"time": 1767077582.187119, "phase": "train", "update": 64, "total_env_steps": 204800, "episode_reward": 0.16212128102779388, "value_loss": 0.02912633940577507, "policy_loss": -0.0012070260698921586, "dist_entropy": 1.4037872791290282, "actor_grad_norm": 0.07243770360946655, "critic_grad_norm": 0.18856219947338104, "ratio": 1.0003780126571655, "entropy": 1.4037872791290282, "incre_win_rate": 0.0, "step": 64}
{"time": 1767077587.2379992, "phase": "train", "update": 65, "total_env_steps": 208000, "episode_reward": 0.15860667824745178, "value_loss": 0.03184093274176121, "policy_loss": -0.0012947338496022808, "dist_entropy": 1.354284906387329, "actor_grad_norm": 0.11626414209604263, "critic_grad_norm": 0.15826453268527985, "ratio": 0.999821662902832, "entropy": 1.354284906387329, "incre_win_rate": 0.0, "step": 65}
{"time": 1767077592.2905245, "phase": "train", "update": 66, "total_env_steps": 211200, "episode_reward": 0.1706586480140686, "value_loss": 0.033064113557338716, "policy_loss": -0.0009083086712496247, "dist_entropy": 1.3565362215042114, "actor_grad_norm": 0.1183987632393837, "critic_grad_norm": 0.09058848023414612, "ratio": 1.0002068281173706, "entropy": 1.3565362215042114, "incre_win_rate": 0.0, "step": 66}
{"time": 1767077597.1890247, "phase": "train", "update": 67, "total_env_steps": 214400, "episode_reward": 0.17026491463184357, "value_loss": 0.03077092096209526, "policy_loss": -0.0006190635413660273, "dist_entropy": 1.3625807762145996, "actor_grad_norm": 0.11356893926858902, "critic_grad_norm": 0.13995973765850067, "ratio": 0.9998119473457336, "entropy": 1.3625807762145996, "incre_win_rate": 0.0, "step": 67}
{"time": 1767077602.052422, "phase": "train", "update": 68, "total_env_steps": 217600, "episode_reward": 0.169351726770401, "value_loss": 0.03311421498656273, "policy_loss": -0.0007444281465730284, "dist_entropy": 1.3549427032470702, "actor_grad_norm": 0.07585542649030685, "critic_grad_norm": 0.12365692853927612, "ratio": 0.9999421238899231, "entropy": 1.3549427032470702, "incre_win_rate": 0.0, "step": 68}
{"time": 1767077606.9212918, "phase": "train", "update": 69, "total_env_steps": 220800, "episode_reward": 0.15620914101600647, "value_loss": 0.030329736322164534, "policy_loss": -0.001363300857529204, "dist_entropy": 1.3450060844421388, "actor_grad_norm": 0.1261264532804489, "critic_grad_norm": 0.08790305256843567, "ratio": 0.9999923706054688, "entropy": 1.3450060844421388, "incre_win_rate": 0.0, "step": 69}
{"time": 1767077611.692911, "phase": "train", "update": 70, "total_env_steps": 224000, "episode_reward": 0.15332472324371338, "value_loss": 0.026316000521183013, "policy_loss": -0.0004812108849668206, "dist_entropy": 1.3885644197463989, "actor_grad_norm": 0.1897108405828476, "critic_grad_norm": 0.07992186397314072, "ratio": 0.9999319314956665, "entropy": 1.3885644197463989, "incre_win_rate": 0.0, "step": 70}
{"time": 1767077616.6595926, "phase": "train", "update": 71, "total_env_steps": 227200, "episode_reward": 0.1660958230495453, "value_loss": 0.028422799333930014, "policy_loss": -0.0007108085762368432, "dist_entropy": 1.41035737991333, "actor_grad_norm": 0.08797139674425125, "critic_grad_norm": 0.06883970648050308, "ratio": 0.9999944567680359, "entropy": 1.41035737991333, "incre_win_rate": 0.0, "step": 71}
{"time": 1767077621.9829333, "phase": "train", "update": 72, "total_env_steps": 230400, "episode_reward": 0.17851459980010986, "value_loss": 0.028160234540700914, "policy_loss": -0.0008285782357553729, "dist_entropy": 1.413352084159851, "actor_grad_norm": 0.10608235746622086, "critic_grad_norm": 0.09336277097463608, "ratio": 1.000012755393982, "entropy": 1.413352084159851, "incre_win_rate": 0.0, "step": 72}
{"time": 1767077627.119621, "phase": "train", "update": 73, "total_env_steps": 233600, "episode_reward": 0.16573727130889893, "value_loss": 0.030711373686790465, "policy_loss": -0.0013701019888216592, "dist_entropy": 1.413091254234314, "actor_grad_norm": 0.14333997666835785, "critic_grad_norm": 0.10832365602254868, "ratio": 1.0003845691680908, "entropy": 1.413091254234314, "incre_win_rate": 0.0, "step": 73}
{"time": 1767077632.184019, "phase": "train", "update": 74, "total_env_steps": 236800, "episode_reward": 0.16320623457431793, "value_loss": 0.031635763496160506, "policy_loss": -0.0006891398112571778, "dist_entropy": 1.4085214138031006, "actor_grad_norm": 0.07345106452703476, "critic_grad_norm": 0.0776933804154396, "ratio": 0.9998372197151184, "entropy": 1.4085214138031006, "incre_win_rate": 0.0, "step": 74}
{"time": 1767077637.3278213, "phase": "train", "update": 75, "total_env_steps": 240000, "episode_reward": 0.16926738619804382, "value_loss": 0.028298569470644, "policy_loss": -0.001185350826577114, "dist_entropy": 1.4177490711212157, "actor_grad_norm": 0.0862918272614479, "critic_grad_norm": 0.0769282802939415, "ratio": 0.999915599822998, "entropy": 1.4177490711212157, "incre_win_rate": 0.0, "step": 75}
{"time": 1767077642.5096657, "phase": "train", "update": 76, "total_env_steps": 243200, "episode_reward": 0.17859739065170288, "value_loss": 0.03196902349591255, "policy_loss": -0.0007531170301840362, "dist_entropy": 1.4521604776382446, "actor_grad_norm": 0.07033856958150864, "critic_grad_norm": 0.0614350251853466, "ratio": 0.9999335408210754, "entropy": 1.4521604776382446, "incre_win_rate": 0.0, "step": 76}
{"time": 1767077647.6052647, "phase": "train", "update": 77, "total_env_steps": 246400, "episode_reward": 0.17197072505950928, "value_loss": 0.030855878815054895, "policy_loss": -0.001064027043351601, "dist_entropy": 1.4241848707199096, "actor_grad_norm": 0.13263173401355743, "critic_grad_norm": 0.03368692100048065, "ratio": 0.9999997019767761, "entropy": 1.4241848707199096, "incre_win_rate": 0.0, "step": 77}
{"time": 1767077652.6844342, "phase": "train", "update": 78, "total_env_steps": 249600, "episode_reward": 0.16140833497047424, "value_loss": 0.029827046021819115, "policy_loss": -0.0010775691089790485, "dist_entropy": 1.3891255140304566, "actor_grad_norm": 0.13548734784126282, "critic_grad_norm": 0.03966502100229263, "ratio": 1.0000282526016235, "entropy": 1.3891255140304566, "incre_win_rate": 0.0, "step": 78}
{"time": 1767077657.9158347, "phase": "train", "update": 79, "total_env_steps": 252800, "episode_reward": 0.17509105801582336, "value_loss": 0.02871544025838375, "policy_loss": -0.0016097300714964292, "dist_entropy": 1.4048022747039794, "actor_grad_norm": 0.11230764538049698, "critic_grad_norm": 0.08534761518239975, "ratio": 0.9998735785484314, "entropy": 1.4048022747039794, "incre_win_rate": 0.0, "step": 79}
{"time": 1767077663.074417, "phase": "train", "update": 80, "total_env_steps": 256000, "episode_reward": 0.145245760679245, "value_loss": 0.035757414251565936, "policy_loss": -0.0011399543958261482, "dist_entropy": 1.3276015758514403, "actor_grad_norm": 0.14733408391475677, "critic_grad_norm": 0.0756329894065857, "ratio": 0.9998599886894226, "entropy": 1.3276015758514403, "incre_win_rate": 0.0, "step": 80}
{"time": 1767077668.1811254, "phase": "train", "update": 81, "total_env_steps": 259200, "episode_reward": 0.1557859182357788, "value_loss": 0.03349778801202774, "policy_loss": -0.0007228106292334502, "dist_entropy": 1.3147114276885987, "actor_grad_norm": 0.0978875532746315, "critic_grad_norm": 0.08265148103237152, "ratio": 1.0002070665359497, "entropy": 1.3147114276885987, "incre_win_rate": 0.0, "step": 81}
{"time": 1767077681.6759925, "phase": "eval", "update": 81, "total_env_steps": 259200, "eval_win_rate": 0.0, "eval_episode_reward": 10.24891349337747, "step": 81}
{"time": 1767077686.7451355, "phase": "train", "update": 82, "total_env_steps": 262400, "episode_reward": 0.15052565932273865, "value_loss": 0.03404317274689674, "policy_loss": -0.001095934793129416, "dist_entropy": 1.2999835014343262, "actor_grad_norm": 0.07540971040725708, "critic_grad_norm": 0.08053950220346451, "ratio": 1.0002797842025757, "entropy": 1.2999835014343262, "incre_win_rate": 0.0, "step": 82}
{"time": 1767077691.8059938, "phase": "train", "update": 83, "total_env_steps": 265600, "episode_reward": 0.1631850302219391, "value_loss": 0.033479724824428556, "policy_loss": -0.0011417799571916908, "dist_entropy": 1.2782589435577392, "actor_grad_norm": 0.09283202886581421, "critic_grad_norm": 0.2043784111738205, "ratio": 1.0000017881393433, "entropy": 1.2782589435577392, "incre_win_rate": 0.0, "step": 83}
{"time": 1767077696.7874448, "phase": "train", "update": 84, "total_env_steps": 268800, "episode_reward": 0.15914011001586914, "value_loss": 0.031292129307985306, "policy_loss": -0.000625961767843819, "dist_entropy": 1.2506617069244386, "actor_grad_norm": 0.08878207206726074, "critic_grad_norm": 0.16196198761463165, "ratio": 1.0000351667404175, "entropy": 1.2506617069244386, "incre_win_rate": 0.0, "step": 84}
{"time": 1767077701.8313544, "phase": "train", "update": 85, "total_env_steps": 272000, "episode_reward": 0.1324172168970108, "value_loss": 0.03589693829417229, "policy_loss": -0.0010901042049116683, "dist_entropy": 1.259214496612549, "actor_grad_norm": 0.08604298532009125, "critic_grad_norm": 0.07754132896661758, "ratio": 0.9996874928474426, "entropy": 1.259214496612549, "incre_win_rate": 0.0, "step": 85}
{"time": 1767077706.964509, "phase": "train", "update": 86, "total_env_steps": 275200, "episode_reward": 0.16821914911270142, "value_loss": 0.030452480539679527, "policy_loss": -0.0008894493689130201, "dist_entropy": 1.243918514251709, "actor_grad_norm": 0.11181030422449112, "critic_grad_norm": 0.051182132214307785, "ratio": 0.9996828436851501, "entropy": 1.243918514251709, "incre_win_rate": 0.0, "step": 86}
{"time": 1767077712.158819, "phase": "train", "update": 87, "total_env_steps": 278400, "episode_reward": 0.164777010679245, "value_loss": 0.02688829191029072, "policy_loss": -0.0009395371063622094, "dist_entropy": 1.2443021535873413, "actor_grad_norm": 0.0741773247718811, "critic_grad_norm": 0.04181946441531181, "ratio": 1.0001899003982544, "entropy": 1.2443021535873413, "incre_win_rate": 0.0, "step": 87}
{"time": 1767077716.7183154, "phase": "train", "update": 88, "total_env_steps": 281600, "episode_reward": 0.1506752073764801, "value_loss": 0.036157722026109694, "policy_loss": -0.0009231057403605192, "dist_entropy": 1.2325251579284668, "actor_grad_norm": 0.06878363341093063, "critic_grad_norm": 0.0425649993121624, "ratio": 0.9999405741691589, "entropy": 1.2325251579284668, "incre_win_rate": 0.0, "step": 88}
{"time": 1767077721.3792238, "phase": "train", "update": 89, "total_env_steps": 284800, "episode_reward": 0.15645746886730194, "value_loss": 0.025443455576896666, "policy_loss": -0.00100754655336317, "dist_entropy": 1.2366371631622315, "actor_grad_norm": 0.08558721840381622, "critic_grad_norm": 0.030829206109046936, "ratio": 0.9994128346443176, "entropy": 1.2366371631622315, "incre_win_rate": 0.0, "step": 89}
{"time": 1767077725.9448717, "phase": "train", "update": 90, "total_env_steps": 288000, "episode_reward": 0.14874017238616943, "value_loss": 0.031291411444544795, "policy_loss": -0.0009810639621282036, "dist_entropy": 1.2256824016571044, "actor_grad_norm": 0.1161695271730423, "critic_grad_norm": 0.0906679555773735, "ratio": 1.000093698501587, "entropy": 1.2256824016571044, "incre_win_rate": 0.0, "step": 90}
{"time": 1767077730.5043502, "phase": "train", "update": 91, "total_env_steps": 291200, "episode_reward": 0.15548117458820343, "value_loss": 0.03636507019400596, "policy_loss": -0.0007863484663928943, "dist_entropy": 1.2504521608352661, "actor_grad_norm": 0.10590650141239166, "critic_grad_norm": 0.07668641954660416, "ratio": 1.0001713037490845, "entropy": 1.2504521608352661, "incre_win_rate": 0.0, "step": 91}
{"time": 1767077735.0649824, "phase": "train", "update": 92, "total_env_steps": 294400, "episode_reward": 0.16010606288909912, "value_loss": 0.032728830724954604, "policy_loss": -0.0006300151172567326, "dist_entropy": 1.2649454593658447, "actor_grad_norm": 0.06826072931289673, "critic_grad_norm": 0.0560857355594635, "ratio": 0.9999074339866638, "entropy": 1.2649454593658447, "incre_win_rate": 0.0, "step": 92}
{"time": 1767077739.5665371, "phase": "train", "update": 93, "total_env_steps": 297600, "episode_reward": 0.13429997861385345, "value_loss": 0.036177242547273634, "policy_loss": -0.0016266610558560047, "dist_entropy": 1.2376120805740356, "actor_grad_norm": 0.1403851956129074, "critic_grad_norm": 0.05586545541882515, "ratio": 1.0001469850540161, "entropy": 1.2376120805740356, "incre_win_rate": 0.0, "step": 93}
{"time": 1767077744.1989584, "phase": "train", "update": 94, "total_env_steps": 300800, "episode_reward": 0.1684359610080719, "value_loss": 0.0323649175465107, "policy_loss": -0.000867025677617761, "dist_entropy": 1.2344379901885987, "actor_grad_norm": 0.14217408001422882, "critic_grad_norm": 0.11674292385578156, "ratio": 1.0002243518829346, "entropy": 1.2344379901885987, "incre_win_rate": 0.0, "step": 94}
{"time": 1767077748.7430387, "phase": "train", "update": 95, "total_env_steps": 304000, "episode_reward": 0.14864704012870789, "value_loss": 0.03094952329993248, "policy_loss": -0.0009770365706721408, "dist_entropy": 1.2179729700088502, "actor_grad_norm": 0.1409764289855957, "critic_grad_norm": 0.09019642323255539, "ratio": 1.0000449419021606, "entropy": 1.2179729700088502, "incre_win_rate": 0.0, "step": 95}
{"time": 1767077753.2147446, "phase": "train", "update": 96, "total_env_steps": 307200, "episode_reward": 0.14686517417430878, "value_loss": 0.03174920901656151, "policy_loss": -0.0007853117183689529, "dist_entropy": 1.1986725568771361, "actor_grad_norm": 0.1237211748957634, "critic_grad_norm": 0.15236154198646545, "ratio": 1.0000841617584229, "entropy": 1.1986725568771361, "incre_win_rate": 0.0, "step": 96}
{"time": 1767077757.676995, "phase": "train", "update": 97, "total_env_steps": 310400, "episode_reward": 0.14311516284942627, "value_loss": 0.03442360013723374, "policy_loss": -0.0010825340057806442, "dist_entropy": 1.188235092163086, "actor_grad_norm": 0.09506820142269135, "critic_grad_norm": 0.12474711239337921, "ratio": 1.0001312494277954, "entropy": 1.188235092163086, "incre_win_rate": 0.0, "step": 97}
{"time": 1767077762.1060328, "phase": "train", "update": 98, "total_env_steps": 313600, "episode_reward": 0.1453554481267929, "value_loss": 0.032281474024057386, "policy_loss": -0.0012357184412243427, "dist_entropy": 1.1726288795471191, "actor_grad_norm": 0.08595091104507446, "critic_grad_norm": 0.11116702854633331, "ratio": 1.0000507831573486, "entropy": 1.1726288795471191, "incre_win_rate": 0.0, "step": 98}
{"time": 1767077766.6566403, "phase": "train", "update": 99, "total_env_steps": 316800, "episode_reward": 0.17143884301185608, "value_loss": 0.03239736109972, "policy_loss": -0.0007577065122646332, "dist_entropy": 1.1442447185516358, "actor_grad_norm": 0.06973841786384583, "critic_grad_norm": 0.09206372499465942, "ratio": 0.9993869662284851, "entropy": 1.1442447185516358, "incre_win_rate": 0.0, "step": 99}
{"time": 1767077771.1202388, "phase": "train", "update": 100, "total_env_steps": 320000, "episode_reward": 0.15042737126350403, "value_loss": 0.03768294975161553, "policy_loss": -0.0010969981944615626, "dist_entropy": 1.126737928390503, "actor_grad_norm": 0.08839993178844452, "critic_grad_norm": 0.09713858366012573, "ratio": 0.9998254776000977, "entropy": 1.126737928390503, "incre_win_rate": 0.0, "step": 100}
{"time": 1767077775.5579455, "phase": "train", "update": 101, "total_env_steps": 323200, "episode_reward": 0.16019298136234283, "value_loss": 0.03512358441948891, "policy_loss": -0.0008369895669360971, "dist_entropy": 1.1055628538131714, "actor_grad_norm": 0.110203817486763, "critic_grad_norm": 0.19331930577754974, "ratio": 1.0001426935195923, "entropy": 1.1055628538131714, "incre_win_rate": 0.0, "step": 101}
{"time": 1767077787.7095692, "phase": "eval", "update": 101, "total_env_steps": 323200, "eval_win_rate": 0.0, "eval_episode_reward": 9.905991307947009, "step": 101}
{"time": 1767077792.2797863, "phase": "train", "update": 102, "total_env_steps": 326400, "episode_reward": 0.1683293730020523, "value_loss": 0.0367210641503334, "policy_loss": -0.0011264726688757776, "dist_entropy": 1.1201411247253419, "actor_grad_norm": 0.10947144031524658, "critic_grad_norm": 0.27812445163726807, "ratio": 0.9997819066047668, "entropy": 1.1201411247253419, "incre_win_rate": 0.0, "step": 102}
{"time": 1767077796.7643104, "phase": "train", "update": 103, "total_env_steps": 329600, "episode_reward": 0.13985513150691986, "value_loss": 0.03693303465843201, "policy_loss": -0.0005677449531674483, "dist_entropy": 1.1023255586624146, "actor_grad_norm": 0.10409803688526154, "critic_grad_norm": 0.14683310687541962, "ratio": 0.9999523162841797, "entropy": 1.1023255586624146, "incre_win_rate": 0.0, "step": 103}
{"time": 1767077801.2503517, "phase": "train", "update": 104, "total_env_steps": 332800, "episode_reward": 0.15067362785339355, "value_loss": 0.03319615498185158, "policy_loss": -0.0006482790374555236, "dist_entropy": 1.1312138319015503, "actor_grad_norm": 0.1016426682472229, "critic_grad_norm": 0.13667182624340057, "ratio": 0.9998270273208618, "entropy": 1.1312138319015503, "incre_win_rate": 0.0, "step": 104}
{"time": 1767077805.7351394, "phase": "train", "update": 105, "total_env_steps": 336000, "episode_reward": 0.15065035223960876, "value_loss": 0.03055105432868004, "policy_loss": -0.001043171316368685, "dist_entropy": 1.124229073524475, "actor_grad_norm": 0.08678263425827026, "critic_grad_norm": 0.11036796867847443, "ratio": 1.0003674030303955, "entropy": 1.124229073524475, "incre_win_rate": 0.0, "step": 105}
{"time": 1767077810.2192318, "phase": "train", "update": 106, "total_env_steps": 339200, "episode_reward": 0.15109530091285706, "value_loss": 0.03930545225739479, "policy_loss": -0.0005764445869424151, "dist_entropy": 1.1335575342178346, "actor_grad_norm": 0.07858296483755112, "critic_grad_norm": 0.10505594313144684, "ratio": 0.9999458193778992, "entropy": 1.1335575342178346, "incre_win_rate": 0.0, "step": 106}
{"time": 1767077814.6313655, "phase": "train", "update": 107, "total_env_steps": 342400, "episode_reward": 0.13747982680797577, "value_loss": 0.032701609283685686, "policy_loss": -0.0006709678567592192, "dist_entropy": 1.1062168598175048, "actor_grad_norm": 0.10675444453954697, "critic_grad_norm": 0.08935029804706573, "ratio": 0.9998570680618286, "entropy": 1.1062168598175048, "incre_win_rate": 0.0, "step": 107}
{"time": 1767077819.2184222, "phase": "train", "update": 108, "total_env_steps": 345600, "episode_reward": 0.16441793739795685, "value_loss": 0.028339482843875885, "policy_loss": -0.0012323614016445106, "dist_entropy": 1.0961429834365846, "actor_grad_norm": 0.09245412796735764, "critic_grad_norm": 0.07331075519323349, "ratio": 1.000015139579773, "entropy": 1.0961429834365846, "incre_win_rate": 0.0, "step": 108}
{"time": 1767077823.6795175, "phase": "train", "update": 109, "total_env_steps": 348800, "episode_reward": 0.14825278520584106, "value_loss": 0.03519271910190582, "policy_loss": -0.0009583376175719138, "dist_entropy": 1.0784910202026368, "actor_grad_norm": 0.07597657293081284, "critic_grad_norm": 0.10041584074497223, "ratio": 0.9997795224189758, "entropy": 1.0784910202026368, "incre_win_rate": 0.0, "step": 109}
{"time": 1767077828.1098647, "phase": "train", "update": 110, "total_env_steps": 352000, "episode_reward": 0.15048997104167938, "value_loss": 0.03223442733287811, "policy_loss": -0.0007224520600146889, "dist_entropy": 1.0805378675460815, "actor_grad_norm": 0.06727661937475204, "critic_grad_norm": 0.13866154849529266, "ratio": 1.0001797676086426, "entropy": 1.0805378675460815, "incre_win_rate": 0.0, "step": 110}
{"time": 1767077832.7002707, "phase": "train", "update": 111, "total_env_steps": 355200, "episode_reward": 0.1528870016336441, "value_loss": 0.03270535543560982, "policy_loss": -0.0011854732280895063, "dist_entropy": 1.059384250640869, "actor_grad_norm": 0.11095383018255234, "critic_grad_norm": 0.09961613267660141, "ratio": 1.000383973121643, "entropy": 1.059384250640869, "incre_win_rate": 0.0, "step": 111}
{"time": 1767077837.552172, "phase": "train", "update": 112, "total_env_steps": 358400, "episode_reward": 0.16633328795433044, "value_loss": 0.03497529625892639, "policy_loss": -0.000415218481687063, "dist_entropy": 1.0608610391616822, "actor_grad_norm": 0.10100866854190826, "critic_grad_norm": 0.12153515964746475, "ratio": 1.0000120401382446, "entropy": 1.0608610391616822, "incre_win_rate": 0.0, "step": 112}
{"time": 1767077842.6073697, "phase": "train", "update": 113, "total_env_steps": 361600, "episode_reward": 0.14658837020397186, "value_loss": 0.03191006928682327, "policy_loss": -0.0005385889423623724, "dist_entropy": 1.0523816347122192, "actor_grad_norm": 0.13600914180278778, "critic_grad_norm": 0.0857650563120842, "ratio": 1.0003130435943604, "entropy": 1.0523816347122192, "incre_win_rate": 0.0, "step": 113}
{"time": 1767077847.557017, "phase": "train", "update": 114, "total_env_steps": 364800, "episode_reward": 0.14338679611682892, "value_loss": 0.03666485697031021, "policy_loss": -0.0007027464190356714, "dist_entropy": 1.0749404430389404, "actor_grad_norm": 0.10573776811361313, "critic_grad_norm": 0.0830906555056572, "ratio": 0.9998371005058289, "entropy": 1.0749404430389404, "incre_win_rate": 0.0, "step": 114}
{"time": 1767077852.5344713, "phase": "train", "update": 115, "total_env_steps": 368000, "episode_reward": 0.15452556312084198, "value_loss": 0.02824113592505455, "policy_loss": -0.0008167751234491761, "dist_entropy": 1.056546688079834, "actor_grad_norm": 0.09509632736444473, "critic_grad_norm": 0.15046755969524384, "ratio": 1.000373125076294, "entropy": 1.056546688079834, "incre_win_rate": 0.0, "step": 115}
{"time": 1767077857.0534115, "phase": "train", "update": 116, "total_env_steps": 371200, "episode_reward": 0.15296047925949097, "value_loss": 0.03559531569480896, "policy_loss": -0.0010070712442789898, "dist_entropy": 1.0799394130706788, "actor_grad_norm": 0.11313342303037643, "critic_grad_norm": 0.08069301396608353, "ratio": 0.9998388290405273, "entropy": 1.0799394130706788, "incre_win_rate": 0.0, "step": 116}
{"time": 1767077861.7024329, "phase": "train", "update": 117, "total_env_steps": 374400, "episode_reward": 0.14898282289505005, "value_loss": 0.032787592709064485, "policy_loss": -0.0010509232350340626, "dist_entropy": 1.082319164276123, "actor_grad_norm": 0.14671123027801514, "critic_grad_norm": 0.06794112175703049, "ratio": 0.9999462366104126, "entropy": 1.082319164276123, "incre_win_rate": 0.0, "step": 117}
{"time": 1767077866.1684, "phase": "train", "update": 118, "total_env_steps": 377600, "episode_reward": 0.1468222290277481, "value_loss": 0.03151359781622887, "policy_loss": -0.0006902271740223398, "dist_entropy": 1.056278657913208, "actor_grad_norm": 0.10263391584157944, "critic_grad_norm": 0.09870123118162155, "ratio": 1.0002862215042114, "entropy": 1.056278657913208, "incre_win_rate": 0.0, "step": 118}
{"time": 1767077870.5961404, "phase": "train", "update": 119, "total_env_steps": 380800, "episode_reward": 0.1484525054693222, "value_loss": 0.030162467062473296, "policy_loss": -0.001336868051168949, "dist_entropy": 1.0385149002075196, "actor_grad_norm": 0.07747025787830353, "critic_grad_norm": 0.10188474506139755, "ratio": 0.9995396733283997, "entropy": 1.0385149002075196, "incre_win_rate": 0.0, "step": 119}
{"time": 1767077875.0345495, "phase": "train", "update": 120, "total_env_steps": 384000, "episode_reward": 0.14455711841583252, "value_loss": 0.02709931768476963, "policy_loss": -0.0007140061763463379, "dist_entropy": 1.0349681377410889, "actor_grad_norm": 0.06879875808954239, "critic_grad_norm": 0.10765587538480759, "ratio": 0.9999977946281433, "entropy": 1.0349681377410889, "incre_win_rate": 0.0, "step": 120}
{"time": 1767077879.491299, "phase": "train", "update": 121, "total_env_steps": 387200, "episode_reward": 0.15069380402565002, "value_loss": 0.031469990685582164, "policy_loss": -0.000720691013009822, "dist_entropy": 1.063991379737854, "actor_grad_norm": 0.08342884480953217, "critic_grad_norm": 0.10508009046316147, "ratio": 1.0001500844955444, "entropy": 1.063991379737854, "incre_win_rate": 0.0, "step": 121}
{"time": 1767077889.2409484, "phase": "eval", "update": 121, "total_env_steps": 387200, "eval_win_rate": 0.0, "eval_episode_reward": 11.044029387417211, "step": 121}
{"time": 1767077893.745994, "phase": "train", "update": 122, "total_env_steps": 390400, "episode_reward": 0.15303859114646912, "value_loss": 0.0269821897149086, "policy_loss": -0.0009183198708591078, "dist_entropy": 1.070401406288147, "actor_grad_norm": 0.12742771208286285, "critic_grad_norm": 0.13735006749629974, "ratio": 1.0001320838928223, "entropy": 1.070401406288147, "incre_win_rate": 0.0, "step": 122}
{"time": 1767077898.2363667, "phase": "train", "update": 123, "total_env_steps": 393600, "episode_reward": 0.15316638350486755, "value_loss": 0.028337443992495537, "policy_loss": -0.0007207070029053853, "dist_entropy": 1.0640156269073486, "actor_grad_norm": 0.09996337443590164, "critic_grad_norm": 0.10515948385000229, "ratio": 0.9999937415122986, "entropy": 1.0640156269073486, "incre_win_rate": 0.0, "step": 123}
{"time": 1767077902.7908037, "phase": "train", "update": 124, "total_env_steps": 396800, "episode_reward": 0.1531188040971756, "value_loss": 0.028991054743528366, "policy_loss": -0.0008110366119554513, "dist_entropy": 1.0787365674972533, "actor_grad_norm": 0.0921139344573021, "critic_grad_norm": 0.0677894875407219, "ratio": 1.000044345855713, "entropy": 1.0787365674972533, "incre_win_rate": 0.0, "step": 124}
{"time": 1767077907.2989948, "phase": "train", "update": 125, "total_env_steps": 400000, "episode_reward": 0.15610668063163757, "value_loss": 0.02747011333703995, "policy_loss": -0.0007399490569254708, "dist_entropy": 1.0703196763992309, "actor_grad_norm": 0.10272518545389175, "critic_grad_norm": 0.05194845795631409, "ratio": 0.9997507333755493, "entropy": 1.0703196763992309, "incre_win_rate": 0.0, "step": 125}
{"time": 1767077911.85177, "phase": "train", "update": 126, "total_env_steps": 403200, "episode_reward": 0.15697123110294342, "value_loss": 0.03185700476169586, "policy_loss": -0.0009022641864007142, "dist_entropy": 1.068595004081726, "actor_grad_norm": 0.09173330664634705, "critic_grad_norm": 0.039950281381607056, "ratio": 0.9994572997093201, "entropy": 1.068595004081726, "incre_win_rate": 0.0, "step": 126}
{"time": 1767077916.2999985, "phase": "train", "update": 127, "total_env_steps": 406400, "episode_reward": 0.14719940721988678, "value_loss": 0.03617383614182472, "policy_loss": -0.0008314185605080126, "dist_entropy": 1.0530990362167358, "actor_grad_norm": 0.08237270265817642, "critic_grad_norm": 0.13940809667110443, "ratio": 0.9998710751533508, "entropy": 1.0530990362167358, "incre_win_rate": 0.0, "step": 127}
{"time": 1767077920.6978416, "phase": "train", "update": 128, "total_env_steps": 409600, "episode_reward": 0.13588006794452667, "value_loss": 0.025183580815792084, "policy_loss": -0.0013845655208172048, "dist_entropy": 1.0595368146896362, "actor_grad_norm": 0.08278342336416245, "critic_grad_norm": 0.28573042154312134, "ratio": 0.9999472498893738, "entropy": 1.0595368146896362, "incre_win_rate": 0.0, "step": 128}
{"time": 1767077925.2580302, "phase": "train", "update": 129, "total_env_steps": 412800, "episode_reward": 0.17027316987514496, "value_loss": 0.02986317649483681, "policy_loss": -0.0011708227351096667, "dist_entropy": 1.0599040031433105, "actor_grad_norm": 0.1339927315711975, "critic_grad_norm": 0.2351309061050415, "ratio": 1.0001308917999268, "entropy": 1.0599040031433105, "incre_win_rate": 0.0, "step": 129}
{"time": 1767077929.655424, "phase": "train", "update": 130, "total_env_steps": 416000, "episode_reward": 0.1379040777683258, "value_loss": 0.03531497344374657, "policy_loss": -0.0009449688216534469, "dist_entropy": 1.035611915588379, "actor_grad_norm": 0.07756531983613968, "critic_grad_norm": 0.18848824501037598, "ratio": 0.9997105002403259, "entropy": 1.035611915588379, "incre_win_rate": 0.0, "step": 130}
{"time": 1767077934.0485594, "phase": "train", "update": 131, "total_env_steps": 419200, "episode_reward": 0.13793615996837616, "value_loss": 0.031240345165133476, "policy_loss": -0.0011599073500953238, "dist_entropy": 1.0195273876190185, "actor_grad_norm": 0.11327256262302399, "critic_grad_norm": 0.15603779256343842, "ratio": 0.9998928308486938, "entropy": 1.0195273876190185, "incre_win_rate": 0.0, "step": 131}
{"time": 1767077938.469538, "phase": "train", "update": 132, "total_env_steps": 422400, "episode_reward": 0.14144091308116913, "value_loss": 0.0327360525727272, "policy_loss": -0.0012231401958933575, "dist_entropy": 1.0511474370956422, "actor_grad_norm": 0.06774117797613144, "critic_grad_norm": 0.07625643163919449, "ratio": 0.9999815225601196, "entropy": 1.0511474370956422, "incre_win_rate": 0.0, "step": 132}
{"time": 1767077943.0648534, "phase": "train", "update": 133, "total_env_steps": 425600, "episode_reward": 0.16402368247509003, "value_loss": 0.03686466068029404, "policy_loss": -0.0006437900040836553, "dist_entropy": 1.0686451196670532, "actor_grad_norm": 0.09726879745721817, "critic_grad_norm": 0.14623069763183594, "ratio": 1.0000594854354858, "entropy": 1.0686451196670532, "incre_win_rate": 0.0, "step": 133}
{"time": 1767077947.3014631, "phase": "train", "update": 134, "total_env_steps": 428800, "episode_reward": 0.11541442573070526, "value_loss": 0.03026955686509609, "policy_loss": -0.0010780801869320733, "dist_entropy": 1.051159715652466, "actor_grad_norm": 0.07820607721805573, "critic_grad_norm": 0.11640705168247223, "ratio": 0.9999716877937317, "entropy": 1.051159715652466, "incre_win_rate": 0.0, "step": 134}
{"time": 1767077951.7236571, "phase": "train", "update": 135, "total_env_steps": 432000, "episode_reward": 0.14817260205745697, "value_loss": 0.034815742075443266, "policy_loss": -0.0011759769331430193, "dist_entropy": 1.070587396621704, "actor_grad_norm": 0.0753299668431282, "critic_grad_norm": 0.09877228736877441, "ratio": 1.0001267194747925, "entropy": 1.070587396621704, "incre_win_rate": 0.0, "step": 135}
{"time": 1767077956.195828, "phase": "train", "update": 136, "total_env_steps": 435200, "episode_reward": 0.16142280399799347, "value_loss": 0.031796906143426895, "policy_loss": -0.0008271871859871993, "dist_entropy": 1.0806489944458009, "actor_grad_norm": 0.1104319617152214, "critic_grad_norm": 0.11319521814584732, "ratio": 0.9996263384819031, "entropy": 1.0806489944458009, "incre_win_rate": 0.0, "step": 136}
{"time": 1767077960.5689092, "phase": "train", "update": 137, "total_env_steps": 438400, "episode_reward": 0.1312882900238037, "value_loss": 0.03329767808318138, "policy_loss": -0.0007031352284052161, "dist_entropy": 1.0802674055099488, "actor_grad_norm": 0.10384561866521835, "critic_grad_norm": 0.12685206532478333, "ratio": 0.9999732375144958, "entropy": 1.0802674055099488, "incre_win_rate": 0.0, "step": 137}
{"time": 1767077964.8764963, "phase": "train", "update": 138, "total_env_steps": 441600, "episode_reward": 0.11876862496137619, "value_loss": 0.03584075123071671, "policy_loss": -0.0008634098135409829, "dist_entropy": 1.0723114967346192, "actor_grad_norm": 0.08815192431211472, "critic_grad_norm": 0.185386061668396, "ratio": 0.9995900988578796, "entropy": 1.0723114967346192, "incre_win_rate": 0.0, "step": 138}
{"time": 1767077969.3072798, "phase": "train", "update": 139, "total_env_steps": 444800, "episode_reward": 0.140047088265419, "value_loss": 0.0351743683218956, "policy_loss": -0.0005298704658276421, "dist_entropy": 1.0648334264755248, "actor_grad_norm": 0.08647849410772324, "critic_grad_norm": 0.13615046441555023, "ratio": 0.9995890855789185, "entropy": 1.0648334264755248, "incre_win_rate": 0.0, "step": 139}
{"time": 1767077973.747585, "phase": "train", "update": 140, "total_env_steps": 448000, "episode_reward": 0.14142072200775146, "value_loss": 0.029228439927101134, "policy_loss": -0.0012219868175940007, "dist_entropy": 1.0708734273910523, "actor_grad_norm": 0.093168705701828, "critic_grad_norm": 0.09094956517219543, "ratio": 0.9998854994773865, "entropy": 1.0708734273910523, "incre_win_rate": 0.0, "step": 140}
{"time": 1767077978.1896574, "phase": "train", "update": 141, "total_env_steps": 451200, "episode_reward": 0.14130795001983643, "value_loss": 0.030410612002015114, "policy_loss": -0.0006698738342151955, "dist_entropy": 1.1059464931488037, "actor_grad_norm": 0.08668161183595657, "critic_grad_norm": 0.11371629685163498, "ratio": 0.9999973177909851, "entropy": 1.1059464931488037, "incre_win_rate": 0.0, "step": 141}
{"time": 1767077989.3245275, "phase": "eval", "update": 141, "total_env_steps": 451200, "eval_win_rate": 0.0, "eval_episode_reward": 10.989807533112575, "step": 141}
{"time": 1767077993.7342026, "phase": "train", "update": 142, "total_env_steps": 454400, "episode_reward": 0.1253719925880432, "value_loss": 0.03509529754519462, "policy_loss": -0.0005724558719354178, "dist_entropy": 1.1140087127685547, "actor_grad_norm": 0.07105518877506256, "critic_grad_norm": 0.1097644716501236, "ratio": 0.9998550415039062, "entropy": 1.1140087127685547, "incre_win_rate": 0.0, "step": 142}
{"time": 1767077998.118458, "phase": "train", "update": 143, "total_env_steps": 457600, "episode_reward": 0.1474187821149826, "value_loss": 0.03442526087164879, "policy_loss": -0.0015058214033988548, "dist_entropy": 1.0997060060501098, "actor_grad_norm": 0.09204258769750595, "critic_grad_norm": 0.09497224539518356, "ratio": 1.0000953674316406, "entropy": 1.0997060060501098, "incre_win_rate": 0.0, "step": 143}
{"time": 1767078002.5800369, "phase": "train", "update": 144, "total_env_steps": 460800, "episode_reward": 0.14436103403568268, "value_loss": 0.031902245432138446, "policy_loss": -0.0014673439969392632, "dist_entropy": 1.0796446561813355, "actor_grad_norm": 0.0774550661444664, "critic_grad_norm": 0.05701316520571709, "ratio": 0.9998846054077148, "entropy": 1.0796446561813355, "incre_win_rate": 0.0, "step": 144}
{"time": 1767078006.9438975, "phase": "train", "update": 145, "total_env_steps": 464000, "episode_reward": 0.13916648924350739, "value_loss": 0.03261162601411342, "policy_loss": -0.001550855459452194, "dist_entropy": 1.0767128467559814, "actor_grad_norm": 0.10893478244543076, "critic_grad_norm": 0.2231525480747223, "ratio": 0.9996855854988098, "entropy": 1.0767128467559814, "incre_win_rate": 0.0, "step": 145}
{"time": 1767078011.3196902, "phase": "train", "update": 146, "total_env_steps": 467200, "episode_reward": 0.14560534060001373, "value_loss": 0.037002908438444136, "policy_loss": -0.0007007395806041927, "dist_entropy": 1.044591760635376, "actor_grad_norm": 0.10061611980199814, "critic_grad_norm": 0.21910324692726135, "ratio": 1.000339388847351, "entropy": 1.044591760635376, "incre_win_rate": 0.0, "step": 146}
{"time": 1767078015.7629418, "phase": "train", "update": 147, "total_env_steps": 470400, "episode_reward": 0.15761537849903107, "value_loss": 0.0325330838561058, "policy_loss": -0.0006465436936093028, "dist_entropy": 1.028013777732849, "actor_grad_norm": 0.09321356564760208, "critic_grad_norm": 0.11044042557477951, "ratio": 1.0000667572021484, "entropy": 1.028013777732849, "incre_win_rate": 0.0, "step": 147}
{"time": 1767078020.1470761, "phase": "train", "update": 148, "total_env_steps": 473600, "episode_reward": 0.13961197435855865, "value_loss": 0.030565729737281798, "policy_loss": -0.0008500691107848013, "dist_entropy": 1.0627515077590943, "actor_grad_norm": 0.10124587267637253, "critic_grad_norm": 0.05641507729887962, "ratio": 0.9999217987060547, "entropy": 1.0627515077590943, "incre_win_rate": 0.0, "step": 148}
{"time": 1767078024.5605261, "phase": "train", "update": 149, "total_env_steps": 476800, "episode_reward": 0.14874430000782013, "value_loss": 0.03063337542116642, "policy_loss": -0.0017008748168311882, "dist_entropy": 1.0530251502990722, "actor_grad_norm": 0.14064419269561768, "critic_grad_norm": 0.07927216589450836, "ratio": 0.9998793601989746, "entropy": 1.0530251502990722, "incre_win_rate": 0.0, "step": 149}
{"time": 1767078028.9821575, "phase": "train", "update": 150, "total_env_steps": 480000, "episode_reward": 0.15153610706329346, "value_loss": 0.03226940557360649, "policy_loss": -0.0014573675900621196, "dist_entropy": 1.0309432029724122, "actor_grad_norm": 0.0795428603887558, "critic_grad_norm": 0.07442118972539902, "ratio": 0.9998165369033813, "entropy": 1.0309432029724122, "incre_win_rate": 0.0, "step": 150}
{"time": 1767078033.50348, "phase": "train", "update": 151, "total_env_steps": 483200, "episode_reward": 0.15931342542171478, "value_loss": 0.03288074433803558, "policy_loss": -0.000642665343333526, "dist_entropy": 0.9888433933258056, "actor_grad_norm": 0.0569147951900959, "critic_grad_norm": 0.03810705989599228, "ratio": 0.9999925494194031, "entropy": 0.9888433933258056, "incre_win_rate": 0.0, "step": 151}
{"time": 1767078037.9128118, "phase": "train", "update": 152, "total_env_steps": 486400, "episode_reward": 0.15726356208324432, "value_loss": 0.03681453689932823, "policy_loss": -0.0006941325221458073, "dist_entropy": 1.0052470445632935, "actor_grad_norm": 0.0809544250369072, "critic_grad_norm": 0.1543118953704834, "ratio": 1.0001637935638428, "entropy": 1.0052470445632935, "incre_win_rate": 0.0, "step": 152}
{"time": 1767078042.424133, "phase": "train", "update": 153, "total_env_steps": 489600, "episode_reward": 0.16855496168136597, "value_loss": 0.036588753759860995, "policy_loss": -0.0011927571174993544, "dist_entropy": 0.9864617228507996, "actor_grad_norm": 0.09576454758644104, "critic_grad_norm": 0.12494111061096191, "ratio": 0.9999785423278809, "entropy": 0.9864617228507996, "incre_win_rate": 0.0, "step": 153}
{"time": 1767078046.9614372, "phase": "train", "update": 154, "total_env_steps": 492800, "episode_reward": 0.16633537411689758, "value_loss": 0.030732500925660135, "policy_loss": -0.0004112115693146734, "dist_entropy": 0.9892926216125488, "actor_grad_norm": 0.07321345806121826, "critic_grad_norm": 0.1270282119512558, "ratio": 1.0000015497207642, "entropy": 0.9892926216125488, "incre_win_rate": 0.0, "step": 154}
{"time": 1767078051.44762, "phase": "train", "update": 155, "total_env_steps": 496000, "episode_reward": 0.1618506759405136, "value_loss": 0.03030572235584259, "policy_loss": -0.0006837543488257935, "dist_entropy": 0.988060712814331, "actor_grad_norm": 0.09295370429754257, "critic_grad_norm": 0.1676577776670456, "ratio": 0.999676525592804, "entropy": 0.988060712814331, "incre_win_rate": 0.0, "step": 155}
{"time": 1767078055.9060647, "phase": "train", "update": 156, "total_env_steps": 499200, "episode_reward": 0.16057533025741577, "value_loss": 0.03201814442873001, "policy_loss": -0.0010448789020271576, "dist_entropy": 0.9760828733444213, "actor_grad_norm": 0.10061484575271606, "critic_grad_norm": 0.14828960597515106, "ratio": 0.9999246001243591, "entropy": 0.9760828733444213, "incre_win_rate": 0.0, "step": 156}
{"time": 1767078060.4320643, "phase": "train", "update": 157, "total_env_steps": 502400, "episode_reward": 0.1800031214952469, "value_loss": 0.03327414691448212, "policy_loss": -0.0004838221685510291, "dist_entropy": 1.0152389287948609, "actor_grad_norm": 0.12304790318012238, "critic_grad_norm": 0.08454882353544235, "ratio": 0.9998796582221985, "entropy": 1.0152389287948609, "incre_win_rate": 0.0, "step": 157}
{"time": 1767078064.9349418, "phase": "train", "update": 158, "total_env_steps": 505600, "episode_reward": 0.17725010216236115, "value_loss": 0.029132623970508576, "policy_loss": -0.0008210600004289858, "dist_entropy": 0.999313223361969, "actor_grad_norm": 0.1091693863272667, "critic_grad_norm": 0.11966092884540558, "ratio": 0.9999980330467224, "entropy": 0.999313223361969, "incre_win_rate": 0.0, "step": 158}
{"time": 1767078069.4732296, "phase": "train", "update": 159, "total_env_steps": 508800, "episode_reward": 0.18545323610305786, "value_loss": 0.029950698465108873, "policy_loss": -0.0005471210509487179, "dist_entropy": 1.0255062103271484, "actor_grad_norm": 0.10714073479175568, "critic_grad_norm": 0.1451626867055893, "ratio": 0.9996890425682068, "entropy": 1.0255062103271484, "incre_win_rate": 0.0, "step": 159}
{"time": 1767078073.9884202, "phase": "train", "update": 160, "total_env_steps": 512000, "episode_reward": 0.17518159747123718, "value_loss": 0.026946506276726723, "policy_loss": -0.0008911052376037176, "dist_entropy": 1.0318060874938966, "actor_grad_norm": 0.07977469265460968, "critic_grad_norm": 0.10528750717639923, "ratio": 0.9998542070388794, "entropy": 1.0318060874938966, "incre_win_rate": 0.0, "step": 160}
{"time": 1767078078.4670057, "phase": "train", "update": 161, "total_env_steps": 515200, "episode_reward": 0.1748163253068924, "value_loss": 0.02946920171380043, "policy_loss": -0.0007497010254972735, "dist_entropy": 1.0031414389610291, "actor_grad_norm": 0.10642044991254807, "critic_grad_norm": 0.11724797636270523, "ratio": 0.9998173117637634, "entropy": 1.0031414389610291, "incre_win_rate": 0.0, "step": 161}
{"time": 1767078087.9025183, "phase": "eval", "update": 161, "total_env_steps": 515200, "eval_win_rate": 0.0, "eval_episode_reward": 9.92860099337748, "step": 161}
{"time": 1767078092.4391375, "phase": "train", "update": 162, "total_env_steps": 518400, "episode_reward": 0.16928702592849731, "value_loss": 0.032523879408836366, "policy_loss": -0.0011192231125622064, "dist_entropy": 1.0107314825057983, "actor_grad_norm": 0.12126266956329346, "critic_grad_norm": 0.07954523712396622, "ratio": 0.9996833205223083, "entropy": 1.0107314825057983, "incre_win_rate": 0.0, "step": 162}
{"time": 1767078096.96055, "phase": "train", "update": 163, "total_env_steps": 521600, "episode_reward": 0.1797444224357605, "value_loss": 0.03426646813750267, "policy_loss": -0.0007400868479393808, "dist_entropy": 1.0143769264221192, "actor_grad_norm": 0.09257113933563232, "critic_grad_norm": 0.06727608293294907, "ratio": 1.0000663995742798, "entropy": 1.0143769264221192, "incre_win_rate": 0.0, "step": 163}
{"time": 1767078127.300859, "phase": "train", "update": 164, "total_env_steps": 524800, "episode_reward": 0.17724595963954926, "value_loss": 0.06487808376550674, "policy_loss": -0.0010375489320016084, "dist_entropy": 0.9938019514083862, "actor_grad_norm": 0.11110293120145798, "critic_grad_norm": 0.22919543087482452, "ratio": 0.9999508857727051, "entropy": 0.9938019514083862, "incre_win_rate": 0.0, "step": 164}
{"time": 1767078131.8070304, "phase": "train", "update": 165, "total_env_steps": 528000, "episode_reward": 0.18087543547153473, "value_loss": 0.029440762102603914, "policy_loss": -0.0006869145361186213, "dist_entropy": 0.9863997578620911, "actor_grad_norm": 0.07332446426153183, "critic_grad_norm": 0.12918905913829803, "ratio": 0.9997963309288025, "entropy": 0.9863997578620911, "incre_win_rate": 0.0, "step": 165}
{"time": 1767078136.290653, "phase": "train", "update": 166, "total_env_steps": 531200, "episode_reward": 0.17187291383743286, "value_loss": 0.03264989256858826, "policy_loss": -0.000939198737112168, "dist_entropy": 0.9992726802825928, "actor_grad_norm": 0.07817743718624115, "critic_grad_norm": 0.09929113835096359, "ratio": 0.9998470544815063, "entropy": 0.9992726802825928, "incre_win_rate": 0.0, "step": 166}
{"time": 1767078140.8029943, "phase": "train", "update": 167, "total_env_steps": 534400, "episode_reward": 0.1792999655008316, "value_loss": 0.03165379725396633, "policy_loss": -0.0009743367172642791, "dist_entropy": 1.0065834522247314, "actor_grad_norm": 0.07989469915628433, "critic_grad_norm": 0.09841009229421616, "ratio": 0.9999522566795349, "entropy": 1.0065834522247314, "incre_win_rate": 0.0, "step": 167}
{"time": 1767078145.2987313, "phase": "train", "update": 168, "total_env_steps": 537600, "episode_reward": 0.17679168283939362, "value_loss": 0.031050043925642968, "policy_loss": -0.0005115120703941045, "dist_entropy": 0.9744010090827941, "actor_grad_norm": 0.07238968461751938, "critic_grad_norm": 0.13788071274757385, "ratio": 0.999829888343811, "entropy": 0.9744010090827941, "incre_win_rate": 0.0, "step": 168}
{"time": 1767078149.6376247, "phase": "train", "update": 169, "total_env_steps": 540800, "episode_reward": 0.16409355401992798, "value_loss": 0.03683678582310677, "policy_loss": -0.0007259090934666368, "dist_entropy": 0.9776269674301148, "actor_grad_norm": 0.11856561154127121, "critic_grad_norm": 0.10931131988763809, "ratio": 0.9999977350234985, "entropy": 0.9776269674301148, "incre_win_rate": 0.0, "step": 169}
{"time": 1767078154.154397, "phase": "train", "update": 170, "total_env_steps": 544000, "episode_reward": 0.16620396077632904, "value_loss": 0.036136509478092195, "policy_loss": -0.0010403750441373206, "dist_entropy": 0.9501729369163513, "actor_grad_norm": 0.09526865929365158, "critic_grad_norm": 0.06829841434955597, "ratio": 0.9998435378074646, "entropy": 0.9501729369163513, "incre_win_rate": 0.0, "step": 170}
{"time": 1767078158.642919, "phase": "train", "update": 171, "total_env_steps": 547200, "episode_reward": 0.1739957630634308, "value_loss": 0.039505385607481, "policy_loss": -0.0009337432825585523, "dist_entropy": 0.9797235250473022, "actor_grad_norm": 0.0862564668059349, "critic_grad_norm": 0.06588727980852127, "ratio": 0.9996160864830017, "entropy": 0.9797235250473022, "incre_win_rate": 0.0, "step": 171}
{"time": 1767078163.0269568, "phase": "train", "update": 172, "total_env_steps": 550400, "episode_reward": 0.157876655459404, "value_loss": 0.03274186924099922, "policy_loss": -0.0006073987899368305, "dist_entropy": 0.9693069458007812, "actor_grad_norm": 0.07947897911071777, "critic_grad_norm": 0.05908849462866783, "ratio": 1.000095248222351, "entropy": 0.9693069458007812, "incre_win_rate": 0.0, "step": 172}
{"time": 1767078167.4857888, "phase": "train", "update": 173, "total_env_steps": 553600, "episode_reward": 0.16839973628520966, "value_loss": 0.02925712279975414, "policy_loss": -0.0006298216002985413, "dist_entropy": 0.9623449921607972, "actor_grad_norm": 0.07809831947088242, "critic_grad_norm": 0.06343994289636612, "ratio": 0.999650776386261, "entropy": 0.9623449921607972, "incre_win_rate": 0.0, "step": 173}
{"time": 1767078172.0474217, "phase": "train", "update": 174, "total_env_steps": 556800, "episode_reward": 0.17171771824359894, "value_loss": 0.03584323972463608, "policy_loss": -0.0009468538600393206, "dist_entropy": 0.9357403874397278, "actor_grad_norm": 0.12780824303627014, "critic_grad_norm": 0.10187172889709473, "ratio": 1.0000289678573608, "entropy": 0.9357403874397278, "incre_win_rate": 0.0, "step": 174}
{"time": 1767078176.4269073, "phase": "train", "update": 175, "total_env_steps": 560000, "episode_reward": 0.1620483249425888, "value_loss": 0.03253335580229759, "policy_loss": -0.001508902769811371, "dist_entropy": 0.9363393545150757, "actor_grad_norm": 0.11245959252119064, "critic_grad_norm": 0.07210054993629456, "ratio": 0.9997987747192383, "entropy": 0.9363393545150757, "incre_win_rate": 0.0, "step": 175}
{"time": 1767078181.0240612, "phase": "train", "update": 176, "total_env_steps": 563200, "episode_reward": 0.17493325471878052, "value_loss": 0.037501346319913864, "policy_loss": -0.000876759967028029, "dist_entropy": 0.9515589714050293, "actor_grad_norm": 0.0973479151725769, "critic_grad_norm": 0.05905003100633621, "ratio": 1.0001850128173828, "entropy": 0.9515589714050293, "incre_win_rate": 0.0, "step": 176}
{"time": 1767078185.4985929, "phase": "train", "update": 177, "total_env_steps": 566400, "episode_reward": 0.18561206758022308, "value_loss": 0.03263663724064827, "policy_loss": -0.0009816574132749168, "dist_entropy": 0.9417671322822571, "actor_grad_norm": 0.09403776377439499, "critic_grad_norm": 0.07057616859674454, "ratio": 1.0000782012939453, "entropy": 0.9417671322822571, "incre_win_rate": 0.0, "step": 177}
{"time": 1767078190.4928937, "phase": "train", "update": 178, "total_env_steps": 569600, "episode_reward": 0.18602392077445984, "value_loss": 0.030128064006567, "policy_loss": -0.0005493774758356551, "dist_entropy": 0.9528239965438843, "actor_grad_norm": 0.07873491197824478, "critic_grad_norm": 0.10143136233091354, "ratio": 0.9998630881309509, "entropy": 0.9528239965438843, "incre_win_rate": 0.0, "step": 178}
{"time": 1767078195.404399, "phase": "train", "update": 179, "total_env_steps": 572800, "episode_reward": 0.17759467661380768, "value_loss": 0.031951656192541124, "policy_loss": -0.0008989641171934737, "dist_entropy": 0.9232244729995728, "actor_grad_norm": 0.08428936451673508, "critic_grad_norm": 0.05616578459739685, "ratio": 0.9998270273208618, "entropy": 0.9232244729995728, "incre_win_rate": 0.0, "step": 179}
{"time": 1767078199.9717772, "phase": "train", "update": 180, "total_env_steps": 576000, "episode_reward": 0.18229873478412628, "value_loss": 0.028635318949818613, "policy_loss": -0.0006364880974174981, "dist_entropy": 0.9423823475837707, "actor_grad_norm": 0.09357336908578873, "critic_grad_norm": 0.08850666135549545, "ratio": 0.9998612403869629, "entropy": 0.9423823475837707, "incre_win_rate": 0.0, "step": 180}
{"time": 1767078204.5330944, "phase": "train", "update": 181, "total_env_steps": 579200, "episode_reward": 0.17674723267555237, "value_loss": 0.028571749851107598, "policy_loss": -0.00031321204979093407, "dist_entropy": 0.9699559569358825, "actor_grad_norm": 0.08165545761585236, "critic_grad_norm": 0.14769227802753448, "ratio": 0.9996081590652466, "entropy": 0.9699559569358825, "incre_win_rate": 0.0, "step": 181}
{"time": 1767078213.7436533, "phase": "eval", "update": 181, "total_env_steps": 579200, "eval_win_rate": 0.0, "eval_episode_reward": 10.238824503311253, "step": 181}
{"time": 1767078218.3462393, "phase": "train", "update": 182, "total_env_steps": 582400, "episode_reward": 0.1783417910337448, "value_loss": 0.02856203056871891, "policy_loss": -0.0006605010679329836, "dist_entropy": 0.9597428560256958, "actor_grad_norm": 0.06654835492372513, "critic_grad_norm": 0.12635348737239838, "ratio": 0.9997450113296509, "entropy": 0.9597428560256958, "incre_win_rate": 0.0, "step": 182}
{"time": 1767078222.8945618, "phase": "train", "update": 183, "total_env_steps": 585600, "episode_reward": 0.17610926926136017, "value_loss": 0.03152326606214047, "policy_loss": -0.0007892823946473726, "dist_entropy": 0.9383952140808105, "actor_grad_norm": 0.09374690055847168, "critic_grad_norm": 0.07990624010562897, "ratio": 0.9999979138374329, "entropy": 0.9383952140808105, "incre_win_rate": 0.0, "step": 183}
{"time": 1767078227.422603, "phase": "train", "update": 184, "total_env_steps": 588800, "episode_reward": 0.1843682825565338, "value_loss": 0.031011245027184487, "policy_loss": -0.0009251572939685815, "dist_entropy": 0.9581124186515808, "actor_grad_norm": 0.10516520589590073, "critic_grad_norm": 0.11090544611215591, "ratio": 0.9999114871025085, "entropy": 0.9581124186515808, "incre_win_rate": 0.0, "step": 184}
{"time": 1767078231.9783242, "phase": "train", "update": 185, "total_env_steps": 592000, "episode_reward": 0.18073417246341705, "value_loss": 0.023458931222558023, "policy_loss": -0.0009643807596637188, "dist_entropy": 0.9482592344284058, "actor_grad_norm": 0.12655816972255707, "critic_grad_norm": 0.10099402815103531, "ratio": 1.000328779220581, "entropy": 0.9482592344284058, "incre_win_rate": 0.0, "step": 185}
{"time": 1767078236.5251582, "phase": "train", "update": 186, "total_env_steps": 595200, "episode_reward": 0.1797599196434021, "value_loss": 0.029180718958377837, "policy_loss": -0.0009156415961641074, "dist_entropy": 0.9703411936759949, "actor_grad_norm": 0.1010444164276123, "critic_grad_norm": 0.07081733644008636, "ratio": 0.9999756217002869, "entropy": 0.9703411936759949, "incre_win_rate": 0.0, "step": 186}
{"time": 1767078240.9867902, "phase": "train", "update": 187, "total_env_steps": 598400, "episode_reward": 0.17253829538822174, "value_loss": 0.03636003881692886, "policy_loss": -0.0011455848002341895, "dist_entropy": 0.9714747190475463, "actor_grad_norm": 0.06851809471845627, "critic_grad_norm": 0.058293092995882034, "ratio": 0.9998511672019958, "entropy": 0.9714747190475463, "incre_win_rate": 0.0, "step": 187}
{"time": 1767078245.5270288, "phase": "train", "update": 188, "total_env_steps": 601600, "episode_reward": 0.18145745992660522, "value_loss": 0.028728873282670975, "policy_loss": -0.0007810490875266752, "dist_entropy": 0.929158627986908, "actor_grad_norm": 0.12444200366735458, "critic_grad_norm": 0.05706305056810379, "ratio": 1.0001544952392578, "entropy": 0.929158627986908, "incre_win_rate": 0.0, "step": 188}
{"time": 1767078250.0266037, "phase": "train", "update": 189, "total_env_steps": 604800, "episode_reward": 0.18284301459789276, "value_loss": 0.030245450511574744, "policy_loss": -0.0007029786779899183, "dist_entropy": 0.9488442182540894, "actor_grad_norm": 0.09454714506864548, "critic_grad_norm": 0.10457959026098251, "ratio": 0.9996377229690552, "entropy": 0.9488442182540894, "incre_win_rate": 0.0, "step": 189}
{"time": 1767078254.6111271, "phase": "train", "update": 190, "total_env_steps": 608000, "episode_reward": 0.1877312809228897, "value_loss": 0.03211938962340355, "policy_loss": -0.0007161610475257873, "dist_entropy": 0.9202707886695862, "actor_grad_norm": 0.07568202167749405, "critic_grad_norm": 0.08316998183727264, "ratio": 0.9998646974563599, "entropy": 0.9202707886695862, "incre_win_rate": 0.0, "step": 190}
{"time": 1767078259.1346996, "phase": "train", "update": 191, "total_env_steps": 611200, "episode_reward": 0.1816633939743042, "value_loss": 0.03141894824802875, "policy_loss": -0.0007210997103467065, "dist_entropy": 0.9217471241950989, "actor_grad_norm": 0.11870312690734863, "critic_grad_norm": 0.05360063537955284, "ratio": 0.9999807476997375, "entropy": 0.9217471241950989, "incre_win_rate": 0.0, "step": 191}
{"time": 1767078263.6098845, "phase": "train", "update": 192, "total_env_steps": 614400, "episode_reward": 0.1756410151720047, "value_loss": 0.03323495760560036, "policy_loss": -0.00036207611378884507, "dist_entropy": 0.9467839241027832, "actor_grad_norm": 0.11058457940816879, "critic_grad_norm": 0.12223776429891586, "ratio": 0.9998934864997864, "entropy": 0.9467839241027832, "incre_win_rate": 0.0, "step": 192}
{"time": 1767078268.046661, "phase": "train", "update": 193, "total_env_steps": 617600, "episode_reward": 0.17368894815444946, "value_loss": 0.02712126597762108, "policy_loss": -0.0008655776595671849, "dist_entropy": 0.9529529213905334, "actor_grad_norm": 0.11402904987335205, "critic_grad_norm": 0.08775979280471802, "ratio": 1.0001648664474487, "entropy": 0.9529529213905334, "incre_win_rate": 0.0, "step": 193}
{"time": 1767078272.5757651, "phase": "train", "update": 194, "total_env_steps": 620800, "episode_reward": 0.18191950023174286, "value_loss": 0.035298775881528854, "policy_loss": -0.0011069000156762598, "dist_entropy": 0.9536529779434204, "actor_grad_norm": 0.1008678674697876, "critic_grad_norm": 0.0916580855846405, "ratio": 0.9999924898147583, "entropy": 0.9536529779434204, "incre_win_rate": 0.0, "step": 194}
{"time": 1767078277.107305, "phase": "train", "update": 195, "total_env_steps": 624000, "episode_reward": 0.17484891414642334, "value_loss": 0.029056844860315324, "policy_loss": -0.0009417401468333253, "dist_entropy": 0.9704130053520202, "actor_grad_norm": 0.08652300387620926, "critic_grad_norm": 0.12376629561185837, "ratio": 0.9998696446418762, "entropy": 0.9704130053520202, "incre_win_rate": 0.0, "step": 195}
{"time": 1767078281.6570911, "phase": "train", "update": 196, "total_env_steps": 627200, "episode_reward": 0.18138039112091064, "value_loss": 0.026090662553906442, "policy_loss": -0.0009806651248268849, "dist_entropy": 0.9821849584579467, "actor_grad_norm": 0.11708343029022217, "critic_grad_norm": 0.11863622814416885, "ratio": 0.9999960064888, "entropy": 0.9821849584579467, "incre_win_rate": 0.0, "step": 196}
{"time": 1767078286.2143328, "phase": "train", "update": 197, "total_env_steps": 630400, "episode_reward": 0.18074193596839905, "value_loss": 0.028869401291012765, "policy_loss": -0.0011376957989373438, "dist_entropy": 0.9827957034111023, "actor_grad_norm": 0.09500546753406525, "critic_grad_norm": 0.03914573788642883, "ratio": 1.0000900030136108, "entropy": 0.9827957034111023, "incre_win_rate": 0.0, "step": 197}
{"time": 1767078290.6689613, "phase": "train", "update": 198, "total_env_steps": 633600, "episode_reward": 0.1707884967327118, "value_loss": 0.033128393441438676, "policy_loss": -0.0007118138318357836, "dist_entropy": 0.9960543394088746, "actor_grad_norm": 0.10174628347158432, "critic_grad_norm": 0.05881146341562271, "ratio": 0.9998628497123718, "entropy": 0.9960543394088746, "incre_win_rate": 0.0, "step": 198}
{"time": 1767078295.602036, "phase": "train", "update": 199, "total_env_steps": 636800, "episode_reward": 0.17331281304359436, "value_loss": 0.03373541086912155, "policy_loss": -0.001015201378481123, "dist_entropy": 1.0398252487182618, "actor_grad_norm": 0.10400339215993881, "critic_grad_norm": 0.09822316467761993, "ratio": 1.000124216079712, "entropy": 1.0398252487182618, "incre_win_rate": 0.0, "step": 199}
{"time": 1767078300.1540174, "phase": "train", "update": 200, "total_env_steps": 640000, "episode_reward": 0.17944949865341187, "value_loss": 0.03175614960491657, "policy_loss": -0.0014161063822427876, "dist_entropy": 1.0457475185394287, "actor_grad_norm": 0.09567739814519882, "critic_grad_norm": 0.10943237692117691, "ratio": 0.9998566508293152, "entropy": 1.0457475185394287, "incre_win_rate": 0.0, "step": 200}
{"time": 1767078304.7166991, "phase": "train", "update": 201, "total_env_steps": 643200, "episode_reward": 0.1736910194158554, "value_loss": 0.029516069591045378, "policy_loss": -0.001068033927696632, "dist_entropy": 1.0630943298339843, "actor_grad_norm": 0.09497012197971344, "critic_grad_norm": 0.15545736253261566, "ratio": 0.9997746348381042, "entropy": 1.0630943298339843, "incre_win_rate": 0.0, "step": 201}
{"time": 1767078316.0669305, "phase": "eval", "update": 201, "total_env_steps": 643200, "eval_win_rate": 0.0, "eval_episode_reward": 11.543408526490058, "step": 201}
{"time": 1767078320.6822786, "phase": "train", "update": 202, "total_env_steps": 646400, "episode_reward": 0.17606736719608307, "value_loss": 0.031810793280601504, "policy_loss": -0.000879819399938242, "dist_entropy": 1.04603054523468, "actor_grad_norm": 0.07807975262403488, "critic_grad_norm": 0.1835257112979889, "ratio": 1.0000706911087036, "entropy": 1.04603054523468, "incre_win_rate": 0.0, "step": 202}
{"time": 1767078325.1731668, "phase": "train", "update": 203, "total_env_steps": 649600, "episode_reward": 0.17686672508716583, "value_loss": 0.029785018414258957, "policy_loss": -0.0008019565349350443, "dist_entropy": 1.0525904893875122, "actor_grad_norm": 0.10574795305728912, "critic_grad_norm": 0.1830969601869583, "ratio": 0.9999080896377563, "entropy": 1.0525904893875122, "incre_win_rate": 0.0, "step": 203}
{"time": 1767078329.6096659, "phase": "train", "update": 204, "total_env_steps": 652800, "episode_reward": 0.1701759397983551, "value_loss": 0.02967626564204693, "policy_loss": -0.0013453655124853192, "dist_entropy": 1.0447161674499512, "actor_grad_norm": 0.09610811620950699, "critic_grad_norm": 0.04554165154695511, "ratio": 1.0001916885375977, "entropy": 1.0447161674499512, "incre_win_rate": 0.0, "step": 204}
{"time": 1767078334.048346, "phase": "train", "update": 205, "total_env_steps": 656000, "episode_reward": 0.16562967002391815, "value_loss": 0.03262441232800484, "policy_loss": -0.0009506821578597168, "dist_entropy": 0.9995133996009826, "actor_grad_norm": 0.07930361479520798, "critic_grad_norm": 0.07556699961423874, "ratio": 0.9999837875366211, "entropy": 0.9995133996009826, "incre_win_rate": 0.0, "step": 205}
{"time": 1767078338.7469552, "phase": "train", "update": 206, "total_env_steps": 659200, "episode_reward": 0.17647455632686615, "value_loss": 0.03682626560330391, "policy_loss": -0.0010715367130593734, "dist_entropy": 1.037590789794922, "actor_grad_norm": 0.0942758098244667, "critic_grad_norm": 0.09919866919517517, "ratio": 1.0001858472824097, "entropy": 1.037590789794922, "incre_win_rate": 0.0, "step": 206}
{"time": 1767078343.2336245, "phase": "train", "update": 207, "total_env_steps": 662400, "episode_reward": 0.16781611740589142, "value_loss": 0.033238344639539716, "policy_loss": -0.0011634506595473494, "dist_entropy": 1.0180786371231079, "actor_grad_norm": 0.0943276435136795, "critic_grad_norm": 0.16794453561306, "ratio": 1.0002597570419312, "entropy": 1.0180786371231079, "incre_win_rate": 0.0, "step": 207}
{"time": 1767078347.6248953, "phase": "train", "update": 208, "total_env_steps": 665600, "episode_reward": 0.17469991743564606, "value_loss": 0.035047661513090134, "policy_loss": -0.0007102073935058683, "dist_entropy": 1.0252044677734375, "actor_grad_norm": 0.09653018414974213, "critic_grad_norm": 0.1118047758936882, "ratio": 0.9999566078186035, "entropy": 1.0252044677734375, "incre_win_rate": 0.0, "step": 208}
{"time": 1767078352.1119194, "phase": "train", "update": 209, "total_env_steps": 668800, "episode_reward": 0.18273025751113892, "value_loss": 0.03408785611391067, "policy_loss": -0.0007088429090742921, "dist_entropy": 1.0400113582611084, "actor_grad_norm": 0.08172882348299026, "critic_grad_norm": 0.10036319494247437, "ratio": 1.0000728368759155, "entropy": 1.0400113582611084, "incre_win_rate": 0.0, "step": 209}
{"time": 1767078356.6046789, "phase": "train", "update": 210, "total_env_steps": 672000, "episode_reward": 0.1688540130853653, "value_loss": 0.03453204184770584, "policy_loss": -0.000966802139604539, "dist_entropy": 1.05906240940094, "actor_grad_norm": 0.10614415258169174, "critic_grad_norm": 0.10941120237112045, "ratio": 0.99964439868927, "entropy": 1.05906240940094, "incre_win_rate": 0.0, "step": 210}
{"time": 1767078361.124917, "phase": "train", "update": 211, "total_env_steps": 675200, "episode_reward": 0.17032542824745178, "value_loss": 0.030025144666433336, "policy_loss": -0.000848727556326434, "dist_entropy": 1.0180740833282471, "actor_grad_norm": 0.08339004963636398, "critic_grad_norm": 0.06999092549085617, "ratio": 0.9995861053466797, "entropy": 1.0180740833282471, "incre_win_rate": 0.0, "step": 211}
{"time": 1767078365.5912938, "phase": "train", "update": 212, "total_env_steps": 678400, "episode_reward": 0.17215333878993988, "value_loss": 0.03451688140630722, "policy_loss": -0.0012985011952500792, "dist_entropy": 1.0178943872451782, "actor_grad_norm": 0.10640424489974976, "critic_grad_norm": 0.08884801715612411, "ratio": 0.9997294545173645, "entropy": 1.0178943872451782, "incre_win_rate": 0.0, "step": 212}
{"time": 1767078369.9717433, "phase": "train", "update": 213, "total_env_steps": 681600, "episode_reward": 0.15691328048706055, "value_loss": 0.03720149844884872, "policy_loss": -0.0012470199170117268, "dist_entropy": 1.012132716178894, "actor_grad_norm": 0.09894997626543045, "critic_grad_norm": 0.19989384710788727, "ratio": 0.9998309016227722, "entropy": 1.012132716178894, "incre_win_rate": 0.0, "step": 213}
{"time": 1767078374.357256, "phase": "train", "update": 214, "total_env_steps": 684800, "episode_reward": 0.14574605226516724, "value_loss": 0.030516603216528892, "policy_loss": -0.0017482403581436045, "dist_entropy": 1.0031135201454162, "actor_grad_norm": 0.14231927692890167, "critic_grad_norm": 0.12904572486877441, "ratio": 0.9999446868896484, "entropy": 1.0031135201454162, "incre_win_rate": 0.0, "step": 214}
{"time": 1767078378.7686417, "phase": "train", "update": 215, "total_env_steps": 688000, "episode_reward": 0.1654268503189087, "value_loss": 0.03003593608736992, "policy_loss": -0.0010389585739943642, "dist_entropy": 0.9840603351593018, "actor_grad_norm": 0.12682048976421356, "critic_grad_norm": 0.20577695965766907, "ratio": 0.999914288520813, "entropy": 0.9840603351593018, "incre_win_rate": 0.0, "step": 215}
{"time": 1767078383.3131955, "phase": "train", "update": 216, "total_env_steps": 691200, "episode_reward": 0.1836501657962799, "value_loss": 0.034385628253221515, "policy_loss": -0.0006690593994635563, "dist_entropy": 0.9792508959770203, "actor_grad_norm": 0.08381996303796768, "critic_grad_norm": 0.11565077304840088, "ratio": 0.999886155128479, "entropy": 0.9792508959770203, "incre_win_rate": 0.0, "step": 216}
{"time": 1767078387.7805057, "phase": "train", "update": 217, "total_env_steps": 694400, "episode_reward": 0.16063743829727173, "value_loss": 0.035091910511255264, "policy_loss": -0.0008337593065071758, "dist_entropy": 0.995735228061676, "actor_grad_norm": 0.08902116864919662, "critic_grad_norm": 0.11884986609220505, "ratio": 0.9999391436576843, "entropy": 0.995735228061676, "incre_win_rate": 0.0, "step": 217}
{"time": 1767078392.1663473, "phase": "train", "update": 218, "total_env_steps": 697600, "episode_reward": 0.1598556637763977, "value_loss": 0.031071607023477554, "policy_loss": -0.0015415233066690347, "dist_entropy": 0.9817398905754089, "actor_grad_norm": 0.09562312066555023, "critic_grad_norm": 0.2033102959394455, "ratio": 0.9999399185180664, "entropy": 0.9817398905754089, "incre_win_rate": 0.0, "step": 218}
{"time": 1767078396.6218562, "phase": "train", "update": 219, "total_env_steps": 700800, "episode_reward": 0.15972216427326202, "value_loss": 0.031080207601189614, "policy_loss": -0.0013251341934726213, "dist_entropy": 1.0211906909942627, "actor_grad_norm": 0.09752539545297623, "critic_grad_norm": 0.18629126250743866, "ratio": 0.999904453754425, "entropy": 1.0211906909942627, "incre_win_rate": 0.0, "step": 219}
{"time": 1767078401.0154686, "phase": "train", "update": 220, "total_env_steps": 704000, "episode_reward": 0.15096907317638397, "value_loss": 0.028787142410874367, "policy_loss": -0.0012644386320634026, "dist_entropy": 1.00156272649765, "actor_grad_norm": 0.09606803953647614, "critic_grad_norm": 0.14613932371139526, "ratio": 1.0002154111862183, "entropy": 1.00156272649765, "incre_win_rate": 0.0, "step": 220}
{"time": 1767078405.3775692, "phase": "train", "update": 221, "total_env_steps": 707200, "episode_reward": 0.15717042982578278, "value_loss": 0.030490797013044357, "policy_loss": -0.0012670205732032258, "dist_entropy": 1.012272310256958, "actor_grad_norm": 0.09690453112125397, "critic_grad_norm": 0.256603479385376, "ratio": 0.999642550945282, "entropy": 1.012272310256958, "incre_win_rate": 0.0, "step": 221}
{"time": 1767078417.2431102, "phase": "eval", "update": 221, "total_env_steps": 707200, "eval_win_rate": 0.0, "eval_episode_reward": 11.90780215231787, "step": 221}
{"time": 1767078421.610612, "phase": "train", "update": 222, "total_env_steps": 710400, "episode_reward": 0.13119308650493622, "value_loss": 0.03238560184836388, "policy_loss": -0.0016329871860110146, "dist_entropy": 1.0486516952514648, "actor_grad_norm": 0.09794960170984268, "critic_grad_norm": 0.17743010818958282, "ratio": 1.0001009702682495, "entropy": 1.0486516952514648, "incre_win_rate": 0.0, "step": 222}
{"time": 1767078426.0828567, "phase": "train", "update": 223, "total_env_steps": 713600, "episode_reward": 0.17392848432064056, "value_loss": 0.0330889455974102, "policy_loss": -0.0017374517884205076, "dist_entropy": 1.0422187566757202, "actor_grad_norm": 0.11152110248804092, "critic_grad_norm": 0.18510960042476654, "ratio": 0.999916672706604, "entropy": 1.0422187566757202, "incre_win_rate": 0.0, "step": 223}
{"time": 1767078430.4027562, "phase": "train", "update": 224, "total_env_steps": 716800, "episode_reward": 0.14236080646514893, "value_loss": 0.03885107710957527, "policy_loss": -0.0012979876820011782, "dist_entropy": 1.0463752269744873, "actor_grad_norm": 0.09684435278177261, "critic_grad_norm": 0.29804590344429016, "ratio": 0.9999203085899353, "entropy": 1.0463752269744873, "incre_win_rate": 0.0, "step": 224}
{"time": 1767078434.8774953, "phase": "train", "update": 225, "total_env_steps": 720000, "episode_reward": 0.1648680716753006, "value_loss": 0.031404000520706174, "policy_loss": -0.000959076622638122, "dist_entropy": 1.0723575115203858, "actor_grad_norm": 0.10524106025695801, "critic_grad_norm": 0.1531941145658493, "ratio": 1.000038504600525, "entropy": 1.0723575115203858, "incre_win_rate": 0.0, "step": 225}
{"time": 1767078439.1819546, "phase": "train", "update": 226, "total_env_steps": 723200, "episode_reward": 0.1288565844297409, "value_loss": 0.036326447129249574, "policy_loss": -0.0018869874618522076, "dist_entropy": 1.0817636966705322, "actor_grad_norm": 0.11233387142419815, "critic_grad_norm": 0.14357928931713104, "ratio": 0.9997414946556091, "entropy": 1.0817636966705322, "incre_win_rate": 0.0, "step": 226}
{"time": 1767078443.5318077, "phase": "train", "update": 227, "total_env_steps": 726400, "episode_reward": 0.13866876065731049, "value_loss": 0.04066941887140274, "policy_loss": -0.0022111119345865405, "dist_entropy": 1.0916218042373658, "actor_grad_norm": 0.14750806987285614, "critic_grad_norm": 0.13686345517635345, "ratio": 1.0000966787338257, "entropy": 1.0916218042373658, "incre_win_rate": 0.0, "step": 227}
{"time": 1767078447.9631898, "phase": "train", "update": 228, "total_env_steps": 729600, "episode_reward": 0.14528146386146545, "value_loss": 0.02529403455555439, "policy_loss": -0.0017164620964280175, "dist_entropy": 1.0524150609970093, "actor_grad_norm": 0.11334194988012314, "critic_grad_norm": 0.10458401590585709, "ratio": 1.0000778436660767, "entropy": 1.0524150609970093, "incre_win_rate": 0.0, "step": 228}
{"time": 1767078452.3955796, "phase": "train", "update": 229, "total_env_steps": 732800, "episode_reward": 0.1559804528951645, "value_loss": 0.029143627732992172, "policy_loss": -0.001734059017940992, "dist_entropy": 1.0817375183105469, "actor_grad_norm": 0.11008483171463013, "critic_grad_norm": 0.08717245608568192, "ratio": 0.9996922612190247, "entropy": 1.0817375183105469, "incre_win_rate": 0.0, "step": 229}
{"time": 1767078456.872187, "phase": "train", "update": 230, "total_env_steps": 736000, "episode_reward": 0.1544179469347, "value_loss": 0.025874019786715507, "policy_loss": -0.001326324515017241, "dist_entropy": 1.058406925201416, "actor_grad_norm": 0.11598920077085495, "critic_grad_norm": 0.04959695413708687, "ratio": 0.9997772574424744, "entropy": 1.058406925201416, "incre_win_rate": 0.0, "step": 230}
{"time": 1767078461.2653334, "phase": "train", "update": 231, "total_env_steps": 739200, "episode_reward": 0.14617860317230225, "value_loss": 0.02944990210235119, "policy_loss": -0.0014277659108396178, "dist_entropy": 1.0604728221893311, "actor_grad_norm": 0.10356272757053375, "critic_grad_norm": 0.056273799389600754, "ratio": 0.9999767541885376, "entropy": 1.0604728221893311, "incre_win_rate": 0.0, "step": 231}
{"time": 1767078465.6403186, "phase": "train", "update": 232, "total_env_steps": 742400, "episode_reward": 0.13800650835037231, "value_loss": 0.02796197198331356, "policy_loss": -0.0014177879197546871, "dist_entropy": 1.0479985475540161, "actor_grad_norm": 0.10236383974552155, "critic_grad_norm": 0.1442541927099228, "ratio": 1.0000554323196411, "entropy": 1.0479985475540161, "incre_win_rate": 0.0, "step": 232}
{"time": 1767078470.0408149, "phase": "train", "update": 233, "total_env_steps": 745600, "episode_reward": 0.14704056084156036, "value_loss": 0.033071118593215945, "policy_loss": -0.0015210087422108387, "dist_entropy": 1.0699620962142944, "actor_grad_norm": 0.1334022730588913, "critic_grad_norm": 0.11320137232542038, "ratio": 1.0001049041748047, "entropy": 1.0699620962142944, "incre_win_rate": 0.0, "step": 233}
{"time": 1767078474.4586914, "phase": "train", "update": 234, "total_env_steps": 748800, "episode_reward": 0.13340698182582855, "value_loss": 0.035688767582178114, "policy_loss": -0.0016385757109368625, "dist_entropy": 1.0621076345443725, "actor_grad_norm": 0.1072688028216362, "critic_grad_norm": 0.16697369515895844, "ratio": 0.9998656511306763, "entropy": 1.0621076345443725, "incre_win_rate": 0.0, "step": 234}
{"time": 1767078478.769574, "phase": "train", "update": 235, "total_env_steps": 752000, "episode_reward": 0.1296626627445221, "value_loss": 0.034096626192331315, "policy_loss": -0.0018914437479018887, "dist_entropy": 1.0481699705123901, "actor_grad_norm": 0.10894657671451569, "critic_grad_norm": 0.0756976529955864, "ratio": 1.0000314712524414, "entropy": 1.0481699705123901, "incre_win_rate": 0.0, "step": 235}
{"time": 1767078483.0809839, "phase": "train", "update": 236, "total_env_steps": 755200, "episode_reward": 0.13209901750087738, "value_loss": 0.02398572601377964, "policy_loss": -0.002422100056125487, "dist_entropy": 1.022486925125122, "actor_grad_norm": 0.11237867176532745, "critic_grad_norm": 0.09013473242521286, "ratio": 1.0002683401107788, "entropy": 1.022486925125122, "incre_win_rate": 0.0, "step": 236}
{"time": 1767078487.4844947, "phase": "train", "update": 237, "total_env_steps": 758400, "episode_reward": 0.12616772949695587, "value_loss": 0.024209673330187798, "policy_loss": -0.0023569008995210083, "dist_entropy": 1.0104666948318481, "actor_grad_norm": 0.12368281185626984, "critic_grad_norm": 0.05468875914812088, "ratio": 0.99977046251297, "entropy": 1.0104666948318481, "incre_win_rate": 0.0, "step": 237}
{"time": 1767078491.7495987, "phase": "train", "update": 238, "total_env_steps": 761600, "episode_reward": 0.11784147471189499, "value_loss": 0.028661418333649637, "policy_loss": -0.0023250057255609136, "dist_entropy": 1.0134227991104126, "actor_grad_norm": 0.13528279960155487, "critic_grad_norm": 0.051078297197818756, "ratio": 1.0004572868347168, "entropy": 1.0134227991104126, "incre_win_rate": 0.0, "step": 238}
{"time": 1767078495.9959166, "phase": "train", "update": 239, "total_env_steps": 764800, "episode_reward": 0.12051272392272949, "value_loss": 0.02819557562470436, "policy_loss": -0.0015770185823051007, "dist_entropy": 0.9976282835006713, "actor_grad_norm": 0.1406812220811844, "critic_grad_norm": 0.05325780063867569, "ratio": 1.0001556873321533, "entropy": 0.9976282835006713, "incre_win_rate": 0.0, "step": 239}
{"time": 1767078500.2480974, "phase": "train", "update": 240, "total_env_steps": 768000, "episode_reward": 0.12024524062871933, "value_loss": 0.03169439323246479, "policy_loss": -0.0020627006690656204, "dist_entropy": 1.0097013473510743, "actor_grad_norm": 0.1581946462392807, "critic_grad_norm": 0.06618919223546982, "ratio": 0.9997555017471313, "entropy": 1.0097013473510743, "incre_win_rate": 0.0, "step": 240}
{"time": 1767078504.4959373, "phase": "train", "update": 241, "total_env_steps": 771200, "episode_reward": 0.1139693632721901, "value_loss": 0.025567405670881272, "policy_loss": -0.002232969999300849, "dist_entropy": 1.0187535285949707, "actor_grad_norm": 0.13940586149692535, "critic_grad_norm": 0.045178648084402084, "ratio": 1.0002202987670898, "entropy": 1.0187535285949707, "incre_win_rate": 0.0, "step": 241}
{"time": 1767078517.3452559, "phase": "eval", "update": 241, "total_env_steps": 771200, "eval_win_rate": 0.0, "eval_episode_reward": 11.630536009933767, "step": 241}
{"time": 1767078521.6354704, "phase": "train", "update": 242, "total_env_steps": 774400, "episode_reward": 0.12258639931678772, "value_loss": 0.024360578507184982, "policy_loss": -0.0017022382039354467, "dist_entropy": 1.0197859764099122, "actor_grad_norm": 0.1245952770113945, "critic_grad_norm": 0.03924362733960152, "ratio": 0.9998894929885864, "entropy": 1.0197859764099122, "incre_win_rate": 0.0, "step": 242}
{"time": 1767078526.0084667, "phase": "train", "update": 243, "total_env_steps": 777600, "episode_reward": 0.1367565095424652, "value_loss": 0.023110466822981835, "policy_loss": -0.0020964109566360633, "dist_entropy": 0.9941158533096314, "actor_grad_norm": 0.12454875558614731, "critic_grad_norm": 0.05666917562484741, "ratio": 1.0000675916671753, "entropy": 0.9941158533096314, "incre_win_rate": 0.0, "step": 243}
{"time": 1767078530.1854994, "phase": "train", "update": 244, "total_env_steps": 780800, "episode_reward": 0.1068403422832489, "value_loss": 0.019098767638206483, "policy_loss": -0.001885695240351737, "dist_entropy": 0.9659917950630188, "actor_grad_norm": 0.15100470185279846, "critic_grad_norm": 0.08071739971637726, "ratio": 0.9995549321174622, "entropy": 0.9659917950630188, "incre_win_rate": 0.0, "step": 244}
{"time": 1767078534.3282373, "phase": "train", "update": 245, "total_env_steps": 784000, "episode_reward": 0.10433360934257507, "value_loss": 0.01968103349208832, "policy_loss": -0.002071177938451996, "dist_entropy": 0.9891041159629822, "actor_grad_norm": 0.12718820571899414, "critic_grad_norm": 0.07576560229063034, "ratio": 0.9997687339782715, "entropy": 0.9891041159629822, "incre_win_rate": 0.0, "step": 245}
{"time": 1767078538.5750933, "phase": "train", "update": 246, "total_env_steps": 787200, "episode_reward": 0.1178942397236824, "value_loss": 0.019171322509646416, "policy_loss": -0.001984644239568212, "dist_entropy": 1.0110974550247191, "actor_grad_norm": 0.14180408418178558, "critic_grad_norm": 0.17312957346439362, "ratio": 0.9997588396072388, "entropy": 1.0110974550247191, "incre_win_rate": 0.0, "step": 246}
{"time": 1767078542.7338333, "phase": "train", "update": 247, "total_env_steps": 790400, "episode_reward": 0.10214144736528397, "value_loss": 0.01536064688116312, "policy_loss": -0.002046995426012188, "dist_entropy": 0.9955581665039063, "actor_grad_norm": 0.11693055927753448, "critic_grad_norm": 0.1378200352191925, "ratio": 0.9998106956481934, "entropy": 0.9955581665039063, "incre_win_rate": 0.0, "step": 247}
{"time": 1767078547.017033, "phase": "train", "update": 248, "total_env_steps": 793600, "episode_reward": 0.11920063942670822, "value_loss": 0.01834099553525448, "policy_loss": -0.0013802788955338484, "dist_entropy": 1.001218819618225, "actor_grad_norm": 0.14253221452236176, "critic_grad_norm": 0.1120852455496788, "ratio": 0.9997002482414246, "entropy": 1.001218819618225, "incre_win_rate": 0.0, "step": 248}
{"time": 1767078551.2059937, "phase": "train", "update": 249, "total_env_steps": 796800, "episode_reward": 0.11011692881584167, "value_loss": 0.018385697156190872, "policy_loss": -0.0021445677138075326, "dist_entropy": 0.9999164462089538, "actor_grad_norm": 0.1379367560148239, "critic_grad_norm": 0.07308334857225418, "ratio": 1.0000511407852173, "entropy": 0.9999164462089538, "incre_win_rate": 0.0, "step": 249}
{"time": 1767078555.4160564, "phase": "train", "update": 250, "total_env_steps": 800000, "episode_reward": 0.1077488586306572, "value_loss": 0.01655356027185917, "policy_loss": -0.0022867012699885336, "dist_entropy": 0.9737164855003357, "actor_grad_norm": 0.16586123406887054, "critic_grad_norm": 0.09466078132390976, "ratio": 0.9999054074287415, "entropy": 0.9737164855003357, "incre_win_rate": 0.0, "step": 250}
{"time": 1767078559.516738, "phase": "train", "update": 251, "total_env_steps": 803200, "episode_reward": 0.09812500327825546, "value_loss": 0.012667949870228767, "policy_loss": -0.002361868039651682, "dist_entropy": 0.9649269938468933, "actor_grad_norm": 0.165572389960289, "critic_grad_norm": 0.0667225643992424, "ratio": 1.0001391172409058, "entropy": 0.9649269938468933, "incre_win_rate": 0.0, "step": 251}
{"time": 1767078563.6325302, "phase": "train", "update": 252, "total_env_steps": 806400, "episode_reward": 0.09584283083677292, "value_loss": 0.013215947523713112, "policy_loss": -0.0027534278919120413, "dist_entropy": 0.9495441555976868, "actor_grad_norm": 0.14692990481853485, "critic_grad_norm": 0.03330530598759651, "ratio": 0.999822735786438, "entropy": 0.9495441555976868, "incre_win_rate": 0.0, "step": 252}
{"time": 1767078567.8621476, "phase": "train", "update": 253, "total_env_steps": 809600, "episode_reward": 0.10915355384349823, "value_loss": 0.01370277814567089, "policy_loss": -0.002206430678816318, "dist_entropy": 0.9466909050941468, "actor_grad_norm": 0.12641464173793793, "critic_grad_norm": 0.05427730083465576, "ratio": 0.9998680353164673, "entropy": 0.9466909050941468, "incre_win_rate": 0.0, "step": 253}
{"time": 1767078571.892978, "phase": "train", "update": 254, "total_env_steps": 812800, "episode_reward": 0.0862148255109787, "value_loss": 0.013810081221163274, "policy_loss": -0.0026468719849560784, "dist_entropy": 0.9584288597106934, "actor_grad_norm": 0.1505245715379715, "critic_grad_norm": 0.14278315007686615, "ratio": 1.0000241994857788, "entropy": 0.9584288597106934, "incre_win_rate": 0.0, "step": 254}
{"time": 1767078576.0212348, "phase": "train", "update": 255, "total_env_steps": 816000, "episode_reward": 0.08539734780788422, "value_loss": 0.01589046698063612, "policy_loss": -0.0018018416541679017, "dist_entropy": 0.9270228028297425, "actor_grad_norm": 0.13855044543743134, "critic_grad_norm": 0.1449519395828247, "ratio": 0.9998540878295898, "entropy": 0.9270228028297425, "incre_win_rate": 0.0, "step": 255}
{"time": 1767078580.0945432, "phase": "train", "update": 256, "total_env_steps": 819200, "episode_reward": 0.09010295569896698, "value_loss": 0.013875805027782916, "policy_loss": -0.0018242370146027477, "dist_entropy": 0.9577308297157288, "actor_grad_norm": 0.14331762492656708, "critic_grad_norm": 0.11716900020837784, "ratio": 1.000106692314148, "entropy": 0.9577308297157288, "incre_win_rate": 0.0, "step": 256}
{"time": 1767078584.2215395, "phase": "train", "update": 257, "total_env_steps": 822400, "episode_reward": 0.09512469172477722, "value_loss": 0.012251835130155087, "policy_loss": -0.0017772399683657625, "dist_entropy": 0.9467128276824951, "actor_grad_norm": 0.13812048733234406, "critic_grad_norm": 0.06360846012830734, "ratio": 0.9996985793113708, "entropy": 0.9467128276824951, "incre_win_rate": 0.0, "step": 257}
{"time": 1767078588.182378, "phase": "train", "update": 258, "total_env_steps": 825600, "episode_reward": 0.07663079351186752, "value_loss": 0.012074179947376251, "policy_loss": -0.0023556890626622363, "dist_entropy": 0.9526082396507263, "actor_grad_norm": 0.13534513115882874, "critic_grad_norm": 0.036241315305233, "ratio": 1.0000312328338623, "entropy": 0.9526082396507263, "incre_win_rate": 0.0, "step": 258}
{"time": 1767078592.3072863, "phase": "train", "update": 259, "total_env_steps": 828800, "episode_reward": 0.09029439091682434, "value_loss": 0.012697934359312057, "policy_loss": -0.0022301886978610243, "dist_entropy": 0.9421348929405212, "actor_grad_norm": 0.12102049589157104, "critic_grad_norm": 0.05401027947664261, "ratio": 0.9998480677604675, "entropy": 0.9421348929405212, "incre_win_rate": 0.0, "step": 259}
{"time": 1767078596.374644, "phase": "train", "update": 260, "total_env_steps": 832000, "episode_reward": 0.08189621567726135, "value_loss": 0.013499690406024455, "policy_loss": -0.0024023849053936173, "dist_entropy": 0.948622715473175, "actor_grad_norm": 0.13202643394470215, "critic_grad_norm": 0.042009975761175156, "ratio": 0.9999394416809082, "entropy": 0.948622715473175, "incre_win_rate": 0.0, "step": 260}
{"time": 1767078600.5318637, "phase": "train", "update": 261, "total_env_steps": 835200, "episode_reward": 0.08938121795654297, "value_loss": 0.011063743941485881, "policy_loss": -0.0022775558471680667, "dist_entropy": 0.941503393650055, "actor_grad_norm": 0.12504032254219055, "critic_grad_norm": 0.10193973034620285, "ratio": 0.9998598098754883, "entropy": 0.941503393650055, "incre_win_rate": 0.0, "step": 261}
{"time": 1767078615.1435204, "phase": "eval", "update": 261, "total_env_steps": 835200, "eval_win_rate": 0.0, "eval_episode_reward": 9.51102028145694, "step": 261}
{"time": 1767078619.3100302, "phase": "train", "update": 262, "total_env_steps": 838400, "episode_reward": 0.08788751810789108, "value_loss": 0.011170566827058793, "policy_loss": -0.0024832717321523036, "dist_entropy": 0.9341390252113342, "actor_grad_norm": 0.1682199090719223, "critic_grad_norm": 0.10015533119440079, "ratio": 1.0000383853912354, "entropy": 0.9341390252113342, "incre_win_rate": 0.0, "step": 262}
{"time": 1767078623.3923283, "phase": "train", "update": 263, "total_env_steps": 841600, "episode_reward": 0.07936620712280273, "value_loss": 0.010229813121259212, "policy_loss": -0.0038810596396587015, "dist_entropy": 0.8952398300170898, "actor_grad_norm": 0.16485339403152466, "critic_grad_norm": 0.05303492769598961, "ratio": 1.0001394748687744, "entropy": 0.8952398300170898, "incre_win_rate": 0.0, "step": 263}
{"time": 1767078627.5141392, "phase": "train", "update": 264, "total_env_steps": 844800, "episode_reward": 0.09576314687728882, "value_loss": 0.011847135610878468, "policy_loss": -0.002576196440875833, "dist_entropy": 0.8733692765235901, "actor_grad_norm": 0.14708402752876282, "critic_grad_norm": 0.02189016528427601, "ratio": 1.0001530647277832, "entropy": 0.8733692765235901, "incre_win_rate": 0.0, "step": 264}
{"time": 1767078631.6114306, "phase": "train", "update": 265, "total_env_steps": 848000, "episode_reward": 0.07847785204648972, "value_loss": 0.009523510560393333, "policy_loss": -0.0030494158379852365, "dist_entropy": 0.849970006942749, "actor_grad_norm": 0.1798841804265976, "critic_grad_norm": 0.030700519680976868, "ratio": 0.9999803900718689, "entropy": 0.849970006942749, "incre_win_rate": 0.0, "step": 265}
{"time": 1767078635.8177016, "phase": "train", "update": 266, "total_env_steps": 851200, "episode_reward": 0.09399058669805527, "value_loss": 0.012437494099140167, "policy_loss": -0.001695487520533212, "dist_entropy": 0.8744648098945618, "actor_grad_norm": 0.1839383840560913, "critic_grad_norm": 0.022703243419528008, "ratio": 0.9996504187583923, "entropy": 0.8744648098945618, "incre_win_rate": 0.0, "step": 266}
{"time": 1767078640.0208993, "phase": "train", "update": 267, "total_env_steps": 854400, "episode_reward": 0.09219422191381454, "value_loss": 0.011911838687956334, "policy_loss": -0.0021989840842053356, "dist_entropy": 0.8324487447738648, "actor_grad_norm": 0.11788000166416168, "critic_grad_norm": 0.045159898698329926, "ratio": 1.000100016593933, "entropy": 0.8324487447738648, "incre_win_rate": 0.0, "step": 267}
{"time": 1767078644.1707726, "phase": "train", "update": 268, "total_env_steps": 857600, "episode_reward": 0.08289166539907455, "value_loss": 0.011892728880047799, "policy_loss": -0.0024889027876227486, "dist_entropy": 0.8329633355140686, "actor_grad_norm": 0.16054324805736542, "critic_grad_norm": 0.08606687188148499, "ratio": 1.0001888275146484, "entropy": 0.8329633355140686, "incre_win_rate": 0.0, "step": 268}
{"time": 1767078648.3909469, "phase": "train", "update": 269, "total_env_steps": 860800, "episode_reward": 0.10279128700494766, "value_loss": 0.012528758496046066, "policy_loss": -0.001955725785639739, "dist_entropy": 0.8307940721511841, "actor_grad_norm": 0.12962286174297333, "critic_grad_norm": 0.06351755559444427, "ratio": 1.000104308128357, "entropy": 0.8307940721511841, "incre_win_rate": 0.0, "step": 269}
{"time": 1767078652.5698144, "phase": "train", "update": 270, "total_env_steps": 864000, "episode_reward": 0.09538648277521133, "value_loss": 0.011530270427465438, "policy_loss": -0.002264155375832644, "dist_entropy": 0.8498754501342773, "actor_grad_norm": 0.1662876307964325, "critic_grad_norm": 0.04566890746355057, "ratio": 1.0000261068344116, "entropy": 0.8498754501342773, "incre_win_rate": 0.0, "step": 270}
{"time": 1767078656.7038505, "phase": "train", "update": 271, "total_env_steps": 867200, "episode_reward": 0.08999017626047134, "value_loss": 0.010540410690009595, "policy_loss": -0.002847948260636457, "dist_entropy": 0.8352357864379882, "actor_grad_norm": 0.13625554740428925, "critic_grad_norm": 0.03999217972159386, "ratio": 1.000165343284607, "entropy": 0.8352357864379882, "incre_win_rate": 0.0, "step": 271}
{"time": 1767078660.8838897, "phase": "train", "update": 272, "total_env_steps": 870400, "episode_reward": 0.0941416546702385, "value_loss": 0.013159400969743728, "policy_loss": -0.0026421792938517543, "dist_entropy": 0.8154856085777282, "actor_grad_norm": 0.1390540599822998, "critic_grad_norm": 0.052953846752643585, "ratio": 0.9995748400688171, "entropy": 0.8154856085777282, "incre_win_rate": 0.0, "step": 272}
{"time": 1767078665.025901, "phase": "train", "update": 273, "total_env_steps": 873600, "episode_reward": 0.0914171114563942, "value_loss": 0.009124466590583325, "policy_loss": -0.0025222110447451485, "dist_entropy": 0.8191737294197082, "actor_grad_norm": 0.15584297478199005, "critic_grad_norm": 0.06386714428663254, "ratio": 0.9995723962783813, "entropy": 0.8191737294197082, "incre_win_rate": 0.0, "step": 273}
{"time": 1767078669.2417214, "phase": "train", "update": 274, "total_env_steps": 876800, "episode_reward": 0.09360875934362411, "value_loss": 0.010354675352573395, "policy_loss": -0.0021825089189817957, "dist_entropy": 0.8053793787956238, "actor_grad_norm": 0.1159353032708168, "critic_grad_norm": 0.042163997888565063, "ratio": 0.9999372363090515, "entropy": 0.8053793787956238, "incre_win_rate": 0.0, "step": 274}
{"time": 1767078673.4325068, "phase": "train", "update": 275, "total_env_steps": 880000, "episode_reward": 0.08466370403766632, "value_loss": 0.00948200523853302, "policy_loss": -0.002465432953568758, "dist_entropy": 0.8046679854393005, "actor_grad_norm": 0.14087644219398499, "critic_grad_norm": 0.07738252729177475, "ratio": 0.9998869299888611, "entropy": 0.8046679854393005, "incre_win_rate": 0.0, "step": 275}
{"time": 1767078677.6272228, "phase": "train", "update": 276, "total_env_steps": 883200, "episode_reward": 0.09295892715454102, "value_loss": 0.00893758237361908, "policy_loss": -0.0021639895212331338, "dist_entropy": 0.7868030190467834, "actor_grad_norm": 0.11930445581674576, "critic_grad_norm": 0.05772259458899498, "ratio": 0.9997838139533997, "entropy": 0.7868030190467834, "incre_win_rate": 0.0, "step": 276}
{"time": 1767078681.8078775, "phase": "train", "update": 277, "total_env_steps": 886400, "episode_reward": 0.08842664957046509, "value_loss": 0.008868339471518993, "policy_loss": -0.0024212802146273303, "dist_entropy": 0.7921542286872864, "actor_grad_norm": 0.13517169654369354, "critic_grad_norm": 0.03889313340187073, "ratio": 0.9995094537734985, "entropy": 0.7921542286872864, "incre_win_rate": 0.0, "step": 277}
{"time": 1767078685.9080274, "phase": "train", "update": 278, "total_env_steps": 889600, "episode_reward": 0.08209488540887833, "value_loss": 0.010529729537665844, "policy_loss": -0.0024874688375973618, "dist_entropy": 0.7886593818664551, "actor_grad_norm": 0.14157725870609283, "critic_grad_norm": 0.11028850078582764, "ratio": 1.0002987384796143, "entropy": 0.7886593818664551, "incre_win_rate": 0.0, "step": 278}
{"time": 1767078690.1169538, "phase": "train", "update": 279, "total_env_steps": 892800, "episode_reward": 0.09226562827825546, "value_loss": 0.010089645721018314, "policy_loss": -0.002593920207144862, "dist_entropy": 0.7835447788238525, "actor_grad_norm": 0.158686563372612, "critic_grad_norm": 0.07804020494222641, "ratio": 1.0003262758255005, "entropy": 0.7835447788238525, "incre_win_rate": 0.0, "step": 279}
{"time": 1767078694.2631342, "phase": "train", "update": 280, "total_env_steps": 896000, "episode_reward": 0.08777731657028198, "value_loss": 0.009876415319740772, "policy_loss": -0.0016514209344492769, "dist_entropy": 0.7903907656669616, "actor_grad_norm": 0.15212254226207733, "critic_grad_norm": 0.09232544898986816, "ratio": 1.0001801252365112, "entropy": 0.7903907656669616, "incre_win_rate": 0.0, "step": 280}
{"time": 1767078698.4143827, "phase": "train", "update": 281, "total_env_steps": 899200, "episode_reward": 0.07992032915353775, "value_loss": 0.009113678894937038, "policy_loss": -0.0019330053433961325, "dist_entropy": 0.7690959692001342, "actor_grad_norm": 0.1729133576154709, "critic_grad_norm": 0.04981466755270958, "ratio": 0.9998161196708679, "entropy": 0.7690959692001342, "incre_win_rate": 0.0, "step": 281}
{"time": 1767078714.6472478, "phase": "eval", "update": 281, "total_env_steps": 899200, "eval_win_rate": 0.0, "eval_episode_reward": 10.333661009933762, "step": 281}
{"time": 1767078718.8734972, "phase": "train", "update": 282, "total_env_steps": 902400, "episode_reward": 0.08337490260601044, "value_loss": 0.010003549605607986, "policy_loss": -0.0025273010898224867, "dist_entropy": 0.7727746844291687, "actor_grad_norm": 0.1633041352033615, "critic_grad_norm": 0.05741668865084648, "ratio": 1.0000652074813843, "entropy": 0.7727746844291687, "incre_win_rate": 0.0, "step": 282}
{"time": 1767078723.1437538, "phase": "train", "update": 283, "total_env_steps": 905600, "episode_reward": 0.08789734542369843, "value_loss": 0.012231943011283875, "policy_loss": -0.0026500872621183723, "dist_entropy": 0.7798097848892211, "actor_grad_norm": 0.13092468678951263, "critic_grad_norm": 0.07072269171476364, "ratio": 1.0001529455184937, "entropy": 0.7798097848892211, "incre_win_rate": 0.0, "step": 283}
{"time": 1767078727.4614022, "phase": "train", "update": 284, "total_env_steps": 908800, "episode_reward": 0.07180359959602356, "value_loss": 0.009604081697762012, "policy_loss": -0.002446872914278231, "dist_entropy": 0.7456801295280456, "actor_grad_norm": 0.1364877074956894, "critic_grad_norm": 0.03983850032091141, "ratio": 0.9998748898506165, "entropy": 0.7456801295280456, "incre_win_rate": 0.0, "step": 284}
{"time": 1767078731.785764, "phase": "train", "update": 285, "total_env_steps": 912000, "episode_reward": 0.08497050404548645, "value_loss": 0.010194715671241283, "policy_loss": -0.002958653943610301, "dist_entropy": 0.7711117506027222, "actor_grad_norm": 0.1541328877210617, "critic_grad_norm": 0.057392966002225876, "ratio": 0.9999637603759766, "entropy": 0.7711117506027222, "incre_win_rate": 0.0, "step": 285}
{"time": 1767078736.1020236, "phase": "train", "update": 286, "total_env_steps": 915200, "episode_reward": 0.0774751678109169, "value_loss": 0.00953643824905157, "policy_loss": -0.0026645471909517936, "dist_entropy": 0.7471384286880494, "actor_grad_norm": 0.19359274208545685, "critic_grad_norm": 0.09351161867380142, "ratio": 0.9998430609703064, "entropy": 0.7471384286880494, "incre_win_rate": 0.0, "step": 286}
{"time": 1767078740.4624681, "phase": "train", "update": 287, "total_env_steps": 918400, "episode_reward": 0.07497413456439972, "value_loss": 0.008146479912102222, "policy_loss": -0.0014870032323255344, "dist_entropy": 0.7594936966896058, "actor_grad_norm": 0.13568982481956482, "critic_grad_norm": 0.08365221321582794, "ratio": 0.9998060464859009, "entropy": 0.7594936966896058, "incre_win_rate": 0.0, "step": 287}
{"time": 1767078744.5992875, "phase": "train", "update": 288, "total_env_steps": 921600, "episode_reward": 0.08109477907419205, "value_loss": 0.008461985923349857, "policy_loss": -0.0022898615255755317, "dist_entropy": 0.7447136640548706, "actor_grad_norm": 0.1524551659822464, "critic_grad_norm": 0.0435846783220768, "ratio": 1.000120759010315, "entropy": 0.7447136640548706, "incre_win_rate": 0.0, "step": 288}
{"time": 1767078748.6557796, "phase": "train", "update": 289, "total_env_steps": 924800, "episode_reward": 0.07480649650096893, "value_loss": 0.0071231241337955, "policy_loss": -0.0014215088577401503, "dist_entropy": 0.75409836769104, "actor_grad_norm": 0.12009374052286148, "critic_grad_norm": 0.05880153924226761, "ratio": 0.9999310374259949, "entropy": 0.75409836769104, "incre_win_rate": 0.0, "step": 289}
{"time": 1767078752.9719522, "phase": "train", "update": 290, "total_env_steps": 928000, "episode_reward": 0.07448727637529373, "value_loss": 0.008713425323367118, "policy_loss": -0.001952186388019328, "dist_entropy": 0.7251774787902832, "actor_grad_norm": 0.12613266706466675, "critic_grad_norm": 0.0797116830945015, "ratio": 0.9999635815620422, "entropy": 0.7251774787902832, "incre_win_rate": 0.0, "step": 290}
{"time": 1767078757.062981, "phase": "train", "update": 291, "total_env_steps": 931200, "episode_reward": 0.06449814140796661, "value_loss": 0.007202403340488672, "policy_loss": -0.002390900971106191, "dist_entropy": 0.7517112374305726, "actor_grad_norm": 0.15825127065181732, "critic_grad_norm": 0.06410213559865952, "ratio": 0.9995220303535461, "entropy": 0.7517112374305726, "incre_win_rate": 0.0, "step": 291}
{"time": 1767078761.1777418, "phase": "train", "update": 292, "total_env_steps": 934400, "episode_reward": 0.07819071412086487, "value_loss": 0.007252050191164016, "policy_loss": -0.002533317540170543, "dist_entropy": 0.7387919545173645, "actor_grad_norm": 0.1289191097021103, "critic_grad_norm": 0.04913746193051338, "ratio": 1.0002225637435913, "entropy": 0.7387919545173645, "incre_win_rate": 0.0, "step": 292}
{"time": 1767078765.3013067, "phase": "train", "update": 293, "total_env_steps": 937600, "episode_reward": 0.0670866072177887, "value_loss": 0.005874509736895561, "policy_loss": -0.0018965342802386154, "dist_entropy": 0.7090542674064636, "actor_grad_norm": 0.1352267563343048, "critic_grad_norm": 0.03674493730068207, "ratio": 0.9998895525932312, "entropy": 0.7090542674064636, "incre_win_rate": 0.0, "step": 293}
{"time": 1767078769.6874142, "phase": "train", "update": 294, "total_env_steps": 940800, "episode_reward": 0.0692140981554985, "value_loss": 0.007202387042343617, "policy_loss": -0.0020557182924139995, "dist_entropy": 0.7204387545585632, "actor_grad_norm": 0.1464662253856659, "critic_grad_norm": 0.030662113800644875, "ratio": 1.0004180669784546, "entropy": 0.7204387545585632, "incre_win_rate": 0.0, "step": 294}
{"time": 1767078774.270753, "phase": "train", "update": 295, "total_env_steps": 944000, "episode_reward": 0.07838782668113708, "value_loss": 0.007311971299350262, "policy_loss": -0.0026684794880821984, "dist_entropy": 0.7424660682678222, "actor_grad_norm": 0.17949886620044708, "critic_grad_norm": 0.020594660192728043, "ratio": 0.9997895359992981, "entropy": 0.7424660682678222, "incre_win_rate": 0.0, "step": 295}
{"time": 1767078778.476896, "phase": "train", "update": 296, "total_env_steps": 947200, "episode_reward": 0.07099027931690216, "value_loss": 0.006433283444494009, "policy_loss": -0.00183959061436747, "dist_entropy": 0.7547042846679688, "actor_grad_norm": 0.12202375382184982, "critic_grad_norm": 0.03731648996472359, "ratio": 0.9999077916145325, "entropy": 0.7547042846679688, "incre_win_rate": 0.0, "step": 296}
{"time": 1767078782.6933243, "phase": "train", "update": 297, "total_env_steps": 950400, "episode_reward": 0.07142695039510727, "value_loss": 0.0062232489697635176, "policy_loss": -0.00225592350392958, "dist_entropy": 0.7502049922943115, "actor_grad_norm": 0.18216834962368011, "critic_grad_norm": 0.038872458040714264, "ratio": 1.000301718711853, "entropy": 0.7502049922943115, "incre_win_rate": 0.0, "step": 297}
{"time": 1767078786.7883062, "phase": "train", "update": 298, "total_env_steps": 953600, "episode_reward": 0.06684395670890808, "value_loss": 0.005930957198143005, "policy_loss": -0.002318638571656706, "dist_entropy": 0.7176759839057922, "actor_grad_norm": 0.15529580414295197, "critic_grad_norm": 0.037228379398584366, "ratio": 0.999638557434082, "entropy": 0.7176759839057922, "incre_win_rate": 0.0, "step": 298}
{"time": 1767078790.8703032, "phase": "train", "update": 299, "total_env_steps": 956800, "episode_reward": 0.0631762221455574, "value_loss": 0.0052360700443387035, "policy_loss": -0.0025765893271287865, "dist_entropy": 0.7603313088417053, "actor_grad_norm": 0.14414627850055695, "critic_grad_norm": 0.04485094174742699, "ratio": 0.9998134970664978, "entropy": 0.7603313088417053, "incre_win_rate": 0.0, "step": 299}
{"time": 1767078795.0219707, "phase": "train", "update": 300, "total_env_steps": 960000, "episode_reward": 0.06455401331186295, "value_loss": 0.005900326464325189, "policy_loss": -0.002401003559576509, "dist_entropy": 0.7321007132530213, "actor_grad_norm": 0.1322217732667923, "critic_grad_norm": 0.021401438862085342, "ratio": 0.9997668266296387, "entropy": 0.7321007132530213, "incre_win_rate": 0.0, "step": 300}
{"time": 1767078799.0843697, "phase": "train", "update": 301, "total_env_steps": 963200, "episode_reward": 0.06004190817475319, "value_loss": 0.00521265072748065, "policy_loss": -0.002408433523348208, "dist_entropy": 0.713332986831665, "actor_grad_norm": 0.12453363090753555, "critic_grad_norm": 0.01999625563621521, "ratio": 0.9997760653495789, "entropy": 0.713332986831665, "incre_win_rate": 0.0, "step": 301}
{"time": 1767078812.9927874, "phase": "eval", "update": 301, "total_env_steps": 963200, "eval_win_rate": 0.0, "eval_episode_reward": 7.763969370860918, "step": 301}
{"time": 1767078817.1917531, "phase": "train", "update": 302, "total_env_steps": 966400, "episode_reward": 0.06918926537036896, "value_loss": 0.007218002900481224, "policy_loss": -0.002214544093001436, "dist_entropy": 0.7293422222137451, "actor_grad_norm": 0.11950469017028809, "critic_grad_norm": 0.032848652452230453, "ratio": 1.0000245571136475, "entropy": 0.7293422222137451, "incre_win_rate": 0.0, "step": 302}
{"time": 1767078821.441564, "phase": "train", "update": 303, "total_env_steps": 969600, "episode_reward": 0.06708506494760513, "value_loss": 0.004785818140953779, "policy_loss": -0.002573573804269813, "dist_entropy": 0.717749559879303, "actor_grad_norm": 0.17310838401317596, "critic_grad_norm": 0.035663921386003494, "ratio": 0.9999222159385681, "entropy": 0.717749559879303, "incre_win_rate": 0.0, "step": 303}
{"time": 1767078825.747624, "phase": "train", "update": 304, "total_env_steps": 972800, "episode_reward": 0.06165149062871933, "value_loss": 0.005406051594763994, "policy_loss": -0.0017766019327719817, "dist_entropy": 0.7121168971061707, "actor_grad_norm": 0.14697684347629547, "critic_grad_norm": 0.04104246571660042, "ratio": 0.9997000098228455, "entropy": 0.7121168971061707, "incre_win_rate": 0.0, "step": 304}
{"time": 1767078830.058756, "phase": "train", "update": 305, "total_env_steps": 976000, "episode_reward": 0.07015572488307953, "value_loss": 0.005509213916957379, "policy_loss": -0.002272530016489327, "dist_entropy": 0.7301225066184998, "actor_grad_norm": 0.13554005324840546, "critic_grad_norm": 0.03241875767707825, "ratio": 1.0001411437988281, "entropy": 0.7301225066184998, "incre_win_rate": 0.0, "step": 305}
{"time": 1767078834.3072524, "phase": "train", "update": 306, "total_env_steps": 979200, "episode_reward": 0.06379656493663788, "value_loss": 0.004804036766290665, "policy_loss": -0.002464956729727741, "dist_entropy": 0.7263926029205322, "actor_grad_norm": 0.1365768164396286, "critic_grad_norm": 0.03297394886612892, "ratio": 1.0000178813934326, "entropy": 0.7263926029205322, "incre_win_rate": 0.0, "step": 306}
{"time": 1767078838.380634, "phase": "train", "update": 307, "total_env_steps": 982400, "episode_reward": 0.07029180228710175, "value_loss": 0.006001418642699719, "policy_loss": -0.0021580497617719628, "dist_entropy": 0.7116934418678283, "actor_grad_norm": 0.14579693973064423, "critic_grad_norm": 0.03680025413632393, "ratio": 0.9998568892478943, "entropy": 0.7116934418678283, "incre_win_rate": 0.0, "step": 307}
{"time": 1767078842.6686664, "phase": "train", "update": 308, "total_env_steps": 985600, "episode_reward": 0.06479200720787048, "value_loss": 0.004788963682949543, "policy_loss": -0.0021229621234668096, "dist_entropy": 0.7393131971359252, "actor_grad_norm": 0.13878268003463745, "critic_grad_norm": 0.0498734675347805, "ratio": 0.9999487996101379, "entropy": 0.7393131971359252, "incre_win_rate": 0.0, "step": 308}
{"time": 1767078848.1252604, "phase": "train", "update": 309, "total_env_steps": 988800, "episode_reward": 0.06861961632966995, "value_loss": 0.005376933235675096, "policy_loss": -0.0021374433562343143, "dist_entropy": 0.7317998766899109, "actor_grad_norm": 0.14434215426445007, "critic_grad_norm": 0.03701905161142349, "ratio": 1.0000486373901367, "entropy": 0.7317998766899109, "incre_win_rate": 0.0, "step": 309}
{"time": 1767078853.0029106, "phase": "train", "update": 310, "total_env_steps": 992000, "episode_reward": 0.06751759350299835, "value_loss": 0.006246871780604124, "policy_loss": -0.0022501951140570854, "dist_entropy": 0.7644944071769715, "actor_grad_norm": 0.14580391347408295, "critic_grad_norm": 0.02270137518644333, "ratio": 0.9999265074729919, "entropy": 0.7644944071769715, "incre_win_rate": 0.0, "step": 310}
{"time": 1767078857.3486602, "phase": "train", "update": 311, "total_env_steps": 995200, "episode_reward": 0.07534406334161758, "value_loss": 0.0050841962918639185, "policy_loss": -0.002047400439971625, "dist_entropy": 0.7313755035400391, "actor_grad_norm": 0.1486767828464508, "critic_grad_norm": 0.04897304251790047, "ratio": 0.9999090433120728, "entropy": 0.7313755035400391, "incre_win_rate": 0.0, "step": 311}
{"time": 1767078861.6373572, "phase": "train", "update": 312, "total_env_steps": 998400, "episode_reward": 0.07295478135347366, "value_loss": 0.005202811397612095, "policy_loss": -0.0030249956376081854, "dist_entropy": 0.7216896772384643, "actor_grad_norm": 0.1366644948720932, "critic_grad_norm": 0.02857697382569313, "ratio": 0.9999405145645142, "entropy": 0.7216896772384643, "incre_win_rate": 0.0, "step": 312}
{"time": 1767078866.0089872, "phase": "train", "update": 313, "total_env_steps": 1001600, "episode_reward": 0.06808516383171082, "value_loss": 0.004597144015133381, "policy_loss": -0.002471229884398696, "dist_entropy": 0.7266613483428955, "actor_grad_norm": 0.1614830046892166, "critic_grad_norm": 0.0624721460044384, "ratio": 0.999302327632904, "entropy": 0.7266613483428955, "incre_win_rate": 0.0, "step": 313}
{"time": 1767078870.2829509, "phase": "train", "update": 314, "total_env_steps": 1004800, "episode_reward": 0.07064621150493622, "value_loss": 0.004248396027833223, "policy_loss": -0.0013559935337056571, "dist_entropy": 0.704878306388855, "actor_grad_norm": 0.11260061711072922, "critic_grad_norm": 0.040199220180511475, "ratio": 0.9999746680259705, "entropy": 0.704878306388855, "incre_win_rate": 0.0, "step": 314}
{"time": 1767078874.661875, "phase": "train", "update": 315, "total_env_steps": 1008000, "episode_reward": 0.06665614247322083, "value_loss": 0.005502812005579472, "policy_loss": -0.0018584816129858517, "dist_entropy": 0.7210007548332215, "actor_grad_norm": 0.10674595087766647, "critic_grad_norm": 0.024282794445753098, "ratio": 1.0002726316452026, "entropy": 0.7210007548332215, "incre_win_rate": 0.0, "step": 315}
{"time": 1767078878.8590696, "phase": "train", "update": 316, "total_env_steps": 1011200, "episode_reward": 0.06690189987421036, "value_loss": 0.0042172309942543505, "policy_loss": -0.0023469321686803825, "dist_entropy": 0.6811732888221741, "actor_grad_norm": 0.15999655425548553, "critic_grad_norm": 0.06105292588472366, "ratio": 0.9997239112854004, "entropy": 0.6811732888221741, "incre_win_rate": 0.0, "step": 316}
{"time": 1767078883.1100452, "phase": "train", "update": 317, "total_env_steps": 1014400, "episode_reward": 0.06456591933965683, "value_loss": 0.005119152367115021, "policy_loss": -0.0019480178609683207, "dist_entropy": 0.6991800904273987, "actor_grad_norm": 0.12994824349880219, "critic_grad_norm": 0.03525887429714203, "ratio": 0.9999877214431763, "entropy": 0.6991800904273987, "incre_win_rate": 0.0, "step": 317}
{"time": 1767078887.3603733, "phase": "train", "update": 318, "total_env_steps": 1017600, "episode_reward": 0.06122102588415146, "value_loss": 0.004201063234359026, "policy_loss": -0.0021072756367239267, "dist_entropy": 0.7023778319358825, "actor_grad_norm": 0.15665724873542786, "critic_grad_norm": 0.0566304512321949, "ratio": 0.9998014569282532, "entropy": 0.7023778319358825, "incre_win_rate": 0.0, "step": 318}
{"time": 1767078891.9035761, "phase": "train", "update": 319, "total_env_steps": 1020800, "episode_reward": 0.06733909249305725, "value_loss": 0.004565922822803259, "policy_loss": -0.0018528186443144356, "dist_entropy": 0.6849991202354431, "actor_grad_norm": 0.15374945104122162, "critic_grad_norm": 0.053259290754795074, "ratio": 0.9997738003730774, "entropy": 0.6849991202354431, "incre_win_rate": 0.0, "step": 319}
{"time": 1767078896.137636, "phase": "train", "update": 320, "total_env_steps": 1024000, "episode_reward": 0.06076159328222275, "value_loss": 0.003919625515118241, "policy_loss": -0.0019244815519208203, "dist_entropy": 0.6905542016029358, "actor_grad_norm": 0.12783603370189667, "critic_grad_norm": 0.05600795894861221, "ratio": 0.9996059536933899, "entropy": 0.6905542016029358, "incre_win_rate": 0.0, "step": 320}
{"time": 1767078900.346499, "phase": "train", "update": 321, "total_env_steps": 1027200, "episode_reward": 0.06964197009801865, "value_loss": 0.0044248059391975405, "policy_loss": -0.0017190102073109336, "dist_entropy": 0.7004181385040283, "actor_grad_norm": 0.1395108550786972, "critic_grad_norm": 0.02531564235687256, "ratio": 0.9995269179344177, "entropy": 0.7004181385040283, "incre_win_rate": 0.0, "step": 321}
{"time": 1767078915.4617283, "phase": "eval", "update": 321, "total_env_steps": 1027200, "eval_win_rate": 0.0, "eval_episode_reward": 7.873603062913902, "step": 321}
{"time": 1767078919.7482963, "phase": "train", "update": 322, "total_env_steps": 1030400, "episode_reward": 0.0633510947227478, "value_loss": 0.005245125759392977, "policy_loss": -0.002607055407257519, "dist_entropy": 0.7066341042518616, "actor_grad_norm": 0.1458451747894287, "critic_grad_norm": 0.039804767817258835, "ratio": 0.9997754096984863, "entropy": 0.7066341042518616, "incre_win_rate": 0.0, "step": 322}
{"time": 1767078924.4832213, "phase": "train", "update": 323, "total_env_steps": 1033600, "episode_reward": 0.06554117798805237, "value_loss": 0.005007385648787022, "policy_loss": -0.00193034836031174, "dist_entropy": 0.7068320870399475, "actor_grad_norm": 0.1461344063282013, "critic_grad_norm": 0.04681125283241272, "ratio": 1.00023353099823, "entropy": 0.7068320870399475, "incre_win_rate": 0.0, "step": 323}
{"time": 1767078929.146815, "phase": "train", "update": 324, "total_env_steps": 1036800, "episode_reward": 0.06606322526931763, "value_loss": 0.003974654246121645, "policy_loss": -0.0022370063801218977, "dist_entropy": 0.6966102957725525, "actor_grad_norm": 0.11956287920475006, "critic_grad_norm": 0.030622243881225586, "ratio": 0.9997017979621887, "entropy": 0.6966102957725525, "incre_win_rate": 0.0, "step": 324}
{"time": 1767078933.6503685, "phase": "train", "update": 325, "total_env_steps": 1040000, "episode_reward": 0.06040821224451065, "value_loss": 0.005452934745699167, "policy_loss": -0.0019713932265858604, "dist_entropy": 0.6919585585594177, "actor_grad_norm": 0.131042942404747, "critic_grad_norm": 0.09432661533355713, "ratio": 0.9997959136962891, "entropy": 0.6919585585594177, "incre_win_rate": 0.0, "step": 325}
{"time": 1767078937.9069862, "phase": "train", "update": 326, "total_env_steps": 1043200, "episode_reward": 0.06009933352470398, "value_loss": 0.0043803748674690725, "policy_loss": -0.001895045380058491, "dist_entropy": 0.6853266000747681, "actor_grad_norm": 0.15744920074939728, "critic_grad_norm": 0.052005376666784286, "ratio": 0.9999996423721313, "entropy": 0.6853266000747681, "incre_win_rate": 0.0, "step": 326}
{"time": 1767078967.774877, "phase": "train", "update": 327, "total_env_steps": 1046400, "episode_reward": 0.06776438653469086, "value_loss": 0.011973650567233563, "policy_loss": -0.0009900112700943708, "dist_entropy": 0.6733614921569824, "actor_grad_norm": 0.11114493757486343, "critic_grad_norm": 0.06499165296554565, "ratio": 1.0001839399337769, "entropy": 0.6733614921569824, "incre_win_rate": 0.0, "step": 327}
{"time": 1767078971.9202826, "phase": "train", "update": 328, "total_env_steps": 1049600, "episode_reward": 0.06260813772678375, "value_loss": 0.004280588403344154, "policy_loss": -0.002045504439719359, "dist_entropy": 0.692890727519989, "actor_grad_norm": 0.153268501162529, "critic_grad_norm": 0.02718307077884674, "ratio": 0.9998430609703064, "entropy": 0.692890727519989, "incre_win_rate": 0.0, "step": 328}
{"time": 1767078976.101234, "phase": "train", "update": 329, "total_env_steps": 1052800, "episode_reward": 0.06497930735349655, "value_loss": 0.004303304105997085, "policy_loss": -0.0019559891413187813, "dist_entropy": 0.7061686158180237, "actor_grad_norm": 0.11646000295877457, "critic_grad_norm": 0.027827506884932518, "ratio": 1.000163197517395, "entropy": 0.7061686158180237, "incre_win_rate": 0.0, "step": 329}
{"time": 1767078980.243992, "phase": "train", "update": 330, "total_env_steps": 1056000, "episode_reward": 0.06424254924058914, "value_loss": 0.0042199291288852695, "policy_loss": -0.002123736127487774, "dist_entropy": 0.7083842992782593, "actor_grad_norm": 0.1310841590166092, "critic_grad_norm": 0.039653073996305466, "ratio": 1.0000886917114258, "entropy": 0.7083842992782593, "incre_win_rate": 0.0, "step": 330}
{"time": 1767078984.4705808, "phase": "train", "update": 331, "total_env_steps": 1059200, "episode_reward": 0.0658019483089447, "value_loss": 0.004626111593097448, "policy_loss": -0.0025658733280064182, "dist_entropy": 0.7103061199188232, "actor_grad_norm": 0.1283460557460785, "critic_grad_norm": 0.02670566737651825, "ratio": 0.9997797012329102, "entropy": 0.7103061199188232, "incre_win_rate": 0.0, "step": 331}
{"time": 1767078988.730649, "phase": "train", "update": 332, "total_env_steps": 1062400, "episode_reward": 0.06752483546733856, "value_loss": 0.004349104687571525, "policy_loss": -0.002372628174430247, "dist_entropy": 0.68654705286026, "actor_grad_norm": 0.1444677710533142, "critic_grad_norm": 0.044855862855911255, "ratio": 1.0001901388168335, "entropy": 0.68654705286026, "incre_win_rate": 0.0, "step": 332}
{"time": 1767078993.161551, "phase": "train", "update": 333, "total_env_steps": 1065600, "episode_reward": 0.06592974811792374, "value_loss": 0.004893494863063097, "policy_loss": -0.0020210701816996135, "dist_entropy": 0.709180223941803, "actor_grad_norm": 0.1274528056383133, "critic_grad_norm": 0.021226784214377403, "ratio": 1.000055193901062, "entropy": 0.709180223941803, "incre_win_rate": 0.0, "step": 333}
{"time": 1767078997.5521789, "phase": "train", "update": 334, "total_env_steps": 1068800, "episode_reward": 0.07291752845048904, "value_loss": 0.004050277825444937, "policy_loss": -0.0021743878777868986, "dist_entropy": 0.6905232310295105, "actor_grad_norm": 0.10998295992612839, "critic_grad_norm": 0.01337686087936163, "ratio": 1.0001896619796753, "entropy": 0.6905232310295105, "incre_win_rate": 0.0, "step": 334}
{"time": 1767079001.8620582, "phase": "train", "update": 335, "total_env_steps": 1072000, "episode_reward": 0.07037355750799179, "value_loss": 0.0044573316350579265, "policy_loss": -0.002382952287105411, "dist_entropy": 0.7086750864982605, "actor_grad_norm": 0.1553746461868286, "critic_grad_norm": 0.012537906877696514, "ratio": 0.9998379945755005, "entropy": 0.7086750864982605, "incre_win_rate": 0.0, "step": 335}
{"time": 1767079006.143139, "phase": "train", "update": 336, "total_env_steps": 1075200, "episode_reward": 0.06599131226539612, "value_loss": 0.004518944304436445, "policy_loss": -0.0021710890707683284, "dist_entropy": 0.687681782245636, "actor_grad_norm": 0.13266052305698395, "critic_grad_norm": 0.014909068122506142, "ratio": 0.999912440776825, "entropy": 0.687681782245636, "incre_win_rate": 0.0, "step": 336}
{"time": 1767079010.2964664, "phase": "train", "update": 337, "total_env_steps": 1078400, "episode_reward": 0.06955867260694504, "value_loss": 0.003756534168496728, "policy_loss": -0.0019593983706457153, "dist_entropy": 0.6810596585273743, "actor_grad_norm": 0.17101620137691498, "critic_grad_norm": 0.018630562350153923, "ratio": 1.0000053644180298, "entropy": 0.6810596585273743, "incre_win_rate": 0.0, "step": 337}
{"time": 1767079014.387067, "phase": "train", "update": 338, "total_env_steps": 1081600, "episode_reward": 0.06399989873170853, "value_loss": 0.003787454077973962, "policy_loss": -0.0019992072930412165, "dist_entropy": 0.7140162825584412, "actor_grad_norm": 0.1542692631483078, "critic_grad_norm": 0.025853995233774185, "ratio": 0.9995657205581665, "entropy": 0.7140162825584412, "incre_win_rate": 0.0, "step": 338}
{"time": 1767079018.5046546, "phase": "train", "update": 339, "total_env_steps": 1084800, "episode_reward": 0.06099855527281761, "value_loss": 0.004071292746812105, "policy_loss": -0.0016645336200014071, "dist_entropy": 0.7022306084632873, "actor_grad_norm": 0.15539011359214783, "critic_grad_norm": 0.029290666803717613, "ratio": 1.0000437498092651, "entropy": 0.7022306084632873, "incre_win_rate": 0.0, "step": 339}
{"time": 1767079022.6482658, "phase": "train", "update": 340, "total_env_steps": 1088000, "episode_reward": 0.06372568756341934, "value_loss": 0.004310655035078525, "policy_loss": -0.002311069210293226, "dist_entropy": 0.7017963528633118, "actor_grad_norm": 0.15117914974689484, "critic_grad_norm": 0.025517458096146584, "ratio": 1.00017249584198, "entropy": 0.7017963528633118, "incre_win_rate": 0.0, "step": 340}
{"time": 1767079026.812368, "phase": "train", "update": 341, "total_env_steps": 1091200, "episode_reward": 0.0687277540564537, "value_loss": 0.005791525263339281, "policy_loss": -0.001655826690913642, "dist_entropy": 0.7191414952278137, "actor_grad_norm": 0.154481440782547, "critic_grad_norm": 0.022404609248042107, "ratio": 0.9997454881668091, "entropy": 0.7191414952278137, "incre_win_rate": 0.0, "step": 341}
{"time": 1767079043.2016656, "phase": "eval", "update": 341, "total_env_steps": 1091200, "eval_win_rate": 0.0, "eval_episode_reward": 7.794184602648999, "step": 341}
{"time": 1767079047.3080816, "phase": "train", "update": 342, "total_env_steps": 1094400, "episode_reward": 0.06523074954748154, "value_loss": 0.004481458384543657, "policy_loss": -0.0018008767093014467, "dist_entropy": 0.7269447088241577, "actor_grad_norm": 0.12090038508176804, "critic_grad_norm": 0.024377359077334404, "ratio": 0.9997677206993103, "entropy": 0.7269447088241577, "incre_win_rate": 0.0, "step": 342}
{"time": 1767079051.4096317, "phase": "train", "update": 343, "total_env_steps": 1097600, "episode_reward": 0.061816535890102386, "value_loss": 0.003313788818195462, "policy_loss": -0.0022647230873218405, "dist_entropy": 0.716937267780304, "actor_grad_norm": 0.14154541492462158, "critic_grad_norm": 0.018170200288295746, "ratio": 0.9998735785484314, "entropy": 0.716937267780304, "incre_win_rate": 0.0, "step": 343}
{"time": 1767079055.6282885, "phase": "train", "update": 344, "total_env_steps": 1100800, "episode_reward": 0.0742492750287056, "value_loss": 0.004435206390917301, "policy_loss": -0.0021687262342065415, "dist_entropy": 0.7467023611068726, "actor_grad_norm": 0.15049998462200165, "critic_grad_norm": 0.01772148534655571, "ratio": 1.0000749826431274, "entropy": 0.7467023611068726, "incre_win_rate": 0.0, "step": 344}
{"time": 1767079059.7881691, "phase": "train", "update": 345, "total_env_steps": 1104000, "episode_reward": 0.06593749672174454, "value_loss": 0.004294970165938139, "policy_loss": -0.0024242971906573985, "dist_entropy": 0.7449727654457092, "actor_grad_norm": 0.1338011473417282, "critic_grad_norm": 0.01378632802516222, "ratio": 0.9997286796569824, "entropy": 0.7449727654457092, "incre_win_rate": 0.0, "step": 345}
{"time": 1767079064.0410225, "phase": "train", "update": 346, "total_env_steps": 1107200, "episode_reward": 0.06650662422180176, "value_loss": 0.004450681526213885, "policy_loss": -0.0017727877650429492, "dist_entropy": 0.7720541000366211, "actor_grad_norm": 0.1329011768102646, "critic_grad_norm": 0.04199349880218506, "ratio": 1.0003042221069336, "entropy": 0.7720541000366211, "incre_win_rate": 0.0, "step": 346}
{"time": 1767079068.2207916, "phase": "train", "update": 347, "total_env_steps": 1110400, "episode_reward": 0.06706953793764114, "value_loss": 0.004237033054232597, "policy_loss": -0.002035944201170281, "dist_entropy": 0.7492110133171082, "actor_grad_norm": 0.11184685677289963, "critic_grad_norm": 0.043721798807382584, "ratio": 0.9997354745864868, "entropy": 0.7492110133171082, "incre_win_rate": 0.0, "step": 347}
{"time": 1767079072.382818, "phase": "train", "update": 348, "total_env_steps": 1113600, "episode_reward": 0.0623251236975193, "value_loss": 0.003938300255686045, "policy_loss": -0.0016245666669171045, "dist_entropy": 0.684839129447937, "actor_grad_norm": 0.19686420261859894, "critic_grad_norm": 0.05146506428718567, "ratio": 0.9997944235801697, "entropy": 0.684839129447937, "incre_win_rate": 0.0, "step": 348}
{"time": 1767079076.5482023, "phase": "train", "update": 349, "total_env_steps": 1116800, "episode_reward": 0.0670752227306366, "value_loss": 0.004251371044665575, "policy_loss": -0.0020953033888952534, "dist_entropy": 0.685637104511261, "actor_grad_norm": 0.134455606341362, "critic_grad_norm": 0.02480015531182289, "ratio": 0.9999361038208008, "entropy": 0.685637104511261, "incre_win_rate": 0.0, "step": 349}
{"time": 1767079080.589512, "phase": "train", "update": 350, "total_env_steps": 1120000, "episode_reward": 0.058049459010362625, "value_loss": 0.00455843023955822, "policy_loss": -0.00245392084330085, "dist_entropy": 0.6556164503097535, "actor_grad_norm": 0.14075542986392975, "critic_grad_norm": 0.04125722125172615, "ratio": 0.9998990297317505, "entropy": 0.6556164503097535, "incre_win_rate": 0.0, "step": 350}
{"time": 1767079084.7477047, "phase": "train", "update": 351, "total_env_steps": 1123200, "episode_reward": 0.061447642743587494, "value_loss": 0.004087365325540304, "policy_loss": -0.0017411532619163949, "dist_entropy": 0.6184769868850708, "actor_grad_norm": 0.14788250625133514, "critic_grad_norm": 0.01919853501021862, "ratio": 0.99990314245224, "entropy": 0.6184769868850708, "incre_win_rate": 0.0, "step": 351}
{"time": 1767079088.9905627, "phase": "train", "update": 352, "total_env_steps": 1126400, "episode_reward": 0.06742704659700394, "value_loss": 0.0037877904716879128, "policy_loss": -0.0013827131663163073, "dist_entropy": 0.661745285987854, "actor_grad_norm": 0.13740143179893494, "critic_grad_norm": 0.02451683022081852, "ratio": 0.9998485445976257, "entropy": 0.661745285987854, "incre_win_rate": 0.0, "step": 352}
{"time": 1767079093.172925, "phase": "train", "update": 353, "total_env_steps": 1129600, "episode_reward": 0.060539111495018005, "value_loss": 0.004489716701209545, "policy_loss": -0.0019777542787359436, "dist_entropy": 0.6325134396553039, "actor_grad_norm": 0.15920279920101166, "critic_grad_norm": 0.017022306099534035, "ratio": 0.9999832510948181, "entropy": 0.6325134396553039, "incre_win_rate": 0.0, "step": 353}
{"time": 1767079097.3073945, "phase": "train", "update": 354, "total_env_steps": 1132800, "episode_reward": 0.058708611875772476, "value_loss": 0.004220540449023247, "policy_loss": -0.0017913212357413499, "dist_entropy": 0.6746469855308532, "actor_grad_norm": 0.17812620103359222, "critic_grad_norm": 0.03797166794538498, "ratio": 0.9998435974121094, "entropy": 0.6746469855308532, "incre_win_rate": 0.0, "step": 354}
{"time": 1767079101.4317636, "phase": "train", "update": 355, "total_env_steps": 1136000, "episode_reward": 0.058941956609487534, "value_loss": 0.005048114061355591, "policy_loss": -0.001834059431031676, "dist_entropy": 0.6909728288650513, "actor_grad_norm": 0.16583296656608582, "critic_grad_norm": 0.04151570424437523, "ratio": 1.000193476676941, "entropy": 0.6909728288650513, "incre_win_rate": 0.0, "step": 355}
{"time": 1767079105.562407, "phase": "train", "update": 356, "total_env_steps": 1139200, "episode_reward": 0.05484478920698166, "value_loss": 0.0028919653501361608, "policy_loss": -0.0019862797366158704, "dist_entropy": 0.6904712796211243, "actor_grad_norm": 0.16018474102020264, "critic_grad_norm": 0.04102499410510063, "ratio": 0.9999579787254333, "entropy": 0.6904712796211243, "incre_win_rate": 0.0, "step": 356}
{"time": 1767079109.6611865, "phase": "train", "update": 357, "total_env_steps": 1142400, "episode_reward": 0.060188841074705124, "value_loss": 0.003984128218144178, "policy_loss": -0.001678999020573002, "dist_entropy": 0.696531331539154, "actor_grad_norm": 0.15294578671455383, "critic_grad_norm": 0.03086315467953682, "ratio": 0.9999482035636902, "entropy": 0.696531331539154, "incre_win_rate": 0.0, "step": 357}
{"time": 1767079113.7856948, "phase": "train", "update": 358, "total_env_steps": 1145600, "episode_reward": 0.05564362555742264, "value_loss": 0.0034481015056371687, "policy_loss": -0.0017031677558073, "dist_entropy": 0.6649388432502746, "actor_grad_norm": 0.1078411340713501, "critic_grad_norm": 0.02932678535580635, "ratio": 1.0000336170196533, "entropy": 0.6649388432502746, "incre_win_rate": 0.0, "step": 358}
{"time": 1767079117.9511764, "phase": "train", "update": 359, "total_env_steps": 1148800, "episode_reward": 0.05321244150400162, "value_loss": 0.004017180018126965, "policy_loss": -0.0019119726694114547, "dist_entropy": 0.650097393989563, "actor_grad_norm": 0.11864558607339859, "critic_grad_norm": 0.02729366160929203, "ratio": 0.9997782707214355, "entropy": 0.650097393989563, "incre_win_rate": 0.0, "step": 359}
{"time": 1767079122.182702, "phase": "train", "update": 360, "total_env_steps": 1152000, "episode_reward": 0.06599544733762741, "value_loss": 0.004504621494561434, "policy_loss": -0.0019130251463121083, "dist_entropy": 0.7178391456604004, "actor_grad_norm": 0.11615633964538574, "critic_grad_norm": 0.07678711414337158, "ratio": 1.0000238418579102, "entropy": 0.7178391456604004, "incre_win_rate": 0.0, "step": 360}
{"time": 1767079126.3131516, "phase": "train", "update": 361, "total_env_steps": 1155200, "episode_reward": 0.05659095197916031, "value_loss": 0.004580461978912353, "policy_loss": -0.0022971379338912355, "dist_entropy": 0.6889277696609497, "actor_grad_norm": 0.1268451064825058, "critic_grad_norm": 0.03636172041296959, "ratio": 0.9998946189880371, "entropy": 0.6889277696609497, "incre_win_rate": 0.0, "step": 361}
{"time": 1767079143.2827165, "phase": "eval", "update": 361, "total_env_steps": 1155200, "eval_win_rate": 0.0, "eval_episode_reward": 7.961506622516547, "step": 361}
{"time": 1767079147.3829749, "phase": "train", "update": 362, "total_env_steps": 1158400, "episode_reward": 0.06033474951982498, "value_loss": 0.003932585008442402, "policy_loss": -0.0021493693472905305, "dist_entropy": 0.6848368525505066, "actor_grad_norm": 0.15623117983341217, "critic_grad_norm": 0.026505151763558388, "ratio": 0.9998135566711426, "entropy": 0.6848368525505066, "incre_win_rate": 0.0, "step": 362}
{"time": 1767079151.3814209, "phase": "train", "update": 363, "total_env_steps": 1161600, "episode_reward": 0.057318396866321564, "value_loss": 0.0033925309777259826, "policy_loss": -0.0017566701116134454, "dist_entropy": 0.7026221752166748, "actor_grad_norm": 0.09912919253110886, "critic_grad_norm": 0.022737249732017517, "ratio": 1.0000602006912231, "entropy": 0.7026221752166748, "incre_win_rate": 0.0, "step": 363}
{"time": 1767079155.5351539, "phase": "train", "update": 364, "total_env_steps": 1164800, "episode_reward": 0.06054636090993881, "value_loss": 0.0037105883937329056, "policy_loss": -0.002253841964831338, "dist_entropy": 0.7237173795700074, "actor_grad_norm": 0.125011146068573, "critic_grad_norm": 0.0265591349452734, "ratio": 1.0000113248825073, "entropy": 0.7237173795700074, "incre_win_rate": 0.0, "step": 364}
{"time": 1767079159.6695213, "phase": "train", "update": 365, "total_env_steps": 1168000, "episode_reward": 0.05946658179163933, "value_loss": 0.0040877734310925005, "policy_loss": -0.0018217234617086576, "dist_entropy": 0.6550369262695312, "actor_grad_norm": 0.12953415513038635, "critic_grad_norm": 0.021496081724762917, "ratio": 0.9999317526817322, "entropy": 0.6550369262695312, "incre_win_rate": 0.0, "step": 365}
{"time": 1767079163.760055, "phase": "train", "update": 366, "total_env_steps": 1171200, "episode_reward": 0.05419392138719559, "value_loss": 0.004050314798951149, "policy_loss": -0.001893304353793468, "dist_entropy": 0.6763399243354797, "actor_grad_norm": 0.15985746681690216, "critic_grad_norm": 0.017592232674360275, "ratio": 0.9999514818191528, "entropy": 0.6763399243354797, "incre_win_rate": 0.0, "step": 366}
{"time": 1767079167.8565836, "phase": "train", "update": 367, "total_env_steps": 1174400, "episode_reward": 0.059943605214357376, "value_loss": 0.004074905160814523, "policy_loss": -0.0011853203634814235, "dist_entropy": 0.6413003921508789, "actor_grad_norm": 0.11989785730838776, "critic_grad_norm": 0.044416654855012894, "ratio": 1.000076174736023, "entropy": 0.6413003921508789, "incre_win_rate": 0.0, "step": 367}
{"time": 1767079171.908835, "phase": "train", "update": 368, "total_env_steps": 1177600, "episode_reward": 0.05788235366344452, "value_loss": 0.003907197155058384, "policy_loss": -0.0016328482422636626, "dist_entropy": 0.6653470158576965, "actor_grad_norm": 0.11548630148172379, "critic_grad_norm": 0.04553496465086937, "ratio": 0.9997188448905945, "entropy": 0.6653470158576965, "incre_win_rate": 0.0, "step": 368}
{"time": 1767079176.0658226, "phase": "train", "update": 369, "total_env_steps": 1180800, "episode_reward": 0.04976459592580795, "value_loss": 0.0037716442719101908, "policy_loss": -0.0019135136662367103, "dist_entropy": 0.6510915040969849, "actor_grad_norm": 0.1216084286570549, "critic_grad_norm": 0.06410882622003555, "ratio": 0.9998648762702942, "entropy": 0.6510915040969849, "incre_win_rate": 0.0, "step": 369}
{"time": 1767079180.2266452, "phase": "train", "update": 370, "total_env_steps": 1184000, "episode_reward": 0.05461610481142998, "value_loss": 0.0032170067075639962, "policy_loss": -0.0014248375687529347, "dist_entropy": 0.6590954542160035, "actor_grad_norm": 0.14053426682949066, "critic_grad_norm": 0.04107613489031792, "ratio": 0.9999491572380066, "entropy": 0.6590954542160035, "incre_win_rate": 0.0, "step": 370}
{"time": 1767079184.4063883, "phase": "train", "update": 371, "total_env_steps": 1187200, "episode_reward": 0.04881105571985245, "value_loss": 0.002648963825777173, "policy_loss": -0.0017035163559299348, "dist_entropy": 0.629067325592041, "actor_grad_norm": 0.138482928276062, "critic_grad_norm": 0.023710675537586212, "ratio": 1.000302791595459, "entropy": 0.629067325592041, "incre_win_rate": 0.0, "step": 371}
{"time": 1767079188.4586678, "phase": "train", "update": 372, "total_env_steps": 1190400, "episode_reward": 0.050489965826272964, "value_loss": 0.0035613074898719786, "policy_loss": -0.001685054525977847, "dist_entropy": 0.6431575059890747, "actor_grad_norm": 0.13786904513835907, "critic_grad_norm": 0.05357889086008072, "ratio": 0.9999580383300781, "entropy": 0.6431575059890747, "incre_win_rate": 0.0, "step": 372}
{"time": 1767079192.4148624, "phase": "train", "update": 373, "total_env_steps": 1193600, "episode_reward": 0.049760449677705765, "value_loss": 0.004758528806269169, "policy_loss": -0.001370897695403528, "dist_entropy": 0.5895092368125916, "actor_grad_norm": 0.15945498645305634, "critic_grad_norm": 0.046104930341243744, "ratio": 0.9999639391899109, "entropy": 0.5895092368125916, "incre_win_rate": 0.0, "step": 373}
{"time": 1767079196.4767916, "phase": "train", "update": 374, "total_env_steps": 1196800, "episode_reward": 0.050945259630680084, "value_loss": 0.0033699460327625275, "policy_loss": -0.0015767442448741064, "dist_entropy": 0.5869252204895019, "actor_grad_norm": 0.1499529480934143, "critic_grad_norm": 0.03355557471513748, "ratio": 0.9999025464057922, "entropy": 0.5869252204895019, "incre_win_rate": 0.0, "step": 374}
{"time": 1767079200.4982803, "phase": "train", "update": 375, "total_env_steps": 1200000, "episode_reward": 0.05259157717227936, "value_loss": 0.0032102353870868683, "policy_loss": -0.0012351448871100955, "dist_entropy": 0.5919757127761841, "actor_grad_norm": 0.11379080265760422, "critic_grad_norm": 0.0498136505484581, "ratio": 0.999814510345459, "entropy": 0.5919757127761841, "incre_win_rate": 0.0, "step": 375}
{"time": 1767079204.5208457, "phase": "train", "update": 376, "total_env_steps": 1203200, "episode_reward": 0.051232922822237015, "value_loss": 0.002867291960865259, "policy_loss": -0.0009189291400346633, "dist_entropy": 0.5721765398979187, "actor_grad_norm": 0.10332552343606949, "critic_grad_norm": 0.035310883074998856, "ratio": 0.99984210729599, "entropy": 0.5721765398979187, "incre_win_rate": 0.0, "step": 376}
{"time": 1767079208.5220156, "phase": "train", "update": 377, "total_env_steps": 1206400, "episode_reward": 0.05290459096431732, "value_loss": 0.003009890578687191, "policy_loss": -0.0014444740726560212, "dist_entropy": 0.567598295211792, "actor_grad_norm": 0.14533160626888275, "critic_grad_norm": 0.03177103027701378, "ratio": 1.000052809715271, "entropy": 0.567598295211792, "incre_win_rate": 0.0, "step": 377}
{"time": 1767079212.5267339, "phase": "train", "update": 378, "total_env_steps": 1209600, "episode_reward": 0.04978373646736145, "value_loss": 0.0030666572507470845, "policy_loss": -0.0013203662019782847, "dist_entropy": 0.5633576512336731, "actor_grad_norm": 0.1384630650281906, "critic_grad_norm": 0.03226003423333168, "ratio": 0.999851644039154, "entropy": 0.5633576512336731, "incre_win_rate": 0.0, "step": 378}
{"time": 1767079216.5920255, "phase": "train", "update": 379, "total_env_steps": 1212800, "episode_reward": 0.05001189559698105, "value_loss": 0.002972780307754874, "policy_loss": -0.0011692476130745534, "dist_entropy": 0.5951346516609192, "actor_grad_norm": 0.11512750387191772, "critic_grad_norm": 0.030621593818068504, "ratio": 0.9997960925102234, "entropy": 0.5951346516609192, "incre_win_rate": 0.0, "step": 379}
{"time": 1767079220.6111202, "phase": "train", "update": 380, "total_env_steps": 1216000, "episode_reward": 0.054109059274196625, "value_loss": 0.0028709772042930124, "policy_loss": -0.0019137771207446974, "dist_entropy": 0.598071014881134, "actor_grad_norm": 0.13348473608493805, "critic_grad_norm": 0.021040724590420723, "ratio": 1.0000571012496948, "entropy": 0.598071014881134, "incre_win_rate": 0.0, "step": 380}
{"time": 1767079224.5882056, "phase": "train", "update": 381, "total_env_steps": 1219200, "episode_reward": 0.052422910928726196, "value_loss": 0.0029406499583274127, "policy_loss": -0.0019556889678894684, "dist_entropy": 0.5773743867874146, "actor_grad_norm": 0.13153675198554993, "critic_grad_norm": 0.024968821555376053, "ratio": 1.0000157356262207, "entropy": 0.5773743867874146, "incre_win_rate": 0.0, "step": 381}
{"time": 1767079242.5382905, "phase": "eval", "update": 381, "total_env_steps": 1219200, "eval_win_rate": 0.0, "eval_episode_reward": 6.814259105960255, "step": 381}
{"time": 1767079246.7298002, "phase": "train", "update": 382, "total_env_steps": 1222400, "episode_reward": 0.05488462373614311, "value_loss": 0.0029134786687791347, "policy_loss": -0.0016674047757383903, "dist_entropy": 0.5869111180305481, "actor_grad_norm": 0.14583007991313934, "critic_grad_norm": 0.012129479087889194, "ratio": 0.9999266862869263, "entropy": 0.5869111180305481, "incre_win_rate": 0.0, "step": 382}
{"time": 1767079250.787698, "phase": "train", "update": 383, "total_env_steps": 1225600, "episode_reward": 0.04942932724952698, "value_loss": 0.002126131532713771, "policy_loss": -0.001589465447476357, "dist_entropy": 0.565684688091278, "actor_grad_norm": 0.1386243849992752, "critic_grad_norm": 0.021397283300757408, "ratio": 1.000304102897644, "entropy": 0.565684688091278, "incre_win_rate": 0.0, "step": 383}
{"time": 1767079254.8694952, "phase": "train", "update": 384, "total_env_steps": 1228800, "episode_reward": 0.05330505222082138, "value_loss": 0.0030829985160380604, "policy_loss": -0.0017363161800567184, "dist_entropy": 0.5726386070251465, "actor_grad_norm": 0.10313417762517929, "critic_grad_norm": 0.013170457445085049, "ratio": 1.0000218152999878, "entropy": 0.5726386070251465, "incre_win_rate": 0.0, "step": 384}
{"time": 1767079258.9150424, "phase": "train", "update": 385, "total_env_steps": 1232000, "episode_reward": 0.04960109665989876, "value_loss": 0.0022543839644640685, "policy_loss": -0.0013963871483568368, "dist_entropy": 0.5907813668251037, "actor_grad_norm": 0.15608654916286469, "critic_grad_norm": 0.01650390215218067, "ratio": 0.9996674656867981, "entropy": 0.5907813668251037, "incre_win_rate": 0.0, "step": 385}
{"time": 1767079262.8782341, "phase": "train", "update": 386, "total_env_steps": 1235200, "episode_reward": 0.04292166605591774, "value_loss": 0.00240927436389029, "policy_loss": -0.0011241643181236327, "dist_entropy": 0.5626657724380493, "actor_grad_norm": 0.10529094934463501, "critic_grad_norm": 0.03906654566526413, "ratio": 1.0001866817474365, "entropy": 0.5626657724380493, "incre_win_rate": 0.0, "step": 386}
{"time": 1767079266.955659, "phase": "train", "update": 387, "total_env_steps": 1238400, "episode_reward": 0.04810275137424469, "value_loss": 0.0033567451871931555, "policy_loss": -0.001758537659899595, "dist_entropy": 0.5568777561187744, "actor_grad_norm": 0.1214301586151123, "critic_grad_norm": 0.033999763429164886, "ratio": 0.9999768137931824, "entropy": 0.5568777561187744, "incre_win_rate": 0.0, "step": 387}
{"time": 1767079270.9749558, "phase": "train", "update": 388, "total_env_steps": 1241600, "episode_reward": 0.04901076480746269, "value_loss": 0.0024127820506691933, "policy_loss": -0.0010602932144990972, "dist_entropy": 0.5643741488456726, "actor_grad_norm": 0.09899694472551346, "critic_grad_norm": 0.03790774568915367, "ratio": 1.0001510381698608, "entropy": 0.5643741488456726, "incre_win_rate": 0.0, "step": 388}
{"time": 1767079275.0687754, "phase": "train", "update": 389, "total_env_steps": 1244800, "episode_reward": 0.048014797270298004, "value_loss": 0.002403239533305168, "policy_loss": -0.0011747526469079617, "dist_entropy": 0.5719072222709656, "actor_grad_norm": 0.09720008820295334, "critic_grad_norm": 0.01900514028966427, "ratio": 0.9998245239257812, "entropy": 0.5719072222709656, "incre_win_rate": 0.0, "step": 389}
{"time": 1767079279.1924915, "phase": "train", "update": 390, "total_env_steps": 1248000, "episode_reward": 0.054665252566337585, "value_loss": 0.0022353945299983025, "policy_loss": -0.0015838435813646302, "dist_entropy": 0.6052718877792358, "actor_grad_norm": 0.10830695927143097, "critic_grad_norm": 0.0308255385607481, "ratio": 0.9998276829719543, "entropy": 0.6052718877792358, "incre_win_rate": 0.0, "step": 390}
{"time": 1767079283.2677643, "phase": "train", "update": 391, "total_env_steps": 1251200, "episode_reward": 0.04887210205197334, "value_loss": 0.0020357972010970117, "policy_loss": -0.0012187051477651422, "dist_entropy": 0.6142453551292419, "actor_grad_norm": 0.08918681740760803, "critic_grad_norm": 0.027397042140364647, "ratio": 1.0000189542770386, "entropy": 0.6142453551292419, "incre_win_rate": 0.0, "step": 391}
{"time": 1767079287.422805, "phase": "train", "update": 392, "total_env_steps": 1254400, "episode_reward": 0.054850999265909195, "value_loss": 0.002791193453595042, "policy_loss": -0.0015951145031605663, "dist_entropy": 0.6184365153312683, "actor_grad_norm": 0.1283087581396103, "critic_grad_norm": 0.021643318235874176, "ratio": 0.9997149705886841, "entropy": 0.6184365153312683, "incre_win_rate": 0.0, "step": 392}
{"time": 1767079291.520429, "phase": "train", "update": 393, "total_env_steps": 1257600, "episode_reward": 0.052166808396577835, "value_loss": 0.0028107500169426204, "policy_loss": -0.0015169089037883055, "dist_entropy": 0.6038232445716858, "actor_grad_norm": 0.11485324054956436, "critic_grad_norm": 0.022356046363711357, "ratio": 0.9999198317527771, "entropy": 0.6038232445716858, "incre_win_rate": 0.0, "step": 393}
{"time": 1767079295.5658, "phase": "train", "update": 394, "total_env_steps": 1260800, "episode_reward": 0.05175549164414406, "value_loss": 0.002815542323514819, "policy_loss": -0.001342349531785203, "dist_entropy": 0.6130500793457031, "actor_grad_norm": 0.09622861444950104, "critic_grad_norm": 0.017880043014883995, "ratio": 1.0001873970031738, "entropy": 0.6130500793457031, "incre_win_rate": 0.0, "step": 394}
{"time": 1767079299.6883407, "phase": "train", "update": 395, "total_env_steps": 1264000, "episode_reward": 0.05221906304359436, "value_loss": 0.002595408633351326, "policy_loss": -0.0021162718881484466, "dist_entropy": 0.6206958055496216, "actor_grad_norm": 0.14455974102020264, "critic_grad_norm": 0.015535115264356136, "ratio": 0.9998525977134705, "entropy": 0.6206958055496216, "incre_win_rate": 0.0, "step": 395}
{"time": 1767079303.7927616, "phase": "train", "update": 396, "total_env_steps": 1267200, "episode_reward": 0.0573132261633873, "value_loss": 0.0025382800959050655, "policy_loss": -0.0016272377892860845, "dist_entropy": 0.6153682351112366, "actor_grad_norm": 0.16285452246665955, "critic_grad_norm": 0.028798693791031837, "ratio": 0.9997067451477051, "entropy": 0.6153682351112366, "incre_win_rate": 0.0, "step": 396}
{"time": 1767079307.9509625, "phase": "train", "update": 397, "total_env_steps": 1270400, "episode_reward": 0.0540490485727787, "value_loss": 0.0021893182303756474, "policy_loss": -0.0013845938445477656, "dist_entropy": 0.6197306036949157, "actor_grad_norm": 0.14248132705688477, "critic_grad_norm": 0.01864500157535076, "ratio": 1.0000423192977905, "entropy": 0.6197306036949157, "incre_win_rate": 0.0, "step": 397}
{"time": 1767079312.074131, "phase": "train", "update": 398, "total_env_steps": 1273600, "episode_reward": 0.05409561097621918, "value_loss": 0.0018411824014037848, "policy_loss": -0.000817417996812253, "dist_entropy": 0.601162052154541, "actor_grad_norm": 0.11782355606555939, "critic_grad_norm": 0.019572146236896515, "ratio": 1.0001204013824463, "entropy": 0.601162052154541, "incre_win_rate": 0.0, "step": 398}
{"time": 1767079316.1830556, "phase": "train", "update": 399, "total_env_steps": 1276800, "episode_reward": 0.05107616260647774, "value_loss": 0.0018323155120015145, "policy_loss": -0.0012993263275053123, "dist_entropy": 0.5931338667869568, "actor_grad_norm": 0.11031506210565567, "critic_grad_norm": 0.04289213567972183, "ratio": 0.9998695254325867, "entropy": 0.5931338667869568, "incre_win_rate": 0.0, "step": 399}
{"time": 1767079320.236239, "phase": "train", "update": 400, "total_env_steps": 1280000, "episode_reward": 0.05289579927921295, "value_loss": 0.0028495040722191336, "policy_loss": -0.0011256225698311972, "dist_entropy": 0.5804507732391357, "actor_grad_norm": 0.11110363155603409, "critic_grad_norm": 0.0433928407728672, "ratio": 1.0000375509262085, "entropy": 0.5804507732391357, "incre_win_rate": 0.0, "step": 400}
{"time": 1767079324.2519314, "phase": "train", "update": 401, "total_env_steps": 1283200, "episode_reward": 0.05546616017818451, "value_loss": 0.0029259944800287484, "policy_loss": -0.0018518646411212814, "dist_entropy": 0.594962990283966, "actor_grad_norm": 0.12913821637630463, "critic_grad_norm": 0.03541133552789688, "ratio": 1.0000174045562744, "entropy": 0.594962990283966, "incre_win_rate": 0.0, "step": 401}
{"time": 1767079346.7794464, "phase": "eval", "update": 401, "total_env_steps": 1283200, "eval_win_rate": 0.0, "eval_episode_reward": 7.7969784768211845, "step": 401}
{"time": 1767079350.807323, "phase": "train", "update": 402, "total_env_steps": 1286400, "episode_reward": 0.05172961205244064, "value_loss": 0.0026253147982060908, "policy_loss": -0.0014055839940750603, "dist_entropy": 0.6049138903617859, "actor_grad_norm": 0.12559138238430023, "critic_grad_norm": 0.04250447824597359, "ratio": 0.9999250769615173, "entropy": 0.6049138903617859, "incre_win_rate": 0.0, "step": 402}
{"time": 1767079354.8118606, "phase": "train", "update": 403, "total_env_steps": 1289600, "episode_reward": 0.05425238236784935, "value_loss": 0.0027531988453119993, "policy_loss": -0.0010538524313803421, "dist_entropy": 0.6172747850418091, "actor_grad_norm": 0.11976929754018784, "critic_grad_norm": 0.053703673183918, "ratio": 1.0000466108322144, "entropy": 0.6172747850418091, "incre_win_rate": 0.0, "step": 403}
{"time": 1767079358.9246383, "phase": "train", "update": 404, "total_env_steps": 1292800, "episode_reward": 0.052072640508413315, "value_loss": 0.0031742701306939126, "policy_loss": -0.002059054041352226, "dist_entropy": 0.6131293416023255, "actor_grad_norm": 0.15591983497142792, "critic_grad_norm": 0.038100071251392365, "ratio": 0.9997041821479797, "entropy": 0.6131293416023255, "incre_win_rate": 0.0, "step": 404}
{"time": 1767079362.937511, "phase": "train", "update": 405, "total_env_steps": 1296000, "episode_reward": 0.05160802975296974, "value_loss": 0.0022757976315915585, "policy_loss": -0.001587753742020226, "dist_entropy": 0.6282268166542053, "actor_grad_norm": 0.1382361203432083, "critic_grad_norm": 0.022593757137656212, "ratio": 1.0000299215316772, "entropy": 0.6282268166542053, "incre_win_rate": 0.0, "step": 405}
{"time": 1767079366.9434536, "phase": "train", "update": 406, "total_env_steps": 1299200, "episode_reward": 0.05296357721090317, "value_loss": 0.0023744901176542045, "policy_loss": -0.002198944117582968, "dist_entropy": 0.6303440809249878, "actor_grad_norm": 0.12600097060203552, "critic_grad_norm": 0.025938836857676506, "ratio": 0.9999009966850281, "entropy": 0.6303440809249878, "incre_win_rate": 0.0, "step": 406}
{"time": 1767079370.9246242, "phase": "train", "update": 407, "total_env_steps": 1302400, "episode_reward": 0.05065241828560829, "value_loss": 0.0024817007593810557, "policy_loss": -0.0016884665807724631, "dist_entropy": 0.6249460458755494, "actor_grad_norm": 0.11745572090148926, "critic_grad_norm": 0.01554544921964407, "ratio": 0.9998801350593567, "entropy": 0.6249460458755494, "incre_win_rate": 0.0, "step": 407}
{"time": 1767079375.054278, "phase": "train", "update": 408, "total_env_steps": 1305600, "episode_reward": 0.05283837392926216, "value_loss": 0.001956106862053275, "policy_loss": -0.0017807687758338631, "dist_entropy": 0.6337012052536011, "actor_grad_norm": 0.12829481065273285, "critic_grad_norm": 0.017321962863206863, "ratio": 0.9997183084487915, "entropy": 0.6337012052536011, "incre_win_rate": 0.0, "step": 408}
{"time": 1767079379.1203318, "phase": "train", "update": 409, "total_env_steps": 1308800, "episode_reward": 0.053631000220775604, "value_loss": 0.0027234848588705064, "policy_loss": -0.002443855290758279, "dist_entropy": 0.6297915816307068, "actor_grad_norm": 0.14129270613193512, "critic_grad_norm": 0.017366142943501472, "ratio": 0.9999794960021973, "entropy": 0.6297915816307068, "incre_win_rate": 0.0, "step": 409}
{"time": 1767079383.1438963, "phase": "train", "update": 410, "total_env_steps": 1312000, "episode_reward": 0.05380484461784363, "value_loss": 0.002383385458961129, "policy_loss": -0.0009085507093935519, "dist_entropy": 0.6275896430015564, "actor_grad_norm": 0.1310872733592987, "critic_grad_norm": 0.042138949036598206, "ratio": 0.9996427893638611, "entropy": 0.6275896430015564, "incre_win_rate": 0.0, "step": 410}
{"time": 1767079387.1793995, "phase": "train", "update": 411, "total_env_steps": 1315200, "episode_reward": 0.0504051111638546, "value_loss": 0.0020653885323554276, "policy_loss": -0.0022868188421547586, "dist_entropy": 0.6010945320129395, "actor_grad_norm": 0.10098879784345627, "critic_grad_norm": 0.03100542537868023, "ratio": 0.9998940825462341, "entropy": 0.6010945320129395, "incre_win_rate": 0.0, "step": 411}
{"time": 1767079391.2442052, "phase": "train", "update": 412, "total_env_steps": 1318400, "episode_reward": 0.049064572900533676, "value_loss": 0.003001653216779232, "policy_loss": -0.0014827383309355291, "dist_entropy": 0.5856712579727172, "actor_grad_norm": 0.11007194966077805, "critic_grad_norm": 0.041472043842077255, "ratio": 0.9996580481529236, "entropy": 0.5856712579727172, "incre_win_rate": 0.0, "step": 412}
{"time": 1767079395.3091378, "phase": "train", "update": 413, "total_env_steps": 1321600, "episode_reward": 0.0505494698882103, "value_loss": 0.0025030749849975107, "policy_loss": -0.001799404919626113, "dist_entropy": 0.607092022895813, "actor_grad_norm": 0.12621916830539703, "critic_grad_norm": 0.03441842645406723, "ratio": 0.9999527931213379, "entropy": 0.607092022895813, "incre_win_rate": 0.0, "step": 413}
{"time": 1767079399.374027, "phase": "train", "update": 414, "total_env_steps": 1324800, "episode_reward": 0.05663597211241722, "value_loss": 0.002176473755389452, "policy_loss": -0.0013484917559253517, "dist_entropy": 0.6062536358833313, "actor_grad_norm": 0.1244794949889183, "critic_grad_norm": 0.04138403758406639, "ratio": 0.9996574521064758, "entropy": 0.6062536358833313, "incre_win_rate": 0.0, "step": 414}
{"time": 1767079403.291919, "phase": "train", "update": 415, "total_env_steps": 1328000, "episode_reward": 0.050106581300497055, "value_loss": 0.001801974675618112, "policy_loss": -0.0015399834759868725, "dist_entropy": 0.6078462243080139, "actor_grad_norm": 0.11668150871992111, "critic_grad_norm": 0.019274210557341576, "ratio": 1.0000065565109253, "entropy": 0.6078462243080139, "incre_win_rate": 0.0, "step": 415}
{"time": 1767079407.486409, "phase": "train", "update": 416, "total_env_steps": 1331200, "episode_reward": 0.053763970732688904, "value_loss": 0.002355658821761608, "policy_loss": -0.0012275952996873229, "dist_entropy": 0.630170476436615, "actor_grad_norm": 0.10859700292348862, "critic_grad_norm": 0.04927835613489151, "ratio": 0.9999293684959412, "entropy": 0.630170476436615, "incre_win_rate": 0.0, "step": 416}
{"time": 1767079411.612174, "phase": "train", "update": 417, "total_env_steps": 1334400, "episode_reward": 0.054063018411397934, "value_loss": 0.001715503423474729, "policy_loss": -0.0009429831647388198, "dist_entropy": 0.6440809607505799, "actor_grad_norm": 0.13939690589904785, "critic_grad_norm": 0.027419835329055786, "ratio": 1.000025987625122, "entropy": 0.6440809607505799, "incre_win_rate": 0.0, "step": 417}
{"time": 1767079415.8269007, "phase": "train", "update": 418, "total_env_steps": 1337600, "episode_reward": 0.05315811187028885, "value_loss": 0.0030581092927604915, "policy_loss": -0.0010943232973271932, "dist_entropy": 0.6497752428054809, "actor_grad_norm": 0.09354009479284286, "critic_grad_norm": 0.027774453163146973, "ratio": 1.0000067949295044, "entropy": 0.6497752428054809, "incre_win_rate": 0.0, "step": 418}
{"time": 1767079420.0889585, "phase": "train", "update": 419, "total_env_steps": 1340800, "episode_reward": 0.04895436763763428, "value_loss": 0.0021271828562021257, "policy_loss": -0.0022836302007320343, "dist_entropy": 0.6739965081214905, "actor_grad_norm": 0.11734535545110703, "critic_grad_norm": 0.020292652770876884, "ratio": 0.9998992085456848, "entropy": 0.6739965081214905, "incre_win_rate": 0.0, "step": 419}
{"time": 1767079424.2472334, "phase": "train", "update": 420, "total_env_steps": 1344000, "episode_reward": 0.05100993067026138, "value_loss": 0.0012598930159583687, "policy_loss": -0.0018053743411867273, "dist_entropy": 0.6910516619682312, "actor_grad_norm": 0.14284268021583557, "critic_grad_norm": 0.026567935943603516, "ratio": 0.9999580383300781, "entropy": 0.6910516619682312, "incre_win_rate": 0.0, "step": 420}
{"time": 1767079428.3866925, "phase": "train", "update": 421, "total_env_steps": 1347200, "episode_reward": 0.05136486515402794, "value_loss": 0.002050187438726425, "policy_loss": -0.0016842763110531678, "dist_entropy": 0.6932901978492737, "actor_grad_norm": 0.12280169874429703, "critic_grad_norm": 0.03593429923057556, "ratio": 1.0002487897872925, "entropy": 0.6932901978492737, "incre_win_rate": 0.0, "step": 421}
{"time": 1767079446.5451438, "phase": "eval", "update": 421, "total_env_steps": 1347200, "eval_win_rate": 0.0, "eval_episode_reward": 7.497102649006617, "step": 421}
{"time": 1767079450.6317482, "phase": "train", "update": 422, "total_env_steps": 1350400, "episode_reward": 0.05384623631834984, "value_loss": 0.0021195390727370977, "policy_loss": -0.0015285182990798063, "dist_entropy": 0.690165114402771, "actor_grad_norm": 0.15686440467834473, "critic_grad_norm": 0.02969544567167759, "ratio": 0.9999503493309021, "entropy": 0.690165114402771, "incre_win_rate": 0.0, "step": 422}
{"time": 1767079454.7837458, "phase": "train", "update": 423, "total_env_steps": 1353600, "episode_reward": 0.05298219993710518, "value_loss": 0.0016109098214656115, "policy_loss": -0.0014102058206809432, "dist_entropy": 0.7165356159210206, "actor_grad_norm": 0.09690951555967331, "critic_grad_norm": 0.02256927080452442, "ratio": 1.000182867050171, "entropy": 0.7165356159210206, "incre_win_rate": 0.0, "step": 423}
{"time": 1767079458.895283, "phase": "train", "update": 424, "total_env_steps": 1356800, "episode_reward": 0.05497568100690842, "value_loss": 0.0020857700612396, "policy_loss": -0.0013946044879261875, "dist_entropy": 0.751673448085785, "actor_grad_norm": 0.12018715590238571, "critic_grad_norm": 0.02382165752351284, "ratio": 0.9998729825019836, "entropy": 0.751673448085785, "incre_win_rate": 0.0, "step": 424}
{"time": 1767079462.9706023, "phase": "train", "update": 425, "total_env_steps": 1360000, "episode_reward": 0.0560099333524704, "value_loss": 0.0029179451521486044, "policy_loss": -0.0018172752147012972, "dist_entropy": 0.7459701538085938, "actor_grad_norm": 0.10417162626981735, "critic_grad_norm": 0.023901721462607384, "ratio": 0.9999441504478455, "entropy": 0.7459701538085938, "incre_win_rate": 0.0, "step": 425}
{"time": 1767079467.0875845, "phase": "train", "update": 426, "total_env_steps": 1363200, "episode_reward": 0.05322381854057312, "value_loss": 0.0014590709703043102, "policy_loss": -0.001262572440725762, "dist_entropy": 0.7995669364929199, "actor_grad_norm": 0.1164049431681633, "critic_grad_norm": 0.03230014815926552, "ratio": 1.0000653266906738, "entropy": 0.7995669364929199, "incre_win_rate": 0.0, "step": 426}
{"time": 1767079471.1719265, "phase": "train", "update": 427, "total_env_steps": 1366400, "episode_reward": 0.05482771247625351, "value_loss": 0.0017393788322806359, "policy_loss": -0.0015293715581819356, "dist_entropy": 0.7632120847702026, "actor_grad_norm": 0.10688280314207077, "critic_grad_norm": 0.02518836222589016, "ratio": 0.9995335936546326, "entropy": 0.7632120847702026, "incre_win_rate": 0.0, "step": 427}
{"time": 1767079475.1726146, "phase": "train", "update": 428, "total_env_steps": 1369600, "episode_reward": 0.052693501114845276, "value_loss": 0.0015694395639002322, "policy_loss": -0.0012701032357520959, "dist_entropy": 0.7601718425750732, "actor_grad_norm": 0.11469389498233795, "critic_grad_norm": 0.02069508098065853, "ratio": 1.0002583265304565, "entropy": 0.7601718425750732, "incre_win_rate": 0.0, "step": 428}
{"time": 1767079479.2920816, "phase": "train", "update": 429, "total_env_steps": 1372800, "episode_reward": 0.05516659840941429, "value_loss": 0.0018554141046479345, "policy_loss": -0.0015042140452678153, "dist_entropy": 0.7703682065010071, "actor_grad_norm": 0.11279051750898361, "critic_grad_norm": 0.022586045786738396, "ratio": 0.9999845623970032, "entropy": 0.7703682065010071, "incre_win_rate": 0.0, "step": 429}
{"time": 1767079483.4303668, "phase": "train", "update": 430, "total_env_steps": 1376000, "episode_reward": 0.05354459583759308, "value_loss": 0.00200807792134583, "policy_loss": -0.001246181022316506, "dist_entropy": 0.8017374753952027, "actor_grad_norm": 0.1182120069861412, "critic_grad_norm": 0.017843836918473244, "ratio": 1.0000447034835815, "entropy": 0.8017374753952027, "incre_win_rate": 0.0, "step": 430}
{"time": 1767079487.536447, "phase": "train", "update": 431, "total_env_steps": 1379200, "episode_reward": 0.052414633333683014, "value_loss": 0.00223371721804142, "policy_loss": -0.0018862635186019717, "dist_entropy": 0.8055232763290405, "actor_grad_norm": 0.12995164096355438, "critic_grad_norm": 0.02207374945282936, "ratio": 0.9998688697814941, "entropy": 0.8055232763290405, "incre_win_rate": 0.0, "step": 431}
{"time": 1767079491.67096, "phase": "train", "update": 432, "total_env_steps": 1382400, "episode_reward": 0.05677410960197449, "value_loss": 0.002997267059981823, "policy_loss": -0.0019150269283946919, "dist_entropy": 0.8429948687553406, "actor_grad_norm": 0.15370750427246094, "critic_grad_norm": 0.03154725581407547, "ratio": 0.9998087286949158, "entropy": 0.8429948687553406, "incre_win_rate": 0.0, "step": 432}
{"time": 1767079495.7299185, "phase": "train", "update": 433, "total_env_steps": 1385600, "episode_reward": 0.052234068512916565, "value_loss": 0.00231359857134521, "policy_loss": -0.0018567071542456403, "dist_entropy": 0.8642871856689454, "actor_grad_norm": 0.16357851028442383, "critic_grad_norm": 0.024158494547009468, "ratio": 1.0004469156265259, "entropy": 0.8642871856689454, "incre_win_rate": 0.0, "step": 433}
{"time": 1767079499.7705147, "phase": "train", "update": 434, "total_env_steps": 1388800, "episode_reward": 0.05501396954059601, "value_loss": 0.0020783817395567893, "policy_loss": -0.0021373782936318976, "dist_entropy": 0.8356556057929992, "actor_grad_norm": 0.11717282980680466, "critic_grad_norm": 0.03719231113791466, "ratio": 0.9998995065689087, "entropy": 0.8356556057929992, "incre_win_rate": 0.0, "step": 434}
{"time": 1767079504.1934779, "phase": "train", "update": 435, "total_env_steps": 1392000, "episode_reward": 0.05473199486732483, "value_loss": 0.002241646684706211, "policy_loss": -0.001185057922922539, "dist_entropy": 0.8096097826957702, "actor_grad_norm": 0.12834644317626953, "critic_grad_norm": 0.025603044778108597, "ratio": 0.9998828768730164, "entropy": 0.8096097826957702, "incre_win_rate": 0.0, "step": 435}
{"time": 1767079508.55372, "phase": "train", "update": 436, "total_env_steps": 1395200, "episode_reward": 0.05301583185791969, "value_loss": 0.002207092987373471, "policy_loss": -0.0011506097401678516, "dist_entropy": 0.7952558636665344, "actor_grad_norm": 0.11779546737670898, "critic_grad_norm": 0.018920516595244408, "ratio": 0.9997217059135437, "entropy": 0.7952558636665344, "incre_win_rate": 0.0, "step": 436}
{"time": 1767079512.570959, "phase": "train", "update": 437, "total_env_steps": 1398400, "episode_reward": 0.05283474922180176, "value_loss": 0.002798956073820591, "policy_loss": -0.0018199113925120968, "dist_entropy": 0.7862275004386902, "actor_grad_norm": 0.1195388063788414, "critic_grad_norm": 0.015096045099198818, "ratio": 0.9999660849571228, "entropy": 0.7862275004386902, "incre_win_rate": 0.0, "step": 437}
{"time": 1767079516.669039, "phase": "train", "update": 438, "total_env_steps": 1401600, "episode_reward": 0.05315656214952469, "value_loss": 0.0025200692005455496, "policy_loss": -0.00183200271340489, "dist_entropy": 0.7799167633056641, "actor_grad_norm": 0.13806505501270294, "critic_grad_norm": 0.012293394654989243, "ratio": 0.9997550249099731, "entropy": 0.7799167633056641, "incre_win_rate": 0.0, "step": 438}
{"time": 1767079520.7061465, "phase": "train", "update": 439, "total_env_steps": 1404800, "episode_reward": 0.05226045474410057, "value_loss": 0.0026073561515659095, "policy_loss": -0.0018743359012098892, "dist_entropy": 0.7990522384643555, "actor_grad_norm": 0.13208217918872833, "critic_grad_norm": 0.02450212650001049, "ratio": 1.0000851154327393, "entropy": 0.7990522384643555, "incre_win_rate": 0.0, "step": 439}
{"time": 1767079524.7599473, "phase": "train", "update": 440, "total_env_steps": 1408000, "episode_reward": 0.052066951990127563, "value_loss": 0.0019416033057495952, "policy_loss": -0.0010500841642070214, "dist_entropy": 0.8009667992591858, "actor_grad_norm": 0.11014195531606674, "critic_grad_norm": 0.010611881501972675, "ratio": 1.0001062154769897, "entropy": 0.8009667992591858, "incre_win_rate": 0.0, "step": 440}
{"time": 1767079528.8237576, "phase": "train", "update": 441, "total_env_steps": 1411200, "episode_reward": 0.05645851045846939, "value_loss": 0.0026872692164033652, "policy_loss": -0.001378614929802424, "dist_entropy": 0.8159470558166504, "actor_grad_norm": 0.12302873283624649, "critic_grad_norm": 0.01274640392512083, "ratio": 1.0001226663589478, "entropy": 0.8159470558166504, "incre_win_rate": 0.0, "step": 441}
{"time": 1767079546.6458755, "phase": "eval", "update": 441, "total_env_steps": 1411200, "eval_win_rate": 0.0, "eval_episode_reward": 7.641866721854292, "step": 441}
{"time": 1767079550.7500167, "phase": "train", "update": 442, "total_env_steps": 1414400, "episode_reward": 0.05474286153912544, "value_loss": 0.002032455708831549, "policy_loss": -0.0013222258822324306, "dist_entropy": 0.8564179301261902, "actor_grad_norm": 0.12594948709011078, "critic_grad_norm": 0.017465462908148766, "ratio": 1.0000547170639038, "entropy": 0.8564179301261902, "incre_win_rate": 0.0, "step": 442}
{"time": 1767079554.8325834, "phase": "train", "update": 443, "total_env_steps": 1417600, "episode_reward": 0.05576779693365097, "value_loss": 0.0022456578910350798, "policy_loss": -0.0018428450875912715, "dist_entropy": 0.8937708139419556, "actor_grad_norm": 0.12180709838867188, "critic_grad_norm": 0.013381115160882473, "ratio": 0.9998623132705688, "entropy": 0.8937708139419556, "incre_win_rate": 0.0, "step": 443}
{"time": 1767079558.917682, "phase": "train", "update": 444, "total_env_steps": 1420800, "episode_reward": 0.05538390204310417, "value_loss": 0.0029198544099926947, "policy_loss": -0.002133852095744615, "dist_entropy": 0.9072300434112549, "actor_grad_norm": 0.13479937613010406, "critic_grad_norm": 0.026979906484484673, "ratio": 0.9996519088745117, "entropy": 0.9072300434112549, "incre_win_rate": 0.0, "step": 444}
{"time": 1767079562.9946814, "phase": "train", "update": 445, "total_env_steps": 1424000, "episode_reward": 0.05417787656188011, "value_loss": 0.002236903877928853, "policy_loss": -0.0016008191622674417, "dist_entropy": 0.8639546155929565, "actor_grad_norm": 0.12753549218177795, "critic_grad_norm": 0.02525249682366848, "ratio": 1.0001155138015747, "entropy": 0.8639546155929565, "incre_win_rate": 0.0, "step": 445}
{"time": 1767079567.0548332, "phase": "train", "update": 446, "total_env_steps": 1427200, "episode_reward": 0.05858340114355087, "value_loss": 0.0023719755001366137, "policy_loss": -0.0014942914044453915, "dist_entropy": 0.8411209464073182, "actor_grad_norm": 0.11523278057575226, "critic_grad_norm": 0.015607026405632496, "ratio": 0.9999417662620544, "entropy": 0.8411209464073182, "incre_win_rate": 0.0, "step": 446}
{"time": 1767079571.1232781, "phase": "train", "update": 447, "total_env_steps": 1430400, "episode_reward": 0.05796564742922783, "value_loss": 0.0029262467753142117, "policy_loss": -0.0015581784576895075, "dist_entropy": 0.869068706035614, "actor_grad_norm": 0.14398477971553802, "critic_grad_norm": 0.026309048756957054, "ratio": 0.9998766183853149, "entropy": 0.869068706035614, "incre_win_rate": 0.0, "step": 447}
{"time": 1767079575.1839814, "phase": "train", "update": 448, "total_env_steps": 1433600, "episode_reward": 0.057044707238674164, "value_loss": 0.002310238778591156, "policy_loss": -0.001290089043730802, "dist_entropy": 0.9203562617301941, "actor_grad_norm": 0.12519723176956177, "critic_grad_norm": 0.013794014230370522, "ratio": 0.9998764991760254, "entropy": 0.9203562617301941, "incre_win_rate": 0.0, "step": 448}
{"time": 1767079579.2744362, "phase": "train", "update": 449, "total_env_steps": 1436800, "episode_reward": 0.0529434010386467, "value_loss": 0.002855898439884186, "policy_loss": -0.0022575944069018307, "dist_entropy": 0.8976863980293274, "actor_grad_norm": 0.12990573048591614, "critic_grad_norm": 0.04819604381918907, "ratio": 0.9999629259109497, "entropy": 0.8976863980293274, "incre_win_rate": 0.0, "step": 449}
{"time": 1767079583.3693464, "phase": "train", "update": 450, "total_env_steps": 1440000, "episode_reward": 0.05691380053758621, "value_loss": 0.00268159918487072, "policy_loss": -0.0018042192647598654, "dist_entropy": 0.8868969559669495, "actor_grad_norm": 0.1281135529279709, "critic_grad_norm": 0.03666632995009422, "ratio": 1.0003613233566284, "entropy": 0.8868969559669495, "incre_win_rate": 0.0, "step": 450}
{"time": 1767079587.37465, "phase": "train", "update": 451, "total_env_steps": 1443200, "episode_reward": 0.054638348519802094, "value_loss": 0.001968597364611924, "policy_loss": -0.001882018459326318, "dist_entropy": 0.9003136038780213, "actor_grad_norm": 0.12406223267316818, "critic_grad_norm": 0.0216260626912117, "ratio": 0.9999910593032837, "entropy": 0.9003136038780213, "incre_win_rate": 0.0, "step": 451}
{"time": 1767079591.428156, "phase": "train", "update": 452, "total_env_steps": 1446400, "episode_reward": 0.058308668434619904, "value_loss": 0.003151141665875912, "policy_loss": -0.001402242935050424, "dist_entropy": 0.8854390263557435, "actor_grad_norm": 0.1291959136724472, "critic_grad_norm": 0.03043377958238125, "ratio": 0.9999307990074158, "entropy": 0.8854390263557435, "incre_win_rate": 0.0, "step": 452}
{"time": 1767079595.4343803, "phase": "train", "update": 453, "total_env_steps": 1449600, "episode_reward": 0.055127277970314026, "value_loss": 0.0032299292739480733, "policy_loss": -0.0011728857254688307, "dist_entropy": 0.9049928426742554, "actor_grad_norm": 0.13577507436275482, "critic_grad_norm": 0.04798151180148125, "ratio": 1.0000962018966675, "entropy": 0.9049928426742554, "incre_win_rate": 0.0, "step": 453}
{"time": 1767079599.46031, "phase": "train", "update": 454, "total_env_steps": 1452800, "episode_reward": 0.05480546876788139, "value_loss": 0.0024297769647091626, "policy_loss": -0.0014327136847334999, "dist_entropy": 0.9249396085739136, "actor_grad_norm": 0.10753120481967926, "critic_grad_norm": 0.032714325934648514, "ratio": 1.0001122951507568, "entropy": 0.9249396085739136, "incre_win_rate": 0.0, "step": 454}
{"time": 1767079603.6424057, "phase": "train", "update": 455, "total_env_steps": 1456000, "episode_reward": 0.05719008296728134, "value_loss": 0.002529217442497611, "policy_loss": -0.0015835992258615762, "dist_entropy": 0.8923828363418579, "actor_grad_norm": 0.1332300752401352, "critic_grad_norm": 0.051813315600156784, "ratio": 0.9998068809509277, "entropy": 0.8923828363418579, "incre_win_rate": 0.0, "step": 455}
{"time": 1767079607.6855724, "phase": "train", "update": 456, "total_env_steps": 1459200, "episode_reward": 0.055558256804943085, "value_loss": 0.0027498260606080294, "policy_loss": -0.0018280531442972149, "dist_entropy": 0.9002794861793518, "actor_grad_norm": 0.12417793273925781, "critic_grad_norm": 0.03875458985567093, "ratio": 1.0003775358200073, "entropy": 0.9002794861793518, "incre_win_rate": 0.0, "step": 456}
{"time": 1767079611.7219906, "phase": "train", "update": 457, "total_env_steps": 1462400, "episode_reward": 0.05503983795642853, "value_loss": 0.002885202364996076, "policy_loss": -0.0013252676250658623, "dist_entropy": 0.8947830200195312, "actor_grad_norm": 0.12286539375782013, "critic_grad_norm": 0.013794179074466228, "ratio": 0.9996843338012695, "entropy": 0.8947830200195312, "incre_win_rate": 0.0, "step": 457}
{"time": 1767079615.6899438, "phase": "train", "update": 458, "total_env_steps": 1465600, "episode_reward": 0.053041186183691025, "value_loss": 0.0024664615280926227, "policy_loss": -0.0020194216740502926, "dist_entropy": 0.8975656628608704, "actor_grad_norm": 0.1407274454832077, "critic_grad_norm": 0.029391521587967873, "ratio": 0.9997914433479309, "entropy": 0.8975656628608704, "incre_win_rate": 0.0, "step": 458}
{"time": 1767079619.6483886, "phase": "train", "update": 459, "total_env_steps": 1468800, "episode_reward": 0.05756364017724991, "value_loss": 0.0029772360809147357, "policy_loss": -0.0013407184625492618, "dist_entropy": 0.9086466789245605, "actor_grad_norm": 0.13110485672950745, "critic_grad_norm": 0.025111069902777672, "ratio": 1.000212550163269, "entropy": 0.9086466789245605, "incre_win_rate": 0.0, "step": 459}
{"time": 1767079623.6324365, "phase": "train", "update": 460, "total_env_steps": 1472000, "episode_reward": 0.05546305701136589, "value_loss": 0.0024392481427639723, "policy_loss": -0.0014932477632427776, "dist_entropy": 0.9104506373405457, "actor_grad_norm": 0.11227734386920929, "critic_grad_norm": 0.03466833010315895, "ratio": 0.9998002052307129, "entropy": 0.9104506373405457, "incre_win_rate": 0.0, "step": 460}
{"time": 1767079627.6592112, "phase": "train", "update": 461, "total_env_steps": 1475200, "episode_reward": 0.05185999721288681, "value_loss": 0.002853799145668745, "policy_loss": -0.0019142891519770445, "dist_entropy": 0.9121401309967041, "actor_grad_norm": 0.12162550538778305, "critic_grad_norm": 0.03720620647072792, "ratio": 1.000102162361145, "entropy": 0.9121401309967041, "incre_win_rate": 0.0, "step": 461}
{"time": 1767079645.6855063, "phase": "eval", "update": 461, "total_env_steps": 1475200, "eval_win_rate": 0.0, "eval_episode_reward": 7.842508278145688, "step": 461}
{"time": 1767079649.7716193, "phase": "train", "update": 462, "total_env_steps": 1478400, "episode_reward": 0.055244721472263336, "value_loss": 0.0022069110535085203, "policy_loss": -0.0020480368725969813, "dist_entropy": 0.8889153838157654, "actor_grad_norm": 0.13928675651550293, "critic_grad_norm": 0.030774956569075584, "ratio": 0.9996551871299744, "entropy": 0.8889153838157654, "incre_win_rate": 0.0, "step": 462}
{"time": 1767079653.8143785, "phase": "train", "update": 463, "total_env_steps": 1481600, "episode_reward": 0.05529697239398956, "value_loss": 0.004228297621011734, "policy_loss": -0.0017992182281901137, "dist_entropy": 0.8348458886146546, "actor_grad_norm": 0.12541961669921875, "critic_grad_norm": 0.05735521391034126, "ratio": 1.0000109672546387, "entropy": 0.8348458886146546, "incre_win_rate": 0.0, "step": 463}
{"time": 1767079657.8139532, "phase": "train", "update": 464, "total_env_steps": 1484800, "episode_reward": 0.0568155013024807, "value_loss": 0.0030690496787428856, "policy_loss": -0.0018713364098207562, "dist_entropy": 0.8832837224006653, "actor_grad_norm": 0.1736486256122589, "critic_grad_norm": 0.038515616208314896, "ratio": 1.0002224445343018, "entropy": 0.8832837224006653, "incre_win_rate": 0.0, "step": 464}
{"time": 1767079661.9876304, "phase": "train", "update": 465, "total_env_steps": 1488000, "episode_reward": 0.05594836547970772, "value_loss": 0.002040710742585361, "policy_loss": -0.0014737703956463123, "dist_entropy": 0.8591869473457336, "actor_grad_norm": 0.13045772910118103, "critic_grad_norm": 0.021191930398344994, "ratio": 1.0001033544540405, "entropy": 0.8591869473457336, "incre_win_rate": 0.0, "step": 465}
{"time": 1767079666.0996075, "phase": "train", "update": 466, "total_env_steps": 1491200, "episode_reward": 0.0527762845158577, "value_loss": 0.0025431379210203884, "policy_loss": -0.0010804352071318135, "dist_entropy": 0.8795069575309753, "actor_grad_norm": 0.10420594364404678, "critic_grad_norm": 0.03439741209149361, "ratio": 1.0001697540283203, "entropy": 0.8795069575309753, "incre_win_rate": 0.0, "step": 466}
{"time": 1767079670.2324786, "phase": "train", "update": 467, "total_env_steps": 1494400, "episode_reward": 0.0580277293920517, "value_loss": 0.003096790984272957, "policy_loss": -0.0012477215367830753, "dist_entropy": 0.8670335650444031, "actor_grad_norm": 0.1399511992931366, "critic_grad_norm": 0.0565020814538002, "ratio": 0.9999672770500183, "entropy": 0.8670335650444031, "incre_win_rate": 0.0, "step": 467}
{"time": 1767079674.352587, "phase": "train", "update": 468, "total_env_steps": 1497600, "episode_reward": 0.056130483746528625, "value_loss": 0.002848919201642275, "policy_loss": -0.0020822750934627265, "dist_entropy": 0.8853458046913147, "actor_grad_norm": 0.16380596160888672, "critic_grad_norm": 0.03965999558568001, "ratio": 1.0005223751068115, "entropy": 0.8853458046913147, "incre_win_rate": 0.0, "step": 468}
{"time": 1767079678.418314, "phase": "train", "update": 469, "total_env_steps": 1500800, "episode_reward": 0.054742347449064255, "value_loss": 0.0028340011835098267, "policy_loss": -0.0020337029409030817, "dist_entropy": 0.8768692374229431, "actor_grad_norm": 0.14173291623592377, "critic_grad_norm": 0.028094440698623657, "ratio": 0.9997467398643494, "entropy": 0.8768692374229431, "incre_win_rate": 0.0, "step": 469}
{"time": 1767079682.6020532, "phase": "train", "update": 470, "total_env_steps": 1504000, "episode_reward": 0.059693194925785065, "value_loss": 0.0026873232796788215, "policy_loss": -0.0020231533661203118, "dist_entropy": 0.8692751407623291, "actor_grad_norm": 0.12125089019536972, "critic_grad_norm": 0.022751180455088615, "ratio": 1.0000654458999634, "entropy": 0.8692751407623291, "incre_win_rate": 0.0, "step": 470}
{"time": 1767079686.611311, "phase": "train", "update": 471, "total_env_steps": 1507200, "episode_reward": 0.05836299806833267, "value_loss": 0.0037484354805201294, "policy_loss": -0.0013315330848080009, "dist_entropy": 0.8474827289581299, "actor_grad_norm": 0.10487796366214752, "critic_grad_norm": 0.026792434975504875, "ratio": 1.0000686645507812, "entropy": 0.8474827289581299, "incre_win_rate": 0.0, "step": 471}
{"time": 1767079690.6344187, "phase": "train", "update": 472, "total_env_steps": 1510400, "episode_reward": 0.05834799259901047, "value_loss": 0.0023560647387057543, "policy_loss": -0.0017846027620443295, "dist_entropy": 0.850756824016571, "actor_grad_norm": 0.10890813171863556, "critic_grad_norm": 0.03132110834121704, "ratio": 1.0001593828201294, "entropy": 0.850756824016571, "incre_win_rate": 0.0, "step": 472}
{"time": 1767079694.699858, "phase": "train", "update": 473, "total_env_steps": 1513600, "episode_reward": 0.05550341680645943, "value_loss": 0.0022686140611767767, "policy_loss": -0.0020599205199028246, "dist_entropy": 0.8820830702781677, "actor_grad_norm": 0.12094079703092575, "critic_grad_norm": 0.022518325597047806, "ratio": 0.9997857213020325, "entropy": 0.8820830702781677, "incre_win_rate": 0.0, "step": 473}
{"time": 1767079698.7112756, "phase": "train", "update": 474, "total_env_steps": 1516800, "episode_reward": 0.0565190427005291, "value_loss": 0.003078226884827018, "policy_loss": -0.001560287084927836, "dist_entropy": 0.87094806432724, "actor_grad_norm": 0.13496045768260956, "critic_grad_norm": 0.01735491305589676, "ratio": 1.000195026397705, "entropy": 0.87094806432724, "incre_win_rate": 0.0, "step": 474}
{"time": 1767079702.8084624, "phase": "train", "update": 475, "total_env_steps": 1520000, "episode_reward": 0.05865376442670822, "value_loss": 0.002594820922240615, "policy_loss": -0.001655406237845858, "dist_entropy": 0.8477758526802063, "actor_grad_norm": 0.12813977897167206, "critic_grad_norm": 0.022090455517172813, "ratio": 1.0002508163452148, "entropy": 0.8477758526802063, "incre_win_rate": 0.0, "step": 475}
{"time": 1767079707.3100896, "phase": "train", "update": 476, "total_env_steps": 1523200, "episode_reward": 0.05823726952075958, "value_loss": 0.002042892808094621, "policy_loss": -0.002346533336803702, "dist_entropy": 0.8753456950187684, "actor_grad_norm": 0.1687304824590683, "critic_grad_norm": 0.01857217587530613, "ratio": 0.9998855590820312, "entropy": 0.8753456950187684, "incre_win_rate": 0.0, "step": 476}
{"time": 1767079711.4483786, "phase": "train", "update": 477, "total_env_steps": 1526400, "episode_reward": 0.05851614475250244, "value_loss": 0.0024247376248240473, "policy_loss": -0.001796173220742503, "dist_entropy": 0.8587981581687927, "actor_grad_norm": 0.11208797991275787, "critic_grad_norm": 0.013050051406025887, "ratio": 1.0000711679458618, "entropy": 0.8587981581687927, "incre_win_rate": 0.0, "step": 477}
{"time": 1767079715.5989819, "phase": "train", "update": 478, "total_env_steps": 1529600, "episode_reward": 0.057754553854465485, "value_loss": 0.002972097974270582, "policy_loss": -0.0014540259706596892, "dist_entropy": 0.8333855271339417, "actor_grad_norm": 0.102729931473732, "critic_grad_norm": 0.025429880246520042, "ratio": 1.0000699758529663, "entropy": 0.8333855271339417, "incre_win_rate": 0.0, "step": 478}
{"time": 1767079719.8378606, "phase": "train", "update": 479, "total_env_steps": 1532800, "episode_reward": 0.05740014463663101, "value_loss": 0.0017683472018688918, "policy_loss": -0.002351245217413833, "dist_entropy": 0.8355673313140869, "actor_grad_norm": 0.13853298127651215, "critic_grad_norm": 0.020065952092409134, "ratio": 0.9999725222587585, "entropy": 0.8355673313140869, "incre_win_rate": 0.0, "step": 479}
{"time": 1767079724.2203796, "phase": "train", "update": 480, "total_env_steps": 1536000, "episode_reward": 0.061453331261873245, "value_loss": 0.003315098164603114, "policy_loss": -0.0020617165086683543, "dist_entropy": 0.8249422788619996, "actor_grad_norm": 0.12662971019744873, "critic_grad_norm": 0.02895086444914341, "ratio": 1.000095248222351, "entropy": 0.8249422788619996, "incre_win_rate": 0.0, "step": 480}
{"time": 1767079728.3316364, "phase": "train", "update": 481, "total_env_steps": 1539200, "episode_reward": 0.06179066747426987, "value_loss": 0.0035525433253496886, "policy_loss": -0.0019530829275026917, "dist_entropy": 0.7942775845527649, "actor_grad_norm": 0.10775367170572281, "critic_grad_norm": 0.02830992452800274, "ratio": 1.0000869035720825, "entropy": 0.7942775845527649, "incre_win_rate": 0.0, "step": 481}
{"time": 1767079747.4104013, "phase": "eval", "update": 481, "total_env_steps": 1539200, "eval_win_rate": 0.0, "eval_episode_reward": 8.221595612582774, "step": 481}
{"time": 1767079751.5737693, "phase": "train", "update": 482, "total_env_steps": 1542400, "episode_reward": 0.05744464322924614, "value_loss": 0.0029096220154315234, "policy_loss": -0.0018821820857574778, "dist_entropy": 0.8096120357513428, "actor_grad_norm": 0.1474638432264328, "critic_grad_norm": 0.015310317277908325, "ratio": 0.9995876550674438, "entropy": 0.8096120357513428, "incre_win_rate": 0.0, "step": 482}
{"time": 1767079755.78726, "phase": "train", "update": 483, "total_env_steps": 1545600, "episode_reward": 0.062027111649513245, "value_loss": 0.0034671835601329803, "policy_loss": -0.00221964699945616, "dist_entropy": 0.811808967590332, "actor_grad_norm": 0.13136982917785645, "critic_grad_norm": 0.018257400020956993, "ratio": 0.9997448325157166, "entropy": 0.811808967590332, "incre_win_rate": 0.0, "step": 483}
{"time": 1767079759.882365, "phase": "train", "update": 484, "total_env_steps": 1548800, "episode_reward": 0.05975683033466339, "value_loss": 0.0038541593123227356, "policy_loss": -0.0017889914855594214, "dist_entropy": 0.84224773645401, "actor_grad_norm": 0.11354940384626389, "critic_grad_norm": 0.020136795938014984, "ratio": 0.99982088804245, "entropy": 0.84224773645401, "incre_win_rate": 0.0, "step": 484}
{"time": 1767079764.0050166, "phase": "train", "update": 485, "total_env_steps": 1552000, "episode_reward": 0.0610523596405983, "value_loss": 0.00288871880620718, "policy_loss": -0.002442836204759402, "dist_entropy": 0.8259649872779846, "actor_grad_norm": 0.15144765377044678, "critic_grad_norm": 0.021740609779953957, "ratio": 1.0000340938568115, "entropy": 0.8259649872779846, "incre_win_rate": 0.0, "step": 485}
{"time": 1767079768.0775301, "phase": "train", "update": 486, "total_env_steps": 1555200, "episode_reward": 0.06159250810742378, "value_loss": 0.0043018247932195665, "policy_loss": -0.0019742453610525957, "dist_entropy": 0.7839617013931275, "actor_grad_norm": 0.13625280559062958, "critic_grad_norm": 0.045848868787288666, "ratio": 0.9999337196350098, "entropy": 0.7839617013931275, "incre_win_rate": 0.0, "step": 486}
{"time": 1767079772.2085354, "phase": "train", "update": 487, "total_env_steps": 1558400, "episode_reward": 0.05929429084062576, "value_loss": 0.003264694195240736, "policy_loss": -0.0017181000022773673, "dist_entropy": 0.7793579936027527, "actor_grad_norm": 0.13292887806892395, "critic_grad_norm": 0.0329502634704113, "ratio": 0.9999483227729797, "entropy": 0.7793579936027527, "incre_win_rate": 0.0, "step": 487}
{"time": 1767079776.3086562, "phase": "train", "update": 488, "total_env_steps": 1561600, "episode_reward": 0.06582522392272949, "value_loss": 0.004730424750596285, "policy_loss": -0.002178241174485862, "dist_entropy": 0.7702765464782715, "actor_grad_norm": 0.146529421210289, "critic_grad_norm": 0.03205816075205803, "ratio": 1.0001773834228516, "entropy": 0.7702765464782715, "incre_win_rate": 0.0, "step": 488}
{"time": 1767079780.4684956, "phase": "train", "update": 489, "total_env_steps": 1564800, "episode_reward": 0.06738618016242981, "value_loss": 0.004308800119906664, "policy_loss": -0.002325697479718247, "dist_entropy": 0.7675224781036377, "actor_grad_norm": 0.12797869741916656, "critic_grad_norm": 0.030270809307694435, "ratio": 0.9998680353164673, "entropy": 0.7675224781036377, "incre_win_rate": 0.0, "step": 489}
{"time": 1767079784.8552506, "phase": "train", "update": 490, "total_env_steps": 1568000, "episode_reward": 0.06347578763961792, "value_loss": 0.0035445103887468575, "policy_loss": -0.0019771276650793366, "dist_entropy": 0.7601739764213562, "actor_grad_norm": 0.14474882185459137, "critic_grad_norm": 0.0472087524831295, "ratio": 0.9997453093528748, "entropy": 0.7601739764213562, "incre_win_rate": 0.0, "step": 490}
{"time": 1767079814.6476693, "phase": "train", "update": 491, "total_env_steps": 1571200, "episode_reward": 0.06725062429904938, "value_loss": 0.013766246289014817, "policy_loss": -0.0013239903588541323, "dist_entropy": 0.7472811341285706, "actor_grad_norm": 0.1197371706366539, "critic_grad_norm": 0.034779977053403854, "ratio": 0.9998503923416138, "entropy": 0.7472811341285706, "incre_win_rate": 0.0, "step": 491}
{"time": 1767079818.8798738, "phase": "train", "update": 492, "total_env_steps": 1574400, "episode_reward": 0.061577506363391876, "value_loss": 0.003655189462006092, "policy_loss": -0.0016407231960943846, "dist_entropy": 0.7657999396324158, "actor_grad_norm": 0.15117597579956055, "critic_grad_norm": 0.04377683624625206, "ratio": 0.9993870854377747, "entropy": 0.7657999396324158, "incre_win_rate": 0.0, "step": 492}
{"time": 1767079823.1960146, "phase": "train", "update": 493, "total_env_steps": 1577600, "episode_reward": 0.06213731691241264, "value_loss": 0.0050768937915563585, "policy_loss": -0.002247754541641811, "dist_entropy": 0.7901345729827881, "actor_grad_norm": 0.13652633130550385, "critic_grad_norm": 0.02912430837750435, "ratio": 0.9999085664749146, "entropy": 0.7901345729827881, "incre_win_rate": 0.0, "step": 493}
{"time": 1767079827.520551, "phase": "train", "update": 494, "total_env_steps": 1580800, "episode_reward": 0.06767021864652634, "value_loss": 0.005922135710716247, "policy_loss": -0.0023853446135067456, "dist_entropy": 0.7886457324028016, "actor_grad_norm": 0.11255567520856857, "critic_grad_norm": 0.07009124755859375, "ratio": 0.9999794960021973, "entropy": 0.7886457324028016, "incre_win_rate": 0.0, "step": 494}
{"time": 1767079831.9563866, "phase": "train", "update": 495, "total_env_steps": 1584000, "episode_reward": 0.06198985502123833, "value_loss": 0.004257288761436939, "policy_loss": -0.002497172020206051, "dist_entropy": 0.7993597030639649, "actor_grad_norm": 0.14478369057178497, "critic_grad_norm": 0.017834903672337532, "ratio": 0.9996609687805176, "entropy": 0.7993597030639649, "incre_win_rate": 0.0, "step": 495}
{"time": 1767079836.2495656, "phase": "train", "update": 496, "total_env_steps": 1587200, "episode_reward": 0.06296616792678833, "value_loss": 0.00453072227537632, "policy_loss": -0.0021259122391427353, "dist_entropy": 0.7692866563796997, "actor_grad_norm": 0.12419282644987106, "critic_grad_norm": 0.01731199026107788, "ratio": 0.9998404383659363, "entropy": 0.7692866563796997, "incre_win_rate": 0.0, "step": 496}
{"time": 1767079840.6445322, "phase": "train", "update": 497, "total_env_steps": 1590400, "episode_reward": 0.0737587958574295, "value_loss": 0.008209139481186867, "policy_loss": -0.0017892084921360407, "dist_entropy": 0.7469778418540954, "actor_grad_norm": 0.166873961687088, "critic_grad_norm": 0.03469957783818245, "ratio": 0.999810516834259, "entropy": 0.7469778418540954, "incre_win_rate": 0.0, "step": 497}
{"time": 1767079845.2778904, "phase": "train", "update": 498, "total_env_steps": 1593600, "episode_reward": 0.06977701187133789, "value_loss": 0.006357391830533743, "policy_loss": -0.0016291984138792515, "dist_entropy": 0.7261870384216309, "actor_grad_norm": 0.10830338299274445, "critic_grad_norm": 0.04764528200030327, "ratio": 0.9999675750732422, "entropy": 0.7261870384216309, "incre_win_rate": 0.0, "step": 498}
{"time": 1767079849.5340526, "phase": "train", "update": 499, "total_env_steps": 1596800, "episode_reward": 0.06518315523862839, "value_loss": 0.0051976902410388, "policy_loss": -0.002286148632411766, "dist_entropy": 0.7356079578399658, "actor_grad_norm": 0.12697084248065948, "critic_grad_norm": 0.027749305590987206, "ratio": 1.00006902217865, "entropy": 0.7356079578399658, "incre_win_rate": 0.0, "step": 499}
{"time": 1767079853.8382444, "phase": "train", "update": 500, "total_env_steps": 1600000, "episode_reward": 0.06818760186433792, "value_loss": 0.006727459374815226, "policy_loss": -0.0027710332202246944, "dist_entropy": 0.7399679303169251, "actor_grad_norm": 0.14618723094463348, "critic_grad_norm": 0.02738896571099758, "ratio": 1.0000420808792114, "entropy": 0.7399679303169251, "incre_win_rate": 0.0, "step": 500}
{"time": 1767079858.1615741, "phase": "train", "update": 501, "total_env_steps": 1603200, "episode_reward": 0.07203952968120575, "value_loss": 0.0061718253418803215, "policy_loss": -0.0018873190058727118, "dist_entropy": 0.738370418548584, "actor_grad_norm": 0.17140518128871918, "critic_grad_norm": 0.04258496314287186, "ratio": 1.0000994205474854, "entropy": 0.738370418548584, "incre_win_rate": 0.0, "step": 501}
{"time": 1767079877.5949516, "phase": "eval", "update": 501, "total_env_steps": 1603200, "eval_win_rate": 0.0, "eval_episode_reward": 8.732667632450326, "step": 501}
{"time": 1767079882.1676621, "phase": "train", "update": 502, "total_env_steps": 1606400, "episode_reward": 0.06336557865142822, "value_loss": 0.00890063662081957, "policy_loss": -0.002534188443893015, "dist_entropy": 0.7436309456825256, "actor_grad_norm": 0.14465999603271484, "critic_grad_norm": 0.06163119152188301, "ratio": 1.0001024007797241, "entropy": 0.7436309456825256, "incre_win_rate": 0.0, "step": 502}
{"time": 1767079886.6785285, "phase": "train", "update": 503, "total_env_steps": 1609600, "episode_reward": 0.06259830296039581, "value_loss": 0.0051936649717390536, "policy_loss": -0.0018937428438697169, "dist_entropy": 0.7660897493362426, "actor_grad_norm": 0.1405058652162552, "critic_grad_norm": 0.04679640009999275, "ratio": 1.0005574226379395, "entropy": 0.7660897493362426, "incre_win_rate": 0.0, "step": 503}
{"time": 1767079891.8968182, "phase": "train", "update": 504, "total_env_steps": 1612800, "episode_reward": 0.07246585190296173, "value_loss": 0.007050196453928947, "policy_loss": -0.0022226004990187676, "dist_entropy": 0.7344782829284668, "actor_grad_norm": 0.16039617359638214, "critic_grad_norm": 0.04703127220273018, "ratio": 1.0001670122146606, "entropy": 0.7344782829284668, "incre_win_rate": 0.0, "step": 504}
{"time": 1767079897.019813, "phase": "train", "update": 505, "total_env_steps": 1616000, "episode_reward": 0.0681653544306755, "value_loss": 0.007836270332336425, "policy_loss": -0.002751213157409893, "dist_entropy": 0.7329722762107849, "actor_grad_norm": 0.14485597610473633, "critic_grad_norm": 0.06193059682846069, "ratio": 0.9998802542686462, "entropy": 0.7329722762107849, "incre_win_rate": 0.0, "step": 505}
{"time": 1767079902.011327, "phase": "train", "update": 506, "total_env_steps": 1619200, "episode_reward": 0.07093801349401474, "value_loss": 0.005842798203229904, "policy_loss": -0.002546599514903036, "dist_entropy": 0.7284254193305969, "actor_grad_norm": 0.14569471776485443, "critic_grad_norm": 0.07221319526433945, "ratio": 0.9998316168785095, "entropy": 0.7284254193305969, "incre_win_rate": 0.0, "step": 506}
{"time": 1767079907.0123127, "phase": "train", "update": 507, "total_env_steps": 1622400, "episode_reward": 0.06659509986639023, "value_loss": 0.007775834202766419, "policy_loss": -0.0021395557852343927, "dist_entropy": 0.7446418523788452, "actor_grad_norm": 0.1317761093378067, "critic_grad_norm": 0.11938681453466415, "ratio": 1.0001243352890015, "entropy": 0.7446418523788452, "incre_win_rate": 0.0, "step": 507}
{"time": 1767079911.3942034, "phase": "train", "update": 508, "total_env_steps": 1625600, "episode_reward": 0.06801635026931763, "value_loss": 0.0071217968128621575, "policy_loss": -0.0021680833991325698, "dist_entropy": 0.6834452152252197, "actor_grad_norm": 0.15124087035655975, "critic_grad_norm": 0.06703242659568787, "ratio": 0.9998718500137329, "entropy": 0.6834452152252197, "incre_win_rate": 0.0, "step": 508}
{"time": 1767079915.7956877, "phase": "train", "update": 509, "total_env_steps": 1628800, "episode_reward": 0.06723561882972717, "value_loss": 0.005594686046242714, "policy_loss": -0.0014909084340231971, "dist_entropy": 0.6863644838333129, "actor_grad_norm": 0.1413039118051529, "critic_grad_norm": 0.06895247846841812, "ratio": 0.9995624423027039, "entropy": 0.6863644838333129, "incre_win_rate": 0.0, "step": 509}
{"time": 1767079920.1558323, "phase": "train", "update": 510, "total_env_steps": 1632000, "episode_reward": 0.060064151883125305, "value_loss": 0.004447091091424227, "policy_loss": -0.0023353598253095242, "dist_entropy": 0.6968351840972901, "actor_grad_norm": 0.15896835923194885, "critic_grad_norm": 0.04027624428272247, "ratio": 0.9998380541801453, "entropy": 0.6968351840972901, "incre_win_rate": 0.0, "step": 510}
{"time": 1767079924.6302786, "phase": "train", "update": 511, "total_env_steps": 1635200, "episode_reward": 0.06638193875551224, "value_loss": 0.004955244343727827, "policy_loss": -0.0018876647937020152, "dist_entropy": 0.6621673822402954, "actor_grad_norm": 0.15137629210948944, "critic_grad_norm": 0.03455207869410515, "ratio": 1.0003070831298828, "entropy": 0.6621673822402954, "incre_win_rate": 0.0, "step": 511}
{"time": 1767079928.9842901, "phase": "train", "update": 512, "total_env_steps": 1638400, "episode_reward": 0.06430773437023163, "value_loss": 0.00496900575235486, "policy_loss": -0.0014234038144387284, "dist_entropy": 0.6713593959808349, "actor_grad_norm": 0.14314322173595428, "critic_grad_norm": 0.04191441461443901, "ratio": 0.999927818775177, "entropy": 0.6713593959808349, "incre_win_rate": 0.0, "step": 512}
{"time": 1767079933.4402637, "phase": "train", "update": 513, "total_env_steps": 1641600, "episode_reward": 0.06502173095941544, "value_loss": 0.005480811838060618, "policy_loss": -0.0018274490388442643, "dist_entropy": 0.6660939693450928, "actor_grad_norm": 0.13492873311042786, "critic_grad_norm": 0.07916822284460068, "ratio": 1.0000312328338623, "entropy": 0.6660939693450928, "incre_win_rate": 0.0, "step": 513}
{"time": 1767079937.9650903, "phase": "train", "update": 514, "total_env_steps": 1644800, "episode_reward": 0.061720818281173706, "value_loss": 0.0035144282970577478, "policy_loss": -0.0014593925440699706, "dist_entropy": 0.6560505986213684, "actor_grad_norm": 0.10462283343076706, "critic_grad_norm": 0.044690653681755066, "ratio": 1.0002490282058716, "entropy": 0.6560505986213684, "incre_win_rate": 0.0, "step": 514}
{"time": 1767079942.4291055, "phase": "train", "update": 515, "total_env_steps": 1648000, "episode_reward": 0.06399161368608475, "value_loss": 0.006000850722193718, "policy_loss": -0.0016926571380423638, "dist_entropy": 0.6545831322669983, "actor_grad_norm": 0.142065167427063, "critic_grad_norm": 0.041924577206373215, "ratio": 1.0000308752059937, "entropy": 0.6545831322669983, "incre_win_rate": 0.0, "step": 515}
{"time": 1767079946.8476079, "phase": "train", "update": 516, "total_env_steps": 1651200, "episode_reward": 0.059780631214380264, "value_loss": 0.004280988965183497, "policy_loss": -0.0026332907170459664, "dist_entropy": 0.6427708506584168, "actor_grad_norm": 0.1563829630613327, "critic_grad_norm": 0.03293344005942345, "ratio": 0.9997579455375671, "entropy": 0.6427708506584168, "incre_win_rate": 0.0, "step": 516}
{"time": 1767079951.1725326, "phase": "train", "update": 517, "total_env_steps": 1654400, "episode_reward": 0.06181861087679863, "value_loss": 0.004024236742407083, "policy_loss": -0.00190200530033664, "dist_entropy": 0.6536184549331665, "actor_grad_norm": 0.13832996785640717, "critic_grad_norm": 0.03218291327357292, "ratio": 1.000119686126709, "entropy": 0.6536184549331665, "incre_win_rate": 0.0, "step": 517}
{"time": 1767079955.5538292, "phase": "train", "update": 518, "total_env_steps": 1657600, "episode_reward": 0.06495291739702225, "value_loss": 0.0036233055870980024, "policy_loss": -0.001489888953119589, "dist_entropy": 0.6226375818252563, "actor_grad_norm": 0.1225329041481018, "critic_grad_norm": 0.02329353243112564, "ratio": 0.9997403025627136, "entropy": 0.6226375818252563, "incre_win_rate": 0.0, "step": 518}
{"time": 1767079959.7630248, "phase": "train", "update": 519, "total_env_steps": 1660800, "episode_reward": 0.059368796646595, "value_loss": 0.0037515432573854922, "policy_loss": -0.0020510767374386065, "dist_entropy": 0.6400638103485108, "actor_grad_norm": 0.11240275949239731, "critic_grad_norm": 0.01909337192773819, "ratio": 0.9998376965522766, "entropy": 0.6400638103485108, "incre_win_rate": 0.0, "step": 519}
{"time": 1767079964.1289504, "phase": "train", "update": 520, "total_env_steps": 1664000, "episode_reward": 0.056100476533174515, "value_loss": 0.0041295233182609085, "policy_loss": -0.001435396029727798, "dist_entropy": 0.657326340675354, "actor_grad_norm": 0.09981510788202286, "critic_grad_norm": 0.06003863736987114, "ratio": 1.000109314918518, "entropy": 0.657326340675354, "incre_win_rate": 0.0, "step": 520}
{"time": 1767079968.4105592, "phase": "train", "update": 521, "total_env_steps": 1667200, "episode_reward": 0.06098148226737976, "value_loss": 0.0044111012481153015, "policy_loss": -0.0014144820425333825, "dist_entropy": 0.643736720085144, "actor_grad_norm": 0.12554194033145905, "critic_grad_norm": 0.0267289187759161, "ratio": 0.9999529719352722, "entropy": 0.643736720085144, "incre_win_rate": 0.0, "step": 521}
{"time": 1767079988.0081306, "phase": "eval", "update": 521, "total_env_steps": 1667200, "eval_win_rate": 0.0, "eval_episode_reward": 8.306136175496679, "step": 521}
{"time": 1767079992.406065, "phase": "train", "update": 522, "total_env_steps": 1670400, "episode_reward": 0.05834022909402847, "value_loss": 0.002893580263480544, "policy_loss": -0.0013752746696383156, "dist_entropy": 0.6698891639709472, "actor_grad_norm": 0.12557658553123474, "critic_grad_norm": 0.023333458229899406, "ratio": 1.0002142190933228, "entropy": 0.6698891639709472, "incre_win_rate": 0.0, "step": 522}
{"time": 1767079996.816784, "phase": "train", "update": 523, "total_env_steps": 1673600, "episode_reward": 0.05756312236189842, "value_loss": 0.0035318381618708373, "policy_loss": -0.0014319615109371852, "dist_entropy": 0.6677454352378845, "actor_grad_norm": 0.11688192188739777, "critic_grad_norm": 0.02010965347290039, "ratio": 0.9998616576194763, "entropy": 0.6677454352378845, "incre_win_rate": 0.0, "step": 523}
{"time": 1767080001.1567113, "phase": "train", "update": 524, "total_env_steps": 1676800, "episode_reward": 0.061500415205955505, "value_loss": 0.0034361238591372966, "policy_loss": -0.0014029142774361959, "dist_entropy": 0.6502396583557128, "actor_grad_norm": 0.11385666579008102, "critic_grad_norm": 0.014500933699309826, "ratio": 0.9999386668205261, "entropy": 0.6502396583557128, "incre_win_rate": 0.0, "step": 524}
{"time": 1767080005.6916447, "phase": "train", "update": 525, "total_env_steps": 1680000, "episode_reward": 0.06284509599208832, "value_loss": 0.004430615436285734, "policy_loss": -0.0018120524532262649, "dist_entropy": 0.6484544277191162, "actor_grad_norm": 0.09951774775981903, "critic_grad_norm": 0.017509812489151955, "ratio": 0.9998733401298523, "entropy": 0.6484544277191162, "incre_win_rate": 0.0, "step": 525}
{"time": 1767080010.425517, "phase": "train", "update": 526, "total_env_steps": 1683200, "episode_reward": 0.0646052360534668, "value_loss": 0.0037949084769934418, "policy_loss": -0.0014091876556392435, "dist_entropy": 0.6495372653007507, "actor_grad_norm": 0.10679514706134796, "critic_grad_norm": 0.031015662476420403, "ratio": 0.9999004602432251, "entropy": 0.6495372653007507, "incre_win_rate": 0.0, "step": 526}
{"time": 1767080014.8569272, "phase": "train", "update": 527, "total_env_steps": 1686400, "episode_reward": 0.06299564987421036, "value_loss": 0.003791713109239936, "policy_loss": -0.0020025190675301728, "dist_entropy": 0.667188823223114, "actor_grad_norm": 0.12826131284236908, "critic_grad_norm": 0.042260557413101196, "ratio": 1.0000507831573486, "entropy": 0.667188823223114, "incre_win_rate": 0.0, "step": 527}
{"time": 1767080019.3472245, "phase": "train", "update": 528, "total_env_steps": 1689600, "episode_reward": 0.06234943866729736, "value_loss": 0.0037483845837414263, "policy_loss": -0.0017773940254507182, "dist_entropy": 0.6807854294776916, "actor_grad_norm": 0.1311294585466385, "critic_grad_norm": 0.022205978631973267, "ratio": 1.0004256963729858, "entropy": 0.6807854294776916, "incre_win_rate": 0.0, "step": 528}
{"time": 1767080023.7263365, "phase": "train", "update": 529, "total_env_steps": 1692800, "episode_reward": 0.06372154504060745, "value_loss": 0.003728307643905282, "policy_loss": -0.001656349996196127, "dist_entropy": 0.6777745366096497, "actor_grad_norm": 0.12877683341503143, "critic_grad_norm": 0.050763316452503204, "ratio": 0.9996300935745239, "entropy": 0.6777745366096497, "incre_win_rate": 0.0, "step": 529}
{"time": 1767080028.1237242, "phase": "train", "update": 530, "total_env_steps": 1696000, "episode_reward": 0.06548479199409485, "value_loss": 0.004111445881426335, "policy_loss": -0.0013628714701031442, "dist_entropy": 0.6850776195526123, "actor_grad_norm": 0.12373387068510056, "critic_grad_norm": 0.03296368196606636, "ratio": 0.9999232292175293, "entropy": 0.6850776195526123, "incre_win_rate": 0.0, "step": 530}
{"time": 1767080032.489781, "phase": "train", "update": 531, "total_env_steps": 1699200, "episode_reward": 0.062628835439682, "value_loss": 0.002852003229781985, "policy_loss": -0.0012135969758432451, "dist_entropy": 0.6682595252990723, "actor_grad_norm": 0.1075763925909996, "critic_grad_norm": 0.05926797538995743, "ratio": 0.9999815225601196, "entropy": 0.6682595252990723, "incre_win_rate": 0.0, "step": 531}
{"time": 1767080036.8217287, "phase": "train", "update": 532, "total_env_steps": 1702400, "episode_reward": 0.06312655657529831, "value_loss": 0.003931697085499763, "policy_loss": -0.0018606356882202135, "dist_entropy": 0.7014594674110413, "actor_grad_norm": 0.13582630455493927, "critic_grad_norm": 0.03378601744771004, "ratio": 0.9998176693916321, "entropy": 0.7014594674110413, "incre_win_rate": 0.0, "step": 532}
{"time": 1767080041.1946518, "phase": "train", "update": 533, "total_env_steps": 1705600, "episode_reward": 0.06480701267719269, "value_loss": 0.0035004844423383473, "policy_loss": -0.0011807567351517889, "dist_entropy": 0.6581233263015747, "actor_grad_norm": 0.10578189045190811, "critic_grad_norm": 0.021042078733444214, "ratio": 1.000056266784668, "entropy": 0.6581233263015747, "incre_win_rate": 0.0, "step": 533}
{"time": 1767080045.4333427, "phase": "train", "update": 534, "total_env_steps": 1708800, "episode_reward": 0.0582062229514122, "value_loss": 0.0036090172827243803, "policy_loss": -0.0011735789943930542, "dist_entropy": 0.6687220931053162, "actor_grad_norm": 0.10986155271530151, "critic_grad_norm": 0.01847095601260662, "ratio": 1.000106692314148, "entropy": 0.6687220931053162, "incre_win_rate": 0.0, "step": 534}
{"time": 1767080049.9427443, "phase": "train", "update": 535, "total_env_steps": 1712000, "episode_reward": 0.06382502615451813, "value_loss": 0.0041833283379673954, "policy_loss": -0.001170817854583106, "dist_entropy": 0.6410379528999328, "actor_grad_norm": 0.11233004182577133, "critic_grad_norm": 0.04184039682149887, "ratio": 0.9999772906303406, "entropy": 0.6410379528999328, "incre_win_rate": 0.0, "step": 535}
{"time": 1767080054.503209, "phase": "train", "update": 536, "total_env_steps": 1715200, "episode_reward": 0.06354717910289764, "value_loss": 0.0033768934197723867, "policy_loss": -0.0012194993964858014, "dist_entropy": 0.6451045632362366, "actor_grad_norm": 0.08745044469833374, "critic_grad_norm": 0.03007700853049755, "ratio": 1.000030755996704, "entropy": 0.6451045632362366, "incre_win_rate": 0.0, "step": 536}
{"time": 1767080058.896231, "phase": "train", "update": 537, "total_env_steps": 1718400, "episode_reward": 0.058634623885154724, "value_loss": 0.0028823968023061752, "policy_loss": -0.0014365051299954246, "dist_entropy": 0.6587498784065247, "actor_grad_norm": 0.10011891275644302, "critic_grad_norm": 0.04226295277476311, "ratio": 1.0000358819961548, "entropy": 0.6587498784065247, "incre_win_rate": 0.0, "step": 537}
{"time": 1767080063.2277603, "phase": "train", "update": 538, "total_env_steps": 1721600, "episode_reward": 0.06900041550397873, "value_loss": 0.0037298752460628746, "policy_loss": -0.0015143874900694243, "dist_entropy": 0.653544819355011, "actor_grad_norm": 0.11819052696228027, "critic_grad_norm": 0.04860208183526993, "ratio": 1.0003629922866821, "entropy": 0.653544819355011, "incre_win_rate": 0.0, "step": 538}
{"time": 1767080067.7472866, "phase": "train", "update": 539, "total_env_steps": 1724800, "episode_reward": 0.06411629915237427, "value_loss": 0.00436791917309165, "policy_loss": -0.002084492992435116, "dist_entropy": 0.6779323577880859, "actor_grad_norm": 0.16769659519195557, "critic_grad_norm": 0.03330272436141968, "ratio": 0.999890148639679, "entropy": 0.6779323577880859, "incre_win_rate": 0.0, "step": 539}
{"time": 1767080072.161144, "phase": "train", "update": 540, "total_env_steps": 1728000, "episode_reward": 0.05957936868071556, "value_loss": 0.0033815424423664807, "policy_loss": -0.0015948755034457917, "dist_entropy": 0.7169037461280823, "actor_grad_norm": 0.11378484219312668, "critic_grad_norm": 0.024470264092087746, "ratio": 0.9999818801879883, "entropy": 0.7169037461280823, "incre_win_rate": 0.0, "step": 540}
{"time": 1767080076.7308235, "phase": "train", "update": 541, "total_env_steps": 1731200, "episode_reward": 0.0626102089881897, "value_loss": 0.0038719563744962215, "policy_loss": -0.0012299066400073499, "dist_entropy": 0.7087646126747131, "actor_grad_norm": 0.11816810816526413, "critic_grad_norm": 0.037132348865270615, "ratio": 0.9997279047966003, "entropy": 0.7087646126747131, "incre_win_rate": 0.0, "step": 541}
{"time": 1767080095.9369223, "phase": "eval", "update": 541, "total_env_steps": 1731200, "eval_win_rate": 0.0, "eval_episode_reward": 7.9089921357615784, "step": 541}
{"time": 1767080100.223277, "phase": "train", "update": 542, "total_env_steps": 1734400, "episode_reward": 0.0619603730738163, "value_loss": 0.004322801250964403, "policy_loss": -0.0013412986072644628, "dist_entropy": 0.6886252522468567, "actor_grad_norm": 0.14076469838619232, "critic_grad_norm": 0.027793515473604202, "ratio": 0.9998272061347961, "entropy": 0.6886252522468567, "incre_win_rate": 0.0, "step": 542}
{"time": 1767080104.6788385, "phase": "train", "update": 543, "total_env_steps": 1737600, "episode_reward": 0.06221337243914604, "value_loss": 0.002794862538576126, "policy_loss": -0.0013287141060985164, "dist_entropy": 0.6695925235748291, "actor_grad_norm": 0.15914908051490784, "critic_grad_norm": 0.06169532611966133, "ratio": 0.9998440146446228, "entropy": 0.6695925235748291, "incre_win_rate": 0.0, "step": 543}
{"time": 1767080108.9570935, "phase": "train", "update": 544, "total_env_steps": 1740800, "episode_reward": 0.05827711522579193, "value_loss": 0.0031587359961122276, "policy_loss": -0.0015406078666451606, "dist_entropy": 0.6689903497695923, "actor_grad_norm": 0.14196322858333588, "critic_grad_norm": 0.03081413172185421, "ratio": 1.0001357793807983, "entropy": 0.6689903497695923, "incre_win_rate": 0.0, "step": 544}
{"time": 1767080113.084516, "phase": "train", "update": 545, "total_env_steps": 1744000, "episode_reward": 0.062451884150505066, "value_loss": 0.003933219145983458, "policy_loss": -0.0012577644040526082, "dist_entropy": 0.6414959311485291, "actor_grad_norm": 0.13812457025051117, "critic_grad_norm": 0.0662703737616539, "ratio": 0.99969482421875, "entropy": 0.6414959311485291, "incre_win_rate": 0.0, "step": 545}
{"time": 1767080117.3823931, "phase": "train", "update": 546, "total_env_steps": 1747200, "episode_reward": 0.05741773918271065, "value_loss": 0.0025150127708911895, "policy_loss": -0.0015925956229516202, "dist_entropy": 0.6522810935974122, "actor_grad_norm": 0.12099509686231613, "critic_grad_norm": 0.046250175684690475, "ratio": 0.9999632835388184, "entropy": 0.6522810935974122, "incre_win_rate": 0.0, "step": 546}
{"time": 1767080121.6648889, "phase": "train", "update": 547, "total_env_steps": 1750400, "episode_reward": 0.05834954231977463, "value_loss": 0.003441368043422699, "policy_loss": -0.0008444115238479099, "dist_entropy": 0.6540095090866089, "actor_grad_norm": 0.11351633071899414, "critic_grad_norm": 0.04892037436366081, "ratio": 0.9998189806938171, "entropy": 0.6540095090866089, "incre_win_rate": 0.0, "step": 547}
{"time": 1767080125.8801825, "phase": "train", "update": 548, "total_env_steps": 1753600, "episode_reward": 0.06040873005986214, "value_loss": 0.0024749692529439926, "policy_loss": -0.0012140854305839888, "dist_entropy": 0.644425892829895, "actor_grad_norm": 0.11761533468961716, "critic_grad_norm": 0.03343311324715614, "ratio": 1.0000438690185547, "entropy": 0.644425892829895, "incre_win_rate": 0.0, "step": 548}
{"time": 1767080130.1482525, "phase": "train", "update": 549, "total_env_steps": 1756800, "episode_reward": 0.06380122154951096, "value_loss": 0.0038486847188323736, "policy_loss": -0.0017077777206850441, "dist_entropy": 0.6727650403976441, "actor_grad_norm": 0.1926550567150116, "critic_grad_norm": 0.018197452649474144, "ratio": 1.0000486373901367, "entropy": 0.6727650403976441, "incre_win_rate": 0.0, "step": 549}
{"time": 1767080134.3157237, "phase": "train", "update": 550, "total_env_steps": 1760000, "episode_reward": 0.05970974266529083, "value_loss": 0.002841684361919761, "policy_loss": -0.0013477687539584337, "dist_entropy": 0.671002459526062, "actor_grad_norm": 0.1469150334596634, "critic_grad_norm": 0.032926641404628754, "ratio": 0.9999022483825684, "entropy": 0.671002459526062, "incre_win_rate": 0.0, "step": 550}
{"time": 1767080138.6720192, "phase": "train", "update": 551, "total_env_steps": 1763200, "episode_reward": 0.06284406036138535, "value_loss": 0.004012094158679247, "policy_loss": -0.0020252082376160272, "dist_entropy": 0.6443370223045349, "actor_grad_norm": 0.15396647155284882, "critic_grad_norm": 0.02014016918838024, "ratio": 0.9996630549430847, "entropy": 0.6443370223045349, "incre_win_rate": 0.0, "step": 551}
{"time": 1767080142.9465148, "phase": "train", "update": 552, "total_env_steps": 1766400, "episode_reward": 0.05867549777030945, "value_loss": 0.002783715771511197, "policy_loss": -0.0012872743929207785, "dist_entropy": 0.6369812726974488, "actor_grad_norm": 0.11331864446401596, "critic_grad_norm": 0.015451534651219845, "ratio": 0.9998887181282043, "entropy": 0.6369812726974488, "incre_win_rate": 0.0, "step": 552}
{"time": 1767080147.369084, "phase": "train", "update": 553, "total_env_steps": 1769600, "episode_reward": 0.06571916490793228, "value_loss": 0.0035299776121973992, "policy_loss": -0.0015441768158250824, "dist_entropy": 0.6246901869773864, "actor_grad_norm": 0.12801805138587952, "critic_grad_norm": 0.016532275825738907, "ratio": 0.9998610615730286, "entropy": 0.6246901869773864, "incre_win_rate": 0.0, "step": 553}
{"time": 1767080151.7029, "phase": "train", "update": 554, "total_env_steps": 1772800, "episode_reward": 0.0634116381406784, "value_loss": 0.0033599883317947388, "policy_loss": -0.0012886311091435231, "dist_entropy": 0.6528734922409057, "actor_grad_norm": 0.11871106922626495, "critic_grad_norm": 0.022305380553007126, "ratio": 0.9999315142631531, "entropy": 0.6528734922409057, "incre_win_rate": 0.0, "step": 554}
{"time": 1767080155.999142, "phase": "train", "update": 555, "total_env_steps": 1776000, "episode_reward": 0.05849389731884003, "value_loss": 0.002586450334638357, "policy_loss": -0.0013058301012563334, "dist_entropy": 0.6684446215629578, "actor_grad_norm": 0.10570438206195831, "critic_grad_norm": 0.013628204353153706, "ratio": 0.9999092221260071, "entropy": 0.6684446215629578, "incre_win_rate": 0.0, "step": 555}
{"time": 1767080160.3379016, "phase": "train", "update": 556, "total_env_steps": 1779200, "episode_reward": 0.06481529027223587, "value_loss": 0.003573279874399304, "policy_loss": -0.001343884219551228, "dist_entropy": 0.6781936526298523, "actor_grad_norm": 0.11742663383483887, "critic_grad_norm": 0.01531153917312622, "ratio": 1.0000876188278198, "entropy": 0.6781936526298523, "incre_win_rate": 0.0, "step": 556}
{"time": 1767080164.6214666, "phase": "train", "update": 557, "total_env_steps": 1782400, "episode_reward": 0.06575900316238403, "value_loss": 0.005025250744074583, "policy_loss": -0.001378783894966773, "dist_entropy": 0.6754197359085083, "actor_grad_norm": 0.12797346711158752, "critic_grad_norm": 0.013014341704547405, "ratio": 0.9998283386230469, "entropy": 0.6754197359085083, "incre_win_rate": 0.0, "step": 557}
{"time": 1767080168.884825, "phase": "train", "update": 558, "total_env_steps": 1785600, "episode_reward": 0.05875414237380028, "value_loss": 0.0033307472709566354, "policy_loss": -0.0019349977702347587, "dist_entropy": 0.7015745759010314, "actor_grad_norm": 0.11644934862852097, "critic_grad_norm": 0.027150971814990044, "ratio": 1.0000501871109009, "entropy": 0.7015745759010314, "incre_win_rate": 0.0, "step": 558}
{"time": 1767080173.167043, "phase": "train", "update": 559, "total_env_steps": 1788800, "episode_reward": 0.067105233669281, "value_loss": 0.0027977236546576022, "policy_loss": -0.0014592453834524123, "dist_entropy": 0.6761994361877441, "actor_grad_norm": 0.1173337921500206, "critic_grad_norm": 0.024504555389285088, "ratio": 0.9999605417251587, "entropy": 0.6761994361877441, "incre_win_rate": 0.0, "step": 559}
{"time": 1767080177.5231402, "phase": "train", "update": 560, "total_env_steps": 1792000, "episode_reward": 0.05914320796728134, "value_loss": 0.004411735571920872, "policy_loss": -0.001301833415942255, "dist_entropy": 0.6805790781974792, "actor_grad_norm": 0.11189445108175278, "critic_grad_norm": 0.04713677987456322, "ratio": 1.000037670135498, "entropy": 0.6805790781974792, "incre_win_rate": 0.0, "step": 560}
{"time": 1767080181.839923, "phase": "train", "update": 561, "total_env_steps": 1795200, "episode_reward": 0.05857926234602928, "value_loss": 0.004449660703539848, "policy_loss": -0.002357508306829459, "dist_entropy": 0.7048938870429993, "actor_grad_norm": 0.1653800755739212, "critic_grad_norm": 0.0522085502743721, "ratio": 0.9999308586120605, "entropy": 0.7048938870429993, "incre_win_rate": 0.0, "step": 561}
{"time": 1767080200.3113751, "phase": "eval", "update": 561, "total_env_steps": 1795200, "eval_win_rate": 0.0, "eval_episode_reward": 8.545943708609261, "step": 561}
{"time": 1767080204.6036794, "phase": "train", "update": 562, "total_env_steps": 1798400, "episode_reward": 0.06793667376041412, "value_loss": 0.00398689373396337, "policy_loss": -0.0015219710499209782, "dist_entropy": 0.6735170960426331, "actor_grad_norm": 0.1567566990852356, "critic_grad_norm": 0.07933048158884048, "ratio": 0.9998389482498169, "entropy": 0.6735170960426331, "incre_win_rate": 0.0, "step": 562}
{"time": 1767080208.8848813, "phase": "train", "update": 563, "total_env_steps": 1801600, "episode_reward": 0.06062965840101242, "value_loss": 0.002968333149328828, "policy_loss": -0.0008271292570618983, "dist_entropy": 0.6643549680709839, "actor_grad_norm": 0.11749179661273956, "critic_grad_norm": 0.043591249734163284, "ratio": 1.000161051750183, "entropy": 0.6643549680709839, "incre_win_rate": 0.0, "step": 563}
{"time": 1767080213.2314045, "phase": "train", "update": 564, "total_env_steps": 1804800, "episode_reward": 0.0625569075345993, "value_loss": 0.004553434625267983, "policy_loss": -0.0015154456483713829, "dist_entropy": 0.6821886658668518, "actor_grad_norm": 0.12493918091058731, "critic_grad_norm": 0.03217853978276253, "ratio": 1.0001769065856934, "entropy": 0.6821886658668518, "incre_win_rate": 0.0, "step": 564}
{"time": 1767080217.61834, "phase": "train", "update": 565, "total_env_steps": 1808000, "episode_reward": 0.06703901290893555, "value_loss": 0.002734561311081052, "policy_loss": -0.0015663736982912014, "dist_entropy": 0.6992493033409118, "actor_grad_norm": 0.12956801056861877, "critic_grad_norm": 0.02617172710597515, "ratio": 0.9999876022338867, "entropy": 0.6992493033409118, "incre_win_rate": 0.0, "step": 565}
{"time": 1767080221.883541, "phase": "train", "update": 566, "total_env_steps": 1811200, "episode_reward": 0.06302979588508606, "value_loss": 0.00314449411816895, "policy_loss": -0.001647539630710426, "dist_entropy": 0.7085773229599, "actor_grad_norm": 0.12180950492620468, "critic_grad_norm": 0.024358266964554787, "ratio": 1.0001786947250366, "entropy": 0.7085773229599, "incre_win_rate": 0.0, "step": 566}
{"time": 1767080226.2067704, "phase": "train", "update": 567, "total_env_steps": 1814400, "episode_reward": 0.06324762105941772, "value_loss": 0.0032631942071020604, "policy_loss": -0.0017802704008005321, "dist_entropy": 0.692386794090271, "actor_grad_norm": 0.12843315303325653, "critic_grad_norm": 0.014390513300895691, "ratio": 1.000205159187317, "entropy": 0.692386794090271, "incre_win_rate": 0.0, "step": 567}
{"time": 1767080230.5072896, "phase": "train", "update": 568, "total_env_steps": 1817600, "episode_reward": 0.06712386012077332, "value_loss": 0.002998918294906616, "policy_loss": -0.0014853944213491844, "dist_entropy": 0.6455332159996032, "actor_grad_norm": 0.13639359176158905, "critic_grad_norm": 0.030512792989611626, "ratio": 0.9997591376304626, "entropy": 0.6455332159996032, "incre_win_rate": 0.0, "step": 568}
{"time": 1767080234.8083265, "phase": "train", "update": 569, "total_env_steps": 1820800, "episode_reward": 0.06390883773565292, "value_loss": 0.0036460595205426217, "policy_loss": -0.0016921825537321133, "dist_entropy": 0.6818068504333497, "actor_grad_norm": 0.1455574333667755, "critic_grad_norm": 0.017882654443383217, "ratio": 0.9997445940971375, "entropy": 0.6818068504333497, "incre_win_rate": 0.0, "step": 569}
{"time": 1767080239.0809906, "phase": "train", "update": 570, "total_env_steps": 1824000, "episode_reward": 0.06461920589208603, "value_loss": 0.0021749799605458977, "policy_loss": -0.000943748970270164, "dist_entropy": 0.698993718624115, "actor_grad_norm": 0.12849685549736023, "critic_grad_norm": 0.02454741857945919, "ratio": 1.0003982782363892, "entropy": 0.698993718624115, "incre_win_rate": 0.0, "step": 570}
{"time": 1767080243.3166745, "phase": "train", "update": 571, "total_env_steps": 1827200, "episode_reward": 0.07148540765047073, "value_loss": 0.0032571413088589908, "policy_loss": -0.00151861008762868, "dist_entropy": 0.7009941935539246, "actor_grad_norm": 0.13013283908367157, "critic_grad_norm": 0.02048408053815365, "ratio": 0.9999383091926575, "entropy": 0.7009941935539246, "incre_win_rate": 0.0, "step": 571}
{"time": 1767080247.6164136, "phase": "train", "update": 572, "total_env_steps": 1830400, "episode_reward": 0.06857874989509583, "value_loss": 0.003374771308153868, "policy_loss": -0.0009228045048438105, "dist_entropy": 0.7082816958427429, "actor_grad_norm": 0.15154026448726654, "critic_grad_norm": 0.03351685032248497, "ratio": 1.0005391836166382, "entropy": 0.7082816958427429, "incre_win_rate": 0.0, "step": 572}
{"time": 1767080251.9493077, "phase": "train", "update": 573, "total_env_steps": 1833600, "episode_reward": 0.07058257609605789, "value_loss": 0.0034206807613372803, "policy_loss": -0.000843692261010176, "dist_entropy": 0.7089514613151551, "actor_grad_norm": 0.12118591368198395, "critic_grad_norm": 0.037770964205265045, "ratio": 0.9999343752861023, "entropy": 0.7089514613151551, "incre_win_rate": 0.0, "step": 573}
{"time": 1767080256.3472416, "phase": "train", "update": 574, "total_env_steps": 1836800, "episode_reward": 0.06944639980792999, "value_loss": 0.002618509437888861, "policy_loss": -0.0010595443122369374, "dist_entropy": 0.7095833539962768, "actor_grad_norm": 0.16590192914009094, "critic_grad_norm": 0.027137313038110733, "ratio": 1.0000942945480347, "entropy": 0.7095833539962768, "incre_win_rate": 0.0, "step": 574}
{"time": 1767080260.7423732, "phase": "train", "update": 575, "total_env_steps": 1840000, "episode_reward": 0.07109581679105759, "value_loss": 0.0036077880300581454, "policy_loss": -0.001670883576965565, "dist_entropy": 0.69011310338974, "actor_grad_norm": 0.11059071868658066, "critic_grad_norm": 0.02819347381591797, "ratio": 0.999742329120636, "entropy": 0.69011310338974, "incre_win_rate": 0.0, "step": 575}
{"time": 1767080265.0142012, "phase": "train", "update": 576, "total_env_steps": 1843200, "episode_reward": 0.07120344042778015, "value_loss": 0.0037663279566913844, "policy_loss": -0.0016496514210373903, "dist_entropy": 0.7034219622611999, "actor_grad_norm": 0.12456583976745605, "critic_grad_norm": 0.05211815983057022, "ratio": 1.000022053718567, "entropy": 0.7034219622611999, "incre_win_rate": 0.0, "step": 576}
{"time": 1767080269.2980764, "phase": "train", "update": 577, "total_env_steps": 1846400, "episode_reward": 0.06700590252876282, "value_loss": 0.0031078564934432507, "policy_loss": -0.0016834358179465881, "dist_entropy": 0.70997314453125, "actor_grad_norm": 0.13383297622203827, "critic_grad_norm": 0.03522523120045662, "ratio": 0.9998230338096619, "entropy": 0.70997314453125, "incre_win_rate": 0.0, "step": 577}
{"time": 1767080273.573874, "phase": "train", "update": 578, "total_env_steps": 1849600, "episode_reward": 0.0729382261633873, "value_loss": 0.0034930961206555366, "policy_loss": -0.001780069311185173, "dist_entropy": 0.6956329822540284, "actor_grad_norm": 0.11318664997816086, "critic_grad_norm": 0.020417863503098488, "ratio": 1.0001333951950073, "entropy": 0.6956329822540284, "incre_win_rate": 0.0, "step": 578}
{"time": 1767080277.824255, "phase": "train", "update": 579, "total_env_steps": 1852800, "episode_reward": 0.0738503709435463, "value_loss": 0.0034112873021513225, "policy_loss": -0.0017390374255711548, "dist_entropy": 0.7206192374229431, "actor_grad_norm": 0.11633002012968063, "critic_grad_norm": 0.03005528263747692, "ratio": 1.0001475811004639, "entropy": 0.7206192374229431, "incre_win_rate": 0.0, "step": 579}
{"time": 1767080282.0095677, "phase": "train", "update": 580, "total_env_steps": 1856000, "episode_reward": 0.06750155240297318, "value_loss": 0.002920418558642268, "policy_loss": -0.0017837990013060078, "dist_entropy": 0.7426047444343566, "actor_grad_norm": 0.1259678602218628, "critic_grad_norm": 0.038198310881853104, "ratio": 1.0001020431518555, "entropy": 0.7426047444343566, "incre_win_rate": 0.0, "step": 580}
{"time": 1767080286.337893, "phase": "train", "update": 581, "total_env_steps": 1859200, "episode_reward": 0.07882346957921982, "value_loss": 0.003983698831871152, "policy_loss": -0.0014495492943936484, "dist_entropy": 0.7032472491264343, "actor_grad_norm": 0.13536487519741058, "critic_grad_norm": 0.03385351225733757, "ratio": 1.0001474618911743, "entropy": 0.7032472491264343, "incre_win_rate": 0.0, "step": 581}
{"time": 1767080305.319277, "phase": "eval", "update": 581, "total_env_steps": 1859200, "eval_win_rate": 0.0, "eval_episode_reward": 10.042942880794687, "step": 581}
{"time": 1767080309.5863006, "phase": "train", "update": 582, "total_env_steps": 1862400, "episode_reward": 0.07084386050701141, "value_loss": 0.008542943745851517, "policy_loss": -0.001223802825329301, "dist_entropy": 0.7057212114334106, "actor_grad_norm": 0.11886992305517197, "critic_grad_norm": 0.11488837003707886, "ratio": 1.000020980834961, "entropy": 0.7057212114334106, "incre_win_rate": 0.0, "step": 582}
{"time": 1767080313.855479, "phase": "train", "update": 583, "total_env_steps": 1865600, "episode_reward": 0.07018936425447464, "value_loss": 0.005566454492509365, "policy_loss": -0.0018868143123867754, "dist_entropy": 0.6946937918663025, "actor_grad_norm": 0.12580561637878418, "critic_grad_norm": 0.07178046554327011, "ratio": 0.9995737075805664, "entropy": 0.6946937918663025, "incre_win_rate": 0.0, "step": 583}
{"time": 1767080318.1589541, "phase": "train", "update": 584, "total_env_steps": 1868800, "episode_reward": 0.07202401012182236, "value_loss": 0.004988889675587416, "policy_loss": -0.0022972463606784287, "dist_entropy": 0.7020010590553284, "actor_grad_norm": 0.14374056458473206, "critic_grad_norm": 0.05131077766418457, "ratio": 0.9996183514595032, "entropy": 0.7020010590553284, "incre_win_rate": 0.0, "step": 584}
{"time": 1767080322.5153437, "phase": "train", "update": 585, "total_env_steps": 1872000, "episode_reward": 0.07846130430698395, "value_loss": 0.0052248452790081504, "policy_loss": -0.0011620313923188519, "dist_entropy": 0.6733673453330994, "actor_grad_norm": 0.12724566459655762, "critic_grad_norm": 0.05402248725295067, "ratio": 1.0001386404037476, "entropy": 0.6733673453330994, "incre_win_rate": 0.0, "step": 585}
{"time": 1767080326.9005458, "phase": "train", "update": 586, "total_env_steps": 1875200, "episode_reward": 0.06763400882482529, "value_loss": 0.00490921139717102, "policy_loss": -0.002058974696668159, "dist_entropy": 0.7019547820091248, "actor_grad_norm": 0.14888505637645721, "critic_grad_norm": 0.036380134522914886, "ratio": 0.9997745752334595, "entropy": 0.7019547820091248, "incre_win_rate": 0.0, "step": 586}
{"time": 1767080331.3051665, "phase": "train", "update": 587, "total_env_steps": 1878400, "episode_reward": 0.07970302551984787, "value_loss": 0.005644341185688973, "policy_loss": -0.0013331494633938234, "dist_entropy": 0.6856491923332214, "actor_grad_norm": 0.11427493393421173, "critic_grad_norm": 0.03290332481265068, "ratio": 0.9999906420707703, "entropy": 0.6856491923332214, "incre_win_rate": 0.0, "step": 587}
{"time": 1767080335.5974994, "phase": "train", "update": 588, "total_env_steps": 1881600, "episode_reward": 0.07204729318618774, "value_loss": 0.0044843491166830065, "policy_loss": -0.0020006659245925817, "dist_entropy": 0.68678719997406, "actor_grad_norm": 0.1524105817079544, "critic_grad_norm": 0.05476099252700806, "ratio": 0.9998427629470825, "entropy": 0.68678719997406, "incre_win_rate": 0.0, "step": 588}
{"time": 1767080339.9534106, "phase": "train", "update": 589, "total_env_steps": 1884800, "episode_reward": 0.06939828395843506, "value_loss": 0.0036852766759693624, "policy_loss": -0.0015425329085296368, "dist_entropy": 0.6878154277801514, "actor_grad_norm": 0.1659180074930191, "critic_grad_norm": 0.04698237404227257, "ratio": 0.9998726844787598, "entropy": 0.6878154277801514, "incre_win_rate": 0.0, "step": 589}
{"time": 1767080344.377561, "phase": "train", "update": 590, "total_env_steps": 1888000, "episode_reward": 0.07812810689210892, "value_loss": 0.0050204828381538395, "policy_loss": -0.0012130861938636883, "dist_entropy": 0.6648149251937866, "actor_grad_norm": 0.09210880845785141, "critic_grad_norm": 0.04393196851015091, "ratio": 0.9998381733894348, "entropy": 0.6648149251937866, "incre_win_rate": 0.0, "step": 590}
{"time": 1767080348.8567321, "phase": "train", "update": 591, "total_env_steps": 1891200, "episode_reward": 0.07322640717029572, "value_loss": 0.004360278230160474, "policy_loss": -0.0014155456269783428, "dist_entropy": 0.657610821723938, "actor_grad_norm": 0.11490330845117569, "critic_grad_norm": 0.02348043955862522, "ratio": 1.0001264810562134, "entropy": 0.657610821723938, "incre_win_rate": 0.0, "step": 591}
{"time": 1767080353.4995668, "phase": "train", "update": 592, "total_env_steps": 1894400, "episode_reward": 0.06774317473173141, "value_loss": 0.0038166246842592953, "policy_loss": -0.0011820900991715844, "dist_entropy": 0.6807444572448731, "actor_grad_norm": 0.13121765851974487, "critic_grad_norm": 0.03983579948544502, "ratio": 0.9999296069145203, "entropy": 0.6807444572448731, "incre_win_rate": 0.0, "step": 592}
{"time": 1767080358.030235, "phase": "train", "update": 593, "total_env_steps": 1897600, "episode_reward": 0.07109685242176056, "value_loss": 0.0025846386794000863, "policy_loss": -0.0013172338611049383, "dist_entropy": 0.679308819770813, "actor_grad_norm": 0.12262841314077377, "critic_grad_norm": 0.037857234477996826, "ratio": 0.9998347163200378, "entropy": 0.679308819770813, "incre_win_rate": 0.0, "step": 593}
{"time": 1767080362.3989081, "phase": "train", "update": 594, "total_env_steps": 1900800, "episode_reward": 0.07221906632184982, "value_loss": 0.002962038293480873, "policy_loss": -0.001532164227049293, "dist_entropy": 0.6851242184638977, "actor_grad_norm": 0.12539049983024597, "critic_grad_norm": 0.027721522375941277, "ratio": 0.9999547004699707, "entropy": 0.6851242184638977, "incre_win_rate": 0.0, "step": 594}
{"time": 1767080366.607672, "phase": "train", "update": 595, "total_env_steps": 1904000, "episode_reward": 0.06350631266832352, "value_loss": 0.003030225448310375, "policy_loss": -0.0012892978784449839, "dist_entropy": 0.7056070446968079, "actor_grad_norm": 0.11416023224592209, "critic_grad_norm": 0.02516350708901882, "ratio": 0.999757707118988, "entropy": 0.7056070446968079, "incre_win_rate": 0.0, "step": 595}
{"time": 1767080371.0148127, "phase": "train", "update": 596, "total_env_steps": 1907200, "episode_reward": 0.07836661487817764, "value_loss": 0.0035199082456529142, "policy_loss": -0.0013618098716705162, "dist_entropy": 0.7118039846420288, "actor_grad_norm": 0.10768496245145798, "critic_grad_norm": 0.029726503416895866, "ratio": 1.000096321105957, "entropy": 0.7118039846420288, "incre_win_rate": 0.0, "step": 596}
{"time": 1767080375.3830037, "phase": "train", "update": 597, "total_env_steps": 1910400, "episode_reward": 0.07363773137331009, "value_loss": 0.003091344842687249, "policy_loss": -0.0014829079298031012, "dist_entropy": 0.7214663863182068, "actor_grad_norm": 0.11046230792999268, "critic_grad_norm": 0.04614796116948128, "ratio": 1.0003026723861694, "entropy": 0.7214663863182068, "incre_win_rate": 0.0, "step": 597}
{"time": 1767080379.6785648, "phase": "train", "update": 598, "total_env_steps": 1913600, "episode_reward": 0.06480908393859863, "value_loss": 0.0034565662499517202, "policy_loss": -0.0012559925741555845, "dist_entropy": 0.7420758724212646, "actor_grad_norm": 0.11490929126739502, "critic_grad_norm": 0.026599496603012085, "ratio": 0.9999843835830688, "entropy": 0.7420758724212646, "incre_win_rate": 0.0, "step": 598}
{"time": 1767080384.0375402, "phase": "train", "update": 599, "total_env_steps": 1916800, "episode_reward": 0.07659664750099182, "value_loss": 0.004882232751697302, "policy_loss": -0.0016100254845291318, "dist_entropy": 0.7422592997550964, "actor_grad_norm": 0.11028555780649185, "critic_grad_norm": 0.04014484956860542, "ratio": 0.9998750686645508, "entropy": 0.7422592997550964, "incre_win_rate": 0.0, "step": 599}
{"time": 1767080388.4545383, "phase": "train", "update": 600, "total_env_steps": 1920000, "episode_reward": 0.07379035651683807, "value_loss": 0.0037973800674080847, "policy_loss": -0.001766720874423555, "dist_entropy": 0.7469716906547547, "actor_grad_norm": 0.11598952859640121, "critic_grad_norm": 0.04415181279182434, "ratio": 0.999846875667572, "entropy": 0.7469716906547547, "incre_win_rate": 0.0, "step": 600}
{"time": 1767080392.7841337, "phase": "train", "update": 601, "total_env_steps": 1923200, "episode_reward": 0.07093284279108047, "value_loss": 0.005163521599024534, "policy_loss": -0.0017691053561925685, "dist_entropy": 0.7810108184814453, "actor_grad_norm": 0.11932513862848282, "critic_grad_norm": 0.06919264048337936, "ratio": 0.9999066591262817, "entropy": 0.7810108184814453, "incre_win_rate": 0.0, "step": 601}
{"time": 1767080412.737705, "phase": "eval", "update": 601, "total_env_steps": 1923200, "eval_win_rate": 0.0, "eval_episode_reward": 9.745188327814567, "step": 601}
{"time": 1767080417.582545, "phase": "train", "update": 602, "total_env_steps": 1926400, "episode_reward": 0.0776614248752594, "value_loss": 0.004890954587608576, "policy_loss": -0.0017692577000013809, "dist_entropy": 0.7496828198432922, "actor_grad_norm": 0.11241817474365234, "critic_grad_norm": 0.037849485874176025, "ratio": 1.0000718832015991, "entropy": 0.7496828198432922, "incre_win_rate": 0.0, "step": 602}
{"time": 1767080422.485139, "phase": "train", "update": 603, "total_env_steps": 1929600, "episode_reward": 0.075936459004879, "value_loss": 0.005917737632989884, "policy_loss": -0.001621746901081167, "dist_entropy": 0.7200434446334839, "actor_grad_norm": 0.1306365579366684, "critic_grad_norm": 0.03412078693509102, "ratio": 1.0001718997955322, "entropy": 0.7200434446334839, "incre_win_rate": 0.0, "step": 603}
{"time": 1767080427.3206525, "phase": "train", "update": 604, "total_env_steps": 1932800, "episode_reward": 0.07501138001680374, "value_loss": 0.005915036611258984, "policy_loss": -0.0020044873596674504, "dist_entropy": 0.7385832905769348, "actor_grad_norm": 0.12481784075498581, "critic_grad_norm": 0.0492062084376812, "ratio": 0.9997315406799316, "entropy": 0.7385832905769348, "incre_win_rate": 0.0, "step": 604}
{"time": 1767080432.1283033, "phase": "train", "update": 605, "total_env_steps": 1936000, "episode_reward": 0.06892332434654236, "value_loss": 0.0044213030487298965, "policy_loss": -0.0020217315663156655, "dist_entropy": 0.7600082278251648, "actor_grad_norm": 0.13940231502056122, "critic_grad_norm": 0.026929093524813652, "ratio": 1.0000194311141968, "entropy": 0.7600082278251648, "incre_win_rate": 0.0, "step": 605}
{"time": 1767080436.5643885, "phase": "train", "update": 606, "total_env_steps": 1939200, "episode_reward": 0.06589403748512268, "value_loss": 0.002572864992544055, "policy_loss": -0.0013342659132405288, "dist_entropy": 0.7396448254585266, "actor_grad_norm": 0.10356294363737106, "critic_grad_norm": 0.041716527193784714, "ratio": 1.0000537633895874, "entropy": 0.7396448254585266, "incre_win_rate": 0.0, "step": 606}
{"time": 1767080440.9251404, "phase": "train", "update": 607, "total_env_steps": 1942400, "episode_reward": 0.08064518123865128, "value_loss": 0.0049667379818856714, "policy_loss": -0.0012819325248116797, "dist_entropy": 0.7151415348052979, "actor_grad_norm": 0.10224443674087524, "critic_grad_norm": 0.03781319782137871, "ratio": 1.0000507831573486, "entropy": 0.7151415348052979, "incre_win_rate": 0.0, "step": 607}
{"time": 1767080445.2166054, "phase": "train", "update": 608, "total_env_steps": 1945600, "episode_reward": 0.07856633514165878, "value_loss": 0.00527542494237423, "policy_loss": -0.0022190503999865996, "dist_entropy": 0.7091888546943664, "actor_grad_norm": 0.13589467108249664, "critic_grad_norm": 0.06854657083749771, "ratio": 0.999842643737793, "entropy": 0.7091888546943664, "incre_win_rate": 0.0, "step": 608}
{"time": 1767080449.5642257, "phase": "train", "update": 609, "total_env_steps": 1948800, "episode_reward": 0.07658940553665161, "value_loss": 0.004522544145584106, "policy_loss": -0.0021131615365632683, "dist_entropy": 0.7061277270317078, "actor_grad_norm": 0.1324731558561325, "critic_grad_norm": 0.04245593771338463, "ratio": 0.9999781847000122, "entropy": 0.7061277270317078, "incre_win_rate": 0.0, "step": 609}
{"time": 1767080453.935653, "phase": "train", "update": 610, "total_env_steps": 1952000, "episode_reward": 0.07260657846927643, "value_loss": 0.0038529270328581332, "policy_loss": -0.001735547430554618, "dist_entropy": 0.7026708602905274, "actor_grad_norm": 0.173904687166214, "critic_grad_norm": 0.03966061398386955, "ratio": 1.0000287294387817, "entropy": 0.7026708602905274, "incre_win_rate": 0.0, "step": 610}
{"time": 1767080458.0744169, "phase": "train", "update": 611, "total_env_steps": 1955200, "episode_reward": 0.07323675602674484, "value_loss": 0.004572183545678854, "policy_loss": -0.0016757638504117268, "dist_entropy": 0.7116215705871582, "actor_grad_norm": 0.13024234771728516, "critic_grad_norm": 0.03752628713846207, "ratio": 0.9999597668647766, "entropy": 0.7116215705871582, "incre_win_rate": 0.0, "step": 611}
{"time": 1767080462.326284, "phase": "train", "update": 612, "total_env_steps": 1958400, "episode_reward": 0.07659923285245895, "value_loss": 0.0049311256036162375, "policy_loss": -0.00178435064432243, "dist_entropy": 0.7503860473632813, "actor_grad_norm": 0.12942543625831604, "critic_grad_norm": 0.027614256367087364, "ratio": 1.000069260597229, "entropy": 0.7503860473632813, "incre_win_rate": 0.0, "step": 612}
{"time": 1767080466.4994159, "phase": "train", "update": 613, "total_env_steps": 1961600, "episode_reward": 0.0700501874089241, "value_loss": 0.003481646766886115, "policy_loss": -0.002026988368595539, "dist_entropy": 0.7834729194641114, "actor_grad_norm": 0.14244405925273895, "critic_grad_norm": 0.01623755879700184, "ratio": 1.0001310110092163, "entropy": 0.7834729194641114, "incre_win_rate": 0.0, "step": 613}
{"time": 1767080470.7915976, "phase": "train", "update": 614, "total_env_steps": 1964800, "episode_reward": 0.07611599564552307, "value_loss": 0.005411335825920105, "policy_loss": -0.001463164037565079, "dist_entropy": 0.7665739536285401, "actor_grad_norm": 0.14329783618450165, "critic_grad_norm": 0.05712144449353218, "ratio": 0.9999305009841919, "entropy": 0.7665739536285401, "incre_win_rate": 0.0, "step": 614}
{"time": 1767080475.1577635, "phase": "train", "update": 615, "total_env_steps": 1968000, "episode_reward": 0.07619515806436539, "value_loss": 0.0052685274742543696, "policy_loss": -0.0015242758421898372, "dist_entropy": 0.7881309509277343, "actor_grad_norm": 0.11963377147912979, "critic_grad_norm": 0.05374298244714737, "ratio": 0.9998471140861511, "entropy": 0.7881309509277343, "incre_win_rate": 0.0, "step": 615}
{"time": 1767080479.4620578, "phase": "train", "update": 616, "total_env_steps": 1971200, "episode_reward": 0.07129397988319397, "value_loss": 0.004082769155502319, "policy_loss": -0.0014685890955404624, "dist_entropy": 0.785989248752594, "actor_grad_norm": 0.1566222906112671, "critic_grad_norm": 0.0392804853618145, "ratio": 0.9999484419822693, "entropy": 0.785989248752594, "incre_win_rate": 0.0, "step": 616}
{"time": 1767080483.7955892, "phase": "train", "update": 617, "total_env_steps": 1974400, "episode_reward": 0.07011434435844421, "value_loss": 0.004074952146038413, "policy_loss": -0.0018754971462172421, "dist_entropy": 0.7740995764732361, "actor_grad_norm": 0.12201696634292603, "critic_grad_norm": 0.046170324087142944, "ratio": 0.9999937415122986, "entropy": 0.7740995764732361, "incre_win_rate": 0.0, "step": 617}
{"time": 1767080488.0790753, "phase": "train", "update": 618, "total_env_steps": 1977600, "episode_reward": 0.07294339686632156, "value_loss": 0.004143966268748045, "policy_loss": -0.0014986057849903033, "dist_entropy": 0.7386866211891174, "actor_grad_norm": 0.11825539916753769, "critic_grad_norm": 0.048331715166568756, "ratio": 0.9998226165771484, "entropy": 0.7386866211891174, "incre_win_rate": 0.0, "step": 618}
{"time": 1767080492.3802643, "phase": "train", "update": 619, "total_env_steps": 1980800, "episode_reward": 0.07307636737823486, "value_loss": 0.004670856986194849, "policy_loss": -0.0015334654721549158, "dist_entropy": 0.7263552069664001, "actor_grad_norm": 0.11764619499444962, "critic_grad_norm": 0.033424872905015945, "ratio": 1.0001258850097656, "entropy": 0.7263552069664001, "incre_win_rate": 0.0, "step": 619}
{"time": 1767080496.644198, "phase": "train", "update": 620, "total_env_steps": 1984000, "episode_reward": 0.0742984265089035, "value_loss": 0.003893311554566026, "policy_loss": -0.001800501116080966, "dist_entropy": 0.7710261583328247, "actor_grad_norm": 0.16816596686840057, "critic_grad_norm": 0.04248705506324768, "ratio": 0.9997629523277283, "entropy": 0.7710261583328247, "incre_win_rate": 0.0, "step": 620}
{"time": 1767080500.9935002, "phase": "train", "update": 621, "total_env_steps": 1987200, "episode_reward": 0.07784353941679001, "value_loss": 0.005144192278385163, "policy_loss": -0.0020028750062920154, "dist_entropy": 0.7913721561431885, "actor_grad_norm": 0.11324211210012436, "critic_grad_norm": 0.08435424417257309, "ratio": 0.999864399433136, "entropy": 0.7913721561431885, "incre_win_rate": 0.0, "step": 621}
{"time": 1767080518.6104732, "phase": "eval", "update": 621, "total_env_steps": 1987200, "eval_win_rate": 0.0, "eval_episode_reward": 9.919805463576155, "step": 621}
{"time": 1767080522.8730886, "phase": "train", "update": 622, "total_env_steps": 1990400, "episode_reward": 0.07250258326530457, "value_loss": 0.00649805311113596, "policy_loss": -0.0015363422342872467, "dist_entropy": 0.826557457447052, "actor_grad_norm": 0.11217015236616135, "critic_grad_norm": 0.09424425661563873, "ratio": 1.000048279762268, "entropy": 0.826557457447052, "incre_win_rate": 0.0, "step": 622}
{"time": 1767080527.1598969, "phase": "train", "update": 623, "total_env_steps": 1993600, "episode_reward": 0.0764833390712738, "value_loss": 0.005549745261669159, "policy_loss": -0.002331006682390324, "dist_entropy": 0.8326521515846252, "actor_grad_norm": 0.12566626071929932, "critic_grad_norm": 0.04731108993291855, "ratio": 0.9998599886894226, "entropy": 0.8326521515846252, "incre_win_rate": 0.0, "step": 623}
{"time": 1767080531.4746451, "phase": "train", "update": 624, "total_env_steps": 1996800, "episode_reward": 0.07093439251184464, "value_loss": 0.005051028355956078, "policy_loss": -0.0013933932719908172, "dist_entropy": 0.8229962348937988, "actor_grad_norm": 0.1414525955915451, "critic_grad_norm": 0.03055056929588318, "ratio": 1.0001710653305054, "entropy": 0.8229962348937988, "incre_win_rate": 0.0, "step": 624}
{"time": 1767080535.8137321, "phase": "train", "update": 625, "total_env_steps": 2000000, "episode_reward": 0.07571554183959961, "value_loss": 0.004703013598918915, "policy_loss": -0.001608464447406277, "dist_entropy": 0.8003753185272217, "actor_grad_norm": 0.13016073405742645, "critic_grad_norm": 0.09064515680074692, "ratio": 0.9998529553413391, "entropy": 0.8003753185272217, "incre_win_rate": 0.0, "step": 625}
{"time": 1767080540.121349, "phase": "train", "update": 626, "total_env_steps": 2003200, "episode_reward": 0.07627741992473602, "value_loss": 0.005115109216421843, "policy_loss": -0.0018450806075790637, "dist_entropy": 0.7965450048446655, "actor_grad_norm": 0.15653784573078156, "critic_grad_norm": 0.059027303010225296, "ratio": 0.9999605417251587, "entropy": 0.7965450048446655, "incre_win_rate": 0.0, "step": 626}
{"time": 1767080544.376722, "phase": "train", "update": 627, "total_env_steps": 2006400, "episode_reward": 0.06654231995344162, "value_loss": 0.004512673895806074, "policy_loss": -0.00339539963154607, "dist_entropy": 0.862664771080017, "actor_grad_norm": 0.20895381271839142, "critic_grad_norm": 0.06856133788824081, "ratio": 0.9999823570251465, "entropy": 0.862664771080017, "incre_win_rate": 0.0, "step": 627}
{"time": 1767080548.5992618, "phase": "train", "update": 628, "total_env_steps": 2009600, "episode_reward": 0.0723608210682869, "value_loss": 0.0066812453791499134, "policy_loss": -0.0013614189310416692, "dist_entropy": 0.8537449598312378, "actor_grad_norm": 0.12240904569625854, "critic_grad_norm": 0.10927686840295792, "ratio": 0.9995642900466919, "entropy": 0.8537449598312378, "incre_win_rate": 0.0, "step": 628}
{"time": 1767080552.88841, "phase": "train", "update": 629, "total_env_steps": 2012800, "episode_reward": 0.07704056054353714, "value_loss": 0.007246759533882141, "policy_loss": -0.0013410953807060366, "dist_entropy": 0.813829505443573, "actor_grad_norm": 0.125919371843338, "critic_grad_norm": 0.08724450320005417, "ratio": 1.0000065565109253, "entropy": 0.813829505443573, "incre_win_rate": 0.0, "step": 629}
{"time": 1767080557.0541484, "phase": "train", "update": 630, "total_env_steps": 2016000, "episode_reward": 0.06859685480594635, "value_loss": 0.005336816888302565, "policy_loss": -0.0020196233310254995, "dist_entropy": 0.8711118102073669, "actor_grad_norm": 0.14760138094425201, "critic_grad_norm": 0.05555495619773865, "ratio": 1.0001890659332275, "entropy": 0.8711118102073669, "incre_win_rate": 0.0, "step": 630}
{"time": 1767080561.3314087, "phase": "train", "update": 631, "total_env_steps": 2019200, "episode_reward": 0.07199245691299438, "value_loss": 0.0041736941784620285, "policy_loss": -0.0017905396636569647, "dist_entropy": 0.8552451610565186, "actor_grad_norm": 0.14154364168643951, "critic_grad_norm": 0.10193236172199249, "ratio": 0.9998800158500671, "entropy": 0.8552451610565186, "incre_win_rate": 0.0, "step": 631}
{"time": 1767080565.6569228, "phase": "train", "update": 632, "total_env_steps": 2022400, "episode_reward": 0.0753663033246994, "value_loss": 0.0057547100819647316, "policy_loss": -0.002160193881567807, "dist_entropy": 0.8398878931999206, "actor_grad_norm": 0.15964318811893463, "critic_grad_norm": 0.0898602306842804, "ratio": 0.9995636940002441, "entropy": 0.8398878931999206, "incre_win_rate": 0.0, "step": 632}
{"time": 1767080569.9282272, "phase": "train", "update": 633, "total_env_steps": 2025600, "episode_reward": 0.07435327768325806, "value_loss": 0.00476970337331295, "policy_loss": -0.0015932871807343928, "dist_entropy": 0.8189728617668152, "actor_grad_norm": 0.13840189576148987, "critic_grad_norm": 0.07331154495477676, "ratio": 0.9997258186340332, "entropy": 0.8189728617668152, "incre_win_rate": 0.0, "step": 633}
{"time": 1767080574.2236726, "phase": "train", "update": 634, "total_env_steps": 2028800, "episode_reward": 0.07229821383953094, "value_loss": 0.006942708604037761, "policy_loss": -0.001856874450240653, "dist_entropy": 0.8165537595748902, "actor_grad_norm": 0.13535311818122864, "critic_grad_norm": 0.10895681381225586, "ratio": 0.999829888343811, "entropy": 0.8165537595748902, "incre_win_rate": 0.0, "step": 634}
{"time": 1767080578.5328648, "phase": "train", "update": 635, "total_env_steps": 2032000, "episode_reward": 0.07934343814849854, "value_loss": 0.007702582143247127, "policy_loss": -0.0019929696583382396, "dist_entropy": 0.8087976336479187, "actor_grad_norm": 0.1243225485086441, "critic_grad_norm": 0.03928099945187569, "ratio": 1.0000401735305786, "entropy": 0.8087976336479187, "incre_win_rate": 0.0, "step": 635}
{"time": 1767080582.8750875, "phase": "train", "update": 636, "total_env_steps": 2035200, "episode_reward": 0.07331850379705429, "value_loss": 0.00546431103721261, "policy_loss": -0.002013637060936091, "dist_entropy": 0.8569196462631226, "actor_grad_norm": 0.13408547639846802, "critic_grad_norm": 0.023929433897137642, "ratio": 1.0001028776168823, "entropy": 0.8569196462631226, "incre_win_rate": 0.0, "step": 636}
{"time": 1767080587.1886501, "phase": "train", "update": 637, "total_env_steps": 2038400, "episode_reward": 0.0734928548336029, "value_loss": 0.0041523372754454614, "policy_loss": -0.001782764308154583, "dist_entropy": 0.8091206908226013, "actor_grad_norm": 0.11959963291883469, "critic_grad_norm": 0.02173905447125435, "ratio": 0.9999286532402039, "entropy": 0.8091206908226013, "incre_win_rate": 0.0, "step": 637}
{"time": 1767080591.4917388, "phase": "train", "update": 638, "total_env_steps": 2041600, "episode_reward": 0.07996171712875366, "value_loss": 0.005786406435072422, "policy_loss": -0.0022885624712152717, "dist_entropy": 0.7872357487678527, "actor_grad_norm": 0.1289820522069931, "critic_grad_norm": 0.04401099309325218, "ratio": 0.9999634027481079, "entropy": 0.7872357487678527, "incre_win_rate": 0.0, "step": 638}
{"time": 1767080595.8059232, "phase": "train", "update": 639, "total_env_steps": 2044800, "episode_reward": 0.07583712786436081, "value_loss": 0.0066350865177810196, "policy_loss": -0.0017963674528985508, "dist_entropy": 0.7294812202453613, "actor_grad_norm": 0.13334782421588898, "critic_grad_norm": 0.06621883064508438, "ratio": 0.9997392892837524, "entropy": 0.7294812202453613, "incre_win_rate": 0.0, "step": 639}
{"time": 1767080600.148559, "phase": "train", "update": 640, "total_env_steps": 2048000, "episode_reward": 0.07769091427326202, "value_loss": 0.00417450126260519, "policy_loss": -0.002177784559603424, "dist_entropy": 0.7131320238113403, "actor_grad_norm": 0.13615769147872925, "critic_grad_norm": 0.03254464268684387, "ratio": 0.9998216032981873, "entropy": 0.7131320238113403, "incre_win_rate": 0.0, "step": 640}
{"time": 1767080604.4973338, "phase": "train", "update": 641, "total_env_steps": 2051200, "episode_reward": 0.07192104309797287, "value_loss": 0.0048877491615712644, "policy_loss": -0.0019943515879745632, "dist_entropy": 0.7034860849380493, "actor_grad_norm": 0.19563469290733337, "critic_grad_norm": 0.03179877623915672, "ratio": 1.000107765197754, "entropy": 0.7034860849380493, "incre_win_rate": 0.0, "step": 641}
{"time": 1767080623.1178465, "phase": "eval", "update": 641, "total_env_steps": 2051200, "eval_win_rate": 0.0, "eval_episode_reward": 8.808930049668861, "step": 641}
{"time": 1767080627.5240448, "phase": "train", "update": 642, "total_env_steps": 2054400, "episode_reward": 0.06693501770496368, "value_loss": 0.003982356656342745, "policy_loss": -0.0024016234809607793, "dist_entropy": 0.7433422207832336, "actor_grad_norm": 0.1560584306716919, "critic_grad_norm": 0.05493512749671936, "ratio": 0.9998831152915955, "entropy": 0.7433422207832336, "incre_win_rate": 0.0, "step": 642}
{"time": 1767080631.8310041, "phase": "train", "update": 643, "total_env_steps": 2057600, "episode_reward": 0.07595302164554596, "value_loss": 0.005156189668923616, "policy_loss": -0.001886451153403712, "dist_entropy": 0.7372999668121338, "actor_grad_norm": 0.1255882829427719, "critic_grad_norm": 0.0422724150121212, "ratio": 1.0001710653305054, "entropy": 0.7372999668121338, "incre_win_rate": 0.0, "step": 643}
{"time": 1767080636.1375408, "phase": "train", "update": 644, "total_env_steps": 2060800, "episode_reward": 0.0729382261633873, "value_loss": 0.004538824036717415, "policy_loss": -0.0017866276517685797, "dist_entropy": 0.7542471408843994, "actor_grad_norm": 0.1151152178645134, "critic_grad_norm": 0.06844597309827805, "ratio": 0.9999504089355469, "entropy": 0.7542471408843994, "incre_win_rate": 0.0, "step": 644}
{"time": 1767080640.2284665, "phase": "train", "update": 645, "total_env_steps": 2064000, "episode_reward": 0.06358185410499573, "value_loss": 0.0035109064076095818, "policy_loss": -0.0019057075553336133, "dist_entropy": 0.800241482257843, "actor_grad_norm": 0.1324986219406128, "critic_grad_norm": 0.053756218403577805, "ratio": 0.9999756813049316, "entropy": 0.800241482257843, "incre_win_rate": 0.0, "step": 645}
{"time": 1767080644.4843075, "phase": "train", "update": 646, "total_env_steps": 2067200, "episode_reward": 0.07536786794662476, "value_loss": 0.003213692642748356, "policy_loss": -0.002039320837508285, "dist_entropy": 0.8014763474464417, "actor_grad_norm": 0.13549137115478516, "critic_grad_norm": 0.052447181195020676, "ratio": 1.0002645254135132, "entropy": 0.8014763474464417, "incre_win_rate": 0.0, "step": 646}
{"time": 1767080648.6857843, "phase": "train", "update": 647, "total_env_steps": 2070400, "episode_reward": 0.07986496388912201, "value_loss": 0.004856173507869243, "policy_loss": -0.0019429899646207006, "dist_entropy": 0.788368284702301, "actor_grad_norm": 0.12887150049209595, "critic_grad_norm": 0.06466862559318542, "ratio": 0.9997937083244324, "entropy": 0.788368284702301, "incre_win_rate": 0.0, "step": 647}
{"time": 1767080652.9771636, "phase": "train", "update": 648, "total_env_steps": 2073600, "episode_reward": 0.06862273067235947, "value_loss": 0.0035438880324363707, "policy_loss": -0.0014732386805086151, "dist_entropy": 0.8246899604797363, "actor_grad_norm": 0.12669353187084198, "critic_grad_norm": 0.0371103398501873, "ratio": 0.9998642206192017, "entropy": 0.8246899604797363, "incre_win_rate": 0.0, "step": 648}
{"time": 1767080657.2341564, "phase": "train", "update": 649, "total_env_steps": 2076800, "episode_reward": 0.07761693000793457, "value_loss": 0.005486091785132885, "policy_loss": -0.0016614382658701743, "dist_entropy": 0.8162791013717652, "actor_grad_norm": 0.09632207453250885, "critic_grad_norm": 0.03145258501172066, "ratio": 0.999890923500061, "entropy": 0.8162791013717652, "incre_win_rate": 0.0, "step": 649}
{"time": 1767080661.5625575, "phase": "train", "update": 650, "total_env_steps": 2080000, "episode_reward": 0.07384934276342392, "value_loss": 0.0037191313691437244, "policy_loss": -0.0012082500007259966, "dist_entropy": 0.7940393924713135, "actor_grad_norm": 0.11683231592178345, "critic_grad_norm": 0.04278823360800743, "ratio": 0.9998285174369812, "entropy": 0.7940393924713135, "incre_win_rate": 0.0, "step": 650}
{"time": 1767080665.8919744, "phase": "train", "update": 651, "total_env_steps": 2083200, "episode_reward": 0.07717766612768173, "value_loss": 0.00567303104326129, "policy_loss": -0.0018417130606380283, "dist_entropy": 0.7846854329109192, "actor_grad_norm": 0.10485925525426865, "critic_grad_norm": 0.03670680522918701, "ratio": 1.000015377998352, "entropy": 0.7846854329109192, "incre_win_rate": 0.0, "step": 651}
{"time": 1767080670.1437018, "phase": "train", "update": 652, "total_env_steps": 2086400, "episode_reward": 0.0789569616317749, "value_loss": 0.004761647246778011, "policy_loss": -0.001754149480722589, "dist_entropy": 0.7745570182800293, "actor_grad_norm": 0.13925552368164062, "critic_grad_norm": 0.09281313419342041, "ratio": 1.0001767873764038, "entropy": 0.7745570182800293, "incre_win_rate": 0.0, "step": 652}
{"time": 1767080674.4592648, "phase": "train", "update": 653, "total_env_steps": 2089600, "episode_reward": 0.07381674647331238, "value_loss": 0.005832636263221502, "policy_loss": -0.0015326971649720633, "dist_entropy": 0.8004173874855042, "actor_grad_norm": 0.10529129952192307, "critic_grad_norm": 0.053088415414094925, "ratio": 1.0002104043960571, "entropy": 0.8004173874855042, "incre_win_rate": 0.0, "step": 653}
{"time": 1767080709.1358995, "phase": "train", "update": 654, "total_env_steps": 2092800, "episode_reward": 0.0798199474811554, "value_loss": 0.011992352455854416, "policy_loss": -0.001710878921677761, "dist_entropy": 0.7703326344490051, "actor_grad_norm": 0.12901847064495087, "critic_grad_norm": 0.08375313133001328, "ratio": 0.9998787045478821, "entropy": 0.7703326344490051, "incre_win_rate": 0.0, "step": 654}
{"time": 1767080713.3161569, "phase": "train", "update": 655, "total_env_steps": 2096000, "episode_reward": 0.08080194145441055, "value_loss": 0.004115248657763004, "policy_loss": -0.0019718738066238474, "dist_entropy": 0.8053300380706787, "actor_grad_norm": 0.15582862496376038, "critic_grad_norm": 0.04122001305222511, "ratio": 1.0003284215927124, "entropy": 0.8053300380706787, "incre_win_rate": 0.0, "step": 655}
{"time": 1767080717.5871997, "phase": "train", "update": 656, "total_env_steps": 2099200, "episode_reward": 0.07683050632476807, "value_loss": 0.0055150240659713745, "policy_loss": -0.001576002770363516, "dist_entropy": 0.8528288722038269, "actor_grad_norm": 0.10996854305267334, "critic_grad_norm": 0.040124308317899704, "ratio": 0.9999892115592957, "entropy": 0.8528288722038269, "incre_win_rate": 0.0, "step": 656}
{"time": 1767080721.8607488, "phase": "train", "update": 657, "total_env_steps": 2102400, "episode_reward": 0.06853269785642624, "value_loss": 0.003626789292320609, "policy_loss": -0.0016918133037151506, "dist_entropy": 0.8941885352134704, "actor_grad_norm": 0.15460354089736938, "critic_grad_norm": 0.03582298383116722, "ratio": 0.999941349029541, "entropy": 0.8941885352134704, "incre_win_rate": 0.0, "step": 657}
{"time": 1767080726.181507, "phase": "train", "update": 658, "total_env_steps": 2105600, "episode_reward": 0.0824798196554184, "value_loss": 0.006620865408331155, "policy_loss": -0.0019005340786428348, "dist_entropy": 0.8645584940910339, "actor_grad_norm": 0.14063610136508942, "critic_grad_norm": 0.030706658959388733, "ratio": 0.9999758005142212, "entropy": 0.8645584940910339, "incre_win_rate": 0.0, "step": 658}
{"time": 1767080730.4267347, "phase": "train", "update": 659, "total_env_steps": 2108800, "episode_reward": 0.07781663537025452, "value_loss": 0.005308095458894968, "policy_loss": -0.0017118531046889985, "dist_entropy": 0.8455609917640686, "actor_grad_norm": 0.1287468522787094, "critic_grad_norm": 0.027829959988594055, "ratio": 0.9999894499778748, "entropy": 0.8455609917640686, "incre_win_rate": 0.0, "step": 659}
{"time": 1767080734.7678905, "phase": "train", "update": 660, "total_env_steps": 2112000, "episode_reward": 0.08000672608613968, "value_loss": 0.005630552023649216, "policy_loss": -0.0015507652636731705, "dist_entropy": 0.8437541484832763, "actor_grad_norm": 0.09941007941961288, "critic_grad_norm": 0.07884631305932999, "ratio": 0.9999480247497559, "entropy": 0.8437541484832763, "incre_win_rate": 0.0, "step": 660}
{"time": 1767080739.0970352, "phase": "train", "update": 661, "total_env_steps": 2115200, "episode_reward": 0.08951468765735626, "value_loss": 0.006111088674515486, "policy_loss": -0.0015559919232330799, "dist_entropy": 0.8067598342895508, "actor_grad_norm": 0.12670587003231049, "critic_grad_norm": 0.13705377280712128, "ratio": 0.9999889731407166, "entropy": 0.8067598342895508, "incre_win_rate": 0.0, "step": 661}
{"time": 1767080757.4145913, "phase": "eval", "update": 661, "total_env_steps": 2115200, "eval_win_rate": 0.0, "eval_episode_reward": 10.351355546357608, "step": 661}
{"time": 1767080761.6995223, "phase": "train", "update": 662, "total_env_steps": 2118400, "episode_reward": 0.07914838939905167, "value_loss": 0.004070162819698453, "policy_loss": -0.0018757634057628536, "dist_entropy": 0.8260639190673829, "actor_grad_norm": 0.11606557667255402, "critic_grad_norm": 0.04540916904807091, "ratio": 1.0001262426376343, "entropy": 0.8260639190673829, "incre_win_rate": 0.0, "step": 662}
{"time": 1767080766.039928, "phase": "train", "update": 663, "total_env_steps": 2121600, "episode_reward": 0.07951780408620834, "value_loss": 0.004398492258042097, "policy_loss": -0.0019693126323099717, "dist_entropy": 0.8119851231575013, "actor_grad_norm": 0.11067285388708115, "critic_grad_norm": 0.05149859935045242, "ratio": 1.0000187158584595, "entropy": 0.8119851231575013, "incre_win_rate": 0.0, "step": 663}
{"time": 1767080770.3413646, "phase": "train", "update": 664, "total_env_steps": 2124800, "episode_reward": 0.08347733318805695, "value_loss": 0.005024390481412411, "policy_loss": -0.001847004059510482, "dist_entropy": 0.8178369283676148, "actor_grad_norm": 0.12982754409313202, "critic_grad_norm": 0.04251115024089813, "ratio": 0.9997536540031433, "entropy": 0.8178369283676148, "incre_win_rate": 0.0, "step": 664}
{"time": 1767080774.6985643, "phase": "train", "update": 665, "total_env_steps": 2128000, "episode_reward": 0.08052152395248413, "value_loss": 0.003424374433234334, "policy_loss": -0.001160976853241813, "dist_entropy": 0.8455241799354554, "actor_grad_norm": 0.15949973464012146, "critic_grad_norm": 0.1038987785577774, "ratio": 0.9999813437461853, "entropy": 0.8455241799354554, "incre_win_rate": 0.0, "step": 665}
{"time": 1767080778.9742005, "phase": "train", "update": 666, "total_env_steps": 2131200, "episode_reward": 0.07723820954561234, "value_loss": 0.005286591127514839, "policy_loss": -0.0012597079888901242, "dist_entropy": 0.8272862434387207, "actor_grad_norm": 0.10967154800891876, "critic_grad_norm": 0.044981975108385086, "ratio": 1.0000606775283813, "entropy": 0.8272862434387207, "incre_win_rate": 0.0, "step": 666}
{"time": 1767080783.3728967, "phase": "train", "update": 667, "total_env_steps": 2134400, "episode_reward": 0.07874482870101929, "value_loss": 0.004938448499888182, "policy_loss": -0.0015850285109813456, "dist_entropy": 0.8184464693069458, "actor_grad_norm": 0.12218435108661652, "critic_grad_norm": 0.04445599392056465, "ratio": 1.0000035762786865, "entropy": 0.8184464693069458, "incre_win_rate": 0.0, "step": 667}
{"time": 1767080787.7214582, "phase": "train", "update": 668, "total_env_steps": 2137600, "episode_reward": 0.07806652784347534, "value_loss": 0.005363940913230181, "policy_loss": -0.0016087537547164743, "dist_entropy": 0.8377892374992371, "actor_grad_norm": 0.1480281800031662, "critic_grad_norm": 0.029919356107711792, "ratio": 1.0000149011611938, "entropy": 0.8377892374992371, "incre_win_rate": 0.0, "step": 668}
{"time": 1767080792.1828203, "phase": "train", "update": 669, "total_env_steps": 2140800, "episode_reward": 0.07607564330101013, "value_loss": 0.003894535358995199, "policy_loss": -0.001324237785022575, "dist_entropy": 0.8489473223686218, "actor_grad_norm": 0.15863636136054993, "critic_grad_norm": 0.02557193674147129, "ratio": 0.999768853187561, "entropy": 0.8489473223686218, "incre_win_rate": 0.0, "step": 669}
{"time": 1767080796.5419729, "phase": "train", "update": 670, "total_env_steps": 2144000, "episode_reward": 0.07535596191883087, "value_loss": 0.005054111778736115, "policy_loss": -0.0013557464397955243, "dist_entropy": 0.8284824371337891, "actor_grad_norm": 0.1706477850675583, "critic_grad_norm": 0.028720689937472343, "ratio": 0.9999442100524902, "entropy": 0.8284824371337891, "incre_win_rate": 0.0, "step": 670}
{"time": 1767080800.9136584, "phase": "train", "update": 671, "total_env_steps": 2147200, "episode_reward": 0.08401025086641312, "value_loss": 0.0056673184968531135, "policy_loss": -0.001570962156845379, "dist_entropy": 0.7997007489204406, "actor_grad_norm": 0.11696233600378036, "critic_grad_norm": 0.060972660779953, "ratio": 0.9999679923057556, "entropy": 0.7997007489204406, "incre_win_rate": 0.0, "step": 671}
{"time": 1767080805.2096653, "phase": "train", "update": 672, "total_env_steps": 2150400, "episode_reward": 0.07845095545053482, "value_loss": 0.004116578493267298, "policy_loss": -0.001560376444760081, "dist_entropy": 0.8031259775161743, "actor_grad_norm": 0.11832412332296371, "critic_grad_norm": 0.02841651439666748, "ratio": 0.9998037219047546, "entropy": 0.8031259775161743, "incre_win_rate": 0.0, "step": 672}
{"time": 1767080809.5775654, "phase": "train", "update": 673, "total_env_steps": 2153600, "episode_reward": 0.07929997146129608, "value_loss": 0.0050540811382234095, "policy_loss": -0.0016499432989611762, "dist_entropy": 0.7914184093475342, "actor_grad_norm": 0.13849666714668274, "critic_grad_norm": 0.08559401333332062, "ratio": 0.9997133612632751, "entropy": 0.7914184093475342, "incre_win_rate": 0.0, "step": 673}
{"time": 1767080813.8413765, "phase": "train", "update": 674, "total_env_steps": 2156800, "episode_reward": 0.08030060678720474, "value_loss": 0.003412516973912716, "policy_loss": -0.0016489333870083555, "dist_entropy": 0.805453896522522, "actor_grad_norm": 0.14410248398780823, "critic_grad_norm": 0.04590296745300293, "ratio": 0.9997089505195618, "entropy": 0.805453896522522, "incre_win_rate": 0.0, "step": 674}
{"time": 1767080818.0496898, "phase": "train", "update": 675, "total_env_steps": 2160000, "episode_reward": 0.07099234312772751, "value_loss": 0.00544820474460721, "policy_loss": -0.0016746969948780333, "dist_entropy": 0.8537981390953064, "actor_grad_norm": 0.1499980241060257, "critic_grad_norm": 0.02212163247168064, "ratio": 0.9999347925186157, "entropy": 0.8537981390953064, "incre_win_rate": 0.0, "step": 675}
{"time": 1767080822.3252976, "phase": "train", "update": 676, "total_env_steps": 2163200, "episode_reward": 0.08582988381385803, "value_loss": 0.00647884039208293, "policy_loss": -0.0016334748367430763, "dist_entropy": 0.8418644070625305, "actor_grad_norm": 0.16742977499961853, "critic_grad_norm": 0.07303880900144577, "ratio": 0.9998692870140076, "entropy": 0.8418644070625305, "incre_win_rate": 0.0, "step": 676}
{"time": 1767080826.664562, "phase": "train", "update": 677, "total_env_steps": 2166400, "episode_reward": 0.08071088790893555, "value_loss": 0.005112196877598762, "policy_loss": -0.0016424632984509912, "dist_entropy": 0.8619857788085937, "actor_grad_norm": 0.1431644707918167, "critic_grad_norm": 0.03758925199508667, "ratio": 0.9999608397483826, "entropy": 0.8619857788085937, "incre_win_rate": 0.0, "step": 677}
{"time": 1767080830.949228, "phase": "train", "update": 678, "total_env_steps": 2169600, "episode_reward": 0.07346802949905396, "value_loss": 0.0032756886444985866, "policy_loss": -0.0018826204234478894, "dist_entropy": 0.8933509469032288, "actor_grad_norm": 0.12199058383703232, "critic_grad_norm": 0.02931717038154602, "ratio": 0.9999406933784485, "entropy": 0.8933509469032288, "incre_win_rate": 0.0, "step": 678}
{"time": 1767080835.267207, "phase": "train", "update": 679, "total_env_steps": 2172800, "episode_reward": 0.07869567722082138, "value_loss": 0.004602519050240517, "policy_loss": -0.0016908333248501605, "dist_entropy": 0.8368510007858276, "actor_grad_norm": 0.16205443441867828, "critic_grad_norm": 0.02402271330356598, "ratio": 0.9998368620872498, "entropy": 0.8368510007858276, "incre_win_rate": 0.0, "step": 679}
{"time": 1767080839.5240817, "phase": "train", "update": 680, "total_env_steps": 2176000, "episode_reward": 0.07973147183656693, "value_loss": 0.005722236819565296, "policy_loss": -0.001650888005769513, "dist_entropy": 0.8365408539772033, "actor_grad_norm": 0.12018096446990967, "critic_grad_norm": 0.015550792217254639, "ratio": 0.9999399185180664, "entropy": 0.8365408539772033, "incre_win_rate": 0.0, "step": 680}
{"time": 1767080843.8136537, "phase": "train", "update": 681, "total_env_steps": 2179200, "episode_reward": 0.07238411158323288, "value_loss": 0.00495903855189681, "policy_loss": -0.0019610815531237334, "dist_entropy": 0.816714859008789, "actor_grad_norm": 0.1371537446975708, "critic_grad_norm": 0.029120082035660744, "ratio": 1.0001229047775269, "entropy": 0.816714859008789, "incre_win_rate": 0.0, "step": 681}
{"time": 1767080861.9992552, "phase": "eval", "update": 681, "total_env_steps": 2179200, "eval_win_rate": 0.0, "eval_episode_reward": 11.053859685430456, "step": 681}
{"time": 1767080866.3382835, "phase": "train", "update": 682, "total_env_steps": 2182400, "episode_reward": 0.0788886621594429, "value_loss": 0.004746203310787678, "policy_loss": -0.0016821720657347328, "dist_entropy": 0.8128548979759216, "actor_grad_norm": 0.1335141360759735, "critic_grad_norm": 0.04396484047174454, "ratio": 1.000014066696167, "entropy": 0.8128548979759216, "incre_win_rate": 0.0, "step": 682}
{"time": 1767080870.628637, "phase": "train", "update": 683, "total_env_steps": 2185600, "episode_reward": 0.08317570388317108, "value_loss": 0.006242372002452612, "policy_loss": -0.0012689155310798839, "dist_entropy": 0.8028002858161927, "actor_grad_norm": 0.12658409774303436, "critic_grad_norm": 0.02899649180471897, "ratio": 0.9999081492424011, "entropy": 0.8028002858161927, "incre_win_rate": 0.0, "step": 683}
{"time": 1767080874.8796601, "phase": "train", "update": 684, "total_env_steps": 2188800, "episode_reward": 0.07194174826145172, "value_loss": 0.003691316582262516, "policy_loss": -0.002035126620598504, "dist_entropy": 0.8422092795372009, "actor_grad_norm": 0.14130118489265442, "critic_grad_norm": 0.022505639120936394, "ratio": 0.9997537732124329, "entropy": 0.8422092795372009, "incre_win_rate": 0.0, "step": 684}
{"time": 1767080879.0639577, "phase": "train", "update": 685, "total_env_steps": 2192000, "episode_reward": 0.07485203444957733, "value_loss": 0.0038587886840105055, "policy_loss": -0.0014305414999910226, "dist_entropy": 0.8145381808280945, "actor_grad_norm": 0.12236467748880386, "critic_grad_norm": 0.021142957732081413, "ratio": 0.9999009966850281, "entropy": 0.8145381808280945, "incre_win_rate": 0.0, "step": 685}
{"time": 1767080883.3650053, "phase": "train", "update": 686, "total_env_steps": 2195200, "episode_reward": 0.08105908334255219, "value_loss": 0.005947843380272389, "policy_loss": -0.001500260918590879, "dist_entropy": 0.7904817819595337, "actor_grad_norm": 0.1097748652100563, "critic_grad_norm": 0.0682930126786232, "ratio": 1.0000746250152588, "entropy": 0.7904817819595337, "incre_win_rate": 0.0, "step": 686}
{"time": 1767080887.766589, "phase": "train", "update": 687, "total_env_steps": 2198400, "episode_reward": 0.0749218687415123, "value_loss": 0.003778132889419794, "policy_loss": -0.0014533109548864331, "dist_entropy": 0.7763927340507507, "actor_grad_norm": 0.12959253787994385, "critic_grad_norm": 0.056649982929229736, "ratio": 0.9997240304946899, "entropy": 0.7763927340507507, "incre_win_rate": 0.0, "step": 687}
{"time": 1767080892.0715933, "phase": "train", "update": 688, "total_env_steps": 2201600, "episode_reward": 0.07621585577726364, "value_loss": 0.004629569035023451, "policy_loss": -0.0016594117626070215, "dist_entropy": 0.7758479356765747, "actor_grad_norm": 0.14241622388362885, "critic_grad_norm": 0.030546370893716812, "ratio": 1.000034213066101, "entropy": 0.7758479356765747, "incre_win_rate": 0.0, "step": 688}
{"time": 1767080896.4411201, "phase": "train", "update": 689, "total_env_steps": 2204800, "episode_reward": 0.0727747306227684, "value_loss": 0.0047060707584023476, "policy_loss": -0.001968384790836808, "dist_entropy": 0.7950915813446044, "actor_grad_norm": 0.1497376412153244, "critic_grad_norm": 0.024136541411280632, "ratio": 0.9996960759162903, "entropy": 0.7950915813446044, "incre_win_rate": 0.0, "step": 689}
{"time": 1767080900.8483965, "phase": "train", "update": 690, "total_env_steps": 2208000, "episode_reward": 0.07843026518821716, "value_loss": 0.006322224065661431, "policy_loss": -0.0019095494554678184, "dist_entropy": 0.789099931716919, "actor_grad_norm": 0.1607140451669693, "critic_grad_norm": 0.07191715389490128, "ratio": 0.9998933672904968, "entropy": 0.789099931716919, "incre_win_rate": 0.0, "step": 690}
{"time": 1767080905.1379187, "phase": "train", "update": 691, "total_env_steps": 2211200, "episode_reward": 0.0714750587940216, "value_loss": 0.003316462645307183, "policy_loss": -0.0020222024246066895, "dist_entropy": 0.8276922821998596, "actor_grad_norm": 0.12098117917776108, "critic_grad_norm": 0.03395592048764229, "ratio": 1.0002821683883667, "entropy": 0.8276922821998596, "incre_win_rate": 0.0, "step": 691}
{"time": 1767080909.4794836, "phase": "train", "update": 692, "total_env_steps": 2214400, "episode_reward": 0.07336610555648804, "value_loss": 0.0035331503953784705, "policy_loss": -0.002246654884652344, "dist_entropy": 0.8164759755134583, "actor_grad_norm": 0.1863149255514145, "critic_grad_norm": 0.042966123670339584, "ratio": 1.0003372430801392, "entropy": 0.8164759755134583, "incre_win_rate": 0.0, "step": 692}
{"time": 1767080913.8198452, "phase": "train", "update": 693, "total_env_steps": 2217600, "episode_reward": 0.07523747533559799, "value_loss": 0.0049125456251204016, "policy_loss": -0.001845724907394697, "dist_entropy": 0.8312007188796997, "actor_grad_norm": 0.17897000908851624, "critic_grad_norm": 0.036253802478313446, "ratio": 0.9999639391899109, "entropy": 0.8312007188796997, "incre_win_rate": 0.0, "step": 693}
{"time": 1767080918.2437956, "phase": "train", "update": 694, "total_env_steps": 2220800, "episode_reward": 0.07910855114459991, "value_loss": 0.007178372330963611, "policy_loss": -0.0012771787076616193, "dist_entropy": 0.8158439636230469, "actor_grad_norm": 0.12266867607831955, "critic_grad_norm": 0.07340504229068756, "ratio": 0.9999893307685852, "entropy": 0.8158439636230469, "incre_win_rate": 0.0, "step": 694}
{"time": 1767080922.5874615, "phase": "train", "update": 695, "total_env_steps": 2224000, "episode_reward": 0.0718589574098587, "value_loss": 0.004132444225251675, "policy_loss": -0.0017994370338563215, "dist_entropy": 0.8603972315788269, "actor_grad_norm": 0.13618405163288116, "critic_grad_norm": 0.036168087273836136, "ratio": 0.9999028444290161, "entropy": 0.8603972315788269, "incre_win_rate": 0.0, "step": 695}
{"time": 1767080927.068717, "phase": "train", "update": 696, "total_env_steps": 2227200, "episode_reward": 0.08411527425050735, "value_loss": 0.009569978713989258, "policy_loss": -0.0019010009716566856, "dist_entropy": 0.8273399710655213, "actor_grad_norm": 0.12048938125371933, "critic_grad_norm": 0.11027085781097412, "ratio": 1.0001662969589233, "entropy": 0.8273399710655213, "incre_win_rate": 0.0, "step": 696}
{"time": 1767080931.4139543, "phase": "train", "update": 697, "total_env_steps": 2230400, "episode_reward": 0.08109168708324432, "value_loss": 0.00804336704313755, "policy_loss": -0.0017742053519224754, "dist_entropy": 0.833101212978363, "actor_grad_norm": 0.12282463163137436, "critic_grad_norm": 0.058478206396102905, "ratio": 1.0005844831466675, "entropy": 0.833101212978363, "incre_win_rate": 0.0, "step": 697}
{"time": 1767080935.8110795, "phase": "train", "update": 698, "total_env_steps": 2233600, "episode_reward": 0.0815940573811531, "value_loss": 0.009234883263707161, "policy_loss": -0.0021443780685430625, "dist_entropy": 0.8082592010498046, "actor_grad_norm": 0.11970927566289902, "critic_grad_norm": 0.05428106710314751, "ratio": 0.9997965097427368, "entropy": 0.8082592010498046, "incre_win_rate": 0.0, "step": 698}
{"time": 1767080940.167219, "phase": "train", "update": 699, "total_env_steps": 2236800, "episode_reward": 0.0803895890712738, "value_loss": 0.009104260802268982, "policy_loss": -0.0016550000934710597, "dist_entropy": 0.8298527121543884, "actor_grad_norm": 0.14649039506912231, "critic_grad_norm": 0.04939872771501541, "ratio": 1.000006079673767, "entropy": 0.8298527121543884, "incre_win_rate": 0.0, "step": 699}
{"time": 1767080944.674998, "phase": "train", "update": 700, "total_env_steps": 2240000, "episode_reward": 0.08521264046430588, "value_loss": 0.011469066143035889, "policy_loss": -0.0016667738588147074, "dist_entropy": 0.8006198763847351, "actor_grad_norm": 0.12233857065439224, "critic_grad_norm": 0.03842296451330185, "ratio": 0.9999778866767883, "entropy": 0.8006198763847351, "incre_win_rate": 0.0, "step": 700}
{"time": 1767080948.995772, "phase": "train", "update": 701, "total_env_steps": 2243200, "episode_reward": 0.08060585707426071, "value_loss": 0.009873456694185734, "policy_loss": -0.0016745417415926056, "dist_entropy": 0.8441405534744263, "actor_grad_norm": 0.11390860378742218, "critic_grad_norm": 0.033026035875082016, "ratio": 0.999986469745636, "entropy": 0.8441405534744263, "incre_win_rate": 0.0, "step": 701}
{"time": 1767080972.9021087, "phase": "eval", "update": 701, "total_env_steps": 2243200, "eval_win_rate": 0.0, "eval_episode_reward": 10.661216887417208, "step": 701}
{"time": 1767080977.6130738, "phase": "train", "update": 702, "total_env_steps": 2246400, "episode_reward": 0.07932015508413315, "value_loss": 0.006445596180856228, "policy_loss": -0.0021158702975855983, "dist_entropy": 0.8609835147857666, "actor_grad_norm": 0.12964539229869843, "critic_grad_norm": 0.034260597079992294, "ratio": 1.000010371208191, "entropy": 0.8609835147857666, "incre_win_rate": 0.0, "step": 702}
{"time": 1767080982.6325295, "phase": "train", "update": 703, "total_env_steps": 2249600, "episode_reward": 0.09126448631286621, "value_loss": 0.009480811655521393, "policy_loss": -0.001961235421541119, "dist_entropy": 0.8346950292587281, "actor_grad_norm": 0.11012617498636246, "critic_grad_norm": 0.05576930195093155, "ratio": 0.9999048113822937, "entropy": 0.8346950292587281, "incre_win_rate": 0.0, "step": 703}
{"time": 1767080987.8212354, "phase": "train", "update": 704, "total_env_steps": 2252800, "episode_reward": 0.0715930238366127, "value_loss": 0.006323791760951281, "policy_loss": -0.0017175416621228123, "dist_entropy": 0.8739762306213379, "actor_grad_norm": 0.1307295262813568, "critic_grad_norm": 0.030178679153323174, "ratio": 1.0003355741500854, "entropy": 0.8739762306213379, "incre_win_rate": 0.0, "step": 704}
{"time": 1767080992.3179047, "phase": "train", "update": 705, "total_env_steps": 2256000, "episode_reward": 0.07131984829902649, "value_loss": 0.005100106168538332, "policy_loss": -0.001714539482046007, "dist_entropy": 0.9161670923233032, "actor_grad_norm": 0.12132131308317184, "critic_grad_norm": 0.05868621543049812, "ratio": 1.0000507831573486, "entropy": 0.9161670923233032, "incre_win_rate": 0.0, "step": 705}
{"time": 1767080997.3530552, "phase": "train", "update": 706, "total_env_steps": 2259200, "episode_reward": 0.0846761167049408, "value_loss": 0.01566214393824339, "policy_loss": -0.0013100553266419013, "dist_entropy": 0.8499817371368408, "actor_grad_norm": 0.12195344269275665, "critic_grad_norm": 0.11892054229974747, "ratio": 1.000287413597107, "entropy": 0.8499817371368408, "incre_win_rate": 0.0, "step": 706}
{"time": 1767081002.2339656, "phase": "train", "update": 707, "total_env_steps": 2262400, "episode_reward": 0.07066018879413605, "value_loss": 0.006082908902317286, "policy_loss": -0.001778907368422722, "dist_entropy": 0.9085890531539917, "actor_grad_norm": 0.11053039878606796, "critic_grad_norm": 0.1243647113442421, "ratio": 0.9998308420181274, "entropy": 0.9085890531539917, "incre_win_rate": 0.0, "step": 707}
{"time": 1767081007.291529, "phase": "train", "update": 708, "total_env_steps": 2265600, "episode_reward": 0.07791391015052795, "value_loss": 0.00963153298944235, "policy_loss": -0.0026755427125102925, "dist_entropy": 0.8869004726409913, "actor_grad_norm": 0.17620158195495605, "critic_grad_norm": 0.08176444470882416, "ratio": 1.0003288984298706, "entropy": 0.8869004726409913, "incre_win_rate": 0.0, "step": 708}
{"time": 1767081011.9747138, "phase": "train", "update": 709, "total_env_steps": 2268800, "episode_reward": 0.07808464020490646, "value_loss": 0.0057245979085564615, "policy_loss": -0.002297194574342143, "dist_entropy": 0.8920529127120972, "actor_grad_norm": 0.13352659344673157, "critic_grad_norm": 0.06707268953323364, "ratio": 1.00019109249115, "entropy": 0.8920529127120972, "incre_win_rate": 0.0, "step": 709}
{"time": 1767081016.379596, "phase": "train", "update": 710, "total_env_steps": 2272000, "episode_reward": 0.07810068875551224, "value_loss": 0.007257489487528801, "policy_loss": -0.002676512691253663, "dist_entropy": 0.8514743447303772, "actor_grad_norm": 0.21230486035346985, "critic_grad_norm": 0.0678885355591774, "ratio": 0.9997215270996094, "entropy": 0.8514743447303772, "incre_win_rate": 0.0, "step": 710}
{"time": 1767081020.978816, "phase": "train", "update": 711, "total_env_steps": 2275200, "episode_reward": 0.07519763708114624, "value_loss": 0.007423281855881214, "policy_loss": -0.002304413471635769, "dist_entropy": 0.8496353507041932, "actor_grad_norm": 0.16274672746658325, "critic_grad_norm": 0.037862639874219894, "ratio": 0.9997350573539734, "entropy": 0.8496353507041932, "incre_win_rate": 0.0, "step": 711}
{"time": 1767081025.4332602, "phase": "train", "update": 712, "total_env_steps": 2278400, "episode_reward": 0.0731850117444992, "value_loss": 0.005975213460624218, "policy_loss": -0.0021508284330595375, "dist_entropy": 0.8535681247711182, "actor_grad_norm": 0.14389799535274506, "critic_grad_norm": 0.07116620987653732, "ratio": 0.9998766183853149, "entropy": 0.8535681247711182, "incre_win_rate": 0.0, "step": 712}
{"time": 1767081029.9767625, "phase": "train", "update": 713, "total_env_steps": 2281600, "episode_reward": 0.07598820328712463, "value_loss": 0.006639545038342476, "policy_loss": -0.0016768752336785652, "dist_entropy": 0.8314401745796204, "actor_grad_norm": 0.14684779942035675, "critic_grad_norm": 0.03847971186041832, "ratio": 1.0001630783081055, "entropy": 0.8314401745796204, "incre_win_rate": 0.0, "step": 713}
{"time": 1767081034.529587, "phase": "train", "update": 714, "total_env_steps": 2284800, "episode_reward": 0.07212024927139282, "value_loss": 0.005994353629648686, "policy_loss": -0.0014368093177537845, "dist_entropy": 0.858756709098816, "actor_grad_norm": 0.12896643579006195, "critic_grad_norm": 0.03073822893202305, "ratio": 1.0000330209732056, "entropy": 0.858756709098816, "incre_win_rate": 0.0, "step": 714}
{"time": 1767081038.9563591, "phase": "train", "update": 715, "total_env_steps": 2288000, "episode_reward": 0.0734742283821106, "value_loss": 0.005625101178884507, "policy_loss": -0.001662400545204079, "dist_entropy": 0.8472711205482483, "actor_grad_norm": 0.13348396122455597, "critic_grad_norm": 0.04789121448993683, "ratio": 1.0000317096710205, "entropy": 0.8472711205482483, "incre_win_rate": 0.0, "step": 715}
{"time": 1767081043.355121, "phase": "train", "update": 716, "total_env_steps": 2291200, "episode_reward": 0.07585420459508896, "value_loss": 0.005562730319797993, "policy_loss": -0.001934682081076744, "dist_entropy": 0.8461440443992615, "actor_grad_norm": 0.12172627449035645, "critic_grad_norm": 0.04175187647342682, "ratio": 1.0001055002212524, "entropy": 0.8461440443992615, "incre_win_rate": 0.0, "step": 716}
{"time": 1767081047.7268314, "phase": "train", "update": 717, "total_env_steps": 2294400, "episode_reward": 0.07009158283472061, "value_loss": 0.005422382522374392, "policy_loss": -0.0014779039532800907, "dist_entropy": 0.8594444274902344, "actor_grad_norm": 0.11362507194280624, "critic_grad_norm": 0.021520331501960754, "ratio": 0.9998545050621033, "entropy": 0.8594444274902344, "incre_win_rate": 0.0, "step": 717}
{"time": 1767081052.0952592, "phase": "train", "update": 718, "total_env_steps": 2297600, "episode_reward": 0.06855443120002747, "value_loss": 0.0040246272459626194, "policy_loss": -0.0025451970059996443, "dist_entropy": 0.8700963735580445, "actor_grad_norm": 0.1307484656572342, "critic_grad_norm": 0.09523124992847443, "ratio": 1.0000699758529663, "entropy": 0.8700963735580445, "incre_win_rate": 0.0, "step": 718}
{"time": 1767081056.4522164, "phase": "train", "update": 719, "total_env_steps": 2300800, "episode_reward": 0.07320156693458557, "value_loss": 0.004398021195083856, "policy_loss": -0.0025261653124928783, "dist_entropy": 0.8670843362808227, "actor_grad_norm": 0.16201035678386688, "critic_grad_norm": 0.04242393374443054, "ratio": 1.0001745223999023, "entropy": 0.8670843362808227, "incre_win_rate": 0.0, "step": 719}
{"time": 1767081061.0934622, "phase": "train", "update": 720, "total_env_steps": 2304000, "episode_reward": 0.06796149909496307, "value_loss": 0.0068527496419847015, "policy_loss": -0.0022246644527978534, "dist_entropy": 0.8334740161895752, "actor_grad_norm": 0.1372082680463791, "critic_grad_norm": 0.04183460399508476, "ratio": 1.0001972913742065, "entropy": 0.8334740161895752, "incre_win_rate": 0.0, "step": 720}
{"time": 1767081065.6982467, "phase": "train", "update": 721, "total_env_steps": 2307200, "episode_reward": 0.07244361191987991, "value_loss": 0.004559391923248768, "policy_loss": -0.0019830016961460474, "dist_entropy": 0.81473867893219, "actor_grad_norm": 0.13361996412277222, "critic_grad_norm": 0.02368568442761898, "ratio": 1.0000636577606201, "entropy": 0.81473867893219, "incre_win_rate": 0.0, "step": 721}
{"time": 1767081084.7065308, "phase": "eval", "update": 721, "total_env_steps": 2307200, "eval_win_rate": 0.0, "eval_episode_reward": 10.055929221854292, "step": 721}
{"time": 1767081089.1638715, "phase": "train", "update": 722, "total_env_steps": 2310400, "episode_reward": 0.06624224036931992, "value_loss": 0.0025482842698693275, "policy_loss": -0.0018672150227622808, "dist_entropy": 0.8506670355796814, "actor_grad_norm": 0.16704021394252777, "critic_grad_norm": 0.017412958666682243, "ratio": 0.9998025894165039, "entropy": 0.8506670355796814, "incre_win_rate": 0.0, "step": 722}
{"time": 1767081093.337669, "phase": "train", "update": 723, "total_env_steps": 2313600, "episode_reward": 0.06739756464958191, "value_loss": 0.003708444209769368, "policy_loss": -0.002284188476208726, "dist_entropy": 0.8610548496246337, "actor_grad_norm": 0.16887657344341278, "critic_grad_norm": 0.028052425011992455, "ratio": 0.9999871253967285, "entropy": 0.8610548496246337, "incre_win_rate": 0.0, "step": 723}
{"time": 1767081097.6785455, "phase": "train", "update": 724, "total_env_steps": 2316800, "episode_reward": 0.07361599802970886, "value_loss": 0.0055531392805278305, "policy_loss": -0.002357017703910458, "dist_entropy": 0.8332746386528015, "actor_grad_norm": 0.171747088432312, "critic_grad_norm": 0.043496835976839066, "ratio": 0.9999575018882751, "entropy": 0.8332746386528015, "incre_win_rate": 0.0, "step": 724}
{"time": 1767081102.2673182, "phase": "train", "update": 725, "total_env_steps": 2320000, "episode_reward": 0.07198934257030487, "value_loss": 0.004078869242221117, "policy_loss": -0.002072546750827442, "dist_entropy": 0.860015618801117, "actor_grad_norm": 0.14818160235881805, "critic_grad_norm": 0.029599998146295547, "ratio": 0.999445378780365, "entropy": 0.860015618801117, "incre_win_rate": 0.0, "step": 725}
{"time": 1767081106.7019236, "phase": "train", "update": 726, "total_env_steps": 2323200, "episode_reward": 0.07604511082172394, "value_loss": 0.003984022233635187, "policy_loss": -0.002064378073882267, "dist_entropy": 0.8755656957626343, "actor_grad_norm": 0.1782589554786682, "critic_grad_norm": 0.07273676991462708, "ratio": 0.9999895095825195, "entropy": 0.8755656957626343, "incre_win_rate": 0.0, "step": 726}
{"time": 1767081111.4607704, "phase": "train", "update": 727, "total_env_steps": 2326400, "episode_reward": 0.07241256535053253, "value_loss": 0.004340578615665436, "policy_loss": -0.0018367972968768242, "dist_entropy": 0.8713645458221435, "actor_grad_norm": 0.18186573684215546, "critic_grad_norm": 0.056162286549806595, "ratio": 0.999859631061554, "entropy": 0.8713645458221435, "incre_win_rate": 0.0, "step": 727}
{"time": 1767081115.9266853, "phase": "train", "update": 728, "total_env_steps": 2329600, "episode_reward": 0.07386382669210434, "value_loss": 0.003483729064464569, "policy_loss": -0.0020593383737534054, "dist_entropy": 0.8418358206748963, "actor_grad_norm": 0.110477976500988, "critic_grad_norm": 0.023548131808638573, "ratio": 0.9999815225601196, "entropy": 0.8418358206748963, "incre_win_rate": 0.0, "step": 728}
{"time": 1767081120.4334152, "phase": "train", "update": 729, "total_env_steps": 2332800, "episode_reward": 0.074659563601017, "value_loss": 0.003993858164176345, "policy_loss": -0.0022195752568125115, "dist_entropy": 0.8229873657226563, "actor_grad_norm": 0.14333339035511017, "critic_grad_norm": 0.08475536853075027, "ratio": 0.9998427629470825, "entropy": 0.8229873657226563, "incre_win_rate": 0.0, "step": 729}
{"time": 1767081124.8882122, "phase": "train", "update": 730, "total_env_steps": 2336000, "episode_reward": 0.06954367458820343, "value_loss": 0.004433347936719656, "policy_loss": -0.0017679395759717664, "dist_entropy": 0.8593921542167664, "actor_grad_norm": 0.12341373413801193, "critic_grad_norm": 0.06994182616472244, "ratio": 0.9998087286949158, "entropy": 0.8593921542167664, "incre_win_rate": 0.0, "step": 730}
{"time": 1767081129.3909163, "phase": "train", "update": 731, "total_env_steps": 2339200, "episode_reward": 0.06800185889005661, "value_loss": 0.004439106117933989, "policy_loss": -0.0020364083338556328, "dist_entropy": 0.9035438179969788, "actor_grad_norm": 0.1719382107257843, "critic_grad_norm": 0.023587023839354515, "ratio": 0.9995892643928528, "entropy": 0.9035438179969788, "incre_win_rate": 0.0, "step": 731}
{"time": 1767081134.0024056, "phase": "train", "update": 732, "total_env_steps": 2342400, "episode_reward": 0.06781819462776184, "value_loss": 0.003423408046364784, "policy_loss": -0.00147799563412363, "dist_entropy": 0.8789808869361877, "actor_grad_norm": 0.12138338387012482, "critic_grad_norm": 0.04607561230659485, "ratio": 1.0000196695327759, "entropy": 0.8789808869361877, "incre_win_rate": 0.0, "step": 732}
{"time": 1767081139.5749626, "phase": "train", "update": 733, "total_env_steps": 2345600, "episode_reward": 0.07541339099407196, "value_loss": 0.0026843391824513674, "policy_loss": -0.0014722109852328912, "dist_entropy": 0.8540345549583435, "actor_grad_norm": 0.189181387424469, "critic_grad_norm": 0.045704856514930725, "ratio": 0.9999201893806458, "entropy": 0.8540345549583435, "incre_win_rate": 0.0, "step": 733}
{"time": 1767081145.4374878, "phase": "train", "update": 734, "total_env_steps": 2348800, "episode_reward": 0.07540717720985413, "value_loss": 0.003514011623337865, "policy_loss": -0.0017375919682836027, "dist_entropy": 0.8771435618400574, "actor_grad_norm": 0.1387825459241867, "critic_grad_norm": 0.016666486859321594, "ratio": 0.9998693466186523, "entropy": 0.8771435618400574, "incre_win_rate": 0.0, "step": 734}
{"time": 1767081150.0092146, "phase": "train", "update": 735, "total_env_steps": 2352000, "episode_reward": 0.0634690597653389, "value_loss": 0.004130652733147144, "policy_loss": -0.002213785825797032, "dist_entropy": 0.9020316958427429, "actor_grad_norm": 0.16272810101509094, "critic_grad_norm": 0.09839459508657455, "ratio": 0.9998640418052673, "entropy": 0.9020316958427429, "incre_win_rate": 0.0, "step": 735}
{"time": 1767081154.4167416, "phase": "train", "update": 736, "total_env_steps": 2355200, "episode_reward": 0.0749027356505394, "value_loss": 0.004512255731970072, "policy_loss": -0.0013161897325900894, "dist_entropy": 0.8816025257110596, "actor_grad_norm": 0.13248658180236816, "critic_grad_norm": 0.058752287179231644, "ratio": 0.9998043179512024, "entropy": 0.8816025257110596, "incre_win_rate": 0.0, "step": 736}
{"time": 1767081159.0663579, "phase": "train", "update": 737, "total_env_steps": 2358400, "episode_reward": 0.06987892836332321, "value_loss": 0.0027642666827887297, "policy_loss": -0.0016170268783028518, "dist_entropy": 0.8971006751060486, "actor_grad_norm": 0.15099336206912994, "critic_grad_norm": 0.06058211252093315, "ratio": 1.0000847578048706, "entropy": 0.8971006751060486, "incre_win_rate": 0.0, "step": 737}
{"time": 1767081163.6982036, "phase": "train", "update": 738, "total_env_steps": 2361600, "episode_reward": 0.06982822716236115, "value_loss": 0.002498434577137232, "policy_loss": -0.001647127734543119, "dist_entropy": 0.8989086031913758, "actor_grad_norm": 0.1271885633468628, "critic_grad_norm": 0.037579964846372604, "ratio": 1.0000765323638916, "entropy": 0.8989086031913758, "incre_win_rate": 0.0, "step": 738}
{"time": 1767081168.336987, "phase": "train", "update": 739, "total_env_steps": 2364800, "episode_reward": 0.07174357771873474, "value_loss": 0.0035439409781247377, "policy_loss": -0.0019608333855018144, "dist_entropy": 0.8879178881645202, "actor_grad_norm": 0.1386808156967163, "critic_grad_norm": 0.04251272603869438, "ratio": 0.9996728301048279, "entropy": 0.8879178881645202, "incre_win_rate": 0.0, "step": 739}
{"time": 1767081172.9581227, "phase": "train", "update": 740, "total_env_steps": 2368000, "episode_reward": 0.07704470306634903, "value_loss": 0.003515990963205695, "policy_loss": -0.00196357568445773, "dist_entropy": 0.898915147781372, "actor_grad_norm": 0.1603032648563385, "critic_grad_norm": 0.023045789450407028, "ratio": 1.000166654586792, "entropy": 0.898915147781372, "incre_win_rate": 0.0, "step": 740}
{"time": 1767081177.419602, "phase": "train", "update": 741, "total_env_steps": 2371200, "episode_reward": 0.07304894179105759, "value_loss": 0.0038802238181233407, "policy_loss": -0.0024975026140197087, "dist_entropy": 0.9295191884040832, "actor_grad_norm": 0.17913274466991425, "critic_grad_norm": 0.028578773140907288, "ratio": 1.0000946521759033, "entropy": 0.9295191884040832, "incre_win_rate": 0.0, "step": 741}
{"time": 1767081197.5172997, "phase": "eval", "update": 741, "total_env_steps": 2371200, "eval_win_rate": 0.0, "eval_episode_reward": 10.715387003311253, "step": 741}
{"time": 1767081201.8958142, "phase": "train", "update": 742, "total_env_steps": 2374400, "episode_reward": 0.07595405727624893, "value_loss": 0.0037834450602531435, "policy_loss": -0.002748670186687363, "dist_entropy": 0.9181373834609985, "actor_grad_norm": 0.14593690633773804, "critic_grad_norm": 0.017162861302495003, "ratio": 0.9999449849128723, "entropy": 0.9181373834609985, "incre_win_rate": 0.0, "step": 742}
{"time": 1767081206.2753372, "phase": "train", "update": 743, "total_env_steps": 2377600, "episode_reward": 0.0746326595544815, "value_loss": 0.0025950784794986246, "policy_loss": -0.0012462823102869169, "dist_entropy": 0.9080254316329956, "actor_grad_norm": 0.15357591211795807, "critic_grad_norm": 0.03221098706126213, "ratio": 1.0001715421676636, "entropy": 0.9080254316329956, "incre_win_rate": 0.0, "step": 743}
{"time": 1767081210.8034265, "phase": "train", "update": 744, "total_env_steps": 2380800, "episode_reward": 0.07643212378025055, "value_loss": 0.005000842735171318, "policy_loss": -0.0025550088120269267, "dist_entropy": 0.9222427129745483, "actor_grad_norm": 0.1681959480047226, "critic_grad_norm": 0.023570556193590164, "ratio": 1.000243067741394, "entropy": 0.9222427129745483, "incre_win_rate": 0.0, "step": 744}
{"time": 1767081215.20047, "phase": "train", "update": 745, "total_env_steps": 2384000, "episode_reward": 0.07729408144950867, "value_loss": 0.002628094702959061, "policy_loss": -0.001908194194505697, "dist_entropy": 0.9252089381217956, "actor_grad_norm": 0.16163575649261475, "critic_grad_norm": 0.019822340458631516, "ratio": 0.9999843835830688, "entropy": 0.9252089381217956, "incre_win_rate": 0.0, "step": 745}
{"time": 1767081219.6832588, "phase": "train", "update": 746, "total_env_steps": 2387200, "episode_reward": 0.06920529901981354, "value_loss": 0.0023558076936751604, "policy_loss": -0.0019048879510943806, "dist_entropy": 0.9373589873313903, "actor_grad_norm": 0.1668706089258194, "critic_grad_norm": 0.013736550696194172, "ratio": 0.9998742341995239, "entropy": 0.9373589873313903, "incre_win_rate": 0.0, "step": 746}
{"time": 1767081224.31097, "phase": "train", "update": 747, "total_env_steps": 2390400, "episode_reward": 0.07779025286436081, "value_loss": 0.004898446053266526, "policy_loss": -0.001735486418670007, "dist_entropy": 0.8825107216835022, "actor_grad_norm": 0.1319417804479599, "critic_grad_norm": 0.02558460645377636, "ratio": 0.9999673962593079, "entropy": 0.8825107216835022, "incre_win_rate": 0.0, "step": 747}
{"time": 1767081229.1119637, "phase": "train", "update": 748, "total_env_steps": 2393600, "episode_reward": 0.07114755362272263, "value_loss": 0.0036354549694806336, "policy_loss": -0.0019862251624587655, "dist_entropy": 0.8900929808616638, "actor_grad_norm": 0.15866656601428986, "critic_grad_norm": 0.020471107214689255, "ratio": 0.9997817873954773, "entropy": 0.8900929808616638, "incre_win_rate": 0.0, "step": 748}
{"time": 1767081233.7792947, "phase": "train", "update": 749, "total_env_steps": 2396800, "episode_reward": 0.075905941426754, "value_loss": 0.0036590221337974072, "policy_loss": -0.0021921100139124404, "dist_entropy": 0.8778866767883301, "actor_grad_norm": 0.1618453711271286, "critic_grad_norm": 0.01912812888622284, "ratio": 0.9999821782112122, "entropy": 0.8778866767883301, "incre_win_rate": 0.0, "step": 749}
{"time": 1767081238.2886558, "phase": "train", "update": 750, "total_env_steps": 2400000, "episode_reward": 0.0735916793346405, "value_loss": 0.0035362818744033575, "policy_loss": -0.0026685145634814944, "dist_entropy": 0.9108006954193115, "actor_grad_norm": 0.16280598938465118, "critic_grad_norm": 0.07323752343654633, "ratio": 0.9999589920043945, "entropy": 0.9108006954193115, "incre_win_rate": 0.0, "step": 750}
{"time": 1767081242.9646084, "phase": "train", "update": 751, "total_env_steps": 2403200, "episode_reward": 0.06859271973371506, "value_loss": 0.0026605631224811076, "policy_loss": -0.002301095174173895, "dist_entropy": 0.9323676228523254, "actor_grad_norm": 0.15935900807380676, "critic_grad_norm": 0.0667005181312561, "ratio": 0.9996446967124939, "entropy": 0.9323676228523254, "incre_win_rate": 0.0, "step": 751}
{"time": 1767081247.5921211, "phase": "train", "update": 752, "total_env_steps": 2406400, "episode_reward": 0.07057274132966995, "value_loss": 0.0029515080619603395, "policy_loss": -0.001440096835984539, "dist_entropy": 0.9310425043106079, "actor_grad_norm": 0.12330356985330582, "critic_grad_norm": 0.04143489524722099, "ratio": 0.9997710585594177, "entropy": 0.9310425043106079, "incre_win_rate": 0.0, "step": 752}
{"time": 1767081252.0766165, "phase": "train", "update": 753, "total_env_steps": 2409600, "episode_reward": 0.07446347177028656, "value_loss": 0.004274114686995745, "policy_loss": -0.0021306640725278214, "dist_entropy": 0.9269432187080383, "actor_grad_norm": 0.14264068007469177, "critic_grad_norm": 0.0580868124961853, "ratio": 1.0001716613769531, "entropy": 0.9269432187080383, "incre_win_rate": 0.0, "step": 753}
{"time": 1767081256.622867, "phase": "train", "update": 754, "total_env_steps": 2412800, "episode_reward": 0.07420115917921066, "value_loss": 0.004492672439664602, "policy_loss": -0.002342711782198137, "dist_entropy": 0.887433934211731, "actor_grad_norm": 0.16804543137550354, "critic_grad_norm": 0.01851600967347622, "ratio": 1.00019371509552, "entropy": 0.887433934211731, "incre_win_rate": 0.0, "step": 754}
{"time": 1767081261.4384987, "phase": "train", "update": 755, "total_env_steps": 2416000, "episode_reward": 0.07775299996137619, "value_loss": 0.003872512513771653, "policy_loss": -0.0023553948520657285, "dist_entropy": 0.8787460327148438, "actor_grad_norm": 0.1373271495103836, "critic_grad_norm": 0.04196837171912193, "ratio": 0.9999317526817322, "entropy": 0.8787460327148438, "incre_win_rate": 0.0, "step": 755}
{"time": 1767081265.9748833, "phase": "train", "update": 756, "total_env_steps": 2419200, "episode_reward": 0.0732233077287674, "value_loss": 0.0037644767202436925, "policy_loss": -0.0020244672890889605, "dist_entropy": 0.9219285130500794, "actor_grad_norm": 0.12885430455207825, "critic_grad_norm": 0.060965996235609055, "ratio": 0.999837338924408, "entropy": 0.9219285130500794, "incre_win_rate": 0.0, "step": 756}
{"time": 1767081270.426094, "phase": "train", "update": 757, "total_env_steps": 2422400, "episode_reward": 0.07166080176830292, "value_loss": 0.003903532261028886, "policy_loss": -0.002378329085316011, "dist_entropy": 0.9269270181655884, "actor_grad_norm": 0.18148139119148254, "critic_grad_norm": 0.02295028418302536, "ratio": 0.9998725056648254, "entropy": 0.9269270181655884, "incre_win_rate": 0.0, "step": 757}
{"time": 1767081274.9642649, "phase": "train", "update": 758, "total_env_steps": 2425600, "episode_reward": 0.06769867241382599, "value_loss": 0.003326421556994319, "policy_loss": -0.0019833258911887697, "dist_entropy": 0.917847192287445, "actor_grad_norm": 0.1861995905637741, "critic_grad_norm": 0.03059460036456585, "ratio": 1.000080943107605, "entropy": 0.917847192287445, "incre_win_rate": 0.0, "step": 758}
{"time": 1767081279.5692499, "phase": "train", "update": 759, "total_env_steps": 2428800, "episode_reward": 0.07675289362668991, "value_loss": 0.004527060966938734, "policy_loss": -0.0015759648108990998, "dist_entropy": 0.8563111305236817, "actor_grad_norm": 0.16316449642181396, "critic_grad_norm": 0.026927942410111427, "ratio": 1.0001744031906128, "entropy": 0.8563111305236817, "incre_win_rate": 0.0, "step": 759}
{"time": 1767081284.1887949, "phase": "train", "update": 760, "total_env_steps": 2432000, "episode_reward": 0.0769624412059784, "value_loss": 0.004632604867219925, "policy_loss": -0.0025601870836709393, "dist_entropy": 0.8461771249771118, "actor_grad_norm": 0.14879950881004333, "critic_grad_norm": 0.01725994609296322, "ratio": 0.9999415278434753, "entropy": 0.8461771249771118, "incre_win_rate": 0.0, "step": 760}
{"time": 1767081288.8041651, "phase": "train", "update": 761, "total_env_steps": 2435200, "episode_reward": 0.07785958051681519, "value_loss": 0.004312781151384115, "policy_loss": -0.0021604856378282023, "dist_entropy": 0.8626217007637024, "actor_grad_norm": 0.14477020502090454, "critic_grad_norm": 0.0702938437461853, "ratio": 1.0000544786453247, "entropy": 0.8626217007637024, "incre_win_rate": 0.0, "step": 761}
{"time": 1767081308.0577657, "phase": "eval", "update": 761, "total_env_steps": 2435200, "eval_win_rate": 0.0, "eval_episode_reward": 10.365687086092708, "step": 761}
{"time": 1767081312.4914153, "phase": "train", "update": 762, "total_env_steps": 2438400, "episode_reward": 0.07254812121391296, "value_loss": 0.0030227620154619217, "policy_loss": -0.002156899056338801, "dist_entropy": 0.8332465410232544, "actor_grad_norm": 0.13030187785625458, "critic_grad_norm": 0.027157464995980263, "ratio": 0.99996417760849, "entropy": 0.8332465410232544, "incre_win_rate": 0.0, "step": 762}
{"time": 1767081316.9341664, "phase": "train", "update": 763, "total_env_steps": 2441600, "episode_reward": 0.07290200889110565, "value_loss": 0.004440007451921702, "policy_loss": -0.0022416797603497683, "dist_entropy": 0.8092967629432678, "actor_grad_norm": 0.15597274899482727, "critic_grad_norm": 0.02701069973409176, "ratio": 0.9999648928642273, "entropy": 0.8092967629432678, "incre_win_rate": 0.0, "step": 763}
{"time": 1767081321.660491, "phase": "train", "update": 764, "total_env_steps": 2444800, "episode_reward": 0.07783319801092148, "value_loss": 0.005690301209688187, "policy_loss": -0.002881291726642132, "dist_entropy": 0.7893157362937927, "actor_grad_norm": 0.13523809611797333, "critic_grad_norm": 0.030933169648051262, "ratio": 0.9996870160102844, "entropy": 0.7893157362937927, "incre_win_rate": 0.0, "step": 764}
{"time": 1767081326.107049, "phase": "train", "update": 765, "total_env_steps": 2448000, "episode_reward": 0.07261072099208832, "value_loss": 0.00497586689889431, "policy_loss": -0.001951122870827504, "dist_entropy": 0.8085808992385864, "actor_grad_norm": 0.1440012902021408, "critic_grad_norm": 0.07229746878147125, "ratio": 0.99983149766922, "entropy": 0.8085808992385864, "incre_win_rate": 0.0, "step": 765}
{"time": 1767081330.5691807, "phase": "train", "update": 766, "total_env_steps": 2451200, "episode_reward": 0.08335627615451813, "value_loss": 0.006343972682952881, "policy_loss": -0.0018863731773830494, "dist_entropy": 0.8096148610115051, "actor_grad_norm": 0.16249552369117737, "critic_grad_norm": 0.06068333610892296, "ratio": 1.0002094507217407, "entropy": 0.8096148610115051, "incre_win_rate": 0.0, "step": 766}
{"time": 1767081335.0723789, "phase": "train", "update": 767, "total_env_steps": 2454400, "episode_reward": 0.0771864652633667, "value_loss": 0.0068181631155312065, "policy_loss": -0.0021104717217411916, "dist_entropy": 0.836917519569397, "actor_grad_norm": 0.1401289701461792, "critic_grad_norm": 0.045008670538663864, "ratio": 0.9999290704727173, "entropy": 0.836917519569397, "incre_win_rate": 0.0, "step": 767}
{"time": 1767081339.5728302, "phase": "train", "update": 768, "total_env_steps": 2457600, "episode_reward": 0.08005329221487045, "value_loss": 0.006796600203961134, "policy_loss": -0.002272527287454906, "dist_entropy": 0.8278117656707764, "actor_grad_norm": 0.16389934718608856, "critic_grad_norm": 0.038609638810157776, "ratio": 0.9998547434806824, "entropy": 0.8278117656707764, "incre_win_rate": 0.0, "step": 768}
{"time": 1767081344.1344337, "phase": "train", "update": 769, "total_env_steps": 2460800, "episode_reward": 0.07414062321186066, "value_loss": 0.004195837210863829, "policy_loss": -0.001983320381452813, "dist_entropy": 0.8838843822479248, "actor_grad_norm": 0.1869034320116043, "critic_grad_norm": 0.028431681916117668, "ratio": 0.9999870657920837, "entropy": 0.8838843822479248, "incre_win_rate": 0.0, "step": 769}
{"time": 1767081348.692003, "phase": "train", "update": 770, "total_env_steps": 2464000, "episode_reward": 0.0755448043346405, "value_loss": 0.005554454773664475, "policy_loss": -0.002035563901036497, "dist_entropy": 0.8463355898857117, "actor_grad_norm": 0.1574927419424057, "critic_grad_norm": 0.0451258085668087, "ratio": 1.0002375841140747, "entropy": 0.8463355898857117, "incre_win_rate": 0.0, "step": 770}
{"time": 1767081353.1768641, "phase": "train", "update": 771, "total_env_steps": 2467200, "episode_reward": 0.08233185112476349, "value_loss": 0.006022419314831495, "policy_loss": -0.001463123061756022, "dist_entropy": 0.7983402848243714, "actor_grad_norm": 0.1230643168091774, "critic_grad_norm": 0.046604495495557785, "ratio": 1.000250220298767, "entropy": 0.7983402848243714, "incre_win_rate": 0.0, "step": 771}
{"time": 1767081357.5250328, "phase": "train", "update": 772, "total_env_steps": 2470400, "episode_reward": 0.07446295768022537, "value_loss": 0.004570014774799347, "policy_loss": -0.002360219254954643, "dist_entropy": 0.8239973187446594, "actor_grad_norm": 0.15522992610931396, "critic_grad_norm": 0.03881753236055374, "ratio": 0.9997532963752747, "entropy": 0.8239973187446594, "incre_win_rate": 0.0, "step": 772}
{"time": 1767081362.0502942, "phase": "train", "update": 773, "total_env_steps": 2473600, "episode_reward": 0.07831643521785736, "value_loss": 0.005789006687700748, "policy_loss": -0.0022109722006419474, "dist_entropy": 0.7607340335845947, "actor_grad_norm": 0.12085314095020294, "critic_grad_norm": 0.0262080579996109, "ratio": 1.0000604391098022, "entropy": 0.7607340335845947, "incre_win_rate": 0.0, "step": 773}
{"time": 1767081366.441081, "phase": "train", "update": 774, "total_env_steps": 2476800, "episode_reward": 0.07710420340299606, "value_loss": 0.0031198722776025535, "policy_loss": -0.0020045304644064287, "dist_entropy": 0.7797085165977478, "actor_grad_norm": 0.14346809685230255, "critic_grad_norm": 0.027791563421487808, "ratio": 0.9996771216392517, "entropy": 0.7797085165977478, "incre_win_rate": 0.0, "step": 774}
{"time": 1767081370.8703878, "phase": "train", "update": 775, "total_env_steps": 2480000, "episode_reward": 0.07474493235349655, "value_loss": 0.0059556390158832075, "policy_loss": -0.0025949663063329353, "dist_entropy": 0.8024141550064087, "actor_grad_norm": 0.1443658173084259, "critic_grad_norm": 0.037270043045282364, "ratio": 1.000110149383545, "entropy": 0.8024141550064087, "incre_win_rate": 0.0, "step": 775}
{"time": 1767081375.4435399, "phase": "train", "update": 776, "total_env_steps": 2483200, "episode_reward": 0.07554686814546585, "value_loss": 0.006439369358122349, "policy_loss": -0.0016037350095793102, "dist_entropy": 0.8226226210594177, "actor_grad_norm": 0.1348087191581726, "critic_grad_norm": 0.027732325717806816, "ratio": 0.9999341368675232, "entropy": 0.8226226210594177, "incre_win_rate": 0.0, "step": 776}
{"time": 1767081380.0794332, "phase": "train", "update": 777, "total_env_steps": 2486400, "episode_reward": 0.08905008435249329, "value_loss": 0.010893280617892742, "policy_loss": -0.0014739994052145988, "dist_entropy": 0.7801156401634216, "actor_grad_norm": 0.1434573233127594, "critic_grad_norm": 0.02969786338508129, "ratio": 0.9997817277908325, "entropy": 0.7801156401634216, "incre_win_rate": 0.0, "step": 777}
{"time": 1767081384.635835, "phase": "train", "update": 778, "total_env_steps": 2489600, "episode_reward": 0.08734634518623352, "value_loss": 0.009269461221992969, "policy_loss": -0.0016454501635735142, "dist_entropy": 0.7918036103248596, "actor_grad_norm": 0.1504904329776764, "critic_grad_norm": 0.02582249604165554, "ratio": 0.9997466206550598, "entropy": 0.7918036103248596, "incre_win_rate": 0.0, "step": 778}
{"time": 1767081389.0181162, "phase": "train", "update": 779, "total_env_steps": 2492800, "episode_reward": 0.08387520909309387, "value_loss": 0.007769427914172411, "policy_loss": -0.0026648868329839813, "dist_entropy": 0.7870525598526001, "actor_grad_norm": 0.2252844125032425, "critic_grad_norm": 0.019136520102620125, "ratio": 1.0000511407852173, "entropy": 0.7870525598526001, "incre_win_rate": 0.0, "step": 779}
{"time": 1767081393.4761167, "phase": "train", "update": 780, "total_env_steps": 2496000, "episode_reward": 0.0858764573931694, "value_loss": 0.0066556412726640705, "policy_loss": -0.0018345597402912972, "dist_entropy": 0.7640527009963989, "actor_grad_norm": 0.15132908523082733, "critic_grad_norm": 0.047898080199956894, "ratio": 0.9997550845146179, "entropy": 0.7640527009963989, "incre_win_rate": 0.0, "step": 780}
{"time": 1767081397.77413, "phase": "train", "update": 781, "total_env_steps": 2499200, "episode_reward": 0.08333505690097809, "value_loss": 0.007180573418736458, "policy_loss": -0.0022857883892513087, "dist_entropy": 0.760557758808136, "actor_grad_norm": 0.15649846196174622, "critic_grad_norm": 0.03267071023583412, "ratio": 1.0002888441085815, "entropy": 0.760557758808136, "incre_win_rate": 0.0, "step": 781}
{"time": 1767081414.7810004, "phase": "eval", "update": 781, "total_env_steps": 2499200, "eval_win_rate": 0.0, "eval_episode_reward": 10.315138658940393, "step": 781}
{"time": 1767081419.3163514, "phase": "train", "update": 782, "total_env_steps": 2502400, "episode_reward": 0.08262882381677628, "value_loss": 0.005737005174160004, "policy_loss": -0.0016513512290492471, "dist_entropy": 0.7565709948539734, "actor_grad_norm": 0.14958952367305756, "critic_grad_norm": 0.02494029700756073, "ratio": 1.0000991821289062, "entropy": 0.7565709948539734, "incre_win_rate": 0.0, "step": 782}
{"time": 1767081423.9894125, "phase": "train", "update": 783, "total_env_steps": 2505600, "episode_reward": 0.07955142855644226, "value_loss": 0.004416392184793949, "policy_loss": -0.0025054163197218314, "dist_entropy": 0.7660091400146485, "actor_grad_norm": 0.15995578467845917, "critic_grad_norm": 0.0277099609375, "ratio": 1.0001503229141235, "entropy": 0.7660091400146485, "incre_win_rate": 0.0, "step": 783}
{"time": 1767081428.5149825, "phase": "train", "update": 784, "total_env_steps": 2508800, "episode_reward": 0.07795477658510208, "value_loss": 0.004426888190209866, "policy_loss": -0.001852101670744588, "dist_entropy": 0.7747996687889099, "actor_grad_norm": 0.16213320195674896, "critic_grad_norm": 0.017075130715966225, "ratio": 0.9998876452445984, "entropy": 0.7747996687889099, "incre_win_rate": 0.0, "step": 784}
{"time": 1767081433.0204372, "phase": "train", "update": 785, "total_env_steps": 2512000, "episode_reward": 0.07371792942285538, "value_loss": 0.0042652650736272335, "policy_loss": -0.001281243683968114, "dist_entropy": 0.787262213230133, "actor_grad_norm": 0.13986408710479736, "critic_grad_norm": 0.0339168906211853, "ratio": 0.9998982548713684, "entropy": 0.787262213230133, "incre_win_rate": 0.0, "step": 785}
{"time": 1767081437.4627297, "phase": "train", "update": 786, "total_env_steps": 2515200, "episode_reward": 0.08066845685243607, "value_loss": 0.004599028639495373, "policy_loss": -0.0016705501846612236, "dist_entropy": 0.7725678086280823, "actor_grad_norm": 0.172638401389122, "critic_grad_norm": 0.03214959427714348, "ratio": 1.0000271797180176, "entropy": 0.7725678086280823, "incre_win_rate": 0.0, "step": 786}
{"time": 1767081442.0673935, "phase": "train", "update": 787, "total_env_steps": 2518400, "episode_reward": 0.08821398764848709, "value_loss": 0.006520101241767407, "policy_loss": -0.0022445196256803968, "dist_entropy": 0.7501648306846619, "actor_grad_norm": 0.17449966073036194, "critic_grad_norm": 0.04426146671175957, "ratio": 1.000259280204773, "entropy": 0.7501648306846619, "incre_win_rate": 0.0, "step": 787}
{"time": 1767081446.7870495, "phase": "train", "update": 788, "total_env_steps": 2521600, "episode_reward": 0.08381002396345139, "value_loss": 0.00495234876871109, "policy_loss": -0.0017340550417825895, "dist_entropy": 0.76691175699234, "actor_grad_norm": 0.1352696269750595, "critic_grad_norm": 0.025022728368639946, "ratio": 1.0000746250152588, "entropy": 0.76691175699234, "incre_win_rate": 0.0, "step": 788}
{"time": 1767081451.3019047, "phase": "train", "update": 789, "total_env_steps": 2524800, "episode_reward": 0.07296667993068695, "value_loss": 0.0038047711830586197, "policy_loss": -0.0017752688177907316, "dist_entropy": 0.8339997291564941, "actor_grad_norm": 0.16188564896583557, "critic_grad_norm": 0.01964506320655346, "ratio": 0.9998135566711426, "entropy": 0.8339997291564941, "incre_win_rate": 0.0, "step": 789}
{"time": 1767081455.7669904, "phase": "train", "update": 790, "total_env_steps": 2528000, "episode_reward": 0.0757879763841629, "value_loss": 0.004812522232532502, "policy_loss": -0.002810656259380551, "dist_entropy": 0.8192540884017945, "actor_grad_norm": 0.21024970710277557, "critic_grad_norm": 0.013197734020650387, "ratio": 0.9998785257339478, "entropy": 0.8192540884017945, "incre_win_rate": 0.0, "step": 790}
{"time": 1767081460.0804152, "phase": "train", "update": 791, "total_env_steps": 2531200, "episode_reward": 0.07719526439905167, "value_loss": 0.0031226047314703463, "policy_loss": -0.0017427245141709235, "dist_entropy": 0.8557115077972413, "actor_grad_norm": 0.13903211057186127, "critic_grad_norm": 0.01601761393249035, "ratio": 1.000150203704834, "entropy": 0.8557115077972413, "incre_win_rate": 0.0, "step": 791}
{"time": 1767081464.4744003, "phase": "train", "update": 792, "total_env_steps": 2534400, "episode_reward": 0.07705762982368469, "value_loss": 0.0030019848141819238, "policy_loss": -0.0019300257163806123, "dist_entropy": 0.8479550838470459, "actor_grad_norm": 0.15177397429943085, "critic_grad_norm": 0.017416438087821007, "ratio": 0.9997750520706177, "entropy": 0.8479550838470459, "incre_win_rate": 0.0, "step": 792}
{"time": 1767081468.941861, "phase": "train", "update": 793, "total_env_steps": 2537600, "episode_reward": 0.0801122784614563, "value_loss": 0.0056852766312658785, "policy_loss": -0.0022175486252628217, "dist_entropy": 0.8379494905471802, "actor_grad_norm": 0.16914033889770508, "critic_grad_norm": 0.0159737728536129, "ratio": 1.0000181198120117, "entropy": 0.8379494905471802, "incre_win_rate": 0.0, "step": 793}
{"time": 1767081473.3458807, "phase": "train", "update": 794, "total_env_steps": 2540800, "episode_reward": 0.08388762176036835, "value_loss": 0.00537916012108326, "policy_loss": -0.001974955123078459, "dist_entropy": 0.83128981590271, "actor_grad_norm": 0.13523638248443604, "critic_grad_norm": 0.01478212233632803, "ratio": 1.000079870223999, "entropy": 0.83128981590271, "incre_win_rate": 0.0, "step": 794}
{"time": 1767081477.7033784, "phase": "train", "update": 795, "total_env_steps": 2544000, "episode_reward": 0.08204677700996399, "value_loss": 0.005708110984414816, "policy_loss": -0.001489517149417452, "dist_entropy": 0.817627465724945, "actor_grad_norm": 0.14173035323619843, "critic_grad_norm": 0.056123651564121246, "ratio": 1.000006079673767, "entropy": 0.817627465724945, "incre_win_rate": 0.0, "step": 795}
{"time": 1767081482.298637, "phase": "train", "update": 796, "total_env_steps": 2547200, "episode_reward": 0.08131725341081619, "value_loss": 0.005966932792216539, "policy_loss": -0.001943917372958026, "dist_entropy": 0.7991845965385437, "actor_grad_norm": 0.14136162400245667, "critic_grad_norm": 0.025469226762652397, "ratio": 0.9997116327285767, "entropy": 0.7991845965385437, "incre_win_rate": 0.0, "step": 796}
{"time": 1767081486.9834294, "phase": "train", "update": 797, "total_env_steps": 2550400, "episode_reward": 0.07911061495542526, "value_loss": 0.0042326987721025945, "policy_loss": -0.0017865290843516845, "dist_entropy": 0.8165044903755188, "actor_grad_norm": 0.12939946353435516, "critic_grad_norm": 0.031141135841608047, "ratio": 1.0000600814819336, "entropy": 0.8165044903755188, "incre_win_rate": 0.0, "step": 797}
{"time": 1767081491.6069534, "phase": "train", "update": 798, "total_env_steps": 2553600, "episode_reward": 0.07447019964456558, "value_loss": 0.00515057509765029, "policy_loss": -0.0023972151287750877, "dist_entropy": 0.8297576546669007, "actor_grad_norm": 0.15472882986068726, "critic_grad_norm": 0.04146720468997955, "ratio": 0.9997002482414246, "entropy": 0.8297576546669007, "incre_win_rate": 0.0, "step": 798}
{"time": 1767081496.387978, "phase": "train", "update": 799, "total_env_steps": 2556800, "episode_reward": 0.07567001134157181, "value_loss": 0.003983218548819422, "policy_loss": -0.0021355296316592385, "dist_entropy": 0.8493245720863343, "actor_grad_norm": 0.1178184524178505, "critic_grad_norm": 0.045570258051157, "ratio": 1.0000017881393433, "entropy": 0.8493245720863343, "incre_win_rate": 0.0, "step": 799}
{"time": 1767081501.05015, "phase": "train", "update": 800, "total_env_steps": 2560000, "episode_reward": 0.08007140457630157, "value_loss": 0.004229979868978262, "policy_loss": -0.002595786300032277, "dist_entropy": 0.8312414765357972, "actor_grad_norm": 0.1394207924604416, "critic_grad_norm": 0.04827749356627464, "ratio": 1.0000579357147217, "entropy": 0.8312414765357972, "incre_win_rate": 0.0, "step": 800}
{"time": 1767081505.7660792, "phase": "train", "update": 801, "total_env_steps": 2563200, "episode_reward": 0.07460058480501175, "value_loss": 0.006055782362818718, "policy_loss": -0.0020347473790309325, "dist_entropy": 0.7947587490081787, "actor_grad_norm": 0.11240792274475098, "critic_grad_norm": 0.01670549064874649, "ratio": 0.9998044371604919, "entropy": 0.7947587490081787, "incre_win_rate": 0.0, "step": 801}
{"time": 1767081524.503851, "phase": "eval", "update": 801, "total_env_steps": 2563200, "eval_win_rate": 0.0, "eval_episode_reward": 11.214662665562905, "step": 801}
{"time": 1767081529.0777504, "phase": "train", "update": 802, "total_env_steps": 2566400, "episode_reward": 0.0760844349861145, "value_loss": 0.006271612364798784, "policy_loss": -0.0020574838384575856, "dist_entropy": 0.8136078000068665, "actor_grad_norm": 0.1221005916595459, "critic_grad_norm": 0.033544909209012985, "ratio": 1.0000195503234863, "entropy": 0.8136078000068665, "incre_win_rate": 0.0, "step": 802}
{"time": 1767081533.581143, "phase": "train", "update": 803, "total_env_steps": 2569600, "episode_reward": 0.08037614077329636, "value_loss": 0.005124554410576821, "policy_loss": -0.0016556721413508058, "dist_entropy": 0.8221460819244385, "actor_grad_norm": 0.12121473997831345, "critic_grad_norm": 0.021993661299347878, "ratio": 1.000151515007019, "entropy": 0.8221460819244385, "incre_win_rate": 0.0, "step": 803}
{"time": 1767081538.0679414, "phase": "train", "update": 804, "total_env_steps": 2572800, "episode_reward": 0.07763452082872391, "value_loss": 0.004910106863826513, "policy_loss": -0.0017246220780648969, "dist_entropy": 0.8226186871528626, "actor_grad_norm": 0.1450486034154892, "critic_grad_norm": 0.01908445730805397, "ratio": 1.0001811981201172, "entropy": 0.8226186871528626, "incre_win_rate": 0.0, "step": 804}
{"time": 1767081542.6418712, "phase": "train", "update": 805, "total_env_steps": 2576000, "episode_reward": 0.08327142894268036, "value_loss": 0.006391737703233957, "policy_loss": -0.0026044048980395475, "dist_entropy": 0.7941835880279541, "actor_grad_norm": 0.15316109359264374, "critic_grad_norm": 0.053151197731494904, "ratio": 0.9999762773513794, "entropy": 0.7941835880279541, "incre_win_rate": 0.0, "step": 805}
{"time": 1767081547.3009667, "phase": "train", "update": 806, "total_env_steps": 2579200, "episode_reward": 0.07752948999404907, "value_loss": 0.008185987919569015, "policy_loss": -0.0021500543015605445, "dist_entropy": 0.823052191734314, "actor_grad_norm": 0.14020633697509766, "critic_grad_norm": 0.031679119914770126, "ratio": 1.0000351667404175, "entropy": 0.823052191734314, "incre_win_rate": 0.0, "step": 806}
{"time": 1767081551.699807, "phase": "train", "update": 807, "total_env_steps": 2582400, "episode_reward": 0.07341318577528, "value_loss": 0.0045344516634941105, "policy_loss": -0.001328291685335614, "dist_entropy": 0.876829731464386, "actor_grad_norm": 0.13306955993175507, "critic_grad_norm": 0.04080675169825554, "ratio": 1.0001325607299805, "entropy": 0.876829731464386, "incre_win_rate": 0.0, "step": 807}
{"time": 1767081556.1828454, "phase": "train", "update": 808, "total_env_steps": 2585600, "episode_reward": 0.08001241832971573, "value_loss": 0.005342883802950382, "policy_loss": -0.0024772453383654636, "dist_entropy": 0.8712588548660278, "actor_grad_norm": 0.1715545952320099, "critic_grad_norm": 0.032609786838293076, "ratio": 0.999923050403595, "entropy": 0.8712588548660278, "incre_win_rate": 0.0, "step": 808}
{"time": 1767081560.4717517, "phase": "train", "update": 809, "total_env_steps": 2588800, "episode_reward": 0.0764755830168724, "value_loss": 0.0036693753208965063, "policy_loss": -0.0019205311249493207, "dist_entropy": 0.8650271773338318, "actor_grad_norm": 0.15196336805820465, "critic_grad_norm": 0.027383077889680862, "ratio": 0.9997637867927551, "entropy": 0.8650271773338318, "incre_win_rate": 0.0, "step": 809}
{"time": 1767081564.8650916, "phase": "train", "update": 810, "total_env_steps": 2592000, "episode_reward": 0.07189155369997025, "value_loss": 0.0055032925680279735, "policy_loss": -0.0020577199210535468, "dist_entropy": 0.9116023302078247, "actor_grad_norm": 0.12845367193222046, "critic_grad_norm": 0.033702462911605835, "ratio": 1.0000743865966797, "entropy": 0.9116023302078247, "incre_win_rate": 0.0, "step": 810}
{"time": 1767081569.359457, "phase": "train", "update": 811, "total_env_steps": 2595200, "episode_reward": 0.07751862704753876, "value_loss": 0.005636394768953323, "policy_loss": -0.0019542774917091776, "dist_entropy": 0.9007008314132691, "actor_grad_norm": 0.14393489062786102, "critic_grad_norm": 0.024721194058656693, "ratio": 0.9996536374092102, "entropy": 0.9007008314132691, "incre_win_rate": 0.0, "step": 811}
{"time": 1767081573.5935616, "phase": "train", "update": 812, "total_env_steps": 2598400, "episode_reward": 0.0811154842376709, "value_loss": 0.005526877474039793, "policy_loss": -0.0019013035042334536, "dist_entropy": 0.8723465919494628, "actor_grad_norm": 0.1563752144575119, "critic_grad_norm": 0.02081548236310482, "ratio": 1.0002363920211792, "entropy": 0.8723465919494628, "incre_win_rate": 0.0, "step": 812}
{"time": 1767081577.9405396, "phase": "train", "update": 813, "total_env_steps": 2601600, "episode_reward": 0.07762624323368073, "value_loss": 0.005055175535380841, "policy_loss": -0.00244142780287433, "dist_entropy": 0.8843385815620423, "actor_grad_norm": 0.17958025634288788, "critic_grad_norm": 0.0208634864538908, "ratio": 0.9997643828392029, "entropy": 0.8843385815620423, "incre_win_rate": 0.0, "step": 813}
{"time": 1767081582.4650826, "phase": "train", "update": 814, "total_env_steps": 2604800, "episode_reward": 0.07173789292573929, "value_loss": 0.004331520013511181, "policy_loss": -0.002724606174984956, "dist_entropy": 0.8857972383499145, "actor_grad_norm": 0.18380232155323029, "critic_grad_norm": 0.03944827988743782, "ratio": 0.9998030662536621, "entropy": 0.8857972383499145, "incre_win_rate": 0.0, "step": 814}
{"time": 1767081587.118388, "phase": "train", "update": 815, "total_env_steps": 2608000, "episode_reward": 0.07804324477910995, "value_loss": 0.007782705407589674, "policy_loss": -0.001144748678895091, "dist_entropy": 0.8381020784378052, "actor_grad_norm": 0.1270933598279953, "critic_grad_norm": 0.0325704887509346, "ratio": 1.000309705734253, "entropy": 0.8381020784378052, "incre_win_rate": 0.0, "step": 815}
{"time": 1767081591.5577362, "phase": "train", "update": 816, "total_env_steps": 2611200, "episode_reward": 0.07523386180400848, "value_loss": 0.0035531452391296624, "policy_loss": -0.0015391830144263706, "dist_entropy": 0.8311639547348022, "actor_grad_norm": 0.1369570642709732, "critic_grad_norm": 0.024917198345065117, "ratio": 1.0003199577331543, "entropy": 0.8311639547348022, "incre_win_rate": 0.0, "step": 816}
{"time": 1767081595.9776297, "phase": "train", "update": 817, "total_env_steps": 2614400, "episode_reward": 0.07527525722980499, "value_loss": 0.004157785698771477, "policy_loss": -0.0009393076773921649, "dist_entropy": 0.8167597055435181, "actor_grad_norm": 0.1186443343758583, "critic_grad_norm": 0.015010075643658638, "ratio": 1.0001270771026611, "entropy": 0.8167597055435181, "incre_win_rate": 0.0, "step": 817}
{"time": 1767081630.8780897, "phase": "train", "update": 818, "total_env_steps": 2617600, "episode_reward": 0.08914165198802948, "value_loss": 0.01762169674038887, "policy_loss": -0.0009761485003352277, "dist_entropy": 0.7952245116233826, "actor_grad_norm": 0.12337227165699005, "critic_grad_norm": 0.17828966677188873, "ratio": 0.9998571276664734, "entropy": 0.7952245116233826, "incre_win_rate": 0.0, "step": 818}
{"time": 1767081635.158205, "phase": "train", "update": 819, "total_env_steps": 2620800, "episode_reward": 0.06740687042474747, "value_loss": 0.004712989088147879, "policy_loss": -0.002054831200540974, "dist_entropy": 0.8902295231819153, "actor_grad_norm": 0.15536737442016602, "critic_grad_norm": 0.09811095148324966, "ratio": 1.0001953840255737, "entropy": 0.8902295231819153, "incre_win_rate": 0.0, "step": 819}
{"time": 1767081639.4068527, "phase": "train", "update": 820, "total_env_steps": 2624000, "episode_reward": 0.07751034945249557, "value_loss": 0.004448457155376673, "policy_loss": -0.001780252215533551, "dist_entropy": 0.83188898563385, "actor_grad_norm": 0.1849849671125412, "critic_grad_norm": 0.08007983863353729, "ratio": 0.9999105334281921, "entropy": 0.83188898563385, "incre_win_rate": 0.0, "step": 820}
{"time": 1767081643.8785532, "phase": "train", "update": 821, "total_env_steps": 2627200, "episode_reward": 0.07300393283367157, "value_loss": 0.005255058407783508, "policy_loss": -0.0022813672695910724, "dist_entropy": 0.8647675037384033, "actor_grad_norm": 0.11467228084802628, "critic_grad_norm": 0.06189962849020958, "ratio": 1.0001100301742554, "entropy": 0.8647675037384033, "incre_win_rate": 0.0, "step": 821}
{"time": 1767081663.0763621, "phase": "eval", "update": 821, "total_env_steps": 2627200, "eval_win_rate": 0.0, "eval_episode_reward": 10.67301324503311, "step": 821}
{"time": 1767081667.384969, "phase": "train", "update": 822, "total_env_steps": 2630400, "episode_reward": 0.07500673085451126, "value_loss": 0.0025768896564841272, "policy_loss": -0.0019006714974736383, "dist_entropy": 0.8852613925933838, "actor_grad_norm": 0.12593679130077362, "critic_grad_norm": 0.04196209833025932, "ratio": 1.0000039339065552, "entropy": 0.8852613925933838, "incre_win_rate": 0.0, "step": 822}
{"time": 1767081671.6850097, "phase": "train", "update": 823, "total_env_steps": 2633600, "episode_reward": 0.07068345695734024, "value_loss": 0.003092446690425277, "policy_loss": -0.0019672606736889976, "dist_entropy": 0.8964065790176392, "actor_grad_norm": 0.13291828334331512, "critic_grad_norm": 0.036940157413482666, "ratio": 0.9998928308486938, "entropy": 0.8964065790176392, "incre_win_rate": 0.0, "step": 823}
{"time": 1767081676.041028, "phase": "train", "update": 824, "total_env_steps": 2636800, "episode_reward": 0.07644660770893097, "value_loss": 0.004811288230121136, "policy_loss": -0.0018598425878110446, "dist_entropy": 0.9137441039085388, "actor_grad_norm": 0.1799742579460144, "critic_grad_norm": 0.03368833288550377, "ratio": 0.9999718070030212, "entropy": 0.9137441039085388, "incre_win_rate": 0.0, "step": 824}
{"time": 1767081680.2356465, "phase": "train", "update": 825, "total_env_steps": 2640000, "episode_reward": 0.07340490818023682, "value_loss": 0.0041521148756146434, "policy_loss": -0.002752875041244529, "dist_entropy": 0.9375760197639466, "actor_grad_norm": 0.17426005005836487, "critic_grad_norm": 0.0435967892408371, "ratio": 0.9997758865356445, "entropy": 0.9375760197639466, "incre_win_rate": 0.0, "step": 825}
{"time": 1767081684.5435078, "phase": "train", "update": 826, "total_env_steps": 2643200, "episode_reward": 0.07691535353660583, "value_loss": 0.004039843566715717, "policy_loss": -0.002591226452715034, "dist_entropy": 0.9107540488243103, "actor_grad_norm": 0.15151265263557434, "critic_grad_norm": 0.054620712995529175, "ratio": 0.9996320605278015, "entropy": 0.9107540488243103, "incre_win_rate": 0.0, "step": 826}
{"time": 1767081688.8506453, "phase": "train", "update": 827, "total_env_steps": 2646400, "episode_reward": 0.07653973996639252, "value_loss": 0.0030568996910005806, "policy_loss": -0.0018620984425965048, "dist_entropy": 0.8795054793357849, "actor_grad_norm": 0.15650728344917297, "critic_grad_norm": 0.05315389111638069, "ratio": 0.9998529553413391, "entropy": 0.8795054793357849, "incre_win_rate": 0.0, "step": 827}
{"time": 1767081693.1602378, "phase": "train", "update": 828, "total_env_steps": 2649600, "episode_reward": 0.0674705058336258, "value_loss": 0.001983918924815953, "policy_loss": -0.001394643862589362, "dist_entropy": 0.9236626386642456, "actor_grad_norm": 0.1308111846446991, "critic_grad_norm": 0.03948013857007027, "ratio": 0.9997634887695312, "entropy": 0.9236626386642456, "incre_win_rate": 0.0, "step": 828}
{"time": 1767081697.5906603, "phase": "train", "update": 829, "total_env_steps": 2652800, "episode_reward": 0.07355236262083054, "value_loss": 0.0036897392477840186, "policy_loss": -0.0019422557932330165, "dist_entropy": 0.8574678897857666, "actor_grad_norm": 0.1345456838607788, "critic_grad_norm": 0.03680375590920448, "ratio": 1.0001171827316284, "entropy": 0.8574678897857666, "incre_win_rate": 0.0, "step": 829}
{"time": 1767081701.8771431, "phase": "train", "update": 830, "total_env_steps": 2656000, "episode_reward": 0.07374275475740433, "value_loss": 0.002335952548310161, "policy_loss": -0.0012528627185311337, "dist_entropy": 0.8622963070869446, "actor_grad_norm": 0.10740610212087631, "critic_grad_norm": 0.031837716698646545, "ratio": 0.9999687075614929, "entropy": 0.8622963070869446, "incre_win_rate": 0.0, "step": 830}
{"time": 1767081706.1155665, "phase": "train", "update": 831, "total_env_steps": 2659200, "episode_reward": 0.06830039620399475, "value_loss": 0.0021191232837736605, "policy_loss": -0.0015402291103159271, "dist_entropy": 0.8828866481781006, "actor_grad_norm": 0.11796531826257706, "critic_grad_norm": 0.021557597443461418, "ratio": 1.0002377033233643, "entropy": 0.8828866481781006, "incre_win_rate": 0.0, "step": 831}
{"time": 1767081710.4036481, "phase": "train", "update": 832, "total_env_steps": 2662400, "episode_reward": 0.07388193905353546, "value_loss": 0.0025777706876397135, "policy_loss": -0.0014325078690518467, "dist_entropy": 0.8795935273170471, "actor_grad_norm": 0.14873819053173065, "critic_grad_norm": 0.016273686662316322, "ratio": 1.000133752822876, "entropy": 0.8795935273170471, "incre_win_rate": 0.0, "step": 832}
{"time": 1767081714.7689881, "phase": "train", "update": 833, "total_env_steps": 2665600, "episode_reward": 0.0777716264128685, "value_loss": 0.003715845849364996, "policy_loss": -0.0014654708498088808, "dist_entropy": 0.873068368434906, "actor_grad_norm": 0.12246011942625046, "critic_grad_norm": 0.01947358436882496, "ratio": 1.0000324249267578, "entropy": 0.873068368434906, "incre_win_rate": 0.0, "step": 833}
{"time": 1767081719.148091, "phase": "train", "update": 834, "total_env_steps": 2668800, "episode_reward": 0.07585886120796204, "value_loss": 0.0037814087700098753, "policy_loss": -0.002428535748373406, "dist_entropy": 0.8580454826354981, "actor_grad_norm": 0.14488260447978973, "critic_grad_norm": 0.01428288221359253, "ratio": 0.9997338652610779, "entropy": 0.8580454826354981, "incre_win_rate": 0.0, "step": 834}
{"time": 1767081723.4813566, "phase": "train", "update": 835, "total_env_steps": 2672000, "episode_reward": 0.07259157299995422, "value_loss": 0.0036034706514328717, "policy_loss": -0.0018816049919273326, "dist_entropy": 0.8808780908584595, "actor_grad_norm": 0.1600141078233719, "critic_grad_norm": 0.018995508551597595, "ratio": 1.000099539756775, "entropy": 0.8808780908584595, "incre_win_rate": 0.0, "step": 835}
{"time": 1767081727.7648916, "phase": "train", "update": 836, "total_env_steps": 2675200, "episode_reward": 0.07073313742876053, "value_loss": 0.0022619232069700955, "policy_loss": -0.001550630620539195, "dist_entropy": 0.9132683992385864, "actor_grad_norm": 0.13687948882579803, "critic_grad_norm": 0.018154267221689224, "ratio": 1.0005228519439697, "entropy": 0.9132683992385864, "incre_win_rate": 0.0, "step": 836}
{"time": 1767081732.062098, "phase": "train", "update": 837, "total_env_steps": 2678400, "episode_reward": 0.07586558163166046, "value_loss": 0.005304244719445706, "policy_loss": -0.0022031556816784815, "dist_entropy": 0.8573724150657653, "actor_grad_norm": 0.16498832404613495, "critic_grad_norm": 0.026666445657610893, "ratio": 1.0001929998397827, "entropy": 0.8573724150657653, "incre_win_rate": 0.0, "step": 837}
{"time": 1767081736.4356747, "phase": "train", "update": 838, "total_env_steps": 2681600, "episode_reward": 0.07675807178020477, "value_loss": 0.003853824036195874, "policy_loss": -0.0019563714849759606, "dist_entropy": 0.8536141991615296, "actor_grad_norm": 0.12229368835687637, "critic_grad_norm": 0.02251715585589409, "ratio": 0.9999393820762634, "entropy": 0.8536141991615296, "incre_win_rate": 0.0, "step": 838}
{"time": 1767081740.735324, "phase": "train", "update": 839, "total_env_steps": 2684800, "episode_reward": 0.07647557556629181, "value_loss": 0.0037710538133978845, "policy_loss": -0.001973816191514288, "dist_entropy": 0.8280062079429626, "actor_grad_norm": 0.11766233295202255, "critic_grad_norm": 0.02387058176100254, "ratio": 1.0000370740890503, "entropy": 0.8280062079429626, "incre_win_rate": 0.0, "step": 839}
{"time": 1767081744.9935217, "phase": "train", "update": 840, "total_env_steps": 2688000, "episode_reward": 0.06697589159011841, "value_loss": 0.0032200058456510307, "policy_loss": -0.001888468048416314, "dist_entropy": 0.8876323223114013, "actor_grad_norm": 0.16628490388393402, "critic_grad_norm": 0.015611681155860424, "ratio": 0.9999147653579712, "entropy": 0.8876323223114013, "incre_win_rate": 0.0, "step": 840}
{"time": 1767081749.2803328, "phase": "train", "update": 841, "total_env_steps": 2691200, "episode_reward": 0.07979460060596466, "value_loss": 0.004504376742988825, "policy_loss": -0.001863271331991001, "dist_entropy": 0.7914951086044312, "actor_grad_norm": 0.16118207573890686, "critic_grad_norm": 0.013553100638091564, "ratio": 0.9998931288719177, "entropy": 0.7914951086044312, "incre_win_rate": 0.0, "step": 841}
{"time": 1767081767.528821, "phase": "eval", "update": 841, "total_env_steps": 2691200, "eval_win_rate": 0.0, "eval_episode_reward": 10.055308360927143, "step": 841}
{"time": 1767081771.849939, "phase": "train", "update": 842, "total_env_steps": 2694400, "episode_reward": 0.07296306639909744, "value_loss": 0.004316073656082153, "policy_loss": -0.0022255396229226678, "dist_entropy": 0.8524404644966126, "actor_grad_norm": 0.14240007102489471, "critic_grad_norm": 0.032055165618658066, "ratio": 0.9998856782913208, "entropy": 0.8524404644966126, "incre_win_rate": 0.0, "step": 842}
{"time": 1767081776.2220416, "phase": "train", "update": 843, "total_env_steps": 2697600, "episode_reward": 0.07758485525846481, "value_loss": 0.006534911040216684, "policy_loss": -0.00185401682044386, "dist_entropy": 0.8110636115074158, "actor_grad_norm": 0.1346227526664734, "critic_grad_norm": 0.08080796152353287, "ratio": 1.0003210306167603, "entropy": 0.8110636115074158, "incre_win_rate": 0.0, "step": 843}
{"time": 1767081780.6321, "phase": "train", "update": 844, "total_env_steps": 2700800, "episode_reward": 0.07626552134752274, "value_loss": 0.004310256615281105, "policy_loss": -0.001999468672477711, "dist_entropy": 0.8111985325813293, "actor_grad_norm": 0.12557576596736908, "critic_grad_norm": 0.0561772845685482, "ratio": 0.9999964833259583, "entropy": 0.8111985325813293, "incre_win_rate": 0.0, "step": 844}
{"time": 1767081784.9869292, "phase": "train", "update": 845, "total_env_steps": 2704000, "episode_reward": 0.07325123995542526, "value_loss": 0.003318604873493314, "policy_loss": -0.001706372778306786, "dist_entropy": 0.81739422082901, "actor_grad_norm": 0.15060833096504211, "critic_grad_norm": 0.03073396161198616, "ratio": 1.000162124633789, "entropy": 0.81739422082901, "incre_win_rate": 0.0, "step": 845}
{"time": 1767081789.4321496, "phase": "train", "update": 846, "total_env_steps": 2707200, "episode_reward": 0.0758335068821907, "value_loss": 0.006329580582678318, "policy_loss": -0.002205303056004482, "dist_entropy": 0.8090336918830872, "actor_grad_norm": 0.14813272655010223, "critic_grad_norm": 0.03565499186515808, "ratio": 1.00006902217865, "entropy": 0.8090336918830872, "incre_win_rate": 0.0, "step": 846}
{"time": 1767081793.8594224, "phase": "train", "update": 847, "total_env_steps": 2710400, "episode_reward": 0.07338990271091461, "value_loss": 0.003889899794012308, "policy_loss": -0.002394841515651791, "dist_entropy": 0.8037744522094726, "actor_grad_norm": 0.1409771740436554, "critic_grad_norm": 0.03717486932873726, "ratio": 0.9998509287834167, "entropy": 0.8037744522094726, "incre_win_rate": 0.0, "step": 847}
{"time": 1767081798.1861553, "phase": "train", "update": 848, "total_env_steps": 2713600, "episode_reward": 0.06753518432378769, "value_loss": 0.005209726095199585, "policy_loss": -0.0024826259447358725, "dist_entropy": 0.8243208408355713, "actor_grad_norm": 0.16290311515331268, "critic_grad_norm": 0.022955667227506638, "ratio": 0.9997895359992981, "entropy": 0.8243208408355713, "incre_win_rate": 0.0, "step": 848}
{"time": 1767081802.5676537, "phase": "train", "update": 849, "total_env_steps": 2716800, "episode_reward": 0.08094267547130585, "value_loss": 0.004763382766395807, "policy_loss": -0.0015147563818914023, "dist_entropy": 0.7503406882286072, "actor_grad_norm": 0.13708479702472687, "critic_grad_norm": 0.0646982416510582, "ratio": 0.9997865557670593, "entropy": 0.7503406882286072, "incre_win_rate": 0.0, "step": 849}
{"time": 1767081806.9939451, "phase": "train", "update": 850, "total_env_steps": 2720000, "episode_reward": 0.06966576725244522, "value_loss": 0.0026510116644203664, "policy_loss": -0.0017718760728254069, "dist_entropy": 0.820596444606781, "actor_grad_norm": 0.1450057178735733, "critic_grad_norm": 0.049241553992033005, "ratio": 0.9998241662979126, "entropy": 0.820596444606781, "incre_win_rate": 0.0, "step": 850}
{"time": 1767081811.442319, "phase": "train", "update": 851, "total_env_steps": 2723200, "episode_reward": 0.07955453544855118, "value_loss": 0.006225068774074316, "policy_loss": -0.0016650881804125106, "dist_entropy": 0.7887284755706787, "actor_grad_norm": 0.14619828760623932, "critic_grad_norm": 0.03249572962522507, "ratio": 0.9999918341636658, "entropy": 0.7887284755706787, "incre_win_rate": 0.041666666666666664, "step": 851}
{"time": 1767081815.7538397, "phase": "train", "update": 852, "total_env_steps": 2726400, "episode_reward": 0.07061930745840073, "value_loss": 0.0028363062534481286, "policy_loss": -0.0022051614846859023, "dist_entropy": 0.8550580501556396, "actor_grad_norm": 0.15335367619991302, "critic_grad_norm": 0.02824748493731022, "ratio": 0.9998387694358826, "entropy": 0.8550580501556396, "incre_win_rate": 0.0, "step": 852}
{"time": 1767081820.3486018, "phase": "train", "update": 853, "total_env_steps": 2729600, "episode_reward": 0.07657232880592346, "value_loss": 0.004192619677633047, "policy_loss": -0.002410466135046718, "dist_entropy": 0.8239213705062867, "actor_grad_norm": 0.15547305345535278, "critic_grad_norm": 0.052774786949157715, "ratio": 0.9996002316474915, "entropy": 0.8239213705062867, "incre_win_rate": 0.0, "step": 853}
{"time": 1767081824.7386768, "phase": "train", "update": 854, "total_env_steps": 2732800, "episode_reward": 0.07553445547819138, "value_loss": 0.0035761484410613774, "policy_loss": -0.0018509964927510224, "dist_entropy": 0.8129807114601135, "actor_grad_norm": 0.1303471326828003, "critic_grad_norm": 0.02724139392375946, "ratio": 0.9997491836547852, "entropy": 0.8129807114601135, "incre_win_rate": 0.0, "step": 854}
{"time": 1767081829.1154134, "phase": "train", "update": 855, "total_env_steps": 2736000, "episode_reward": 0.07138917595148087, "value_loss": 0.00435592932626605, "policy_loss": -0.0021644191431171578, "dist_entropy": 0.8521109580993652, "actor_grad_norm": 0.14854584634304047, "critic_grad_norm": 0.015317702665925026, "ratio": 0.9999294281005859, "entropy": 0.8521109580993652, "incre_win_rate": 0.0, "step": 855}
{"time": 1767081833.4222653, "phase": "train", "update": 856, "total_env_steps": 2739200, "episode_reward": 0.07077763229608536, "value_loss": 0.003576719807460904, "policy_loss": -0.002109905709252935, "dist_entropy": 0.8744705080986023, "actor_grad_norm": 0.15221717953681946, "critic_grad_norm": 0.027346530929207802, "ratio": 0.9997023940086365, "entropy": 0.8744705080986023, "incre_win_rate": 0.0, "step": 856}
{"time": 1767081837.7933865, "phase": "train", "update": 857, "total_env_steps": 2742400, "episode_reward": 0.07940241694450378, "value_loss": 0.00444453489035368, "policy_loss": -0.002012790192736702, "dist_entropy": 0.8295154809951782, "actor_grad_norm": 0.14119185507297516, "critic_grad_norm": 0.048230160027742386, "ratio": 1.0000752210617065, "entropy": 0.8295154809951782, "incre_win_rate": 0.0, "step": 857}
{"time": 1767081842.2348108, "phase": "train", "update": 858, "total_env_steps": 2745600, "episode_reward": 0.07645022869110107, "value_loss": 0.004240323882550001, "policy_loss": -0.001805436371618807, "dist_entropy": 0.840787410736084, "actor_grad_norm": 0.14573882520198822, "critic_grad_norm": 0.04173281416296959, "ratio": 0.9998998641967773, "entropy": 0.840787410736084, "incre_win_rate": 0.0, "step": 858}
{"time": 1767081846.5512338, "phase": "train", "update": 859, "total_env_steps": 2748800, "episode_reward": 0.0708635151386261, "value_loss": 0.004548485111445189, "policy_loss": -0.0016451967765394927, "dist_entropy": 0.8598857879638672, "actor_grad_norm": 0.1666322946548462, "critic_grad_norm": 0.047512851655483246, "ratio": 0.9997164011001587, "entropy": 0.8598857879638672, "incre_win_rate": 0.0, "step": 859}
{"time": 1767081850.8923433, "phase": "train", "update": 860, "total_env_steps": 2752000, "episode_reward": 0.07187137752771378, "value_loss": 0.0024666732642799616, "policy_loss": -0.001585153619427615, "dist_entropy": 0.8375553965568543, "actor_grad_norm": 0.15123604238033295, "critic_grad_norm": 0.027337610721588135, "ratio": 1.0003350973129272, "entropy": 0.8375553965568543, "incre_win_rate": 0.0, "step": 860}
{"time": 1767081855.1727972, "phase": "train", "update": 861, "total_env_steps": 2755200, "episode_reward": 0.0716918483376503, "value_loss": 0.0028395661152899264, "policy_loss": -0.001766797898754291, "dist_entropy": 0.8387686610221863, "actor_grad_norm": 0.15824346244335175, "critic_grad_norm": 0.025091519579291344, "ratio": 0.9997994303703308, "entropy": 0.8387686610221863, "incre_win_rate": 0.0, "step": 861}
{"time": 1767081873.439418, "phase": "eval", "update": 861, "total_env_steps": 2755200, "eval_win_rate": 0.0, "eval_episode_reward": 10.843336092715225, "step": 861}
{"time": 1767081877.6669137, "phase": "train", "update": 862, "total_env_steps": 2758400, "episode_reward": 0.06788234412670135, "value_loss": 0.0021581195760518312, "policy_loss": -0.0025649396358389254, "dist_entropy": 0.8762271881103516, "actor_grad_norm": 0.16049306094646454, "critic_grad_norm": 0.019566377624869347, "ratio": 0.9999948740005493, "entropy": 0.8762271881103516, "incre_win_rate": 0.0, "step": 862}
{"time": 1767081882.0672538, "phase": "train", "update": 863, "total_env_steps": 2761600, "episode_reward": 0.0777524933218956, "value_loss": 0.0031885924283415077, "policy_loss": -0.0019451254653240825, "dist_entropy": 0.8578446388244629, "actor_grad_norm": 0.13181093335151672, "critic_grad_norm": 0.030755329877138138, "ratio": 0.9997493624687195, "entropy": 0.8578446388244629, "incre_win_rate": 0.0, "step": 863}
{"time": 1767081886.3258505, "phase": "train", "update": 864, "total_env_steps": 2764800, "episode_reward": 0.07213111221790314, "value_loss": 0.0033722553867846727, "policy_loss": -0.0023825654232481953, "dist_entropy": 0.8551690697669982, "actor_grad_norm": 0.13960635662078857, "critic_grad_norm": 0.08653341978788376, "ratio": 0.9999890327453613, "entropy": 0.8551690697669982, "incre_win_rate": 0.0, "step": 864}
{"time": 1767081890.7012274, "phase": "train", "update": 865, "total_env_steps": 2768000, "episode_reward": 0.06815190613269806, "value_loss": 0.0027763404417783023, "policy_loss": -0.0018001109109212266, "dist_entropy": 0.9085883021354675, "actor_grad_norm": 0.12559369206428528, "critic_grad_norm": 0.053123604506254196, "ratio": 0.9996337890625, "entropy": 0.9085883021354675, "incre_win_rate": 0.0, "step": 865}
{"time": 1767081895.430563, "phase": "train", "update": 866, "total_env_steps": 2771200, "episode_reward": 0.07150869071483612, "value_loss": 0.0022385939955711365, "policy_loss": -0.002034935904363788, "dist_entropy": 0.8702855229377746, "actor_grad_norm": 0.14142100512981415, "critic_grad_norm": 0.03529506176710129, "ratio": 0.999882161617279, "entropy": 0.8702855229377746, "incre_win_rate": 0.0, "step": 866}
{"time": 1767081899.9945407, "phase": "train", "update": 867, "total_env_steps": 2774400, "episode_reward": 0.07809757441282272, "value_loss": 0.004070959985256195, "policy_loss": -0.002105178276472941, "dist_entropy": 0.8327499866485596, "actor_grad_norm": 0.11141299456357956, "critic_grad_norm": 0.03997360169887543, "ratio": 1.0004521608352661, "entropy": 0.8327499866485596, "incre_win_rate": 0.0, "step": 867}
{"time": 1767081904.1936266, "phase": "train", "update": 868, "total_env_steps": 2777600, "episode_reward": 0.06736599653959274, "value_loss": 0.0031376408878713846, "policy_loss": -0.0024850278049342476, "dist_entropy": 0.8867814779281616, "actor_grad_norm": 0.16811060905456543, "critic_grad_norm": 0.03997885808348656, "ratio": 0.9999540448188782, "entropy": 0.8867814779281616, "incre_win_rate": 0.0, "step": 868}
{"time": 1767081908.3875003, "phase": "train", "update": 869, "total_env_steps": 2780800, "episode_reward": 0.0715055912733078, "value_loss": 0.0023920508567243813, "policy_loss": -0.0019380035810470987, "dist_entropy": 0.9255898118019104, "actor_grad_norm": 0.14547036588191986, "critic_grad_norm": 0.02169632352888584, "ratio": 1.0000923871994019, "entropy": 0.9255898118019104, "incre_win_rate": 0.0, "step": 869}
{"time": 1767081912.6570575, "phase": "train", "update": 870, "total_env_steps": 2784000, "episode_reward": 0.07621274888515472, "value_loss": 0.0022553844843059777, "policy_loss": -0.002573836979578914, "dist_entropy": 0.9087970852851868, "actor_grad_norm": 0.15789596736431122, "critic_grad_norm": 0.0249683428555727, "ratio": 1.000062346458435, "entropy": 0.9087970852851868, "incre_win_rate": 0.0, "step": 870}
{"time": 1767081916.8929348, "phase": "train", "update": 871, "total_env_steps": 2787200, "episode_reward": 0.0733143612742424, "value_loss": 0.0027926403097808363, "policy_loss": -0.0024086884979539038, "dist_entropy": 0.9049480080604553, "actor_grad_norm": 0.18491587042808533, "critic_grad_norm": 0.027606690302491188, "ratio": 0.9997205138206482, "entropy": 0.9049480080604553, "incre_win_rate": 0.0, "step": 871}
{"time": 1767081921.2062848, "phase": "train", "update": 872, "total_env_steps": 2790400, "episode_reward": 0.07236547768115997, "value_loss": 0.002951755095273256, "policy_loss": -0.0017396502330036868, "dist_entropy": 0.8579485058784485, "actor_grad_norm": 0.14716221392154694, "critic_grad_norm": 0.016673795878887177, "ratio": 1.0001870393753052, "entropy": 0.8579485058784485, "incre_win_rate": 0.0, "step": 872}
{"time": 1767081925.4858232, "phase": "train", "update": 873, "total_env_steps": 2793600, "episode_reward": 0.0747428610920906, "value_loss": 0.0019678188022226096, "policy_loss": -0.0022067827111875715, "dist_entropy": 0.855426025390625, "actor_grad_norm": 0.15916769206523895, "critic_grad_norm": 0.016601210460066795, "ratio": 0.9995095133781433, "entropy": 0.855426025390625, "incre_win_rate": 0.0, "step": 873}
{"time": 1767081929.8684487, "phase": "train", "update": 874, "total_env_steps": 2796800, "episode_reward": 0.07447434216737747, "value_loss": 0.00206494783051312, "policy_loss": -0.001760685130771833, "dist_entropy": 0.8296406030654907, "actor_grad_norm": 0.13823555409908295, "critic_grad_norm": 0.010933849960565567, "ratio": 1.0001875162124634, "entropy": 0.8296406030654907, "incre_win_rate": 0.0, "step": 874}
{"time": 1767081934.1853552, "phase": "train", "update": 875, "total_env_steps": 2800000, "episode_reward": 0.07849027216434479, "value_loss": 0.003689449606463313, "policy_loss": -0.00227676115421076, "dist_entropy": 0.799948799610138, "actor_grad_norm": 0.15614400804042816, "critic_grad_norm": 0.017497969791293144, "ratio": 1.0002849102020264, "entropy": 0.799948799610138, "incre_win_rate": 0.0, "step": 875}
{"time": 1767081938.7616065, "phase": "train", "update": 876, "total_env_steps": 2803200, "episode_reward": 0.07537303119897842, "value_loss": 0.004274968802928924, "policy_loss": -0.00235260387509868, "dist_entropy": 0.8093738317489624, "actor_grad_norm": 0.17123690247535706, "critic_grad_norm": 0.03163110092282295, "ratio": 1.000015139579773, "entropy": 0.8093738317489624, "incre_win_rate": 0.0, "step": 876}
{"time": 1767081943.1047478, "phase": "train", "update": 877, "total_env_steps": 2806400, "episode_reward": 0.07221181690692902, "value_loss": 0.0021035501733422278, "policy_loss": -0.0015554736155044325, "dist_entropy": 0.8339575052261352, "actor_grad_norm": 0.1308995932340622, "critic_grad_norm": 0.021882440894842148, "ratio": 0.9999423027038574, "entropy": 0.8339575052261352, "incre_win_rate": 0.0, "step": 877}
{"time": 1767081947.433568, "phase": "train", "update": 878, "total_env_steps": 2809600, "episode_reward": 0.07415304332971573, "value_loss": 0.00278824339620769, "policy_loss": -0.0015344837363954866, "dist_entropy": 0.8172974109649658, "actor_grad_norm": 0.14983855187892914, "critic_grad_norm": 0.03667274862527847, "ratio": 0.999588668346405, "entropy": 0.8172974109649658, "incre_win_rate": 0.0, "step": 878}
{"time": 1767081951.8025749, "phase": "train", "update": 879, "total_env_steps": 2812800, "episode_reward": 0.07766349613666534, "value_loss": 0.0035059247631579636, "policy_loss": -0.001647862968867031, "dist_entropy": 0.7897603034973144, "actor_grad_norm": 0.1339438259601593, "critic_grad_norm": 0.050359901040792465, "ratio": 1.000104546546936, "entropy": 0.7897603034973144, "incre_win_rate": 0.0, "step": 879}
{"time": 1767081956.1167886, "phase": "train", "update": 880, "total_env_steps": 2816000, "episode_reward": 0.07580763846635818, "value_loss": 0.004724176041781903, "policy_loss": -0.0021220465743759576, "dist_entropy": 0.7607404112815856, "actor_grad_norm": 0.16344375908374786, "critic_grad_norm": 0.048016831278800964, "ratio": 0.9999276399612427, "entropy": 0.7607404112815856, "incre_win_rate": 0.0, "step": 880}
{"time": 1767081960.5187573, "phase": "train", "update": 881, "total_env_steps": 2819200, "episode_reward": 0.07337179034948349, "value_loss": 0.002824601484462619, "policy_loss": -0.0011098128453394195, "dist_entropy": 0.7725323677062989, "actor_grad_norm": 0.11496775597333908, "critic_grad_norm": 0.03455967456102371, "ratio": 1.0001450777053833, "entropy": 0.7725323677062989, "incre_win_rate": 0.0, "step": 881}
{"time": 1767081978.53722, "phase": "eval", "update": 881, "total_env_steps": 2819200, "eval_win_rate": 0.0, "eval_episode_reward": 10.753000827814562, "step": 881}
{"time": 1767081982.916321, "phase": "train", "update": 882, "total_env_steps": 2822400, "episode_reward": 0.0792306512594223, "value_loss": 0.003289121901616454, "policy_loss": -0.0024460146902740123, "dist_entropy": 0.7783649444580079, "actor_grad_norm": 0.1441241055727005, "critic_grad_norm": 0.020035194233059883, "ratio": 1.0001026391983032, "entropy": 0.7783649444580079, "incre_win_rate": 0.0, "step": 882}
{"time": 1767081987.241505, "phase": "train", "update": 883, "total_env_steps": 2825600, "episode_reward": 0.07566381245851517, "value_loss": 0.0032059061340987682, "policy_loss": -0.001412558930621799, "dist_entropy": 0.7550695776939392, "actor_grad_norm": 0.12163304537534714, "critic_grad_norm": 0.012354017235338688, "ratio": 0.9998713731765747, "entropy": 0.7550695776939392, "incre_win_rate": 0.0, "step": 883}
{"time": 1767081991.6484125, "phase": "train", "update": 884, "total_env_steps": 2828800, "episode_reward": 0.08040149509906769, "value_loss": 0.0029828289523720743, "policy_loss": -0.0022016755035407344, "dist_entropy": 0.7182832479476928, "actor_grad_norm": 0.14581327140331268, "critic_grad_norm": 0.05350413918495178, "ratio": 0.9999448657035828, "entropy": 0.7182832479476928, "incre_win_rate": 0.0, "step": 884}
{"time": 1767081995.9295342, "phase": "train", "update": 885, "total_env_steps": 2832000, "episode_reward": 0.07715386897325516, "value_loss": 0.003783079609274864, "policy_loss": -0.00189514200721419, "dist_entropy": 0.7421934485435486, "actor_grad_norm": 0.17439179122447968, "critic_grad_norm": 0.031547240912914276, "ratio": 1.0000311136245728, "entropy": 0.7421934485435486, "incre_win_rate": 0.0, "step": 885}
{"time": 1767082000.2189045, "phase": "train", "update": 886, "total_env_steps": 2835200, "episode_reward": 0.08055101335048676, "value_loss": 0.003365963324904442, "policy_loss": -0.00225743280459767, "dist_entropy": 0.7406040668487549, "actor_grad_norm": 0.158914715051651, "critic_grad_norm": 0.01522765588015318, "ratio": 1.0000263452529907, "entropy": 0.7406040668487549, "incre_win_rate": 0.0, "step": 886}
{"time": 1767082004.4540226, "phase": "train", "update": 887, "total_env_steps": 2838400, "episode_reward": 0.07639434933662415, "value_loss": 0.004070199932903052, "policy_loss": -0.0022056009184602487, "dist_entropy": 0.7463571548461914, "actor_grad_norm": 0.13224823772907257, "critic_grad_norm": 0.07040654867887497, "ratio": 0.9997659921646118, "entropy": 0.7463571548461914, "incre_win_rate": 0.0, "step": 887}
{"time": 1767082008.714758, "phase": "train", "update": 888, "total_env_steps": 2841600, "episode_reward": 0.0783873125910759, "value_loss": 0.002867974620312452, "policy_loss": -0.0019004894613885881, "dist_entropy": 0.7737006425857544, "actor_grad_norm": 0.13454274833202362, "critic_grad_norm": 0.03127823397517204, "ratio": 0.9999675154685974, "entropy": 0.7737006425857544, "incre_win_rate": 0.0, "step": 888}
{"time": 1767082013.1205592, "phase": "train", "update": 889, "total_env_steps": 2844800, "episode_reward": 0.08316224813461304, "value_loss": 0.0032631823793053626, "policy_loss": -0.001780858620726633, "dist_entropy": 0.7079230904579162, "actor_grad_norm": 0.13218553364276886, "critic_grad_norm": 0.027663415297865868, "ratio": 1.000063419342041, "entropy": 0.7079230904579162, "incre_win_rate": 0.0, "step": 889}
{"time": 1767082017.455381, "phase": "train", "update": 890, "total_env_steps": 2848000, "episode_reward": 0.08227493613958359, "value_loss": 0.003020897414535284, "policy_loss": -0.0020273241843099753, "dist_entropy": 0.7451158881187439, "actor_grad_norm": 0.16788426041603088, "critic_grad_norm": 0.021109284833073616, "ratio": 1.0003118515014648, "entropy": 0.7451158881187439, "incre_win_rate": 0.0, "step": 890}
{"time": 1767082021.683006, "phase": "train", "update": 891, "total_env_steps": 2851200, "episode_reward": 0.08015003800392151, "value_loss": 0.004004221688956022, "policy_loss": -0.0013704509707167744, "dist_entropy": 0.7727662205696106, "actor_grad_norm": 0.15496811270713806, "critic_grad_norm": 0.04467920586466789, "ratio": 1.0001881122589111, "entropy": 0.7727662205696106, "incre_win_rate": 0.0, "step": 891}
{"time": 1767082025.9166574, "phase": "train", "update": 892, "total_env_steps": 2854400, "episode_reward": 0.07706799358129501, "value_loss": 0.003689537150785327, "policy_loss": -0.0025305719975875717, "dist_entropy": 0.775617527961731, "actor_grad_norm": 0.17920123040676117, "critic_grad_norm": 0.0741305872797966, "ratio": 0.9998249411582947, "entropy": 0.775617527961731, "incre_win_rate": 0.0, "step": 892}
{"time": 1767082030.2941582, "phase": "train", "update": 893, "total_env_steps": 2857600, "episode_reward": 0.08865635097026825, "value_loss": 0.0047126651741564276, "policy_loss": -0.001279296715529199, "dist_entropy": 0.7158676862716675, "actor_grad_norm": 0.14952856302261353, "critic_grad_norm": 0.05476563796401024, "ratio": 0.9999057054519653, "entropy": 0.7158676862716675, "incre_win_rate": 0.0, "step": 893}
{"time": 1767082034.505257, "phase": "train", "update": 894, "total_env_steps": 2860800, "episode_reward": 0.0744732990860939, "value_loss": 0.003275471646338701, "policy_loss": -0.001961031020314863, "dist_entropy": 0.7759045958518982, "actor_grad_norm": 0.1429479867219925, "critic_grad_norm": 0.018946915864944458, "ratio": 1.0001343488693237, "entropy": 0.7759045958518982, "incre_win_rate": 0.0, "step": 894}
{"time": 1767082038.757982, "phase": "train", "update": 895, "total_env_steps": 2864000, "episode_reward": 0.07100993394851685, "value_loss": 0.003073912439867854, "policy_loss": -0.002115343147717752, "dist_entropy": 0.8015544056892395, "actor_grad_norm": 0.16169844567775726, "critic_grad_norm": 0.02657863311469555, "ratio": 0.99988853931427, "entropy": 0.8015544056892395, "incre_win_rate": 0.0, "step": 895}
{"time": 1767082043.2454212, "phase": "train", "update": 896, "total_env_steps": 2867200, "episode_reward": 0.07985720038414001, "value_loss": 0.003725144034251571, "policy_loss": -0.0017913631834204579, "dist_entropy": 0.748094642162323, "actor_grad_norm": 0.15359048545360565, "critic_grad_norm": 0.01608453132212162, "ratio": 1.0000447034835815, "entropy": 0.748094642162323, "incre_win_rate": 0.0, "step": 896}
{"time": 1767082047.599376, "phase": "train", "update": 897, "total_env_steps": 2870400, "episode_reward": 0.08113255351781845, "value_loss": 0.002904248656705022, "policy_loss": -0.0024288391963281698, "dist_entropy": 0.7605036616325378, "actor_grad_norm": 0.1515853852033615, "critic_grad_norm": 0.010590612888336182, "ratio": 0.9997604489326477, "entropy": 0.7605036616325378, "incre_win_rate": 0.0, "step": 897}
{"time": 1767082051.7821698, "phase": "train", "update": 898, "total_env_steps": 2873600, "episode_reward": 0.07377742230892181, "value_loss": 0.002165362052619457, "policy_loss": -0.002131682476215957, "dist_entropy": 0.8358114123344421, "actor_grad_norm": 0.17176271975040436, "critic_grad_norm": 0.03862087428569794, "ratio": 0.9994417428970337, "entropy": 0.8358114123344421, "incre_win_rate": 0.0, "step": 898}
{"time": 1767082056.0180418, "phase": "train", "update": 899, "total_env_steps": 2876800, "episode_reward": 0.08378570526838303, "value_loss": 0.004318131972104311, "policy_loss": -0.0013165229849917636, "dist_entropy": 0.7882799744606018, "actor_grad_norm": 0.11140467971563339, "critic_grad_norm": 0.026146382093429565, "ratio": 0.9998685717582703, "entropy": 0.7882799744606018, "incre_win_rate": 0.0, "step": 899}
{"time": 1767082060.3584883, "phase": "train", "update": 900, "total_env_steps": 2880000, "episode_reward": 0.07896160334348679, "value_loss": 0.002463329629972577, "policy_loss": -0.0027619853674842433, "dist_entropy": 0.7969778180122375, "actor_grad_norm": 0.20119820535182953, "critic_grad_norm": 0.04057447612285614, "ratio": 0.9999481439590454, "entropy": 0.7969778180122375, "incre_win_rate": 0.0, "step": 900}
{"time": 1767082064.6917315, "phase": "train", "update": 901, "total_env_steps": 2883200, "episode_reward": 0.07697796076536179, "value_loss": 0.00398222184740007, "policy_loss": -0.0022673059196288035, "dist_entropy": 0.801514494419098, "actor_grad_norm": 0.13447369635105133, "critic_grad_norm": 0.03410032019019127, "ratio": 1.0000861883163452, "entropy": 0.801514494419098, "incre_win_rate": 0.0, "step": 901}
{"time": 1767082083.4465363, "phase": "eval", "update": 901, "total_env_steps": 2883200, "eval_win_rate": 0.0, "eval_episode_reward": 11.352804221854303, "step": 901}
{"time": 1767082087.7819793, "phase": "train", "update": 902, "total_env_steps": 2886400, "episode_reward": 0.08431137353181839, "value_loss": 0.003740578377619386, "policy_loss": -0.0021088159755436207, "dist_entropy": 0.7789818406105041, "actor_grad_norm": 0.1626448780298233, "critic_grad_norm": 0.044356267899274826, "ratio": 0.9999248385429382, "entropy": 0.7789818406105041, "incre_win_rate": 0.0, "step": 902}
{"time": 1767082092.110065, "phase": "train", "update": 903, "total_env_steps": 2889600, "episode_reward": 0.07632657885551453, "value_loss": 0.002177613228559494, "policy_loss": -0.0017829247090293877, "dist_entropy": 0.8272012233734131, "actor_grad_norm": 0.16290274262428284, "critic_grad_norm": 0.019627436995506287, "ratio": 0.9997686743736267, "entropy": 0.8272012233734131, "incre_win_rate": 0.0, "step": 903}
{"time": 1767082096.4350712, "phase": "train", "update": 904, "total_env_steps": 2892800, "episode_reward": 0.084987573325634, "value_loss": 0.0035804114304482937, "policy_loss": -0.0012148999492808342, "dist_entropy": 0.7851242542266845, "actor_grad_norm": 0.13590654730796814, "critic_grad_norm": 0.0435112826526165, "ratio": 1.0000015497207642, "entropy": 0.7851242542266845, "incre_win_rate": 0.0, "step": 904}
{"time": 1767082100.771448, "phase": "train", "update": 905, "total_env_steps": 2896000, "episode_reward": 0.08092301338911057, "value_loss": 0.0031670655589550734, "policy_loss": -0.0018978022680975926, "dist_entropy": 0.7751547932624817, "actor_grad_norm": 0.16254018247127533, "critic_grad_norm": 0.02389569766819477, "ratio": 1.0001699924468994, "entropy": 0.7751547932624817, "incre_win_rate": 0.0, "step": 905}
{"time": 1767082105.1323626, "phase": "train", "update": 906, "total_env_steps": 2899200, "episode_reward": 0.08464299887418747, "value_loss": 0.0029261409770697357, "policy_loss": -0.0018024739470405393, "dist_entropy": 0.7674030542373658, "actor_grad_norm": 0.18719391524791718, "critic_grad_norm": 0.014710399322211742, "ratio": 0.9998842477798462, "entropy": 0.7674030542373658, "incre_win_rate": 0.0, "step": 906}
{"time": 1767082109.505715, "phase": "train", "update": 907, "total_env_steps": 2902400, "episode_reward": 0.0799906849861145, "value_loss": 0.003478132374584675, "policy_loss": -0.0015445967376727765, "dist_entropy": 0.7509832143783569, "actor_grad_norm": 0.164124995470047, "critic_grad_norm": 0.048955902457237244, "ratio": 0.9998480677604675, "entropy": 0.7509832143783569, "incre_win_rate": 0.0, "step": 907}
{"time": 1767082113.891764, "phase": "train", "update": 908, "total_env_steps": 2905600, "episode_reward": 0.08331074565649033, "value_loss": 0.004050504229962826, "policy_loss": -0.001485134684466516, "dist_entropy": 0.7803566932678223, "actor_grad_norm": 0.16769163310527802, "critic_grad_norm": 0.036550238728523254, "ratio": 0.9997690320014954, "entropy": 0.7803566932678223, "incre_win_rate": 0.0, "step": 908}
{"time": 1767082118.1117501, "phase": "train", "update": 909, "total_env_steps": 2908800, "episode_reward": 0.07617601752281189, "value_loss": 0.0029940757900476455, "policy_loss": -0.0018344177478568202, "dist_entropy": 0.816815185546875, "actor_grad_norm": 0.1454005241394043, "critic_grad_norm": 0.029542014002799988, "ratio": 0.9996053576469421, "entropy": 0.816815185546875, "incre_win_rate": 0.0, "step": 909}
{"time": 1767082122.4272583, "phase": "train", "update": 910, "total_env_steps": 2912000, "episode_reward": 0.07721957564353943, "value_loss": 0.0035567347425967456, "policy_loss": -0.001597314332162192, "dist_entropy": 0.7946473956108093, "actor_grad_norm": 0.13283061981201172, "critic_grad_norm": 0.027879217639565468, "ratio": 1.0002027750015259, "entropy": 0.7946473956108093, "incre_win_rate": 0.0, "step": 910}
{"time": 1767082126.6926749, "phase": "train", "update": 911, "total_env_steps": 2915200, "episode_reward": 0.08859219402074814, "value_loss": 0.00407635853625834, "policy_loss": -0.0019459311979737493, "dist_entropy": 0.7874675154685974, "actor_grad_norm": 0.14556920528411865, "critic_grad_norm": 0.03898605331778526, "ratio": 1.000045657157898, "entropy": 0.7874675154685974, "incre_win_rate": 0.0, "step": 911}
{"time": 1767082131.039698, "phase": "train", "update": 912, "total_env_steps": 2918400, "episode_reward": 0.08868015557527542, "value_loss": 0.004358152579516173, "policy_loss": -0.0016149879212576934, "dist_entropy": 0.8278526902198792, "actor_grad_norm": 0.11083456128835678, "critic_grad_norm": 0.06468500196933746, "ratio": 1.0000019073486328, "entropy": 0.8278526902198792, "incre_win_rate": 0.0, "step": 912}
{"time": 1767082135.4338593, "phase": "train", "update": 913, "total_env_steps": 2921600, "episode_reward": 0.08255225419998169, "value_loss": 0.004627899918705225, "policy_loss": -0.0016972807365661425, "dist_entropy": 0.822284483909607, "actor_grad_norm": 0.12292055040597916, "critic_grad_norm": 0.07458584755659103, "ratio": 0.9995867609977722, "entropy": 0.822284483909607, "incre_win_rate": 0.0, "step": 913}
{"time": 1767082139.6954918, "phase": "train", "update": 914, "total_env_steps": 2924800, "episode_reward": 0.07472372055053711, "value_loss": 0.004853069689124823, "policy_loss": -0.0024145159649620494, "dist_entropy": 0.8604674220085144, "actor_grad_norm": 0.14276504516601562, "critic_grad_norm": 0.05498737096786499, "ratio": 0.9998214840888977, "entropy": 0.8604674220085144, "incre_win_rate": 0.0, "step": 914}
{"time": 1767082144.0620348, "phase": "train", "update": 915, "total_env_steps": 2928000, "episode_reward": 0.08282337337732315, "value_loss": 0.0036717491690069436, "policy_loss": -0.002756723073953893, "dist_entropy": 0.8082491755485535, "actor_grad_norm": 0.1877012997865677, "critic_grad_norm": 0.016928737983107567, "ratio": 0.9997782707214355, "entropy": 0.8082491755485535, "incre_win_rate": 0.0, "step": 915}
{"time": 1767082148.3612483, "phase": "train", "update": 916, "total_env_steps": 2931200, "episode_reward": 0.08207523077726364, "value_loss": 0.0033057764638215305, "policy_loss": -0.0020337241346403802, "dist_entropy": 0.760123360157013, "actor_grad_norm": 0.13480554521083832, "critic_grad_norm": 0.017576316371560097, "ratio": 0.9998754858970642, "entropy": 0.760123360157013, "incre_win_rate": 0.0, "step": 916}
{"time": 1767082154.2570596, "phase": "train", "update": 917, "total_env_steps": 2934400, "episode_reward": 0.0806255117058754, "value_loss": 0.0038081019185483454, "policy_loss": -0.002526475655846028, "dist_entropy": 0.7503748655319213, "actor_grad_norm": 0.1573266237974167, "critic_grad_norm": 0.03687627613544464, "ratio": 1.0001534223556519, "entropy": 0.7503748655319213, "incre_win_rate": 0.0, "step": 917}
{"time": 1767082159.1699982, "phase": "train", "update": 918, "total_env_steps": 2937600, "episode_reward": 0.0781477615237236, "value_loss": 0.0034260861575603485, "policy_loss": -0.001528560262568135, "dist_entropy": 0.7598799586296081, "actor_grad_norm": 0.1589810699224472, "critic_grad_norm": 0.018218979239463806, "ratio": 1.000118613243103, "entropy": 0.7598799586296081, "incre_win_rate": 0.0, "step": 918}
{"time": 1767082163.801288, "phase": "train", "update": 919, "total_env_steps": 2940800, "episode_reward": 0.08182740211486816, "value_loss": 0.0044316243380308155, "policy_loss": -0.002066605029470736, "dist_entropy": 0.7198375344276429, "actor_grad_norm": 0.14591413736343384, "critic_grad_norm": 0.04595739021897316, "ratio": 0.9998273253440857, "entropy": 0.7198375344276429, "incre_win_rate": 0.0, "step": 919}
{"time": 1767082168.2023463, "phase": "train", "update": 920, "total_env_steps": 2944000, "episode_reward": 0.08080866932868958, "value_loss": 0.0047850913368165495, "policy_loss": -0.0018124644195466999, "dist_entropy": 0.7208239674568176, "actor_grad_norm": 0.14424733817577362, "critic_grad_norm": 0.05667189881205559, "ratio": 1.0001286268234253, "entropy": 0.7208239674568176, "incre_win_rate": 0.0, "step": 920}
{"time": 1767082172.6002748, "phase": "train", "update": 921, "total_env_steps": 2947200, "episode_reward": 0.07344629615545273, "value_loss": 0.004365394916385412, "policy_loss": -0.0019829164612843895, "dist_entropy": 0.7807629227638244, "actor_grad_norm": 0.1513189673423767, "critic_grad_norm": 0.023022567853331566, "ratio": 1.0000414848327637, "entropy": 0.7807629227638244, "incre_win_rate": 0.0, "step": 921}
{"time": 1767082191.0346467, "phase": "eval", "update": 921, "total_env_steps": 2947200, "eval_win_rate": 0.0, "eval_episode_reward": 10.932377897350978, "step": 921}
{"time": 1767082195.739206, "phase": "train", "update": 922, "total_env_steps": 2950400, "episode_reward": 0.08018315583467484, "value_loss": 0.0039528313558548685, "policy_loss": -0.002399079071106769, "dist_entropy": 0.7401392102241516, "actor_grad_norm": 0.17614801228046417, "critic_grad_norm": 0.04248589277267456, "ratio": 0.9996722340583801, "entropy": 0.7401392102241516, "incre_win_rate": 0.0, "step": 922}
{"time": 1767082200.0717676, "phase": "train", "update": 923, "total_env_steps": 2953600, "episode_reward": 0.08377432078123093, "value_loss": 0.0048136417753994465, "policy_loss": -0.0019681619660477877, "dist_entropy": 0.7249478220939636, "actor_grad_norm": 0.1697276085615158, "critic_grad_norm": 0.035449739545583725, "ratio": 1.0000113248825073, "entropy": 0.7249478220939636, "incre_win_rate": 0.0, "step": 923}
{"time": 1767082204.2380643, "phase": "train", "update": 924, "total_env_steps": 2956800, "episode_reward": 0.06832471489906311, "value_loss": 0.0026748885400593283, "policy_loss": -0.0017510777630228348, "dist_entropy": 0.7822412133216858, "actor_grad_norm": 0.1295168250799179, "critic_grad_norm": 0.030345115810632706, "ratio": 0.9999805688858032, "entropy": 0.7822412133216858, "incre_win_rate": 0.0, "step": 924}
{"time": 1767082208.8139806, "phase": "train", "update": 925, "total_env_steps": 2960000, "episode_reward": 0.08033837378025055, "value_loss": 0.004053428303450346, "policy_loss": -0.002333230206370729, "dist_entropy": 0.7007927894592285, "actor_grad_norm": 0.14439405500888824, "critic_grad_norm": 0.043359171599149704, "ratio": 0.9999813437461853, "entropy": 0.7007927894592285, "incre_win_rate": 0.0, "step": 925}
{"time": 1767082213.2785559, "phase": "train", "update": 926, "total_env_steps": 2963200, "episode_reward": 0.0773044303059578, "value_loss": 0.003015353111550212, "policy_loss": -0.0021513809642044633, "dist_entropy": 0.7196704626083374, "actor_grad_norm": 0.13329768180847168, "critic_grad_norm": 0.013161000795662403, "ratio": 0.9999578595161438, "entropy": 0.7196704626083374, "incre_win_rate": 0.0, "step": 926}
{"time": 1767082217.6832397, "phase": "train", "update": 927, "total_env_steps": 2966400, "episode_reward": 0.07511278986930847, "value_loss": 0.0038253855891525745, "policy_loss": -0.001580122713670562, "dist_entropy": 0.7067834496498108, "actor_grad_norm": 0.12727725505828857, "critic_grad_norm": 0.023320425301790237, "ratio": 0.9996570944786072, "entropy": 0.7067834496498108, "incre_win_rate": 0.0, "step": 927}
{"time": 1767082222.0172327, "phase": "train", "update": 928, "total_env_steps": 2969600, "episode_reward": 0.08117136359214783, "value_loss": 0.0033274613786488773, "policy_loss": -0.001738544488233984, "dist_entropy": 0.6754735946655274, "actor_grad_norm": 0.1798725575208664, "critic_grad_norm": 0.031153280287981033, "ratio": 0.9998866319656372, "entropy": 0.6754735946655274, "incre_win_rate": 0.0, "step": 928}
{"time": 1767082226.5300677, "phase": "train", "update": 929, "total_env_steps": 2972800, "episode_reward": 0.08021213859319687, "value_loss": 0.00448437612503767, "policy_loss": -0.002032347201389939, "dist_entropy": 0.6834640026092529, "actor_grad_norm": 0.1566346436738968, "critic_grad_norm": 0.06836269050836563, "ratio": 1.0002714395523071, "entropy": 0.6834640026092529, "incre_win_rate": 0.0, "step": 929}
{"time": 1767082230.9517326, "phase": "train", "update": 930, "total_env_steps": 2976000, "episode_reward": 0.08083248138427734, "value_loss": 0.0045985933393239975, "policy_loss": -0.002066280014912536, "dist_entropy": 0.6720707893371582, "actor_grad_norm": 0.17788033187389374, "critic_grad_norm": 0.09157946705818176, "ratio": 1.0000766515731812, "entropy": 0.6720707893371582, "incre_win_rate": 0.0, "step": 930}
{"time": 1767082235.3420727, "phase": "train", "update": 931, "total_env_steps": 2979200, "episode_reward": 0.07914269715547562, "value_loss": 0.005240516737103462, "policy_loss": -0.0019918389459107288, "dist_entropy": 0.6876925230026245, "actor_grad_norm": 0.12246084213256836, "critic_grad_norm": 0.07369303703308105, "ratio": 0.9998503923416138, "entropy": 0.6876925230026245, "incre_win_rate": 0.0, "step": 931}
{"time": 1767082239.7029884, "phase": "train", "update": 932, "total_env_steps": 2982400, "episode_reward": 0.07131467014551163, "value_loss": 0.0034182189963757994, "policy_loss": -0.0020096787331112865, "dist_entropy": 0.6932086229324341, "actor_grad_norm": 0.17144252359867096, "critic_grad_norm": 0.028152242302894592, "ratio": 0.9999875426292419, "entropy": 0.6932086229324341, "incre_win_rate": 0.0, "step": 932}
{"time": 1767082244.1333773, "phase": "train", "update": 933, "total_env_steps": 2985600, "episode_reward": 0.07709488272666931, "value_loss": 0.002684855880215764, "policy_loss": -0.002346793720490581, "dist_entropy": 0.7298699378967285, "actor_grad_norm": 0.16932472586631775, "critic_grad_norm": 0.04184659197926521, "ratio": 1.0005580186843872, "entropy": 0.7298699378967285, "incre_win_rate": 0.0, "step": 933}
{"time": 1767082248.4683573, "phase": "train", "update": 934, "total_env_steps": 2988800, "episode_reward": 0.07395333051681519, "value_loss": 0.0023197961039841176, "policy_loss": -0.001984018670974308, "dist_entropy": 0.7401626110076904, "actor_grad_norm": 0.13193866610527039, "critic_grad_norm": 0.035601090639829636, "ratio": 1.0001108646392822, "entropy": 0.7401626110076904, "incre_win_rate": 0.0, "step": 934}
{"time": 1767082252.9232793, "phase": "train", "update": 935, "total_env_steps": 2992000, "episode_reward": 0.07361962646245956, "value_loss": 0.0029016468208283184, "policy_loss": -0.00196027089331281, "dist_entropy": 0.7428715705871582, "actor_grad_norm": 0.14994724094867706, "critic_grad_norm": 0.04803070053458214, "ratio": 1.000054955482483, "entropy": 0.7428715705871582, "incre_win_rate": 0.0, "step": 935}
{"time": 1767082257.2709844, "phase": "train", "update": 936, "total_env_steps": 2995200, "episode_reward": 0.07903662323951721, "value_loss": 0.0025070729665458203, "policy_loss": -0.0019541399372073444, "dist_entropy": 0.74918452501297, "actor_grad_norm": 0.16038742661476135, "critic_grad_norm": 0.046919602900743484, "ratio": 1.0000308752059937, "entropy": 0.74918452501297, "incre_win_rate": 0.0, "step": 936}
{"time": 1767082261.6869211, "phase": "train", "update": 937, "total_env_steps": 2998400, "episode_reward": 0.08016970753669739, "value_loss": 0.0040795630775392056, "policy_loss": -0.0018374241296058359, "dist_entropy": 0.7047662615776062, "actor_grad_norm": 0.19853469729423523, "critic_grad_norm": 0.050142645835876465, "ratio": 1.0000813007354736, "entropy": 0.7047662615776062, "incre_win_rate": 0.0, "step": 937}
{"time": 1767082266.1213565, "phase": "train", "update": 938, "total_env_steps": 3001600, "episode_reward": 0.0749063566327095, "value_loss": 0.003687654482200742, "policy_loss": -0.0013815416695727833, "dist_entropy": 0.7294007658958435, "actor_grad_norm": 0.15830548107624054, "critic_grad_norm": 0.07191137224435806, "ratio": 0.9999950528144836, "entropy": 0.7294007658958435, "incre_win_rate": 0.0, "step": 938}
{"time": 1767082270.451519, "phase": "train", "update": 939, "total_env_steps": 3004800, "episode_reward": 0.07644350081682205, "value_loss": 0.00221629049628973, "policy_loss": -0.0016874734084511012, "dist_entropy": 0.7597578406333924, "actor_grad_norm": 0.19045118987560272, "critic_grad_norm": 0.03187015652656555, "ratio": 1.0000262260437012, "entropy": 0.7597578406333924, "incre_win_rate": 0.0, "step": 939}
{"time": 1767082274.8101258, "phase": "train", "update": 940, "total_env_steps": 3008000, "episode_reward": 0.0793599933385849, "value_loss": 0.002989414846524596, "policy_loss": -0.0015351280230177621, "dist_entropy": 0.7546173453330993, "actor_grad_norm": 0.1672508716583252, "critic_grad_norm": 0.02763635478913784, "ratio": 0.9997314810752869, "entropy": 0.7546173453330993, "incre_win_rate": 0.0, "step": 940}
{"time": 1767082279.0387075, "phase": "train", "update": 941, "total_env_steps": 3011200, "episode_reward": 0.07310792803764343, "value_loss": 0.0031710946932435036, "policy_loss": -0.0021494687005305215, "dist_entropy": 0.8029048085212708, "actor_grad_norm": 0.18150989711284637, "critic_grad_norm": 0.023530689999461174, "ratio": 1.0003886222839355, "entropy": 0.8029048085212708, "incre_win_rate": 0.0, "step": 941}
{"time": 1767082297.7865226, "phase": "eval", "update": 941, "total_env_steps": 3011200, "eval_win_rate": 0.0, "eval_episode_reward": 11.26019246688741, "step": 941}
{"time": 1767082302.0774999, "phase": "train", "update": 942, "total_env_steps": 3014400, "episode_reward": 0.07608598470687866, "value_loss": 0.003457682067528367, "policy_loss": -0.0019735114836421986, "dist_entropy": 0.7820636510849, "actor_grad_norm": 0.1599886417388916, "critic_grad_norm": 0.06955041736364365, "ratio": 1.0002074241638184, "entropy": 0.7820636510849, "incre_win_rate": 0.0, "step": 942}
{"time": 1767082306.5663013, "phase": "train", "update": 943, "total_env_steps": 3017600, "episode_reward": 0.08628621697425842, "value_loss": 0.004822566173970699, "policy_loss": -0.0018509514689284857, "dist_entropy": 0.7355220675468445, "actor_grad_norm": 0.13556236028671265, "critic_grad_norm": 0.06680529564619064, "ratio": 0.9997650980949402, "entropy": 0.7355220675468445, "incre_win_rate": 0.0, "step": 943}
{"time": 1767082310.9171827, "phase": "train", "update": 944, "total_env_steps": 3020800, "episode_reward": 0.07419236749410629, "value_loss": 0.0029186430387198926, "policy_loss": -0.0019371001243627007, "dist_entropy": 0.7859626650810242, "actor_grad_norm": 0.1347518414258957, "critic_grad_norm": 0.03918370231986046, "ratio": 0.999768078327179, "entropy": 0.7859626650810242, "incre_win_rate": 0.0, "step": 944}
{"time": 1767082315.3321762, "phase": "train", "update": 945, "total_env_steps": 3024000, "episode_reward": 0.08209075033664703, "value_loss": 0.0040145769715309145, "policy_loss": -0.0029887872686664707, "dist_entropy": 0.7441087603569031, "actor_grad_norm": 0.14563676714897156, "critic_grad_norm": 0.024474970996379852, "ratio": 1.0002163648605347, "entropy": 0.7441087603569031, "incre_win_rate": 0.0, "step": 945}
{"time": 1767082319.818609, "phase": "train", "update": 946, "total_env_steps": 3027200, "episode_reward": 0.08627690374851227, "value_loss": 0.003324431087821722, "policy_loss": -0.0020218017280221544, "dist_entropy": 0.7166396856307984, "actor_grad_norm": 0.15132836997509003, "critic_grad_norm": 0.03836307302117348, "ratio": 0.9997779726982117, "entropy": 0.7166396856307984, "incre_win_rate": 0.0, "step": 946}
{"time": 1767082324.1867118, "phase": "train", "update": 947, "total_env_steps": 3030400, "episode_reward": 0.07519195228815079, "value_loss": 0.002326419949531555, "policy_loss": -0.002663707379402069, "dist_entropy": 0.793122935295105, "actor_grad_norm": 0.16115687787532806, "critic_grad_norm": 0.035218603909015656, "ratio": 0.9999969601631165, "entropy": 0.793122935295105, "incre_win_rate": 0.0, "step": 947}
{"time": 1767082328.4786718, "phase": "train", "update": 948, "total_env_steps": 3033600, "episode_reward": 0.07766349613666534, "value_loss": 0.0021896746940910814, "policy_loss": -0.001897369561568496, "dist_entropy": 0.7506931066513062, "actor_grad_norm": 0.15191149711608887, "critic_grad_norm": 0.024048155173659325, "ratio": 0.9992181062698364, "entropy": 0.7506931066513062, "incre_win_rate": 0.0, "step": 948}
{"time": 1767082332.889258, "phase": "train", "update": 949, "total_env_steps": 3036800, "episode_reward": 0.08069071173667908, "value_loss": 0.006667634937912226, "policy_loss": -0.0014572815024365582, "dist_entropy": 0.7001574397087097, "actor_grad_norm": 0.14115796983242035, "critic_grad_norm": 0.10258185118436813, "ratio": 0.9999722838401794, "entropy": 0.7001574397087097, "incre_win_rate": 0.0, "step": 949}
{"time": 1767082337.2594018, "phase": "train", "update": 950, "total_env_steps": 3040000, "episode_reward": 0.07718439400196075, "value_loss": 0.002384347515180707, "policy_loss": -0.0019332371070049704, "dist_entropy": 0.7579510450363159, "actor_grad_norm": 0.13315938413143158, "critic_grad_norm": 0.04963092505931854, "ratio": 0.9999783635139465, "entropy": 0.7579510450363159, "incre_win_rate": 0.0, "step": 950}
{"time": 1767082341.5558817, "phase": "train", "update": 951, "total_env_steps": 3043200, "episode_reward": 0.0773877277970314, "value_loss": 0.0037305084988474846, "policy_loss": -0.001322002776454312, "dist_entropy": 0.7661185026168823, "actor_grad_norm": 0.14112772047519684, "critic_grad_norm": 0.04712110385298729, "ratio": 0.9997720718383789, "entropy": 0.7661185026168823, "incre_win_rate": 0.0, "step": 951}
{"time": 1767082346.0694501, "phase": "train", "update": 952, "total_env_steps": 3046400, "episode_reward": 0.08101769536733627, "value_loss": 0.0045609381049871445, "policy_loss": -0.0016837460520861213, "dist_entropy": 0.7393264532089233, "actor_grad_norm": 0.12865278124809265, "critic_grad_norm": 0.06103786453604698, "ratio": 1.0000910758972168, "entropy": 0.7393264532089233, "incre_win_rate": 0.0, "step": 952}
{"time": 1767082350.4122791, "phase": "train", "update": 953, "total_env_steps": 3049600, "episode_reward": 0.0835777223110199, "value_loss": 0.0032385965343564747, "policy_loss": -0.0023881408583885876, "dist_entropy": 0.7494305849075318, "actor_grad_norm": 0.1497403234243393, "critic_grad_norm": 0.026471255347132683, "ratio": 0.9998875856399536, "entropy": 0.7494305849075318, "incre_win_rate": 0.0, "step": 953}
{"time": 1767082354.7921956, "phase": "train", "update": 954, "total_env_steps": 3052800, "episode_reward": 0.0890304297208786, "value_loss": 0.007826533541083336, "policy_loss": -0.0016544612176401686, "dist_entropy": 0.7179458260536193, "actor_grad_norm": 0.12220795452594757, "critic_grad_norm": 0.045064907521009445, "ratio": 1.0002816915512085, "entropy": 0.7179458260536193, "incre_win_rate": 0.041666666666666664, "step": 954}
{"time": 1767082359.1354623, "phase": "train", "update": 955, "total_env_steps": 3056000, "episode_reward": 0.07897505909204483, "value_loss": 0.0036186321638524534, "policy_loss": -0.0016821380154567577, "dist_entropy": 0.7420228242874145, "actor_grad_norm": 0.13768231868743896, "critic_grad_norm": 0.026455817744135857, "ratio": 1.0001087188720703, "entropy": 0.7420228242874145, "incre_win_rate": 0.0, "step": 955}
{"time": 1767082363.485635, "phase": "train", "update": 956, "total_env_steps": 3059200, "episode_reward": 0.0746026560664177, "value_loss": 0.0029054562095552684, "policy_loss": -0.0019651167810501137, "dist_entropy": 0.7482210636138916, "actor_grad_norm": 0.142507404088974, "critic_grad_norm": 0.0621357224881649, "ratio": 0.999993622303009, "entropy": 0.7482210636138916, "incre_win_rate": 0.0, "step": 956}
{"time": 1767082367.9196274, "phase": "train", "update": 957, "total_env_steps": 3062400, "episode_reward": 0.09100992977619171, "value_loss": 0.00578377190977335, "policy_loss": -0.0020686105409424725, "dist_entropy": 0.6817281484603882, "actor_grad_norm": 0.13073132932186127, "critic_grad_norm": 0.07695339620113373, "ratio": 1.0000227689743042, "entropy": 0.6817281484603882, "incre_win_rate": 0.0, "step": 957}
{"time": 1767082372.2471006, "phase": "train", "update": 958, "total_env_steps": 3065600, "episode_reward": 0.0819743424654007, "value_loss": 0.006348393019288778, "policy_loss": -0.002293263960489611, "dist_entropy": 0.7174336075782776, "actor_grad_norm": 0.12617285549640656, "critic_grad_norm": 0.05129694566130638, "ratio": 1.0001027584075928, "entropy": 0.7174336075782776, "incre_win_rate": 0.0, "step": 958}
{"time": 1767082376.732011, "phase": "train", "update": 959, "total_env_steps": 3068800, "episode_reward": 0.07730184495449066, "value_loss": 0.003926450200378895, "policy_loss": -0.0021348830053049992, "dist_entropy": 0.724793803691864, "actor_grad_norm": 0.18712732195854187, "critic_grad_norm": 0.057336486876010895, "ratio": 1.000238299369812, "entropy": 0.724793803691864, "incre_win_rate": 0.0, "step": 959}
{"time": 1767082381.3150136, "phase": "train", "update": 960, "total_env_steps": 3072000, "episode_reward": 0.07919443398714066, "value_loss": 0.004799183364957571, "policy_loss": -0.0016230085322455068, "dist_entropy": 0.7539464950561523, "actor_grad_norm": 0.1588677018880844, "critic_grad_norm": 0.07646297663450241, "ratio": 0.9999300241470337, "entropy": 0.7539464950561523, "incre_win_rate": 0.0, "step": 960}
{"time": 1767082385.7536337, "phase": "train", "update": 961, "total_env_steps": 3075200, "episode_reward": 0.0846647322177887, "value_loss": 0.0044616441242396835, "policy_loss": -0.0021781475842367116, "dist_entropy": 0.7248324394226074, "actor_grad_norm": 0.17435233294963837, "critic_grad_norm": 0.048883501440286636, "ratio": 0.9995965361595154, "entropy": 0.7248324394226074, "incre_win_rate": 0.0, "step": 961}
{"time": 1767082403.5744655, "phase": "eval", "update": 961, "total_env_steps": 3075200, "eval_win_rate": 0.0, "eval_episode_reward": 11.226614238410594, "step": 961}
{"time": 1767082407.9994295, "phase": "train", "update": 962, "total_env_steps": 3078400, "episode_reward": 0.07879139482975006, "value_loss": 0.0033252860885113478, "policy_loss": -0.002144588520053503, "dist_entropy": 0.8058179259300232, "actor_grad_norm": 0.15619012713432312, "critic_grad_norm": 0.05154544860124588, "ratio": 1.000125765800476, "entropy": 0.8058179259300232, "incre_win_rate": 0.0, "step": 962}
{"time": 1767082412.415115, "phase": "train", "update": 963, "total_env_steps": 3081600, "episode_reward": 0.08622206002473831, "value_loss": 0.0036947456188499927, "policy_loss": -0.002247954906849259, "dist_entropy": 0.7343614816665649, "actor_grad_norm": 0.16587014496326447, "critic_grad_norm": 0.06947799772024155, "ratio": 0.999862790107727, "entropy": 0.7343614816665649, "incre_win_rate": 0.0, "step": 963}
{"time": 1767082417.4778736, "phase": "train", "update": 964, "total_env_steps": 3084800, "episode_reward": 0.08525094389915466, "value_loss": 0.004279077332466841, "policy_loss": -0.0024971715746666236, "dist_entropy": 0.7713269829750061, "actor_grad_norm": 0.15103381872177124, "critic_grad_norm": 0.05761301517486572, "ratio": 1.0001840591430664, "entropy": 0.7713269829750061, "incre_win_rate": 0.0, "step": 964}
{"time": 1767082421.8252065, "phase": "train", "update": 965, "total_env_steps": 3088000, "episode_reward": 0.08011020720005035, "value_loss": 0.003275124169886112, "policy_loss": -0.0017804463124349468, "dist_entropy": 0.7755021452903748, "actor_grad_norm": 0.1391846388578415, "critic_grad_norm": 0.0422961600124836, "ratio": 1.000069499015808, "entropy": 0.7755021452903748, "incre_win_rate": 0.0, "step": 965}
{"time": 1767082426.7451665, "phase": "train", "update": 966, "total_env_steps": 3091200, "episode_reward": 0.08413855731487274, "value_loss": 0.0035626874305307865, "policy_loss": -0.0021208643117063275, "dist_entropy": 0.7861599326133728, "actor_grad_norm": 0.1419111043214798, "critic_grad_norm": 0.040617045015096664, "ratio": 0.9998324513435364, "entropy": 0.7861599326133728, "incre_win_rate": 0.0, "step": 966}
{"time": 1767082431.2011774, "phase": "train", "update": 967, "total_env_steps": 3094400, "episode_reward": 0.0811304822564125, "value_loss": 0.0033880156464874745, "policy_loss": -0.002123224627221987, "dist_entropy": 0.8017432689666748, "actor_grad_norm": 0.1602175086736679, "critic_grad_norm": 0.035621341317892075, "ratio": 1.0001261234283447, "entropy": 0.8017432689666748, "incre_win_rate": 0.0, "step": 967}
{"time": 1767082436.041655, "phase": "train", "update": 968, "total_env_steps": 3097600, "episode_reward": 0.07820674777030945, "value_loss": 0.005367893632501364, "policy_loss": -0.0020389336199137633, "dist_entropy": 0.7315752863883972, "actor_grad_norm": 0.18067538738250732, "critic_grad_norm": 0.1494615077972412, "ratio": 1.0000618696212769, "entropy": 0.7315752863883972, "incre_win_rate": 0.0, "step": 968}
{"time": 1767082440.4958417, "phase": "train", "update": 969, "total_env_steps": 3100800, "episode_reward": 0.08290304243564606, "value_loss": 0.00420147068798542, "policy_loss": -0.001254052357252533, "dist_entropy": 0.7545869588851929, "actor_grad_norm": 0.148962140083313, "critic_grad_norm": 0.08681000769138336, "ratio": 1.0000165700912476, "entropy": 0.7545869588851929, "incre_win_rate": 0.0, "step": 969}
{"time": 1767082444.8418908, "phase": "train", "update": 970, "total_env_steps": 3104000, "episode_reward": 0.08088783174753189, "value_loss": 0.004297980107367039, "policy_loss": -0.0020787784506588027, "dist_entropy": 0.7711910843849182, "actor_grad_norm": 0.16790269315242767, "critic_grad_norm": 0.046445947140455246, "ratio": 1.0002068281173706, "entropy": 0.7711910843849182, "incre_win_rate": 0.0, "step": 970}
{"time": 1767082449.2636237, "phase": "train", "update": 971, "total_env_steps": 3107200, "episode_reward": 0.07682894915342331, "value_loss": 0.004998852126300335, "policy_loss": -0.0021454643039589883, "dist_entropy": 0.778759491443634, "actor_grad_norm": 0.14328819513320923, "critic_grad_norm": 0.046061936765909195, "ratio": 0.9999958872795105, "entropy": 0.778759491443634, "incre_win_rate": 0.0, "step": 971}
{"time": 1767082454.06311, "phase": "train", "update": 972, "total_env_steps": 3110400, "episode_reward": 0.07487840950489044, "value_loss": 0.0038256871048361063, "policy_loss": -0.00228446772945714, "dist_entropy": 0.7795525550842285, "actor_grad_norm": 0.17568382620811462, "critic_grad_norm": 0.05899697542190552, "ratio": 0.9999416470527649, "entropy": 0.7795525550842285, "incre_win_rate": 0.0, "step": 972}
{"time": 1767082458.510504, "phase": "train", "update": 973, "total_env_steps": 3113600, "episode_reward": 0.07659923285245895, "value_loss": 0.004383963160216808, "policy_loss": -0.002351549440403744, "dist_entropy": 0.7970250844955444, "actor_grad_norm": 0.18714283406734467, "critic_grad_norm": 0.07051721960306168, "ratio": 1.0001944303512573, "entropy": 0.7970250844955444, "incre_win_rate": 0.0, "step": 973}
{"time": 1767082462.7493906, "phase": "train", "update": 974, "total_env_steps": 3116800, "episode_reward": 0.07676169276237488, "value_loss": 0.002966704126447439, "policy_loss": -0.0015712997822333818, "dist_entropy": 0.7921480298042297, "actor_grad_norm": 0.1716679185628891, "critic_grad_norm": 0.05643370375037193, "ratio": 0.999896228313446, "entropy": 0.7921480298042297, "incre_win_rate": 0.0, "step": 974}
{"time": 1767082467.0965118, "phase": "train", "update": 975, "total_env_steps": 3120000, "episode_reward": 0.0805986151099205, "value_loss": 0.0034314468037337066, "policy_loss": -0.0021238828792064625, "dist_entropy": 0.7506510972976684, "actor_grad_norm": 0.1600094586610794, "critic_grad_norm": 0.0575275719165802, "ratio": 1.0001411437988281, "entropy": 0.7506510972976684, "incre_win_rate": 0.0, "step": 975}
{"time": 1767082471.5007772, "phase": "train", "update": 976, "total_env_steps": 3123200, "episode_reward": 0.07636071741580963, "value_loss": 0.0029494422487914562, "policy_loss": -0.0018737224345727554, "dist_entropy": 0.794939661026001, "actor_grad_norm": 0.17749136686325073, "critic_grad_norm": 0.04750928282737732, "ratio": 0.9997484087944031, "entropy": 0.794939661026001, "incre_win_rate": 0.0, "step": 976}
{"time": 1767082475.8851814, "phase": "train", "update": 977, "total_env_steps": 3126400, "episode_reward": 0.07678291201591492, "value_loss": 0.0026543539017438887, "policy_loss": -0.001631388276248913, "dist_entropy": 0.7960543870925904, "actor_grad_norm": 0.15918754041194916, "critic_grad_norm": 0.043601762503385544, "ratio": 0.9999663233757019, "entropy": 0.7960543870925904, "incre_win_rate": 0.0, "step": 977}
{"time": 1767082480.3195343, "phase": "train", "update": 978, "total_env_steps": 3129600, "episode_reward": 0.08111082762479782, "value_loss": 0.0035525925923138857, "policy_loss": -0.0017433465331194498, "dist_entropy": 0.724117660522461, "actor_grad_norm": 0.1280449777841568, "critic_grad_norm": 0.03156392276287079, "ratio": 0.9998423457145691, "entropy": 0.724117660522461, "incre_win_rate": 0.0, "step": 978}
{"time": 1767082484.7365, "phase": "train", "update": 979, "total_env_steps": 3132800, "episode_reward": 0.0808986946940422, "value_loss": 0.004812518320977688, "policy_loss": -0.0019202800296408639, "dist_entropy": 0.7272986650466919, "actor_grad_norm": 0.12519057095050812, "critic_grad_norm": 0.027084553614258766, "ratio": 1.0002433061599731, "entropy": 0.7272986650466919, "incre_win_rate": 0.0, "step": 979}
{"time": 1767082489.1713889, "phase": "train", "update": 980, "total_env_steps": 3136000, "episode_reward": 0.08110513538122177, "value_loss": 0.0037883763667196035, "policy_loss": -0.0018415811714532992, "dist_entropy": 0.7792227983474731, "actor_grad_norm": 0.13138653337955475, "critic_grad_norm": 0.04698706790804863, "ratio": 0.9999790191650391, "entropy": 0.7792227983474731, "incre_win_rate": 0.0, "step": 980}
{"time": 1767082524.3024032, "phase": "train", "update": 981, "total_env_steps": 3139200, "episode_reward": 0.08152473717927933, "value_loss": 0.030372947454452515, "policy_loss": -0.0016296983932303278, "dist_entropy": 0.7817107200622558, "actor_grad_norm": 0.14399947226047516, "critic_grad_norm": 0.18991021811962128, "ratio": 1.0000356435775757, "entropy": 0.7817107200622558, "incre_win_rate": 0.0, "step": 981}
{"time": 1767082547.3819222, "phase": "eval", "update": 981, "total_env_steps": 3139200, "eval_win_rate": 0.0, "eval_episode_reward": 11.290614652317874, "step": 981}
{"time": 1767082551.495963, "phase": "train", "update": 982, "total_env_steps": 3142400, "episode_reward": 0.08554118126630783, "value_loss": 0.0049033848568797115, "policy_loss": -0.0013716593413519718, "dist_entropy": 0.7838614821434021, "actor_grad_norm": 0.13503940403461456, "critic_grad_norm": 0.08970674127340317, "ratio": 0.9998337030410767, "entropy": 0.7838614821434021, "incre_win_rate": 0.0, "step": 982}
{"time": 1767082555.7334273, "phase": "train", "update": 983, "total_env_steps": 3145600, "episode_reward": 0.0778740718960762, "value_loss": 0.003076997306197882, "policy_loss": -0.001533199914624106, "dist_entropy": 0.7855194449424744, "actor_grad_norm": 0.14584870636463165, "critic_grad_norm": 0.06702607125043869, "ratio": 0.9998863339424133, "entropy": 0.7855194449424744, "incre_win_rate": 0.0, "step": 983}
{"time": 1767082560.0361655, "phase": "train", "update": 984, "total_env_steps": 3148800, "episode_reward": 0.08379967510700226, "value_loss": 0.005112478602677583, "policy_loss": -0.0015733802247652306, "dist_entropy": 0.7656554341316223, "actor_grad_norm": 0.11957176774740219, "critic_grad_norm": 0.06846371293067932, "ratio": 0.9998287558555603, "entropy": 0.7656554341316223, "incre_win_rate": 0.0, "step": 984}
{"time": 1767082564.2660933, "phase": "train", "update": 985, "total_env_steps": 3152000, "episode_reward": 0.07821347564458847, "value_loss": 0.003231269586831331, "policy_loss": -0.0016438944245393827, "dist_entropy": 0.8237800598144531, "actor_grad_norm": 0.1764127016067505, "critic_grad_norm": 0.0699567049741745, "ratio": 0.9999961256980896, "entropy": 0.8237800598144531, "incre_win_rate": 0.0, "step": 985}
{"time": 1767082568.6037173, "phase": "train", "update": 986, "total_env_steps": 3155200, "episode_reward": 0.08058826625347137, "value_loss": 0.003884866088628769, "policy_loss": -0.002057738156232247, "dist_entropy": 0.8038233876228332, "actor_grad_norm": 0.14840273559093475, "critic_grad_norm": 0.05300645902752876, "ratio": 0.9999001622200012, "entropy": 0.8038233876228332, "incre_win_rate": 0.0, "step": 986}
{"time": 1767082572.848212, "phase": "train", "update": 987, "total_env_steps": 3158400, "episode_reward": 0.07690708339214325, "value_loss": 0.003743748599663377, "policy_loss": -0.0018145867456929921, "dist_entropy": 0.7938474893569947, "actor_grad_norm": 0.1491185873746872, "critic_grad_norm": 0.04931635782122612, "ratio": 0.9998672604560852, "entropy": 0.7938474893569947, "incre_win_rate": 0.0, "step": 987}
{"time": 1767082577.1836216, "phase": "train", "update": 988, "total_env_steps": 3161600, "episode_reward": 0.08417633175849915, "value_loss": 0.0036591698415577413, "policy_loss": -0.0018625210309533458, "dist_entropy": 0.7802804470062256, "actor_grad_norm": 0.1231258288025856, "critic_grad_norm": 0.04473458603024483, "ratio": 1.0002797842025757, "entropy": 0.7802804470062256, "incre_win_rate": 0.0, "step": 988}
{"time": 1767082581.6820745, "phase": "train", "update": 989, "total_env_steps": 3164800, "episode_reward": 0.08279439061880112, "value_loss": 0.0030708197504282, "policy_loss": -0.0019999654154361224, "dist_entropy": 0.7598401665687561, "actor_grad_norm": 0.14604909718036652, "critic_grad_norm": 0.04960000142455101, "ratio": 0.9997960329055786, "entropy": 0.7598401665687561, "incre_win_rate": 0.0, "step": 989}
{"time": 1767082586.1636105, "phase": "train", "update": 990, "total_env_steps": 3168000, "episode_reward": 0.07473509758710861, "value_loss": 0.003954655025154352, "policy_loss": -0.002169192148427612, "dist_entropy": 0.7919463396072388, "actor_grad_norm": 0.16088278591632843, "critic_grad_norm": 0.0447358600795269, "ratio": 0.9997806549072266, "entropy": 0.7919463396072388, "incre_win_rate": 0.0, "step": 990}
{"time": 1767082590.4623148, "phase": "train", "update": 991, "total_env_steps": 3171200, "episode_reward": 0.07948727160692215, "value_loss": 0.0020897180773317816, "policy_loss": -0.0016501125009138918, "dist_entropy": 0.8151304364204407, "actor_grad_norm": 0.1500423550605774, "critic_grad_norm": 0.03040512278676033, "ratio": 1.000057339668274, "entropy": 0.8151304364204407, "incre_win_rate": 0.0, "step": 991}
{"time": 1767082595.0532317, "phase": "train", "update": 992, "total_env_steps": 3174400, "episode_reward": 0.08305981010198593, "value_loss": 0.0032941731158643963, "policy_loss": -0.0021729899985068355, "dist_entropy": 0.790181303024292, "actor_grad_norm": 0.17061100900173187, "critic_grad_norm": 0.021542077884078026, "ratio": 1.0001531839370728, "entropy": 0.790181303024292, "incre_win_rate": 0.0, "step": 992}
{"time": 1767082599.5421932, "phase": "train", "update": 993, "total_env_steps": 3177600, "episode_reward": 0.07661785930395126, "value_loss": 0.00257979491725564, "policy_loss": -0.0020868916198859113, "dist_entropy": 0.8349026083946228, "actor_grad_norm": 0.15203312039375305, "critic_grad_norm": 0.05381379649043083, "ratio": 1.0000861883163452, "entropy": 0.8349026083946228, "incre_win_rate": 0.0, "step": 993}
{"time": 1767082604.163973, "phase": "train", "update": 994, "total_env_steps": 3180800, "episode_reward": 0.0833231508731842, "value_loss": 0.002915958222001791, "policy_loss": -0.0018549022073955257, "dist_entropy": 0.8223701238632202, "actor_grad_norm": 0.15802724659442902, "critic_grad_norm": 0.03548533469438553, "ratio": 0.9998685121536255, "entropy": 0.8223701238632202, "incre_win_rate": 0.0, "step": 994}
{"time": 1767082608.9077315, "phase": "train", "update": 995, "total_env_steps": 3184000, "episode_reward": 0.08222164213657379, "value_loss": 0.003616886865347624, "policy_loss": -0.0023740326648017175, "dist_entropy": 0.7579184651374817, "actor_grad_norm": 0.17723098397254944, "critic_grad_norm": 0.04751560464501381, "ratio": 1.0001392364501953, "entropy": 0.7579184651374817, "incre_win_rate": 0.0, "step": 995}
{"time": 1767082613.8224025, "phase": "train", "update": 996, "total_env_steps": 3187200, "episode_reward": 0.07969939708709717, "value_loss": 0.0033444258384406566, "policy_loss": -0.0022876859173052823, "dist_entropy": 0.7486961364746094, "actor_grad_norm": 0.17111773788928986, "critic_grad_norm": 0.07801499217748642, "ratio": 1.0005844831466675, "entropy": 0.7486961364746094, "incre_win_rate": 0.0, "step": 996}
{"time": 1767082618.7362168, "phase": "train", "update": 997, "total_env_steps": 3190400, "episode_reward": 0.08347062021493912, "value_loss": 0.004320989642292261, "policy_loss": -0.002572670087479878, "dist_entropy": 0.71130850315094, "actor_grad_norm": 0.1708030253648758, "critic_grad_norm": 0.05321500450372696, "ratio": 0.9999813437461853, "entropy": 0.71130850315094, "incre_win_rate": 0.0, "step": 997}
{"time": 1767082623.7121618, "phase": "train", "update": 998, "total_env_steps": 3193600, "episode_reward": 0.09043615311384201, "value_loss": 0.006549824588000774, "policy_loss": -0.0023546482233001596, "dist_entropy": 0.6556368350982666, "actor_grad_norm": 0.12155131250619888, "critic_grad_norm": 0.09174668788909912, "ratio": 1.000065803527832, "entropy": 0.6556368350982666, "incre_win_rate": 0.0, "step": 998}
{"time": 1767082628.7322943, "phase": "train", "update": 999, "total_env_steps": 3196800, "episode_reward": 0.09224647283554077, "value_loss": 0.00807480989024043, "policy_loss": -0.0022876883378270207, "dist_entropy": 0.6447377920150756, "actor_grad_norm": 0.15124045312404633, "critic_grad_norm": 0.05528273060917854, "ratio": 1.0000752210617065, "entropy": 0.6447377920150756, "incre_win_rate": 0.0, "step": 999}
{"time": 1767082633.7902436, "phase": "train", "update": 1000, "total_env_steps": 3200000, "episode_reward": 0.09049409627914429, "value_loss": 0.006211505550891161, "policy_loss": -0.0029986302645532703, "dist_entropy": 0.7126818418502807, "actor_grad_norm": 0.17839066684246063, "critic_grad_norm": 0.08311830461025238, "ratio": 0.9994270205497742, "entropy": 0.7126818418502807, "incre_win_rate": 0.0, "step": 1000}
{"time": 1767082638.604241, "phase": "train", "update": 1001, "total_env_steps": 3203200, "episode_reward": 0.08537354320287704, "value_loss": 0.007417435478419066, "policy_loss": -0.002621260142069559, "dist_entropy": 0.6985674738883972, "actor_grad_norm": 0.12960012257099152, "critic_grad_norm": 0.06663648039102554, "ratio": 0.9999836087226868, "entropy": 0.6985674738883972, "incre_win_rate": 0.0, "step": 1001}
{"time": 1767082657.5771358, "phase": "eval", "update": 1001, "total_env_steps": 3203200, "eval_win_rate": 0.0, "eval_episode_reward": 12.129035596026476, "step": 1001}
{"time": 1767082661.9940646, "phase": "train", "update": 1002, "total_env_steps": 3206400, "episode_reward": 0.08278042823076248, "value_loss": 0.0033793422393500806, "policy_loss": -0.0019618546095674814, "dist_entropy": 0.7511365175247192, "actor_grad_norm": 0.17728060483932495, "critic_grad_norm": 0.03776957467198372, "ratio": 1.000109314918518, "entropy": 0.7511365175247192, "incre_win_rate": 0.0, "step": 1002}
{"time": 1767082666.5524013, "phase": "train", "update": 1003, "total_env_steps": 3209600, "episode_reward": 0.08718957006931305, "value_loss": 0.00453556003049016, "policy_loss": -0.002627751838809189, "dist_entropy": 0.6905786871910096, "actor_grad_norm": 0.18967024981975555, "critic_grad_norm": 0.030762111768126488, "ratio": 0.9999184012413025, "entropy": 0.6905786871910096, "incre_win_rate": 0.0, "step": 1003}
{"time": 1767082671.0165925, "phase": "train", "update": 1004, "total_env_steps": 3212800, "episode_reward": 0.08397868275642395, "value_loss": 0.004108130466192961, "policy_loss": -0.001987419904546073, "dist_entropy": 0.7043901324272156, "actor_grad_norm": 0.1644318401813507, "critic_grad_norm": 0.02180228941142559, "ratio": 0.9998610615730286, "entropy": 0.7043901324272156, "incre_win_rate": 0.0, "step": 1004}
{"time": 1767082675.5222645, "phase": "train", "update": 1005, "total_env_steps": 3216000, "episode_reward": 0.07720819860696793, "value_loss": 0.004062556242570281, "policy_loss": -0.0014033371080742541, "dist_entropy": 0.7331695199012757, "actor_grad_norm": 0.13319151103496552, "critic_grad_norm": 0.07494150847196579, "ratio": 0.9997753500938416, "entropy": 0.7331695199012757, "incre_win_rate": 0.0, "step": 1005}
{"time": 1767082680.1311088, "phase": "train", "update": 1006, "total_env_steps": 3219200, "episode_reward": 0.089942567050457, "value_loss": 0.006378450058400631, "policy_loss": -0.002087856088576245, "dist_entropy": 0.6809706687927246, "actor_grad_norm": 0.14081980288028717, "critic_grad_norm": 0.05703554302453995, "ratio": 0.9997647404670715, "entropy": 0.6809706687927246, "incre_win_rate": 0.0, "step": 1006}
{"time": 1767082684.5757253, "phase": "train", "update": 1007, "total_env_steps": 3222400, "episode_reward": 0.08336816728115082, "value_loss": 0.004155724868178367, "policy_loss": -0.0020943200098258786, "dist_entropy": 0.6957744717597961, "actor_grad_norm": 0.14968924224376678, "critic_grad_norm": 0.02533278800547123, "ratio": 1.0000758171081543, "entropy": 0.6957744717597961, "incre_win_rate": 0.0, "step": 1007}
{"time": 1767082689.0252807, "phase": "train", "update": 1008, "total_env_steps": 3225600, "episode_reward": 0.08718491345643997, "value_loss": 0.006057697534561157, "policy_loss": -0.001963458047147526, "dist_entropy": 0.6899750709533692, "actor_grad_norm": 0.13376562297344208, "critic_grad_norm": 0.04179507493972778, "ratio": 0.9999195337295532, "entropy": 0.6899750709533692, "incre_win_rate": 0.0, "step": 1008}
{"time": 1767082693.4801636, "phase": "train", "update": 1009, "total_env_steps": 3228800, "episode_reward": 0.08444536477327347, "value_loss": 0.005560712423175573, "policy_loss": -0.002050789255272889, "dist_entropy": 0.6909676790237427, "actor_grad_norm": 0.1471320390701294, "critic_grad_norm": 0.02886776439845562, "ratio": 0.9998764991760254, "entropy": 0.6909676790237427, "incre_win_rate": 0.0, "step": 1009}
{"time": 1767082697.9575307, "phase": "train", "update": 1010, "total_env_steps": 3232000, "episode_reward": 0.08113772422075272, "value_loss": 0.004514488205313682, "policy_loss": -0.0027973486758625654, "dist_entropy": 0.6792390823364258, "actor_grad_norm": 0.16136996448040009, "critic_grad_norm": 0.046306971460580826, "ratio": 1.0000194311141968, "entropy": 0.6792390823364258, "incre_win_rate": 0.0, "step": 1010}
{"time": 1767082702.4150064, "phase": "train", "update": 1011, "total_env_steps": 3235200, "episode_reward": 0.08453590422868729, "value_loss": 0.004610072914510965, "policy_loss": -0.0021275890704494315, "dist_entropy": 0.6804401040077209, "actor_grad_norm": 0.15735884010791779, "critic_grad_norm": 0.0178566575050354, "ratio": 0.9998866319656372, "entropy": 0.6804401040077209, "incre_win_rate": 0.0, "step": 1011}
{"time": 1767082706.7226598, "phase": "train", "update": 1012, "total_env_steps": 3238400, "episode_reward": 0.07980597764253616, "value_loss": 0.0036325329914689065, "policy_loss": -0.002162200725675234, "dist_entropy": 0.7054923415184021, "actor_grad_norm": 0.15025953948497772, "critic_grad_norm": 0.017210448160767555, "ratio": 1.0000200271606445, "entropy": 0.7054923415184021, "incre_win_rate": 0.0, "step": 1012}
{"time": 1767082711.3352706, "phase": "train", "update": 1013, "total_env_steps": 3241600, "episode_reward": 0.08645229041576385, "value_loss": 0.0037492289207875728, "policy_loss": -0.002781383186479047, "dist_entropy": 0.6800639271736145, "actor_grad_norm": 0.15007004141807556, "critic_grad_norm": 0.04491008073091507, "ratio": 0.9998441934585571, "entropy": 0.6800639271736145, "incre_win_rate": 0.0, "step": 1013}
{"time": 1767082715.8674088, "phase": "train", "update": 1014, "total_env_steps": 3244800, "episode_reward": 0.08286683261394501, "value_loss": 0.0047128708101809025, "policy_loss": -0.002273607022037538, "dist_entropy": 0.6730411887168884, "actor_grad_norm": 0.1846756786108017, "critic_grad_norm": 0.02614007331430912, "ratio": 0.9999794363975525, "entropy": 0.6730411887168884, "incre_win_rate": 0.0, "step": 1014}
{"time": 1767082720.2997696, "phase": "train", "update": 1015, "total_env_steps": 3248000, "episode_reward": 0.08531508594751358, "value_loss": 0.005826458986848593, "policy_loss": -0.0019865650602994833, "dist_entropy": 0.6851862072944641, "actor_grad_norm": 0.1712520569562912, "critic_grad_norm": 0.05787212774157524, "ratio": 1.000274419784546, "entropy": 0.6851862072944641, "incre_win_rate": 0.0, "step": 1015}
{"time": 1767082724.653154, "phase": "train", "update": 1016, "total_env_steps": 3251200, "episode_reward": 0.0831710547208786, "value_loss": 0.0042730806395411495, "policy_loss": -0.0014914681932324924, "dist_entropy": 0.6786626696586608, "actor_grad_norm": 0.12432024627923965, "critic_grad_norm": 0.020709097385406494, "ratio": 1.000038504600525, "entropy": 0.6786626696586608, "incre_win_rate": 0.0, "step": 1016}
{"time": 1767082729.0383437, "phase": "train", "update": 1017, "total_env_steps": 3254400, "episode_reward": 0.08579161018133163, "value_loss": 0.004048490012064576, "policy_loss": -0.0018378094988058535, "dist_entropy": 0.6770495653152466, "actor_grad_norm": 0.15128716826438904, "critic_grad_norm": 0.029750531539320946, "ratio": 1.000083327293396, "entropy": 0.6770495653152466, "incre_win_rate": 0.0, "step": 1017}
{"time": 1767082733.3566735, "phase": "train", "update": 1018, "total_env_steps": 3257600, "episode_reward": 0.07874792814254761, "value_loss": 0.0035762608051300047, "policy_loss": -0.002878810943644794, "dist_entropy": 0.6948824167251587, "actor_grad_norm": 0.18626824021339417, "critic_grad_norm": 0.02743883989751339, "ratio": 0.9994624257087708, "entropy": 0.6948824167251587, "incre_win_rate": 0.0, "step": 1018}
{"time": 1767082737.8989122, "phase": "train", "update": 1019, "total_env_steps": 3260800, "episode_reward": 0.0748572051525116, "value_loss": 0.004750115051865578, "policy_loss": -0.002464607527986118, "dist_entropy": 0.738943076133728, "actor_grad_norm": 0.1585710495710373, "critic_grad_norm": 0.04802630469202995, "ratio": 0.999825656414032, "entropy": 0.738943076133728, "incre_win_rate": 0.0, "step": 1019}
{"time": 1767082742.4054837, "phase": "train", "update": 1020, "total_env_steps": 3264000, "episode_reward": 0.08613566309213638, "value_loss": 0.005989088863134384, "policy_loss": -0.002110159861058847, "dist_entropy": 0.6592497110366822, "actor_grad_norm": 0.16723261773586273, "critic_grad_norm": 0.02241869829595089, "ratio": 0.9997067451477051, "entropy": 0.6592497110366822, "incre_win_rate": 0.0, "step": 1020}
{"time": 1767082746.9844687, "phase": "train", "update": 1021, "total_env_steps": 3267200, "episode_reward": 0.08641814440488815, "value_loss": 0.0057126921601593494, "policy_loss": -0.002388070130232478, "dist_entropy": 0.6373423099517822, "actor_grad_norm": 0.13341309130191803, "critic_grad_norm": 0.021481642499566078, "ratio": 1.00011146068573, "entropy": 0.6373423099517822, "incre_win_rate": 0.0, "step": 1021}
{"time": 1767082764.4329433, "phase": "eval", "update": 1021, "total_env_steps": 3267200, "eval_win_rate": 0.0, "eval_episode_reward": 11.469733029801317, "step": 1021}
{"time": 1767082768.8361955, "phase": "train", "update": 1022, "total_env_steps": 3270400, "episode_reward": 0.08086299896240234, "value_loss": 0.0064957357943058016, "policy_loss": -0.002638626015161094, "dist_entropy": 0.7121299743652344, "actor_grad_norm": 0.1563163697719574, "critic_grad_norm": 0.09854954481124878, "ratio": 0.9996417164802551, "entropy": 0.7121299743652344, "incre_win_rate": 0.0, "step": 1022}
{"time": 1767082773.335364, "phase": "train", "update": 1023, "total_env_steps": 3273600, "episode_reward": 0.08643418550491333, "value_loss": 0.007465120311826468, "policy_loss": -0.0019300462997279056, "dist_entropy": 0.6756619691848755, "actor_grad_norm": 0.14717493951320648, "critic_grad_norm": 0.04396890476346016, "ratio": 1.0000308752059937, "entropy": 0.6756619691848755, "incre_win_rate": 0.0, "step": 1023}
{"time": 1767082778.017612, "phase": "train", "update": 1024, "total_env_steps": 3276800, "episode_reward": 0.08013606816530228, "value_loss": 0.0073576697148382665, "policy_loss": -0.0018719342245695713, "dist_entropy": 0.7007959842681885, "actor_grad_norm": 0.13474492728710175, "critic_grad_norm": 0.037291765213012695, "ratio": 0.9998127222061157, "entropy": 0.7007959842681885, "incre_win_rate": 0.045454545454545456, "step": 1024}
{"time": 1767082782.8536332, "phase": "train", "update": 1025, "total_env_steps": 3280000, "episode_reward": 0.08702090382575989, "value_loss": 0.008889042586088181, "policy_loss": -0.0017817016314660705, "dist_entropy": 0.6406871318817139, "actor_grad_norm": 0.13494117558002472, "critic_grad_norm": 0.028790632262825966, "ratio": 0.9998671412467957, "entropy": 0.6406871318817139, "incre_win_rate": 0.0, "step": 1025}
{"time": 1767082787.6027024, "phase": "train", "update": 1026, "total_env_steps": 3283200, "episode_reward": 0.08308205753564835, "value_loss": 0.006176835019141435, "policy_loss": -0.0023862015359224385, "dist_entropy": 0.6493433356285095, "actor_grad_norm": 0.19196538627147675, "critic_grad_norm": 0.04232049733400345, "ratio": 1.0000993013381958, "entropy": 0.6493433356285095, "incre_win_rate": 0.0, "step": 1026}
{"time": 1767082792.4454868, "phase": "train", "update": 1027, "total_env_steps": 3286400, "episode_reward": 0.07512624561786652, "value_loss": 0.005382557772099972, "policy_loss": -0.0019414064482129235, "dist_entropy": 0.7022706151008606, "actor_grad_norm": 0.15971694886684418, "critic_grad_norm": 0.024795906618237495, "ratio": 1.000219464302063, "entropy": 0.7022706151008606, "incre_win_rate": 0.0, "step": 1027}
{"time": 1767082797.1975698, "phase": "train", "update": 1028, "total_env_steps": 3289600, "episode_reward": 0.08563017100095749, "value_loss": 0.006348923221230507, "policy_loss": -0.0015728880529451317, "dist_entropy": 0.6747857689857483, "actor_grad_norm": 0.1458567976951599, "critic_grad_norm": 0.027605703100562096, "ratio": 1.0001829862594604, "entropy": 0.6747857689857483, "incre_win_rate": 0.0, "step": 1028}
{"time": 1767082801.6361008, "phase": "train", "update": 1029, "total_env_steps": 3292800, "episode_reward": 0.07931239157915115, "value_loss": 0.006190057285130024, "policy_loss": -0.001967783584412075, "dist_entropy": 0.69533269405365, "actor_grad_norm": 0.17693272233009338, "critic_grad_norm": 0.09043820947408676, "ratio": 0.999609112739563, "entropy": 0.69533269405365, "incre_win_rate": 0.0, "step": 1029}
{"time": 1767082805.8375604, "phase": "train", "update": 1030, "total_env_steps": 3296000, "episode_reward": 0.08564362674951553, "value_loss": 0.005615001264959574, "policy_loss": -0.002148861376517175, "dist_entropy": 0.6259842038154602, "actor_grad_norm": 0.15685801208019257, "critic_grad_norm": 0.03993045911192894, "ratio": 0.9999375343322754, "entropy": 0.6259842038154602, "incre_win_rate": 0.0, "step": 1030}
{"time": 1767082810.254509, "phase": "train", "update": 1031, "total_env_steps": 3299200, "episode_reward": 0.07202090322971344, "value_loss": 0.008239019941538573, "policy_loss": -0.0024857029963371246, "dist_entropy": 0.7108383059501648, "actor_grad_norm": 0.17548176646232605, "critic_grad_norm": 0.07921802252531052, "ratio": 1.0000051259994507, "entropy": 0.7108383059501648, "incre_win_rate": 0.0, "step": 1031}
{"time": 1767082814.9711938, "phase": "train", "update": 1032, "total_env_steps": 3302400, "episode_reward": 0.09196502715349197, "value_loss": 0.006952204555273056, "policy_loss": -0.0017638214838939347, "dist_entropy": 0.622609269618988, "actor_grad_norm": 0.14144910871982574, "critic_grad_norm": 0.038190554827451706, "ratio": 1.000288486480713, "entropy": 0.622609269618988, "incre_win_rate": 0.0, "step": 1032}
{"time": 1767082819.415123, "phase": "train", "update": 1033, "total_env_steps": 3305600, "episode_reward": 0.07885296642780304, "value_loss": 0.005263775866478681, "policy_loss": -0.0015032788204536018, "dist_entropy": 0.6822308540344239, "actor_grad_norm": 0.13624300062656403, "critic_grad_norm": 0.04241328686475754, "ratio": 1.0000826120376587, "entropy": 0.6822308540344239, "incre_win_rate": 0.0, "step": 1033}
{"time": 1767082824.014737, "phase": "train", "update": 1034, "total_env_steps": 3308800, "episode_reward": 0.0769888237118721, "value_loss": 0.005390385072678328, "policy_loss": -0.0016043325056802615, "dist_entropy": 0.6928955912590027, "actor_grad_norm": 0.14899598062038422, "critic_grad_norm": 0.05266208574175835, "ratio": 0.9998012781143188, "entropy": 0.6928955912590027, "incre_win_rate": 0.0, "step": 1034}
{"time": 1767082828.3236566, "phase": "train", "update": 1035, "total_env_steps": 3312000, "episode_reward": 0.07703849673271179, "value_loss": 0.0039396085776388645, "policy_loss": -0.0023881546240311024, "dist_entropy": 0.7238757610321045, "actor_grad_norm": 0.15145264565944672, "critic_grad_norm": 0.054106008261442184, "ratio": 0.9998259544372559, "entropy": 0.7238757610321045, "incre_win_rate": 0.0, "step": 1035}
{"time": 1767082832.8305066, "phase": "train", "update": 1036, "total_env_steps": 3315200, "episode_reward": 0.08516763895750046, "value_loss": 0.005870809778571129, "policy_loss": -0.002151528300193206, "dist_entropy": 0.6691549181938171, "actor_grad_norm": 0.1716059446334839, "critic_grad_norm": 0.0485069639980793, "ratio": 1.0000094175338745, "entropy": 0.6691549181938171, "incre_win_rate": 0.0, "step": 1036}
{"time": 1767082837.1753385, "phase": "train", "update": 1037, "total_env_steps": 3318400, "episode_reward": 0.0843946635723114, "value_loss": 0.004297802504152059, "policy_loss": -0.002340757095674206, "dist_entropy": 0.6729981184005738, "actor_grad_norm": 0.13733427226543427, "critic_grad_norm": 0.03242313116788864, "ratio": 0.999493420124054, "entropy": 0.6729981184005738, "incre_win_rate": 0.0, "step": 1037}
{"time": 1767082841.7818973, "phase": "train", "update": 1038, "total_env_steps": 3321600, "episode_reward": 0.07918873429298401, "value_loss": 0.0037942025344818832, "policy_loss": -0.0019124935797677268, "dist_entropy": 0.7057322859764099, "actor_grad_norm": 0.15587101876735687, "critic_grad_norm": 0.05960128456354141, "ratio": 1.0000338554382324, "entropy": 0.7057322859764099, "incre_win_rate": 0.0, "step": 1038}
{"time": 1767082846.3609645, "phase": "train", "update": 1039, "total_env_steps": 3324800, "episode_reward": 0.07882294803857803, "value_loss": 0.0041407251730561255, "policy_loss": -0.00202812248034121, "dist_entropy": 0.6756420850753784, "actor_grad_norm": 0.1375659555196762, "critic_grad_norm": 0.03619625046849251, "ratio": 1.000299096107483, "entropy": 0.6756420850753784, "incre_win_rate": 0.0, "step": 1039}
{"time": 1767082850.7454333, "phase": "train", "update": 1040, "total_env_steps": 3328000, "episode_reward": 0.08420684933662415, "value_loss": 0.0038957240059971808, "policy_loss": -0.0019160066114331186, "dist_entropy": 0.6644710421562194, "actor_grad_norm": 0.13218320906162262, "critic_grad_norm": 0.03227236866950989, "ratio": 1.0001963376998901, "entropy": 0.6644710421562194, "incre_win_rate": 0.0, "step": 1040}
{"time": 1767082855.125417, "phase": "train", "update": 1041, "total_env_steps": 3331200, "episode_reward": 0.08557843416929245, "value_loss": 0.005870162323117256, "policy_loss": -0.002595835919734313, "dist_entropy": 0.684702706336975, "actor_grad_norm": 0.16281817853450775, "critic_grad_norm": 0.033391449600458145, "ratio": 0.9997515082359314, "entropy": 0.684702706336975, "incre_win_rate": 0.0, "step": 1041}
{"time": 1767082872.4479501, "phase": "eval", "update": 1041, "total_env_steps": 3331200, "eval_win_rate": 0.0, "eval_episode_reward": 11.868636175496679, "step": 1041}
{"time": 1767082877.077433, "phase": "train", "update": 1042, "total_env_steps": 3334400, "episode_reward": 0.08079108595848083, "value_loss": 0.0033444375265389683, "policy_loss": -0.0020103799593908177, "dist_entropy": 0.7121165037155152, "actor_grad_norm": 0.15163540840148926, "critic_grad_norm": 0.03220503777265549, "ratio": 0.9999015927314758, "entropy": 0.7121165037155152, "incre_win_rate": 0.0, "step": 1042}
{"time": 1767082881.478979, "phase": "train", "update": 1043, "total_env_steps": 3337600, "episode_reward": 0.07904180884361267, "value_loss": 0.0030168517027050258, "policy_loss": -0.002033824002859319, "dist_entropy": 0.7607739329338074, "actor_grad_norm": 0.1285700500011444, "critic_grad_norm": 0.017968932166695595, "ratio": 0.999927818775177, "entropy": 0.7607739329338074, "incre_win_rate": 0.0, "step": 1043}
{"time": 1767082885.8994787, "phase": "train", "update": 1044, "total_env_steps": 3340800, "episode_reward": 0.08983393013477325, "value_loss": 0.005819832626730204, "policy_loss": -0.002268344030380831, "dist_entropy": 0.6810548543930054, "actor_grad_norm": 0.1525171846151352, "critic_grad_norm": 0.03968077152967453, "ratio": 0.9998041987419128, "entropy": 0.6810548543930054, "incre_win_rate": 0.0, "step": 1044}
{"time": 1767082890.2128522, "phase": "train", "update": 1045, "total_env_steps": 3344000, "episode_reward": 0.07852648943662643, "value_loss": 0.005118504911661148, "policy_loss": -0.0022577717758871076, "dist_entropy": 0.7360140442848205, "actor_grad_norm": 0.16915373504161835, "critic_grad_norm": 0.02147621475160122, "ratio": 0.9997695088386536, "entropy": 0.7360140442848205, "incre_win_rate": 0.0, "step": 1045}
{"time": 1767082894.7103245, "phase": "train", "update": 1046, "total_env_steps": 3347200, "episode_reward": 0.08646056801080704, "value_loss": 0.005947356857359409, "policy_loss": -0.0021196253738104075, "dist_entropy": 0.6872093081474304, "actor_grad_norm": 0.17823609709739685, "critic_grad_norm": 0.04331381618976593, "ratio": 1.0001171827316284, "entropy": 0.6872093081474304, "incre_win_rate": 0.041666666666666664, "step": 1046}
{"time": 1767082899.3174667, "phase": "train", "update": 1047, "total_env_steps": 3350400, "episode_reward": 0.07484684884548187, "value_loss": 0.0043044563382864, "policy_loss": -0.0022270557966393768, "dist_entropy": 0.7599655032157898, "actor_grad_norm": 0.1709725558757782, "critic_grad_norm": 0.05310922861099243, "ratio": 0.9998373985290527, "entropy": 0.7599655032157898, "incre_win_rate": 0.0, "step": 1047}
{"time": 1767082904.1278095, "phase": "train", "update": 1048, "total_env_steps": 3353600, "episode_reward": 0.08216576278209686, "value_loss": 0.0043326329439878465, "policy_loss": -0.0026070474919663413, "dist_entropy": 0.7166727423667908, "actor_grad_norm": 0.14086806774139404, "critic_grad_norm": 0.06584547460079193, "ratio": 0.9996616244316101, "entropy": 0.7166727423667908, "incre_win_rate": 0.0, "step": 1048}
{"time": 1767082908.8334806, "phase": "train", "update": 1049, "total_env_steps": 3356800, "episode_reward": 0.07438742369413376, "value_loss": 0.0042495569214224815, "policy_loss": -0.0023816135110578786, "dist_entropy": 0.7496554970741272, "actor_grad_norm": 0.15799526870250702, "critic_grad_norm": 0.08949590474367142, "ratio": 0.9997246861457825, "entropy": 0.7496554970741272, "incre_win_rate": 0.0, "step": 1049}
{"time": 1767082913.6810834, "phase": "train", "update": 1050, "total_env_steps": 3360000, "episode_reward": 0.0831332802772522, "value_loss": 0.0059160061180591585, "policy_loss": -0.0016432325987004504, "dist_entropy": 0.6998151779174805, "actor_grad_norm": 0.13462691009044647, "critic_grad_norm": 0.08021105825901031, "ratio": 0.9999334216117859, "entropy": 0.6998151779174805, "incre_win_rate": 0.0, "step": 1050}
{"time": 1767082918.454144, "phase": "train", "update": 1051, "total_env_steps": 3363200, "episode_reward": 0.08707987517118454, "value_loss": 0.006395698338747024, "policy_loss": -0.0024033358725958466, "dist_entropy": 0.6616347312927247, "actor_grad_norm": 0.15953688323497772, "critic_grad_norm": 0.047816019505262375, "ratio": 0.9996189475059509, "entropy": 0.6616347312927247, "incre_win_rate": 0.0, "step": 1051}
{"time": 1767082923.321441, "phase": "train", "update": 1052, "total_env_steps": 3366400, "episode_reward": 0.07678186893463135, "value_loss": 0.00515538863837719, "policy_loss": -0.0016520493522507174, "dist_entropy": 0.6962826490402222, "actor_grad_norm": 0.13814890384674072, "critic_grad_norm": 0.07570893317461014, "ratio": 0.999714195728302, "entropy": 0.6962826490402222, "incre_win_rate": 0.0, "step": 1052}
{"time": 1767082927.716001, "phase": "train", "update": 1053, "total_env_steps": 3369600, "episode_reward": 0.08121119439601898, "value_loss": 0.005037615820765495, "policy_loss": -0.002481634168405478, "dist_entropy": 0.6718198299407959, "actor_grad_norm": 0.13133388757705688, "critic_grad_norm": 0.0799507349729538, "ratio": 0.9999737739562988, "entropy": 0.6718198299407959, "incre_win_rate": 0.0, "step": 1053}
{"time": 1767082932.0419657, "phase": "train", "update": 1054, "total_env_steps": 3372800, "episode_reward": 0.08175288885831833, "value_loss": 0.003911892510950565, "policy_loss": -0.0017158797558089133, "dist_entropy": 0.6846686363220215, "actor_grad_norm": 0.16014444828033447, "critic_grad_norm": 0.03379309922456741, "ratio": 1.0000447034835815, "entropy": 0.6846686363220215, "incre_win_rate": 0.0, "step": 1054}
{"time": 1767082936.3713548, "phase": "train", "update": 1055, "total_env_steps": 3376000, "episode_reward": 0.07960264384746552, "value_loss": 0.005814305413514376, "policy_loss": -0.002046104383848046, "dist_entropy": 0.6914726376533509, "actor_grad_norm": 0.14653827250003815, "critic_grad_norm": 0.027851665392518044, "ratio": 1.0000656843185425, "entropy": 0.6914726376533509, "incre_win_rate": 0.0, "step": 1055}
{"time": 1767082940.6539376, "phase": "train", "update": 1056, "total_env_steps": 3379200, "episode_reward": 0.08410234749317169, "value_loss": 0.003195728454738855, "policy_loss": -0.00215085887888975, "dist_entropy": 0.6347333669662476, "actor_grad_norm": 0.1331159919500351, "critic_grad_norm": 0.02656332217156887, "ratio": 1.0001024007797241, "entropy": 0.6347333669662476, "incre_win_rate": 0.0, "step": 1056}
{"time": 1767082945.038066, "phase": "train", "update": 1057, "total_env_steps": 3382400, "episode_reward": 0.0839502215385437, "value_loss": 0.004739843588322401, "policy_loss": -0.0017525247323092684, "dist_entropy": 0.6694124698638916, "actor_grad_norm": 0.14222994446754456, "critic_grad_norm": 0.038285862654447556, "ratio": 0.9998666048049927, "entropy": 0.6694124698638916, "incre_win_rate": 0.0, "step": 1057}
{"time": 1767082949.211413, "phase": "train", "update": 1058, "total_env_steps": 3385600, "episode_reward": 0.0745721161365509, "value_loss": 0.0032335903029888867, "policy_loss": -0.0025867424388735572, "dist_entropy": 0.7229198575019836, "actor_grad_norm": 0.13112108409404755, "critic_grad_norm": 0.052846115082502365, "ratio": 0.999808132648468, "entropy": 0.7229198575019836, "incre_win_rate": 0.0, "step": 1058}
{"time": 1767082953.550366, "phase": "train", "update": 1059, "total_env_steps": 3388800, "episode_reward": 0.0896311029791832, "value_loss": 0.004588168207556009, "policy_loss": -0.0011960017206227747, "dist_entropy": 0.6404063463211059, "actor_grad_norm": 0.11818324774503708, "critic_grad_norm": 0.056791748851537704, "ratio": 1.0000170469284058, "entropy": 0.6404063463211059, "incre_win_rate": 0.0, "step": 1059}
{"time": 1767082957.8363955, "phase": "train", "update": 1060, "total_env_steps": 3392000, "episode_reward": 0.08117084205150604, "value_loss": 0.0036385823972523213, "policy_loss": -0.0024599336037212536, "dist_entropy": 0.708071494102478, "actor_grad_norm": 0.168636292219162, "critic_grad_norm": 0.028562171384692192, "ratio": 1.0002132654190063, "entropy": 0.708071494102478, "incre_win_rate": 0.0, "step": 1060}
{"time": 1767082962.0917284, "phase": "train", "update": 1061, "total_env_steps": 3395200, "episode_reward": 0.07731219381093979, "value_loss": 0.0036282791290432213, "policy_loss": -0.001575785654131323, "dist_entropy": 0.6936436533927918, "actor_grad_norm": 0.1671065390110016, "critic_grad_norm": 0.0314372256398201, "ratio": 0.9997178912162781, "entropy": 0.6936436533927918, "incre_win_rate": 0.0, "step": 1061}
{"time": 1767082979.3368297, "phase": "eval", "update": 1061, "total_env_steps": 3395200, "eval_win_rate": 0.0, "eval_episode_reward": 11.938069122516545, "step": 1061}
{"time": 1767082983.6749477, "phase": "train", "update": 1062, "total_env_steps": 3398400, "episode_reward": 0.09078487753868103, "value_loss": 0.005554157495498657, "policy_loss": -0.0021633506077144205, "dist_entropy": 0.6145933628082275, "actor_grad_norm": 0.15720383822917938, "critic_grad_norm": 0.032552797347307205, "ratio": 1.0000405311584473, "entropy": 0.6145933628082275, "incre_win_rate": 0.0, "step": 1062}
{"time": 1767082987.9804115, "phase": "train", "update": 1063, "total_env_steps": 3401600, "episode_reward": 0.07883898913860321, "value_loss": 0.003192915301769972, "policy_loss": -0.0018934762464137833, "dist_entropy": 0.6614507436752319, "actor_grad_norm": 0.14100438356399536, "critic_grad_norm": 0.02308753877878189, "ratio": 1.0001401901245117, "entropy": 0.6614507436752319, "incre_win_rate": 0.0, "step": 1063}
{"time": 1767082992.2365654, "phase": "train", "update": 1064, "total_env_steps": 3404800, "episode_reward": 0.08129502087831497, "value_loss": 0.0035080650355666875, "policy_loss": -0.0012778807744609822, "dist_entropy": 0.6937073230743408, "actor_grad_norm": 0.16000603139400482, "critic_grad_norm": 0.021727710962295532, "ratio": 1.000407338142395, "entropy": 0.6937073230743408, "incre_win_rate": 0.0, "step": 1064}
{"time": 1767082996.6740694, "phase": "train", "update": 1065, "total_env_steps": 3408000, "episode_reward": 0.09614342451095581, "value_loss": 0.004725757241249085, "policy_loss": -0.001589316210447933, "dist_entropy": 0.6037780404090881, "actor_grad_norm": 0.14482219517230988, "critic_grad_norm": 0.039985548704862595, "ratio": 0.9997413754463196, "entropy": 0.6037780404090881, "incre_win_rate": 0.0, "step": 1065}
{"time": 1767083001.0323727, "phase": "train", "update": 1066, "total_env_steps": 3411200, "episode_reward": 0.08314207196235657, "value_loss": 0.005745281092822551, "policy_loss": -0.0012830376574157754, "dist_entropy": 0.6629113912582397, "actor_grad_norm": 0.1926354169845581, "critic_grad_norm": 0.03742460161447525, "ratio": 1.0001347064971924, "entropy": 0.6629113912582397, "incre_win_rate": 0.0, "step": 1066}
{"time": 1767083005.3474195, "phase": "train", "update": 1067, "total_env_steps": 3414400, "episode_reward": 0.08412355184555054, "value_loss": 0.005576406978070736, "policy_loss": -0.0012788842691463741, "dist_entropy": 0.6722721934318543, "actor_grad_norm": 0.16805724799633026, "critic_grad_norm": 0.04467618837952614, "ratio": 1.0000861883163452, "entropy": 0.6722721934318543, "incre_win_rate": 0.0, "step": 1067}
{"time": 1767083009.703973, "phase": "train", "update": 1068, "total_env_steps": 3417600, "episode_reward": 0.08259674906730652, "value_loss": 0.0058749130927026275, "policy_loss": -0.0025798622095679845, "dist_entropy": 0.7090521812438965, "actor_grad_norm": 0.168113574385643, "critic_grad_norm": 0.038203537464141846, "ratio": 0.9998303651809692, "entropy": 0.7090521812438965, "incre_win_rate": 0.0, "step": 1068}
{"time": 1767083014.120386, "phase": "train", "update": 1069, "total_env_steps": 3420800, "episode_reward": 0.09230856597423553, "value_loss": 0.003873812174424529, "policy_loss": -0.0019058589260211533, "dist_entropy": 0.693102216720581, "actor_grad_norm": 0.15072417259216309, "critic_grad_norm": 0.056889262050390244, "ratio": 1.0000723600387573, "entropy": 0.693102216720581, "incre_win_rate": 0.0, "step": 1069}
{"time": 1767083018.7234082, "phase": "train", "update": 1070, "total_env_steps": 3424000, "episode_reward": 0.08460316807031631, "value_loss": 0.005448509100824594, "policy_loss": -0.0018767897627000707, "dist_entropy": 0.6822221159934998, "actor_grad_norm": 0.16155213117599487, "critic_grad_norm": 0.049340516328811646, "ratio": 1.0001500844955444, "entropy": 0.6822221159934998, "incre_win_rate": 0.0, "step": 1070}
{"time": 1767083023.1694522, "phase": "train", "update": 1071, "total_env_steps": 3427200, "episode_reward": 0.08758174628019333, "value_loss": 0.005588459409773349, "policy_loss": -0.0019046895073923764, "dist_entropy": 0.6737539529800415, "actor_grad_norm": 0.1656922549009323, "critic_grad_norm": 0.0541975274682045, "ratio": 1.0001319646835327, "entropy": 0.6737539529800415, "incre_win_rate": 0.0, "step": 1071}
{"time": 1767083027.5733507, "phase": "train", "update": 1072, "total_env_steps": 3430400, "episode_reward": 0.08422806859016418, "value_loss": 0.004513487219810486, "policy_loss": -0.0017417811812201478, "dist_entropy": 0.6835226893424988, "actor_grad_norm": 0.13447225093841553, "critic_grad_norm": 0.06002005562186241, "ratio": 1.000276803970337, "entropy": 0.6835226893424988, "incre_win_rate": 0.0, "step": 1072}
{"time": 1767083032.0069094, "phase": "train", "update": 1073, "total_env_steps": 3433600, "episode_reward": 0.07576727867126465, "value_loss": 0.004017060995101929, "policy_loss": -0.002106499474763268, "dist_entropy": 0.7608640909194946, "actor_grad_norm": 0.1455758661031723, "critic_grad_norm": 0.053028374910354614, "ratio": 0.9997448325157166, "entropy": 0.7608640909194946, "incre_win_rate": 0.0, "step": 1073}
{"time": 1767083036.4716449, "phase": "train", "update": 1074, "total_env_steps": 3436800, "episode_reward": 0.0816473513841629, "value_loss": 0.004495516512542963, "policy_loss": -0.0019332793156131346, "dist_entropy": 0.7345289945602417, "actor_grad_norm": 0.12214391678571701, "critic_grad_norm": 0.03842025622725487, "ratio": 0.9999805688858032, "entropy": 0.7345289945602417, "incre_win_rate": 0.0, "step": 1074}
{"time": 1767083040.8248813, "phase": "train", "update": 1075, "total_env_steps": 3440000, "episode_reward": 0.08578331768512726, "value_loss": 0.005817404855042696, "policy_loss": -0.0020738351950569723, "dist_entropy": 0.7069997072219849, "actor_grad_norm": 0.13092195987701416, "critic_grad_norm": 0.027569612488150597, "ratio": 0.9998766779899597, "entropy": 0.7069997072219849, "incre_win_rate": 0.0, "step": 1075}
{"time": 1767083045.162041, "phase": "train", "update": 1076, "total_env_steps": 3443200, "episode_reward": 0.08707161247730255, "value_loss": 0.005178454145789146, "policy_loss": -0.002082445486614448, "dist_entropy": 0.7083780765533447, "actor_grad_norm": 0.13989241421222687, "critic_grad_norm": 0.023209331557154655, "ratio": 1.000332236289978, "entropy": 0.7083780765533447, "incre_win_rate": 0.0, "step": 1076}
{"time": 1767083049.4565613, "phase": "train", "update": 1077, "total_env_steps": 3446400, "episode_reward": 0.08023075014352798, "value_loss": 0.003558774571865797, "policy_loss": -0.0019634208667024923, "dist_entropy": 0.714772629737854, "actor_grad_norm": 0.14507023990154266, "critic_grad_norm": 0.017058847472071648, "ratio": 1.0000369548797607, "entropy": 0.714772629737854, "incre_win_rate": 0.0, "step": 1077}
{"time": 1767083053.8781946, "phase": "train", "update": 1078, "total_env_steps": 3449600, "episode_reward": 0.08548375219106674, "value_loss": 0.004354713205248118, "policy_loss": -0.0017162090180065093, "dist_entropy": 0.6728667974472046, "actor_grad_norm": 0.1527092009782791, "critic_grad_norm": 0.038476623594760895, "ratio": 0.9999443888664246, "entropy": 0.6728667974472046, "incre_win_rate": 0.0, "step": 1078}
{"time": 1767083058.2179756, "phase": "train", "update": 1079, "total_env_steps": 3452800, "episode_reward": 0.08484841138124466, "value_loss": 0.003113116743043065, "policy_loss": -0.0019202243197472767, "dist_entropy": 0.7051877379417419, "actor_grad_norm": 0.13993990421295166, "critic_grad_norm": 0.032915811985731125, "ratio": 1.0000572204589844, "entropy": 0.7051877379417419, "incre_win_rate": 0.0, "step": 1079}
{"time": 1767083062.6946995, "phase": "train", "update": 1080, "total_env_steps": 3456000, "episode_reward": 0.08568605780601501, "value_loss": 0.0040242687799036505, "policy_loss": -0.0023616183293739823, "dist_entropy": 0.6747471928596497, "actor_grad_norm": 0.18614605069160461, "critic_grad_norm": 0.02526065520942211, "ratio": 1.000148892402649, "entropy": 0.6747471928596497, "incre_win_rate": 0.0, "step": 1080}
{"time": 1767083067.3239126, "phase": "train", "update": 1081, "total_env_steps": 3459200, "episode_reward": 0.08240066468715668, "value_loss": 0.003532934468239546, "policy_loss": -0.0019736761199034445, "dist_entropy": 0.697706151008606, "actor_grad_norm": 0.1317482441663742, "critic_grad_norm": 0.02283596806228161, "ratio": 1.0000158548355103, "entropy": 0.697706151008606, "incre_win_rate": 0.0, "step": 1081}
{"time": 1767083085.5865664, "phase": "eval", "update": 1081, "total_env_steps": 3459200, "eval_win_rate": 0.0, "eval_episode_reward": 11.403559602648993, "step": 1081}
{"time": 1767083090.1509523, "phase": "train", "update": 1082, "total_env_steps": 3462400, "episode_reward": 0.0858692079782486, "value_loss": 0.007319985143840313, "policy_loss": -0.0015970216673608206, "dist_entropy": 0.6987698554992676, "actor_grad_norm": 0.13131359219551086, "critic_grad_norm": 0.07429414242506027, "ratio": 0.9998028874397278, "entropy": 0.6987698554992676, "incre_win_rate": 0.043478260869565216, "step": 1082}
{"time": 1767083094.727757, "phase": "train", "update": 1083, "total_env_steps": 3465600, "episode_reward": 0.07401490211486816, "value_loss": 0.004724199324846268, "policy_loss": -0.0013868834984336331, "dist_entropy": 0.7115965604782104, "actor_grad_norm": 0.16645507514476776, "critic_grad_norm": 0.06023132801055908, "ratio": 0.9998279809951782, "entropy": 0.7115965604782104, "incre_win_rate": 0.0, "step": 1083}
{"time": 1767083099.2598739, "phase": "train", "update": 1084, "total_env_steps": 3468800, "episode_reward": 0.08800031989812851, "value_loss": 0.0059046088717877865, "policy_loss": -0.0013732233664057957, "dist_entropy": 0.607870900630951, "actor_grad_norm": 0.14547578990459442, "critic_grad_norm": 0.05797715112566948, "ratio": 0.9999990463256836, "entropy": 0.607870900630951, "incre_win_rate": 0.0, "step": 1084}
{"time": 1767083103.5143003, "phase": "train", "update": 1085, "total_env_steps": 3472000, "episode_reward": 0.07894504815340042, "value_loss": 0.005548025202006102, "policy_loss": -0.0019571024613334485, "dist_entropy": 0.697585153579712, "actor_grad_norm": 0.15046581625938416, "critic_grad_norm": 0.04744928702712059, "ratio": 1.0000454187393188, "entropy": 0.697585153579712, "incre_win_rate": 0.0, "step": 1085}
{"time": 1767083108.2498822, "phase": "train", "update": 1086, "total_env_steps": 3475200, "episode_reward": 0.07555204629898071, "value_loss": 0.0037621014751493933, "policy_loss": -0.0020305753701066465, "dist_entropy": 0.6975103616714478, "actor_grad_norm": 0.16033467650413513, "critic_grad_norm": 0.03259849548339844, "ratio": 1.0004432201385498, "entropy": 0.6975103616714478, "incre_win_rate": 0.0, "step": 1086}
{"time": 1767083112.9300056, "phase": "train", "update": 1087, "total_env_steps": 3478400, "episode_reward": 0.09082834422588348, "value_loss": 0.005483363009989262, "policy_loss": -0.0014322926308665274, "dist_entropy": 0.6249397277832032, "actor_grad_norm": 0.11563409864902496, "critic_grad_norm": 0.02762621082365513, "ratio": 1.0000511407852173, "entropy": 0.6249397277832032, "incre_win_rate": 0.0, "step": 1087}
{"time": 1767083117.564142, "phase": "train", "update": 1088, "total_env_steps": 3481600, "episode_reward": 0.08516866713762283, "value_loss": 0.004336291737854481, "policy_loss": -0.0011772184306757083, "dist_entropy": 0.6291819930076599, "actor_grad_norm": 0.1028195396065712, "critic_grad_norm": 0.03358517214655876, "ratio": 0.9997329115867615, "entropy": 0.6291819930076599, "incre_win_rate": 0.0, "step": 1088}
{"time": 1767083121.9763663, "phase": "train", "update": 1089, "total_env_steps": 3484800, "episode_reward": 0.09009469300508499, "value_loss": 0.0053052552044391636, "policy_loss": -0.0018757428831715829, "dist_entropy": 0.6358755469322205, "actor_grad_norm": 0.12999534606933594, "critic_grad_norm": 0.07101050764322281, "ratio": 1.000139594078064, "entropy": 0.6358755469322205, "incre_win_rate": 0.0, "step": 1089}
{"time": 1767083126.4603229, "phase": "train", "update": 1090, "total_env_steps": 3488000, "episode_reward": 0.0831482782959938, "value_loss": 0.004902992770075798, "policy_loss": -0.001886928088799067, "dist_entropy": 0.6048364043235779, "actor_grad_norm": 0.12804821133613586, "critic_grad_norm": 0.027210434898734093, "ratio": 0.9997912645339966, "entropy": 0.6048364043235779, "incre_win_rate": 0.0, "step": 1090}
{"time": 1767083131.3424017, "phase": "train", "update": 1091, "total_env_steps": 3491200, "episode_reward": 0.08023799955844879, "value_loss": 0.002848795335739851, "policy_loss": -0.0021122253709769724, "dist_entropy": 0.6703091979026794, "actor_grad_norm": 0.1584782898426056, "critic_grad_norm": 0.022501027211546898, "ratio": 0.9994567036628723, "entropy": 0.6703091979026794, "incre_win_rate": 0.0, "step": 1091}
{"time": 1767083136.4764102, "phase": "train", "update": 1092, "total_env_steps": 3494400, "episode_reward": 0.08425600081682205, "value_loss": 0.004298560600727796, "policy_loss": -0.0020181981237882953, "dist_entropy": 0.6735591173171998, "actor_grad_norm": 0.16182823479175568, "critic_grad_norm": 0.018598251044750214, "ratio": 0.999879002571106, "entropy": 0.6735591173171998, "incre_win_rate": 0.0, "step": 1092}
{"time": 1767083141.4567573, "phase": "train", "update": 1093, "total_env_steps": 3497600, "episode_reward": 0.08326573669910431, "value_loss": 0.0048275342211127285, "policy_loss": -0.0019263177614291748, "dist_entropy": 0.6295565128326416, "actor_grad_norm": 0.14931385219097137, "critic_grad_norm": 0.04426227882504463, "ratio": 0.9999378323554993, "entropy": 0.6295565128326416, "incre_win_rate": 0.0, "step": 1093}
{"time": 1767083146.8959177, "phase": "train", "update": 1094, "total_env_steps": 3500800, "episode_reward": 0.08927462249994278, "value_loss": 0.005536246951669455, "policy_loss": -0.0017580639346050475, "dist_entropy": 0.5975610613822937, "actor_grad_norm": 0.1618736833333969, "critic_grad_norm": 0.029735906049609184, "ratio": 0.9997184872627258, "entropy": 0.5975610613822937, "incre_win_rate": 0.04, "step": 1094}
{"time": 1767083152.3194377, "phase": "train", "update": 1095, "total_env_steps": 3504000, "episode_reward": 0.08391401171684265, "value_loss": 0.006145655922591686, "policy_loss": -0.0018128546215564257, "dist_entropy": 0.6289203524589538, "actor_grad_norm": 0.1538536548614502, "critic_grad_norm": 0.024654997512698174, "ratio": 0.9998265504837036, "entropy": 0.6289203524589538, "incre_win_rate": 0.0, "step": 1095}
{"time": 1767083157.461168, "phase": "train", "update": 1096, "total_env_steps": 3507200, "episode_reward": 0.08588317036628723, "value_loss": 0.007319112215191126, "policy_loss": -0.00121746502598441, "dist_entropy": 0.594657039642334, "actor_grad_norm": 0.15920564532279968, "critic_grad_norm": 0.058221060782670975, "ratio": 0.9998469352722168, "entropy": 0.594657039642334, "incre_win_rate": 0.0, "step": 1096}
{"time": 1767083162.1490762, "phase": "train", "update": 1097, "total_env_steps": 3510400, "episode_reward": 0.08287200331687927, "value_loss": 0.005303686112165451, "policy_loss": -0.0014984645304593868, "dist_entropy": 0.6146657466888428, "actor_grad_norm": 0.14339619874954224, "critic_grad_norm": 0.032951779663562775, "ratio": 0.9996486902236938, "entropy": 0.6146657466888428, "incre_win_rate": 0.0, "step": 1097}
{"time": 1767083166.6333878, "phase": "train", "update": 1098, "total_env_steps": 3513600, "episode_reward": 0.08430205285549164, "value_loss": 0.004162353556603193, "policy_loss": -0.001669349058305869, "dist_entropy": 0.6071345210075378, "actor_grad_norm": 0.16888046264648438, "critic_grad_norm": 0.021504977717995644, "ratio": 1.0000468492507935, "entropy": 0.6071345210075378, "incre_win_rate": 0.0, "step": 1098}
{"time": 1767083171.171517, "phase": "train", "update": 1099, "total_env_steps": 3516800, "episode_reward": 0.08613719791173935, "value_loss": 0.0047064444050192835, "policy_loss": -0.0014984206488295015, "dist_entropy": 0.5815314292907715, "actor_grad_norm": 0.14262890815734863, "critic_grad_norm": 0.013730851002037525, "ratio": 0.999778687953949, "entropy": 0.5815314292907715, "incre_win_rate": 0.0, "step": 1099}
{"time": 1767083175.5812442, "phase": "train", "update": 1100, "total_env_steps": 3520000, "episode_reward": 0.08849389851093292, "value_loss": 0.004114844743162394, "policy_loss": -0.001974247327911627, "dist_entropy": 0.5704808950424194, "actor_grad_norm": 0.17277224361896515, "critic_grad_norm": 0.01215828862041235, "ratio": 0.9999751448631287, "entropy": 0.5704808950424194, "incre_win_rate": 0.0, "step": 1100}
{"time": 1767083180.031153, "phase": "train", "update": 1101, "total_env_steps": 3523200, "episode_reward": 0.0846300721168518, "value_loss": 0.004489151574671268, "policy_loss": -0.0015559298163950075, "dist_entropy": 0.5836907625198364, "actor_grad_norm": 0.14783933758735657, "critic_grad_norm": 0.012595017440617085, "ratio": 0.9997522234916687, "entropy": 0.5836907625198364, "incre_win_rate": 0.0, "step": 1101}
{"time": 1767083197.1644564, "phase": "eval", "update": 1101, "total_env_steps": 3523200, "eval_win_rate": 0.03125, "eval_episode_reward": 12.133122930463564, "step": 1101}
{"time": 1767083201.6337628, "phase": "train", "update": 1102, "total_env_steps": 3526400, "episode_reward": 0.08954626321792603, "value_loss": 0.004965137876570225, "policy_loss": -0.0015212940470348713, "dist_entropy": 0.5810797572135925, "actor_grad_norm": 0.11305484920740128, "critic_grad_norm": 0.03422429412603378, "ratio": 1.0001766681671143, "entropy": 0.5810797572135925, "incre_win_rate": 0.0, "step": 1102}
{"time": 1767083206.4132335, "phase": "train", "update": 1103, "total_env_steps": 3529600, "episode_reward": 0.09778766334056854, "value_loss": 0.007154374476522207, "policy_loss": -0.0010509261188566654, "dist_entropy": 0.5714550733566284, "actor_grad_norm": 0.11435319483280182, "critic_grad_norm": 0.10533668845891953, "ratio": 0.9999762773513794, "entropy": 0.5714550733566284, "incre_win_rate": 0.08695652173913043, "step": 1103}
{"time": 1767083211.0066245, "phase": "train", "update": 1104, "total_env_steps": 3532800, "episode_reward": 0.08436775952577591, "value_loss": 0.004978612437844277, "policy_loss": -0.0015926424622271895, "dist_entropy": 0.5982076764106751, "actor_grad_norm": 0.11383721977472305, "critic_grad_norm": 0.041477035731077194, "ratio": 0.9999666213989258, "entropy": 0.5982076764106751, "incre_win_rate": 0.0, "step": 1104}
{"time": 1767083215.4359224, "phase": "train", "update": 1105, "total_env_steps": 3536000, "episode_reward": 0.09181550145149231, "value_loss": 0.004997943993657827, "policy_loss": -0.0012632832103491864, "dist_entropy": 0.5675736904144287, "actor_grad_norm": 0.12597627937793732, "critic_grad_norm": 0.06214645132422447, "ratio": 1.0000574588775635, "entropy": 0.5675736904144287, "incre_win_rate": 0.0, "step": 1105}
{"time": 1767083219.8218215, "phase": "train", "update": 1106, "total_env_steps": 3539200, "episode_reward": 0.08929532766342163, "value_loss": 0.007602299097925425, "policy_loss": -0.0017729166965082753, "dist_entropy": 0.6316393494606019, "actor_grad_norm": 0.12882690131664276, "critic_grad_norm": 0.06511043757200241, "ratio": 1.0001777410507202, "entropy": 0.6316393494606019, "incre_win_rate": 0.045454545454545456, "step": 1106}
{"time": 1767083224.1534886, "phase": "train", "update": 1107, "total_env_steps": 3542400, "episode_reward": 0.09331073611974716, "value_loss": 0.008877226337790489, "policy_loss": -0.0019774161279201507, "dist_entropy": 0.5711819648742675, "actor_grad_norm": 0.15320605039596558, "critic_grad_norm": 0.06424062699079514, "ratio": 0.9996431469917297, "entropy": 0.5711819648742675, "incre_win_rate": 0.0, "step": 1107}
{"time": 1767083228.5371914, "phase": "train", "update": 1108, "total_env_steps": 3545600, "episode_reward": 0.08734685927629471, "value_loss": 0.006690946966409683, "policy_loss": -0.001611055524921312, "dist_entropy": 0.5992376804351807, "actor_grad_norm": 0.18072494864463806, "critic_grad_norm": 0.034876253455877304, "ratio": 1.0002483129501343, "entropy": 0.5992376804351807, "incre_win_rate": 0.04, "step": 1108}
{"time": 1767083232.9066482, "phase": "train", "update": 1109, "total_env_steps": 3548800, "episode_reward": 0.08827917277812958, "value_loss": 0.005810275673866272, "policy_loss": -0.0015397571697874923, "dist_entropy": 0.618267560005188, "actor_grad_norm": 0.14782951772212982, "critic_grad_norm": 0.05515578016638756, "ratio": 0.9998623728752136, "entropy": 0.618267560005188, "incre_win_rate": 0.0, "step": 1109}
{"time": 1767083237.3734093, "phase": "train", "update": 1110, "total_env_steps": 3552000, "episode_reward": 0.09189724922180176, "value_loss": 0.007164956070482731, "policy_loss": -0.0017174276128557153, "dist_entropy": 0.6042269468307495, "actor_grad_norm": 0.17479896545410156, "critic_grad_norm": 0.03242777660489082, "ratio": 1.0001718997955322, "entropy": 0.6042269468307495, "incre_win_rate": 0.038461538461538464, "step": 1110}
{"time": 1767083241.811195, "phase": "train", "update": 1111, "total_env_steps": 3555200, "episode_reward": 0.09587852656841278, "value_loss": 0.00846164096146822, "policy_loss": -0.001933038622032157, "dist_entropy": 0.5786292552947998, "actor_grad_norm": 0.14691229164600372, "critic_grad_norm": 0.046583738178014755, "ratio": 0.9997782111167908, "entropy": 0.5786292552947998, "incre_win_rate": 0.04, "step": 1111}
{"time": 1767083246.1273932, "phase": "train", "update": 1112, "total_env_steps": 3558400, "episode_reward": 0.07954521477222443, "value_loss": 0.005073105450719595, "policy_loss": -0.0021029262784786782, "dist_entropy": 0.6391215920448303, "actor_grad_norm": 0.16467900574207306, "critic_grad_norm": 0.07104340940713882, "ratio": 0.9999015927314758, "entropy": 0.6391215920448303, "incre_win_rate": 0.0, "step": 1112}
{"time": 1767083250.5361552, "phase": "train", "update": 1113, "total_env_steps": 3561600, "episode_reward": 0.0920436680316925, "value_loss": 0.005834269616752863, "policy_loss": -0.0013245872294213256, "dist_entropy": 0.6124804735183715, "actor_grad_norm": 0.16970257461071014, "critic_grad_norm": 0.023206181824207306, "ratio": 1.0001192092895508, "entropy": 0.6124804735183715, "incre_win_rate": 0.0, "step": 1113}
{"time": 1767083254.9203799, "phase": "train", "update": 1114, "total_env_steps": 3564800, "episode_reward": 0.09172548353672028, "value_loss": 0.005087308399379253, "policy_loss": -0.0018175625432582444, "dist_entropy": 0.6052813768386841, "actor_grad_norm": 0.12472023069858551, "critic_grad_norm": 0.05336195230484009, "ratio": 0.9999914169311523, "entropy": 0.6052813768386841, "incre_win_rate": 0.04, "step": 1114}
{"time": 1767083259.382754, "phase": "train", "update": 1115, "total_env_steps": 3568000, "episode_reward": 0.09466473758220673, "value_loss": 0.008529301173985005, "policy_loss": -0.0020853203514107576, "dist_entropy": 0.5881495475769043, "actor_grad_norm": 0.13165293633937836, "critic_grad_norm": 0.05364236235618591, "ratio": 0.9997283220291138, "entropy": 0.5881495475769043, "incre_win_rate": 0.0, "step": 1115}
{"time": 1767083263.8774972, "phase": "train", "update": 1116, "total_env_steps": 3571200, "episode_reward": 0.09182895720005035, "value_loss": 0.00827944055199623, "policy_loss": -0.0020524189916393707, "dist_entropy": 0.6196982026100158, "actor_grad_norm": 0.1618897169828415, "critic_grad_norm": 0.03730378672480583, "ratio": 0.9997848868370056, "entropy": 0.6196982026100158, "incre_win_rate": 0.0, "step": 1116}
{"time": 1767083268.3711216, "phase": "train", "update": 1117, "total_env_steps": 3574400, "episode_reward": 0.09125879406929016, "value_loss": 0.004823264200240374, "policy_loss": -0.0020405617384184893, "dist_entropy": 0.6258314251899719, "actor_grad_norm": 0.14642241597175598, "critic_grad_norm": 0.03393326327204704, "ratio": 0.9998967051506042, "entropy": 0.6258314251899719, "incre_win_rate": 0.0, "step": 1117}
{"time": 1767083272.8188841, "phase": "train", "update": 1118, "total_env_steps": 3577600, "episode_reward": 0.08403301239013672, "value_loss": 0.005368715431541204, "policy_loss": -0.002164116763118784, "dist_entropy": 0.6302080631256104, "actor_grad_norm": 0.1719915121793747, "critic_grad_norm": 0.04154638946056366, "ratio": 0.9997835159301758, "entropy": 0.6302080631256104, "incre_win_rate": 0.0, "step": 1118}
{"time": 1767083277.2965107, "phase": "train", "update": 1119, "total_env_steps": 3580800, "episode_reward": 0.0865531861782074, "value_loss": 0.005371643975377083, "policy_loss": -0.0017232288022256625, "dist_entropy": 0.6427571535110473, "actor_grad_norm": 0.1430072784423828, "critic_grad_norm": 0.03248097375035286, "ratio": 0.9996311068534851, "entropy": 0.6427571535110473, "incre_win_rate": 0.041666666666666664, "step": 1119}
{"time": 1767083281.8186646, "phase": "train", "update": 1120, "total_env_steps": 3584000, "episode_reward": 0.10383898764848709, "value_loss": 0.007090909313410521, "policy_loss": -0.0015728266355949927, "dist_entropy": 0.5686929941177368, "actor_grad_norm": 0.14659054577350616, "critic_grad_norm": 0.07681702822446823, "ratio": 0.999897301197052, "entropy": 0.5686929941177368, "incre_win_rate": 0.0, "step": 1120}
{"time": 1767083286.2120943, "phase": "train", "update": 1121, "total_env_steps": 3587200, "episode_reward": 0.09407078474760056, "value_loss": 0.006805793475359678, "policy_loss": -0.0018586831339920452, "dist_entropy": 0.6128666281700135, "actor_grad_norm": 0.13560335338115692, "critic_grad_norm": 0.057779669761657715, "ratio": 0.9996852874755859, "entropy": 0.6128666281700135, "incre_win_rate": 0.0, "step": 1121}
{"time": 1767083304.4885442, "phase": "eval", "update": 1121, "total_env_steps": 3587200, "eval_win_rate": 0.03125, "eval_episode_reward": 12.8630484271523, "step": 1121}
{"time": 1767083309.2111788, "phase": "train", "update": 1122, "total_env_steps": 3590400, "episode_reward": 0.08284095674753189, "value_loss": 0.005259714368730783, "policy_loss": -0.0023329768942005557, "dist_entropy": 0.6493206977844238, "actor_grad_norm": 0.1642109751701355, "critic_grad_norm": 0.04241761937737465, "ratio": 0.9997536540031433, "entropy": 0.6493206977844238, "incre_win_rate": 0.0, "step": 1122}
{"time": 1767083314.076475, "phase": "train", "update": 1123, "total_env_steps": 3593600, "episode_reward": 0.09494515508413315, "value_loss": 0.007118182722479105, "policy_loss": -0.0017644149522890729, "dist_entropy": 0.6300337791442872, "actor_grad_norm": 0.12905193865299225, "critic_grad_norm": 0.04232880100607872, "ratio": 1.0002247095108032, "entropy": 0.6300337791442872, "incre_win_rate": 0.041666666666666664, "step": 1123}
{"time": 1767083318.882197, "phase": "train", "update": 1124, "total_env_steps": 3596800, "episode_reward": 0.0967937633395195, "value_loss": 0.006419973261654377, "policy_loss": -0.0023849553805476375, "dist_entropy": 0.5861452579498291, "actor_grad_norm": 0.19732427597045898, "critic_grad_norm": 0.03009672462940216, "ratio": 0.9996566772460938, "entropy": 0.5861452579498291, "incre_win_rate": 0.0, "step": 1124}
{"time": 1767083323.7499416, "phase": "train", "update": 1125, "total_env_steps": 3600000, "episode_reward": 0.09444070607423782, "value_loss": 0.006853255350142718, "policy_loss": -0.0013590657236974835, "dist_entropy": 0.6051478862762452, "actor_grad_norm": 0.15013591945171356, "critic_grad_norm": 0.042506225407123566, "ratio": 0.9996084570884705, "entropy": 0.6051478862762452, "incre_win_rate": 0.0, "step": 1125}
{"time": 1767083328.8548806, "phase": "train", "update": 1126, "total_env_steps": 3603200, "episode_reward": 0.08902318775653839, "value_loss": 0.006989026442170143, "policy_loss": -0.001699733804576198, "dist_entropy": 0.6182801127433777, "actor_grad_norm": 0.16325291991233826, "critic_grad_norm": 0.08730907738208771, "ratio": 0.9999487996101379, "entropy": 0.6182801127433777, "incre_win_rate": 0.0, "step": 1126}
{"time": 1767083333.4469419, "phase": "train", "update": 1127, "total_env_steps": 3606400, "episode_reward": 0.08840698003768921, "value_loss": 0.006341323629021645, "policy_loss": -0.00199643924021089, "dist_entropy": 0.6189696431159973, "actor_grad_norm": 0.16095414757728577, "critic_grad_norm": 0.071414053440094, "ratio": 1.0000383853912354, "entropy": 0.6189696431159973, "incre_win_rate": 0.0, "step": 1127}
{"time": 1767083338.1048622, "phase": "train", "update": 1128, "total_env_steps": 3609600, "episode_reward": 0.09287872910499573, "value_loss": 0.008139268681406974, "policy_loss": -0.0017104943608153178, "dist_entropy": 0.5990901589393616, "actor_grad_norm": 0.16314952075481415, "critic_grad_norm": 0.06195539981126785, "ratio": 0.9998511672019958, "entropy": 0.5990901589393616, "incre_win_rate": 0.0, "step": 1128}
{"time": 1767083342.8529537, "phase": "train", "update": 1129, "total_env_steps": 3612800, "episode_reward": 0.10086093097925186, "value_loss": 0.008596385456621647, "policy_loss": -0.001739115593608176, "dist_entropy": 0.5700428009033203, "actor_grad_norm": 0.13186149299144745, "critic_grad_norm": 0.05381040647625923, "ratio": 1.0000801086425781, "entropy": 0.5700428009033203, "incre_win_rate": 0.041666666666666664, "step": 1129}
{"time": 1767083347.7183213, "phase": "train", "update": 1130, "total_env_steps": 3616000, "episode_reward": 0.08676894009113312, "value_loss": 0.004584240075200796, "policy_loss": -0.0014743773147444018, "dist_entropy": 0.598157775402069, "actor_grad_norm": 0.1294044703245163, "critic_grad_norm": 0.03802349045872688, "ratio": 0.9998810887336731, "entropy": 0.598157775402069, "incre_win_rate": 0.0, "step": 1130}
{"time": 1767083352.3550448, "phase": "train", "update": 1131, "total_env_steps": 3619200, "episode_reward": 0.09511227905750275, "value_loss": 0.008262275345623493, "policy_loss": -0.002119075226441236, "dist_entropy": 0.5848499298095703, "actor_grad_norm": 0.14488373696804047, "critic_grad_norm": 0.013763508759438992, "ratio": 0.9996264576911926, "entropy": 0.5848499298095703, "incre_win_rate": 0.08333333333333333, "step": 1131}
{"time": 1767083356.8648524, "phase": "train", "update": 1132, "total_env_steps": 3622400, "episode_reward": 0.09225113689899445, "value_loss": 0.005958080850541591, "policy_loss": -0.001932518125560012, "dist_entropy": 0.5947107672691345, "actor_grad_norm": 0.14885342121124268, "critic_grad_norm": 0.03674929961562157, "ratio": 0.9999697804450989, "entropy": 0.5947107672691345, "incre_win_rate": 0.0, "step": 1132}
{"time": 1767083361.2313352, "phase": "train", "update": 1133, "total_env_steps": 3625600, "episode_reward": 0.07807482033967972, "value_loss": 0.005296719633042813, "policy_loss": -0.00233140473144573, "dist_entropy": 0.656894040107727, "actor_grad_norm": 0.15909673273563385, "critic_grad_norm": 0.09799598902463913, "ratio": 1.0000652074813843, "entropy": 0.656894040107727, "incre_win_rate": 0.0, "step": 1133}
{"time": 1767083365.6808817, "phase": "train", "update": 1134, "total_env_steps": 3628800, "episode_reward": 0.09008537232875824, "value_loss": 0.0067858449183404446, "policy_loss": -0.001386641142399725, "dist_entropy": 0.6161522030830383, "actor_grad_norm": 0.1462114304304123, "critic_grad_norm": 0.055633991956710815, "ratio": 0.9998464584350586, "entropy": 0.6161522030830383, "incre_win_rate": 0.0, "step": 1134}
{"time": 1767083370.1277153, "phase": "train", "update": 1135, "total_env_steps": 3632000, "episode_reward": 0.08896315842866898, "value_loss": 0.0069896096363663675, "policy_loss": -0.0020472393879344963, "dist_entropy": 0.6188024520874024, "actor_grad_norm": 0.15846554934978485, "critic_grad_norm": 0.07031334191560745, "ratio": 1.0001078844070435, "entropy": 0.6188024520874024, "incre_win_rate": 0.0, "step": 1135}
{"time": 1767083374.5210075, "phase": "train", "update": 1136, "total_env_steps": 3635200, "episode_reward": 0.09948572516441345, "value_loss": 0.008761552907526494, "policy_loss": -0.0018116502790888945, "dist_entropy": 0.5920007824897766, "actor_grad_norm": 0.14403392374515533, "critic_grad_norm": 0.05996628478169441, "ratio": 0.9996936917304993, "entropy": 0.5920007824897766, "incre_win_rate": 0.08695652173913043, "step": 1136}
{"time": 1767083379.0187302, "phase": "train", "update": 1137, "total_env_steps": 3638400, "episode_reward": 0.09117136150598526, "value_loss": 0.006720810476690531, "policy_loss": -0.0015873889226448057, "dist_entropy": 0.5809269905090332, "actor_grad_norm": 0.10874128341674805, "critic_grad_norm": 0.04904092475771904, "ratio": 1.0001657009124756, "entropy": 0.5809269905090332, "incre_win_rate": 0.0, "step": 1137}
{"time": 1767083383.5637937, "phase": "train", "update": 1138, "total_env_steps": 3641600, "episode_reward": 0.0967213436961174, "value_loss": 0.007843801658600569, "policy_loss": -0.001713657191558937, "dist_entropy": 0.5570050239562988, "actor_grad_norm": 0.12415719032287598, "critic_grad_norm": 0.03499814495444298, "ratio": 0.9999874234199524, "entropy": 0.5570050239562988, "incre_win_rate": 0.0, "step": 1138}
{"time": 1767083388.0640607, "phase": "train", "update": 1139, "total_env_steps": 3644800, "episode_reward": 0.08886796236038208, "value_loss": 0.006853079050779342, "policy_loss": -0.0025415490127173256, "dist_entropy": 0.577540647983551, "actor_grad_norm": 0.17274299263954163, "critic_grad_norm": 0.07979805767536163, "ratio": 0.9995490312576294, "entropy": 0.577540647983551, "incre_win_rate": 0.043478260869565216, "step": 1139}
{"time": 1767083392.6351135, "phase": "train", "update": 1140, "total_env_steps": 3648000, "episode_reward": 0.09582366794347763, "value_loss": 0.008627614565193653, "policy_loss": -0.0017126305929048512, "dist_entropy": 0.5395200371742248, "actor_grad_norm": 0.12617139518260956, "critic_grad_norm": 0.06641124188899994, "ratio": 0.9998804330825806, "entropy": 0.5395200371742248, "incre_win_rate": 0.0, "step": 1140}
{"time": 1767083397.0524335, "phase": "train", "update": 1141, "total_env_steps": 3651200, "episode_reward": 0.08887055516242981, "value_loss": 0.006013025157153606, "policy_loss": -0.0017838827335623364, "dist_entropy": 0.6450346946716309, "actor_grad_norm": 0.1709914654493332, "critic_grad_norm": 0.054633576422929764, "ratio": 1.0001472234725952, "entropy": 0.6450346946716309, "incre_win_rate": 0.0, "step": 1141}
{"time": 1767083414.5669744, "phase": "eval", "update": 1141, "total_env_steps": 3651200, "eval_win_rate": 0.0, "eval_episode_reward": 12.482719370860913, "step": 1141}
{"time": 1767083419.0295496, "phase": "train", "update": 1142, "total_env_steps": 3654400, "episode_reward": 0.08857616782188416, "value_loss": 0.006447181198745966, "policy_loss": -0.0020113288983537813, "dist_entropy": 0.6315940618515015, "actor_grad_norm": 0.16089753806591034, "critic_grad_norm": 0.056412674486637115, "ratio": 0.9996784329414368, "entropy": 0.6315940618515015, "incre_win_rate": 0.0, "step": 1142}
{"time": 1767083423.5449827, "phase": "train", "update": 1143, "total_env_steps": 3657600, "episode_reward": 0.09260140359401703, "value_loss": 0.009227907843887806, "policy_loss": -0.001564621852416792, "dist_entropy": 0.6027783274650573, "actor_grad_norm": 0.13236409425735474, "critic_grad_norm": 0.02605443075299263, "ratio": 0.9996792078018188, "entropy": 0.6027783274650573, "incre_win_rate": 0.037037037037037035, "step": 1143}
{"time": 1767083428.122822, "phase": "train", "update": 1144, "total_env_steps": 3660800, "episode_reward": 0.08976148813962936, "value_loss": 0.009601217322051525, "policy_loss": -0.002364840705223514, "dist_entropy": 0.6353089213371277, "actor_grad_norm": 0.19017328321933746, "critic_grad_norm": 0.10105379670858383, "ratio": 0.9999344944953918, "entropy": 0.6353089213371277, "incre_win_rate": 0.0, "step": 1144}
{"time": 1767083458.302778, "phase": "train", "update": 1145, "total_env_steps": 3664000, "episode_reward": 0.09897299110889435, "value_loss": 0.03892155289649964, "policy_loss": -0.0014410815827311297, "dist_entropy": 0.6107468843460083, "actor_grad_norm": 0.13563166558742523, "critic_grad_norm": 0.2819173038005829, "ratio": 0.9996753931045532, "entropy": 0.6107468843460083, "incre_win_rate": 0.0, "step": 1145}
{"time": 1767083463.5033221, "phase": "train", "update": 1146, "total_env_steps": 3667200, "episode_reward": 0.09236030280590057, "value_loss": 0.007923097629100085, "policy_loss": -0.0016252942943762783, "dist_entropy": 0.6518471240997314, "actor_grad_norm": 0.210053488612175, "critic_grad_norm": 0.031941674649715424, "ratio": 1.0002161264419556, "entropy": 0.6518471240997314, "incre_win_rate": 0.038461538461538464, "step": 1146}
{"time": 1767083468.210165, "phase": "train", "update": 1147, "total_env_steps": 3670400, "episode_reward": 0.09192311018705368, "value_loss": 0.006624116469174624, "policy_loss": -0.002268066839901195, "dist_entropy": 0.6626208305358887, "actor_grad_norm": 0.1498391181230545, "critic_grad_norm": 0.026346296072006226, "ratio": 1.00015127658844, "entropy": 0.6626208305358887, "incre_win_rate": 0.038461538461538464, "step": 1147}
{"time": 1767083473.0920403, "phase": "train", "update": 1148, "total_env_steps": 3673600, "episode_reward": 0.08868791908025742, "value_loss": 0.007757391687482596, "policy_loss": -0.0022526915322814032, "dist_entropy": 0.653473961353302, "actor_grad_norm": 0.15029679238796234, "critic_grad_norm": 0.09086453914642334, "ratio": 0.9999189376831055, "entropy": 0.653473961353302, "incre_win_rate": 0.041666666666666664, "step": 1148}
{"time": 1767083478.0851948, "phase": "train", "update": 1149, "total_env_steps": 3676800, "episode_reward": 0.08770695328712463, "value_loss": 0.007284353021532297, "policy_loss": -0.0017242857006905866, "dist_entropy": 0.6761984586715698, "actor_grad_norm": 0.1499330848455429, "critic_grad_norm": 0.050674766302108765, "ratio": 1.0000537633895874, "entropy": 0.6761984586715698, "incre_win_rate": 0.0, "step": 1149}
{"time": 1767083482.9854374, "phase": "train", "update": 1150, "total_env_steps": 3680000, "episode_reward": 0.0890112891793251, "value_loss": 0.01148464847356081, "policy_loss": -0.002143438131624542, "dist_entropy": 0.680978512763977, "actor_grad_norm": 0.12516431510448456, "critic_grad_norm": 0.03843403980135918, "ratio": 0.9999359250068665, "entropy": 0.680978512763977, "incre_win_rate": 0.09090909090909091, "step": 1150}
{"time": 1767083487.8698418, "phase": "train", "update": 1151, "total_env_steps": 3683200, "episode_reward": 0.09081590920686722, "value_loss": 0.008227653801441193, "policy_loss": -0.0015442298397559285, "dist_entropy": 0.6504678964614868, "actor_grad_norm": 0.11345293372869492, "critic_grad_norm": 0.0608985498547554, "ratio": 1.0001375675201416, "entropy": 0.6504678964614868, "incre_win_rate": 0.04, "step": 1151}
{"time": 1767083492.7257354, "phase": "train", "update": 1152, "total_env_steps": 3686400, "episode_reward": 0.09360255300998688, "value_loss": 0.008261137828230857, "policy_loss": -0.002064830332172818, "dist_entropy": 0.6470762729644776, "actor_grad_norm": 0.15661802887916565, "critic_grad_norm": 0.0822104960680008, "ratio": 0.9998869299888611, "entropy": 0.6470762729644776, "incre_win_rate": 0.043478260869565216, "step": 1152}
{"time": 1767083497.1791167, "phase": "train", "update": 1153, "total_env_steps": 3689600, "episode_reward": 0.09823261946439743, "value_loss": 0.008656394481658936, "policy_loss": -0.0019877179792771927, "dist_entropy": 0.6127713799476624, "actor_grad_norm": 0.14892874658107758, "critic_grad_norm": 0.06968380510807037, "ratio": 0.9999845623970032, "entropy": 0.6127713799476624, "incre_win_rate": 0.037037037037037035, "step": 1153}
{"time": 1767083501.7925918, "phase": "train", "update": 1154, "total_env_steps": 3692800, "episode_reward": 0.08848302811384201, "value_loss": 0.009329519048333169, "policy_loss": -0.002223039357922829, "dist_entropy": 0.6477044105529786, "actor_grad_norm": 0.1897159069776535, "critic_grad_norm": 0.06564236432313919, "ratio": 0.9996346831321716, "entropy": 0.6477044105529786, "incre_win_rate": 0.0, "step": 1154}
{"time": 1767083506.546921, "phase": "train", "update": 1155, "total_env_steps": 3696000, "episode_reward": 0.09386797249317169, "value_loss": 0.00734397042542696, "policy_loss": -0.0023813022136778272, "dist_entropy": 0.6182561397552491, "actor_grad_norm": 0.1559595912694931, "critic_grad_norm": 0.03932614251971245, "ratio": 1.0000637769699097, "entropy": 0.6182561397552491, "incre_win_rate": 0.04, "step": 1155}
{"time": 1767083511.1952076, "phase": "train", "update": 1156, "total_env_steps": 3699200, "episode_reward": 0.10896264016628265, "value_loss": 0.01088837068527937, "policy_loss": -0.0022017061023035466, "dist_entropy": 0.6035005331039429, "actor_grad_norm": 0.17204070091247559, "critic_grad_norm": 0.024223653599619865, "ratio": 0.9997567534446716, "entropy": 0.6035005331039429, "incre_win_rate": 0.1111111111111111, "step": 1156}
{"time": 1767083515.5697494, "phase": "train", "update": 1157, "total_env_steps": 3702400, "episode_reward": 0.08918151259422302, "value_loss": 0.008850505575537682, "policy_loss": -0.0016085917660980443, "dist_entropy": 0.6340747833251953, "actor_grad_norm": 0.167423814535141, "critic_grad_norm": 0.08104288578033447, "ratio": 0.9998759627342224, "entropy": 0.6340747833251953, "incre_win_rate": 0.043478260869565216, "step": 1157}
{"time": 1767083520.3003616, "phase": "train", "update": 1158, "total_env_steps": 3705600, "episode_reward": 0.10823313891887665, "value_loss": 0.009195814654231072, "policy_loss": -0.0016923511810421842, "dist_entropy": 0.5828089475631714, "actor_grad_norm": 0.1630059778690338, "critic_grad_norm": 0.09654694050550461, "ratio": 1.0003339052200317, "entropy": 0.5828089475631714, "incre_win_rate": 0.03571428571428571, "step": 1158}
{"time": 1767083524.989109, "phase": "train", "update": 1159, "total_env_steps": 3708800, "episode_reward": 0.10847941040992737, "value_loss": 0.01230146996676922, "policy_loss": -0.0015655670873002236, "dist_entropy": 0.5584621906280518, "actor_grad_norm": 0.16272281110286713, "critic_grad_norm": 0.10907310247421265, "ratio": 0.9998876452445984, "entropy": 0.5584621906280518, "incre_win_rate": 0.06896551724137931, "step": 1159}
{"time": 1767083529.6438868, "phase": "train", "update": 1160, "total_env_steps": 3712000, "episode_reward": 0.09073883295059204, "value_loss": 0.00836782418191433, "policy_loss": -0.00198356561280022, "dist_entropy": 0.6024116039276123, "actor_grad_norm": 0.17031528055667877, "critic_grad_norm": 0.05318876728415489, "ratio": 1.0000982284545898, "entropy": 0.6024116039276123, "incre_win_rate": 0.0, "step": 1160}
{"time": 1767083534.4434419, "phase": "train", "update": 1161, "total_env_steps": 3715200, "episode_reward": 0.09976407140493393, "value_loss": 0.00927284937351942, "policy_loss": -0.002191876365360912, "dist_entropy": 0.5931799411773682, "actor_grad_norm": 0.13597528636455536, "critic_grad_norm": 0.05912336707115173, "ratio": 0.9998747110366821, "entropy": 0.5931799411773682, "incre_win_rate": 0.07407407407407407, "step": 1161}
{"time": 1767083551.149063, "phase": "eval", "update": 1161, "total_env_steps": 3715200, "eval_win_rate": 0.0625, "eval_episode_reward": 12.09183567880793, "step": 1161}
{"time": 1767083555.8338878, "phase": "train", "update": 1162, "total_env_steps": 3718400, "episode_reward": 0.1028735414147377, "value_loss": 0.01043755616992712, "policy_loss": -0.001331355613944929, "dist_entropy": 0.613789975643158, "actor_grad_norm": 0.1465843766927719, "critic_grad_norm": 0.05351356416940689, "ratio": 0.9999885559082031, "entropy": 0.613789975643158, "incre_win_rate": 0.03571428571428571, "step": 1162}
{"time": 1767083560.431654, "phase": "train", "update": 1163, "total_env_steps": 3721600, "episode_reward": 0.108843132853508, "value_loss": 0.010586622543632985, "policy_loss": -0.002233063285942194, "dist_entropy": 0.5778856396675109, "actor_grad_norm": 0.13422057032585144, "critic_grad_norm": 0.04987841844558716, "ratio": 0.9997798800468445, "entropy": 0.5778856396675109, "incre_win_rate": 0.0, "step": 1163}
{"time": 1767083565.1387632, "phase": "train", "update": 1164, "total_env_steps": 3724800, "episode_reward": 0.09563586860895157, "value_loss": 0.011101227812469005, "policy_loss": -0.0022224311210067072, "dist_entropy": 0.6291793704032898, "actor_grad_norm": 0.2154749482870102, "critic_grad_norm": 0.08840332180261612, "ratio": 0.9999532699584961, "entropy": 0.6291793704032898, "incre_win_rate": 0.08333333333333333, "step": 1164}
{"time": 1767083570.1733189, "phase": "train", "update": 1165, "total_env_steps": 3728000, "episode_reward": 0.10893315076828003, "value_loss": 0.01078491136431694, "policy_loss": -0.0016964279959680085, "dist_entropy": 0.6205965757369996, "actor_grad_norm": 0.15713296830654144, "critic_grad_norm": 0.03943387046456337, "ratio": 1.0000771284103394, "entropy": 0.6205965757369996, "incre_win_rate": 0.07407407407407407, "step": 1165}
{"time": 1767083575.1096437, "phase": "train", "update": 1166, "total_env_steps": 3731200, "episode_reward": 0.1051531508564949, "value_loss": 0.012765123322606087, "policy_loss": -0.0016816681015995982, "dist_entropy": 0.6125665903091431, "actor_grad_norm": 0.13003091514110565, "critic_grad_norm": 0.034895941615104675, "ratio": 0.9995752573013306, "entropy": 0.6125665903091431, "incre_win_rate": 0.07692307692307693, "step": 1166}
{"time": 1767083579.6807191, "phase": "train", "update": 1167, "total_env_steps": 3734400, "episode_reward": 0.10699813812971115, "value_loss": 0.01150030605494976, "policy_loss": -0.0019037295249006547, "dist_entropy": 0.576359486579895, "actor_grad_norm": 0.14284329116344452, "critic_grad_norm": 0.039663005620241165, "ratio": 0.9999721646308899, "entropy": 0.576359486579895, "incre_win_rate": 0.0, "step": 1167}
{"time": 1767083584.1730092, "phase": "train", "update": 1168, "total_env_steps": 3737600, "episode_reward": 0.09088576585054398, "value_loss": 0.009228468500077724, "policy_loss": -0.002122778856150376, "dist_entropy": 0.6627711176872253, "actor_grad_norm": 0.14433613419532776, "critic_grad_norm": 0.08484917134046555, "ratio": 1.0000265836715698, "entropy": 0.6627711176872253, "incre_win_rate": 0.08, "step": 1168}
{"time": 1767083588.6676433, "phase": "train", "update": 1169, "total_env_steps": 3740800, "episode_reward": 0.10201055556535721, "value_loss": 0.010543049499392509, "policy_loss": -0.002153195876856984, "dist_entropy": 0.6046723008155823, "actor_grad_norm": 0.1566244661808014, "critic_grad_norm": 0.051417674869298935, "ratio": 0.99982750415802, "entropy": 0.6046723008155823, "incre_win_rate": 0.0, "step": 1169}
{"time": 1767083593.6815693, "phase": "train", "update": 1170, "total_env_steps": 3744000, "episode_reward": 0.10599491745233536, "value_loss": 0.012757210060954094, "policy_loss": -0.0014874307082699545, "dist_entropy": 0.5788604497909546, "actor_grad_norm": 0.2356094866991043, "critic_grad_norm": 0.04895011708140373, "ratio": 1.0001070499420166, "entropy": 0.5788604497909546, "incre_win_rate": 0.037037037037037035, "step": 1170}
{"time": 1767083598.2610111, "phase": "train", "update": 1171, "total_env_steps": 3747200, "episode_reward": 0.09975218027830124, "value_loss": 0.009012883715331554, "policy_loss": -0.0019026120536040025, "dist_entropy": 0.6475684881210327, "actor_grad_norm": 0.19414527714252472, "critic_grad_norm": 0.03832487389445305, "ratio": 0.9996480941772461, "entropy": 0.6475684881210327, "incre_win_rate": 0.08, "step": 1171}
{"time": 1767083602.715563, "phase": "train", "update": 1172, "total_env_steps": 3750400, "episode_reward": 0.09123344719409943, "value_loss": 0.0076939879916608335, "policy_loss": -0.0024487902863672417, "dist_entropy": 0.6699036002159119, "actor_grad_norm": 0.16832250356674194, "critic_grad_norm": 0.03319088742136955, "ratio": 0.999932587146759, "entropy": 0.6699036002159119, "incre_win_rate": 0.08695652173913043, "step": 1172}
{"time": 1767083607.3236864, "phase": "train", "update": 1173, "total_env_steps": 3753600, "episode_reward": 0.09898903965950012, "value_loss": 0.010620053298771382, "policy_loss": -0.001577581285492613, "dist_entropy": 0.6392812132835388, "actor_grad_norm": 0.1261383444070816, "critic_grad_norm": 0.09372811764478683, "ratio": 0.9999821782112122, "entropy": 0.6392812132835388, "incre_win_rate": 0.04, "step": 1173}
{"time": 1767083611.7610571, "phase": "train", "update": 1174, "total_env_steps": 3756800, "episode_reward": 0.1018548235297203, "value_loss": 0.01035836935043335, "policy_loss": -0.0024973097770921273, "dist_entropy": 0.6456580758094788, "actor_grad_norm": 0.13252218067646027, "critic_grad_norm": 0.05101499706506729, "ratio": 0.9998669028282166, "entropy": 0.6456580758094788, "incre_win_rate": 0.07692307692307693, "step": 1174}
{"time": 1767083616.1762135, "phase": "train", "update": 1175, "total_env_steps": 3760000, "episode_reward": 0.10552359372377396, "value_loss": 0.009989264607429504, "policy_loss": -0.0018829033705404896, "dist_entropy": 0.6041164040565491, "actor_grad_norm": 0.15789107978343964, "critic_grad_norm": 0.05166241154074669, "ratio": 1.0000147819519043, "entropy": 0.6041164040565491, "incre_win_rate": 0.0, "step": 1175}
{"time": 1767083620.6642356, "phase": "train", "update": 1176, "total_env_steps": 3763200, "episode_reward": 0.11281611770391464, "value_loss": 0.01064414121210575, "policy_loss": -0.0018747224523458783, "dist_entropy": 0.5696858763694763, "actor_grad_norm": 0.1369476616382599, "critic_grad_norm": 0.06656797975301743, "ratio": 1.000112771987915, "entropy": 0.5696858763694763, "incre_win_rate": 0.10714285714285714, "step": 1176}
{"time": 1767083625.0969126, "phase": "train", "update": 1177, "total_env_steps": 3766400, "episode_reward": 0.09325279295444489, "value_loss": 0.00790743501856923, "policy_loss": -0.0021721777407337937, "dist_entropy": 0.6014498591423034, "actor_grad_norm": 0.15175051987171173, "critic_grad_norm": 0.029341846704483032, "ratio": 0.9999904036521912, "entropy": 0.6014498591423034, "incre_win_rate": 0.0, "step": 1177}
{"time": 1767083629.5281537, "phase": "train", "update": 1178, "total_env_steps": 3769600, "episode_reward": 0.10618274658918381, "value_loss": 0.010520715452730655, "policy_loss": -0.002215289711221402, "dist_entropy": 0.5710535168647766, "actor_grad_norm": 0.12767432630062103, "critic_grad_norm": 0.07054245471954346, "ratio": 1.000116229057312, "entropy": 0.5710535168647766, "incre_win_rate": 0.037037037037037035, "step": 1178}
{"time": 1767083633.8949363, "phase": "train", "update": 1179, "total_env_steps": 3772800, "episode_reward": 0.09694847464561462, "value_loss": 0.010748294740915298, "policy_loss": -0.0022198196130425174, "dist_entropy": 0.5949440598487854, "actor_grad_norm": 0.13417384028434753, "critic_grad_norm": 0.025363484397530556, "ratio": 1.0001366138458252, "entropy": 0.5949440598487854, "incre_win_rate": 0.041666666666666664, "step": 1179}
{"time": 1767083638.3334315, "phase": "train", "update": 1180, "total_env_steps": 3776000, "episode_reward": 0.10667580366134644, "value_loss": 0.008424243703484536, "policy_loss": -0.001735461447330716, "dist_entropy": 0.6003459453582763, "actor_grad_norm": 0.138509139418602, "critic_grad_norm": 0.025827785953879356, "ratio": 1.0000981092453003, "entropy": 0.6003459453582763, "incre_win_rate": 0.038461538461538464, "step": 1180}
{"time": 1767083642.7375102, "phase": "train", "update": 1181, "total_env_steps": 3779200, "episode_reward": 0.08934862166643143, "value_loss": 0.008746541664004326, "policy_loss": -0.002155173465096283, "dist_entropy": 0.6360304117202759, "actor_grad_norm": 0.1671002209186554, "critic_grad_norm": 0.12067927420139313, "ratio": 0.9996656775474548, "entropy": 0.6360304117202759, "incre_win_rate": 0.0, "step": 1181}
{"time": 1767083659.558958, "phase": "eval", "update": 1181, "total_env_steps": 3779200, "eval_win_rate": 0.15625, "eval_episode_reward": 13.872413079470181, "step": 1181}
{"time": 1767083664.7604685, "phase": "train", "update": 1182, "total_env_steps": 3782400, "episode_reward": 0.10063793510198593, "value_loss": 0.011051245592534542, "policy_loss": -0.001782320176135599, "dist_entropy": 0.608509874343872, "actor_grad_norm": 0.18171098828315735, "critic_grad_norm": 0.1035870909690857, "ratio": 0.9997448325157166, "entropy": 0.608509874343872, "incre_win_rate": 0.037037037037037035, "step": 1182}
{"time": 1767083669.4485729, "phase": "train", "update": 1183, "total_env_steps": 3785600, "episode_reward": 0.12143884599208832, "value_loss": 0.01266319938004017, "policy_loss": -0.0021045119801929245, "dist_entropy": 0.5341779232025147, "actor_grad_norm": 0.18343301117420197, "critic_grad_norm": 0.12124083191156387, "ratio": 1.0000377893447876, "entropy": 0.5341779232025147, "incre_win_rate": 0.10344827586206896, "step": 1183}
{"time": 1767083674.1726894, "phase": "train", "update": 1184, "total_env_steps": 3788800, "episode_reward": 0.11257243901491165, "value_loss": 0.009302197769284249, "policy_loss": -0.0014517222347862457, "dist_entropy": 0.5688228011131287, "actor_grad_norm": 0.20324347913265228, "critic_grad_norm": 0.019557952880859375, "ratio": 1.000158667564392, "entropy": 0.5688228011131287, "incre_win_rate": 0.03333333333333333, "step": 1184}
{"time": 1767083678.8484836, "phase": "train", "update": 1185, "total_env_steps": 3792000, "episode_reward": 0.10551531612873077, "value_loss": 0.009190741740167142, "policy_loss": -0.0018555292682176372, "dist_entropy": 0.5886291623115539, "actor_grad_norm": 0.1869288682937622, "critic_grad_norm": 0.036739807575941086, "ratio": 0.9999029040336609, "entropy": 0.5886291623115539, "incre_win_rate": 0.07692307692307693, "step": 1185}
{"time": 1767083683.2983248, "phase": "train", "update": 1186, "total_env_steps": 3795200, "episode_reward": 0.09907854348421097, "value_loss": 0.008869279734790325, "policy_loss": -0.0029088829746960697, "dist_entropy": 0.5970293164253235, "actor_grad_norm": 0.18093667924404144, "critic_grad_norm": 0.02573557198047638, "ratio": 1.00014066696167, "entropy": 0.5970293164253235, "incre_win_rate": 0.043478260869565216, "step": 1186}
{"time": 1767083687.6570768, "phase": "train", "update": 1187, "total_env_steps": 3798400, "episode_reward": 0.09703332185745239, "value_loss": 0.01000459548085928, "policy_loss": -0.002430962370269185, "dist_entropy": 0.6413096189498901, "actor_grad_norm": 0.17610041797161102, "critic_grad_norm": 0.015708792954683304, "ratio": 0.9998591542243958, "entropy": 0.6413096189498901, "incre_win_rate": 0.04, "step": 1187}
{"time": 1767083692.255864, "phase": "train", "update": 1188, "total_env_steps": 3801600, "episode_reward": 0.09855961054563522, "value_loss": 0.012077567540109158, "policy_loss": -0.0024797104569657335, "dist_entropy": 0.5661900639533997, "actor_grad_norm": 0.1441417783498764, "critic_grad_norm": 0.03884071484208107, "ratio": 1.0000584125518799, "entropy": 0.5661900639533997, "incre_win_rate": 0.03571428571428571, "step": 1188}
{"time": 1767083696.734429, "phase": "train", "update": 1189, "total_env_steps": 3804800, "episode_reward": 0.11277110874652863, "value_loss": 0.012458318285644055, "policy_loss": -0.001435109536118162, "dist_entropy": 0.5584888458251953, "actor_grad_norm": 0.13127826154232025, "critic_grad_norm": 0.10599841922521591, "ratio": 0.9999853372573853, "entropy": 0.5584888458251953, "incre_win_rate": 0.04, "step": 1189}
{"time": 1767083701.2601156, "phase": "train", "update": 1190, "total_env_steps": 3808000, "episode_reward": 0.10473665595054626, "value_loss": 0.011635206080973149, "policy_loss": -0.0022322113564570145, "dist_entropy": 0.5743597745895386, "actor_grad_norm": 0.19667918980121613, "critic_grad_norm": 0.06952804327011108, "ratio": 0.9999479651451111, "entropy": 0.5743597745895386, "incre_win_rate": 0.037037037037037035, "step": 1190}
{"time": 1767083705.7905316, "phase": "train", "update": 1191, "total_env_steps": 3811200, "episode_reward": 0.10400247573852539, "value_loss": 0.011407150700688363, "policy_loss": -0.001639831744949838, "dist_entropy": 0.594404649734497, "actor_grad_norm": 0.14883442223072052, "critic_grad_norm": 0.10488402843475342, "ratio": 0.9997647404670715, "entropy": 0.594404649734497, "incre_win_rate": 0.038461538461538464, "step": 1191}
{"time": 1767083710.2436512, "phase": "train", "update": 1192, "total_env_steps": 3814400, "episode_reward": 0.09809654206037521, "value_loss": 0.00960177443921566, "policy_loss": -0.002499756323898339, "dist_entropy": 0.6319964528083801, "actor_grad_norm": 0.14254449307918549, "critic_grad_norm": 0.046125732362270355, "ratio": 1.00043523311615, "entropy": 0.6319964528083801, "incre_win_rate": 0.041666666666666664, "step": 1192}
{"time": 1767083714.8957217, "phase": "train", "update": 1193, "total_env_steps": 3817600, "episode_reward": 0.10281715542078018, "value_loss": 0.010567893832921981, "policy_loss": -0.0019402273057600894, "dist_entropy": 0.6112280130386353, "actor_grad_norm": 0.17957305908203125, "critic_grad_norm": 0.05535126477479935, "ratio": 1.0000290870666504, "entropy": 0.6112280130386353, "incre_win_rate": 0.0, "step": 1193}
{"time": 1767083719.4617178, "phase": "train", "update": 1194, "total_env_steps": 3820800, "episode_reward": 0.10330349206924438, "value_loss": 0.009772682003676892, "policy_loss": -0.002522516310007461, "dist_entropy": 0.560530424118042, "actor_grad_norm": 0.18456988036632538, "critic_grad_norm": 0.11685039103031158, "ratio": 0.999769389629364, "entropy": 0.560530424118042, "incre_win_rate": 0.03571428571428571, "step": 1194}
{"time": 1767083723.928617, "phase": "train", "update": 1195, "total_env_steps": 3824000, "episode_reward": 0.10504657030105591, "value_loss": 0.008198712952435017, "policy_loss": -0.0014340625526263473, "dist_entropy": 0.5493788003921509, "actor_grad_norm": 0.16682112216949463, "critic_grad_norm": 0.06216544657945633, "ratio": 0.9999740719795227, "entropy": 0.5493788003921509, "incre_win_rate": 0.037037037037037035, "step": 1195}
{"time": 1767083728.4515204, "phase": "train", "update": 1196, "total_env_steps": 3827200, "episode_reward": 0.10762573033571243, "value_loss": 0.009371410496532917, "policy_loss": -0.0020682598878316583, "dist_entropy": 0.5687242031097413, "actor_grad_norm": 0.14395363628864288, "critic_grad_norm": 0.048152144998311996, "ratio": 0.9997698068618774, "entropy": 0.5687242031097413, "incre_win_rate": 0.04, "step": 1196}
{"time": 1767083733.032013, "phase": "train", "update": 1197, "total_env_steps": 3830400, "episode_reward": 0.10683879256248474, "value_loss": 0.009445147775113582, "policy_loss": -0.0021416426428643833, "dist_entropy": 0.54381343126297, "actor_grad_norm": 0.17774271965026855, "critic_grad_norm": 0.02552732639014721, "ratio": 0.9999986886978149, "entropy": 0.54381343126297, "incre_win_rate": 0.03333333333333333, "step": 1197}
{"time": 1767083737.688603, "phase": "train", "update": 1198, "total_env_steps": 3833600, "episode_reward": 0.09798583388328552, "value_loss": 0.0074266866780817505, "policy_loss": -0.002233476673861645, "dist_entropy": 0.5634371161460876, "actor_grad_norm": 0.1535937339067459, "critic_grad_norm": 0.03185209259390831, "ratio": 0.9997343420982361, "entropy": 0.5634371161460876, "incre_win_rate": 0.0, "step": 1198}
{"time": 1767083742.332902, "phase": "train", "update": 1199, "total_env_steps": 3836800, "episode_reward": 0.11539734154939651, "value_loss": 0.009486961737275123, "policy_loss": -0.0016983617900613978, "dist_entropy": 0.5167821049690247, "actor_grad_norm": 0.1627662181854248, "critic_grad_norm": 0.04212033376097679, "ratio": 1.0001972913742065, "entropy": 0.5167821049690247, "incre_win_rate": 0.0, "step": 1199}
{"time": 1767083747.0186942, "phase": "train", "update": 1200, "total_env_steps": 3840000, "episode_reward": 0.09257398545742035, "value_loss": 0.00819760300219059, "policy_loss": -0.00193554927891757, "dist_entropy": 0.6048379898071289, "actor_grad_norm": 0.1469515711069107, "critic_grad_norm": 0.0644824355840683, "ratio": 0.9996785521507263, "entropy": 0.6048379898071289, "incre_win_rate": 0.038461538461538464, "step": 1200}
{"time": 1767083751.9496982, "phase": "train", "update": 1201, "total_env_steps": 3843200, "episode_reward": 0.11589249968528748, "value_loss": 0.01018776074051857, "policy_loss": -0.002052227299358833, "dist_entropy": 0.5381149411201477, "actor_grad_norm": 0.19580495357513428, "critic_grad_norm": 0.04670858010649681, "ratio": 0.9997251629829407, "entropy": 0.5381149411201477, "incre_win_rate": 0.0, "step": 1201}
{"time": 1767083771.2014792, "phase": "eval", "update": 1201, "total_env_steps": 3843200, "eval_win_rate": 0.1875, "eval_episode_reward": 14.774420529801306, "step": 1201}
{"time": 1767083775.9227235, "phase": "train", "update": 1202, "total_env_steps": 3846400, "episode_reward": 0.11956487596035004, "value_loss": 0.013883416540920734, "policy_loss": -0.0015224377163832515, "dist_entropy": 0.5382413387298584, "actor_grad_norm": 0.15230479836463928, "critic_grad_norm": 0.03795969858765602, "ratio": 1.0000628232955933, "entropy": 0.5382413387298584, "incre_win_rate": 0.03125, "step": 1202}
{"time": 1767083780.3739758, "phase": "train", "update": 1203, "total_env_steps": 3849600, "episode_reward": 0.10270850360393524, "value_loss": 0.010702646896243095, "policy_loss": -0.002290978976289182, "dist_entropy": 0.5784287691116333, "actor_grad_norm": 0.18549524247646332, "critic_grad_norm": 0.05503096058964729, "ratio": 1.0001899003982544, "entropy": 0.5784287691116333, "incre_win_rate": 0.038461538461538464, "step": 1203}
{"time": 1767083784.8349378, "phase": "train", "update": 1204, "total_env_steps": 3852800, "episode_reward": 0.1118946522474289, "value_loss": 0.009648655541241169, "policy_loss": -0.00176925485082009, "dist_entropy": 0.5463611006736755, "actor_grad_norm": 0.18865595757961273, "critic_grad_norm": 0.07190309464931488, "ratio": 0.9999333620071411, "entropy": 0.5463611006736755, "incre_win_rate": 0.043478260869565216, "step": 1204}
{"time": 1767083789.322392, "phase": "train", "update": 1205, "total_env_steps": 3856000, "episode_reward": 0.1159183606505394, "value_loss": 0.013621538318693638, "policy_loss": -0.0024491753879118507, "dist_entropy": 0.5315486073493958, "actor_grad_norm": 0.2032880336046219, "critic_grad_norm": 0.06553665548563004, "ratio": 0.9996014833450317, "entropy": 0.5315486073493958, "incre_win_rate": 0.07142857142857142, "step": 1205}
{"time": 1767083793.8138442, "phase": "train", "update": 1206, "total_env_steps": 3859200, "episode_reward": 0.10522609949111938, "value_loss": 0.011400331556797028, "policy_loss": -0.0021464226483486116, "dist_entropy": 0.5646823763847351, "actor_grad_norm": 0.15412817895412445, "critic_grad_norm": 0.08463406562805176, "ratio": 1.0000886917114258, "entropy": 0.5646823763847351, "incre_win_rate": 0.08333333333333333, "step": 1206}
{"time": 1767083798.232356, "phase": "train", "update": 1207, "total_env_steps": 3862400, "episode_reward": 0.09510967880487442, "value_loss": 0.008185552805662155, "policy_loss": -0.0019059767772560577, "dist_entropy": 0.5858641982078552, "actor_grad_norm": 0.1335824728012085, "critic_grad_norm": 0.08689375221729279, "ratio": 0.9999152421951294, "entropy": 0.5858641982078552, "incre_win_rate": 0.0, "step": 1207}
{"time": 1767083802.6580408, "phase": "train", "update": 1208, "total_env_steps": 3865600, "episode_reward": 0.10308361053466797, "value_loss": 0.00966218113899231, "policy_loss": -0.0026564899561094535, "dist_entropy": 0.5686967372894287, "actor_grad_norm": 0.20421157777309418, "critic_grad_norm": 0.08367495983839035, "ratio": 0.9995521903038025, "entropy": 0.5686967372894287, "incre_win_rate": 0.038461538461538464, "step": 1208}
{"time": 1767083807.258351, "phase": "train", "update": 1209, "total_env_steps": 3868800, "episode_reward": 0.09978839755058289, "value_loss": 0.01111829336732626, "policy_loss": -0.0016495411948170614, "dist_entropy": 0.5802677869796753, "actor_grad_norm": 0.2056436538696289, "critic_grad_norm": 0.058920979499816895, "ratio": 0.9997175335884094, "entropy": 0.5802677869796753, "incre_win_rate": 0.04, "step": 1209}
{"time": 1767083811.650394, "phase": "train", "update": 1210, "total_env_steps": 3872000, "episode_reward": 0.11741100251674652, "value_loss": 0.009149488620460033, "policy_loss": -0.0015911961194390756, "dist_entropy": 0.5527406215667725, "actor_grad_norm": 0.15275044739246368, "critic_grad_norm": 0.06557492911815643, "ratio": 0.9999399185180664, "entropy": 0.5527406215667725, "incre_win_rate": 0.038461538461538464, "step": 1210}
{"time": 1767083816.0000994, "phase": "train", "update": 1211, "total_env_steps": 3875200, "episode_reward": 0.09428653120994568, "value_loss": 0.015077035687863827, "policy_loss": -0.002634847428628717, "dist_entropy": 0.6035036683082581, "actor_grad_norm": 0.1328166425228119, "critic_grad_norm": 0.04631916433572769, "ratio": 0.9998421669006348, "entropy": 0.6035036683082581, "incre_win_rate": 0.04, "step": 1211}
{"time": 1767083820.4365652, "phase": "train", "update": 1212, "total_env_steps": 3878400, "episode_reward": 0.10174979269504547, "value_loss": 0.010664175823330879, "policy_loss": -0.0022816649226468757, "dist_entropy": 0.5547462105751038, "actor_grad_norm": 0.16871583461761475, "critic_grad_norm": 0.027475763112306595, "ratio": 0.9998993277549744, "entropy": 0.5547462105751038, "incre_win_rate": 0.04, "step": 1212}
{"time": 1767083825.046003, "phase": "train", "update": 1213, "total_env_steps": 3881600, "episode_reward": 0.11206746846437454, "value_loss": 0.009664281271398067, "policy_loss": -0.0014680436716384194, "dist_entropy": 0.5294836163520813, "actor_grad_norm": 0.14035053551197052, "critic_grad_norm": 0.03166012093424797, "ratio": 1.0000251531600952, "entropy": 0.5294836163520813, "incre_win_rate": 0.07407407407407407, "step": 1213}
{"time": 1767083829.4955797, "phase": "train", "update": 1214, "total_env_steps": 3884800, "episode_reward": 0.11266400665044785, "value_loss": 0.010775093547999859, "policy_loss": -0.0013892908303816398, "dist_entropy": 0.5369773983955384, "actor_grad_norm": 0.15607644617557526, "critic_grad_norm": 0.036605849862098694, "ratio": 0.9995967149734497, "entropy": 0.5369773983955384, "incre_win_rate": 0.0, "step": 1214}
{"time": 1767083833.957189, "phase": "train", "update": 1215, "total_env_steps": 3888000, "episode_reward": 0.09598769247531891, "value_loss": 0.0075411337427794935, "policy_loss": -0.0019104917684764188, "dist_entropy": 0.5681575179100037, "actor_grad_norm": 0.1693430244922638, "critic_grad_norm": 0.030473655089735985, "ratio": 0.9999194145202637, "entropy": 0.5681575179100037, "incre_win_rate": 0.0, "step": 1215}
{"time": 1767083838.55637, "phase": "train", "update": 1216, "total_env_steps": 3891200, "episode_reward": 0.10779853165149689, "value_loss": 0.011354196257889271, "policy_loss": -0.0014829025297885324, "dist_entropy": 0.5720778584480286, "actor_grad_norm": 0.14436101913452148, "critic_grad_norm": 0.10305514186620712, "ratio": 0.9997391700744629, "entropy": 0.5720778584480286, "incre_win_rate": 0.08695652173913043, "step": 1216}
{"time": 1767083842.9609408, "phase": "train", "update": 1217, "total_env_steps": 3894400, "episode_reward": 0.09895746409893036, "value_loss": 0.009672351740300655, "policy_loss": -0.002066705456408968, "dist_entropy": 0.5647361874580383, "actor_grad_norm": 0.16834741830825806, "critic_grad_norm": 0.06501417607069016, "ratio": 0.9999112486839294, "entropy": 0.5647361874580383, "incre_win_rate": 0.038461538461538464, "step": 1217}
{"time": 1767083847.4679883, "phase": "train", "update": 1218, "total_env_steps": 3897600, "episode_reward": 0.11204676330089569, "value_loss": 0.01008687037974596, "policy_loss": -0.002156378855686114, "dist_entropy": 0.5492413520812989, "actor_grad_norm": 0.1576259583234787, "critic_grad_norm": 0.06440469622612, "ratio": 0.9999586343765259, "entropy": 0.5492413520812989, "incre_win_rate": 0.0, "step": 1218}
{"time": 1767083851.8795192, "phase": "train", "update": 1219, "total_env_steps": 3900800, "episode_reward": 0.11461662501096725, "value_loss": 0.011746377497911454, "policy_loss": -0.001639326125322782, "dist_entropy": 0.5280864238739014, "actor_grad_norm": 0.17418503761291504, "critic_grad_norm": 0.08285091817378998, "ratio": 1.000057339668274, "entropy": 0.5280864238739014, "incre_win_rate": 0.03571428571428571, "step": 1219}
{"time": 1767083856.3493745, "phase": "train", "update": 1220, "total_env_steps": 3904000, "episode_reward": 0.10630019009113312, "value_loss": 0.007618672586977482, "policy_loss": -0.0016326281070522697, "dist_entropy": 0.5378514051437377, "actor_grad_norm": 0.12877221405506134, "critic_grad_norm": 0.04107753187417984, "ratio": 0.9999324679374695, "entropy": 0.5378514051437377, "incre_win_rate": 0.0, "step": 1220}
{"time": 1767083861.1735656, "phase": "train", "update": 1221, "total_env_steps": 3907200, "episode_reward": 0.10114030539989471, "value_loss": 0.009532797336578368, "policy_loss": -0.0024802128231257827, "dist_entropy": 0.55678471326828, "actor_grad_norm": 0.1929597109556198, "critic_grad_norm": 0.03638628125190735, "ratio": 1.000149130821228, "entropy": 0.55678471326828, "incre_win_rate": 0.04, "step": 1221}
{"time": 1767083879.9879787, "phase": "eval", "update": 1221, "total_env_steps": 3907200, "eval_win_rate": 0.15625, "eval_episode_reward": 14.318812086092702, "step": 1221}
{"time": 1767083884.5247996, "phase": "train", "update": 1222, "total_env_steps": 3910400, "episode_reward": 0.1079728901386261, "value_loss": 0.010522593557834626, "policy_loss": -0.0019570720909644736, "dist_entropy": 0.5357905626296997, "actor_grad_norm": 0.1786748617887497, "critic_grad_norm": 0.0711803063750267, "ratio": 1.0000333786010742, "entropy": 0.5357905626296997, "incre_win_rate": 0.08, "step": 1222}
{"time": 1767083889.086148, "phase": "train", "update": 1223, "total_env_steps": 3913600, "episode_reward": 0.10074348747730255, "value_loss": 0.012440711073577405, "policy_loss": -0.0022730048450455343, "dist_entropy": 0.5276773810386658, "actor_grad_norm": 0.1579592376947403, "critic_grad_norm": 0.05705273896455765, "ratio": 1.0003741979599, "entropy": 0.5276773810386658, "incre_win_rate": 0.04, "step": 1223}
{"time": 1767083893.5725243, "phase": "train", "update": 1224, "total_env_steps": 3916800, "episode_reward": 0.10089506953954697, "value_loss": 0.01328679621219635, "policy_loss": -0.0021147611991477965, "dist_entropy": 0.5683480620384216, "actor_grad_norm": 0.17331472039222717, "critic_grad_norm": 0.033164139837026596, "ratio": 0.9998646974563599, "entropy": 0.5683480620384216, "incre_win_rate": 0.0, "step": 1224}
{"time": 1767083898.2383852, "phase": "train", "update": 1225, "total_env_steps": 3920000, "episode_reward": 0.1102224737405777, "value_loss": 0.01118288692086935, "policy_loss": -0.0015686517959927926, "dist_entropy": 0.5566755533218384, "actor_grad_norm": 0.1567782312631607, "critic_grad_norm": 0.0303792804479599, "ratio": 0.9998543858528137, "entropy": 0.5566755533218384, "incre_win_rate": 0.07407407407407407, "step": 1225}
{"time": 1767083903.0481858, "phase": "train", "update": 1226, "total_env_steps": 3923200, "episode_reward": 0.11107822507619858, "value_loss": 0.01220853254199028, "policy_loss": -0.0019012291988843798, "dist_entropy": 0.529906940460205, "actor_grad_norm": 0.15290014445781708, "critic_grad_norm": 0.033203382045030594, "ratio": 0.9999940991401672, "entropy": 0.529906940460205, "incre_win_rate": 0.07692307692307693, "step": 1226}
{"time": 1767083907.6195858, "phase": "train", "update": 1227, "total_env_steps": 3926400, "episode_reward": 0.10916545987129211, "value_loss": 0.010372165590524673, "policy_loss": -0.0016628722253591022, "dist_entropy": 0.5358669638633728, "actor_grad_norm": 0.14879988133907318, "critic_grad_norm": 0.031360235065221786, "ratio": 0.9998685717582703, "entropy": 0.5358669638633728, "incre_win_rate": 0.038461538461538464, "step": 1227}
{"time": 1767083912.1053357, "phase": "train", "update": 1228, "total_env_steps": 3929600, "episode_reward": 0.10584747046232224, "value_loss": 0.012728522904217244, "policy_loss": -0.0015288823527360052, "dist_entropy": 0.5711260914802552, "actor_grad_norm": 0.19380496442317963, "critic_grad_norm": 0.025080690160393715, "ratio": 1.000306487083435, "entropy": 0.5711260914802552, "incre_win_rate": 0.07142857142857142, "step": 1228}
{"time": 1767083916.6700594, "phase": "train", "update": 1229, "total_env_steps": 3932800, "episode_reward": 0.0969303622841835, "value_loss": 0.009105939231812955, "policy_loss": -0.0022138992761631116, "dist_entropy": 0.5894096970558167, "actor_grad_norm": 0.21064893901348114, "critic_grad_norm": 0.03655014559626579, "ratio": 1.0000718832015991, "entropy": 0.5894096970558167, "incre_win_rate": 0.04, "step": 1229}
{"time": 1767083921.3653579, "phase": "train", "update": 1230, "total_env_steps": 3936000, "episode_reward": 0.12112944573163986, "value_loss": 0.010647186450660229, "policy_loss": -0.0016049700563755208, "dist_entropy": 0.5393918514251709, "actor_grad_norm": 0.24539390206336975, "critic_grad_norm": 0.018913308158516884, "ratio": 0.9998331069946289, "entropy": 0.5393918514251709, "incre_win_rate": 0.07142857142857142, "step": 1230}
{"time": 1767083925.9738057, "phase": "train", "update": 1231, "total_env_steps": 3939200, "episode_reward": 0.11177928745746613, "value_loss": 0.011804474331438542, "policy_loss": -0.0017881523821571931, "dist_entropy": 0.5248241662979126, "actor_grad_norm": 0.2975195348262787, "critic_grad_norm": 0.1186579018831253, "ratio": 1.000090479850769, "entropy": 0.5248241662979126, "incre_win_rate": 0.03333333333333333, "step": 1231}
{"time": 1767083930.5720685, "phase": "train", "update": 1232, "total_env_steps": 3942400, "episode_reward": 0.11945674568414688, "value_loss": 0.013352153636515141, "policy_loss": -0.0012478600451458987, "dist_entropy": 0.5377013564109803, "actor_grad_norm": 0.22642882168293, "critic_grad_norm": 0.037352558225393295, "ratio": 0.9997822642326355, "entropy": 0.5377013564109803, "incre_win_rate": 0.14285714285714285, "step": 1232}
{"time": 1767083935.1509948, "phase": "train", "update": 1233, "total_env_steps": 3945600, "episode_reward": 0.12369515746831894, "value_loss": 0.011378074809908868, "policy_loss": -0.001776245914435748, "dist_entropy": 0.502074933052063, "actor_grad_norm": 0.22476334869861603, "critic_grad_norm": 0.029369277879595757, "ratio": 0.9999524354934692, "entropy": 0.502074933052063, "incre_win_rate": 0.06666666666666667, "step": 1233}
{"time": 1767083939.6896563, "phase": "train", "update": 1234, "total_env_steps": 3948800, "episode_reward": 0.11192880570888519, "value_loss": 0.015202055312693119, "policy_loss": -0.0014581978519775164, "dist_entropy": 0.5641369581222534, "actor_grad_norm": 0.18607096374034882, "critic_grad_norm": 0.04348760470747948, "ratio": 1.0001013278961182, "entropy": 0.5641369581222534, "incre_win_rate": 0.1111111111111111, "step": 1234}
{"time": 1767083944.3020778, "phase": "train", "update": 1235, "total_env_steps": 3952000, "episode_reward": 0.11930463463068008, "value_loss": 0.016456732526421547, "policy_loss": -0.0017105041054215064, "dist_entropy": 0.5281654596328735, "actor_grad_norm": 0.16039156913757324, "critic_grad_norm": 0.042197756469249725, "ratio": 0.9997537732124329, "entropy": 0.5281654596328735, "incre_win_rate": 0.07142857142857142, "step": 1235}
{"time": 1767083949.2572803, "phase": "train", "update": 1236, "total_env_steps": 3955200, "episode_reward": 0.11721698939800262, "value_loss": 0.01285601481795311, "policy_loss": -0.0021870961277713264, "dist_entropy": 0.5524477481842041, "actor_grad_norm": 0.18874004483222961, "critic_grad_norm": 0.04366632178425789, "ratio": 0.9997879266738892, "entropy": 0.5524477481842041, "incre_win_rate": 0.03571428571428571, "step": 1236}
{"time": 1767083953.9224823, "phase": "train", "update": 1237, "total_env_steps": 3958400, "episode_reward": 0.11674462258815765, "value_loss": 0.013168138824403286, "policy_loss": -0.001963267206264163, "dist_entropy": 0.5265542507171631, "actor_grad_norm": 0.15181174874305725, "critic_grad_norm": 0.03697943314909935, "ratio": 1.0000126361846924, "entropy": 0.5265542507171631, "incre_win_rate": 0.07407407407407407, "step": 1237}
{"time": 1767083958.6560962, "phase": "train", "update": 1238, "total_env_steps": 3961600, "episode_reward": 0.12068295478820801, "value_loss": 0.014769102819263935, "policy_loss": -0.0016220344327990688, "dist_entropy": 0.5326639652252197, "actor_grad_norm": 0.13464535772800446, "critic_grad_norm": 0.034632351249456406, "ratio": 0.9998788833618164, "entropy": 0.5326639652252197, "incre_win_rate": 0.10344827586206896, "step": 1238}
{"time": 1767083963.3157213, "phase": "train", "update": 1239, "total_env_steps": 3964800, "episode_reward": 0.10408268123865128, "value_loss": 0.015972633101046085, "policy_loss": -0.001531800192044841, "dist_entropy": 0.56980881690979, "actor_grad_norm": 0.13015522062778473, "critic_grad_norm": 0.09837305545806885, "ratio": 0.9999400973320007, "entropy": 0.56980881690979, "incre_win_rate": 0.041666666666666664, "step": 1239}
{"time": 1767083967.8856232, "phase": "train", "update": 1240, "total_env_steps": 3968000, "episode_reward": 0.10261744260787964, "value_loss": 0.014720258675515652, "policy_loss": -0.0019980781385328327, "dist_entropy": 0.5577216625213623, "actor_grad_norm": 0.24679432809352875, "critic_grad_norm": 0.07326506823301315, "ratio": 1.0001283884048462, "entropy": 0.5577216625213623, "incre_win_rate": 0.08333333333333333, "step": 1240}
{"time": 1767083972.4612577, "phase": "train", "update": 1241, "total_env_steps": 3971200, "episode_reward": 0.10472474992275238, "value_loss": 0.01283334195613861, "policy_loss": -0.0015751858245394601, "dist_entropy": 0.5413937211036682, "actor_grad_norm": 0.18165694177150726, "critic_grad_norm": 0.09309493750333786, "ratio": 1.0002042055130005, "entropy": 0.5413937211036682, "incre_win_rate": 0.0, "step": 1241}
{"time": 1767083988.382825, "phase": "eval", "update": 1241, "total_env_steps": 3971200, "eval_win_rate": 0.28125, "eval_episode_reward": 15.676169288079459, "step": 1241}
{"time": 1767083992.9580748, "phase": "train", "update": 1242, "total_env_steps": 3974400, "episode_reward": 0.11419133096933365, "value_loss": 0.01097818035632372, "policy_loss": -0.0016202644195674409, "dist_entropy": 0.5365455508232116, "actor_grad_norm": 0.15968208014965057, "critic_grad_norm": 0.07178717106580734, "ratio": 0.999884307384491, "entropy": 0.5365455508232116, "incre_win_rate": 0.07142857142857142, "step": 1242}
{"time": 1767083997.8015504, "phase": "train", "update": 1243, "total_env_steps": 3977600, "episode_reward": 0.10688069462776184, "value_loss": 0.01525091528892517, "policy_loss": -0.0023177981094133935, "dist_entropy": 0.5601375818252563, "actor_grad_norm": 0.12636354565620422, "critic_grad_norm": 0.06363900750875473, "ratio": 0.9998523592948914, "entropy": 0.5601375818252563, "incre_win_rate": 0.038461538461538464, "step": 1243}
{"time": 1767084002.4651902, "phase": "train", "update": 1244, "total_env_steps": 3980800, "episode_reward": 0.10016660392284393, "value_loss": 0.01151159480214119, "policy_loss": -0.002189189623244303, "dist_entropy": 0.5902557373046875, "actor_grad_norm": 0.1437811404466629, "critic_grad_norm": 0.05662029609084129, "ratio": 1.0000206232070923, "entropy": 0.5902557373046875, "incre_win_rate": 0.04, "step": 1244}
{"time": 1767084007.143827, "phase": "train", "update": 1245, "total_env_steps": 3984000, "episode_reward": 0.11095663905143738, "value_loss": 0.016069945879280567, "policy_loss": -0.001843605968108264, "dist_entropy": 0.551833200454712, "actor_grad_norm": 0.1495479792356491, "critic_grad_norm": 0.055614542216062546, "ratio": 1.000306487083435, "entropy": 0.551833200454712, "incre_win_rate": 0.034482758620689655, "step": 1245}
{"time": 1767084011.9340456, "phase": "train", "update": 1246, "total_env_steps": 3987200, "episode_reward": 0.10395540297031403, "value_loss": 0.014866260252892971, "policy_loss": -0.002071218725020696, "dist_entropy": 0.5340495586395264, "actor_grad_norm": 0.1824011206626892, "critic_grad_norm": 0.06882865726947784, "ratio": 0.9998044967651367, "entropy": 0.5340495586395264, "incre_win_rate": 0.07692307692307693, "step": 1246}
{"time": 1767084016.5426288, "phase": "train", "update": 1247, "total_env_steps": 3990400, "episode_reward": 0.09598613530397415, "value_loss": 0.01315751187503338, "policy_loss": -0.0017233346470959532, "dist_entropy": 0.5956581711769104, "actor_grad_norm": 0.16332200169563293, "critic_grad_norm": 0.0732387825846672, "ratio": 1.0001248121261597, "entropy": 0.5956581711769104, "incre_win_rate": 0.08, "step": 1247}
{"time": 1767084021.0388172, "phase": "train", "update": 1248, "total_env_steps": 3993600, "episode_reward": 0.09394402801990509, "value_loss": 0.01036218199878931, "policy_loss": -0.0017820145394779273, "dist_entropy": 0.5957839608192443, "actor_grad_norm": 0.18551507592201233, "critic_grad_norm": 0.09334618598222733, "ratio": 0.999843418598175, "entropy": 0.5957839608192443, "incre_win_rate": 0.0, "step": 1248}
{"time": 1767084025.5842814, "phase": "train", "update": 1249, "total_env_steps": 3996800, "episode_reward": 0.10121792554855347, "value_loss": 0.011498326063156128, "policy_loss": -0.0018445855296889135, "dist_entropy": 0.563282561302185, "actor_grad_norm": 0.183688685297966, "critic_grad_norm": 0.07093779742717743, "ratio": 1.0001925230026245, "entropy": 0.563282561302185, "incre_win_rate": 0.0, "step": 1249}
{"time": 1767084030.213214, "phase": "train", "update": 1250, "total_env_steps": 4000000, "episode_reward": 0.11309085786342621, "value_loss": 0.011493402533233166, "policy_loss": -0.0015584471159481694, "dist_entropy": 0.5363713264465332, "actor_grad_norm": 0.1607474684715271, "critic_grad_norm": 0.05374032258987427, "ratio": 1.0000041723251343, "entropy": 0.5363713264465332, "incre_win_rate": 0.034482758620689655, "step": 1250}
{"time": 1767084034.7649956, "phase": "train", "update": 1251, "total_env_steps": 4003200, "episode_reward": 0.10931447148323059, "value_loss": 0.014069407805800438, "policy_loss": -0.0015749680322102223, "dist_entropy": 0.4933956146240234, "actor_grad_norm": 0.2040003538131714, "critic_grad_norm": 0.051427580416202545, "ratio": 0.99988853931427, "entropy": 0.4933956146240234, "incre_win_rate": 0.07407407407407407, "step": 1251}
{"time": 1767084039.2895083, "phase": "train", "update": 1252, "total_env_steps": 4006400, "episode_reward": 0.10910388827323914, "value_loss": 0.012249301560223103, "policy_loss": -0.001594706043709948, "dist_entropy": 0.544589102268219, "actor_grad_norm": 0.17152035236358643, "critic_grad_norm": 0.05946385860443115, "ratio": 1.0000704526901245, "entropy": 0.544589102268219, "incre_win_rate": 0.0, "step": 1252}
{"time": 1767084043.8756027, "phase": "train", "update": 1253, "total_env_steps": 4009600, "episode_reward": 0.11054791510105133, "value_loss": 0.0165536317974329, "policy_loss": -0.0016727428516361443, "dist_entropy": 0.52742600440979, "actor_grad_norm": 0.1931716948747635, "critic_grad_norm": 0.07890507578849792, "ratio": 0.9998693466186523, "entropy": 0.52742600440979, "incre_win_rate": 0.034482758620689655, "step": 1253}
{"time": 1767084048.5524547, "phase": "train", "update": 1254, "total_env_steps": 4012800, "episode_reward": 0.11591576784849167, "value_loss": 0.01387457549571991, "policy_loss": -0.001834194174055881, "dist_entropy": 0.5489768028259278, "actor_grad_norm": 0.15746304392814636, "critic_grad_norm": 0.026918042451143265, "ratio": 1.0002485513687134, "entropy": 0.5489768028259278, "incre_win_rate": 0.14814814814814814, "step": 1254}
{"time": 1767084053.110859, "phase": "train", "update": 1255, "total_env_steps": 4016000, "episode_reward": 0.0968734547495842, "value_loss": 0.012660283222794532, "policy_loss": -0.002238301322143599, "dist_entropy": 0.5579638600349426, "actor_grad_norm": 0.14133581519126892, "critic_grad_norm": 0.05906993895769119, "ratio": 0.9999536871910095, "entropy": 0.5579638600349426, "incre_win_rate": 0.15384615384615385, "step": 1255}
{"time": 1767084057.6727467, "phase": "train", "update": 1256, "total_env_steps": 4019200, "episode_reward": 0.1073991134762764, "value_loss": 0.015400438010692597, "policy_loss": -0.0019250332087995758, "dist_entropy": 0.5278551936149597, "actor_grad_norm": 0.16284166276454926, "critic_grad_norm": 0.0608198419213295, "ratio": 1.0004972219467163, "entropy": 0.5278551936149597, "incre_win_rate": 0.08, "step": 1256}
{"time": 1767084062.292187, "phase": "train", "update": 1257, "total_env_steps": 4022400, "episode_reward": 0.10938689857721329, "value_loss": 0.014039988815784454, "policy_loss": -0.0014861120104114889, "dist_entropy": 0.5086856245994568, "actor_grad_norm": 0.18269924819469452, "critic_grad_norm": 0.022579079493880272, "ratio": 1.0000958442687988, "entropy": 0.5086856245994568, "incre_win_rate": 0.07142857142857142, "step": 1257}
{"time": 1767084066.8241365, "phase": "train", "update": 1258, "total_env_steps": 4025600, "episode_reward": 0.10322588682174683, "value_loss": 0.011332564242184161, "policy_loss": -0.0017282061639893875, "dist_entropy": 0.5227821588516235, "actor_grad_norm": 0.16289691627025604, "critic_grad_norm": 0.04812155291438103, "ratio": 0.9999797940254211, "entropy": 0.5227821588516235, "incre_win_rate": 0.0, "step": 1258}
{"time": 1767084071.5279956, "phase": "train", "update": 1259, "total_env_steps": 4028800, "episode_reward": 0.13336609303951263, "value_loss": 0.018120744079351426, "policy_loss": -0.0015394216748731537, "dist_entropy": 0.4772722840309143, "actor_grad_norm": 0.11231100559234619, "critic_grad_norm": 0.06213337182998657, "ratio": 0.9998239874839783, "entropy": 0.4772722840309143, "incre_win_rate": 0.12903225806451613, "step": 1259}
{"time": 1767084076.3732905, "phase": "train", "update": 1260, "total_env_steps": 4032000, "episode_reward": 0.11355391144752502, "value_loss": 0.011701976880431175, "policy_loss": -0.0017861330653644813, "dist_entropy": 0.5061223030090332, "actor_grad_norm": 0.17043286561965942, "critic_grad_norm": 0.06799880415201187, "ratio": 0.9998353123664856, "entropy": 0.5061223030090332, "incre_win_rate": 0.13793103448275862, "step": 1260}
{"time": 1767084080.922248, "phase": "train", "update": 1261, "total_env_steps": 4035200, "episode_reward": 0.10363306850194931, "value_loss": 0.018956482410430908, "policy_loss": -0.0017580491502712902, "dist_entropy": 0.5739160180091858, "actor_grad_norm": 0.1371435970067978, "critic_grad_norm": 0.056970518082380295, "ratio": 1.0000492334365845, "entropy": 0.5739160180091858, "incre_win_rate": 0.14285714285714285, "step": 1261}
{"time": 1767084098.1303663, "phase": "eval", "update": 1261, "total_env_steps": 4035200, "eval_win_rate": 0.09375, "eval_episode_reward": 13.978269867549654, "step": 1261}
{"time": 1767084102.8436313, "phase": "train", "update": 1262, "total_env_steps": 4038400, "episode_reward": 0.10450434684753418, "value_loss": 0.012935362569987775, "policy_loss": -0.0019074421871110303, "dist_entropy": 0.5451239347457886, "actor_grad_norm": 0.1778397560119629, "critic_grad_norm": 0.07428859919309616, "ratio": 1.000229835510254, "entropy": 0.5451239347457886, "incre_win_rate": 0.12, "step": 1262}
{"time": 1767084107.4656591, "phase": "train", "update": 1263, "total_env_steps": 4041600, "episode_reward": 0.1192735955119133, "value_loss": 0.014834168367087841, "policy_loss": -0.0015031871786788998, "dist_entropy": 0.4976592600345612, "actor_grad_norm": 0.21867452561855316, "critic_grad_norm": 0.14062544703483582, "ratio": 1.0001496076583862, "entropy": 0.4976592600345612, "incre_win_rate": 0.07142857142857142, "step": 1263}
{"time": 1767084112.270092, "phase": "train", "update": 1264, "total_env_steps": 4044800, "episode_reward": 0.12214197218418121, "value_loss": 0.01439977865666151, "policy_loss": -0.001459177624616359, "dist_entropy": 0.5112716436386109, "actor_grad_norm": 0.16553185880184174, "critic_grad_norm": 0.029005486518144608, "ratio": 0.999981701374054, "entropy": 0.5112716436386109, "incre_win_rate": 0.13793103448275862, "step": 1264}
{"time": 1767084116.88155, "phase": "train", "update": 1265, "total_env_steps": 4048000, "episode_reward": 0.1227923184633255, "value_loss": 0.017658039927482605, "policy_loss": -0.002292967715793992, "dist_entropy": 0.48269436359405515, "actor_grad_norm": 0.17060379683971405, "critic_grad_norm": 0.05226375535130501, "ratio": 1.0000497102737427, "entropy": 0.48269436359405515, "incre_win_rate": 0.24, "step": 1265}
{"time": 1767084121.4750314, "phase": "train", "update": 1266, "total_env_steps": 4051200, "episode_reward": 0.09822950512170792, "value_loss": 0.01125312652438879, "policy_loss": -0.001829473497485168, "dist_entropy": 0.5510890483856201, "actor_grad_norm": 0.2114471048116684, "critic_grad_norm": 0.028495116159319878, "ratio": 1.000016212463379, "entropy": 0.5510890483856201, "incre_win_rate": 0.0, "step": 1266}
{"time": 1767084125.877144, "phase": "train", "update": 1267, "total_env_steps": 4054400, "episode_reward": 0.11128827929496765, "value_loss": 0.015934303402900696, "policy_loss": -0.0019865180846949217, "dist_entropy": 0.5031573891639709, "actor_grad_norm": 0.19881749153137207, "critic_grad_norm": 0.02644321322441101, "ratio": 0.9995967745780945, "entropy": 0.5031573891639709, "incre_win_rate": 0.08, "step": 1267}
{"time": 1767084130.4857461, "phase": "train", "update": 1268, "total_env_steps": 4057600, "episode_reward": 0.13565655052661896, "value_loss": 0.019983020052313803, "policy_loss": -0.001589474466395302, "dist_entropy": 0.5040248274803162, "actor_grad_norm": 0.15054792165756226, "critic_grad_norm": 0.1445256620645523, "ratio": 0.9999756217002869, "entropy": 0.5040248274803162, "incre_win_rate": 0.27586206896551724, "step": 1268}
{"time": 1767084135.229106, "phase": "train", "update": 1269, "total_env_steps": 4060800, "episode_reward": 0.12349441647529602, "value_loss": 0.016416163928806782, "policy_loss": -0.0017083176755136264, "dist_entropy": 0.5072152137756347, "actor_grad_norm": 0.12836936116218567, "critic_grad_norm": 0.03471916913986206, "ratio": 1.0001130104064941, "entropy": 0.5072152137756347, "incre_win_rate": 0.14285714285714285, "step": 1269}
{"time": 1767084139.8716655, "phase": "train", "update": 1270, "total_env_steps": 4064000, "episode_reward": 0.11578279733657837, "value_loss": 0.01526106782257557, "policy_loss": -0.0015925365818041826, "dist_entropy": 0.5220567941665649, "actor_grad_norm": 0.12720079720020294, "critic_grad_norm": 0.03623088076710701, "ratio": 1.000110149383545, "entropy": 0.5220567941665649, "incre_win_rate": 0.14285714285714285, "step": 1270}
{"time": 1767084144.5069978, "phase": "train", "update": 1271, "total_env_steps": 4067200, "episode_reward": 0.11032906174659729, "value_loss": 0.01598859652876854, "policy_loss": -0.0019080178740225051, "dist_entropy": 0.5161250233650208, "actor_grad_norm": 0.11892980337142944, "critic_grad_norm": 0.05875168368220329, "ratio": 1.0000076293945312, "entropy": 0.5161250233650208, "incre_win_rate": 0.16, "step": 1271}
{"time": 1767084149.0775256, "phase": "train", "update": 1272, "total_env_steps": 4070400, "episode_reward": 0.13840800523757935, "value_loss": 0.017014775797724722, "policy_loss": -0.0016245329769560613, "dist_entropy": 0.48636549711227417, "actor_grad_norm": 0.12981148064136505, "critic_grad_norm": 0.1436404436826706, "ratio": 1.0000907182693481, "entropy": 0.48636549711227417, "incre_win_rate": 0.3333333333333333, "step": 1272}
{"time": 1767084153.7683678, "phase": "train", "update": 1273, "total_env_steps": 4073600, "episode_reward": 0.11318657547235489, "value_loss": 0.013514762371778488, "policy_loss": -0.00212807779968216, "dist_entropy": 0.5046058416366577, "actor_grad_norm": 0.17131514847278595, "critic_grad_norm": 0.03755558282136917, "ratio": 1.0001102685928345, "entropy": 0.5046058416366577, "incre_win_rate": 0.041666666666666664, "step": 1273}
{"time": 1767084158.9132657, "phase": "train", "update": 1274, "total_env_steps": 4076800, "episode_reward": 0.12136901170015335, "value_loss": 0.017208104953169823, "policy_loss": -0.0016119618095018495, "dist_entropy": 0.4955098628997803, "actor_grad_norm": 0.1842448115348816, "critic_grad_norm": 0.05046665295958519, "ratio": 0.9998003244400024, "entropy": 0.4955098628997803, "incre_win_rate": 0.10344827586206896, "step": 1274}
{"time": 1767084163.7429204, "phase": "train", "update": 1275, "total_env_steps": 4080000, "episode_reward": 0.09052876383066177, "value_loss": 0.014048508182168008, "policy_loss": -0.0015916369589831446, "dist_entropy": 0.5625685453414917, "actor_grad_norm": 0.14986605942249298, "critic_grad_norm": 0.14968521893024445, "ratio": 1.0001705884933472, "entropy": 0.5625685453414917, "incre_win_rate": 0.0, "step": 1275}
{"time": 1767084168.3043098, "phase": "train", "update": 1276, "total_env_steps": 4083200, "episode_reward": 0.09981942921876907, "value_loss": 0.014780963398516178, "policy_loss": -0.001704042966204611, "dist_entropy": 0.5453481554985047, "actor_grad_norm": 0.13880746066570282, "critic_grad_norm": 0.06167299300432205, "ratio": 1.0000784397125244, "entropy": 0.5453481554985047, "incre_win_rate": 0.0, "step": 1276}
{"time": 1767084172.9673722, "phase": "train", "update": 1277, "total_env_steps": 4086400, "episode_reward": 0.09197226166725159, "value_loss": 0.013917923904955387, "policy_loss": -0.001725296466713644, "dist_entropy": 0.5440425515174866, "actor_grad_norm": 0.1252630203962326, "critic_grad_norm": 0.135756716132164, "ratio": 1.0000749826431274, "entropy": 0.5440425515174866, "incre_win_rate": 0.037037037037037035, "step": 1277}
{"time": 1767084177.4394827, "phase": "train", "update": 1278, "total_env_steps": 4089600, "episode_reward": 0.09046357125043869, "value_loss": 0.015150588192045688, "policy_loss": -0.0018082403007916525, "dist_entropy": 0.553003978729248, "actor_grad_norm": 0.18516315519809723, "critic_grad_norm": 0.09250765293836594, "ratio": 0.9998846054077148, "entropy": 0.553003978729248, "incre_win_rate": 0.08333333333333333, "step": 1278}
{"time": 1767084182.049341, "phase": "train", "update": 1279, "total_env_steps": 4092800, "episode_reward": 0.09936516731977463, "value_loss": 0.014684589952230454, "policy_loss": -0.0017760916931109706, "dist_entropy": 0.5389995336532593, "actor_grad_norm": 0.15475158393383026, "critic_grad_norm": 0.06553977727890015, "ratio": 0.9996771812438965, "entropy": 0.5389995336532593, "incre_win_rate": 0.07142857142857142, "step": 1279}
{"time": 1767084186.4724555, "phase": "train", "update": 1280, "total_env_steps": 4096000, "episode_reward": 0.09730702638626099, "value_loss": 0.012808842584490776, "policy_loss": -0.0021535779270607236, "dist_entropy": 0.5270440936088562, "actor_grad_norm": 0.16451528668403625, "critic_grad_norm": 0.06894000619649887, "ratio": 1.000461459159851, "entropy": 0.5270440936088562, "incre_win_rate": 0.0, "step": 1280}
{"time": 1767084191.0479748, "phase": "train", "update": 1281, "total_env_steps": 4099200, "episode_reward": 0.11649679392576218, "value_loss": 0.015114999935030937, "policy_loss": -0.0016599560772881717, "dist_entropy": 0.5205286979675293, "actor_grad_norm": 0.16505466401576996, "critic_grad_norm": 0.05556781217455864, "ratio": 0.999958336353302, "entropy": 0.5205286979675293, "incre_win_rate": 0.125, "step": 1281}
{"time": 1767084206.801145, "phase": "eval", "update": 1281, "total_env_steps": 4099200, "eval_win_rate": 0.28125, "eval_episode_reward": 15.178549254966878, "step": 1281}
{"time": 1767084211.560045, "phase": "train", "update": 1282, "total_env_steps": 4102400, "episode_reward": 0.1293320655822754, "value_loss": 0.018024221435189246, "policy_loss": -0.0014830078126493618, "dist_entropy": 0.514586615562439, "actor_grad_norm": 0.14060163497924805, "critic_grad_norm": 0.06129995733499527, "ratio": 0.9999375343322754, "entropy": 0.514586615562439, "incre_win_rate": 0.16666666666666666, "step": 1282}
{"time": 1767084216.234763, "phase": "train", "update": 1283, "total_env_steps": 4105600, "episode_reward": 0.11616048961877823, "value_loss": 0.016427090391516685, "policy_loss": -0.0016213254952351264, "dist_entropy": 0.5360325932502746, "actor_grad_norm": 0.1551341563463211, "critic_grad_norm": 0.06218671798706055, "ratio": 1.0000959634780884, "entropy": 0.5360325932502746, "incre_win_rate": 0.17857142857142858, "step": 1283}
{"time": 1767084220.92534, "phase": "train", "update": 1284, "total_env_steps": 4108800, "episode_reward": 0.11890987306833267, "value_loss": 0.016234139539301397, "policy_loss": -0.0014074479885223922, "dist_entropy": 0.5087027311325073, "actor_grad_norm": 0.16969671845436096, "critic_grad_norm": 0.03234418109059334, "ratio": 0.9997998476028442, "entropy": 0.5087027311325073, "incre_win_rate": 0.19230769230769232, "step": 1284}
{"time": 1767084225.6852188, "phase": "train", "update": 1285, "total_env_steps": 4112000, "episode_reward": 0.12784768640995026, "value_loss": 0.01889967769384384, "policy_loss": -0.0018493290549656649, "dist_entropy": 0.5048554897308349, "actor_grad_norm": 0.12940357625484467, "critic_grad_norm": 0.06589475274085999, "ratio": 0.9999834299087524, "entropy": 0.5048554897308349, "incre_win_rate": 0.1, "step": 1285}
{"time": 1767084230.380765, "phase": "train", "update": 1286, "total_env_steps": 4115200, "episode_reward": 0.10943553596735, "value_loss": 0.013376525789499282, "policy_loss": -0.0017239366353464902, "dist_entropy": 0.5378352642059326, "actor_grad_norm": 0.1360594481229782, "critic_grad_norm": 0.1242399588227272, "ratio": 1.0000511407852173, "entropy": 0.5378352642059326, "incre_win_rate": 0.12, "step": 1286}
{"time": 1767084234.9518108, "phase": "train", "update": 1287, "total_env_steps": 4118400, "episode_reward": 0.11163545399904251, "value_loss": 0.016249335929751398, "policy_loss": -0.0018030567570015421, "dist_entropy": 0.5410044193267822, "actor_grad_norm": 0.12588724493980408, "critic_grad_norm": 0.12182648479938507, "ratio": 0.9999995231628418, "entropy": 0.5410044193267822, "incre_win_rate": 0.037037037037037035, "step": 1287}
{"time": 1767084239.4471896, "phase": "train", "update": 1288, "total_env_steps": 4121600, "episode_reward": 0.11486393958330154, "value_loss": 0.015659936144948004, "policy_loss": -0.0013546152453827176, "dist_entropy": 0.5441432476043702, "actor_grad_norm": 0.11111898720264435, "critic_grad_norm": 0.08632474392652512, "ratio": 1.0000637769699097, "entropy": 0.5441432476043702, "incre_win_rate": 0.12, "step": 1288}
{"time": 1767084243.942011, "phase": "train", "update": 1289, "total_env_steps": 4124800, "episode_reward": 0.1216370016336441, "value_loss": 0.013346533104777337, "policy_loss": -0.0017826821942549032, "dist_entropy": 0.5311706066131592, "actor_grad_norm": 0.12050914019346237, "critic_grad_norm": 0.06059321388602257, "ratio": 1.0000131130218506, "entropy": 0.5311706066131592, "incre_win_rate": 0.1111111111111111, "step": 1289}
{"time": 1767084248.3856843, "phase": "train", "update": 1290, "total_env_steps": 4128000, "episode_reward": 0.11774884909391403, "value_loss": 0.014977066591382027, "policy_loss": -0.0017236710390676536, "dist_entropy": 0.4969223141670227, "actor_grad_norm": 0.1712513417005539, "critic_grad_norm": 0.06238313391804695, "ratio": 1.0000227689743042, "entropy": 0.4969223141670227, "incre_win_rate": 0.10714285714285714, "step": 1290}
{"time": 1767084252.9605753, "phase": "train", "update": 1291, "total_env_steps": 4131200, "episode_reward": 0.12335368245840073, "value_loss": 0.013802999816834926, "policy_loss": -0.001304188185454791, "dist_entropy": 0.5216463804244995, "actor_grad_norm": 0.09704376012086868, "critic_grad_norm": 0.03395431861281395, "ratio": 0.9999626278877258, "entropy": 0.5216463804244995, "incre_win_rate": 0.14814814814814814, "step": 1291}
{"time": 1767084257.5169494, "phase": "train", "update": 1292, "total_env_steps": 4134400, "episode_reward": 0.12441743165254593, "value_loss": 0.017036259546875952, "policy_loss": -0.001548361869797965, "dist_entropy": 0.49759828448295595, "actor_grad_norm": 0.16443637013435364, "critic_grad_norm": 0.07109194993972778, "ratio": 1.0001577138900757, "entropy": 0.49759828448295595, "incre_win_rate": 0.17857142857142858, "step": 1292}
{"time": 1767084262.0280044, "phase": "train", "update": 1293, "total_env_steps": 4137600, "episode_reward": 0.14085522294044495, "value_loss": 0.015175349824130536, "policy_loss": -0.0016569161968778446, "dist_entropy": 0.5068556547164917, "actor_grad_norm": 0.12509052455425262, "critic_grad_norm": 0.09407650679349899, "ratio": 0.9998311400413513, "entropy": 0.5068556547164917, "incre_win_rate": 0.2962962962962963, "step": 1293}
{"time": 1767084266.743997, "phase": "train", "update": 1294, "total_env_steps": 4140800, "episode_reward": 0.1251940131187439, "value_loss": 0.01578790321946144, "policy_loss": -0.0018514515493258444, "dist_entropy": 0.48225878477096557, "actor_grad_norm": 0.13766370713710785, "critic_grad_norm": 0.06924263387918472, "ratio": 0.9996721148490906, "entropy": 0.48225878477096557, "incre_win_rate": 0.15384615384615385, "step": 1294}
{"time": 1767084271.4582105, "phase": "train", "update": 1295, "total_env_steps": 4144000, "episode_reward": 0.11333867907524109, "value_loss": 0.014907831884920597, "policy_loss": -0.0012349930150932665, "dist_entropy": 0.533202064037323, "actor_grad_norm": 0.13960328698158264, "critic_grad_norm": 0.06357413530349731, "ratio": 0.9997766613960266, "entropy": 0.533202064037323, "incre_win_rate": 0.1111111111111111, "step": 1295}
{"time": 1767084276.2137244, "phase": "train", "update": 1296, "total_env_steps": 4147200, "episode_reward": 0.10553963482379913, "value_loss": 0.016312772408127785, "policy_loss": -0.001621660838895167, "dist_entropy": 0.5626790046691894, "actor_grad_norm": 0.14359965920448303, "critic_grad_norm": 0.07160227745771408, "ratio": 0.9997938275337219, "entropy": 0.5626790046691894, "incre_win_rate": 0.0, "step": 1296}
{"time": 1767084280.8269727, "phase": "train", "update": 1297, "total_env_steps": 4150400, "episode_reward": 0.1106632873415947, "value_loss": 0.01427327785640955, "policy_loss": -0.001498146039365622, "dist_entropy": 0.5303306698799133, "actor_grad_norm": 0.12818144261837006, "critic_grad_norm": 0.08169393986463547, "ratio": 1.0000529289245605, "entropy": 0.5303306698799133, "incre_win_rate": 0.037037037037037035, "step": 1297}
{"time": 1767084285.3875616, "phase": "train", "update": 1298, "total_env_steps": 4153600, "episode_reward": 0.12098147720098495, "value_loss": 0.013664116151630878, "policy_loss": -0.0017249679788598371, "dist_entropy": 0.5009387373924256, "actor_grad_norm": 0.17488358914852142, "critic_grad_norm": 0.06990834325551987, "ratio": 1.000089406967163, "entropy": 0.5009387373924256, "incre_win_rate": 0.07692307692307693, "step": 1298}
{"time": 1767084289.9538672, "phase": "train", "update": 1299, "total_env_steps": 4156800, "episode_reward": 0.12719112634658813, "value_loss": 0.01369055937975645, "policy_loss": -0.001610804125869425, "dist_entropy": 0.513465166091919, "actor_grad_norm": 0.12388604134321213, "critic_grad_norm": 0.06028546020388603, "ratio": 0.9998807907104492, "entropy": 0.513465166091919, "incre_win_rate": 0.18518518518518517, "step": 1299}
{"time": 1767084294.556724, "phase": "train", "update": 1300, "total_env_steps": 4160000, "episode_reward": 0.12132398784160614, "value_loss": 0.016120313294231893, "policy_loss": -0.0017459873857646358, "dist_entropy": 0.5355507493019104, "actor_grad_norm": 0.14785678684711456, "critic_grad_norm": 0.029395783320069313, "ratio": 0.9997236132621765, "entropy": 0.5355507493019104, "incre_win_rate": 0.13333333333333333, "step": 1300}
{"time": 1767084299.0497859, "phase": "train", "update": 1301, "total_env_steps": 4163200, "episode_reward": 0.13211403787136078, "value_loss": 0.015014416351914407, "policy_loss": -0.0020086986594833435, "dist_entropy": 0.48404440879821775, "actor_grad_norm": 0.1204446330666542, "critic_grad_norm": 0.04715226963162422, "ratio": 1.0002710819244385, "entropy": 0.48404440879821775, "incre_win_rate": 0.19230769230769232, "step": 1301}
{"time": 1767084317.95775, "phase": "eval", "update": 1301, "total_env_steps": 4163200, "eval_win_rate": 0.46875, "eval_episode_reward": 16.65811258278145, "step": 1301}
{"time": 1767084322.466874, "phase": "train", "update": 1302, "total_env_steps": 4166400, "episode_reward": 0.13254500925540924, "value_loss": 0.01624441221356392, "policy_loss": -0.0016182142960602165, "dist_entropy": 0.4731172502040863, "actor_grad_norm": 0.1324128955602646, "critic_grad_norm": 0.03714664652943611, "ratio": 1.0000088214874268, "entropy": 0.4731172502040863, "incre_win_rate": 0.27586206896551724, "step": 1302}
{"time": 1767084326.9880645, "phase": "train", "update": 1303, "total_env_steps": 4169600, "episode_reward": 0.13117548823356628, "value_loss": 0.015273039229214191, "policy_loss": -0.0017364419946119369, "dist_entropy": 0.4707866430282593, "actor_grad_norm": 0.20044083893299103, "critic_grad_norm": 0.10941394418478012, "ratio": 0.9998836517333984, "entropy": 0.4707866430282593, "incre_win_rate": 0.17857142857142858, "step": 1303}
{"time": 1767084331.4422297, "phase": "train", "update": 1304, "total_env_steps": 4172800, "episode_reward": 0.10936103016138077, "value_loss": 0.016477398574352264, "policy_loss": -0.0017600944181083377, "dist_entropy": 0.5131192684173584, "actor_grad_norm": 0.23056860268115997, "critic_grad_norm": 0.053001005202531815, "ratio": 0.9998630881309509, "entropy": 0.5131192684173584, "incre_win_rate": 0.2, "step": 1304}
{"time": 1767084335.9750576, "phase": "train", "update": 1305, "total_env_steps": 4176000, "episode_reward": 0.13094370067119598, "value_loss": 0.018852774053812027, "policy_loss": -0.0016597073571716693, "dist_entropy": 0.5140909910202026, "actor_grad_norm": 0.23123799264431, "critic_grad_norm": 0.10590865463018417, "ratio": 1.0001647472381592, "entropy": 0.5140909910202026, "incre_win_rate": 0.2222222222222222, "step": 1305}
{"time": 1767084340.4882095, "phase": "train", "update": 1306, "total_env_steps": 4179200, "episode_reward": 0.12809914350509644, "value_loss": 0.015028240345418453, "policy_loss": -0.0018699796465647012, "dist_entropy": 0.505260682106018, "actor_grad_norm": 0.15196312963962555, "critic_grad_norm": 0.0667572021484375, "ratio": 1.0001417398452759, "entropy": 0.505260682106018, "incre_win_rate": 0.19230769230769232, "step": 1306}
{"time": 1767084345.023878, "phase": "train", "update": 1307, "total_env_steps": 4182400, "episode_reward": 0.13075745105743408, "value_loss": 0.016658743470907213, "policy_loss": -0.001460656627538981, "dist_entropy": 0.49614335894584655, "actor_grad_norm": 0.1347905397415161, "critic_grad_norm": 0.0665026307106018, "ratio": 1.0000590085983276, "entropy": 0.49614335894584655, "incre_win_rate": 0.1724137931034483, "step": 1307}
{"time": 1767084379.7235446, "phase": "train", "update": 1308, "total_env_steps": 4185600, "episode_reward": 0.14382606744766235, "value_loss": 0.053159239888191226, "policy_loss": -0.0018267492758234027, "dist_entropy": 0.5343287706375122, "actor_grad_norm": 0.14213354885578156, "critic_grad_norm": 0.31006112694740295, "ratio": 0.999871551990509, "entropy": 0.5343287706375122, "incre_win_rate": 0.25, "step": 1308}
{"time": 1767084384.1588936, "phase": "train", "update": 1309, "total_env_steps": 4188800, "episode_reward": 0.11600889265537262, "value_loss": 0.017973658815026283, "policy_loss": -0.0014826658862148179, "dist_entropy": 0.5129300355911255, "actor_grad_norm": 0.1931687444448471, "critic_grad_norm": 0.13871881365776062, "ratio": 0.9999152421951294, "entropy": 0.5129300355911255, "incre_win_rate": 0.18518518518518517, "step": 1309}
{"time": 1767084388.4915993, "phase": "train", "update": 1310, "total_env_steps": 4192000, "episode_reward": 0.12536579370498657, "value_loss": 0.015071879886090756, "policy_loss": -0.002377463209707287, "dist_entropy": 0.5272047519683838, "actor_grad_norm": 0.21951471269130707, "critic_grad_norm": 0.07924004644155502, "ratio": 0.9998415112495422, "entropy": 0.5272047519683838, "incre_win_rate": 0.2608695652173913, "step": 1310}
{"time": 1767084392.9343395, "phase": "train", "update": 1311, "total_env_steps": 4195200, "episode_reward": 0.11034872382879257, "value_loss": 0.01459725946187973, "policy_loss": -0.0023159549385013633, "dist_entropy": 0.5455816984176636, "actor_grad_norm": 0.241488978266716, "critic_grad_norm": 0.04348217323422432, "ratio": 0.9995876550674438, "entropy": 0.5455816984176636, "incre_win_rate": 0.11538461538461539, "step": 1311}
{"time": 1767084397.4601104, "phase": "train", "update": 1312, "total_env_steps": 4198400, "episode_reward": 0.13067001104354858, "value_loss": 0.01782805919647217, "policy_loss": -0.0013650055984822274, "dist_entropy": 0.532430636882782, "actor_grad_norm": 0.16589467227458954, "critic_grad_norm": 0.050088733434677124, "ratio": 0.9999521374702454, "entropy": 0.532430636882782, "incre_win_rate": 0.2413793103448276, "step": 1312}
{"time": 1767084401.8727498, "phase": "train", "update": 1313, "total_env_steps": 4201600, "episode_reward": 0.12866619229316711, "value_loss": 0.013748051598668098, "policy_loss": -0.0016335009323411142, "dist_entropy": 0.523760199546814, "actor_grad_norm": 0.13886356353759766, "critic_grad_norm": 0.028510142117738724, "ratio": 0.9999384880065918, "entropy": 0.523760199546814, "incre_win_rate": 0.2, "step": 1313}
{"time": 1767084406.6707563, "phase": "train", "update": 1314, "total_env_steps": 4204800, "episode_reward": 0.12939466536045074, "value_loss": 0.0161726251244545, "policy_loss": -0.0016807978953721659, "dist_entropy": 0.5376944184303284, "actor_grad_norm": 0.13298220932483673, "critic_grad_norm": 0.05440492555499077, "ratio": 0.9997750520706177, "entropy": 0.5376944184303284, "incre_win_rate": 0.27586206896551724, "step": 1314}
{"time": 1767084411.2886558, "phase": "train", "update": 1315, "total_env_steps": 4208000, "episode_reward": 0.12703175842761993, "value_loss": 0.01493354868143797, "policy_loss": -0.0016793985060949979, "dist_entropy": 0.5385696649551391, "actor_grad_norm": 0.17289060354232788, "critic_grad_norm": 0.04595264047384262, "ratio": 0.999829113483429, "entropy": 0.5385696649551391, "incre_win_rate": 0.25925925925925924, "step": 1315}
{"time": 1767084415.8162358, "phase": "train", "update": 1316, "total_env_steps": 4211200, "episode_reward": 0.10498189926147461, "value_loss": 0.016471200436353684, "policy_loss": -0.0017790500535838304, "dist_entropy": 0.5567077755928039, "actor_grad_norm": 0.16838406026363373, "critic_grad_norm": 0.09003393352031708, "ratio": 1.0001071691513062, "entropy": 0.5567077755928039, "incre_win_rate": 0.2, "step": 1316}
{"time": 1767084420.3446312, "phase": "train", "update": 1317, "total_env_steps": 4214400, "episode_reward": 0.1263374388217926, "value_loss": 0.01671908386051655, "policy_loss": -0.0015044803244450122, "dist_entropy": 0.5069944500923157, "actor_grad_norm": 0.18710406124591827, "critic_grad_norm": 0.06695214658975601, "ratio": 1.0000628232955933, "entropy": 0.5069944500923157, "incre_win_rate": 0.17857142857142858, "step": 1317}
{"time": 1767084425.078881, "phase": "train", "update": 1318, "total_env_steps": 4217600, "episode_reward": 0.14803548157215118, "value_loss": 0.01427366267889738, "policy_loss": -0.0015894477595075785, "dist_entropy": 0.4722485840320587, "actor_grad_norm": 0.13855202496051788, "critic_grad_norm": 0.038436587899923325, "ratio": 0.9998131990432739, "entropy": 0.4722485840320587, "incre_win_rate": 0.25806451612903225, "step": 1318}
{"time": 1767084429.8911014, "phase": "train", "update": 1319, "total_env_steps": 4220800, "episode_reward": 0.1456555277109146, "value_loss": 0.015597127191722394, "policy_loss": -0.0016237688929265914, "dist_entropy": 0.47923868894577026, "actor_grad_norm": 0.17443092167377472, "critic_grad_norm": 0.039174508303403854, "ratio": 0.9998888373374939, "entropy": 0.47923868894577026, "incre_win_rate": 0.3448275862068966, "step": 1319}
{"time": 1767084434.7339063, "phase": "train", "update": 1320, "total_env_steps": 4224000, "episode_reward": 0.11843129247426987, "value_loss": 0.01661076545715332, "policy_loss": -0.0017779000668078026, "dist_entropy": 0.5076864838600159, "actor_grad_norm": 0.19487133622169495, "critic_grad_norm": 0.10512230545282364, "ratio": 1.0001680850982666, "entropy": 0.5076864838600159, "incre_win_rate": 0.06896551724137931, "step": 1320}
{"time": 1767084439.512395, "phase": "train", "update": 1321, "total_env_steps": 4227200, "episode_reward": 0.127675399184227, "value_loss": 0.01371492985635996, "policy_loss": -0.002156857142325208, "dist_entropy": 0.4829867720603943, "actor_grad_norm": 0.21433083713054657, "critic_grad_norm": 0.07508528232574463, "ratio": 0.9999662637710571, "entropy": 0.4829867720603943, "incre_win_rate": 0.1724137931034483, "step": 1321}
{"time": 1767084455.9151428, "phase": "eval", "update": 1321, "total_env_steps": 4227200, "eval_win_rate": 0.375, "eval_episode_reward": 15.08200538079469, "step": 1321}
{"time": 1767084460.7103317, "phase": "train", "update": 1322, "total_env_steps": 4230400, "episode_reward": 0.12654750049114227, "value_loss": 0.01372617408633232, "policy_loss": -0.0021819649813693332, "dist_entropy": 0.496721076965332, "actor_grad_norm": 0.17147648334503174, "critic_grad_norm": 0.08948278427124023, "ratio": 0.9997714161872864, "entropy": 0.496721076965332, "incre_win_rate": 0.14814814814814814, "step": 1322}
{"time": 1767084465.6918805, "phase": "train", "update": 1323, "total_env_steps": 4233600, "episode_reward": 0.13245032727718353, "value_loss": 0.015280111692845821, "policy_loss": -0.0017926293798787186, "dist_entropy": 0.49068971872329714, "actor_grad_norm": 0.1404569447040558, "critic_grad_norm": 0.0361308678984642, "ratio": 0.9999564290046692, "entropy": 0.49068971872329714, "incre_win_rate": 0.15384615384615385, "step": 1323}
{"time": 1767084470.6074224, "phase": "train", "update": 1324, "total_env_steps": 4236800, "episode_reward": 0.14812706410884857, "value_loss": 0.01784028671681881, "policy_loss": -0.0018347110968836232, "dist_entropy": 0.4758842170238495, "actor_grad_norm": 0.17744307219982147, "critic_grad_norm": 0.08637211471796036, "ratio": 0.9998440742492676, "entropy": 0.4758842170238495, "incre_win_rate": 0.3, "step": 1324}
{"time": 1767084475.4948063, "phase": "train", "update": 1325, "total_env_steps": 4240000, "episode_reward": 0.1429470181465149, "value_loss": 0.014461475796997547, "policy_loss": -0.0014128943802589333, "dist_entropy": 0.49746357202529906, "actor_grad_norm": 0.12490244209766388, "critic_grad_norm": 0.11200124025344849, "ratio": 0.999973475933075, "entropy": 0.49746357202529906, "incre_win_rate": 0.3448275862068966, "step": 1325}
{"time": 1767084480.3206384, "phase": "train", "update": 1326, "total_env_steps": 4243200, "episode_reward": 0.15116152167320251, "value_loss": 0.015403871610760688, "policy_loss": -0.0018404450281963136, "dist_entropy": 0.48729958534240725, "actor_grad_norm": 0.14141838252544403, "critic_grad_norm": 0.08706995099782944, "ratio": 0.9999076128005981, "entropy": 0.48729958534240725, "incre_win_rate": 0.27586206896551724, "step": 1326}
{"time": 1767084485.0864182, "phase": "train", "update": 1327, "total_env_steps": 4246400, "episode_reward": 0.13030733168125153, "value_loss": 0.016847334057092666, "policy_loss": -0.001817946361464351, "dist_entropy": 0.5229385137557984, "actor_grad_norm": 0.1526966542005539, "critic_grad_norm": 0.052218563854694366, "ratio": 1.0000005960464478, "entropy": 0.5229385137557984, "incre_win_rate": 0.2222222222222222, "step": 1327}
{"time": 1767084489.9162135, "phase": "train", "update": 1328, "total_env_steps": 4249600, "episode_reward": 0.11749741435050964, "value_loss": 0.017992111667990685, "policy_loss": -0.001916441131169222, "dist_entropy": 0.5380970597267151, "actor_grad_norm": 0.13275551795959473, "critic_grad_norm": 0.1169043779373169, "ratio": 1.0000813007354736, "entropy": 0.5380970597267151, "incre_win_rate": 0.10714285714285714, "step": 1328}
{"time": 1767084494.9942253, "phase": "train", "update": 1329, "total_env_steps": 4252800, "episode_reward": 0.11759883165359497, "value_loss": 0.019416793063282967, "policy_loss": -0.0020610514195567474, "dist_entropy": 0.5628539323806763, "actor_grad_norm": 0.21076367795467377, "critic_grad_norm": 0.10167019814252853, "ratio": 0.9998059272766113, "entropy": 0.5628539323806763, "incre_win_rate": 0.11538461538461539, "step": 1329}
{"time": 1767084499.8471878, "phase": "train", "update": 1330, "total_env_steps": 4256000, "episode_reward": 0.12327142059803009, "value_loss": 0.021062584593892097, "policy_loss": -0.0016034504280327156, "dist_entropy": 0.5384369611740112, "actor_grad_norm": 0.1582440286874771, "critic_grad_norm": 0.11828286945819855, "ratio": 1.000096082687378, "entropy": 0.5384369611740112, "incre_win_rate": 0.2413793103448276, "step": 1330}
{"time": 1767084504.7827687, "phase": "train", "update": 1331, "total_env_steps": 4259200, "episode_reward": 0.12350890040397644, "value_loss": 0.023344342783093452, "policy_loss": -0.0016977593948052315, "dist_entropy": 0.5433136701583863, "actor_grad_norm": 0.13798533380031586, "critic_grad_norm": 0.0852367952466011, "ratio": 0.9998623132705688, "entropy": 0.5433136701583863, "incre_win_rate": 0.2, "step": 1331}
{"time": 1767084509.6115205, "phase": "train", "update": 1332, "total_env_steps": 4262400, "episode_reward": 0.12815605103969574, "value_loss": 0.021424274891614914, "policy_loss": -0.00188611911355423, "dist_entropy": 0.5297614693641662, "actor_grad_norm": 0.15261909365653992, "critic_grad_norm": 0.08943522721529007, "ratio": 0.9998959898948669, "entropy": 0.5297614693641662, "incre_win_rate": 0.17857142857142858, "step": 1332}
{"time": 1767084514.566059, "phase": "train", "update": 1333, "total_env_steps": 4265600, "episode_reward": 0.13619308173656464, "value_loss": 0.024781327694654465, "policy_loss": -0.001989654587870859, "dist_entropy": 0.5355425000190734, "actor_grad_norm": 0.13030199706554413, "critic_grad_norm": 0.1701420694589615, "ratio": 1.0000463724136353, "entropy": 0.5355425000190734, "incre_win_rate": 0.30303030303030304, "step": 1333}
{"time": 1767084519.6569467, "phase": "train", "update": 1334, "total_env_steps": 4268800, "episode_reward": 0.14793717861175537, "value_loss": 0.017252539098262788, "policy_loss": -0.0017643711372812732, "dist_entropy": 0.5160745024681092, "actor_grad_norm": 0.14853718876838684, "critic_grad_norm": 0.1477431058883667, "ratio": 0.9999614953994751, "entropy": 0.5160745024681092, "incre_win_rate": 0.2962962962962963, "step": 1334}
{"time": 1767084525.223815, "phase": "train", "update": 1335, "total_env_steps": 4272000, "episode_reward": 0.17936618626117706, "value_loss": 0.01926545985043049, "policy_loss": -0.0015152097552165954, "dist_entropy": 0.48574033975601194, "actor_grad_norm": 0.1687016487121582, "critic_grad_norm": 0.17926499247550964, "ratio": 0.999875545501709, "entropy": 0.48574033975601194, "incre_win_rate": 0.5588235294117647, "step": 1335}
{"time": 1767084530.2824953, "phase": "train", "update": 1336, "total_env_steps": 4275200, "episode_reward": 0.14636951684951782, "value_loss": 0.017084361612796785, "policy_loss": -0.0016539541943799917, "dist_entropy": 0.5165563106536866, "actor_grad_norm": 0.1457364708185196, "critic_grad_norm": 0.11248510330915451, "ratio": 0.9998959898948669, "entropy": 0.5165563106536866, "incre_win_rate": 0.37037037037037035, "step": 1336}
{"time": 1767084535.1879554, "phase": "train", "update": 1337, "total_env_steps": 4278400, "episode_reward": 0.13358546793460846, "value_loss": 0.021193675696849823, "policy_loss": -0.0016111685708267488, "dist_entropy": 0.545264744758606, "actor_grad_norm": 0.17143665254116058, "critic_grad_norm": 0.09765747934579849, "ratio": 0.9998394846916199, "entropy": 0.545264744758606, "incre_win_rate": 0.3103448275862069, "step": 1337}
{"time": 1767084540.378319, "phase": "train", "update": 1338, "total_env_steps": 4281600, "episode_reward": 0.15465283393859863, "value_loss": 0.018425075709819792, "policy_loss": -0.0021452658970275706, "dist_entropy": 0.5186690807342529, "actor_grad_norm": 0.1337631195783615, "critic_grad_norm": 0.11296895891427994, "ratio": 1.0002278089523315, "entropy": 0.5186690807342529, "incre_win_rate": 0.3870967741935484, "step": 1338}
{"time": 1767084545.6482377, "phase": "train", "update": 1339, "total_env_steps": 4284800, "episode_reward": 0.15459385514259338, "value_loss": 0.014539478719234467, "policy_loss": -0.0017008596529590747, "dist_entropy": 0.5003707885742188, "actor_grad_norm": 0.16267625987529755, "critic_grad_norm": 0.086485356092453, "ratio": 0.9998194575309753, "entropy": 0.5003707885742188, "incre_win_rate": 0.41935483870967744, "step": 1339}
{"time": 1767084550.7200954, "phase": "train", "update": 1340, "total_env_steps": 4288000, "episode_reward": 0.1334850937128067, "value_loss": 0.015799164213240145, "policy_loss": -0.002291886463737569, "dist_entropy": 0.5382491827011109, "actor_grad_norm": 0.18052522838115692, "critic_grad_norm": 0.07791150361299515, "ratio": 1.0000869035720825, "entropy": 0.5382491827011109, "incre_win_rate": 0.1724137931034483, "step": 1340}
{"time": 1767084555.781778, "phase": "train", "update": 1341, "total_env_steps": 4291200, "episode_reward": 0.12002948671579361, "value_loss": 0.01897830031812191, "policy_loss": -0.001751232874259756, "dist_entropy": 0.5279560089111328, "actor_grad_norm": 0.1398727148771286, "critic_grad_norm": 0.0860854834318161, "ratio": 0.9999778866767883, "entropy": 0.5279560089111328, "incre_win_rate": 0.19230769230769232, "step": 1341}
{"time": 1767084571.2831402, "phase": "eval", "update": 1341, "total_env_steps": 4291200, "eval_win_rate": 0.53125, "eval_episode_reward": 16.813896937086085, "step": 1341}
{"time": 1767084576.3219774, "phase": "train", "update": 1342, "total_env_steps": 4294400, "episode_reward": 0.15598095953464508, "value_loss": 0.014354193396866322, "policy_loss": -0.00206406689593166, "dist_entropy": 0.5080921292304993, "actor_grad_norm": 0.16782927513122559, "critic_grad_norm": 0.10938799381256104, "ratio": 0.9997769594192505, "entropy": 0.5080921292304993, "incre_win_rate": 0.36666666666666664, "step": 1342}
{"time": 1767084580.9635394, "phase": "train", "update": 1343, "total_env_steps": 4297600, "episode_reward": 0.15014073252677917, "value_loss": 0.013762765936553479, "policy_loss": -0.0014610801674113105, "dist_entropy": 0.504150903224945, "actor_grad_norm": 0.156594380736351, "critic_grad_norm": 0.07203680276870728, "ratio": 0.999785840511322, "entropy": 0.504150903224945, "incre_win_rate": 0.32142857142857145, "step": 1343}
{"time": 1767084585.5539212, "phase": "train", "update": 1344, "total_env_steps": 4300800, "episode_reward": 0.1566489040851593, "value_loss": 0.014787382632493972, "policy_loss": -0.0019623845172134224, "dist_entropy": 0.5007254540920257, "actor_grad_norm": 0.13821625709533691, "critic_grad_norm": 0.05769611522555351, "ratio": 0.999880313873291, "entropy": 0.5007254540920257, "incre_win_rate": 0.4074074074074074, "step": 1344}
{"time": 1767084590.1491432, "phase": "train", "update": 1345, "total_env_steps": 4304000, "episode_reward": 0.1374787837266922, "value_loss": 0.018021785467863084, "policy_loss": -0.0014987730992293891, "dist_entropy": 0.4906093835830688, "actor_grad_norm": 0.16564281284809113, "critic_grad_norm": 0.13246038556098938, "ratio": 1.0002468824386597, "entropy": 0.4906093835830688, "incre_win_rate": 0.22580645161290322, "step": 1345}
{"time": 1767084594.8548431, "phase": "train", "update": 1346, "total_env_steps": 4307200, "episode_reward": 0.1480075716972351, "value_loss": 0.0124907361343503, "policy_loss": -0.001556498430704778, "dist_entropy": 0.5001706779003143, "actor_grad_norm": 0.1504797488451004, "critic_grad_norm": 0.08923985064029694, "ratio": 1.000059723854065, "entropy": 0.5001706779003143, "incre_win_rate": 0.28125, "step": 1346}
{"time": 1767084599.6561563, "phase": "train", "update": 1347, "total_env_steps": 4310400, "episode_reward": 0.14132140576839447, "value_loss": 0.017082083970308304, "policy_loss": -0.0017893504308773346, "dist_entropy": 0.495733505487442, "actor_grad_norm": 0.1825648546218872, "critic_grad_norm": 0.07699557393789291, "ratio": 1.0001578330993652, "entropy": 0.495733505487442, "incre_win_rate": 0.14814814814814814, "step": 1347}
{"time": 1767084604.2869484, "phase": "train", "update": 1348, "total_env_steps": 4313600, "episode_reward": 0.15591834485530853, "value_loss": 0.021059447899460793, "policy_loss": -0.001844361651596671, "dist_entropy": 0.48890124559402465, "actor_grad_norm": 0.15271826088428497, "critic_grad_norm": 0.08320111781358719, "ratio": 0.9998694658279419, "entropy": 0.48890124559402465, "incre_win_rate": 0.34375, "step": 1348}
{"time": 1767084609.1776958, "phase": "train", "update": 1349, "total_env_steps": 4316800, "episode_reward": 0.15969112515449524, "value_loss": 0.014903237111866474, "policy_loss": -0.0016854009727893526, "dist_entropy": 0.48439323902130127, "actor_grad_norm": 0.15246734023094177, "critic_grad_norm": 0.09257900714874268, "ratio": 0.9996998906135559, "entropy": 0.48439323902130127, "incre_win_rate": 0.40625, "step": 1349}
{"time": 1767084613.843051, "phase": "train", "update": 1350, "total_env_steps": 4320000, "episode_reward": 0.1600683033466339, "value_loss": 0.013731521926820279, "policy_loss": -0.0017530231793728035, "dist_entropy": 0.48683532476425173, "actor_grad_norm": 0.14293286204338074, "critic_grad_norm": 0.08438654989004135, "ratio": 1.0001634359359741, "entropy": 0.48683532476425173, "incre_win_rate": 0.4, "step": 1350}
{"time": 1767084618.720881, "phase": "train", "update": 1351, "total_env_steps": 4323200, "episode_reward": 0.14980028569698334, "value_loss": 0.020785247161984443, "policy_loss": -0.0016785927551410396, "dist_entropy": 0.5013058185577393, "actor_grad_norm": 0.1940814107656479, "critic_grad_norm": 0.06370117515325546, "ratio": 1.0000803470611572, "entropy": 0.5013058185577393, "incre_win_rate": 0.36666666666666664, "step": 1351}
{"time": 1767084623.3998785, "phase": "train", "update": 1352, "total_env_steps": 4326400, "episode_reward": 0.15035441517829895, "value_loss": 0.017016516625881196, "policy_loss": -0.0016979176329943613, "dist_entropy": 0.49775769710540774, "actor_grad_norm": 0.1777704805135727, "critic_grad_norm": 0.0717964768409729, "ratio": 1.0003191232681274, "entropy": 0.49775769710540774, "incre_win_rate": 0.27586206896551724, "step": 1352}
{"time": 1767084628.1065004, "phase": "train", "update": 1353, "total_env_steps": 4329600, "episode_reward": 0.14304687082767487, "value_loss": 0.01325441375374794, "policy_loss": -0.0018311596898907823, "dist_entropy": 0.49961995482444765, "actor_grad_norm": 0.19192329049110413, "critic_grad_norm": 0.07339999824762344, "ratio": 0.9997476935386658, "entropy": 0.49961995482444765, "incre_win_rate": 0.2222222222222222, "step": 1353}
{"time": 1767084632.7562115, "phase": "train", "update": 1354, "total_env_steps": 4332800, "episode_reward": 0.1443827599287033, "value_loss": 0.016999197006225587, "policy_loss": -0.0015624604973702104, "dist_entropy": 0.5260740637779235, "actor_grad_norm": 0.19333060085773468, "critic_grad_norm": 0.07372363656759262, "ratio": 0.9998915791511536, "entropy": 0.5260740637779235, "incre_win_rate": 0.3, "step": 1354}
{"time": 1767084637.2986662, "phase": "train", "update": 1355, "total_env_steps": 4336000, "episode_reward": 0.1498013287782669, "value_loss": 0.015526563860476017, "policy_loss": -0.0016780456983354953, "dist_entropy": 0.487110847234726, "actor_grad_norm": 0.1298852264881134, "critic_grad_norm": 0.11731842905282974, "ratio": 1.000029444694519, "entropy": 0.487110847234726, "incre_win_rate": 0.3333333333333333, "step": 1355}
{"time": 1767084641.9927104, "phase": "train", "update": 1356, "total_env_steps": 4339200, "episode_reward": 0.16248446702957153, "value_loss": 0.01355204414576292, "policy_loss": -0.001307052079623261, "dist_entropy": 0.4935232996940613, "actor_grad_norm": 0.13520483672618866, "critic_grad_norm": 0.08535528182983398, "ratio": 0.9998273253440857, "entropy": 0.4935232996940613, "incre_win_rate": 0.41379310344827586, "step": 1356}
{"time": 1767084646.7044723, "phase": "train", "update": 1357, "total_env_steps": 4342400, "episode_reward": 0.16127018630504608, "value_loss": 0.01528982650488615, "policy_loss": -0.002095022844084471, "dist_entropy": 0.4954515755176544, "actor_grad_norm": 0.20734016597270966, "critic_grad_norm": 0.04892479255795479, "ratio": 0.9999160170555115, "entropy": 0.4954515755176544, "incre_win_rate": 0.36363636363636365, "step": 1357}
{"time": 1767084651.3775263, "phase": "train", "update": 1358, "total_env_steps": 4345600, "episode_reward": 0.15309810638427734, "value_loss": 0.01463420782238245, "policy_loss": -0.0016745295188684394, "dist_entropy": 0.4751167118549347, "actor_grad_norm": 0.14903192222118378, "critic_grad_norm": 0.03457598760724068, "ratio": 1.000052809715271, "entropy": 0.4751167118549347, "incre_win_rate": 0.3225806451612903, "step": 1358}
{"time": 1767084656.0509164, "phase": "train", "update": 1359, "total_env_steps": 4348800, "episode_reward": 0.16330349445343018, "value_loss": 0.01740790791809559, "policy_loss": -0.0018864229536909249, "dist_entropy": 0.47595704197883604, "actor_grad_norm": 0.13132570683956146, "critic_grad_norm": 0.029144763946533203, "ratio": 0.9999438524246216, "entropy": 0.47595704197883604, "incre_win_rate": 0.43333333333333335, "step": 1359}
{"time": 1767084660.8441908, "phase": "train", "update": 1360, "total_env_steps": 4352000, "episode_reward": 0.15231114625930786, "value_loss": 0.017074733227491378, "policy_loss": -0.0020761933288440558, "dist_entropy": 0.4818392515182495, "actor_grad_norm": 0.1769685000181198, "critic_grad_norm": 0.030209867283701897, "ratio": 0.9999507069587708, "entropy": 0.4818392515182495, "incre_win_rate": 0.3333333333333333, "step": 1360}
{"time": 1767084665.6235085, "phase": "train", "update": 1361, "total_env_steps": 4355200, "episode_reward": 0.15286579728126526, "value_loss": 0.015515297278761863, "policy_loss": -0.0016563322714798546, "dist_entropy": 0.4775029182434082, "actor_grad_norm": 0.14695842564105988, "critic_grad_norm": 0.08055904507637024, "ratio": 0.9995919466018677, "entropy": 0.4775029182434082, "incre_win_rate": 0.1935483870967742, "step": 1361}
{"time": 1767084679.0339007, "phase": "eval", "update": 1361, "total_env_steps": 4355200, "eval_win_rate": 0.65625, "eval_episode_reward": 17.880070364238406, "step": 1361}
{"time": 1767084683.715672, "phase": "train", "update": 1362, "total_env_steps": 4358400, "episode_reward": 0.15938173234462738, "value_loss": 0.019496017321944236, "policy_loss": -0.0014668073574448214, "dist_entropy": 0.47944048047065735, "actor_grad_norm": 0.14886850118637085, "critic_grad_norm": 0.07164396345615387, "ratio": 0.9999287724494934, "entropy": 0.47944048047065735, "incre_win_rate": 0.34285714285714286, "step": 1362}
{"time": 1767084688.289983, "phase": "train", "update": 1363, "total_env_steps": 4361600, "episode_reward": 0.1711154729127884, "value_loss": 0.016128852590918542, "policy_loss": -0.0014008285417745014, "dist_entropy": 0.47736126780509947, "actor_grad_norm": 0.12104654312133789, "critic_grad_norm": 0.06778955459594727, "ratio": 0.9996694922447205, "entropy": 0.47736126780509947, "incre_win_rate": 0.45454545454545453, "step": 1363}
{"time": 1767084692.8535018, "phase": "train", "update": 1364, "total_env_steps": 4364800, "episode_reward": 0.1782548725605011, "value_loss": 0.016346435621380807, "policy_loss": -0.0014166136272251606, "dist_entropy": 0.4691340744495392, "actor_grad_norm": 0.13174577057361603, "critic_grad_norm": 0.06359044462442398, "ratio": 1.0002883672714233, "entropy": 0.4691340744495392, "incre_win_rate": 0.4411764705882353, "step": 1364}
{"time": 1767084697.3695953, "phase": "train", "update": 1365, "total_env_steps": 4368000, "episode_reward": 0.17492394149303436, "value_loss": 0.015529726445674897, "policy_loss": -0.001537832464140365, "dist_entropy": 0.49657468795776366, "actor_grad_norm": 0.1588309407234192, "critic_grad_norm": 0.06846851110458374, "ratio": 0.9999534487724304, "entropy": 0.49657468795776366, "incre_win_rate": 0.47058823529411764, "step": 1365}
{"time": 1767084701.8964064, "phase": "train", "update": 1366, "total_env_steps": 4371200, "episode_reward": 0.16324710845947266, "value_loss": 0.017349131032824518, "policy_loss": -0.0012649410664636207, "dist_entropy": 0.48531736731529235, "actor_grad_norm": 0.16023822128772736, "critic_grad_norm": 0.07632631063461304, "ratio": 1.0000886917114258, "entropy": 0.48531736731529235, "incre_win_rate": 0.3793103448275862, "step": 1366}
{"time": 1767084706.4623785, "phase": "train", "update": 1367, "total_env_steps": 4374400, "episode_reward": 0.15015780925750732, "value_loss": 0.017296132817864417, "policy_loss": -0.0015437422308053784, "dist_entropy": 0.473280656337738, "actor_grad_norm": 0.15793679654598236, "critic_grad_norm": 0.042593855410814285, "ratio": 1.0001252889633179, "entropy": 0.473280656337738, "incre_win_rate": 0.25806451612903225, "step": 1367}
{"time": 1767084711.049473, "phase": "train", "update": 1368, "total_env_steps": 4377600, "episode_reward": 0.17696347832679749, "value_loss": 0.017006511613726617, "policy_loss": -0.0017340607761951788, "dist_entropy": 0.4664450943470001, "actor_grad_norm": 0.17105945944786072, "critic_grad_norm": 0.06270956248044968, "ratio": 1.0002243518829346, "entropy": 0.4664450943470001, "incre_win_rate": 0.47058823529411764, "step": 1368}
{"time": 1767084715.6212265, "phase": "train", "update": 1369, "total_env_steps": 4380800, "episode_reward": 0.17678654193878174, "value_loss": 0.01898644007742405, "policy_loss": -0.001365367184972799, "dist_entropy": 0.46952234506607055, "actor_grad_norm": 0.15698175132274628, "critic_grad_norm": 0.0641254410147667, "ratio": 1.0000888109207153, "entropy": 0.46952234506607055, "incre_win_rate": 0.4473684210526316, "step": 1369}
{"time": 1767084720.2075136, "phase": "train", "update": 1370, "total_env_steps": 4384000, "episode_reward": 0.17232616245746613, "value_loss": 0.015577367134392261, "policy_loss": -0.0013591916652330837, "dist_entropy": 0.46149286031723025, "actor_grad_norm": 0.1415688842535019, "critic_grad_norm": 0.05638159438967705, "ratio": 0.9998459815979004, "entropy": 0.46149286031723025, "incre_win_rate": 0.42424242424242425, "step": 1370}
{"time": 1767084724.7072062, "phase": "train", "update": 1371, "total_env_steps": 4387200, "episode_reward": 0.15234945714473724, "value_loss": 0.017002545297145844, "policy_loss": -0.0018162995223944378, "dist_entropy": 0.49287558197975156, "actor_grad_norm": 0.12526783347129822, "critic_grad_norm": 0.05007048323750496, "ratio": 0.9998998641967773, "entropy": 0.49287558197975156, "incre_win_rate": 0.21875, "step": 1371}
{"time": 1767084729.399341, "phase": "train", "update": 1372, "total_env_steps": 4390400, "episode_reward": 0.16800083220005035, "value_loss": 0.015625203400850295, "policy_loss": -0.0018476671208279782, "dist_entropy": 0.49903454184532164, "actor_grad_norm": 0.14301450550556183, "critic_grad_norm": 0.029063725844025612, "ratio": 1.000078558921814, "entropy": 0.49903454184532164, "incre_win_rate": 0.45454545454545453, "step": 1372}
{"time": 1767084734.0641186, "phase": "train", "update": 1373, "total_env_steps": 4393600, "episode_reward": 0.15718956291675568, "value_loss": 0.017426992207765578, "policy_loss": -0.0015923099509450368, "dist_entropy": 0.48749831318855286, "actor_grad_norm": 0.12222995609045029, "critic_grad_norm": 0.022053828462958336, "ratio": 0.9998939633369446, "entropy": 0.48749831318855286, "incre_win_rate": 0.3235294117647059, "step": 1373}
{"time": 1767084738.8373415, "phase": "train", "update": 1374, "total_env_steps": 4396800, "episode_reward": 0.1629677265882492, "value_loss": 0.02063555344939232, "policy_loss": -0.001659105624582935, "dist_entropy": 0.5014933228492737, "actor_grad_norm": 0.1555599421262741, "critic_grad_norm": 0.055483877658843994, "ratio": 0.9999839067459106, "entropy": 0.5014933228492737, "incre_win_rate": 0.375, "step": 1374}
{"time": 1767084743.7288222, "phase": "train", "update": 1375, "total_env_steps": 4400000, "episode_reward": 0.149486243724823, "value_loss": 0.014494734443724155, "policy_loss": -0.0020316131247270163, "dist_entropy": 0.5219937682151794, "actor_grad_norm": 0.1684717983007431, "critic_grad_norm": 0.04030623659491539, "ratio": 1.0001028776168823, "entropy": 0.5219937682151794, "incre_win_rate": 0.22580645161290322, "step": 1375}
{"time": 1767084748.3182979, "phase": "train", "update": 1376, "total_env_steps": 4403200, "episode_reward": 0.15563587844371796, "value_loss": 0.0172699224203825, "policy_loss": -0.0016867526945631539, "dist_entropy": 0.5079900979995727, "actor_grad_norm": 0.17948122322559357, "critic_grad_norm": 0.06924896687269211, "ratio": 0.999858558177948, "entropy": 0.5079900979995727, "incre_win_rate": 0.25806451612903225, "step": 1376}
{"time": 1767084752.9722886, "phase": "train", "update": 1377, "total_env_steps": 4406400, "episode_reward": 0.1492844521999359, "value_loss": 0.01743617430329323, "policy_loss": -0.0017537599354763955, "dist_entropy": 0.5343064904212952, "actor_grad_norm": 0.128323495388031, "critic_grad_norm": 0.0688798800110817, "ratio": 0.9998325705528259, "entropy": 0.5343064904212952, "incre_win_rate": 0.3225806451612903, "step": 1377}
{"time": 1767084757.9498134, "phase": "train", "update": 1378, "total_env_steps": 4409600, "episode_reward": 0.13508795201778412, "value_loss": 0.015887522138655186, "policy_loss": -0.0015984139755467197, "dist_entropy": 0.5534606814384461, "actor_grad_norm": 0.14463749527931213, "critic_grad_norm": 0.053714971989393234, "ratio": 0.9999715089797974, "entropy": 0.5534606814384461, "incre_win_rate": 0.1, "step": 1378}
{"time": 1767084763.0201178, "phase": "train", "update": 1379, "total_env_steps": 4412800, "episode_reward": 0.145533949136734, "value_loss": 0.015666679292917252, "policy_loss": -0.0017351876628595164, "dist_entropy": 0.5328100442886352, "actor_grad_norm": 0.1361350566148758, "critic_grad_norm": 0.041042260825634, "ratio": 0.9998480677604675, "entropy": 0.5328100442886352, "incre_win_rate": 0.23333333333333334, "step": 1379}
{"time": 1767084768.090389, "phase": "train", "update": 1380, "total_env_steps": 4416000, "episode_reward": 0.1486651450395584, "value_loss": 0.020689628645777704, "policy_loss": -0.001467466234598902, "dist_entropy": 0.5320675134658813, "actor_grad_norm": 0.12057564407587051, "critic_grad_norm": 0.04142674431204796, "ratio": 0.999993622303009, "entropy": 0.5320675134658813, "incre_win_rate": 0.25806451612903225, "step": 1380}
{"time": 1767084773.156545, "phase": "train", "update": 1381, "total_env_steps": 4419200, "episode_reward": 0.16474337875843048, "value_loss": 0.017878305166959763, "policy_loss": -0.001492377970735248, "dist_entropy": 0.5241316437721253, "actor_grad_norm": 0.17425939440727234, "critic_grad_norm": 0.09652334451675415, "ratio": 1.000444769859314, "entropy": 0.5241316437721253, "incre_win_rate": 0.38235294117647056, "step": 1381}
{"time": 1767084787.5064876, "phase": "eval", "update": 1381, "total_env_steps": 4419200, "eval_win_rate": 0.78125, "eval_episode_reward": 18.663855546357613, "step": 1381}
{"time": 1767084792.3084426, "phase": "train", "update": 1382, "total_env_steps": 4422400, "episode_reward": 0.16276437044143677, "value_loss": 0.017533089220523834, "policy_loss": -0.0016424462817099083, "dist_entropy": 0.5171399712562561, "actor_grad_norm": 0.12865202128887177, "critic_grad_norm": 0.07907623797655106, "ratio": 0.9995771646499634, "entropy": 0.5171399712562561, "incre_win_rate": 0.34375, "step": 1382}
{"time": 1767084796.8576446, "phase": "train", "update": 1383, "total_env_steps": 4425600, "episode_reward": 0.1546078324317932, "value_loss": 0.020095452293753625, "policy_loss": -0.0015879384724186707, "dist_entropy": 0.5234394311904907, "actor_grad_norm": 0.15617352724075317, "critic_grad_norm": 0.06277696788311005, "ratio": 1.0003098249435425, "entropy": 0.5234394311904907, "incre_win_rate": 0.25, "step": 1383}
{"time": 1767084801.4235039, "phase": "train", "update": 1384, "total_env_steps": 4428800, "episode_reward": 0.16634468734264374, "value_loss": 0.016370842047035695, "policy_loss": -0.0022024260361359184, "dist_entropy": 0.5290570735931397, "actor_grad_norm": 0.20291125774383545, "critic_grad_norm": 0.11620395630598068, "ratio": 0.9998859763145447, "entropy": 0.5290570735931397, "incre_win_rate": 0.4117647058823529, "step": 1384}
{"time": 1767084806.045522, "phase": "train", "update": 1385, "total_env_steps": 4432000, "episode_reward": 0.17521989345550537, "value_loss": 0.021485766023397447, "policy_loss": -0.0012451255627041302, "dist_entropy": 0.525510823726654, "actor_grad_norm": 0.1406782865524292, "critic_grad_norm": 0.09106596559286118, "ratio": 1.0001873970031738, "entropy": 0.525510823726654, "incre_win_rate": 0.4166666666666667, "step": 1385}
{"time": 1767084810.628409, "phase": "train", "update": 1386, "total_env_steps": 4435200, "episode_reward": 0.1572640836238861, "value_loss": 0.021858123317360877, "policy_loss": -0.0018914234209894687, "dist_entropy": 0.5549176692962646, "actor_grad_norm": 0.16455037891864777, "critic_grad_norm": 0.08806400001049042, "ratio": 1.000033974647522, "entropy": 0.5549176692962646, "incre_win_rate": 0.3, "step": 1386}
{"time": 1767084815.0833962, "phase": "train", "update": 1387, "total_env_steps": 4438400, "episode_reward": 0.1380184143781662, "value_loss": 0.01504573319107294, "policy_loss": -0.0015301063094575796, "dist_entropy": 0.5694032073020935, "actor_grad_norm": 0.15639905631542206, "critic_grad_norm": 0.1001518964767456, "ratio": 1.0001434087753296, "entropy": 0.5694032073020935, "incre_win_rate": 0.2413793103448276, "step": 1387}
{"time": 1767084819.9158182, "phase": "train", "update": 1388, "total_env_steps": 4441600, "episode_reward": 0.14938689768314362, "value_loss": 0.01636888012290001, "policy_loss": -0.0017952774442775877, "dist_entropy": 0.5422574520111084, "actor_grad_norm": 0.1485060304403305, "critic_grad_norm": 0.06349027901887894, "ratio": 0.9999105334281921, "entropy": 0.5422574520111084, "incre_win_rate": 0.37037037037037035, "step": 1388}
{"time": 1767084824.5389912, "phase": "train", "update": 1389, "total_env_steps": 4444800, "episode_reward": 0.15577659010887146, "value_loss": 0.012696607783436776, "policy_loss": -0.0017415183593133322, "dist_entropy": 0.552179491519928, "actor_grad_norm": 0.1452094167470932, "critic_grad_norm": 0.04761167988181114, "ratio": 0.9997046589851379, "entropy": 0.552179491519928, "incre_win_rate": 0.36666666666666664, "step": 1389}
{"time": 1767084829.1674361, "phase": "train", "update": 1390, "total_env_steps": 4448000, "episode_reward": 0.1771833598613739, "value_loss": 0.014114565588533879, "policy_loss": -0.0016837198305267975, "dist_entropy": 0.515087342262268, "actor_grad_norm": 0.12255513668060303, "critic_grad_norm": 0.06483375281095505, "ratio": 1.0000131130218506, "entropy": 0.515087342262268, "incre_win_rate": 0.45714285714285713, "step": 1390}
{"time": 1767084833.8995242, "phase": "train", "update": 1391, "total_env_steps": 4451200, "episode_reward": 0.1526329666376114, "value_loss": 0.016072522103786468, "policy_loss": -0.0016551828198910989, "dist_entropy": 0.5302834272384643, "actor_grad_norm": 0.1529172658920288, "critic_grad_norm": 0.07260482758283615, "ratio": 0.9995989203453064, "entropy": 0.5302834272384643, "incre_win_rate": 0.2903225806451613, "step": 1391}
{"time": 1767084838.584237, "phase": "train", "update": 1392, "total_env_steps": 4454400, "episode_reward": 0.15003985166549683, "value_loss": 0.019070442020893096, "policy_loss": -0.0017644374149057285, "dist_entropy": 0.5360901355743408, "actor_grad_norm": 0.13279381394386292, "critic_grad_norm": 0.11878695338964462, "ratio": 1.0003412961959839, "entropy": 0.5360901355743408, "incre_win_rate": 0.21212121212121213, "step": 1392}
{"time": 1767084843.2526546, "phase": "train", "update": 1393, "total_env_steps": 4457600, "episode_reward": 0.15142953395843506, "value_loss": 0.016062304750084876, "policy_loss": -0.001567560993777306, "dist_entropy": 0.5315937280654908, "actor_grad_norm": 0.13013210892677307, "critic_grad_norm": 0.10430800169706345, "ratio": 0.9997925162315369, "entropy": 0.5315937280654908, "incre_win_rate": 0.41379310344827586, "step": 1393}
{"time": 1767084847.8587613, "phase": "train", "update": 1394, "total_env_steps": 4460800, "episode_reward": 0.141103595495224, "value_loss": 0.01791749782860279, "policy_loss": -0.001998126596939187, "dist_entropy": 0.5350976824760437, "actor_grad_norm": 0.16021792590618134, "critic_grad_norm": 0.11614998430013657, "ratio": 0.9996596574783325, "entropy": 0.5350976824760437, "incre_win_rate": 0.16129032258064516, "step": 1394}
{"time": 1767084852.4530525, "phase": "train", "update": 1395, "total_env_steps": 4464000, "episode_reward": 0.14024627208709717, "value_loss": 0.016579838842153548, "policy_loss": -0.0017581735069967408, "dist_entropy": 0.5430371522903442, "actor_grad_norm": 0.1575040966272354, "critic_grad_norm": 0.058699268847703934, "ratio": 1.0002909898757935, "entropy": 0.5430371522903442, "incre_win_rate": 0.25806451612903225, "step": 1395}
{"time": 1767084857.1628203, "phase": "train", "update": 1396, "total_env_steps": 4467200, "episode_reward": 0.15398696064949036, "value_loss": 0.018770568445324896, "policy_loss": -0.0013918448020714181, "dist_entropy": 0.5166167855262757, "actor_grad_norm": 0.1557752937078476, "critic_grad_norm": 0.035310596227645874, "ratio": 0.9996978044509888, "entropy": 0.5166167855262757, "incre_win_rate": 0.2571428571428571, "step": 1396}
{"time": 1767084861.8337026, "phase": "train", "update": 1397, "total_env_steps": 4470400, "episode_reward": 0.1604263335466385, "value_loss": 0.01835915707051754, "policy_loss": -0.0014207881856858062, "dist_entropy": 0.5228464722633361, "actor_grad_norm": 0.17021076381206512, "critic_grad_norm": 0.07531722635030746, "ratio": 1.000108242034912, "entropy": 0.5228464722633361, "incre_win_rate": 0.30303030303030304, "step": 1397}
{"time": 1767084866.4854872, "phase": "train", "update": 1398, "total_env_steps": 4473600, "episode_reward": 0.15852701663970947, "value_loss": 0.018275317922234535, "policy_loss": -0.0015173357619957528, "dist_entropy": 0.5110355615615845, "actor_grad_norm": 0.1330125331878662, "critic_grad_norm": 0.06587188690900803, "ratio": 1.0001825094223022, "entropy": 0.5110355615615845, "incre_win_rate": 0.25, "step": 1398}
{"time": 1767084871.205176, "phase": "train", "update": 1399, "total_env_steps": 4476800, "episode_reward": 0.1578647643327713, "value_loss": 0.018489047512412073, "policy_loss": -0.0013907660914441067, "dist_entropy": 0.5127729296684265, "actor_grad_norm": 0.11232510954141617, "critic_grad_norm": 0.03349349647760391, "ratio": 0.9999305605888367, "entropy": 0.5127729296684265, "incre_win_rate": 0.21875, "step": 1399}
{"time": 1767084876.0854075, "phase": "train", "update": 1400, "total_env_steps": 4480000, "episode_reward": 0.17695312201976776, "value_loss": 0.015673128701746464, "policy_loss": -0.001764553425950055, "dist_entropy": 0.4864950954914093, "actor_grad_norm": 0.18315602838993073, "critic_grad_norm": 0.05770018324255943, "ratio": 0.9997972846031189, "entropy": 0.4864950954914093, "incre_win_rate": 0.3783783783783784, "step": 1400}
{"time": 1767084880.6957042, "phase": "train", "update": 1401, "total_env_steps": 4483200, "episode_reward": 0.15691328048706055, "value_loss": 0.01827910952270031, "policy_loss": -0.0016468879093082477, "dist_entropy": 0.5069509983062744, "actor_grad_norm": 0.10655956715345383, "critic_grad_norm": 0.04600555822253227, "ratio": 0.9999179840087891, "entropy": 0.5069509983062744, "incre_win_rate": 0.3333333333333333, "step": 1401}
{"time": 1767084894.7547984, "phase": "eval", "update": 1401, "total_env_steps": 4483200, "eval_win_rate": 0.3125, "eval_episode_reward": 16.203228476821185, "step": 1401}
{"time": 1767084899.4011786, "phase": "train", "update": 1402, "total_env_steps": 4486400, "episode_reward": 0.15391351282596588, "value_loss": 0.01864585392177105, "policy_loss": -0.0017914572396207974, "dist_entropy": 0.5224825263023376, "actor_grad_norm": 0.1257011741399765, "critic_grad_norm": 0.13239896297454834, "ratio": 0.9998137354850769, "entropy": 0.5224825263023376, "incre_win_rate": 0.14705882352941177, "step": 1402}
{"time": 1767084904.0838597, "phase": "train", "update": 1403, "total_env_steps": 4489600, "episode_reward": 0.14992757141590118, "value_loss": 0.018396776542067526, "policy_loss": -0.0016546141572746365, "dist_entropy": 0.5235559344291687, "actor_grad_norm": 0.12139284610748291, "critic_grad_norm": 0.03956582769751549, "ratio": 0.9999085664749146, "entropy": 0.5235559344291687, "incre_win_rate": 0.2, "step": 1403}
{"time": 1767084908.763634, "phase": "train", "update": 1404, "total_env_steps": 4492800, "episode_reward": 0.15927410125732422, "value_loss": 0.015528985112905503, "policy_loss": -0.0017759503471886263, "dist_entropy": 0.503076696395874, "actor_grad_norm": 0.1256977766752243, "critic_grad_norm": 0.030290335416793823, "ratio": 0.9997653365135193, "entropy": 0.503076696395874, "incre_win_rate": 0.19444444444444445, "step": 1404}
{"time": 1767084913.3613877, "phase": "train", "update": 1405, "total_env_steps": 4496000, "episode_reward": 0.15678083896636963, "value_loss": 0.013794461451470851, "policy_loss": -0.002079293023038531, "dist_entropy": 0.5217970848083496, "actor_grad_norm": 0.20647139847278595, "critic_grad_norm": 0.025457188487052917, "ratio": 0.9996471405029297, "entropy": 0.5217970848083496, "incre_win_rate": 0.23529411764705882, "step": 1405}
{"time": 1767084917.992267, "phase": "train", "update": 1406, "total_env_steps": 4499200, "episode_reward": 0.17666961252689362, "value_loss": 0.016939954087138175, "policy_loss": -0.001615769581455595, "dist_entropy": 0.4922947585582733, "actor_grad_norm": 0.13383011519908905, "critic_grad_norm": 0.08448553085327148, "ratio": 1.0000280141830444, "entropy": 0.4922947585582733, "incre_win_rate": 0.35294117647058826, "step": 1406}
{"time": 1767084922.6259317, "phase": "train", "update": 1407, "total_env_steps": 4502400, "episode_reward": 0.1684400886297226, "value_loss": 0.016582205891609192, "policy_loss": -0.0016099378082174098, "dist_entropy": 0.5050557732582093, "actor_grad_norm": 0.12383725494146347, "critic_grad_norm": 0.07276324182748795, "ratio": 1.0000182390213013, "entropy": 0.5050557732582093, "incre_win_rate": 0.3783783783783784, "step": 1407}
{"time": 1767084927.33525, "phase": "train", "update": 1408, "total_env_steps": 4505600, "episode_reward": 0.16304689645767212, "value_loss": 0.018576662242412566, "policy_loss": -0.0019301039758403248, "dist_entropy": 0.5096488952636719, "actor_grad_norm": 0.15296149253845215, "critic_grad_norm": 0.13945172727108002, "ratio": 1.0000605583190918, "entropy": 0.5096488952636719, "incre_win_rate": 0.2647058823529412, "step": 1408}
{"time": 1767084931.8807538, "phase": "train", "update": 1409, "total_env_steps": 4508800, "episode_reward": 0.1350993514060974, "value_loss": 0.020160259306430818, "policy_loss": -0.00192647426522754, "dist_entropy": 0.5454267024993896, "actor_grad_norm": 0.12839244306087494, "critic_grad_norm": 0.10158431529998779, "ratio": 0.9999128580093384, "entropy": 0.5454267024993896, "incre_win_rate": 0.12121212121212122, "step": 1409}
{"time": 1767084936.4547095, "phase": "train", "update": 1410, "total_env_steps": 4512000, "episode_reward": 0.15459592640399933, "value_loss": 0.015037462860345841, "policy_loss": -0.0019361900331965388, "dist_entropy": 0.5144328236579895, "actor_grad_norm": 0.12355818599462509, "critic_grad_norm": 0.06406866014003754, "ratio": 1.0001499652862549, "entropy": 0.5144328236579895, "incre_win_rate": 0.3125, "step": 1410}
{"time": 1767084941.1725798, "phase": "train", "update": 1411, "total_env_steps": 4515200, "episode_reward": 0.13796719908714294, "value_loss": 0.015425441041588783, "policy_loss": -0.0018967489394967174, "dist_entropy": 0.5295561194419861, "actor_grad_norm": 0.15616115927696228, "critic_grad_norm": 0.046667054295539856, "ratio": 1.0000041723251343, "entropy": 0.5295561194419861, "incre_win_rate": 0.0967741935483871, "step": 1411}
{"time": 1767084945.723601, "phase": "train", "update": 1412, "total_env_steps": 4518400, "episode_reward": 0.15814673900604248, "value_loss": 0.01589162554591894, "policy_loss": -0.0019410600430042279, "dist_entropy": 0.5138444423675537, "actor_grad_norm": 0.14034657180309296, "critic_grad_norm": 0.07978882640600204, "ratio": 0.9996261596679688, "entropy": 0.5138444423675537, "incre_win_rate": 0.30303030303030304, "step": 1412}
{"time": 1767084950.2550175, "phase": "train", "update": 1413, "total_env_steps": 4521600, "episode_reward": 0.141704261302948, "value_loss": 0.013922321051359177, "policy_loss": -0.0018676238572055582, "dist_entropy": 0.5211135983467102, "actor_grad_norm": 0.15300779044628143, "critic_grad_norm": 0.07838084548711777, "ratio": 0.9999513626098633, "entropy": 0.5211135983467102, "incre_win_rate": 0.2413793103448276, "step": 1413}
{"time": 1767084954.8478682, "phase": "train", "update": 1414, "total_env_steps": 4524800, "episode_reward": 0.1431441456079483, "value_loss": 0.018380021676421165, "policy_loss": -0.00156270487016954, "dist_entropy": 0.5157673954963684, "actor_grad_norm": 0.12848083674907684, "critic_grad_norm": 0.08570395410060883, "ratio": 1.0002144575119019, "entropy": 0.5157673954963684, "incre_win_rate": 0.25, "step": 1414}
{"time": 1767084959.388159, "phase": "train", "update": 1415, "total_env_steps": 4528000, "episode_reward": 0.15825383365154266, "value_loss": 0.015461236983537675, "policy_loss": -0.001707321667332451, "dist_entropy": 0.5039962887763977, "actor_grad_norm": 0.1534690260887146, "critic_grad_norm": 0.09127917140722275, "ratio": 1.0001510381698608, "entropy": 0.5039962887763977, "incre_win_rate": 0.20588235294117646, "step": 1415}
{"time": 1767084964.0376184, "phase": "train", "update": 1416, "total_env_steps": 4531200, "episode_reward": 0.1262163668870926, "value_loss": 0.015824644081294536, "policy_loss": -0.0014625393025756495, "dist_entropy": 0.5273833513259888, "actor_grad_norm": 0.13862565159797668, "critic_grad_norm": 0.09514807164669037, "ratio": 0.999846875667572, "entropy": 0.5273833513259888, "incre_win_rate": 0.0967741935483871, "step": 1416}
{"time": 1767084968.8968644, "phase": "train", "update": 1417, "total_env_steps": 4534400, "episode_reward": 0.1631922721862793, "value_loss": 0.013420199416577816, "policy_loss": -0.001322287999892069, "dist_entropy": 0.48307348489761354, "actor_grad_norm": 0.14622871577739716, "critic_grad_norm": 0.05202065780758858, "ratio": 0.9999991655349731, "entropy": 0.48307348489761354, "incre_win_rate": 0.14285714285714285, "step": 1417}
{"time": 1767084973.69934, "phase": "train", "update": 1418, "total_env_steps": 4537600, "episode_reward": 0.14367134869098663, "value_loss": 0.01997132822871208, "policy_loss": -0.0013142710543977642, "dist_entropy": 0.5206994771957397, "actor_grad_norm": 0.0979771837592125, "critic_grad_norm": 0.05644906312227249, "ratio": 1.0000355243682861, "entropy": 0.5206994771957397, "incre_win_rate": 0.23333333333333334, "step": 1418}
{"time": 1767084978.4088242, "phase": "train", "update": 1419, "total_env_steps": 4540800, "episode_reward": 0.1562577486038208, "value_loss": 0.014860492385923862, "policy_loss": -0.0012956061434088895, "dist_entropy": 0.4828025996685028, "actor_grad_norm": 0.14299428462982178, "critic_grad_norm": 0.05939863994717598, "ratio": 0.9999406933784485, "entropy": 0.4828025996685028, "incre_win_rate": 0.15789473684210525, "step": 1419}
{"time": 1767084983.0821886, "phase": "train", "update": 1420, "total_env_steps": 4544000, "episode_reward": 0.1574125736951828, "value_loss": 0.016422636061906814, "policy_loss": -0.0016484502813781886, "dist_entropy": 0.5072414994239807, "actor_grad_norm": 0.1347590982913971, "critic_grad_norm": 0.12186411768198013, "ratio": 0.9998010993003845, "entropy": 0.5072414994239807, "incre_win_rate": 0.28125, "step": 1420}
{"time": 1767084987.6338658, "phase": "train", "update": 1421, "total_env_steps": 4547200, "episode_reward": 0.15662148594856262, "value_loss": 0.015055114217102528, "policy_loss": -0.0014869423463231613, "dist_entropy": 0.48687671422958373, "actor_grad_norm": 0.1695086508989334, "critic_grad_norm": 0.08930789679288864, "ratio": 1.0000724792480469, "entropy": 0.48687671422958373, "incre_win_rate": 0.25, "step": 1421}
{"time": 1767085002.615333, "phase": "eval", "update": 1421, "total_env_steps": 4547200, "eval_win_rate": 0.5, "eval_episode_reward": 16.878725165562905, "step": 1421}
{"time": 1767085007.8148818, "phase": "train", "update": 1422, "total_env_steps": 4550400, "episode_reward": 0.1680298000574112, "value_loss": 0.016789378225803377, "policy_loss": -0.0013444384981823986, "dist_entropy": 0.4658577084541321, "actor_grad_norm": 0.10664290189743042, "critic_grad_norm": 0.06255217641592026, "ratio": 0.9998939633369446, "entropy": 0.4658577084541321, "incre_win_rate": 0.22857142857142856, "step": 1422}
{"time": 1767085013.7018645, "phase": "train", "update": 1423, "total_env_steps": 4553600, "episode_reward": 0.1975470930337906, "value_loss": 0.015897229313850403, "policy_loss": -0.001378304309166367, "dist_entropy": 0.4647083103656769, "actor_grad_norm": 0.1802208423614502, "critic_grad_norm": 0.05639242008328438, "ratio": 0.9999244809150696, "entropy": 0.4647083103656769, "incre_win_rate": 0.5, "step": 1423}
{"time": 1767085018.6551976, "phase": "train", "update": 1424, "total_env_steps": 4556800, "episode_reward": 0.17260192334651947, "value_loss": 0.019388966634869574, "policy_loss": -0.0013584459254499138, "dist_entropy": 0.49436248540878297, "actor_grad_norm": 0.11176087707281113, "critic_grad_norm": 0.08941866457462311, "ratio": 0.9998584985733032, "entropy": 0.49436248540878297, "incre_win_rate": 0.2972972972972973, "step": 1424}
{"time": 1767085023.3447049, "phase": "train", "update": 1425, "total_env_steps": 4560000, "episode_reward": 0.19054584205150604, "value_loss": 0.017329845950007437, "policy_loss": -0.0013806964909448994, "dist_entropy": 0.4629837989807129, "actor_grad_norm": 0.13851743936538696, "critic_grad_norm": 0.04842215031385422, "ratio": 1.0002555847167969, "entropy": 0.4629837989807129, "incre_win_rate": 0.5142857142857142, "step": 1425}
{"time": 1767085027.9375124, "phase": "train", "update": 1426, "total_env_steps": 4563200, "episode_reward": 0.16218024492263794, "value_loss": 0.018924424052238466, "policy_loss": -0.00152588540620755, "dist_entropy": 0.49357754588127134, "actor_grad_norm": 0.13779595494270325, "critic_grad_norm": 0.11171010881662369, "ratio": 0.9996453523635864, "entropy": 0.49357754588127134, "incre_win_rate": 0.2777777777777778, "step": 1426}
{"time": 1767085032.5666742, "phase": "train", "update": 1427, "total_env_steps": 4566400, "episode_reward": 0.16190706193447113, "value_loss": 0.017760814726352693, "policy_loss": -0.0015741952160187368, "dist_entropy": 0.4962255537509918, "actor_grad_norm": 0.13739946484565735, "critic_grad_norm": 0.0628056675195694, "ratio": 0.9998573660850525, "entropy": 0.4962255537509918, "incre_win_rate": 0.25, "step": 1427}
{"time": 1767085037.3210938, "phase": "train", "update": 1428, "total_env_steps": 4569600, "episode_reward": 0.1642865389585495, "value_loss": 0.018414466455578805, "policy_loss": -0.0011416786243188426, "dist_entropy": 0.498228931427002, "actor_grad_norm": 0.1530582755804062, "critic_grad_norm": 0.03928211331367493, "ratio": 1.0001429319381714, "entropy": 0.498228931427002, "incre_win_rate": 0.24242424242424243, "step": 1428}
{"time": 1767085042.1167154, "phase": "train", "update": 1429, "total_env_steps": 4572800, "episode_reward": 0.1631813794374466, "value_loss": 0.014591596461832524, "policy_loss": -0.0016213044415749778, "dist_entropy": 0.5190213918685913, "actor_grad_norm": 0.1413394808769226, "critic_grad_norm": 0.030177325010299683, "ratio": 1.0001665353775024, "entropy": 0.5190213918685913, "incre_win_rate": 0.2727272727272727, "step": 1429}
{"time": 1767085046.746008, "phase": "train", "update": 1430, "total_env_steps": 4576000, "episode_reward": 0.16679273545742035, "value_loss": 0.01927056573331356, "policy_loss": -0.0016493660922520803, "dist_entropy": 0.5211647748947144, "actor_grad_norm": 0.1600799560546875, "critic_grad_norm": 0.03103632666170597, "ratio": 0.9997021555900574, "entropy": 0.5211647748947144, "incre_win_rate": 0.42424242424242425, "step": 1430}
{"time": 1767085051.3950167, "phase": "train", "update": 1431, "total_env_steps": 4579200, "episode_reward": 0.16671046614646912, "value_loss": 0.0166277714073658, "policy_loss": -0.00126671208293061, "dist_entropy": 0.497765052318573, "actor_grad_norm": 0.15354274213314056, "critic_grad_norm": 0.03547582030296326, "ratio": 1.0003684759140015, "entropy": 0.497765052318573, "incre_win_rate": 0.23076923076923078, "step": 1431}
{"time": 1767085055.9991632, "phase": "train", "update": 1432, "total_env_steps": 4582400, "episode_reward": 0.17073364555835724, "value_loss": 0.016080686077475547, "policy_loss": -0.0014708778377837462, "dist_entropy": 0.5012417316436768, "actor_grad_norm": 0.14425000548362732, "critic_grad_norm": 0.09615305811166763, "ratio": 0.9998652338981628, "entropy": 0.5012417316436768, "incre_win_rate": 0.3235294117647059, "step": 1432}
{"time": 1767085060.6484334, "phase": "train", "update": 1433, "total_env_steps": 4585600, "episode_reward": 0.1836511790752411, "value_loss": 0.016188471019268035, "policy_loss": -0.0015536941346923072, "dist_entropy": 0.4890228509902954, "actor_grad_norm": 0.13445641100406647, "critic_grad_norm": 0.05333492159843445, "ratio": 0.9999648928642273, "entropy": 0.4890228509902954, "incre_win_rate": 0.3783783783783784, "step": 1433}
{"time": 1767085065.290537, "phase": "train", "update": 1434, "total_env_steps": 4588800, "episode_reward": 0.1672883778810501, "value_loss": 0.016271358355879784, "policy_loss": -0.0012446623947662161, "dist_entropy": 0.5122101664543152, "actor_grad_norm": 0.1676768958568573, "critic_grad_norm": 0.05746287852525711, "ratio": 0.9999556541442871, "entropy": 0.5122101664543152, "incre_win_rate": 0.35135135135135137, "step": 1434}
{"time": 1767085069.919386, "phase": "train", "update": 1435, "total_env_steps": 4592000, "episode_reward": 0.17698416113853455, "value_loss": 0.012272472120821476, "policy_loss": -0.0012715791205764049, "dist_entropy": 0.5111119151115417, "actor_grad_norm": 0.10087162256240845, "critic_grad_norm": 0.08963245153427124, "ratio": 0.9999818205833435, "entropy": 0.5111119151115417, "incre_win_rate": 0.375, "step": 1435}
{"time": 1767085074.5494833, "phase": "train", "update": 1436, "total_env_steps": 4595200, "episode_reward": 0.17055825889110565, "value_loss": 0.01441560871899128, "policy_loss": -0.0016646564851058089, "dist_entropy": 0.5054070830345154, "actor_grad_norm": 0.130621537566185, "critic_grad_norm": 0.07149890810251236, "ratio": 0.9998952746391296, "entropy": 0.5054070830345154, "incre_win_rate": 0.35294117647058826, "step": 1436}
{"time": 1767085079.125085, "phase": "train", "update": 1437, "total_env_steps": 4598400, "episode_reward": 0.17232617735862732, "value_loss": 0.014265377819538117, "policy_loss": -0.0020119207351079636, "dist_entropy": 0.5168428421020508, "actor_grad_norm": 0.15198229253292084, "critic_grad_norm": 0.04956620931625366, "ratio": 0.999707818031311, "entropy": 0.5168428421020508, "incre_win_rate": 0.45454545454545453, "step": 1437}
{"time": 1767085083.6257572, "phase": "train", "update": 1438, "total_env_steps": 4601600, "episode_reward": 0.146742045879364, "value_loss": 0.015977410972118376, "policy_loss": -0.0019032159978298324, "dist_entropy": 0.5211778879165649, "actor_grad_norm": 0.13999174535274506, "critic_grad_norm": 0.1290193647146225, "ratio": 1.0000066757202148, "entropy": 0.5211778879165649, "incre_win_rate": 0.26666666666666666, "step": 1438}
{"time": 1767085088.2214613, "phase": "train", "update": 1439, "total_env_steps": 4604800, "episode_reward": 0.16497258841991425, "value_loss": 0.01490609310567379, "policy_loss": -0.001404265898660384, "dist_entropy": 0.5009864807128906, "actor_grad_norm": 0.12489016354084015, "critic_grad_norm": 0.13189002871513367, "ratio": 0.9997525215148926, "entropy": 0.5009864807128906, "incre_win_rate": 0.22857142857142856, "step": 1439}
{"time": 1767085092.8893898, "phase": "train", "update": 1440, "total_env_steps": 4608000, "episode_reward": 0.18447022140026093, "value_loss": 0.015067271888256073, "policy_loss": -0.001574121867210465, "dist_entropy": 0.4878182351589203, "actor_grad_norm": 0.11711501330137253, "critic_grad_norm": 0.08850223571062088, "ratio": 0.9999099969863892, "entropy": 0.4878182351589203, "incre_win_rate": 0.3684210526315789, "step": 1440}
{"time": 1767085097.519055, "phase": "train", "update": 1441, "total_env_steps": 4611200, "episode_reward": 0.15065863728523254, "value_loss": 0.017569034546613693, "policy_loss": -0.001648053074902478, "dist_entropy": 0.5144289612770081, "actor_grad_norm": 0.1707964986562729, "critic_grad_norm": 0.09823650121688843, "ratio": 0.9997598528862, "entropy": 0.5144289612770081, "incre_win_rate": 0.15151515151515152, "step": 1441}
{"time": 1767085109.9735754, "phase": "eval", "update": 1441, "total_env_steps": 4611200, "eval_win_rate": 0.71875, "eval_episode_reward": 18.409147350993372, "step": 1441}
{"time": 1767085114.6512938, "phase": "train", "update": 1442, "total_env_steps": 4614400, "episode_reward": 0.1759023219347, "value_loss": 0.014574187807738781, "policy_loss": -0.001424961905341604, "dist_entropy": 0.49403071999549864, "actor_grad_norm": 0.17237989604473114, "critic_grad_norm": 0.07049589604139328, "ratio": 1.000253677368164, "entropy": 0.49403071999549864, "incre_win_rate": 0.35294117647058826, "step": 1442}
{"time": 1767085119.240804, "phase": "train", "update": 1443, "total_env_steps": 4617600, "episode_reward": 0.15084488689899445, "value_loss": 0.01691020391881466, "policy_loss": -0.0018574206342931276, "dist_entropy": 0.5292889475822449, "actor_grad_norm": 0.19985294342041016, "critic_grad_norm": 0.07853768765926361, "ratio": 1.0000970363616943, "entropy": 0.5292889475822449, "incre_win_rate": 0.14705882352941177, "step": 1443}
{"time": 1767085123.847868, "phase": "train", "update": 1444, "total_env_steps": 4620800, "episode_reward": 0.17600683867931366, "value_loss": 0.011889938823878765, "policy_loss": -0.0016827313316611025, "dist_entropy": 0.5138755798339844, "actor_grad_norm": 0.14392495155334473, "critic_grad_norm": 0.1231161579489708, "ratio": 0.9998963475227356, "entropy": 0.5138755798339844, "incre_win_rate": 0.42857142857142855, "step": 1444}
{"time": 1767085128.431919, "phase": "train", "update": 1445, "total_env_steps": 4624000, "episode_reward": 0.18080297112464905, "value_loss": 0.014752619341015816, "policy_loss": -0.0014587506585538534, "dist_entropy": 0.5067934155464172, "actor_grad_norm": 0.1625482141971588, "critic_grad_norm": 0.11873846501111984, "ratio": 1.0001810789108276, "entropy": 0.5067934155464172, "incre_win_rate": 0.4117647058823529, "step": 1445}
{"time": 1767085133.0094454, "phase": "train", "update": 1446, "total_env_steps": 4627200, "episode_reward": 0.17945364117622375, "value_loss": 0.011836761049926281, "policy_loss": -0.0013905092436306888, "dist_entropy": 0.5036653637886047, "actor_grad_norm": 0.1324184387922287, "critic_grad_norm": 0.09252091497182846, "ratio": 1.000038981437683, "entropy": 0.5036653637886047, "incre_win_rate": 0.5454545454545454, "step": 1446}
{"time": 1767085137.6031294, "phase": "train", "update": 1447, "total_env_steps": 4630400, "episode_reward": 0.18395748734474182, "value_loss": 0.01469731479883194, "policy_loss": -0.0012117466312885571, "dist_entropy": 0.4905254602432251, "actor_grad_norm": 0.10546963661909103, "critic_grad_norm": 0.043566007167100906, "ratio": 0.9997313618659973, "entropy": 0.4905254602432251, "incre_win_rate": 0.4473684210526316, "step": 1447}
{"time": 1767085142.260381, "phase": "train", "update": 1448, "total_env_steps": 4633600, "episode_reward": 0.1890464574098587, "value_loss": 0.01410223450511694, "policy_loss": -0.0013430442954231125, "dist_entropy": 0.49515915513038633, "actor_grad_norm": 0.11612206697463989, "critic_grad_norm": 0.036543626338243484, "ratio": 0.9995524287223816, "entropy": 0.49515915513038633, "incre_win_rate": 0.48484848484848486, "step": 1448}
{"time": 1767085146.8996701, "phase": "train", "update": 1449, "total_env_steps": 4636800, "episode_reward": 0.18554843962192535, "value_loss": 0.014922845922410489, "policy_loss": -0.0015645055195307122, "dist_entropy": 0.5021528482437134, "actor_grad_norm": 0.13541702926158905, "critic_grad_norm": 0.04036184027791023, "ratio": 1.0002349615097046, "entropy": 0.5021528482437134, "incre_win_rate": 0.4722222222222222, "step": 1449}
{"time": 1767085151.5261514, "phase": "train", "update": 1450, "total_env_steps": 4640000, "episode_reward": 0.22016918659210205, "value_loss": 0.012705933675169945, "policy_loss": -0.0013854979275954803, "dist_entropy": 0.4773410618305206, "actor_grad_norm": 0.1024697944521904, "critic_grad_norm": 0.06175560504198074, "ratio": 1.0001405477523804, "entropy": 0.4773410618305206, "incre_win_rate": 0.7435897435897436, "step": 1450}
{"time": 1767085156.1572945, "phase": "train", "update": 1451, "total_env_steps": 4643200, "episode_reward": 0.19277162849903107, "value_loss": 0.016623380407691003, "policy_loss": -0.001488360678808931, "dist_entropy": 0.4909877240657806, "actor_grad_norm": 0.12803421914577484, "critic_grad_norm": 0.12528623640537262, "ratio": 1.0000611543655396, "entropy": 0.4909877240657806, "incre_win_rate": 0.3611111111111111, "step": 1451}
{"time": 1767085160.666265, "phase": "train", "update": 1452, "total_env_steps": 4646400, "episode_reward": 0.15828901529312134, "value_loss": 0.018016862124204634, "policy_loss": -0.0018031953142191525, "dist_entropy": 0.5168692946434021, "actor_grad_norm": 0.16121873259544373, "critic_grad_norm": 0.09043275564908981, "ratio": 0.9997259974479675, "entropy": 0.5168692946434021, "incre_win_rate": 0.29411764705882354, "step": 1452}
{"time": 1767085165.2717402, "phase": "train", "update": 1453, "total_env_steps": 4649600, "episode_reward": 0.19135244190692902, "value_loss": 0.014062425307929515, "policy_loss": -0.0011586265337143685, "dist_entropy": 0.4933249533176422, "actor_grad_norm": 0.12411476671695709, "critic_grad_norm": 0.09399883449077606, "ratio": 0.9997891783714294, "entropy": 0.4933249533176422, "incre_win_rate": 0.5588235294117647, "step": 1453}
{"time": 1767085169.8385804, "phase": "train", "update": 1454, "total_env_steps": 4652800, "episode_reward": 0.18628570437431335, "value_loss": 0.014291771315038204, "policy_loss": -0.0013490280132572251, "dist_entropy": 0.4900529146194458, "actor_grad_norm": 0.14123371243476868, "critic_grad_norm": 0.04832126572728157, "ratio": 1.0003905296325684, "entropy": 0.4900529146194458, "incre_win_rate": 0.4, "step": 1454}
{"time": 1767085174.5193787, "phase": "train", "update": 1455, "total_env_steps": 4656000, "episode_reward": 0.18262676894664764, "value_loss": 0.013019138015806675, "policy_loss": -0.0011613653796018752, "dist_entropy": 0.5054129242897034, "actor_grad_norm": 0.13046802580356598, "critic_grad_norm": 0.0592711865901947, "ratio": 1.0000799894332886, "entropy": 0.5054129242897034, "incre_win_rate": 0.5, "step": 1455}
{"time": 1767085179.1888547, "phase": "train", "update": 1456, "total_env_steps": 4659200, "episode_reward": 0.1856462061405182, "value_loss": 0.014746524207293988, "policy_loss": -0.0013074640391607772, "dist_entropy": 0.4824489772319794, "actor_grad_norm": 0.14294502139091492, "critic_grad_norm": 0.10892852395772934, "ratio": 0.9999672770500183, "entropy": 0.4824489772319794, "incre_win_rate": 0.40540540540540543, "step": 1456}
{"time": 1767085183.805592, "phase": "train", "update": 1457, "total_env_steps": 4662400, "episode_reward": 0.18281559646129608, "value_loss": 0.014573320373892784, "policy_loss": -0.0013628678290253048, "dist_entropy": 0.5136982440948487, "actor_grad_norm": 0.15264742076396942, "critic_grad_norm": 0.07326322793960571, "ratio": 1.0000351667404175, "entropy": 0.5136982440948487, "incre_win_rate": 0.3888888888888889, "step": 1457}
{"time": 1767085188.4134734, "phase": "train", "update": 1458, "total_env_steps": 4665600, "episode_reward": 0.18837903439998627, "value_loss": 0.016289471462368966, "policy_loss": -0.0008445315299816514, "dist_entropy": 0.48900646567344663, "actor_grad_norm": 0.12418514490127563, "critic_grad_norm": 0.03733040392398834, "ratio": 0.9999099969863892, "entropy": 0.48900646567344663, "incre_win_rate": 0.47058823529411764, "step": 1458}
{"time": 1767085193.0517673, "phase": "train", "update": 1459, "total_env_steps": 4668800, "episode_reward": 0.1795809119939804, "value_loss": 0.014166773110628129, "policy_loss": -0.001396478298224224, "dist_entropy": 0.5063853859901428, "actor_grad_norm": 0.1495058536529541, "critic_grad_norm": 0.03790704905986786, "ratio": 1.000100016593933, "entropy": 0.5063853859901428, "incre_win_rate": 0.38235294117647056, "step": 1459}
{"time": 1767085197.6994467, "phase": "train", "update": 1460, "total_env_steps": 4672000, "episode_reward": 0.2025812268257141, "value_loss": 0.0132687633857131, "policy_loss": -0.0015001145492988144, "dist_entropy": 0.48408723473548887, "actor_grad_norm": 0.13452063500881195, "critic_grad_norm": 0.07199450582265854, "ratio": 0.9998825192451477, "entropy": 0.48408723473548887, "incre_win_rate": 0.5897435897435898, "step": 1460}
{"time": 1767085202.2407491, "phase": "train", "update": 1461, "total_env_steps": 4675200, "episode_reward": 0.17001138627529144, "value_loss": 0.014984134957194329, "policy_loss": -0.0017827534305503434, "dist_entropy": 0.49752833843231203, "actor_grad_norm": 0.12302066385746002, "critic_grad_norm": 0.08921487629413605, "ratio": 0.9997984766960144, "entropy": 0.49752833843231203, "incre_win_rate": 0.40625, "step": 1461}
{"time": 1767085215.15278, "phase": "eval", "update": 1461, "total_env_steps": 4675200, "eval_win_rate": 0.71875, "eval_episode_reward": 18.21683567880794, "step": 1461}
{"time": 1767085219.8738232, "phase": "train", "update": 1462, "total_env_steps": 4678400, "episode_reward": 0.19158992171287537, "value_loss": 0.014896743558347225, "policy_loss": -0.00135766090243834, "dist_entropy": 0.4664836525917053, "actor_grad_norm": 0.10130863636732101, "critic_grad_norm": 0.08511821925640106, "ratio": 1.0001734495162964, "entropy": 0.4664836525917053, "incre_win_rate": 0.375, "step": 1462}
{"time": 1767085224.4952366, "phase": "train", "update": 1463, "total_env_steps": 4681600, "episode_reward": 0.18519558012485504, "value_loss": 0.015348368510603904, "policy_loss": -0.0012937047504610888, "dist_entropy": 0.4887834429740906, "actor_grad_norm": 0.15645509958267212, "critic_grad_norm": 0.05777962878346443, "ratio": 0.9998523592948914, "entropy": 0.4887834429740906, "incre_win_rate": 0.4444444444444444, "step": 1463}
{"time": 1767085229.1403558, "phase": "train", "update": 1464, "total_env_steps": 4684800, "episode_reward": 0.2083609402179718, "value_loss": 0.015029585734009743, "policy_loss": -0.001400098421939333, "dist_entropy": 0.4801188111305237, "actor_grad_norm": 0.16125378012657166, "critic_grad_norm": 0.07163244485855103, "ratio": 1.0004023313522339, "entropy": 0.4801188111305237, "incre_win_rate": 0.475, "step": 1464}
{"time": 1767085233.814986, "phase": "train", "update": 1465, "total_env_steps": 4688000, "episode_reward": 0.19541391730308533, "value_loss": 0.014686890318989754, "policy_loss": -0.0014528996000962024, "dist_entropy": 0.47462456226348876, "actor_grad_norm": 0.11015374958515167, "critic_grad_norm": 0.05143557861447334, "ratio": 0.9999300837516785, "entropy": 0.47462456226348876, "incre_win_rate": 0.6666666666666666, "step": 1465}
{"time": 1767085238.4779358, "phase": "train", "update": 1466, "total_env_steps": 4691200, "episode_reward": 0.1844107061624527, "value_loss": 0.013940126076340676, "policy_loss": -0.0011983783555393757, "dist_entropy": 0.48366090655326843, "actor_grad_norm": 0.11180994659662247, "critic_grad_norm": 0.06705593317747116, "ratio": 0.9999481439590454, "entropy": 0.48366090655326843, "incre_win_rate": 0.42105263157894735, "step": 1466}
{"time": 1767085243.1286356, "phase": "train", "update": 1467, "total_env_steps": 4694400, "episode_reward": 0.19399473071098328, "value_loss": 0.014485674723982812, "policy_loss": -0.0012416499991360296, "dist_entropy": 0.4836176037788391, "actor_grad_norm": 0.10453756898641586, "critic_grad_norm": 0.02542812190949917, "ratio": 0.9996646046638489, "entropy": 0.4836176037788391, "incre_win_rate": 0.5526315789473685, "step": 1467}
{"time": 1767085247.7954412, "phase": "train", "update": 1468, "total_env_steps": 4697600, "episode_reward": 0.1854139119386673, "value_loss": 0.012387349270284176, "policy_loss": -0.0018077149284557946, "dist_entropy": 0.4848890483379364, "actor_grad_norm": 0.12799125909805298, "critic_grad_norm": 0.040741246193647385, "ratio": 0.9998785257339478, "entropy": 0.4848890483379364, "incre_win_rate": 0.45454545454545453, "step": 1468}
{"time": 1767085252.354694, "phase": "train", "update": 1469, "total_env_steps": 4700800, "episode_reward": 0.15627224743366241, "value_loss": 0.014767821505665779, "policy_loss": -0.0017302146973193545, "dist_entropy": 0.5106484413146972, "actor_grad_norm": 0.1357547491788864, "critic_grad_norm": 0.03220999240875244, "ratio": 0.999973475933075, "entropy": 0.5106484413146972, "incre_win_rate": 0.25, "step": 1469}
{"time": 1767085256.9773352, "phase": "train", "update": 1470, "total_env_steps": 4704000, "episode_reward": 0.18111392855644226, "value_loss": 0.013746656477451324, "policy_loss": -0.0010240999632650017, "dist_entropy": 0.48248815536499023, "actor_grad_norm": 0.11566033214330673, "critic_grad_norm": 0.028564453125, "ratio": 0.9996623992919922, "entropy": 0.48248815536499023, "incre_win_rate": 0.42424242424242425, "step": 1470}
{"time": 1767085261.5916135, "phase": "train", "update": 1471, "total_env_steps": 4707200, "episode_reward": 0.19869722425937653, "value_loss": 0.01732349134981632, "policy_loss": -0.001359591573126906, "dist_entropy": 0.45769757628440855, "actor_grad_norm": 0.12689624726772308, "critic_grad_norm": 0.03863045573234558, "ratio": 1.0000776052474976, "entropy": 0.45769757628440855, "incre_win_rate": 0.5833333333333334, "step": 1471}
{"time": 1767085306.3151436, "phase": "train", "update": 1472, "total_env_steps": 4710400, "episode_reward": 0.16556084156036377, "value_loss": 0.05405160188674927, "policy_loss": -0.0013440248983961566, "dist_entropy": 0.48560595512390137, "actor_grad_norm": 0.11702529340982437, "critic_grad_norm": 0.23809786140918732, "ratio": 0.9999557733535767, "entropy": 0.48560595512390137, "incre_win_rate": 0.30303030303030304, "step": 1472}
{"time": 1767085310.949939, "phase": "train", "update": 1473, "total_env_steps": 4713600, "episode_reward": 0.19288286566734314, "value_loss": 0.01205364242196083, "policy_loss": -0.0012704437221870534, "dist_entropy": 0.4788885056972504, "actor_grad_norm": 0.1449456661939621, "critic_grad_norm": 0.08486665785312653, "ratio": 0.9998385310173035, "entropy": 0.4788885056972504, "incre_win_rate": 0.4444444444444444, "step": 1473}
{"time": 1767085315.6473851, "phase": "train", "update": 1474, "total_env_steps": 4716800, "episode_reward": 0.19853529334068298, "value_loss": 0.012549911811947822, "policy_loss": -0.0012352865679460478, "dist_entropy": 0.4591549515724182, "actor_grad_norm": 0.13667230308055878, "critic_grad_norm": 0.07149713486433029, "ratio": 1.0002655982971191, "entropy": 0.4591549515724182, "incre_win_rate": 0.5128205128205128, "step": 1474}
{"time": 1767085320.2900903, "phase": "train", "update": 1475, "total_env_steps": 4720000, "episode_reward": 0.2098044455051422, "value_loss": 0.01512510869652033, "policy_loss": -0.0013654793020407396, "dist_entropy": 0.4585880100727081, "actor_grad_norm": 0.19748742878437042, "critic_grad_norm": 0.03195961192250252, "ratio": 0.9998828172683716, "entropy": 0.4585880100727081, "incre_win_rate": 0.5833333333333334, "step": 1475}
{"time": 1767085324.9107647, "phase": "train", "update": 1476, "total_env_steps": 4723200, "episode_reward": 0.18368637561798096, "value_loss": 0.016192299127578736, "policy_loss": -0.0018321265417284849, "dist_entropy": 0.474200165271759, "actor_grad_norm": 0.1298522651195526, "critic_grad_norm": 0.025591736659407616, "ratio": 1.0002000331878662, "entropy": 0.474200165271759, "incre_win_rate": 0.4444444444444444, "step": 1476}
{"time": 1767085329.6012545, "phase": "train", "update": 1477, "total_env_steps": 4726400, "episode_reward": 0.17137624323368073, "value_loss": 0.01607911419123411, "policy_loss": -0.0011446351286508616, "dist_entropy": 0.4759384095668793, "actor_grad_norm": 0.14044491946697235, "critic_grad_norm": 0.04747004434466362, "ratio": 0.9999592900276184, "entropy": 0.4759384095668793, "incre_win_rate": 0.2894736842105263, "step": 1477}
{"time": 1767085334.2872484, "phase": "train", "update": 1478, "total_env_steps": 4729600, "episode_reward": 0.19111652672290802, "value_loss": 0.014822523668408394, "policy_loss": -0.0009864839028637107, "dist_entropy": 0.46865891218185424, "actor_grad_norm": 0.12994149327278137, "critic_grad_norm": 0.059593528509140015, "ratio": 0.9998542666435242, "entropy": 0.46865891218185424, "incre_win_rate": 0.42857142857142855, "step": 1478}
{"time": 1767085338.9806979, "phase": "train", "update": 1479, "total_env_steps": 4732800, "episode_reward": 0.18267591297626495, "value_loss": 0.016510317847132683, "policy_loss": -0.0010922746668185824, "dist_entropy": 0.4589862167835236, "actor_grad_norm": 0.1375468224287033, "critic_grad_norm": 0.12063466757535934, "ratio": 0.9999927878379822, "entropy": 0.4589862167835236, "incre_win_rate": 0.28205128205128205, "step": 1479}
{"time": 1767085343.6761956, "phase": "train", "update": 1480, "total_env_steps": 4736000, "episode_reward": 0.1820591688156128, "value_loss": 0.015739890560507775, "policy_loss": -0.0013665778837632203, "dist_entropy": 0.4650943040847778, "actor_grad_norm": 0.1428944319486618, "critic_grad_norm": 0.07864359766244888, "ratio": 0.9999660849571228, "entropy": 0.4650943040847778, "incre_win_rate": 0.4117647058823529, "step": 1480}
{"time": 1767085348.349006, "phase": "train", "update": 1481, "total_env_steps": 4739200, "episode_reward": 0.190403550863266, "value_loss": 0.015126243606209755, "policy_loss": -0.0010915720189984767, "dist_entropy": 0.4542464971542358, "actor_grad_norm": 0.11988582462072372, "critic_grad_norm": 0.0670739933848381, "ratio": 0.9996658563613892, "entropy": 0.4542464971542358, "incre_win_rate": 0.39473684210526316, "step": 1481}
{"time": 1767085360.200211, "phase": "eval", "update": 1481, "total_env_steps": 4739200, "eval_win_rate": 0.84375, "eval_episode_reward": 18.99772350993377, "step": 1481}
{"time": 1767085364.8848262, "phase": "train", "update": 1482, "total_env_steps": 4742400, "episode_reward": 0.19372515380382538, "value_loss": 0.015443688817322254, "policy_loss": -0.0011464541850202182, "dist_entropy": 0.47394028306007385, "actor_grad_norm": 0.152272030711174, "critic_grad_norm": 0.05370226502418518, "ratio": 1.0002243518829346, "entropy": 0.47394028306007385, "incre_win_rate": 0.4146341463414634, "step": 1482}
{"time": 1767085369.5959814, "phase": "train", "update": 1483, "total_env_steps": 4745600, "episode_reward": 0.20044703781604767, "value_loss": 0.013553709164261818, "policy_loss": -0.0013216971567430846, "dist_entropy": 0.4553070545196533, "actor_grad_norm": 0.1064864918589592, "critic_grad_norm": 0.03286172077059746, "ratio": 0.9999866485595703, "entropy": 0.4553070545196533, "incre_win_rate": 0.46153846153846156, "step": 1483}
{"time": 1767085374.3410091, "phase": "train", "update": 1484, "total_env_steps": 4748800, "episode_reward": 0.19222578406333923, "value_loss": 0.015330154635012149, "policy_loss": -0.0013003921356238735, "dist_entropy": 0.44484773874282835, "actor_grad_norm": 0.13207487761974335, "critic_grad_norm": 0.03601481765508652, "ratio": 0.9998723268508911, "entropy": 0.44484773874282835, "incre_win_rate": 0.5, "step": 1484}
{"time": 1767085379.0530028, "phase": "train", "update": 1485, "total_env_steps": 4752000, "episode_reward": 0.18204212188720703, "value_loss": 0.015635040402412415, "policy_loss": -0.0014415216025767564, "dist_entropy": 0.4550095319747925, "actor_grad_norm": 0.1347157061100006, "critic_grad_norm": 0.04958271235227585, "ratio": 1.0001190900802612, "entropy": 0.4550095319747925, "incre_win_rate": 0.3333333333333333, "step": 1485}
{"time": 1767085383.7760236, "phase": "train", "update": 1486, "total_env_steps": 4755200, "episode_reward": 0.18277578055858612, "value_loss": 0.016342731565237044, "policy_loss": -0.0013226663898656455, "dist_entropy": 0.46823506951332095, "actor_grad_norm": 0.1993279755115509, "critic_grad_norm": 0.10625552386045456, "ratio": 0.9999410510063171, "entropy": 0.46823506951332095, "incre_win_rate": 0.2682926829268293, "step": 1486}
{"time": 1767085388.6576307, "phase": "train", "update": 1487, "total_env_steps": 4758400, "episode_reward": 0.21242497861385345, "value_loss": 0.015408331342041493, "policy_loss": -0.001210625022644507, "dist_entropy": 0.42822874188423155, "actor_grad_norm": 0.13651901483535767, "critic_grad_norm": 0.1197228953242302, "ratio": 1.0003386735916138, "entropy": 0.42822874188423155, "incre_win_rate": 0.6153846153846154, "step": 1487}
{"time": 1767085393.338746, "phase": "train", "update": 1488, "total_env_steps": 4761600, "episode_reward": 0.1777229905128479, "value_loss": 0.018972698226571084, "policy_loss": -0.0011857798754419946, "dist_entropy": 0.4543137431144714, "actor_grad_norm": 0.1500166654586792, "critic_grad_norm": 0.07467462122440338, "ratio": 1.0000152587890625, "entropy": 0.4543137431144714, "incre_win_rate": 0.3783783783783784, "step": 1488}
{"time": 1767085398.0785298, "phase": "train", "update": 1489, "total_env_steps": 4764800, "episode_reward": 0.20012624561786652, "value_loss": 0.015461491234600545, "policy_loss": -0.0014957706750280408, "dist_entropy": 0.43263866305351256, "actor_grad_norm": 0.14562468230724335, "critic_grad_norm": 0.056968480348587036, "ratio": 0.9997220039367676, "entropy": 0.43263866305351256, "incre_win_rate": 0.46153846153846156, "step": 1489}
{"time": 1767085402.7411118, "phase": "train", "update": 1490, "total_env_steps": 4768000, "episode_reward": 0.18787717819213867, "value_loss": 0.01663488373160362, "policy_loss": -0.0012009689116087685, "dist_entropy": 0.4413340866565704, "actor_grad_norm": 0.14375121891498566, "critic_grad_norm": 0.06510931998491287, "ratio": 0.9998836517333984, "entropy": 0.4413340866565704, "incre_win_rate": 0.4857142857142857, "step": 1490}
{"time": 1767085407.4639707, "phase": "train", "update": 1491, "total_env_steps": 4771200, "episode_reward": 0.1898825615644455, "value_loss": 0.01505595576018095, "policy_loss": -0.001083968765552612, "dist_entropy": 0.4578752934932709, "actor_grad_norm": 0.13904373347759247, "critic_grad_norm": 0.07001964002847672, "ratio": 1.0000489950180054, "entropy": 0.4578752934932709, "incre_win_rate": 0.5277777777777778, "step": 1491}
{"time": 1767085412.1022992, "phase": "train", "update": 1492, "total_env_steps": 4774400, "episode_reward": 0.17530940473079681, "value_loss": 0.01266069319099188, "policy_loss": -0.0014978426057993487, "dist_entropy": 0.4685134172439575, "actor_grad_norm": 0.14210616052150726, "critic_grad_norm": 0.05420973524451256, "ratio": 1.0001214742660522, "entropy": 0.4685134172439575, "incre_win_rate": 0.45454545454545453, "step": 1492}
{"time": 1767085416.8326375, "phase": "train", "update": 1493, "total_env_steps": 4777600, "episode_reward": 0.1875682771205902, "value_loss": 0.020044852048158646, "policy_loss": -0.0014031391188179753, "dist_entropy": 0.42838149070739745, "actor_grad_norm": 0.17113538086414337, "critic_grad_norm": 0.03476201370358467, "ratio": 0.9998452067375183, "entropy": 0.42838149070739745, "incre_win_rate": 0.4444444444444444, "step": 1493}
{"time": 1767085421.5573692, "phase": "train", "update": 1494, "total_env_steps": 4780800, "episode_reward": 0.18754087388515472, "value_loss": 0.013708853162825108, "policy_loss": -0.0015066986805834404, "dist_entropy": 0.4461999535560608, "actor_grad_norm": 0.1642543375492096, "critic_grad_norm": 0.05878057703375816, "ratio": 1.0002187490463257, "entropy": 0.4461999535560608, "incre_win_rate": 0.4473684210526316, "step": 1494}
{"time": 1767085426.2526045, "phase": "train", "update": 1495, "total_env_steps": 4784000, "episode_reward": 0.19161784648895264, "value_loss": 0.01748693697154522, "policy_loss": -0.0011693237529009082, "dist_entropy": 0.46363064646720886, "actor_grad_norm": 0.13119368255138397, "critic_grad_norm": 0.11911338567733765, "ratio": 1.0001167058944702, "entropy": 0.46363064646720886, "incre_win_rate": 0.3783783783783784, "step": 1495}
{"time": 1767085430.9035625, "phase": "train", "update": 1496, "total_env_steps": 4787200, "episode_reward": 0.16821658611297607, "value_loss": 0.01604535412043333, "policy_loss": -0.0016591402173119717, "dist_entropy": 0.47623866200447085, "actor_grad_norm": 0.10772287845611572, "critic_grad_norm": 0.06534174084663391, "ratio": 1.000031590461731, "entropy": 0.47623866200447085, "incre_win_rate": 0.23529411764705882, "step": 1496}
{"time": 1767085435.6645312, "phase": "train", "update": 1497, "total_env_steps": 4790400, "episode_reward": 0.1825522631406784, "value_loss": 0.014494328387081623, "policy_loss": -0.0015296708370271972, "dist_entropy": 0.4700431764125824, "actor_grad_norm": 0.15635278820991516, "critic_grad_norm": 0.04262091591954231, "ratio": 1.000386118888855, "entropy": 0.4700431764125824, "incre_win_rate": 0.42105263157894735, "step": 1497}
{"time": 1767085440.463687, "phase": "train", "update": 1498, "total_env_steps": 4793600, "episode_reward": 0.2180318832397461, "value_loss": 0.01580258458852768, "policy_loss": -0.001407536894581085, "dist_entropy": 0.4398390769958496, "actor_grad_norm": 0.10175111144781113, "critic_grad_norm": 0.07826138287782669, "ratio": 1.0000207424163818, "entropy": 0.4398390769958496, "incre_win_rate": 0.625, "step": 1498}
{"time": 1767085445.171918, "phase": "train", "update": 1499, "total_env_steps": 4796800, "episode_reward": 0.2090185284614563, "value_loss": 0.011590792052447795, "policy_loss": -0.0014732276003194046, "dist_entropy": 0.42103418707847595, "actor_grad_norm": 0.12951819598674774, "critic_grad_norm": 0.07577462494373322, "ratio": 0.9998084306716919, "entropy": 0.42103418707847595, "incre_win_rate": 0.48717948717948717, "step": 1499}
{"time": 1767085449.828532, "phase": "train", "update": 1500, "total_env_steps": 4800000, "episode_reward": 0.2042766958475113, "value_loss": 0.017007554322481154, "policy_loss": -0.0016058899426056427, "dist_entropy": 0.4433240175247192, "actor_grad_norm": 0.16607606410980225, "critic_grad_norm": 0.04100124165415764, "ratio": 0.9996433258056641, "entropy": 0.4433240175247192, "incre_win_rate": 0.5789473684210527, "step": 1500}
{"time": 1767085454.5494676, "phase": "train", "update": 1501, "total_env_steps": 4803200, "episode_reward": 0.18892334401607513, "value_loss": 0.01674042083323002, "policy_loss": -0.0018674327780018984, "dist_entropy": 0.4365811705589294, "actor_grad_norm": 0.14487449824810028, "critic_grad_norm": 0.09515126049518585, "ratio": 0.9998049139976501, "entropy": 0.4365811705589294, "incre_win_rate": 0.4, "step": 1501}
{"time": 1767085467.2398193, "phase": "eval", "update": 1501, "total_env_steps": 4803200, "eval_win_rate": 0.71875, "eval_episode_reward": 18.274006622516552, "step": 1501}
{"time": 1767085471.9660165, "phase": "train", "update": 1502, "total_env_steps": 4806400, "episode_reward": 0.21855908632278442, "value_loss": 0.012335645034909248, "policy_loss": -0.0014308109126559998, "dist_entropy": 0.4045503795146942, "actor_grad_norm": 0.15985427796840668, "critic_grad_norm": 0.05442773178219795, "ratio": 0.9997893571853638, "entropy": 0.4045503795146942, "incre_win_rate": 0.6410256410256411, "step": 1502}
{"time": 1767085476.6063242, "phase": "train", "update": 1503, "total_env_steps": 4809600, "episode_reward": 0.19455194473266602, "value_loss": 0.0142320666462183, "policy_loss": -0.0015006211575709471, "dist_entropy": 0.4407315254211426, "actor_grad_norm": 0.11214902251958847, "critic_grad_norm": 0.07745691388845444, "ratio": 0.9997547268867493, "entropy": 0.4407315254211426, "incre_win_rate": 0.6470588235294118, "step": 1503}
{"time": 1767085481.328951, "phase": "train", "update": 1504, "total_env_steps": 4812800, "episode_reward": 0.19557791948318481, "value_loss": 0.014213289692997932, "policy_loss": -0.0012345686541365807, "dist_entropy": 0.43497071862220765, "actor_grad_norm": 0.16136768460273743, "critic_grad_norm": 0.0496370866894722, "ratio": 0.9997488856315613, "entropy": 0.43497071862220765, "incre_win_rate": 0.4358974358974359, "step": 1504}
{"time": 1767085486.2650275, "phase": "train", "update": 1505, "total_env_steps": 4816000, "episode_reward": 0.1971631944179535, "value_loss": 0.015667425841093062, "policy_loss": -0.0016447946080006659, "dist_entropy": 0.4180547297000885, "actor_grad_norm": 0.1737835854291916, "critic_grad_norm": 0.0870659276843071, "ratio": 0.9999645352363586, "entropy": 0.4180547297000885, "incre_win_rate": 0.425, "step": 1505}
{"time": 1767085491.0285356, "phase": "train", "update": 1506, "total_env_steps": 4819200, "episode_reward": 0.18625053763389587, "value_loss": 0.014750699512660503, "policy_loss": -0.0012092728633405158, "dist_entropy": 0.4383176863193512, "actor_grad_norm": 0.1451052874326706, "critic_grad_norm": 0.08371201157569885, "ratio": 0.9996350407600403, "entropy": 0.4383176863193512, "incre_win_rate": 0.38461538461538464, "step": 1506}
{"time": 1767085496.686763, "phase": "train", "update": 1507, "total_env_steps": 4822400, "episode_reward": 0.17105701565742493, "value_loss": 0.014760821126401424, "policy_loss": -0.0015178270571553298, "dist_entropy": 0.4606034219264984, "actor_grad_norm": 0.1603379100561142, "critic_grad_norm": 0.09352704137563705, "ratio": 1.0002177953720093, "entropy": 0.4606034219264984, "incre_win_rate": 0.34285714285714286, "step": 1507}
{"time": 1767085501.4337282, "phase": "train", "update": 1508, "total_env_steps": 4825600, "episode_reward": 0.19004036486148834, "value_loss": 0.017137325555086135, "policy_loss": -0.0012483346732743428, "dist_entropy": 0.4399256408214569, "actor_grad_norm": 0.14910732209682465, "critic_grad_norm": 0.16874022781848907, "ratio": 0.999925434589386, "entropy": 0.4399256408214569, "incre_win_rate": 0.3783783783783784, "step": 1508}
{"time": 1767085506.0130153, "phase": "train", "update": 1509, "total_env_steps": 4828800, "episode_reward": 0.1958061009645462, "value_loss": 0.012417754530906678, "policy_loss": -0.0017552130724773462, "dist_entropy": 0.4252408742904663, "actor_grad_norm": 0.14010757207870483, "critic_grad_norm": 0.09886063635349274, "ratio": 0.9999870657920837, "entropy": 0.4252408742904663, "incre_win_rate": 0.5, "step": 1509}
{"time": 1767085510.5302718, "phase": "train", "update": 1510, "total_env_steps": 4832000, "episode_reward": 0.1995488405227661, "value_loss": 0.015688964538276194, "policy_loss": -0.0015717848136191036, "dist_entropy": 0.42713364362716677, "actor_grad_norm": 0.10699742287397385, "critic_grad_norm": 0.05333877354860306, "ratio": 1.0000433921813965, "entropy": 0.42713364362716677, "incre_win_rate": 0.5263157894736842, "step": 1510}
{"time": 1767085515.2092972, "phase": "train", "update": 1511, "total_env_steps": 4835200, "episode_reward": 0.19237375259399414, "value_loss": 0.01203991286456585, "policy_loss": -0.001223236731579691, "dist_entropy": 0.4313516736030579, "actor_grad_norm": 0.13545936346054077, "critic_grad_norm": 0.042216021567583084, "ratio": 1.0001667737960815, "entropy": 0.4313516736030579, "incre_win_rate": 0.47368421052631576, "step": 1511}
{"time": 1767085519.8560112, "phase": "train", "update": 1512, "total_env_steps": 4838400, "episode_reward": 0.19844265282154083, "value_loss": 0.012033035233616828, "policy_loss": -0.0015750568046541957, "dist_entropy": 0.4300960421562195, "actor_grad_norm": 0.11900386959314346, "critic_grad_norm": 0.028823239728808403, "ratio": 0.9998642802238464, "entropy": 0.4300960421562195, "incre_win_rate": 0.5882352941176471, "step": 1512}
{"time": 1767085524.7383046, "phase": "train", "update": 1513, "total_env_steps": 4841600, "episode_reward": 0.20756106078624725, "value_loss": 0.012995000183582305, "policy_loss": -0.0014908221225439888, "dist_entropy": 0.38889787197113035, "actor_grad_norm": 0.13752177357673645, "critic_grad_norm": 0.02932886779308319, "ratio": 1.0003631114959717, "entropy": 0.38889787197113035, "incre_win_rate": 0.575, "step": 1513}
{"time": 1767085529.4726918, "phase": "train", "update": 1514, "total_env_steps": 4844800, "episode_reward": 0.20480702817440033, "value_loss": 0.012105992995202541, "policy_loss": -0.0011786191193777994, "dist_entropy": 0.4080026030540466, "actor_grad_norm": 0.13589416444301605, "critic_grad_norm": 0.03954935073852539, "ratio": 1.000083565711975, "entropy": 0.4080026030540466, "incre_win_rate": 0.6052631578947368, "step": 1514}
{"time": 1767085534.2913084, "phase": "train", "update": 1515, "total_env_steps": 4848000, "episode_reward": 0.1945333331823349, "value_loss": 0.012900283932685852, "policy_loss": -0.0016895662869423234, "dist_entropy": 0.42110812067985537, "actor_grad_norm": 0.13669940829277039, "critic_grad_norm": 0.03656459599733353, "ratio": 0.9999127388000488, "entropy": 0.42110812067985537, "incre_win_rate": 0.5714285714285714, "step": 1515}
{"time": 1767085539.205155, "phase": "train", "update": 1516, "total_env_steps": 4851200, "episode_reward": 0.19709333777427673, "value_loss": 0.01836077682673931, "policy_loss": -0.0015254739597608592, "dist_entropy": 0.42183573842048644, "actor_grad_norm": 0.1871764063835144, "critic_grad_norm": 0.06743388622999191, "ratio": 0.9999127388000488, "entropy": 0.42183573842048644, "incre_win_rate": 0.5, "step": 1516}
{"time": 1767085543.98986, "phase": "train", "update": 1517, "total_env_steps": 4854400, "episode_reward": 0.2095731496810913, "value_loss": 0.02147340402007103, "policy_loss": -0.0014069800810780464, "dist_entropy": 0.41430285573005676, "actor_grad_norm": 0.10401227325201035, "critic_grad_norm": 0.06662434339523315, "ratio": 1.0000872611999512, "entropy": 0.41430285573005676, "incre_win_rate": 0.5384615384615384, "step": 1517}
{"time": 1767085548.65074, "phase": "train", "update": 1518, "total_env_steps": 4857600, "episode_reward": 0.1881498396396637, "value_loss": 0.015686779655516146, "policy_loss": -0.0017505416873973445, "dist_entropy": 0.4240876197814941, "actor_grad_norm": 0.17032544314861298, "critic_grad_norm": 0.05473737791180611, "ratio": 1.0000395774841309, "entropy": 0.4240876197814941, "incre_win_rate": 0.5555555555555556, "step": 1518}
{"time": 1767085553.4160292, "phase": "train", "update": 1519, "total_env_steps": 4860800, "episode_reward": 0.1991991102695465, "value_loss": 0.01666538380086422, "policy_loss": -0.0013418767551698352, "dist_entropy": 0.4105448365211487, "actor_grad_norm": 0.16053889691829681, "critic_grad_norm": 0.047843899577856064, "ratio": 1.0000498294830322, "entropy": 0.4105448365211487, "incre_win_rate": 0.46153846153846156, "step": 1519}
{"time": 1767085558.0964448, "phase": "train", "update": 1520, "total_env_steps": 4864000, "episode_reward": 0.2145431488752365, "value_loss": 0.012330549582839013, "policy_loss": -0.0009105688120584432, "dist_entropy": 0.41372241973876955, "actor_grad_norm": 0.13159461319446564, "critic_grad_norm": 0.08218511939048767, "ratio": 0.9999918937683105, "entropy": 0.41372241973876955, "incre_win_rate": 0.6756756756756757, "step": 1520}
{"time": 1767085562.7631752, "phase": "train", "update": 1521, "total_env_steps": 4867200, "episode_reward": 0.192347913980484, "value_loss": 0.01478544045239687, "policy_loss": -0.0018035012130408034, "dist_entropy": 0.4257871210575104, "actor_grad_norm": 0.16680751740932465, "critic_grad_norm": 0.12673361599445343, "ratio": 0.9997598528862, "entropy": 0.4257871210575104, "incre_win_rate": 0.425, "step": 1521}
{"time": 1767085575.6760156, "phase": "eval", "update": 1521, "total_env_steps": 4867200, "eval_win_rate": 0.6875, "eval_episode_reward": 18.092094370860924, "step": 1521}
{"time": 1767085580.395869, "phase": "train", "update": 1522, "total_env_steps": 4870400, "episode_reward": 0.19933930039405823, "value_loss": 0.015794888697564603, "policy_loss": -0.0012397380639782795, "dist_entropy": 0.41793426871299744, "actor_grad_norm": 0.20178751647472382, "critic_grad_norm": 0.08171427249908447, "ratio": 0.9999673962593079, "entropy": 0.41793426871299744, "incre_win_rate": 0.5, "step": 1522}
{"time": 1767085585.095408, "phase": "train", "update": 1523, "total_env_steps": 4873600, "episode_reward": 0.18625053763389587, "value_loss": 0.015357097424566746, "policy_loss": -0.001702372891850956, "dist_entropy": 0.43812116980552673, "actor_grad_norm": 0.17626002430915833, "critic_grad_norm": 0.053944945335388184, "ratio": 0.999718964099884, "entropy": 0.43812116980552673, "incre_win_rate": 0.5405405405405406, "step": 1523}
{"time": 1767085589.7899294, "phase": "train", "update": 1524, "total_env_steps": 4876800, "episode_reward": 0.1800708770751953, "value_loss": 0.02094353586435318, "policy_loss": -0.0014331995253769492, "dist_entropy": 0.42528281211853025, "actor_grad_norm": 0.19122245907783508, "critic_grad_norm": 0.09532520920038223, "ratio": 0.9995684027671814, "entropy": 0.42528281211853025, "incre_win_rate": 0.358974358974359, "step": 1524}
{"time": 1767085594.4575946, "phase": "train", "update": 1525, "total_env_steps": 4880000, "episode_reward": 0.1907983273267746, "value_loss": 0.01776587441563606, "policy_loss": -0.0013278790445298227, "dist_entropy": 0.4308660626411438, "actor_grad_norm": 0.23075203597545624, "critic_grad_norm": 0.05839164927601814, "ratio": 0.9998640418052673, "entropy": 0.4308660626411438, "incre_win_rate": 0.5135135135135135, "step": 1525}
{"time": 1767085599.175452, "phase": "train", "update": 1526, "total_env_steps": 4883200, "episode_reward": 0.2073044329881668, "value_loss": 0.014819772355258465, "policy_loss": -0.0016409858395562082, "dist_entropy": 0.41193667650222776, "actor_grad_norm": 0.17632275819778442, "critic_grad_norm": 0.038941409438848495, "ratio": 1.000090479850769, "entropy": 0.41193667650222776, "incre_win_rate": 0.525, "step": 1526}
{"time": 1767085603.8434875, "phase": "train", "update": 1527, "total_env_steps": 4886400, "episode_reward": 0.2013203650712967, "value_loss": 0.01598939374089241, "policy_loss": -0.0015062159403278486, "dist_entropy": 0.40974011421203616, "actor_grad_norm": 0.12395062297582626, "critic_grad_norm": 0.0572328083217144, "ratio": 0.9998670816421509, "entropy": 0.40974011421203616, "incre_win_rate": 0.5405405405405406, "step": 1527}
{"time": 1767085608.4407055, "phase": "train", "update": 1528, "total_env_steps": 4889600, "episode_reward": 0.17695623636245728, "value_loss": 0.015384345129132272, "policy_loss": -0.001813749437563672, "dist_entropy": 0.4415667712688446, "actor_grad_norm": 0.19789056479930878, "critic_grad_norm": 0.04875084012746811, "ratio": 1.0000991821289062, "entropy": 0.4415667712688446, "incre_win_rate": 0.45454545454545453, "step": 1528}
{"time": 1767085613.2322197, "phase": "train", "update": 1529, "total_env_steps": 4892800, "episode_reward": 0.19179634749889374, "value_loss": 0.01624850369989872, "policy_loss": -0.001317044807637302, "dist_entropy": 0.4098861336708069, "actor_grad_norm": 0.16231654584407806, "critic_grad_norm": 0.07283571362495422, "ratio": 1.0000345706939697, "entropy": 0.4098861336708069, "incre_win_rate": 0.5, "step": 1529}
{"time": 1767085617.9403915, "phase": "train", "update": 1530, "total_env_steps": 4896000, "episode_reward": 0.2071223109960556, "value_loss": 0.015364158526062965, "policy_loss": -0.0015515496147656903, "dist_entropy": 0.4238122642040253, "actor_grad_norm": 0.13874712586402893, "critic_grad_norm": 0.07170391827821732, "ratio": 0.9998782277107239, "entropy": 0.4238122642040253, "incre_win_rate": 0.631578947368421, "step": 1530}
{"time": 1767085622.5603707, "phase": "train", "update": 1531, "total_env_steps": 4899200, "episode_reward": 0.18728993833065033, "value_loss": 0.01603351403027773, "policy_loss": -0.001404059285448156, "dist_entropy": 0.43677266836166384, "actor_grad_norm": 0.17375515401363373, "critic_grad_norm": 0.05898557975888252, "ratio": 1.0002094507217407, "entropy": 0.43677266836166384, "incre_win_rate": 0.5428571428571428, "step": 1531}
{"time": 1767085627.1658914, "phase": "train", "update": 1532, "total_env_steps": 4902400, "episode_reward": 0.1878761500120163, "value_loss": 0.013661777228116989, "policy_loss": -0.0013277358552386432, "dist_entropy": 0.3989991247653961, "actor_grad_norm": 0.1613791584968567, "critic_grad_norm": 0.055746108293533325, "ratio": 0.9999849200248718, "entropy": 0.3989991247653961, "incre_win_rate": 0.45, "step": 1532}
{"time": 1767085631.8569736, "phase": "train", "update": 1533, "total_env_steps": 4905600, "episode_reward": 0.21856634318828583, "value_loss": 0.013091463223099708, "policy_loss": -0.001511013219426971, "dist_entropy": 0.40245280861854554, "actor_grad_norm": 0.2082434743642807, "critic_grad_norm": 0.042934998869895935, "ratio": 1.0000799894332886, "entropy": 0.40245280861854554, "incre_win_rate": 0.625, "step": 1533}
{"time": 1767085636.48061, "phase": "train", "update": 1534, "total_env_steps": 4908800, "episode_reward": 0.2122449427843094, "value_loss": 0.01303771249949932, "policy_loss": -0.0012067579576850562, "dist_entropy": 0.42959484457969666, "actor_grad_norm": 0.17965762317180634, "critic_grad_norm": 0.03874039277434349, "ratio": 1.0001113414764404, "entropy": 0.42959484457969666, "incre_win_rate": 0.6052631578947368, "step": 1534}
{"time": 1767085641.1612043, "phase": "train", "update": 1535, "total_env_steps": 4912000, "episode_reward": 0.2224932610988617, "value_loss": 0.012710070051252843, "policy_loss": -0.0012365363278624031, "dist_entropy": 0.4141652822494507, "actor_grad_norm": 0.20731937885284424, "critic_grad_norm": 0.11062132567167282, "ratio": 0.9998499751091003, "entropy": 0.4141652822494507, "incre_win_rate": 0.7435897435897436, "step": 1535}
{"time": 1767085645.7720683, "phase": "train", "update": 1536, "total_env_steps": 4915200, "episode_reward": 0.1857367753982544, "value_loss": 0.010624215379357338, "policy_loss": -0.0014325005448025507, "dist_entropy": 0.4147546231746674, "actor_grad_norm": 0.1931220293045044, "critic_grad_norm": 0.08788728713989258, "ratio": 0.9998100399971008, "entropy": 0.4147546231746674, "incre_win_rate": 0.5, "step": 1536}
{"time": 1767085650.4345639, "phase": "train", "update": 1537, "total_env_steps": 4918400, "episode_reward": 0.18795427680015564, "value_loss": 0.014921680092811584, "policy_loss": -0.0016145124391684362, "dist_entropy": 0.4145899534225464, "actor_grad_norm": 0.16606049239635468, "critic_grad_norm": 0.09470807760953903, "ratio": 0.9998384714126587, "entropy": 0.4145899534225464, "incre_win_rate": 0.40540540540540543, "step": 1537}
{"time": 1767085655.1058385, "phase": "train", "update": 1538, "total_env_steps": 4921600, "episode_reward": 0.20489704608917236, "value_loss": 0.01696004383265972, "policy_loss": -0.001371989971900689, "dist_entropy": 0.4060929238796234, "actor_grad_norm": 0.16028666496276855, "critic_grad_norm": 0.07493451982736588, "ratio": 0.9998914003372192, "entropy": 0.4060929238796234, "incre_win_rate": 0.5641025641025641, "step": 1538}
{"time": 1767085659.793699, "phase": "train", "update": 1539, "total_env_steps": 4924800, "episode_reward": 0.22960680723190308, "value_loss": 0.012395143136382103, "policy_loss": -0.0014665711393730073, "dist_entropy": 0.39831097722053527, "actor_grad_norm": 0.18413570523262024, "critic_grad_norm": 0.056750889867544174, "ratio": 1.0000663995742798, "entropy": 0.39831097722053527, "incre_win_rate": 0.6829268292682927, "step": 1539}
{"time": 1767085664.4932835, "phase": "train", "update": 1540, "total_env_steps": 4928000, "episode_reward": 0.2032879889011383, "value_loss": 0.012879601493477822, "policy_loss": -0.001088135528253531, "dist_entropy": 0.42461301684379577, "actor_grad_norm": 0.1418626755475998, "critic_grad_norm": 0.11181463301181793, "ratio": 1.0003544092178345, "entropy": 0.42461301684379577, "incre_win_rate": 0.5, "step": 1540}
{"time": 1767085669.1551597, "phase": "train", "update": 1541, "total_env_steps": 4931200, "episode_reward": 0.2038773000240326, "value_loss": 0.015159469656646251, "policy_loss": -0.001879016128047395, "dist_entropy": 0.4322837173938751, "actor_grad_norm": 0.13185720145702362, "critic_grad_norm": 0.07558634132146835, "ratio": 0.9996870160102844, "entropy": 0.4322837173938751, "incre_win_rate": 0.47368421052631576, "step": 1541}
{"time": 1767085681.2135448, "phase": "eval", "update": 1541, "total_env_steps": 4931200, "eval_win_rate": 0.65625, "eval_episode_reward": 18.113255380794698, "step": 1541}
{"time": 1767085685.8836293, "phase": "train", "update": 1542, "total_env_steps": 4934400, "episode_reward": 0.22100943326950073, "value_loss": 0.014732206426560878, "policy_loss": -0.0013737204273731151, "dist_entropy": 0.43481873273849486, "actor_grad_norm": 0.17678548395633698, "critic_grad_norm": 0.02751845121383667, "ratio": 0.9999483227729797, "entropy": 0.43481873273849486, "incre_win_rate": 0.65, "step": 1542}
{"time": 1767085690.6230114, "phase": "train", "update": 1543, "total_env_steps": 4937600, "episode_reward": 0.22635813057422638, "value_loss": 0.012197756767272949, "policy_loss": -0.00147335458057114, "dist_entropy": 0.41906591653823855, "actor_grad_norm": 0.10757746547460556, "critic_grad_norm": 0.06640028953552246, "ratio": 1.0001124143600464, "entropy": 0.41906591653823855, "incre_win_rate": 0.6190476190476191, "step": 1543}
{"time": 1767085695.2916038, "phase": "train", "update": 1544, "total_env_steps": 4940800, "episode_reward": 0.2217865139245987, "value_loss": 0.008760981261730194, "policy_loss": -0.0014115414041242502, "dist_entropy": 0.4144080400466919, "actor_grad_norm": 0.16547343134880066, "critic_grad_norm": 0.050529152154922485, "ratio": 0.9995984435081482, "entropy": 0.4144080400466919, "incre_win_rate": 0.7027027027027027, "step": 1544}
{"time": 1767085699.9896672, "phase": "train", "update": 1545, "total_env_steps": 4944000, "episode_reward": 0.23560121655464172, "value_loss": 0.011865614354610443, "policy_loss": -0.0015627908235302356, "dist_entropy": 0.40386371612548827, "actor_grad_norm": 0.14750750362873077, "critic_grad_norm": 0.0284795593470335, "ratio": 0.9998928904533386, "entropy": 0.40386371612548827, "incre_win_rate": 0.6136363636363636, "step": 1545}
{"time": 1767085704.6255035, "phase": "train", "update": 1546, "total_env_steps": 4947200, "episode_reward": 0.18974439799785614, "value_loss": 0.011178511753678321, "policy_loss": -0.0012105308594485109, "dist_entropy": 0.44418330788612365, "actor_grad_norm": 0.1195228323340416, "critic_grad_norm": 0.03476151451468468, "ratio": 1.0000625848770142, "entropy": 0.44418330788612365, "incre_win_rate": 0.5142857142857142, "step": 1546}
{"time": 1767085709.3437257, "phase": "train", "update": 1547, "total_env_steps": 4950400, "episode_reward": 0.22907854616641998, "value_loss": 0.011423579603433608, "policy_loss": -0.0013901446225688119, "dist_entropy": 0.4061406373977661, "actor_grad_norm": 0.17192582786083221, "critic_grad_norm": 0.02179303579032421, "ratio": 0.999783992767334, "entropy": 0.4061406373977661, "incre_win_rate": 0.6744186046511628, "step": 1547}
{"time": 1767085714.0297022, "phase": "train", "update": 1548, "total_env_steps": 4953600, "episode_reward": 0.2175455540418625, "value_loss": 0.013437604531645775, "policy_loss": -0.0012934337418641917, "dist_entropy": 0.4058836281299591, "actor_grad_norm": 0.1407581865787506, "critic_grad_norm": 0.025141362100839615, "ratio": 0.9997426271438599, "entropy": 0.4058836281299591, "incre_win_rate": 0.6756756756756757, "step": 1548}
{"time": 1767085718.69172, "phase": "train", "update": 1549, "total_env_steps": 4956800, "episode_reward": 0.21359218657016754, "value_loss": 0.013961278460919857, "policy_loss": -0.0015009077348103529, "dist_entropy": 0.4144578516483307, "actor_grad_norm": 0.11313041299581528, "critic_grad_norm": 0.05521785840392113, "ratio": 0.9999164938926697, "entropy": 0.4144578516483307, "incre_win_rate": 0.5238095238095238, "step": 1549}
{"time": 1767085723.379806, "phase": "train", "update": 1550, "total_env_steps": 4960000, "episode_reward": 0.229739248752594, "value_loss": 0.010526437312364578, "policy_loss": -0.001472796517177244, "dist_entropy": 0.39781426191329955, "actor_grad_norm": 0.22203345596790314, "critic_grad_norm": 0.05371202155947685, "ratio": 0.9998710751533508, "entropy": 0.39781426191329955, "incre_win_rate": 0.675, "step": 1550}
{"time": 1767085728.0195966, "phase": "train", "update": 1551, "total_env_steps": 4963200, "episode_reward": 0.1948567032814026, "value_loss": 0.010790696740150452, "policy_loss": -0.0011435762969597362, "dist_entropy": 0.4219713926315308, "actor_grad_norm": 0.12943407893180847, "critic_grad_norm": 0.042751092463731766, "ratio": 0.9997946619987488, "entropy": 0.4219713926315308, "incre_win_rate": 0.5526315789473685, "step": 1551}
{"time": 1767085732.792136, "phase": "train", "update": 1552, "total_env_steps": 4966400, "episode_reward": 0.20910285413265228, "value_loss": 0.01267102211713791, "policy_loss": -0.0013361908237698116, "dist_entropy": 0.4150101661682129, "actor_grad_norm": 0.10748235136270523, "critic_grad_norm": 0.046114277094602585, "ratio": 0.9999193549156189, "entropy": 0.4150101661682129, "incre_win_rate": 0.5135135135135135, "step": 1552}
{"time": 1767085737.4052181, "phase": "train", "update": 1553, "total_env_steps": 4969600, "episode_reward": 0.2179216742515564, "value_loss": 0.009666147641837597, "policy_loss": -0.0016568652914912719, "dist_entropy": 0.4182961702346802, "actor_grad_norm": 0.11613529920578003, "critic_grad_norm": 0.06138891726732254, "ratio": 0.9999752044677734, "entropy": 0.4182961702346802, "incre_win_rate": 0.717948717948718, "step": 1553}
{"time": 1767085742.154774, "phase": "train", "update": 1554, "total_env_steps": 4972800, "episode_reward": 0.2423013299703598, "value_loss": 0.009296492859721183, "policy_loss": -0.0014133423039567107, "dist_entropy": 0.40583385825157164, "actor_grad_norm": 0.09569460898637772, "critic_grad_norm": 0.04880118742585182, "ratio": 0.9999179244041443, "entropy": 0.40583385825157164, "incre_win_rate": 0.7948717948717948, "step": 1554}
{"time": 1767085746.7630315, "phase": "train", "update": 1555, "total_env_steps": 4976000, "episode_reward": 0.1980442851781845, "value_loss": 0.011536996811628342, "policy_loss": -0.0017157134529469432, "dist_entropy": 0.4265698254108429, "actor_grad_norm": 0.11614078283309937, "critic_grad_norm": 0.06349854916334152, "ratio": 0.9996657371520996, "entropy": 0.4265698254108429, "incre_win_rate": 0.48717948717948717, "step": 1555}
{"time": 1767085751.4662259, "phase": "train", "update": 1556, "total_env_steps": 4979200, "episode_reward": 0.22714868187904358, "value_loss": 0.012133356928825379, "policy_loss": -0.001189008290159066, "dist_entropy": 0.42083475589752195, "actor_grad_norm": 0.15732574462890625, "critic_grad_norm": 0.05520377308130264, "ratio": 0.999572217464447, "entropy": 0.42083475589752195, "incre_win_rate": 0.6428571428571429, "step": 1556}
{"time": 1767085756.0790327, "phase": "train", "update": 1557, "total_env_steps": 4982400, "episode_reward": 0.20256054401397705, "value_loss": 0.008946861885488034, "policy_loss": -0.0016952972756719476, "dist_entropy": 0.4439805209636688, "actor_grad_norm": 0.12851493060588837, "critic_grad_norm": 0.03318149596452713, "ratio": 1.0000649690628052, "entropy": 0.4439805209636688, "incre_win_rate": 0.6285714285714286, "step": 1557}
{"time": 1767085760.6861825, "phase": "train", "update": 1558, "total_env_steps": 4985600, "episode_reward": 0.1894640028476715, "value_loss": 0.010288752615451813, "policy_loss": -0.001247525830075702, "dist_entropy": 0.4526268422603607, "actor_grad_norm": 0.14084264636039734, "critic_grad_norm": 0.03211812302470207, "ratio": 0.9996439218521118, "entropy": 0.4526268422603607, "incre_win_rate": 0.5882352941176471, "step": 1558}
{"time": 1767085765.4843202, "phase": "train", "update": 1559, "total_env_steps": 4988800, "episode_reward": 0.2071223109960556, "value_loss": 0.011543662287294865, "policy_loss": -0.00127256991959257, "dist_entropy": 0.4304538369178772, "actor_grad_norm": 0.14995084702968597, "critic_grad_norm": 0.06497517228126526, "ratio": 1.000006079673767, "entropy": 0.4304538369178772, "incre_win_rate": 0.5789473684210527, "step": 1559}
{"time": 1767085770.0810483, "phase": "train", "update": 1560, "total_env_steps": 4992000, "episode_reward": 0.17122359573841095, "value_loss": 0.012849951721727848, "policy_loss": -0.0018773058277005816, "dist_entropy": 0.4566245198249817, "actor_grad_norm": 0.1449207365512848, "critic_grad_norm": 0.06323534995317459, "ratio": 1.0002813339233398, "entropy": 0.4566245198249817, "incre_win_rate": 0.42424242424242425, "step": 1560}
{"time": 1767085774.710688, "phase": "train", "update": 1561, "total_env_steps": 4995200, "episode_reward": 0.19036011397838593, "value_loss": 0.011171202547848225, "policy_loss": -0.001513908259221175, "dist_entropy": 0.45244423747062684, "actor_grad_norm": 0.17313583195209503, "critic_grad_norm": 0.0414968878030777, "ratio": 0.9999691843986511, "entropy": 0.45244423747062684, "incre_win_rate": 0.6, "step": 1561}
{"time": 1767085787.2001648, "phase": "eval", "update": 1561, "total_env_steps": 4995200, "eval_win_rate": 0.6875, "eval_episode_reward": 18.17275455298013, "step": 1561}
{"time": 1767085791.8422165, "phase": "train", "update": 1562, "total_env_steps": 4998400, "episode_reward": 0.2027100771665573, "value_loss": 0.011096376366913319, "policy_loss": -0.0018158370595273254, "dist_entropy": 0.45499795079231264, "actor_grad_norm": 0.2015600949525833, "critic_grad_norm": 0.050543684512376785, "ratio": 1.0000157356262207, "entropy": 0.45499795079231264, "incre_win_rate": 0.5945945945945946, "step": 1562}
{"time": 1767085796.5115173, "phase": "train", "update": 1563, "total_env_steps": 5001600, "episode_reward": 0.2220716029405594, "value_loss": 0.010580473206937313, "policy_loss": -0.0013059114797762561, "dist_entropy": 0.4179815769195557, "actor_grad_norm": 0.1367289274930954, "critic_grad_norm": 0.041602130979299545, "ratio": 0.9998012781143188, "entropy": 0.4179815769195557, "incre_win_rate": 0.6923076923076923, "step": 1563}
{"time": 1767085801.0987816, "phase": "train", "update": 1564, "total_env_steps": 5004800, "episode_reward": 0.18156664073467255, "value_loss": 0.01672207936644554, "policy_loss": -0.001740399530642378, "dist_entropy": 0.46282480359077455, "actor_grad_norm": 0.17443729937076569, "critic_grad_norm": 0.07945269346237183, "ratio": 0.9996597170829773, "entropy": 0.46282480359077455, "incre_win_rate": 0.42857142857142855, "step": 1564}
{"time": 1767085805.9752917, "phase": "train", "update": 1565, "total_env_steps": 5008000, "episode_reward": 0.23422548174858093, "value_loss": 0.009952778927981853, "policy_loss": -0.0010805249730125865, "dist_entropy": 0.41530293226242065, "actor_grad_norm": 0.17867958545684814, "critic_grad_norm": 0.09774886816740036, "ratio": 0.9998552203178406, "entropy": 0.41530293226242065, "incre_win_rate": 0.6976744186046512, "step": 1565}
{"time": 1767085810.7055442, "phase": "train", "update": 1566, "total_env_steps": 5011200, "episode_reward": 0.22262367606163025, "value_loss": 0.009481821022927762, "policy_loss": -0.0011000649665636076, "dist_entropy": 0.43157142400741577, "actor_grad_norm": 0.11727464199066162, "critic_grad_norm": 0.07087792456150055, "ratio": 1.000321626663208, "entropy": 0.43157142400741577, "incre_win_rate": 0.631578947368421, "step": 1566}
{"time": 1767085815.3495312, "phase": "train", "update": 1567, "total_env_steps": 5014400, "episode_reward": 0.2035771906375885, "value_loss": 0.011336989887058734, "policy_loss": -0.0015114634018193128, "dist_entropy": 0.4383726894855499, "actor_grad_norm": 0.1466909945011139, "critic_grad_norm": 0.03607457876205444, "ratio": 0.9999553561210632, "entropy": 0.4383726894855499, "incre_win_rate": 0.5135135135135135, "step": 1567}
{"time": 1767085820.039513, "phase": "train", "update": 1568, "total_env_steps": 5017600, "episode_reward": 0.22190448641777039, "value_loss": 0.012805397622287273, "policy_loss": -0.0014629537756739807, "dist_entropy": 0.417416387796402, "actor_grad_norm": 0.13387814164161682, "critic_grad_norm": 0.018660608679056168, "ratio": 0.999830424785614, "entropy": 0.417416387796402, "incre_win_rate": 0.6829268292682927, "step": 1568}
{"time": 1767085824.8007176, "phase": "train", "update": 1569, "total_env_steps": 5020800, "episode_reward": 0.23248809576034546, "value_loss": 0.010585260018706322, "policy_loss": -0.0012320709686861164, "dist_entropy": 0.4316872596740723, "actor_grad_norm": 0.15104030072689056, "critic_grad_norm": 0.03755412623286247, "ratio": 1.0001558065414429, "entropy": 0.4316872596740723, "incre_win_rate": 0.725, "step": 1569}
{"time": 1767085829.4901638, "phase": "train", "update": 1570, "total_env_steps": 5024000, "episode_reward": 0.20981734991073608, "value_loss": 0.01296955645084381, "policy_loss": -0.0016089259889415786, "dist_entropy": 0.4463938117027283, "actor_grad_norm": 0.12683849036693573, "critic_grad_norm": 0.05639079958200455, "ratio": 0.9999224543571472, "entropy": 0.4463938117027283, "incre_win_rate": 0.6486486486486487, "step": 1570}
{"time": 1767085834.20509, "phase": "train", "update": 1571, "total_env_steps": 5027200, "episode_reward": 0.2111128866672516, "value_loss": 0.012189566530287266, "policy_loss": -0.0013517770033807607, "dist_entropy": 0.44221946597099304, "actor_grad_norm": 0.18697071075439453, "critic_grad_norm": 0.04693888500332832, "ratio": 1.000098466873169, "entropy": 0.44221946597099304, "incre_win_rate": 0.5476190476190477, "step": 1571}
{"time": 1767085838.8004022, "phase": "train", "update": 1572, "total_env_steps": 5030400, "episode_reward": 0.20000103116035461, "value_loss": 0.01320889350026846, "policy_loss": -0.0014070201516545922, "dist_entropy": 0.44014387130737304, "actor_grad_norm": 0.14762850105762482, "critic_grad_norm": 0.06590445339679718, "ratio": 0.9997760653495789, "entropy": 0.44014387130737304, "incre_win_rate": 0.5135135135135135, "step": 1572}
{"time": 1767085843.5021696, "phase": "train", "update": 1573, "total_env_steps": 5033600, "episode_reward": 0.21239912509918213, "value_loss": 0.013759152777493, "policy_loss": -0.001474763304278781, "dist_entropy": 0.42147394418716433, "actor_grad_norm": 0.18599480390548706, "critic_grad_norm": 0.04904092103242874, "ratio": 0.9995436668395996, "entropy": 0.42147394418716433, "incre_win_rate": 0.5365853658536586, "step": 1573}
{"time": 1767085848.233236, "phase": "train", "update": 1574, "total_env_steps": 5036800, "episode_reward": 0.230742946267128, "value_loss": 0.0118858827278018, "policy_loss": -0.0015023275051525785, "dist_entropy": 0.4102105736732483, "actor_grad_norm": 0.18984486162662506, "critic_grad_norm": 0.027968639507889748, "ratio": 0.9999184012413025, "entropy": 0.4102105736732483, "incre_win_rate": 0.627906976744186, "step": 1574}
{"time": 1767085852.9123917, "phase": "train", "update": 1575, "total_env_steps": 5040000, "episode_reward": 0.23034147918224335, "value_loss": 0.010588975064456463, "policy_loss": -0.0014514851663932405, "dist_entropy": 0.43586702942848204, "actor_grad_norm": 0.15948528051376343, "critic_grad_norm": 0.04577576369047165, "ratio": 1.000096082687378, "entropy": 0.43586702942848204, "incre_win_rate": 0.7297297297297297, "step": 1575}
{"time": 1767085857.9358325, "phase": "train", "update": 1576, "total_env_steps": 5043200, "episode_reward": 0.2126438319683075, "value_loss": 0.012717241793870926, "policy_loss": -0.0017127087827567776, "dist_entropy": 0.43701231479644775, "actor_grad_norm": 0.21087804436683655, "critic_grad_norm": 0.060627784579992294, "ratio": 0.9997984766960144, "entropy": 0.43701231479644775, "incre_win_rate": 0.6153846153846154, "step": 1576}
{"time": 1767085862.7477078, "phase": "train", "update": 1577, "total_env_steps": 5046400, "episode_reward": 0.19908373057842255, "value_loss": 0.011544215120375156, "policy_loss": -0.0013034979585313522, "dist_entropy": 0.4178094744682312, "actor_grad_norm": 0.18031734228134155, "critic_grad_norm": 0.0681162104010582, "ratio": 1.0002189874649048, "entropy": 0.4178094744682312, "incre_win_rate": 0.5, "step": 1577}
{"time": 1767085867.853037, "phase": "train", "update": 1578, "total_env_steps": 5049600, "episode_reward": 0.21247261762619019, "value_loss": 0.013619355857372284, "policy_loss": -0.0015364123641933957, "dist_entropy": 0.40677846074104307, "actor_grad_norm": 0.15206556022167206, "critic_grad_norm": 0.03994864597916603, "ratio": 0.9998047947883606, "entropy": 0.40677846074104307, "incre_win_rate": 0.5526315789473685, "step": 1578}
{"time": 1767085872.909555, "phase": "train", "update": 1579, "total_env_steps": 5052800, "episode_reward": 0.23196762800216675, "value_loss": 0.009717629663646222, "policy_loss": -0.0015774016739264595, "dist_entropy": 0.4292895317077637, "actor_grad_norm": 0.1814068853855133, "critic_grad_norm": 0.10142832249403, "ratio": 0.999825119972229, "entropy": 0.4292895317077637, "incre_win_rate": 0.6585365853658537, "step": 1579}
{"time": 1767085878.0361836, "phase": "train", "update": 1580, "total_env_steps": 5056000, "episode_reward": 0.19572538137435913, "value_loss": 0.015062134712934494, "policy_loss": -0.0012939040136043189, "dist_entropy": 0.4362387597560883, "actor_grad_norm": 0.1411774605512619, "critic_grad_norm": 0.13115127384662628, "ratio": 0.9996945261955261, "entropy": 0.4362387597560883, "incre_win_rate": 0.4864864864864865, "step": 1580}
{"time": 1767085882.9735656, "phase": "train", "update": 1581, "total_env_steps": 5059200, "episode_reward": 0.20531147718429565, "value_loss": 0.017042800411581994, "policy_loss": -0.0018768654754964587, "dist_entropy": 0.4167723298072815, "actor_grad_norm": 0.10265576839447021, "critic_grad_norm": 0.0703093409538269, "ratio": 1.0002349615097046, "entropy": 0.4167723298072815, "incre_win_rate": 0.47368421052631576, "step": 1581}
{"time": 1767085896.8672066, "phase": "eval", "update": 1581, "total_env_steps": 5059200, "eval_win_rate": 0.5, "eval_episode_reward": 16.849389486754966, "step": 1581}
{"time": 1767085901.5621743, "phase": "train", "update": 1582, "total_env_steps": 5062400, "episode_reward": 0.1561516970396042, "value_loss": 0.017866314202547074, "policy_loss": -0.0015941297866945091, "dist_entropy": 0.44193500876426695, "actor_grad_norm": 0.15125451982021332, "critic_grad_norm": 0.10227634757757187, "ratio": 0.9997950792312622, "entropy": 0.44193500876426695, "incre_win_rate": 0.24324324324324326, "step": 1582}
{"time": 1767085906.4580383, "phase": "train", "update": 1583, "total_env_steps": 5065600, "episode_reward": 0.18433929979801178, "value_loss": 0.016865331307053567, "policy_loss": -0.0015008740226793548, "dist_entropy": 0.42844725847244264, "actor_grad_norm": 0.1273457109928131, "critic_grad_norm": 0.06711088865995407, "ratio": 0.999866783618927, "entropy": 0.42844725847244264, "incre_win_rate": 0.3888888888888889, "step": 1583}
{"time": 1767085911.2745461, "phase": "train", "update": 1584, "total_env_steps": 5068800, "episode_reward": 0.17882812023162842, "value_loss": 0.01534240934997797, "policy_loss": -0.0016042346284711906, "dist_entropy": 0.4343539297580719, "actor_grad_norm": 0.1557408571243286, "critic_grad_norm": 0.05474275350570679, "ratio": 1.000055193901062, "entropy": 0.4343539297580719, "incre_win_rate": 0.34210526315789475, "step": 1584}
{"time": 1767085916.231194, "phase": "train", "update": 1585, "total_env_steps": 5072000, "episode_reward": 0.2047092467546463, "value_loss": 0.018119553476572035, "policy_loss": -0.0010503701975672186, "dist_entropy": 0.43572039604187013, "actor_grad_norm": 0.1308603137731552, "critic_grad_norm": 0.03868924081325531, "ratio": 0.9997195601463318, "entropy": 0.43572039604187013, "incre_win_rate": 0.5121951219512195, "step": 1585}
{"time": 1767085921.2211783, "phase": "train", "update": 1586, "total_env_steps": 5075200, "episode_reward": 0.2086232304573059, "value_loss": 0.015729647129774094, "policy_loss": -0.0014074443002584757, "dist_entropy": 0.4340407192707062, "actor_grad_norm": 0.12842312455177307, "critic_grad_norm": 0.07327549159526825, "ratio": 0.99986332654953, "entropy": 0.4340407192707062, "incre_win_rate": 0.5833333333333334, "step": 1586}
{"time": 1767085926.1247985, "phase": "train", "update": 1587, "total_env_steps": 5078400, "episode_reward": 0.18187086284160614, "value_loss": 0.013319368287920953, "policy_loss": -0.001395254523173861, "dist_entropy": 0.434613436460495, "actor_grad_norm": 0.13865599036216736, "critic_grad_norm": 0.05690231919288635, "ratio": 1.0002306699752808, "entropy": 0.434613436460495, "incre_win_rate": 0.38461538461538464, "step": 1587}
{"time": 1767085930.9070528, "phase": "train", "update": 1588, "total_env_steps": 5081600, "episode_reward": 0.18981529772281647, "value_loss": 0.01639137640595436, "policy_loss": -0.0014229272894972667, "dist_entropy": 0.42799211144447324, "actor_grad_norm": 0.15559075772762299, "critic_grad_norm": 0.06774820387363434, "ratio": 0.9998707175254822, "entropy": 0.42799211144447324, "incre_win_rate": 0.3888888888888889, "step": 1588}
{"time": 1767085935.976339, "phase": "train", "update": 1589, "total_env_steps": 5084800, "episode_reward": 0.1967104971408844, "value_loss": 0.01677936129271984, "policy_loss": -0.001828683048097446, "dist_entropy": 0.4411260366439819, "actor_grad_norm": 0.14499269425868988, "critic_grad_norm": 0.06763576716184616, "ratio": 0.9994608163833618, "entropy": 0.4411260366439819, "incre_win_rate": 0.475, "step": 1589}
{"time": 1767085940.851411, "phase": "train", "update": 1590, "total_env_steps": 5088000, "episode_reward": 0.20669753849506378, "value_loss": 0.012964940629899502, "policy_loss": -0.0011481656274284547, "dist_entropy": 0.4284142076969147, "actor_grad_norm": 0.16209423542022705, "critic_grad_norm": 0.08885902166366577, "ratio": 1.0001417398452759, "entropy": 0.4284142076969147, "incre_win_rate": 0.5, "step": 1590}
{"time": 1767085946.0812273, "phase": "train", "update": 1591, "total_env_steps": 5091200, "episode_reward": 0.2220110446214676, "value_loss": 0.013799699209630489, "policy_loss": -0.0014068554356915896, "dist_entropy": 0.41133354902267455, "actor_grad_norm": 0.12981469929218292, "critic_grad_norm": 0.08940105885267258, "ratio": 1.0001369714736938, "entropy": 0.41133354902267455, "incre_win_rate": 0.6, "step": 1591}
{"time": 1767085950.8797116, "phase": "train", "update": 1592, "total_env_steps": 5094400, "episode_reward": 0.2002488672733307, "value_loss": 0.013771187514066696, "policy_loss": -0.0014979387912319453, "dist_entropy": 0.42929887771606445, "actor_grad_norm": 0.14434537291526794, "critic_grad_norm": 0.09401138126850128, "ratio": 1.000225305557251, "entropy": 0.42929887771606445, "incre_win_rate": 0.4473684210526316, "step": 1592}
{"time": 1767085955.7564867, "phase": "train", "update": 1593, "total_env_steps": 5097600, "episode_reward": 0.21090489625930786, "value_loss": 0.012524264864623547, "policy_loss": -0.0016599702712648324, "dist_entropy": 0.4287768006324768, "actor_grad_norm": 0.15747810900211334, "critic_grad_norm": 0.06875474005937576, "ratio": 0.9998270273208618, "entropy": 0.4287768006324768, "incre_win_rate": 0.5365853658536586, "step": 1593}
{"time": 1767085960.6947696, "phase": "train", "update": 1594, "total_env_steps": 5100800, "episode_reward": 0.23435069620609283, "value_loss": 0.016165964677929877, "policy_loss": -0.0012838327751872214, "dist_entropy": 0.39949252009391784, "actor_grad_norm": 0.1270049661397934, "critic_grad_norm": 0.033196140080690384, "ratio": 0.9999228715896606, "entropy": 0.39949252009391784, "incre_win_rate": 0.5609756097560976, "step": 1594}
{"time": 1767085965.4753654, "phase": "train", "update": 1595, "total_env_steps": 5104000, "episode_reward": 0.19485202431678772, "value_loss": 0.01248356644064188, "policy_loss": -0.0015604394103718277, "dist_entropy": 0.42462387681007385, "actor_grad_norm": 0.1302471160888672, "critic_grad_norm": 0.03033076599240303, "ratio": 0.999879002571106, "entropy": 0.42462387681007385, "incre_win_rate": 0.47368421052631576, "step": 1595}
{"time": 1767085970.4039378, "phase": "train", "update": 1596, "total_env_steps": 5107200, "episode_reward": 0.2037215381860733, "value_loss": 0.014104847609996796, "policy_loss": -0.0013251966804148196, "dist_entropy": 0.41230833530426025, "actor_grad_norm": 0.12191291153430939, "critic_grad_norm": 0.04631618410348892, "ratio": 1.000319480895996, "entropy": 0.41230833530426025, "incre_win_rate": 0.4358974358974359, "step": 1596}
{"time": 1767085975.3423302, "phase": "train", "update": 1597, "total_env_steps": 5110400, "episode_reward": 0.2333526462316513, "value_loss": 0.015192161872982978, "policy_loss": -0.0014832371089937625, "dist_entropy": 0.3894872426986694, "actor_grad_norm": 0.10264687985181808, "critic_grad_norm": 0.07948895543813705, "ratio": 0.9999915957450867, "entropy": 0.3894872426986694, "incre_win_rate": 0.6341463414634146, "step": 1597}
{"time": 1767085980.2928205, "phase": "train", "update": 1598, "total_env_steps": 5113600, "episode_reward": 0.21268263459205627, "value_loss": 0.014507375098764897, "policy_loss": -0.0018194458498996368, "dist_entropy": 0.3884697914123535, "actor_grad_norm": 0.11900507658720016, "critic_grad_norm": 0.07081357389688492, "ratio": 0.9997353553771973, "entropy": 0.3884697914123535, "incre_win_rate": 0.5, "step": 1598}
{"time": 1767085985.3276854, "phase": "train", "update": 1599, "total_env_steps": 5116800, "episode_reward": 0.20951367914676666, "value_loss": 0.01500623170286417, "policy_loss": -0.0010359208762238837, "dist_entropy": 0.4172460436820984, "actor_grad_norm": 0.1424713432788849, "critic_grad_norm": 0.03501255810260773, "ratio": 0.9999943971633911, "entropy": 0.4172460436820984, "incre_win_rate": 0.4, "step": 1599}
{"time": 1767085990.154273, "phase": "train", "update": 1600, "total_env_steps": 5120000, "episode_reward": 0.1980406641960144, "value_loss": 0.014870276302099228, "policy_loss": -0.0015670873280875242, "dist_entropy": 0.4268300414085388, "actor_grad_norm": 0.185600146651268, "critic_grad_norm": 0.03479791432619095, "ratio": 0.9997845888137817, "entropy": 0.4268300414085388, "incre_win_rate": 0.46153846153846156, "step": 1600}
{"time": 1767085995.0858378, "phase": "train", "update": 1601, "total_env_steps": 5123200, "episode_reward": 0.22614137828350067, "value_loss": 0.010356077551841735, "policy_loss": -0.0017419873857043911, "dist_entropy": 0.4146225094795227, "actor_grad_norm": 0.16212955117225647, "critic_grad_norm": 0.07655704766511917, "ratio": 1.0000019073486328, "entropy": 0.4146225094795227, "incre_win_rate": 0.7317073170731707, "step": 1601}
{"time": 1767086009.0913675, "phase": "eval", "update": 1601, "total_env_steps": 5123200, "eval_win_rate": 0.53125, "eval_episode_reward": 17.049720612582778, "step": 1601}
{"time": 1767086014.363749, "phase": "train", "update": 1602, "total_env_steps": 5126400, "episode_reward": 0.21138142049312592, "value_loss": 0.012864894792437553, "policy_loss": -0.0015839105832611722, "dist_entropy": 0.41652153730392455, "actor_grad_norm": 0.14576469361782074, "critic_grad_norm": 0.07588556408882141, "ratio": 0.9999253153800964, "entropy": 0.41652153730392455, "incre_win_rate": 0.48717948717948717, "step": 1602}
{"time": 1767086019.3601022, "phase": "train", "update": 1603, "total_env_steps": 5129600, "episode_reward": 0.20442260801792145, "value_loss": 0.01332905050367117, "policy_loss": -0.001516989252107237, "dist_entropy": 0.4155077040195465, "actor_grad_norm": 0.19482028484344482, "critic_grad_norm": 0.05402909591794014, "ratio": 1.0001786947250366, "entropy": 0.4155077040195465, "incre_win_rate": 0.5, "step": 1603}
{"time": 1767086024.0525825, "phase": "train", "update": 1604, "total_env_steps": 5132800, "episode_reward": 0.19297032058238983, "value_loss": 0.016005652025341988, "policy_loss": -0.0012585397979326452, "dist_entropy": 0.4315489292144775, "actor_grad_norm": 0.16995437443256378, "critic_grad_norm": 0.06157892569899559, "ratio": 0.9998324513435364, "entropy": 0.4315489292144775, "incre_win_rate": 0.4594594594594595, "step": 1604}
{"time": 1767086028.6673903, "phase": "train", "update": 1605, "total_env_steps": 5136000, "episode_reward": 0.16743946075439453, "value_loss": 0.018083256855607032, "policy_loss": -0.0019011689703933854, "dist_entropy": 0.43842840790748594, "actor_grad_norm": 0.17121361196041107, "critic_grad_norm": 0.06005183979868889, "ratio": 0.9997732043266296, "entropy": 0.43842840790748594, "incre_win_rate": 0.2857142857142857, "step": 1605}
{"time": 1767086033.4872534, "phase": "train", "update": 1606, "total_env_steps": 5139200, "episode_reward": 0.17481788992881775, "value_loss": 0.01589125245809555, "policy_loss": -0.0020224799646751277, "dist_entropy": 0.44322832822799685, "actor_grad_norm": 0.19918563961982727, "critic_grad_norm": 0.03891202062368393, "ratio": 0.9997066855430603, "entropy": 0.44322832822799685, "incre_win_rate": 0.4, "step": 1606}
{"time": 1767086038.2320056, "phase": "train", "update": 1607, "total_env_steps": 5142400, "episode_reward": 0.20960885286331177, "value_loss": 0.012507829628884793, "policy_loss": -0.001596489658334832, "dist_entropy": 0.42235816121101377, "actor_grad_norm": 0.18071891367435455, "critic_grad_norm": 0.0884699672460556, "ratio": 0.9999331831932068, "entropy": 0.42235816121101377, "incre_win_rate": 0.5555555555555556, "step": 1607}
{"time": 1767086042.877337, "phase": "train", "update": 1608, "total_env_steps": 5145600, "episode_reward": 0.1811615377664566, "value_loss": 0.013262922503054142, "policy_loss": -0.0017737827150995145, "dist_entropy": 0.44527965784072876, "actor_grad_norm": 0.16034972667694092, "critic_grad_norm": 0.08516960591077805, "ratio": 0.9999130368232727, "entropy": 0.44527965784072876, "incre_win_rate": 0.41025641025641024, "step": 1608}
{"time": 1767086047.6790147, "phase": "train", "update": 1609, "total_env_steps": 5148800, "episode_reward": 0.179900661110878, "value_loss": 0.01408961322158575, "policy_loss": -0.0015761439061876103, "dist_entropy": 0.4466506540775299, "actor_grad_norm": 0.14519011974334717, "critic_grad_norm": 0.0673089250922203, "ratio": 0.9999979138374329, "entropy": 0.4466506540775299, "incre_win_rate": 0.42857142857142855, "step": 1609}
{"time": 1767086052.8103135, "phase": "train", "update": 1610, "total_env_steps": 5152000, "episode_reward": 0.19952712953090668, "value_loss": 0.01346419844776392, "policy_loss": -0.001530779326333942, "dist_entropy": 0.4202693998813629, "actor_grad_norm": 0.164780855178833, "critic_grad_norm": 0.056368716061115265, "ratio": 0.9998346567153931, "entropy": 0.4202693998813629, "incre_win_rate": 0.4, "step": 1610}
{"time": 1767086057.8069255, "phase": "train", "update": 1611, "total_env_steps": 5155200, "episode_reward": 0.1795814484357834, "value_loss": 0.018240098655223847, "policy_loss": -0.0016331881545489258, "dist_entropy": 0.44682523012161257, "actor_grad_norm": 0.17558231949806213, "critic_grad_norm": 0.05509646609425545, "ratio": 1.0001453161239624, "entropy": 0.44682523012161257, "incre_win_rate": 0.34210526315789475, "step": 1611}
{"time": 1767086062.6780536, "phase": "train", "update": 1612, "total_env_steps": 5158400, "episode_reward": 0.221394881606102, "value_loss": 0.01501710396260023, "policy_loss": -0.0015807242792100328, "dist_entropy": 0.4266513526439667, "actor_grad_norm": 0.19280627369880676, "critic_grad_norm": 0.08741246908903122, "ratio": 0.9997536540031433, "entropy": 0.4266513526439667, "incre_win_rate": 0.5853658536585366, "step": 1612}
{"time": 1767086067.549446, "phase": "train", "update": 1613, "total_env_steps": 5161600, "episode_reward": 0.21049723029136658, "value_loss": 0.01067757625132799, "policy_loss": -0.0015269528775448294, "dist_entropy": 0.4227741599082947, "actor_grad_norm": 0.14984238147735596, "critic_grad_norm": 0.10558293014764786, "ratio": 1.0002501010894775, "entropy": 0.4227741599082947, "incre_win_rate": 0.6756756756756757, "step": 1613}
{"time": 1767086072.3160064, "phase": "train", "update": 1614, "total_env_steps": 5164800, "episode_reward": 0.19779179990291595, "value_loss": 0.017721722647547723, "policy_loss": -0.0015740631531936168, "dist_entropy": 0.4321121335029602, "actor_grad_norm": 0.15644896030426025, "critic_grad_norm": 0.051882922649383545, "ratio": 0.9996640086174011, "entropy": 0.4321121335029602, "incre_win_rate": 0.41025641025641024, "step": 1614}
{"time": 1767086077.541261, "phase": "train", "update": 1615, "total_env_steps": 5168000, "episode_reward": 0.21975217759609222, "value_loss": 0.010543989017605782, "policy_loss": -0.0013725519665791276, "dist_entropy": 0.4262905538082123, "actor_grad_norm": 0.17063555121421814, "critic_grad_norm": 0.10900727659463882, "ratio": 1.0002549886703491, "entropy": 0.4262905538082123, "incre_win_rate": 0.75, "step": 1615}
{"time": 1767086082.7730796, "phase": "train", "update": 1616, "total_env_steps": 5171200, "episode_reward": 0.20532956719398499, "value_loss": 0.013954262807965278, "policy_loss": -0.0014704259063961444, "dist_entropy": 0.4327025473117828, "actor_grad_norm": 0.22033488750457764, "critic_grad_norm": 0.08278674632310867, "ratio": 1.0002127885818481, "entropy": 0.4327025473117828, "incre_win_rate": 0.5428571428571428, "step": 1616}
{"time": 1767086088.6215599, "phase": "train", "update": 1617, "total_env_steps": 5174400, "episode_reward": 0.1983107328414917, "value_loss": 0.013876053504645824, "policy_loss": -0.0017440585634975747, "dist_entropy": 0.42823666930198667, "actor_grad_norm": 0.204878568649292, "critic_grad_norm": 0.06823688000440598, "ratio": 0.9999337196350098, "entropy": 0.42823666930198667, "incre_win_rate": 0.48717948717948717, "step": 1617}
{"time": 1767086093.9386954, "phase": "train", "update": 1618, "total_env_steps": 5177600, "episode_reward": 0.22390833497047424, "value_loss": 0.009998816065490246, "policy_loss": -0.0011413296830129927, "dist_entropy": 0.40778928995132446, "actor_grad_norm": 0.1858738213777542, "critic_grad_norm": 0.04797348380088806, "ratio": 1.0001296997070312, "entropy": 0.40778928995132446, "incre_win_rate": 0.6, "step": 1618}
{"time": 1767086098.976837, "phase": "train", "update": 1619, "total_env_steps": 5180800, "episode_reward": 0.2264714390039444, "value_loss": 0.010340295359492302, "policy_loss": -0.0013059412681414528, "dist_entropy": 0.4095591604709625, "actor_grad_norm": 0.21316146850585938, "critic_grad_norm": 0.04275250434875488, "ratio": 1.00002121925354, "entropy": 0.4095591604709625, "incre_win_rate": 0.6341463414634146, "step": 1619}
{"time": 1767086103.937214, "phase": "train", "update": 1620, "total_env_steps": 5184000, "episode_reward": 0.23370860517024994, "value_loss": 0.009950465336441994, "policy_loss": -0.0013302977207757748, "dist_entropy": 0.41797939538955686, "actor_grad_norm": 0.20552603900432587, "critic_grad_norm": 0.020083142444491386, "ratio": 1.0002143383026123, "entropy": 0.41797939538955686, "incre_win_rate": 0.6904761904761905, "step": 1620}
{"time": 1767086108.8010354, "phase": "train", "update": 1621, "total_env_steps": 5187200, "episode_reward": 0.23549823462963104, "value_loss": 0.011040446534752845, "policy_loss": -0.0011925206798977684, "dist_entropy": 0.4113582193851471, "actor_grad_norm": 0.15708057582378387, "critic_grad_norm": 0.03093103878200054, "ratio": 1.0000815391540527, "entropy": 0.4113582193851471, "incre_win_rate": 0.6829268292682927, "step": 1621}
{"time": 1767086120.5290208, "phase": "eval", "update": 1621, "total_env_steps": 5187200, "eval_win_rate": 0.78125, "eval_episode_reward": 18.4908423013245, "step": 1621}
{"time": 1767086125.3314161, "phase": "train", "update": 1622, "total_env_steps": 5190400, "episode_reward": 0.2265547513961792, "value_loss": 0.010618561320006848, "policy_loss": -0.0012909535140153139, "dist_entropy": 0.4151671648025513, "actor_grad_norm": 0.1155962273478508, "critic_grad_norm": 0.05466950684785843, "ratio": 1.0000839233398438, "entropy": 0.4151671648025513, "incre_win_rate": 0.7, "step": 1622}
{"time": 1767086130.2116978, "phase": "train", "update": 1623, "total_env_steps": 5193600, "episode_reward": 0.2252323180437088, "value_loss": 0.012662790156900883, "policy_loss": -0.0017579125225971382, "dist_entropy": 0.411546528339386, "actor_grad_norm": 0.11818993091583252, "critic_grad_norm": 0.05131511017680168, "ratio": 0.9996663928031921, "entropy": 0.411546528339386, "incre_win_rate": 0.6666666666666666, "step": 1623}
{"time": 1767086134.9473517, "phase": "train", "update": 1624, "total_env_steps": 5196800, "episode_reward": 0.21557895839214325, "value_loss": 0.012462600879371167, "policy_loss": -0.001241481577211445, "dist_entropy": 0.4173568308353424, "actor_grad_norm": 0.12978696823120117, "critic_grad_norm": 0.03577785938978195, "ratio": 0.9999011158943176, "entropy": 0.4173568308353424, "incre_win_rate": 0.575, "step": 1624}
{"time": 1767086139.6191142, "phase": "train", "update": 1625, "total_env_steps": 5200000, "episode_reward": 0.20369981229305267, "value_loss": 0.01077543143182993, "policy_loss": -0.0012772779579066195, "dist_entropy": 0.40536749958992, "actor_grad_norm": 0.12361228466033936, "critic_grad_norm": 0.028738602995872498, "ratio": 0.9998443722724915, "entropy": 0.40536749958992, "incre_win_rate": 0.6486486486486487, "step": 1625}
{"time": 1767086144.3490953, "phase": "train", "update": 1626, "total_env_steps": 5203200, "episode_reward": 0.21047291159629822, "value_loss": 0.015271980687975884, "policy_loss": -0.0008727221812264929, "dist_entropy": 0.4141100227832794, "actor_grad_norm": 0.12483727931976318, "critic_grad_norm": 0.07938303798437119, "ratio": 0.9999918937683105, "entropy": 0.4141100227832794, "incre_win_rate": 0.5641025641025641, "step": 1626}
{"time": 1767086149.0624077, "phase": "train", "update": 1627, "total_env_steps": 5206400, "episode_reward": 0.1916385442018509, "value_loss": 0.016467829793691637, "policy_loss": -0.0015045419698218154, "dist_entropy": 0.4351567804813385, "actor_grad_norm": 0.14540639519691467, "critic_grad_norm": 0.06536438316106796, "ratio": 0.9999458193778992, "entropy": 0.4351567804813385, "incre_win_rate": 0.5675675675675675, "step": 1627}
{"time": 1767086153.808081, "phase": "train", "update": 1628, "total_env_steps": 5209600, "episode_reward": 0.18076004087924957, "value_loss": 0.014761368185281754, "policy_loss": -0.0015122281127299074, "dist_entropy": 0.4569629967212677, "actor_grad_norm": 0.12855325639247894, "critic_grad_norm": 0.028780503198504448, "ratio": 0.9997994303703308, "entropy": 0.4569629967212677, "incre_win_rate": 0.3684210526315789, "step": 1628}
{"time": 1767086158.5165837, "phase": "train", "update": 1629, "total_env_steps": 5212800, "episode_reward": 0.21187500655651093, "value_loss": 0.012780327908694744, "policy_loss": -0.0015085254969775975, "dist_entropy": 0.39302568435668944, "actor_grad_norm": 0.13390517234802246, "critic_grad_norm": 0.07184083014726639, "ratio": 1.0000810623168945, "entropy": 0.39302568435668944, "incre_win_rate": 0.7222222222222222, "step": 1629}
{"time": 1767086163.2112668, "phase": "train", "update": 1630, "total_env_steps": 5216000, "episode_reward": 0.20583713054656982, "value_loss": 0.011708947271108628, "policy_loss": -0.001482321459241831, "dist_entropy": 0.4125637590885162, "actor_grad_norm": 0.13940851390361786, "critic_grad_norm": 0.06082126125693321, "ratio": 0.9998376965522766, "entropy": 0.4125637590885162, "incre_win_rate": 0.5, "step": 1630}
{"time": 1767086167.9285896, "phase": "train", "update": 1631, "total_env_steps": 5219200, "episode_reward": 0.21727806329727173, "value_loss": 0.011553418263792992, "policy_loss": -0.001317608563323347, "dist_entropy": 0.3955923795700073, "actor_grad_norm": 0.14393913745880127, "critic_grad_norm": 0.024671971797943115, "ratio": 1.0000061988830566, "entropy": 0.3955923795700073, "incre_win_rate": 0.6410256410256411, "step": 1631}
{"time": 1767086172.580774, "phase": "train", "update": 1632, "total_env_steps": 5222400, "episode_reward": 0.20064674317836761, "value_loss": 0.01025501750409603, "policy_loss": -0.001594087173786818, "dist_entropy": 0.4186661601066589, "actor_grad_norm": 0.14645053446292877, "critic_grad_norm": 0.03401186689734459, "ratio": 0.9997319579124451, "entropy": 0.4186661601066589, "incre_win_rate": 0.5405405405405406, "step": 1632}
{"time": 1767086177.2983816, "phase": "train", "update": 1633, "total_env_steps": 5225600, "episode_reward": 0.2186548262834549, "value_loss": 0.011254600994288922, "policy_loss": -0.0015844963305752912, "dist_entropy": 0.4113279163837433, "actor_grad_norm": 0.13230274617671967, "critic_grad_norm": 0.04022584110498428, "ratio": 0.9998149871826172, "entropy": 0.4113279163837433, "incre_win_rate": 0.675, "step": 1633}
{"time": 1767086182.1084926, "phase": "train", "update": 1634, "total_env_steps": 5228800, "episode_reward": 0.21233341097831726, "value_loss": 0.015513582900166512, "policy_loss": -0.0014841671657976007, "dist_entropy": 0.4028402388095856, "actor_grad_norm": 0.10484609752893448, "critic_grad_norm": 0.05025743320584297, "ratio": 1.0001869201660156, "entropy": 0.4028402388095856, "incre_win_rate": 0.5, "step": 1634}
{"time": 1767086227.577283, "phase": "train", "update": 1635, "total_env_steps": 5232000, "episode_reward": 0.19186049699783325, "value_loss": 0.06625799834728241, "policy_loss": -0.0010007901710832102, "dist_entropy": 0.4125474214553833, "actor_grad_norm": 0.09986812621355057, "critic_grad_norm": 0.19781003892421722, "ratio": 0.9999859929084778, "entropy": 0.4125474214553833, "incre_win_rate": 0.4411764705882353, "step": 1635}
{"time": 1767086232.5431883, "phase": "train", "update": 1636, "total_env_steps": 5235200, "episode_reward": 0.18270644545555115, "value_loss": 0.015214786492288112, "policy_loss": -0.0016284336370958386, "dist_entropy": 0.40148223638534547, "actor_grad_norm": 0.13719399273395538, "critic_grad_norm": 0.15973226726055145, "ratio": 0.9998076558113098, "entropy": 0.40148223638534547, "incre_win_rate": 0.45714285714285713, "step": 1636}
{"time": 1767086237.5551074, "phase": "train", "update": 1637, "total_env_steps": 5238400, "episode_reward": 0.19458559155464172, "value_loss": 0.01526539884507656, "policy_loss": -0.0013349529095375346, "dist_entropy": 0.4147112429141998, "actor_grad_norm": 0.14590108394622803, "critic_grad_norm": 0.12222553789615631, "ratio": 1.0000041723251343, "entropy": 0.4147112429141998, "incre_win_rate": 0.4864864864864865, "step": 1637}
{"time": 1767086242.5811992, "phase": "train", "update": 1638, "total_env_steps": 5241600, "episode_reward": 0.22267383337020874, "value_loss": 0.011124967224895954, "policy_loss": -0.0013220389322455618, "dist_entropy": 0.3914874494075775, "actor_grad_norm": 0.1835053712129593, "critic_grad_norm": 0.1102181002497673, "ratio": 0.9999982118606567, "entropy": 0.3914874494075775, "incre_win_rate": 0.6585365853658537, "step": 1638}
{"time": 1767086247.497665, "phase": "train", "update": 1639, "total_env_steps": 5244800, "episode_reward": 0.16301636397838593, "value_loss": 0.016596993803977965, "policy_loss": -0.002239367946363302, "dist_entropy": 0.4235851764678955, "actor_grad_norm": 0.20210523903369904, "critic_grad_norm": 0.12724439799785614, "ratio": 0.9997892379760742, "entropy": 0.4235851764678955, "incre_win_rate": 0.375, "step": 1639}
{"time": 1767086252.4295893, "phase": "train", "update": 1640, "total_env_steps": 5248000, "episode_reward": 0.1936408281326294, "value_loss": 0.01547453012317419, "policy_loss": -0.001197561261858482, "dist_entropy": 0.4058890700340271, "actor_grad_norm": 0.19716058671474457, "critic_grad_norm": 0.099109947681427, "ratio": 0.9997910857200623, "entropy": 0.4058890700340271, "incre_win_rate": 0.5405405405405406, "step": 1640}
{"time": 1767086257.4269, "phase": "train", "update": 1641, "total_env_steps": 5251200, "episode_reward": 0.17956489324569702, "value_loss": 0.01586128454655409, "policy_loss": -0.0017652017335379356, "dist_entropy": 0.4246980011463165, "actor_grad_norm": 0.19246505200862885, "critic_grad_norm": 0.09862919896841049, "ratio": 0.9999886751174927, "entropy": 0.4246980011463165, "incre_win_rate": 0.43243243243243246, "step": 1641}
{"time": 1767086271.2073092, "phase": "eval", "update": 1641, "total_env_steps": 5251200, "eval_win_rate": 0.6875, "eval_episode_reward": 17.87448261589404, "step": 1641}
{"time": 1767086276.438772, "phase": "train", "update": 1642, "total_env_steps": 5254400, "episode_reward": 0.19040612876415253, "value_loss": 0.01619244646281004, "policy_loss": -0.0018228157952847822, "dist_entropy": 0.4287381708621979, "actor_grad_norm": 0.15565283596515656, "critic_grad_norm": 0.0852329283952713, "ratio": 1.0001705884933472, "entropy": 0.4287381708621979, "incre_win_rate": 0.4473684210526316, "step": 1642}
{"time": 1767086281.4873338, "phase": "train", "update": 1643, "total_env_steps": 5257600, "episode_reward": 0.19607046246528625, "value_loss": 0.01662266217172146, "policy_loss": -0.0014704018482007085, "dist_entropy": 0.42170698046684263, "actor_grad_norm": 0.14065255224704742, "critic_grad_norm": 0.0632074624300003, "ratio": 0.9998979568481445, "entropy": 0.42170698046684263, "incre_win_rate": 0.5405405405405406, "step": 1643}
{"time": 1767086286.4780798, "phase": "train", "update": 1644, "total_env_steps": 5260800, "episode_reward": 0.2223334163427353, "value_loss": 0.012343804910778999, "policy_loss": -0.0014286055487648496, "dist_entropy": 0.4100435495376587, "actor_grad_norm": 0.16763074696063995, "critic_grad_norm": 0.06428701430559158, "ratio": 0.9999915361404419, "entropy": 0.4100435495376587, "incre_win_rate": 0.575, "step": 1644}
{"time": 1767086291.5761664, "phase": "train", "update": 1645, "total_env_steps": 5264000, "episode_reward": 0.21259208023548126, "value_loss": 0.012408982962369919, "policy_loss": -0.0014302757749391048, "dist_entropy": 0.4015198707580566, "actor_grad_norm": 0.2798233926296234, "critic_grad_norm": 0.05460963398218155, "ratio": 0.9998977780342102, "entropy": 0.4015198707580566, "incre_win_rate": 0.575, "step": 1645}
{"time": 1767086296.575218, "phase": "train", "update": 1646, "total_env_steps": 5267200, "episode_reward": 0.20289164781570435, "value_loss": 0.014499596506357192, "policy_loss": -0.0012526373042334171, "dist_entropy": 0.4307975769042969, "actor_grad_norm": 0.23320774734020233, "critic_grad_norm": 0.056417208164930344, "ratio": 0.9999747276306152, "entropy": 0.4307975769042969, "incre_win_rate": 0.5135135135135135, "step": 1646}
{"time": 1767086301.6473868, "phase": "train", "update": 1647, "total_env_steps": 5270400, "episode_reward": 0.22596855461597443, "value_loss": 0.013891390897333622, "policy_loss": -0.0011018708419200606, "dist_entropy": 0.41175474524497985, "actor_grad_norm": 0.15721569955348969, "critic_grad_norm": 0.03759697452187538, "ratio": 1.000096321105957, "entropy": 0.41175474524497985, "incre_win_rate": 0.627906976744186, "step": 1647}
{"time": 1767086306.8820634, "phase": "train", "update": 1648, "total_env_steps": 5273600, "episode_reward": 0.2025129348039627, "value_loss": 0.01452961228787899, "policy_loss": -0.0017104054036561679, "dist_entropy": 0.4228522777557373, "actor_grad_norm": 0.18027997016906738, "critic_grad_norm": 0.02214900217950344, "ratio": 0.9998208284378052, "entropy": 0.4228522777557373, "incre_win_rate": 0.4358974358974359, "step": 1648}
{"time": 1767086311.9250085, "phase": "train", "update": 1649, "total_env_steps": 5276800, "episode_reward": 0.23390468955039978, "value_loss": 0.011289909109473228, "policy_loss": -0.0012507552021162383, "dist_entropy": 0.4100463926792145, "actor_grad_norm": 0.15289179980754852, "critic_grad_norm": 0.07986795157194138, "ratio": 0.9997162818908691, "entropy": 0.4100463926792145, "incre_win_rate": 0.7, "step": 1649}
{"time": 1767086316.9511473, "phase": "train", "update": 1650, "total_env_steps": 5280000, "episode_reward": 0.2271166294813156, "value_loss": 0.012720169872045517, "policy_loss": -0.0018717159694375597, "dist_entropy": 0.4016104221343994, "actor_grad_norm": 0.1619882583618164, "critic_grad_norm": 0.06611236929893494, "ratio": 1.0000442266464233, "entropy": 0.4016104221343994, "incre_win_rate": 0.5909090909090909, "step": 1650}
{"time": 1767086321.9769323, "phase": "train", "update": 1651, "total_env_steps": 5283200, "episode_reward": 0.22927461564540863, "value_loss": 0.012128377519547939, "policy_loss": -0.0014064492941697538, "dist_entropy": 0.39127888083457946, "actor_grad_norm": 0.17231547832489014, "critic_grad_norm": 0.05137581750750542, "ratio": 0.9999321103096008, "entropy": 0.39127888083457946, "incre_win_rate": 0.625, "step": 1651}
{"time": 1767086327.1063786, "phase": "train", "update": 1652, "total_env_steps": 5286400, "episode_reward": 0.23352181911468506, "value_loss": 0.014688925072550773, "policy_loss": -0.0018032460416819163, "dist_entropy": 0.3827506065368652, "actor_grad_norm": 0.17530874907970428, "critic_grad_norm": 0.06291896849870682, "ratio": 1.0002514123916626, "entropy": 0.3827506065368652, "incre_win_rate": 0.6829268292682927, "step": 1652}
{"time": 1767086332.278787, "phase": "train", "update": 1653, "total_env_steps": 5289600, "episode_reward": 0.22312965989112854, "value_loss": 0.013279994763433934, "policy_loss": -0.0011001118411352096, "dist_entropy": 0.369267064332962, "actor_grad_norm": 0.19156087934970856, "critic_grad_norm": 0.06112994626164436, "ratio": 0.9999117851257324, "entropy": 0.369267064332962, "incre_win_rate": 0.6341463414634146, "step": 1653}
{"time": 1767086337.4129465, "phase": "train", "update": 1654, "total_env_steps": 5292800, "episode_reward": 0.238289013504982, "value_loss": 0.01190638467669487, "policy_loss": -0.001486551669029268, "dist_entropy": 0.36768444776535036, "actor_grad_norm": 0.20228298008441925, "critic_grad_norm": 0.03920073062181473, "ratio": 0.9998995065689087, "entropy": 0.36768444776535036, "incre_win_rate": 0.7209302325581395, "step": 1654}
{"time": 1767086342.5019248, "phase": "train", "update": 1655, "total_env_steps": 5296000, "episode_reward": 0.21267591416835785, "value_loss": 0.014109509252011775, "policy_loss": -0.0015941161957258032, "dist_entropy": 0.38967888951301577, "actor_grad_norm": 0.16232867538928986, "critic_grad_norm": 0.03339953348040581, "ratio": 0.9998131990432739, "entropy": 0.38967888951301577, "incre_win_rate": 0.55, "step": 1655}
{"time": 1767086347.571908, "phase": "train", "update": 1656, "total_env_steps": 5299200, "episode_reward": 0.21430929005146027, "value_loss": 0.013310674577951431, "policy_loss": -0.0018089168709066073, "dist_entropy": 0.3951629936695099, "actor_grad_norm": 0.17141665518283844, "critic_grad_norm": 0.03419245034456253, "ratio": 0.9997334480285645, "entropy": 0.3951629936695099, "incre_win_rate": 0.5526315789473685, "step": 1656}
{"time": 1767086352.8271744, "phase": "train", "update": 1657, "total_env_steps": 5302400, "episode_reward": 0.20905371010303497, "value_loss": 0.012148854322731495, "policy_loss": -0.0013508665473700888, "dist_entropy": 0.40565656423568724, "actor_grad_norm": 0.1809851974248886, "critic_grad_norm": 0.05208580568432808, "ratio": 0.9999315142631531, "entropy": 0.40565656423568724, "incre_win_rate": 0.5526315789473685, "step": 1657}
{"time": 1767086357.9957297, "phase": "train", "update": 1658, "total_env_steps": 5305600, "episode_reward": 0.22996586561203003, "value_loss": 0.012586894072592258, "policy_loss": -0.0012918449529692566, "dist_entropy": 0.38516181111335757, "actor_grad_norm": 0.17888127267360687, "critic_grad_norm": 0.0422959178686142, "ratio": 0.9999409914016724, "entropy": 0.38516181111335757, "incre_win_rate": 0.5434782608695652, "step": 1658}
{"time": 1767086363.1575701, "phase": "train", "update": 1659, "total_env_steps": 5308800, "episode_reward": 0.19599288702011108, "value_loss": 0.013468981347978115, "policy_loss": -0.0018647710210146328, "dist_entropy": 0.40300853848457335, "actor_grad_norm": 0.14463911950588226, "critic_grad_norm": 0.03519582375884056, "ratio": 0.999870777130127, "entropy": 0.40300853848457335, "incre_win_rate": 0.5294117647058824, "step": 1659}
{"time": 1767086368.2803302, "phase": "train", "update": 1660, "total_env_steps": 5312000, "episode_reward": 0.22543150186538696, "value_loss": 0.015510322712361812, "policy_loss": -0.0013176633909143475, "dist_entropy": 0.39067875742912295, "actor_grad_norm": 0.17623692750930786, "critic_grad_norm": 0.037572819739580154, "ratio": 0.9998455047607422, "entropy": 0.39067875742912295, "incre_win_rate": 0.6190476190476191, "step": 1660}
{"time": 1767086373.479824, "phase": "train", "update": 1661, "total_env_steps": 5315200, "episode_reward": 0.19280733168125153, "value_loss": 0.01868494488298893, "policy_loss": -0.0014812448973046343, "dist_entropy": 0.4173793852329254, "actor_grad_norm": 0.2544815242290497, "critic_grad_norm": 0.09081395715475082, "ratio": 0.999666154384613, "entropy": 0.4173793852329254, "incre_win_rate": 0.2926829268292683, "step": 1661}
{"time": 1767086386.4006166, "phase": "eval", "update": 1661, "total_env_steps": 5315200, "eval_win_rate": 0.71875, "eval_episode_reward": 18.242963576158942, "step": 1661}
{"time": 1767086391.5422564, "phase": "train", "update": 1662, "total_env_steps": 5318400, "episode_reward": 0.22835007309913635, "value_loss": 0.013038569316267967, "policy_loss": -0.001171572719917613, "dist_entropy": 0.3923789858818054, "actor_grad_norm": 0.15535080432891846, "critic_grad_norm": 0.07998166233301163, "ratio": 0.9998716711997986, "entropy": 0.3923789858818054, "incre_win_rate": 0.6097560975609756, "step": 1662}
{"time": 1767086396.6617837, "phase": "train", "update": 1663, "total_env_steps": 5321600, "episode_reward": 0.22257763147354126, "value_loss": 0.01292591355741024, "policy_loss": -0.001551406950553158, "dist_entropy": 0.38710842132568357, "actor_grad_norm": 0.16255933046340942, "critic_grad_norm": 0.08304988592863083, "ratio": 0.9999042749404907, "entropy": 0.38710842132568357, "incre_win_rate": 0.5348837209302325, "step": 1663}
{"time": 1767086401.7501884, "phase": "train", "update": 1664, "total_env_steps": 5324800, "episode_reward": 0.21200384199619293, "value_loss": 0.013109338097274303, "policy_loss": -0.0014729414322481205, "dist_entropy": 0.3820571303367615, "actor_grad_norm": 0.16508808732032776, "critic_grad_norm": 0.06373097747564316, "ratio": 0.9999505877494812, "entropy": 0.3820571303367615, "incre_win_rate": 0.475, "step": 1664}
{"time": 1767086406.8354654, "phase": "train", "update": 1665, "total_env_steps": 5328000, "episode_reward": 0.23559965193271637, "value_loss": 0.011351752281188964, "policy_loss": -0.0016061893918486447, "dist_entropy": 0.393815416097641, "actor_grad_norm": 0.1271180957555771, "critic_grad_norm": 0.06387706845998764, "ratio": 0.9998407363891602, "entropy": 0.393815416097641, "incre_win_rate": 0.65, "step": 1665}
{"time": 1767086411.9944105, "phase": "train", "update": 1666, "total_env_steps": 5331200, "episode_reward": 0.23410287499427795, "value_loss": 0.012552314810454846, "policy_loss": -0.0010864901333420107, "dist_entropy": 0.37752109169960024, "actor_grad_norm": 0.12925861775875092, "critic_grad_norm": 0.052143633365631104, "ratio": 1.0001097917556763, "entropy": 0.37752109169960024, "incre_win_rate": 0.6744186046511628, "step": 1666}
{"time": 1767086417.1927934, "phase": "train", "update": 1667, "total_env_steps": 5334400, "episode_reward": 0.2379465103149414, "value_loss": 0.008818223513662815, "policy_loss": -0.0008775526126385102, "dist_entropy": 0.3823684871196747, "actor_grad_norm": 0.10016258805990219, "critic_grad_norm": 0.03911703824996948, "ratio": 0.999852180480957, "entropy": 0.3823684871196747, "incre_win_rate": 0.7073170731707317, "step": 1667}
{"time": 1767086422.657335, "phase": "train", "update": 1668, "total_env_steps": 5337600, "episode_reward": 0.2253994196653366, "value_loss": 0.01239247489720583, "policy_loss": -0.001386930490666316, "dist_entropy": 0.3558910548686981, "actor_grad_norm": 0.15963898599147797, "critic_grad_norm": 0.035653211176395416, "ratio": 1.0001459121704102, "entropy": 0.3558910548686981, "incre_win_rate": 0.5581395348837209, "step": 1668}
{"time": 1767086427.8483071, "phase": "train", "update": 1669, "total_env_steps": 5340800, "episode_reward": 0.2179827094078064, "value_loss": 0.012991552241146564, "policy_loss": -0.0014228886625687665, "dist_entropy": 0.3747082591056824, "actor_grad_norm": 0.22140827775001526, "critic_grad_norm": 0.05059032514691353, "ratio": 0.9999814033508301, "entropy": 0.3747082591056824, "incre_win_rate": 0.575, "step": 1669}
{"time": 1767086432.514477, "phase": "train", "update": 1670, "total_env_steps": 5344000, "episode_reward": 0.2263193577528, "value_loss": 0.012470727413892746, "policy_loss": -0.0011469720377604632, "dist_entropy": 0.3611011266708374, "actor_grad_norm": 0.20366337895393372, "critic_grad_norm": 0.05492408946156502, "ratio": 0.9999677538871765, "entropy": 0.3611011266708374, "incre_win_rate": 0.7073170731707317, "step": 1670}
{"time": 1767086437.429222, "phase": "train", "update": 1671, "total_env_steps": 5347200, "episode_reward": 0.23109479248523712, "value_loss": 0.012490549683570861, "policy_loss": -0.0009118885971666657, "dist_entropy": 0.3724709928035736, "actor_grad_norm": 0.25665056705474854, "critic_grad_norm": 0.05636253580451012, "ratio": 1.0000988245010376, "entropy": 0.3724709928035736, "incre_win_rate": 0.65, "step": 1671}
{"time": 1767086442.3178098, "phase": "train", "update": 1672, "total_env_steps": 5350400, "episode_reward": 0.23829728364944458, "value_loss": 0.012913343124091625, "policy_loss": -0.0012440989248609924, "dist_entropy": 0.3603089272975922, "actor_grad_norm": 0.2041589319705963, "critic_grad_norm": 0.07054915279150009, "ratio": 1.0000728368759155, "entropy": 0.3603089272975922, "incre_win_rate": 0.6744186046511628, "step": 1672}
{"time": 1767086447.0351045, "phase": "train", "update": 1673, "total_env_steps": 5353600, "episode_reward": 0.22742964327335358, "value_loss": 0.011901133693754673, "policy_loss": -0.0014013363319264726, "dist_entropy": 0.3682373344898224, "actor_grad_norm": 0.14532887935638428, "critic_grad_norm": 0.061217453330755234, "ratio": 0.999952495098114, "entropy": 0.3682373344898224, "incre_win_rate": 0.5476190476190477, "step": 1673}
{"time": 1767086451.863206, "phase": "train", "update": 1674, "total_env_steps": 5356800, "episode_reward": 0.23289424180984497, "value_loss": 0.01089217159897089, "policy_loss": -0.001387812030590929, "dist_entropy": 0.37058966755867007, "actor_grad_norm": 0.14504681527614594, "critic_grad_norm": 0.038937464356422424, "ratio": 0.9998897910118103, "entropy": 0.37058966755867007, "incre_win_rate": 0.6585365853658537, "step": 1674}
{"time": 1767086456.710291, "phase": "train", "update": 1675, "total_env_steps": 5360000, "episode_reward": 0.24359014630317688, "value_loss": 0.010774938203394414, "policy_loss": -0.0011371148571441836, "dist_entropy": 0.35629029870033263, "actor_grad_norm": 0.11255889385938644, "critic_grad_norm": 0.03328273817896843, "ratio": 1.0001813173294067, "entropy": 0.35629029870033263, "incre_win_rate": 0.7209302325581395, "step": 1675}
{"time": 1767086461.5104957, "phase": "train", "update": 1676, "total_env_steps": 5363200, "episode_reward": 0.23790046572685242, "value_loss": 0.013352504558861255, "policy_loss": -0.001214326162994439, "dist_entropy": 0.37540363073349, "actor_grad_norm": 0.13885575532913208, "critic_grad_norm": 0.04259413108229637, "ratio": 0.9999551773071289, "entropy": 0.37540363073349, "incre_win_rate": 0.7380952380952381, "step": 1676}
{"time": 1767086466.4267359, "phase": "train", "update": 1677, "total_env_steps": 5366400, "episode_reward": 0.23174980282783508, "value_loss": 0.013277539052069187, "policy_loss": -0.0011253305830408067, "dist_entropy": 0.38279326558113097, "actor_grad_norm": 0.1079334020614624, "critic_grad_norm": 0.06469803303480148, "ratio": 1.0001333951950073, "entropy": 0.38279326558113097, "incre_win_rate": 0.7, "step": 1677}
{"time": 1767086471.1572974, "phase": "train", "update": 1678, "total_env_steps": 5369600, "episode_reward": 0.23636797070503235, "value_loss": 0.01602395996451378, "policy_loss": -0.0012962046158005336, "dist_entropy": 0.36708056926727295, "actor_grad_norm": 0.18035559356212616, "critic_grad_norm": 0.0493771918118, "ratio": 0.9999774098396301, "entropy": 0.36708056926727295, "incre_win_rate": 0.6590909090909091, "step": 1678}
{"time": 1767086475.9647973, "phase": "train", "update": 1679, "total_env_steps": 5372800, "episode_reward": 0.23817209899425507, "value_loss": 0.011685992777347564, "policy_loss": -0.0012684771186002308, "dist_entropy": 0.37616944313049316, "actor_grad_norm": 0.123365119099617, "critic_grad_norm": 0.05330779775977135, "ratio": 0.9999774098396301, "entropy": 0.37616944313049316, "incre_win_rate": 0.6904761904761905, "step": 1679}
{"time": 1767086481.0182328, "phase": "train", "update": 1680, "total_env_steps": 5376000, "episode_reward": 0.22949503362178802, "value_loss": 0.011734702624380589, "policy_loss": -0.0013523144625224859, "dist_entropy": 0.3848246097564697, "actor_grad_norm": 0.13751447200775146, "critic_grad_norm": 0.049966391175985336, "ratio": 1.0000635385513306, "entropy": 0.3848246097564697, "incre_win_rate": 0.6666666666666666, "step": 1680}
{"time": 1767086486.0512714, "phase": "train", "update": 1681, "total_env_steps": 5379200, "episode_reward": 0.24252896010875702, "value_loss": 0.014144685305655002, "policy_loss": -0.0008503858632693095, "dist_entropy": 0.3698764979839325, "actor_grad_norm": 0.10253969579935074, "critic_grad_norm": 0.03231079503893852, "ratio": 0.9998758435249329, "entropy": 0.3698764979839325, "incre_win_rate": 0.6428571428571429, "step": 1681}
{"time": 1767086498.8265803, "phase": "eval", "update": 1681, "total_env_steps": 5379200, "eval_win_rate": 0.875, "eval_episode_reward": 19.258743791390728, "step": 1681}
{"time": 1767086503.9508462, "phase": "train", "update": 1682, "total_env_steps": 5382400, "episode_reward": 0.2456643134355545, "value_loss": 0.012122653797268868, "policy_loss": -0.0012621700891729316, "dist_entropy": 0.3759526669979095, "actor_grad_norm": 0.11267759650945663, "critic_grad_norm": 0.03320752829313278, "ratio": 0.9996947646141052, "entropy": 0.3759526669979095, "incre_win_rate": 0.7727272727272727, "step": 1682}
{"time": 1767086509.312313, "phase": "train", "update": 1683, "total_env_steps": 5385600, "episode_reward": 0.22521264851093292, "value_loss": 0.012343204580247402, "policy_loss": -0.0009960230607092059, "dist_entropy": 0.3841470003128052, "actor_grad_norm": 0.20597732067108154, "critic_grad_norm": 0.04699741303920746, "ratio": 1.0001431703567505, "entropy": 0.3841470003128052, "incre_win_rate": 0.625, "step": 1683}
{"time": 1767086515.1175513, "phase": "train", "update": 1684, "total_env_steps": 5388800, "episode_reward": 0.2288498431444168, "value_loss": 0.010252887196838856, "policy_loss": -0.0011230680148571538, "dist_entropy": 0.37498701810836793, "actor_grad_norm": 0.20695248246192932, "critic_grad_norm": 0.03599968180060387, "ratio": 0.9998649954795837, "entropy": 0.37498701810836793, "incre_win_rate": 0.65, "step": 1684}
{"time": 1767086520.5446498, "phase": "train", "update": 1685, "total_env_steps": 5392000, "episode_reward": 0.202403262257576, "value_loss": 0.0157156178727746, "policy_loss": -0.0013444253062772304, "dist_entropy": 0.37432735562324526, "actor_grad_norm": 0.28516697883605957, "critic_grad_norm": 0.08623651415109634, "ratio": 0.9998525977134705, "entropy": 0.37432735562324526, "incre_win_rate": 0.425, "step": 1685}
{"time": 1767086526.1298492, "phase": "train", "update": 1686, "total_env_steps": 5395200, "episode_reward": 0.24586248397827148, "value_loss": 0.011527635902166367, "policy_loss": -0.0013523539376656402, "dist_entropy": 0.35665915012359617, "actor_grad_norm": 0.1491556465625763, "critic_grad_norm": 0.1142628937959671, "ratio": 0.9997660517692566, "entropy": 0.35665915012359617, "incre_win_rate": 0.7619047619047619, "step": 1686}
{"time": 1767086530.9817781, "phase": "train", "update": 1687, "total_env_steps": 5398400, "episode_reward": 0.2241344004869461, "value_loss": 0.010972505807876587, "policy_loss": -0.0012817938080239345, "dist_entropy": 0.3670982837677002, "actor_grad_norm": 0.17692148685455322, "critic_grad_norm": 0.06610748171806335, "ratio": 1.0002069473266602, "entropy": 0.3670982837677002, "incre_win_rate": 0.6341463414634146, "step": 1687}
{"time": 1767086535.9553483, "phase": "train", "update": 1688, "total_env_steps": 5401600, "episode_reward": 0.23635245859622955, "value_loss": 0.011205654218792915, "policy_loss": -0.0009192863866147149, "dist_entropy": 0.36398341655731203, "actor_grad_norm": 0.2759493291378021, "critic_grad_norm": 0.03998064994812012, "ratio": 1.0000267028808594, "entropy": 0.36398341655731203, "incre_win_rate": 0.725, "step": 1688}
{"time": 1767086540.7460558, "phase": "train", "update": 1689, "total_env_steps": 5404800, "episode_reward": 0.21418046951293945, "value_loss": 0.015523600950837135, "policy_loss": -0.0006972901541431042, "dist_entropy": 0.3632041931152344, "actor_grad_norm": 0.254355788230896, "critic_grad_norm": 0.0794493779540062, "ratio": 0.9997896552085876, "entropy": 0.3632041931152344, "incre_win_rate": 0.5365853658536586, "step": 1689}
{"time": 1767086545.6239874, "phase": "train", "update": 1690, "total_env_steps": 5408000, "episode_reward": 0.22594837844371796, "value_loss": 0.011113721504807472, "policy_loss": -0.001195389873695074, "dist_entropy": 0.37004727125167847, "actor_grad_norm": 0.18425719439983368, "critic_grad_norm": 0.07632031291723251, "ratio": 0.99996417760849, "entropy": 0.37004727125167847, "incre_win_rate": 0.6341463414634146, "step": 1690}
{"time": 1767086550.4186125, "phase": "train", "update": 1691, "total_env_steps": 5411200, "episode_reward": 0.23889745771884918, "value_loss": 0.011130669713020324, "policy_loss": -0.0014531574820598081, "dist_entropy": 0.3730969488620758, "actor_grad_norm": 0.20444528758525848, "critic_grad_norm": 0.03281135484576225, "ratio": 0.9998510479927063, "entropy": 0.3730969488620758, "incre_win_rate": 0.6666666666666666, "step": 1691}
{"time": 1767086555.4750679, "phase": "train", "update": 1692, "total_env_steps": 5414400, "episode_reward": 0.252826988697052, "value_loss": 0.008837194927036763, "policy_loss": -0.0012306906232325333, "dist_entropy": 0.370898699760437, "actor_grad_norm": 0.19332508742809296, "critic_grad_norm": 0.03461023420095444, "ratio": 1.0000730752944946, "entropy": 0.370898699760437, "incre_win_rate": 0.8, "step": 1692}
{"time": 1767086560.7410984, "phase": "train", "update": 1693, "total_env_steps": 5417600, "episode_reward": 0.21434293687343597, "value_loss": 0.011587262898683549, "policy_loss": -0.001199789122809447, "dist_entropy": 0.3781903743743896, "actor_grad_norm": 0.17667679488658905, "critic_grad_norm": 0.03371215984225273, "ratio": 0.9998264312744141, "entropy": 0.3781903743743896, "incre_win_rate": 0.5945945945945946, "step": 1693}
{"time": 1767086566.0009003, "phase": "train", "update": 1694, "total_env_steps": 5420800, "episode_reward": 0.24799099564552307, "value_loss": 0.007170051522552967, "policy_loss": -0.0014371220830227572, "dist_entropy": 0.3749115288257599, "actor_grad_norm": 0.19263790547847748, "critic_grad_norm": 0.05608340725302696, "ratio": 1.000203013420105, "entropy": 0.3749115288257599, "incre_win_rate": 0.7906976744186046, "step": 1694}
{"time": 1767086570.8640406, "phase": "train", "update": 1695, "total_env_steps": 5424000, "episode_reward": 0.22646473348140717, "value_loss": 0.011393188312649728, "policy_loss": -0.0013929098429265707, "dist_entropy": 0.3871515393257141, "actor_grad_norm": 0.19021622836589813, "critic_grad_norm": 0.04825662449002266, "ratio": 0.9999201893806458, "entropy": 0.3871515393257141, "incre_win_rate": 0.625, "step": 1695}
{"time": 1767086575.7765899, "phase": "train", "update": 1696, "total_env_steps": 5427200, "episode_reward": 0.23835523426532745, "value_loss": 0.011033301427960395, "policy_loss": -0.001399431626278158, "dist_entropy": 0.37924466133117674, "actor_grad_norm": 0.13375796377658844, "critic_grad_norm": 0.040541525930166245, "ratio": 1.0000476837158203, "entropy": 0.37924466133117674, "incre_win_rate": 0.7073170731707317, "step": 1696}
{"time": 1767086580.6632307, "phase": "train", "update": 1697, "total_env_steps": 5430400, "episode_reward": 0.21794183552265167, "value_loss": 0.014033510908484459, "policy_loss": -0.0014592360953976425, "dist_entropy": 0.38958340883255005, "actor_grad_norm": 0.1830119788646698, "critic_grad_norm": 0.08254075050354004, "ratio": 0.9995711445808411, "entropy": 0.38958340883255005, "incre_win_rate": 0.6153846153846154, "step": 1697}
{"time": 1767086585.491403, "phase": "train", "update": 1698, "total_env_steps": 5433600, "episode_reward": 0.2390713095664978, "value_loss": 0.011675718054175378, "policy_loss": -0.0013174674663744667, "dist_entropy": 0.3796704292297363, "actor_grad_norm": 0.12476664036512375, "critic_grad_norm": 0.06857078522443771, "ratio": 0.9998499751091003, "entropy": 0.3796704292297363, "incre_win_rate": 0.8, "step": 1698}
{"time": 1767086590.3968353, "phase": "train", "update": 1699, "total_env_steps": 5436800, "episode_reward": 0.19825538992881775, "value_loss": 0.01402781680226326, "policy_loss": -0.001760989360739984, "dist_entropy": 0.39333018064498904, "actor_grad_norm": 0.12195909023284912, "critic_grad_norm": 0.10085824877023697, "ratio": 0.9997788667678833, "entropy": 0.39333018064498904, "incre_win_rate": 0.5263157894736842, "step": 1699}
{"time": 1767086595.374978, "phase": "train", "update": 1700, "total_env_steps": 5440000, "episode_reward": 0.22729097306728363, "value_loss": 0.01408094186335802, "policy_loss": -0.0016310799841370738, "dist_entropy": 0.374830961227417, "actor_grad_norm": 0.16421611607074738, "critic_grad_norm": 0.09279117733240128, "ratio": 0.9994902610778809, "entropy": 0.374830961227417, "incre_win_rate": 0.5952380952380952, "step": 1700}
{"time": 1767086600.2345648, "phase": "train", "update": 1701, "total_env_steps": 5443200, "episode_reward": 0.20456694066524506, "value_loss": 0.013839863240718842, "policy_loss": -0.0018429195314816128, "dist_entropy": 0.36723363399505615, "actor_grad_norm": 0.1388193815946579, "critic_grad_norm": 0.08910437673330307, "ratio": 0.9996599555015564, "entropy": 0.36723363399505615, "incre_win_rate": 0.38095238095238093, "step": 1701}
{"time": 1767086612.9176996, "phase": "eval", "update": 1701, "total_env_steps": 5443200, "eval_win_rate": 0.625, "eval_episode_reward": 17.31948468543046, "step": 1701}
{"time": 1767086618.2332056, "phase": "train", "update": 1702, "total_env_steps": 5446400, "episode_reward": 0.22688741981983185, "value_loss": 0.014266099594533444, "policy_loss": -0.0016491508319271375, "dist_entropy": 0.35482171177864075, "actor_grad_norm": 0.20859642326831818, "critic_grad_norm": 0.05820968374609947, "ratio": 0.999960720539093, "entropy": 0.35482171177864075, "incre_win_rate": 0.47619047619047616, "step": 1702}
{"time": 1767086623.6861084, "phase": "train", "update": 1703, "total_env_steps": 5449600, "episode_reward": 0.2198209911584854, "value_loss": 0.016265738382935525, "policy_loss": -0.0014676326802614882, "dist_entropy": 0.37015907764434813, "actor_grad_norm": 0.1404341757297516, "critic_grad_norm": 0.043824490159749985, "ratio": 1.00025475025177, "entropy": 0.37015907764434813, "incre_win_rate": 0.6, "step": 1703}
{"time": 1767086629.4503787, "phase": "train", "update": 1704, "total_env_steps": 5452800, "episode_reward": 0.23574092984199524, "value_loss": 0.010589897073805333, "policy_loss": -0.0011010130119515793, "dist_entropy": 0.3572841823101044, "actor_grad_norm": 0.13053016364574432, "critic_grad_norm": 0.11131326109170914, "ratio": 0.9999467730522156, "entropy": 0.3572841823101044, "incre_win_rate": 0.7317073170731707, "step": 1704}
{"time": 1767086634.92386, "phase": "train", "update": 1705, "total_env_steps": 5456000, "episode_reward": 0.23380431532859802, "value_loss": 0.00875218454748392, "policy_loss": -0.0012481919904860916, "dist_entropy": 0.3497658967971802, "actor_grad_norm": 0.12139154970645905, "critic_grad_norm": 0.09252671897411346, "ratio": 0.9997305274009705, "entropy": 0.3497658967971802, "incre_win_rate": 0.7380952380952381, "step": 1705}
{"time": 1767086640.3825815, "phase": "train", "update": 1706, "total_env_steps": 5459200, "episode_reward": 0.21983341872692108, "value_loss": 0.012427126988768578, "policy_loss": -0.0014686691207391079, "dist_entropy": 0.3527803361415863, "actor_grad_norm": 0.16226951777935028, "critic_grad_norm": 0.07244931906461716, "ratio": 0.9996113181114197, "entropy": 0.3527803361415863, "incre_win_rate": 0.5526315789473685, "step": 1706}
{"time": 1767086645.6402407, "phase": "train", "update": 1707, "total_env_steps": 5462400, "episode_reward": 0.22930514812469482, "value_loss": 0.010620624199509621, "policy_loss": -0.001352978736064614, "dist_entropy": 0.3586024880409241, "actor_grad_norm": 0.20114319026470184, "critic_grad_norm": 0.062407124787569046, "ratio": 0.999917209148407, "entropy": 0.3586024880409241, "incre_win_rate": 0.627906976744186, "step": 1707}
{"time": 1767086651.4591804, "phase": "train", "update": 1708, "total_env_steps": 5465600, "episode_reward": 0.24520593881607056, "value_loss": 0.012108330056071282, "policy_loss": -0.0013182054334578198, "dist_entropy": 0.34951965808868407, "actor_grad_norm": 0.16783231496810913, "critic_grad_norm": 0.08315384387969971, "ratio": 1.0000065565109253, "entropy": 0.34951965808868407, "incre_win_rate": 0.7142857142857143, "step": 1708}
{"time": 1767086657.2656593, "phase": "train", "update": 1709, "total_env_steps": 5468800, "episode_reward": 0.23346233367919922, "value_loss": 0.009627512656152248, "policy_loss": -0.001524441894432016, "dist_entropy": 0.3580788791179657, "actor_grad_norm": 0.16406050324440002, "critic_grad_norm": 0.07232438772916794, "ratio": 1.0001252889633179, "entropy": 0.3580788791179657, "incre_win_rate": 0.7209302325581395, "step": 1709}
{"time": 1767086662.8326793, "phase": "train", "update": 1710, "total_env_steps": 5472000, "episode_reward": 0.21313638985157013, "value_loss": 0.01249985545873642, "policy_loss": -0.0012037998447212317, "dist_entropy": 0.38432961106300356, "actor_grad_norm": 0.13958023488521576, "critic_grad_norm": 0.02852967381477356, "ratio": 0.9996514320373535, "entropy": 0.38432961106300356, "incre_win_rate": 0.6176470588235294, "step": 1710}
{"time": 1767086668.3129113, "phase": "train", "update": 1711, "total_env_steps": 5475200, "episode_reward": 0.23097577691078186, "value_loss": 0.011272422783076764, "policy_loss": -0.0012175984939061025, "dist_entropy": 0.36563323736190795, "actor_grad_norm": 0.14177577197551727, "critic_grad_norm": 0.05924122408032417, "ratio": 0.9999098777770996, "entropy": 0.36563323736190795, "incre_win_rate": 0.5869565217391305, "step": 1711}
{"time": 1767086673.505478, "phase": "train", "update": 1712, "total_env_steps": 5478400, "episode_reward": 0.20444278419017792, "value_loss": 0.016607294231653212, "policy_loss": -0.0015319009332120715, "dist_entropy": 0.3593395292758942, "actor_grad_norm": 0.1015155240893364, "critic_grad_norm": 0.09838929772377014, "ratio": 0.9998161196708679, "entropy": 0.3593395292758942, "incre_win_rate": 0.41025641025641024, "step": 1712}
{"time": 1767086679.2591517, "phase": "train", "update": 1713, "total_env_steps": 5481600, "episode_reward": 0.2293061763048172, "value_loss": 0.01216028481721878, "policy_loss": -0.0010454257597672268, "dist_entropy": 0.358459609746933, "actor_grad_norm": 0.10180791467428207, "critic_grad_norm": 0.07718700170516968, "ratio": 0.9997314810752869, "entropy": 0.358459609746933, "incre_win_rate": 0.5238095238095238, "step": 1713}
{"time": 1767086685.0443249, "phase": "train", "update": 1714, "total_env_steps": 5484800, "episode_reward": 0.23030267655849457, "value_loss": 0.014362165331840515, "policy_loss": -0.0019098275795474962, "dist_entropy": 0.3565716028213501, "actor_grad_norm": 0.12660805881023407, "critic_grad_norm": 0.0442473404109478, "ratio": 0.9995999336242676, "entropy": 0.3565716028213501, "incre_win_rate": 0.5581395348837209, "step": 1714}
{"time": 1767086690.7552493, "phase": "train", "update": 1715, "total_env_steps": 5488000, "episode_reward": 0.22082316875457764, "value_loss": 0.009573645889759064, "policy_loss": -0.0017134607691957626, "dist_entropy": 0.3747976243495941, "actor_grad_norm": 0.13666853308677673, "critic_grad_norm": 0.06453818827867508, "ratio": 0.9999377131462097, "entropy": 0.3747976243495941, "incre_win_rate": 0.5789473684210527, "step": 1715}
{"time": 1767086696.7687862, "phase": "train", "update": 1716, "total_env_steps": 5491200, "episode_reward": 0.2295297086238861, "value_loss": 0.012549258954823016, "policy_loss": -0.001372555576868706, "dist_entropy": 0.3662058234214783, "actor_grad_norm": 0.1478317826986313, "critic_grad_norm": 0.05129249766469002, "ratio": 0.9998049736022949, "entropy": 0.3662058234214783, "incre_win_rate": 0.6590909090909091, "step": 1716}
{"time": 1767086702.397984, "phase": "train", "update": 1717, "total_env_steps": 5494400, "episode_reward": 0.21184344589710236, "value_loss": 0.012020662985742092, "policy_loss": -0.0012605668566237683, "dist_entropy": 0.3647651195526123, "actor_grad_norm": 0.1618882417678833, "critic_grad_norm": 0.0422041229903698, "ratio": 0.999958336353302, "entropy": 0.3647651195526123, "incre_win_rate": 0.5675675675675675, "step": 1717}
{"time": 1767086708.2230797, "phase": "train", "update": 1718, "total_env_steps": 5497600, "episode_reward": 0.20413494110107422, "value_loss": 0.01145179122686386, "policy_loss": -0.001527302596011282, "dist_entropy": 0.37682871222496034, "actor_grad_norm": 0.18644414842128754, "critic_grad_norm": 0.03959627076983452, "ratio": 1.0001087188720703, "entropy": 0.37682871222496034, "incre_win_rate": 0.6216216216216216, "step": 1718}
{"time": 1767086715.5505185, "phase": "train", "update": 1719, "total_env_steps": 5500800, "episode_reward": 0.22852183878421783, "value_loss": 0.010750165581703186, "policy_loss": -0.0016418255194551533, "dist_entropy": 0.36532986760139463, "actor_grad_norm": 0.15903165936470032, "critic_grad_norm": 0.04274139925837517, "ratio": 0.9998456835746765, "entropy": 0.36532986760139463, "incre_win_rate": 0.6097560975609756, "step": 1719}
{"time": 1767086720.8288822, "phase": "train", "update": 1720, "total_env_steps": 5504000, "episode_reward": 0.205967515707016, "value_loss": 0.01253910530358553, "policy_loss": -0.0017903747067727239, "dist_entropy": 0.3712909877300262, "actor_grad_norm": 0.19798289239406586, "critic_grad_norm": 0.02888990379869938, "ratio": 1.000036597251892, "entropy": 0.3712909877300262, "incre_win_rate": 0.4864864864864865, "step": 1720}
{"time": 1767086726.661285, "phase": "train", "update": 1721, "total_env_steps": 5507200, "episode_reward": 0.21719889342784882, "value_loss": 0.010280411131680012, "policy_loss": -0.0011147801796827395, "dist_entropy": 0.37706193923950193, "actor_grad_norm": 0.20324085652828217, "critic_grad_norm": 0.04244716838002205, "ratio": 1.0000920295715332, "entropy": 0.37706193923950193, "incre_win_rate": 0.575, "step": 1721}
{"time": 1767086741.1226912, "phase": "eval", "update": 1721, "total_env_steps": 5507200, "eval_win_rate": 0.84375, "eval_episode_reward": 19.15019660596026, "step": 1721}
{"time": 1767086746.4725842, "phase": "train", "update": 1722, "total_env_steps": 5510400, "episode_reward": 0.24313585460186005, "value_loss": 0.008058066852390766, "policy_loss": -0.0014174077189075263, "dist_entropy": 0.3599650740623474, "actor_grad_norm": 0.15473459661006927, "critic_grad_norm": 0.037337776273489, "ratio": 0.9998499155044556, "entropy": 0.3599650740623474, "incre_win_rate": 0.6976744186046512, "step": 1722}
{"time": 1767086751.8112152, "phase": "train", "update": 1723, "total_env_steps": 5513600, "episode_reward": 0.24240118265151978, "value_loss": 0.011014064773917198, "policy_loss": -0.0014989839887235234, "dist_entropy": 0.3758008241653442, "actor_grad_norm": 0.21261513233184814, "critic_grad_norm": 0.035728227347135544, "ratio": 0.9996600151062012, "entropy": 0.3758008241653442, "incre_win_rate": 0.6590909090909091, "step": 1723}
{"time": 1767086756.9190633, "phase": "train", "update": 1724, "total_env_steps": 5516800, "episode_reward": 0.22192984819412231, "value_loss": 0.013288541324436664, "policy_loss": -0.0012876552834605094, "dist_entropy": 0.3506656467914581, "actor_grad_norm": 0.16247272491455078, "critic_grad_norm": 0.04141107201576233, "ratio": 1.0000427961349487, "entropy": 0.3506656467914581, "incre_win_rate": 0.5897435897435898, "step": 1724}
{"time": 1767086762.5257902, "phase": "train", "update": 1725, "total_env_steps": 5520000, "episode_reward": 0.23387470841407776, "value_loss": 0.016194031573832035, "policy_loss": -0.0010070269280468835, "dist_entropy": 0.33726897835731506, "actor_grad_norm": 0.11173143237829208, "critic_grad_norm": 0.06426361948251724, "ratio": 0.9999052882194519, "entropy": 0.33726897835731506, "incre_win_rate": 0.46808510638297873, "step": 1725}
{"time": 1767086769.0586355, "phase": "train", "update": 1726, "total_env_steps": 5523200, "episode_reward": 0.22002588212490082, "value_loss": 0.014772249571979045, "policy_loss": -0.0013935985699518483, "dist_entropy": 0.35803688764572145, "actor_grad_norm": 0.13130724430084229, "critic_grad_norm": 0.040672626346349716, "ratio": 0.9998065829277039, "entropy": 0.35803688764572145, "incre_win_rate": 0.5641025641025641, "step": 1726}
{"time": 1767086774.460603, "phase": "train", "update": 1727, "total_env_steps": 5526400, "episode_reward": 0.22542685270309448, "value_loss": 0.01478641089051962, "policy_loss": -0.001121795375326684, "dist_entropy": 0.34217589497566225, "actor_grad_norm": 0.19085168838500977, "critic_grad_norm": 0.04531192407011986, "ratio": 0.9997960329055786, "entropy": 0.34217589497566225, "incre_win_rate": 0.6046511627906976, "step": 1727}
{"time": 1767086780.003434, "phase": "train", "update": 1728, "total_env_steps": 5529600, "episode_reward": 0.22068554162979126, "value_loss": 0.012379833124577999, "policy_loss": -0.0014023413927795048, "dist_entropy": 0.35679410099983216, "actor_grad_norm": 0.16022658348083496, "critic_grad_norm": 0.0830913707613945, "ratio": 0.9998652338981628, "entropy": 0.35679410099983216, "incre_win_rate": 0.6153846153846154, "step": 1728}
{"time": 1767086785.2715282, "phase": "train", "update": 1729, "total_env_steps": 5532800, "episode_reward": 0.20603375136852264, "value_loss": 0.01355674136430025, "policy_loss": -0.00165542630397848, "dist_entropy": 0.3648982882499695, "actor_grad_norm": 0.24543733894824982, "critic_grad_norm": 0.05288686975836754, "ratio": 0.9997977614402771, "entropy": 0.3648982882499695, "incre_win_rate": 0.5384615384615384, "step": 1729}
{"time": 1767086790.4790351, "phase": "train", "update": 1730, "total_env_steps": 5536000, "episode_reward": 0.22302567958831787, "value_loss": 0.014666581898927689, "policy_loss": -0.000870780182293629, "dist_entropy": 0.3498415112495422, "actor_grad_norm": 0.19958476722240448, "critic_grad_norm": 0.03873801231384277, "ratio": 1.0002011060714722, "entropy": 0.3498415112495422, "incre_win_rate": 0.5853658536585366, "step": 1730}
{"time": 1767086795.8058887, "phase": "train", "update": 1731, "total_env_steps": 5539200, "episode_reward": 0.2193382829427719, "value_loss": 0.012320850230753421, "policy_loss": -0.0014519260528693678, "dist_entropy": 0.373491495847702, "actor_grad_norm": 0.1322939246892929, "critic_grad_norm": 0.04103539139032364, "ratio": 1.0000516176223755, "entropy": 0.373491495847702, "incre_win_rate": 0.6052631578947368, "step": 1731}
{"time": 1767086800.7393782, "phase": "train", "update": 1732, "total_env_steps": 5542400, "episode_reward": 0.21510761976242065, "value_loss": 0.013064856268465519, "policy_loss": -0.0016012965731022177, "dist_entropy": 0.340488588809967, "actor_grad_norm": 0.20932267606258392, "critic_grad_norm": 0.048300325870513916, "ratio": 0.9999598860740662, "entropy": 0.340488588809967, "incre_win_rate": 0.5813953488372093, "step": 1732}
{"time": 1767086805.704566, "phase": "train", "update": 1733, "total_env_steps": 5545600, "episode_reward": 0.21608859300613403, "value_loss": 0.010971411876380444, "policy_loss": -0.000826458252123885, "dist_entropy": 0.354385632276535, "actor_grad_norm": 0.1812765896320343, "critic_grad_norm": 0.04395556449890137, "ratio": 0.9997915625572205, "entropy": 0.354385632276535, "incre_win_rate": 0.5405405405405406, "step": 1733}
{"time": 1767086810.6534095, "phase": "train", "update": 1734, "total_env_steps": 5548800, "episode_reward": 0.22158683836460114, "value_loss": 0.01005728542804718, "policy_loss": -0.001439833623376785, "dist_entropy": 0.3278266489505768, "actor_grad_norm": 0.2052154839038849, "critic_grad_norm": 0.026045236736536026, "ratio": 1.0001529455184937, "entropy": 0.3278266489505768, "incre_win_rate": 0.6046511627906976, "step": 1734}
{"time": 1767086815.4984674, "phase": "train", "update": 1735, "total_env_steps": 5552000, "episode_reward": 0.22166131436824799, "value_loss": 0.01372040119022131, "policy_loss": -0.0011595548053492167, "dist_entropy": 0.3405082404613495, "actor_grad_norm": 0.19349588453769684, "critic_grad_norm": 0.08330100029706955, "ratio": 0.999800980091095, "entropy": 0.3405082404613495, "incre_win_rate": 0.6486486486486487, "step": 1735}
{"time": 1767086820.344893, "phase": "train", "update": 1736, "total_env_steps": 5555200, "episode_reward": 0.22852909564971924, "value_loss": 0.01001055184751749, "policy_loss": -0.0012450018791383855, "dist_entropy": 0.34622715711593627, "actor_grad_norm": 0.1817760020494461, "critic_grad_norm": 0.1016707569360733, "ratio": 0.9999338984489441, "entropy": 0.34622715711593627, "incre_win_rate": 0.6666666666666666, "step": 1736}
{"time": 1767086825.4002655, "phase": "train", "update": 1737, "total_env_steps": 5558400, "episode_reward": 0.2131451815366745, "value_loss": 0.01137885805219412, "policy_loss": -0.0016482921456827172, "dist_entropy": 0.3448877096176147, "actor_grad_norm": 0.12963292002677917, "critic_grad_norm": 0.05819353461265564, "ratio": 1.0002847909927368, "entropy": 0.3448877096176147, "incre_win_rate": 0.5945945945945946, "step": 1737}
{"time": 1767086830.0294602, "phase": "train", "update": 1738, "total_env_steps": 5561600, "episode_reward": 0.22443708777427673, "value_loss": 0.015130341611802578, "policy_loss": -0.0015174786088607561, "dist_entropy": 0.3229025721549988, "actor_grad_norm": 0.125287726521492, "critic_grad_norm": 0.04208787903189659, "ratio": 1.000144124031067, "entropy": 0.3229025721549988, "incre_win_rate": 0.55, "step": 1738}
{"time": 1767086834.760794, "phase": "train", "update": 1739, "total_env_steps": 5564800, "episode_reward": 0.2148851454257965, "value_loss": 0.012231180630624294, "policy_loss": -0.001392043507534879, "dist_entropy": 0.33456207513809205, "actor_grad_norm": 0.10779888927936554, "critic_grad_norm": 0.023862076923251152, "ratio": 0.9996906518936157, "entropy": 0.33456207513809205, "incre_win_rate": 0.5813953488372093, "step": 1739}
{"time": 1767086839.8184075, "phase": "train", "update": 1740, "total_env_steps": 5568000, "episode_reward": 0.23418772220611572, "value_loss": 0.010871990025043488, "policy_loss": -0.001540245658104311, "dist_entropy": 0.34819636344909666, "actor_grad_norm": 0.13863025605678558, "critic_grad_norm": 0.03379254788160324, "ratio": 1.000038743019104, "entropy": 0.34819636344909666, "incre_win_rate": 0.6, "step": 1740}
{"time": 1767086844.6479738, "phase": "train", "update": 1741, "total_env_steps": 5571200, "episode_reward": 0.2275201827287674, "value_loss": 0.012041589617729187, "policy_loss": -0.0010701263320441966, "dist_entropy": 0.33455445170402526, "actor_grad_norm": 0.13099578022956848, "critic_grad_norm": 0.02736450731754303, "ratio": 0.9997367262840271, "entropy": 0.33455445170402526, "incre_win_rate": 0.5348837209302325, "step": 1741}
{"time": 1767086856.6014588, "phase": "eval", "update": 1741, "total_env_steps": 5571200, "eval_win_rate": 0.75, "eval_episode_reward": 18.42601407284768, "step": 1741}
{"time": 1767086861.3699858, "phase": "train", "update": 1742, "total_env_steps": 5574400, "episode_reward": 0.2108428180217743, "value_loss": 0.01099970079958439, "policy_loss": -0.0015633900089085273, "dist_entropy": 0.347261643409729, "actor_grad_norm": 0.17417411506175995, "critic_grad_norm": 0.016739044338464737, "ratio": 0.9998823404312134, "entropy": 0.347261643409729, "incre_win_rate": 0.5853658536585366, "step": 1742}
{"time": 1767086866.1360111, "phase": "train", "update": 1743, "total_env_steps": 5577600, "episode_reward": 0.21794237196445465, "value_loss": 0.013198448531329631, "policy_loss": -0.001605430268282504, "dist_entropy": 0.35493088960647584, "actor_grad_norm": 0.22200942039489746, "critic_grad_norm": 0.05271788313984871, "ratio": 0.9998084902763367, "entropy": 0.35493088960647584, "incre_win_rate": 0.5405405405405406, "step": 1743}
{"time": 1767086871.2532065, "phase": "train", "update": 1744, "total_env_steps": 5580800, "episode_reward": 0.22876086831092834, "value_loss": 0.011640475504100323, "policy_loss": -0.0016017412333290792, "dist_entropy": 0.3316472291946411, "actor_grad_norm": 0.19446225464344025, "critic_grad_norm": 0.05135302618145943, "ratio": 1.0002158880233765, "entropy": 0.3316472291946411, "incre_win_rate": 0.6046511627906976, "step": 1744}
{"time": 1767086876.1019213, "phase": "train", "update": 1745, "total_env_steps": 5584000, "episode_reward": 0.2425527721643448, "value_loss": 0.010457598417997361, "policy_loss": -0.0012609845580385582, "dist_entropy": 0.3383409321308136, "actor_grad_norm": 0.1593398153781891, "critic_grad_norm": 0.10097117722034454, "ratio": 0.9996880888938904, "entropy": 0.3383409321308136, "incre_win_rate": 0.7435897435897436, "step": 1745}
{"time": 1767086881.047527, "phase": "train", "update": 1746, "total_env_steps": 5587200, "episode_reward": 0.20458659529685974, "value_loss": 0.008456549607217312, "policy_loss": -0.0015820168647052491, "dist_entropy": 0.3539826571941376, "actor_grad_norm": 0.1298840343952179, "critic_grad_norm": 0.0685071349143982, "ratio": 0.9999341368675232, "entropy": 0.3539826571941376, "incre_win_rate": 0.6388888888888888, "step": 1746}
{"time": 1767086886.1361713, "phase": "train", "update": 1747, "total_env_steps": 5590400, "episode_reward": 0.22845560312271118, "value_loss": 0.010354544408619404, "policy_loss": -0.00123638621599369, "dist_entropy": 0.3315324604511261, "actor_grad_norm": 0.12747380137443542, "critic_grad_norm": 0.052977174520492554, "ratio": 1.0001027584075928, "entropy": 0.3315324604511261, "incre_win_rate": 0.5714285714285714, "step": 1747}
{"time": 1767086890.908285, "phase": "train", "update": 1748, "total_env_steps": 5593600, "episode_reward": 0.2206689864397049, "value_loss": 0.011857966333627701, "policy_loss": -0.0015598648666748983, "dist_entropy": 0.3448461711406708, "actor_grad_norm": 0.12439721822738647, "critic_grad_norm": 0.10009565204381943, "ratio": 0.9999292492866516, "entropy": 0.3448461711406708, "incre_win_rate": 0.4883720930232558, "step": 1748}
{"time": 1767086895.5756342, "phase": "train", "update": 1749, "total_env_steps": 5596800, "episode_reward": 0.22931134700775146, "value_loss": 0.013348216004669667, "policy_loss": -0.0013130579029024148, "dist_entropy": 0.354471480846405, "actor_grad_norm": 0.1606784164905548, "critic_grad_norm": 0.05724870041012764, "ratio": 0.9999482035636902, "entropy": 0.354471480846405, "incre_win_rate": 0.6666666666666666, "step": 1749}
{"time": 1767086900.414364, "phase": "train", "update": 1750, "total_env_steps": 5600000, "episode_reward": 0.22096234560012817, "value_loss": 0.00992769654840231, "policy_loss": -0.0016962492906102966, "dist_entropy": 0.3502118527889252, "actor_grad_norm": 0.14082717895507812, "critic_grad_norm": 0.058178942650556564, "ratio": 1.0000803470611572, "entropy": 0.3502118527889252, "incre_win_rate": 0.6341463414634146, "step": 1750}
{"time": 1767086905.5026424, "phase": "train", "update": 1751, "total_env_steps": 5603200, "episode_reward": 0.22923219203948975, "value_loss": 0.01187129132449627, "policy_loss": -0.0012578697741716383, "dist_entropy": 0.3540881872177124, "actor_grad_norm": 0.17305046319961548, "critic_grad_norm": 0.05144764855504036, "ratio": 1.000065565109253, "entropy": 0.3540881872177124, "incre_win_rate": 0.5681818181818182, "step": 1751}
{"time": 1767086910.4760256, "phase": "train", "update": 1752, "total_env_steps": 5606400, "episode_reward": 0.24624225497245789, "value_loss": 0.010426612198352813, "policy_loss": -0.0019178389003368323, "dist_entropy": 0.3633940160274506, "actor_grad_norm": 0.19850857555866241, "critic_grad_norm": 0.03129643201828003, "ratio": 0.9996845126152039, "entropy": 0.3633940160274506, "incre_win_rate": 0.6666666666666666, "step": 1752}
{"time": 1767086915.2077048, "phase": "train", "update": 1753, "total_env_steps": 5609600, "episode_reward": 0.20773643255233765, "value_loss": 0.013084137998521327, "policy_loss": -0.0016513642911874626, "dist_entropy": 0.37262300252914426, "actor_grad_norm": 0.15769822895526886, "critic_grad_norm": 0.045042481273412704, "ratio": 0.9998953938484192, "entropy": 0.37262300252914426, "incre_win_rate": 0.425, "step": 1753}
{"time": 1767086920.0845013, "phase": "train", "update": 1754, "total_env_steps": 5612800, "episode_reward": 0.2276991903781891, "value_loss": 0.010955123417079448, "policy_loss": -0.0017753990272893817, "dist_entropy": 0.36301363706588746, "actor_grad_norm": 0.14863011240959167, "critic_grad_norm": 0.05165362358093262, "ratio": 0.999960720539093, "entropy": 0.36301363706588746, "incre_win_rate": 0.6097560975609756, "step": 1754}
{"time": 1767086924.893174, "phase": "train", "update": 1755, "total_env_steps": 5616000, "episode_reward": 0.2252592295408249, "value_loss": 0.010736246034502983, "policy_loss": -0.001543019646447874, "dist_entropy": 0.3738861858844757, "actor_grad_norm": 0.1701659858226776, "critic_grad_norm": 0.058202266693115234, "ratio": 0.9999872446060181, "entropy": 0.3738861858844757, "incre_win_rate": 0.65, "step": 1755}
{"time": 1767086929.8360813, "phase": "train", "update": 1756, "total_env_steps": 5619200, "episode_reward": 0.22806186974048615, "value_loss": 0.009823822975158691, "policy_loss": -0.001433227279345317, "dist_entropy": 0.3720922529697418, "actor_grad_norm": 0.18811123073101044, "critic_grad_norm": 0.044922877103090286, "ratio": 1.0000313520431519, "entropy": 0.3720922529697418, "incre_win_rate": 0.5853658536585366, "step": 1756}
{"time": 1767086934.9209807, "phase": "train", "update": 1757, "total_env_steps": 5622400, "episode_reward": 0.21119308471679688, "value_loss": 0.011690652742981911, "policy_loss": -0.0016043086144122976, "dist_entropy": 0.3746354401111603, "actor_grad_norm": 0.134608194231987, "critic_grad_norm": 0.027993086725473404, "ratio": 0.9999926686286926, "entropy": 0.3746354401111603, "incre_win_rate": 0.5675675675675675, "step": 1757}
{"time": 1767086940.2289937, "phase": "train", "update": 1758, "total_env_steps": 5625600, "episode_reward": 0.23149265348911285, "value_loss": 0.010702990740537644, "policy_loss": -0.001407371006493463, "dist_entropy": 0.3735866665840149, "actor_grad_norm": 0.12198448181152344, "critic_grad_norm": 0.019087210297584534, "ratio": 1.0000587701797485, "entropy": 0.3735866665840149, "incre_win_rate": 0.6428571428571429, "step": 1758}
{"time": 1767086945.5745091, "phase": "train", "update": 1759, "total_env_steps": 5628800, "episode_reward": 0.2136584222316742, "value_loss": 0.012802221812307835, "policy_loss": -0.0016421231291246841, "dist_entropy": 0.37993854880332945, "actor_grad_norm": 0.1533488929271698, "critic_grad_norm": 0.031339455395936966, "ratio": 1.0000972747802734, "entropy": 0.37993854880332945, "incre_win_rate": 0.5263157894736842, "step": 1759}
{"time": 1767086950.9078617, "phase": "train", "update": 1760, "total_env_steps": 5632000, "episode_reward": 0.22380951046943665, "value_loss": 0.012197007052600383, "policy_loss": -0.001398663863697891, "dist_entropy": 0.373354172706604, "actor_grad_norm": 0.1589897722005844, "critic_grad_norm": 0.026447206735610962, "ratio": 0.9999734163284302, "entropy": 0.373354172706604, "incre_win_rate": 0.6, "step": 1760}
{"time": 1767086955.885568, "phase": "train", "update": 1761, "total_env_steps": 5635200, "episode_reward": 0.2137763798236847, "value_loss": 0.012384194694459439, "policy_loss": -0.001700165756081873, "dist_entropy": 0.37512617111206054, "actor_grad_norm": 0.1328691691160202, "critic_grad_norm": 0.028827672824263573, "ratio": 0.9997678995132446, "entropy": 0.37512617111206054, "incre_win_rate": 0.5609756097560976, "step": 1761}
{"time": 1767086969.0383203, "phase": "eval", "update": 1761, "total_env_steps": 5635200, "eval_win_rate": 0.65625, "eval_episode_reward": 17.79749586092715, "step": 1761}
{"time": 1767086974.933407, "phase": "train", "update": 1762, "total_env_steps": 5638400, "episode_reward": 0.22608596086502075, "value_loss": 0.013298306986689568, "policy_loss": -0.0015299124737790492, "dist_entropy": 0.37601167559623716, "actor_grad_norm": 0.13015148043632507, "critic_grad_norm": 0.03283477574586868, "ratio": 0.9999614953994751, "entropy": 0.37601167559623716, "incre_win_rate": 0.6052631578947368, "step": 1762}
{"time": 1767086980.8623607, "phase": "train", "update": 1763, "total_env_steps": 5641600, "episode_reward": 0.2479904741048813, "value_loss": 0.008382616564631462, "policy_loss": -0.0013176261918744104, "dist_entropy": 0.3653352439403534, "actor_grad_norm": 0.11116977781057358, "critic_grad_norm": 0.1183445006608963, "ratio": 1.0001881122589111, "entropy": 0.3653352439403534, "incre_win_rate": 0.8, "step": 1763}
{"time": 1767086986.6920903, "phase": "train", "update": 1764, "total_env_steps": 5644800, "episode_reward": 0.23849338293075562, "value_loss": 0.01147338394075632, "policy_loss": -0.0013999988833965915, "dist_entropy": 0.3612904667854309, "actor_grad_norm": 0.1903173178434372, "critic_grad_norm": 0.1001838818192482, "ratio": 1.0002132654190063, "entropy": 0.3612904667854309, "incre_win_rate": 0.6097560975609756, "step": 1764}
{"time": 1767086992.7738938, "phase": "train", "update": 1765, "total_env_steps": 5648000, "episode_reward": 0.2243243008852005, "value_loss": 0.01047514583915472, "policy_loss": -0.0017120689589106065, "dist_entropy": 0.3705009281635284, "actor_grad_norm": 0.11545101553201675, "critic_grad_norm": 0.07540769875049591, "ratio": 1.0001561641693115, "entropy": 0.3705009281635284, "incre_win_rate": 0.5714285714285714, "step": 1765}
{"time": 1767086998.2367613, "phase": "train", "update": 1766, "total_env_steps": 5651200, "episode_reward": 0.24356943368911743, "value_loss": 0.01079214531928301, "policy_loss": -0.00135062989275605, "dist_entropy": 0.3671528160572052, "actor_grad_norm": 0.10635975748300552, "critic_grad_norm": 0.08285954594612122, "ratio": 0.9998745918273926, "entropy": 0.3671528160572052, "incre_win_rate": 0.7142857142857143, "step": 1766}
{"time": 1767087003.4617841, "phase": "train", "update": 1767, "total_env_steps": 5654400, "episode_reward": 0.21991516649723053, "value_loss": 0.013304993137717247, "policy_loss": -0.0020793861251055647, "dist_entropy": 0.3758966028690338, "actor_grad_norm": 0.14423899352550507, "critic_grad_norm": 0.07677874714136124, "ratio": 0.9997074007987976, "entropy": 0.3758966028690338, "incre_win_rate": 0.5641025641025641, "step": 1767}
{"time": 1767087008.6394644, "phase": "train", "update": 1768, "total_env_steps": 5657600, "episode_reward": 0.22704729437828064, "value_loss": 0.010288926586508752, "policy_loss": -0.0015049930847123249, "dist_entropy": 0.37602261900901796, "actor_grad_norm": 0.12263374775648117, "critic_grad_norm": 0.058264341205358505, "ratio": 1.0000947713851929, "entropy": 0.37602261900901796, "incre_win_rate": 0.7, "step": 1768}
{"time": 1767087013.800565, "phase": "train", "update": 1769, "total_env_steps": 5660800, "episode_reward": 0.22208505868911743, "value_loss": 0.010920758359134197, "policy_loss": -0.001643072872201401, "dist_entropy": 0.3811677873134613, "actor_grad_norm": 0.10704182833433151, "critic_grad_norm": 0.03870339319109917, "ratio": 0.999977707862854, "entropy": 0.3811677873134613, "incre_win_rate": 0.5853658536585366, "step": 1769}
{"time": 1767087019.031421, "phase": "train", "update": 1770, "total_env_steps": 5664000, "episode_reward": 0.2223980873823166, "value_loss": 0.012387674115598202, "policy_loss": -0.0017477616412918452, "dist_entropy": 0.3771719455718994, "actor_grad_norm": 0.11551535129547119, "critic_grad_norm": 0.04294450953602791, "ratio": 1.0000437498092651, "entropy": 0.3771719455718994, "incre_win_rate": 0.6486486486486487, "step": 1770}
{"time": 1767087024.2578135, "phase": "train", "update": 1771, "total_env_steps": 5667200, "episode_reward": 0.21992705762386322, "value_loss": 0.012465710379183292, "policy_loss": -0.0013894661036371048, "dist_entropy": 0.36727755665779116, "actor_grad_norm": 0.12189812958240509, "critic_grad_norm": 0.04175461456179619, "ratio": 1.0000454187393188, "entropy": 0.36727755665779116, "incre_win_rate": 0.625, "step": 1771}
{"time": 1767087029.413324, "phase": "train", "update": 1772, "total_env_steps": 5670400, "episode_reward": 0.22084230184555054, "value_loss": 0.0124898511916399, "policy_loss": -0.001446320523946909, "dist_entropy": 0.3598716676235199, "actor_grad_norm": 0.16365936398506165, "critic_grad_norm": 0.06672190874814987, "ratio": 0.9996245503425598, "entropy": 0.3598716676235199, "incre_win_rate": 0.5, "step": 1772}
{"time": 1767087034.6218581, "phase": "train", "update": 1773, "total_env_steps": 5673600, "episode_reward": 0.2247537225484848, "value_loss": 0.013465104438364506, "policy_loss": -0.0018120836026795928, "dist_entropy": 0.3504411518573761, "actor_grad_norm": 0.13202938437461853, "critic_grad_norm": 0.05434507876634598, "ratio": 1.0000957250595093, "entropy": 0.3504411518573761, "incre_win_rate": 0.625, "step": 1773}
{"time": 1767087039.7177863, "phase": "train", "update": 1774, "total_env_steps": 5676800, "episode_reward": 0.19473302364349365, "value_loss": 0.014096814952790738, "policy_loss": -0.0016888980966090373, "dist_entropy": 0.373652583360672, "actor_grad_norm": 0.17533914744853973, "critic_grad_norm": 0.022936757653951645, "ratio": 0.9998265504837036, "entropy": 0.373652583360672, "incre_win_rate": 0.42105263157894735, "step": 1774}
{"time": 1767087044.8838854, "phase": "train", "update": 1775, "total_env_steps": 5680000, "episode_reward": 0.22512727975845337, "value_loss": 0.014757107384502888, "policy_loss": -0.0014817322362233654, "dist_entropy": 0.33310856819152834, "actor_grad_norm": 0.15341094136238098, "critic_grad_norm": 0.023974290117621422, "ratio": 1.0, "entropy": 0.33310856819152834, "incre_win_rate": 0.6341463414634146, "step": 1775}
{"time": 1767087050.0668728, "phase": "train", "update": 1776, "total_env_steps": 5683200, "episode_reward": 0.22537976503372192, "value_loss": 0.011413710378110408, "policy_loss": -0.0018297218425697536, "dist_entropy": 0.3352935969829559, "actor_grad_norm": 0.1329674869775772, "critic_grad_norm": 0.0925845131278038, "ratio": 0.9996672868728638, "entropy": 0.3352935969829559, "incre_win_rate": 0.6, "step": 1776}
{"time": 1767087055.495716, "phase": "train", "update": 1777, "total_env_steps": 5686400, "episode_reward": 0.23802879452705383, "value_loss": 0.009905363619327544, "policy_loss": -0.001782716475420898, "dist_entropy": 0.32308167815208433, "actor_grad_norm": 0.1840348243713379, "critic_grad_norm": 0.07730215042829514, "ratio": 1.0001825094223022, "entropy": 0.32308167815208433, "incre_win_rate": 0.6818181818181818, "step": 1777}
{"time": 1767087060.6583972, "phase": "train", "update": 1778, "total_env_steps": 5689600, "episode_reward": 0.22752897441387177, "value_loss": 0.012264454178512097, "policy_loss": -0.00126389996513101, "dist_entropy": 0.3483502268791199, "actor_grad_norm": 0.1421659290790558, "critic_grad_norm": 0.06959798187017441, "ratio": 0.9999663233757019, "entropy": 0.3483502268791199, "incre_win_rate": 0.525, "step": 1778}
{"time": 1767087065.7931972, "phase": "train", "update": 1779, "total_env_steps": 5692800, "episode_reward": 0.2361879199743271, "value_loss": 0.013200640864670276, "policy_loss": -0.0015657928947925726, "dist_entropy": 0.333509236574173, "actor_grad_norm": 0.17224499583244324, "critic_grad_norm": 0.053565699607133865, "ratio": 0.9999259114265442, "entropy": 0.333509236574173, "incre_win_rate": 0.75, "step": 1779}
{"time": 1767087071.1682963, "phase": "train", "update": 1780, "total_env_steps": 5696000, "episode_reward": 0.25091785192489624, "value_loss": 0.009666353650391101, "policy_loss": -0.0012946027112167968, "dist_entropy": 0.32797661423683167, "actor_grad_norm": 0.141310453414917, "critic_grad_norm": 0.0586552731692791, "ratio": 0.9999475479125977, "entropy": 0.32797661423683167, "incre_win_rate": 0.7777777777777778, "step": 1780}
{"time": 1767087076.2683039, "phase": "train", "update": 1781, "total_env_steps": 5699200, "episode_reward": 0.23201003670692444, "value_loss": 0.010781543143093587, "policy_loss": -0.0015682766208350075, "dist_entropy": 0.3458995521068573, "actor_grad_norm": 0.13696545362472534, "critic_grad_norm": 0.039876606315374374, "ratio": 1.0001583099365234, "entropy": 0.3458995521068573, "incre_win_rate": 0.7, "step": 1781}
{"time": 1767087094.8649035, "phase": "eval", "update": 1781, "total_env_steps": 5699200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.150041390728475, "step": 1781}
{"time": 1767087100.2396047, "phase": "train", "update": 1782, "total_env_steps": 5702400, "episode_reward": 0.2320985049009323, "value_loss": 0.010442129708826542, "policy_loss": -0.0013914068922773026, "dist_entropy": 0.3439011812210083, "actor_grad_norm": 0.12114367634057999, "critic_grad_norm": 0.03002888336777687, "ratio": 0.9999201893806458, "entropy": 0.3439011812210083, "incre_win_rate": 0.6666666666666666, "step": 1782}
{"time": 1767087105.2948453, "phase": "train", "update": 1783, "total_env_steps": 5705600, "episode_reward": 0.1945829838514328, "value_loss": 0.016056295856833457, "policy_loss": -0.0016270459094201329, "dist_entropy": 0.37739390730857847, "actor_grad_norm": 0.1487494558095932, "critic_grad_norm": 0.05588449910283089, "ratio": 0.9997539520263672, "entropy": 0.37739390730857847, "incre_win_rate": 0.5789473684210527, "step": 1783}
{"time": 1767087110.420259, "phase": "train", "update": 1784, "total_env_steps": 5708800, "episode_reward": 0.23137107491493225, "value_loss": 0.008909068256616592, "policy_loss": -0.0013431019240218943, "dist_entropy": 0.34422162771224973, "actor_grad_norm": 0.0968872681260109, "critic_grad_norm": 0.06931596249341965, "ratio": 1.0001672506332397, "entropy": 0.34422162771224973, "incre_win_rate": 0.6585365853658537, "step": 1784}
{"time": 1767087115.7384243, "phase": "train", "update": 1785, "total_env_steps": 5712000, "episode_reward": 0.224707692861557, "value_loss": 0.008920890651643277, "policy_loss": -0.0013469713235323866, "dist_entropy": 0.343185293674469, "actor_grad_norm": 0.11777599155902863, "critic_grad_norm": 0.04854512959718704, "ratio": 0.9999136924743652, "entropy": 0.343185293674469, "incre_win_rate": 0.6666666666666666, "step": 1785}
{"time": 1767087120.857302, "phase": "train", "update": 1786, "total_env_steps": 5715200, "episode_reward": 0.21436414122581482, "value_loss": 0.013054278306663036, "policy_loss": -0.0016415010057476919, "dist_entropy": 0.34086098670959475, "actor_grad_norm": 0.15201885998249054, "critic_grad_norm": 0.03763983026146889, "ratio": 1.0000441074371338, "entropy": 0.34086098670959475, "incre_win_rate": 0.5897435897435898, "step": 1786}
{"time": 1767087126.0047073, "phase": "train", "update": 1787, "total_env_steps": 5718400, "episode_reward": 0.22233238816261292, "value_loss": 0.011007902398705482, "policy_loss": -0.0011845303758722281, "dist_entropy": 0.3501946032047272, "actor_grad_norm": 0.166951522231102, "critic_grad_norm": 0.03893169388175011, "ratio": 0.9999201893806458, "entropy": 0.3501946032047272, "incre_win_rate": 0.5641025641025641, "step": 1787}
{"time": 1767087131.247457, "phase": "train", "update": 1788, "total_env_steps": 5721600, "episode_reward": 0.2254837453365326, "value_loss": 0.010506195574998855, "policy_loss": -0.0011508273145693694, "dist_entropy": 0.3602086126804352, "actor_grad_norm": 0.15786056220531464, "critic_grad_norm": 0.02912372350692749, "ratio": 0.999471127986908, "entropy": 0.3602086126804352, "incre_win_rate": 0.5952380952380952, "step": 1788}
{"time": 1767087136.4163294, "phase": "train", "update": 1789, "total_env_steps": 5724800, "episode_reward": 0.21374380588531494, "value_loss": 0.012924806587398053, "policy_loss": -0.0015330585086281267, "dist_entropy": 0.37317973375320435, "actor_grad_norm": 0.14385969936847687, "critic_grad_norm": 0.05386841297149658, "ratio": 0.9997979402542114, "entropy": 0.37317973375320435, "incre_win_rate": 0.5128205128205128, "step": 1789}
{"time": 1767087141.5114827, "phase": "train", "update": 1790, "total_env_steps": 5728000, "episode_reward": 0.21381159126758575, "value_loss": 0.01183185651898384, "policy_loss": -0.0013308149825274284, "dist_entropy": 0.3689450442790985, "actor_grad_norm": 0.14239652454853058, "critic_grad_norm": 0.06331175565719604, "ratio": 0.999524712562561, "entropy": 0.3689450442790985, "incre_win_rate": 0.5897435897435898, "step": 1790}
{"time": 1767087146.7490764, "phase": "train", "update": 1791, "total_env_steps": 5731200, "episode_reward": 0.2521321773529053, "value_loss": 0.007540066353976726, "policy_loss": -0.0011640347572139831, "dist_entropy": 0.3504569172859192, "actor_grad_norm": 0.12215249985456467, "critic_grad_norm": 0.081681028008461, "ratio": 1.0002082586288452, "entropy": 0.3504569172859192, "incre_win_rate": 0.7954545454545454, "step": 1791}
{"time": 1767087152.1082258, "phase": "train", "update": 1792, "total_env_steps": 5734400, "episode_reward": 0.23464559018611908, "value_loss": 0.0104402681812644, "policy_loss": -0.00140424179149079, "dist_entropy": 0.36035540103912356, "actor_grad_norm": 0.150207981467247, "critic_grad_norm": 0.05894062668085098, "ratio": 0.9998742938041687, "entropy": 0.36035540103912356, "incre_win_rate": 0.65, "step": 1792}
{"time": 1767087157.2956147, "phase": "train", "update": 1793, "total_env_steps": 5737600, "episode_reward": 0.2499736249446869, "value_loss": 0.00996461659669876, "policy_loss": -0.001241779756919925, "dist_entropy": 0.3426252007484436, "actor_grad_norm": 0.10364588350057602, "critic_grad_norm": 0.04981176555156708, "ratio": 0.999882698059082, "entropy": 0.3426252007484436, "incre_win_rate": 0.7333333333333333, "step": 1793}
{"time": 1767087162.447689, "phase": "train", "update": 1794, "total_env_steps": 5740800, "episode_reward": 0.24090595543384552, "value_loss": 0.010463566891849041, "policy_loss": -0.0016624330310762048, "dist_entropy": 0.342234855890274, "actor_grad_norm": 0.1178702861070633, "critic_grad_norm": 0.0706394612789154, "ratio": 0.9998888969421387, "entropy": 0.342234855890274, "incre_win_rate": 0.6428571428571429, "step": 1794}
{"time": 1767087167.5524142, "phase": "train", "update": 1795, "total_env_steps": 5744000, "episode_reward": 0.22617082297801971, "value_loss": 0.009969410672783851, "policy_loss": -0.0014170651876625584, "dist_entropy": 0.35763055086135864, "actor_grad_norm": 0.13717566430568695, "critic_grad_norm": 0.06371761858463287, "ratio": 0.9996903538703918, "entropy": 0.35763055086135864, "incre_win_rate": 0.6585365853658537, "step": 1795}
{"time": 1767087172.8000424, "phase": "train", "update": 1796, "total_env_steps": 5747200, "episode_reward": 0.25683414936065674, "value_loss": 0.007565934397280216, "policy_loss": -0.0013852010028791995, "dist_entropy": 0.34445506930351255, "actor_grad_norm": 0.11202981323003769, "critic_grad_norm": 0.09090443700551987, "ratio": 1.0002142190933228, "entropy": 0.34445506930351255, "incre_win_rate": 0.7906976744186046, "step": 1796}
{"time": 1767087178.220243, "phase": "train", "update": 1797, "total_env_steps": 5750400, "episode_reward": 0.24601665139198303, "value_loss": 0.007678979728370905, "policy_loss": -0.0012885340201922446, "dist_entropy": 0.36036611795425416, "actor_grad_norm": 0.0978250503540039, "critic_grad_norm": 0.04727184772491455, "ratio": 0.9999351501464844, "entropy": 0.36036611795425416, "incre_win_rate": 0.8095238095238095, "step": 1797}
{"time": 1767087214.7680287, "phase": "train", "update": 1798, "total_env_steps": 5753600, "episode_reward": 0.24013398587703705, "value_loss": 0.03683406785130501, "policy_loss": -0.0012293671347805458, "dist_entropy": 0.3586679041385651, "actor_grad_norm": 0.0918431207537651, "critic_grad_norm": 0.13985243439674377, "ratio": 1.000078797340393, "entropy": 0.3586679041385651, "incre_win_rate": 0.7222222222222222, "step": 1798}
{"time": 1767087220.0702488, "phase": "train", "update": 1799, "total_env_steps": 5756800, "episode_reward": 0.23400093615055084, "value_loss": 0.008594788610935211, "policy_loss": -0.0014426158870307405, "dist_entropy": 0.36200788617134094, "actor_grad_norm": 0.1269737184047699, "critic_grad_norm": 0.0966348946094513, "ratio": 1.0002139806747437, "entropy": 0.36200788617134094, "incre_win_rate": 0.7560975609756098, "step": 1799}
{"time": 1767087225.253832, "phase": "train", "update": 1800, "total_env_steps": 5760000, "episode_reward": 0.23619724810123444, "value_loss": 0.007859118282794952, "policy_loss": -0.0015978982492239168, "dist_entropy": 0.3779985308647156, "actor_grad_norm": 0.12453615665435791, "critic_grad_norm": 0.07759761810302734, "ratio": 0.9995282292366028, "entropy": 0.3779985308647156, "incre_win_rate": 0.7073170731707317, "step": 1800}
{"time": 1767087230.3965678, "phase": "train", "update": 1801, "total_env_steps": 5763200, "episode_reward": 0.2339802384376526, "value_loss": 0.008190036378800869, "policy_loss": -0.0017396852231911452, "dist_entropy": 0.36524805426597595, "actor_grad_norm": 0.12122774124145508, "critic_grad_norm": 0.02844621241092682, "ratio": 1.0000160932540894, "entropy": 0.36524805426597595, "incre_win_rate": 0.7027027027027027, "step": 1801}
{"time": 1767087243.3652163, "phase": "eval", "update": 1801, "total_env_steps": 5763200, "eval_win_rate": 0.78125, "eval_episode_reward": 18.94779594370861, "step": 1801}
{"time": 1767087248.567158, "phase": "train", "update": 1802, "total_env_steps": 5766400, "episode_reward": 0.21065345406532288, "value_loss": 0.010415004007518292, "policy_loss": -0.0013315520840237126, "dist_entropy": 0.3569140493869781, "actor_grad_norm": 0.1384982168674469, "critic_grad_norm": 0.02405167929828167, "ratio": 0.9999068379402161, "entropy": 0.3569140493869781, "incre_win_rate": 0.675, "step": 1802}
{"time": 1767087253.6968277, "phase": "train", "update": 1803, "total_env_steps": 5769600, "episode_reward": 0.23047754168510437, "value_loss": 0.012674195691943169, "policy_loss": -0.0015883972301978134, "dist_entropy": 0.35464670062065123, "actor_grad_norm": 0.13653820753097534, "critic_grad_norm": 0.049025893211364746, "ratio": 0.9997907876968384, "entropy": 0.35464670062065123, "incre_win_rate": 0.6585365853658537, "step": 1803}
{"time": 1767087258.8357766, "phase": "train", "update": 1804, "total_env_steps": 5772800, "episode_reward": 0.2351841926574707, "value_loss": 0.00908371564000845, "policy_loss": -0.001514299178272438, "dist_entropy": 0.3604360044002533, "actor_grad_norm": 0.11701522022485733, "critic_grad_norm": 0.032180942595005035, "ratio": 0.9997017979621887, "entropy": 0.3604360044002533, "incre_win_rate": 0.7380952380952381, "step": 1804}
{"time": 1767087264.17895, "phase": "train", "update": 1805, "total_env_steps": 5776000, "episode_reward": 0.2235984057188034, "value_loss": 0.011021342314779758, "policy_loss": -0.000845546394084451, "dist_entropy": 0.34586973786354064, "actor_grad_norm": 0.10005557537078857, "critic_grad_norm": 0.023290084674954414, "ratio": 0.9998279809951782, "entropy": 0.34586973786354064, "incre_win_rate": 0.65, "step": 1805}
{"time": 1767087269.2716923, "phase": "train", "update": 1806, "total_env_steps": 5779200, "episode_reward": 0.2206234484910965, "value_loss": 0.009293441288173198, "policy_loss": -0.00149598223226306, "dist_entropy": 0.3522556066513062, "actor_grad_norm": 0.1415068507194519, "critic_grad_norm": 0.0369345061480999, "ratio": 0.9997047781944275, "entropy": 0.3522556066513062, "incre_win_rate": 0.6052631578947368, "step": 1806}
{"time": 1767087274.3437028, "phase": "train", "update": 1807, "total_env_steps": 5782400, "episode_reward": 0.2069060504436493, "value_loss": 0.013069565407931805, "policy_loss": -0.0019100073790253801, "dist_entropy": 0.3678838610649109, "actor_grad_norm": 0.10970933735370636, "critic_grad_norm": 0.07048925012350082, "ratio": 0.9993498921394348, "entropy": 0.3678838610649109, "incre_win_rate": 0.47368421052631576, "step": 1807}
{"time": 1767087279.4820862, "phase": "train", "update": 1808, "total_env_steps": 5785600, "episode_reward": 0.22487686574459076, "value_loss": 0.012137038446962834, "policy_loss": -0.0013327400436605075, "dist_entropy": 0.3712718188762665, "actor_grad_norm": 0.16913309693336487, "critic_grad_norm": 0.044058043509721756, "ratio": 0.9995248913764954, "entropy": 0.3712718188762665, "incre_win_rate": 0.627906976744186, "step": 1808}
{"time": 1767087284.6611152, "phase": "train", "update": 1809, "total_env_steps": 5788800, "episode_reward": 0.23424823582172394, "value_loss": 0.010507162474095822, "policy_loss": -0.0015790369327916664, "dist_entropy": 0.3571938216686249, "actor_grad_norm": 0.10961250215768814, "critic_grad_norm": 0.023623188957571983, "ratio": 0.9998793601989746, "entropy": 0.3571938216686249, "incre_win_rate": 0.5609756097560976, "step": 1809}
{"time": 1767087289.8048518, "phase": "train", "update": 1810, "total_env_steps": 5792000, "episode_reward": 0.23123344779014587, "value_loss": 0.009130720421671868, "policy_loss": -0.0012820326978360442, "dist_entropy": 0.36712836027145385, "actor_grad_norm": 0.12508712708950043, "critic_grad_norm": 0.04539370536804199, "ratio": 1.0001885890960693, "entropy": 0.36712836027145385, "incre_win_rate": 0.65, "step": 1810}
{"time": 1767087295.0671828, "phase": "train", "update": 1811, "total_env_steps": 5795200, "episode_reward": 0.234275683760643, "value_loss": 0.009856561198830605, "policy_loss": -0.00147767455257366, "dist_entropy": 0.35162643194198606, "actor_grad_norm": 0.14586102962493896, "critic_grad_norm": 0.03972151502966881, "ratio": 1.00043523311615, "entropy": 0.35162643194198606, "incre_win_rate": 0.6666666666666666, "step": 1811}
{"time": 1767087300.3718033, "phase": "train", "update": 1812, "total_env_steps": 5798400, "episode_reward": 0.21861444413661957, "value_loss": 0.010899985395371913, "policy_loss": -0.0013343495691017892, "dist_entropy": 0.3504533588886261, "actor_grad_norm": 0.1533212959766388, "critic_grad_norm": 0.035007670521736145, "ratio": 0.9996019601821899, "entropy": 0.3504533588886261, "incre_win_rate": 0.5454545454545454, "step": 1812}
{"time": 1767087305.566117, "phase": "train", "update": 1813, "total_env_steps": 5801600, "episode_reward": 0.23084022104740143, "value_loss": 0.010951959900557995, "policy_loss": -0.0013323145139295888, "dist_entropy": 0.34950020909309387, "actor_grad_norm": 0.12348631769418716, "critic_grad_norm": 0.04103757068514824, "ratio": 0.9999920725822449, "entropy": 0.34950020909309387, "incre_win_rate": 0.6842105263157895, "step": 1813}
{"time": 1767087310.7830791, "phase": "train", "update": 1814, "total_env_steps": 5804800, "episode_reward": 0.2450760453939438, "value_loss": 0.00753856198862195, "policy_loss": -0.0012031835836523897, "dist_entropy": 0.372443687915802, "actor_grad_norm": 0.10896500200033188, "critic_grad_norm": 0.06578616797924042, "ratio": 1.0003217458724976, "entropy": 0.372443687915802, "incre_win_rate": 0.8372093023255814, "step": 1814}
{"time": 1767087315.9240382, "phase": "train", "update": 1815, "total_env_steps": 5808000, "episode_reward": 0.2531379461288452, "value_loss": 0.008427611738443374, "policy_loss": -0.0014402085282085864, "dist_entropy": 0.35130481123924256, "actor_grad_norm": 0.1185108944773674, "critic_grad_norm": 0.045724060386419296, "ratio": 0.9995223879814148, "entropy": 0.35130481123924256, "incre_win_rate": 0.7441860465116279, "step": 1815}
{"time": 1767087321.0555012, "phase": "train", "update": 1816, "total_env_steps": 5811200, "episode_reward": 0.2257533222436905, "value_loss": 0.009741392731666566, "policy_loss": -0.0013957783338469198, "dist_entropy": 0.37181503772735597, "actor_grad_norm": 0.12484581768512726, "critic_grad_norm": 0.06536517292261124, "ratio": 0.9999789595603943, "entropy": 0.37181503772735597, "incre_win_rate": 0.7, "step": 1816}
{"time": 1767087326.3089051, "phase": "train", "update": 1817, "total_env_steps": 5814400, "episode_reward": 0.23219217360019684, "value_loss": 0.0086597241461277, "policy_loss": -0.0013803289180614798, "dist_entropy": 0.35451728105545044, "actor_grad_norm": 0.13899457454681396, "critic_grad_norm": 0.04766444116830826, "ratio": 0.9998942613601685, "entropy": 0.35451728105545044, "incre_win_rate": 0.725, "step": 1817}
{"time": 1767087331.1219702, "phase": "train", "update": 1818, "total_env_steps": 5817600, "episode_reward": 0.22826780378818512, "value_loss": 0.008270679973065853, "policy_loss": -0.0016701093113731247, "dist_entropy": 0.36966602206230165, "actor_grad_norm": 0.12199953943490982, "critic_grad_norm": 0.04084482416510582, "ratio": 0.9997909665107727, "entropy": 0.36966602206230165, "incre_win_rate": 0.6829268292682927, "step": 1818}
{"time": 1767087336.0648215, "phase": "train", "update": 1819, "total_env_steps": 5820800, "episode_reward": 0.23004966974258423, "value_loss": 0.010319656133651734, "policy_loss": -0.0015195534096271502, "dist_entropy": 0.37346831560134885, "actor_grad_norm": 0.12647010385990143, "critic_grad_norm": 0.043533649295568466, "ratio": 1.0002140998840332, "entropy": 0.37346831560134885, "incre_win_rate": 0.6666666666666666, "step": 1819}
{"time": 1767087340.861275, "phase": "train", "update": 1820, "total_env_steps": 5824000, "episode_reward": 0.2376159131526947, "value_loss": 0.00855172574520111, "policy_loss": -0.001710299142181526, "dist_entropy": 0.3760235071182251, "actor_grad_norm": 0.11280244588851929, "critic_grad_norm": 0.053714569658041, "ratio": 0.9996878504753113, "entropy": 0.3760235071182251, "incre_win_rate": 0.7441860465116279, "step": 1820}
{"time": 1767087345.6731086, "phase": "train", "update": 1821, "total_env_steps": 5827200, "episode_reward": 0.2403104156255722, "value_loss": 0.008821389637887478, "policy_loss": -0.0012167941118306658, "dist_entropy": 0.3644316136837006, "actor_grad_norm": 0.12038403749465942, "critic_grad_norm": 0.0608002245426178, "ratio": 1.000113844871521, "entropy": 0.3644316136837006, "incre_win_rate": 0.7435897435897436, "step": 1821}
{"time": 1767087356.98303, "phase": "eval", "update": 1821, "total_env_steps": 5827200, "eval_win_rate": 0.875, "eval_episode_reward": 19.377690397350992, "step": 1821}
{"time": 1767087361.7081604, "phase": "train", "update": 1822, "total_env_steps": 5830400, "episode_reward": 0.23430463671684265, "value_loss": 0.007782121561467648, "policy_loss": -0.0014997721530733087, "dist_entropy": 0.3687806010246277, "actor_grad_norm": 0.11267470568418503, "critic_grad_norm": 0.04094744846224785, "ratio": 1.0002124309539795, "entropy": 0.3687806010246277, "incre_win_rate": 0.775, "step": 1822}
{"time": 1767087366.463534, "phase": "train", "update": 1823, "total_env_steps": 5833600, "episode_reward": 0.2361832559108734, "value_loss": 0.009165646694600581, "policy_loss": -0.0016716091275768008, "dist_entropy": 0.3613047242164612, "actor_grad_norm": 0.1252816915512085, "critic_grad_norm": 0.02800116315484047, "ratio": 1.0000669956207275, "entropy": 0.3613047242164612, "incre_win_rate": 0.7380952380952381, "step": 1823}
{"time": 1767087371.1811848, "phase": "train", "update": 1824, "total_env_steps": 5836800, "episode_reward": 0.24338731169700623, "value_loss": 0.008650665543973446, "policy_loss": -0.001479488249105998, "dist_entropy": 0.36316502690315244, "actor_grad_norm": 0.10519609600305557, "critic_grad_norm": 0.050160329788923264, "ratio": 0.9999726414680481, "entropy": 0.36316502690315244, "incre_win_rate": 0.65, "step": 1824}
{"time": 1767087376.0118833, "phase": "train", "update": 1825, "total_env_steps": 5840000, "episode_reward": 0.24915198981761932, "value_loss": 0.009110992588102818, "policy_loss": -0.0015120321591320263, "dist_entropy": 0.35430715084075926, "actor_grad_norm": 0.12443146854639053, "critic_grad_norm": 0.07080771774053574, "ratio": 0.9997919201850891, "entropy": 0.35430715084075926, "incre_win_rate": 0.7777777777777778, "step": 1825}
{"time": 1767087380.8042924, "phase": "train", "update": 1826, "total_env_steps": 5843200, "episode_reward": 0.2562851905822754, "value_loss": 0.006749440263956785, "policy_loss": -0.0016256729186544306, "dist_entropy": 0.36279118061065674, "actor_grad_norm": 0.14204531908035278, "critic_grad_norm": 0.06338584423065186, "ratio": 0.9998766183853149, "entropy": 0.36279118061065674, "incre_win_rate": 0.8333333333333334, "step": 1826}
{"time": 1767087385.6071665, "phase": "train", "update": 1827, "total_env_steps": 5846400, "episode_reward": 0.25006571412086487, "value_loss": 0.006795143708586693, "policy_loss": -0.0013597822661040482, "dist_entropy": 0.35260252356529237, "actor_grad_norm": 0.1681932508945465, "critic_grad_norm": 0.04815642535686493, "ratio": 0.9998859763145447, "entropy": 0.35260252356529237, "incre_win_rate": 0.8333333333333334, "step": 1827}
{"time": 1767087390.3845909, "phase": "train", "update": 1828, "total_env_steps": 5849600, "episode_reward": 0.23935790359973907, "value_loss": 0.009198676235973835, "policy_loss": -0.001288244504794278, "dist_entropy": 0.34824628829956056, "actor_grad_norm": 0.12534916400909424, "critic_grad_norm": 0.02521449886262417, "ratio": 0.9999204874038696, "entropy": 0.34824628829956056, "incre_win_rate": 0.6585365853658537, "step": 1828}
{"time": 1767087395.093177, "phase": "train", "update": 1829, "total_env_steps": 5852800, "episode_reward": 0.21728216111660004, "value_loss": 0.010429485328495502, "policy_loss": -0.0016350410783857682, "dist_entropy": 0.35928659439086913, "actor_grad_norm": 0.138235941529274, "critic_grad_norm": 0.05986999347805977, "ratio": 0.9999551177024841, "entropy": 0.35928659439086913, "incre_win_rate": 0.6923076923076923, "step": 1829}
{"time": 1767087399.8302681, "phase": "train", "update": 1830, "total_env_steps": 5856000, "episode_reward": 0.2355489581823349, "value_loss": 0.010919837839901447, "policy_loss": -0.0010995418731312157, "dist_entropy": 0.335511177778244, "actor_grad_norm": 0.1498323380947113, "critic_grad_norm": 0.05771152302622795, "ratio": 1.0002388954162598, "entropy": 0.335511177778244, "incre_win_rate": 0.6590909090909091, "step": 1830}
{"time": 1767087404.6056006, "phase": "train", "update": 1831, "total_env_steps": 5859200, "episode_reward": 0.24851565062999725, "value_loss": 0.009412646293640137, "policy_loss": -0.0011775846925878852, "dist_entropy": 0.3496695339679718, "actor_grad_norm": 0.11796661466360092, "critic_grad_norm": 0.0340103805065155, "ratio": 0.9998512268066406, "entropy": 0.3496695339679718, "incre_win_rate": 0.8048780487804879, "step": 1831}
{"time": 1767087409.6700678, "phase": "train", "update": 1832, "total_env_steps": 5862400, "episode_reward": 0.2328321486711502, "value_loss": 0.011037942208349704, "policy_loss": -0.001199116466600003, "dist_entropy": 0.35321357250213625, "actor_grad_norm": 0.12732966244220734, "critic_grad_norm": 0.07445768266916275, "ratio": 1.0002690553665161, "entropy": 0.35321357250213625, "incre_win_rate": 0.7, "step": 1832}
{"time": 1767087414.5953975, "phase": "train", "update": 1833, "total_env_steps": 5865600, "episode_reward": 0.22992290556430817, "value_loss": 0.010318621061742306, "policy_loss": -0.0013621738962946496, "dist_entropy": 0.3627622663974762, "actor_grad_norm": 0.15230391919612885, "critic_grad_norm": 0.07562588155269623, "ratio": 0.9998992085456848, "entropy": 0.3627622663974762, "incre_win_rate": 0.7317073170731707, "step": 1833}
{"time": 1767087419.800877, "phase": "train", "update": 1834, "total_env_steps": 5868800, "episode_reward": 0.2409985512495041, "value_loss": 0.009427271783351898, "policy_loss": -0.0012115508765603521, "dist_entropy": 0.3376933455467224, "actor_grad_norm": 0.13544073700904846, "critic_grad_norm": 0.07978574186563492, "ratio": 0.9998593330383301, "entropy": 0.3376933455467224, "incre_win_rate": 0.6829268292682927, "step": 1834}
{"time": 1767087424.995851, "phase": "train", "update": 1835, "total_env_steps": 5872000, "episode_reward": 0.23629139363765717, "value_loss": 0.011131971143186092, "policy_loss": -0.0017262016981803186, "dist_entropy": 0.3364560127258301, "actor_grad_norm": 0.18499958515167236, "critic_grad_norm": 0.034224092960357666, "ratio": 1.0001599788665771, "entropy": 0.3364560127258301, "incre_win_rate": 0.75, "step": 1835}
{"time": 1767087430.2308767, "phase": "train", "update": 1836, "total_env_steps": 5875200, "episode_reward": 0.2378745824098587, "value_loss": 0.00882684402167797, "policy_loss": -0.0014320530708626933, "dist_entropy": 0.350098979473114, "actor_grad_norm": 0.11852177232503891, "critic_grad_norm": 0.032649073749780655, "ratio": 0.9998224377632141, "entropy": 0.350098979473114, "incre_win_rate": 0.7142857142857143, "step": 1836}
{"time": 1767087435.5351331, "phase": "train", "update": 1837, "total_env_steps": 5878400, "episode_reward": 0.2537805438041687, "value_loss": 0.006645997520536184, "policy_loss": -0.001394485954455149, "dist_entropy": 0.35352171659469606, "actor_grad_norm": 0.09100190550088882, "critic_grad_norm": 0.041672173887491226, "ratio": 1.000066876411438, "entropy": 0.35352171659469606, "incre_win_rate": 0.8333333333333334, "step": 1837}
{"time": 1767087440.7667248, "phase": "train", "update": 1838, "total_env_steps": 5881600, "episode_reward": 0.22110822796821594, "value_loss": 0.010139638185501098, "policy_loss": -0.0016334706183741333, "dist_entropy": 0.3474343419075012, "actor_grad_norm": 0.12502749264240265, "critic_grad_norm": 0.09205732494592667, "ratio": 0.9998159408569336, "entropy": 0.3474343419075012, "incre_win_rate": 0.5853658536585366, "step": 1838}
{"time": 1767087445.971821, "phase": "train", "update": 1839, "total_env_steps": 5884800, "episode_reward": 0.23672136664390564, "value_loss": 0.010091044753789902, "policy_loss": -0.0012221543636733224, "dist_entropy": 0.3521214842796326, "actor_grad_norm": 0.15144146978855133, "critic_grad_norm": 0.06899876147508621, "ratio": 0.9998747110366821, "entropy": 0.3521214842796326, "incre_win_rate": 0.775, "step": 1839}
{"time": 1767087451.1138637, "phase": "train", "update": 1840, "total_env_steps": 5888000, "episode_reward": 0.24608394503593445, "value_loss": 0.006691214069724083, "policy_loss": -0.0019807104508760887, "dist_entropy": 0.3539207100868225, "actor_grad_norm": 0.1447114199399948, "critic_grad_norm": 0.06647483259439468, "ratio": 0.9998707175254822, "entropy": 0.3539207100868225, "incre_win_rate": 0.926829268292683, "step": 1840}
{"time": 1767087455.8735836, "phase": "train", "update": 1841, "total_env_steps": 5891200, "episode_reward": 0.2443341463804245, "value_loss": 0.007080826908349991, "policy_loss": -0.0011896629422281535, "dist_entropy": 0.34390034079551696, "actor_grad_norm": 0.1208040714263916, "critic_grad_norm": 0.03275777027010918, "ratio": 0.9996166229248047, "entropy": 0.34390034079551696, "incre_win_rate": 0.8095238095238095, "step": 1841}
{"time": 1767087466.7767582, "phase": "eval", "update": 1841, "total_env_steps": 5891200, "eval_win_rate": 0.875, "eval_episode_reward": 19.177514486754966, "step": 1841}
{"time": 1767087471.532948, "phase": "train", "update": 1842, "total_env_steps": 5894400, "episode_reward": 0.23657286167144775, "value_loss": 0.011112175323069096, "policy_loss": -0.001151361798048356, "dist_entropy": 0.33709155917167666, "actor_grad_norm": 0.11303257197141647, "critic_grad_norm": 0.08999558538198471, "ratio": 0.9998052716255188, "entropy": 0.33709155917167666, "incre_win_rate": 0.6585365853658537, "step": 1842}
{"time": 1767087476.2463944, "phase": "train", "update": 1843, "total_env_steps": 5897600, "episode_reward": 0.22635863721370697, "value_loss": 0.010460175201296806, "policy_loss": -0.0012286151977640714, "dist_entropy": 0.32934861779212954, "actor_grad_norm": 0.11402115970849991, "critic_grad_norm": 0.07496507465839386, "ratio": 0.99981290102005, "entropy": 0.32934861779212954, "incre_win_rate": 0.7, "step": 1843}
{"time": 1767087480.981015, "phase": "train", "update": 1844, "total_env_steps": 5900800, "episode_reward": 0.23512417078018188, "value_loss": 0.013729836046695709, "policy_loss": -0.00159404192840249, "dist_entropy": 0.32932751178741454, "actor_grad_norm": 0.14307010173797607, "critic_grad_norm": 0.0373283252120018, "ratio": 1.000129222869873, "entropy": 0.32932751178741454, "incre_win_rate": 0.6744186046511628, "step": 1844}
{"time": 1767087485.696692, "phase": "train", "update": 1845, "total_env_steps": 5904000, "episode_reward": 0.23785129189491272, "value_loss": 0.00885311309248209, "policy_loss": -0.0013652028083285471, "dist_entropy": 0.336192125082016, "actor_grad_norm": 0.15609459578990936, "critic_grad_norm": 0.03543975204229355, "ratio": 1.0004488229751587, "entropy": 0.336192125082016, "incre_win_rate": 0.7073170731707317, "step": 1845}
{"time": 1767087490.4508545, "phase": "train", "update": 1846, "total_env_steps": 5907200, "episode_reward": 0.24411216378211975, "value_loss": 0.010143784247338772, "policy_loss": -0.0013417228041760153, "dist_entropy": 0.3430450141429901, "actor_grad_norm": 0.1306047886610031, "critic_grad_norm": 0.02463514171540737, "ratio": 0.9999014735221863, "entropy": 0.3430450141429901, "incre_win_rate": 0.6829268292682927, "step": 1846}
{"time": 1767087495.191158, "phase": "train", "update": 1847, "total_env_steps": 5910400, "episode_reward": 0.2366809993982315, "value_loss": 0.008475257270038127, "policy_loss": -0.0016839369829952488, "dist_entropy": 0.3401753604412079, "actor_grad_norm": 0.12186636030673981, "critic_grad_norm": 0.047698017209768295, "ratio": 0.9999162554740906, "entropy": 0.3401753604412079, "incre_win_rate": 0.627906976744186, "step": 1847}
{"time": 1767087499.879953, "phase": "train", "update": 1848, "total_env_steps": 5913600, "episode_reward": 0.2288684844970703, "value_loss": 0.0117445794865489, "policy_loss": -0.0016197062594102362, "dist_entropy": 0.3549241960048676, "actor_grad_norm": 0.11259813606739044, "critic_grad_norm": 0.050583358854055405, "ratio": 0.9995970129966736, "entropy": 0.3549241960048676, "incre_win_rate": 0.717948717948718, "step": 1848}
{"time": 1767087504.616772, "phase": "train", "update": 1849, "total_env_steps": 5916800, "episode_reward": 0.23690500855445862, "value_loss": 0.01420772522687912, "policy_loss": -0.0009074842742570865, "dist_entropy": 0.34581137299537656, "actor_grad_norm": 0.13917672634124756, "critic_grad_norm": 0.05371204763650894, "ratio": 1.0000704526901245, "entropy": 0.34581137299537656, "incre_win_rate": 0.5909090909090909, "step": 1849}
{"time": 1767087509.3730302, "phase": "train", "update": 1850, "total_env_steps": 5920000, "episode_reward": 0.2472413182258606, "value_loss": 0.009856072254478931, "policy_loss": -0.0011690846893387175, "dist_entropy": 0.3422631800174713, "actor_grad_norm": 0.1146782860159874, "critic_grad_norm": 0.06610257923603058, "ratio": 1.0000457763671875, "entropy": 0.3422631800174713, "incre_win_rate": 0.6363636363636364, "step": 1850}
{"time": 1767087514.1101747, "phase": "train", "update": 1851, "total_env_steps": 5923200, "episode_reward": 0.2522987425327301, "value_loss": 0.00830636378377676, "policy_loss": -0.0009854186508832185, "dist_entropy": 0.33285124897956847, "actor_grad_norm": 0.1279364824295044, "critic_grad_norm": 0.045083463191986084, "ratio": 1.0001415014266968, "entropy": 0.33285124897956847, "incre_win_rate": 0.8181818181818182, "step": 1851}
{"time": 1767087518.8134115, "phase": "train", "update": 1852, "total_env_steps": 5926400, "episode_reward": 0.2364269495010376, "value_loss": 0.010429616272449493, "policy_loss": -0.0011809421115231088, "dist_entropy": 0.31981955766677855, "actor_grad_norm": 0.11006064713001251, "critic_grad_norm": 0.05776325985789299, "ratio": 1.0002546310424805, "entropy": 0.31981955766677855, "incre_win_rate": 0.675, "step": 1852}
{"time": 1767087523.532865, "phase": "train", "update": 1853, "total_env_steps": 5929600, "episode_reward": 0.22011537849903107, "value_loss": 0.013152796030044555, "policy_loss": -0.0009414087126479842, "dist_entropy": 0.34569568037986753, "actor_grad_norm": 0.12891852855682373, "critic_grad_norm": 0.04556054621934891, "ratio": 0.9999852180480957, "entropy": 0.34569568037986753, "incre_win_rate": 0.5365853658536586, "step": 1853}
{"time": 1767087528.2575617, "phase": "train", "update": 1854, "total_env_steps": 5932800, "episode_reward": 0.24800445139408112, "value_loss": 0.01089721042662859, "policy_loss": -0.0012827020326689365, "dist_entropy": 0.3262911200523376, "actor_grad_norm": 0.14781546592712402, "critic_grad_norm": 0.08036975562572479, "ratio": 1.0001139640808105, "entropy": 0.3262911200523376, "incre_win_rate": 0.7727272727272727, "step": 1854}
{"time": 1767087532.985511, "phase": "train", "update": 1855, "total_env_steps": 5936000, "episode_reward": 0.21930722892284393, "value_loss": 0.013279750570654869, "policy_loss": -0.0011989574322356588, "dist_entropy": 0.36068500876426696, "actor_grad_norm": 0.12289338558912277, "critic_grad_norm": 0.0856289491057396, "ratio": 0.9996083378791809, "entropy": 0.36068500876426696, "incre_win_rate": 0.5128205128205128, "step": 1855}
{"time": 1767087537.7792692, "phase": "train", "update": 1856, "total_env_steps": 5939200, "episode_reward": 0.24293461441993713, "value_loss": 0.011086690798401832, "policy_loss": -0.0012267519156051066, "dist_entropy": 0.3394252061843872, "actor_grad_norm": 0.1277005821466446, "critic_grad_norm": 0.05803874135017395, "ratio": 0.9996358156204224, "entropy": 0.3394252061843872, "incre_win_rate": 0.7209302325581395, "step": 1856}
{"time": 1767087542.6316683, "phase": "train", "update": 1857, "total_env_steps": 5942400, "episode_reward": 0.2304987758398056, "value_loss": 0.011274943687021732, "policy_loss": -0.0013746796337855472, "dist_entropy": 0.3553612470626831, "actor_grad_norm": 0.13118357956409454, "critic_grad_norm": 0.03322385996580124, "ratio": 1.0000908374786377, "entropy": 0.3553612470626831, "incre_win_rate": 0.5476190476190477, "step": 1857}
{"time": 1767087547.37217, "phase": "train", "update": 1858, "total_env_steps": 5945600, "episode_reward": 0.2411305010318756, "value_loss": 0.011453896202147007, "policy_loss": -0.0013915780729854888, "dist_entropy": 0.3472855925559998, "actor_grad_norm": 0.09151384979486465, "critic_grad_norm": 0.05419822409749031, "ratio": 0.9996430277824402, "entropy": 0.3472855925559998, "incre_win_rate": 0.7142857142857143, "step": 1858}
{"time": 1767087552.3194222, "phase": "train", "update": 1859, "total_env_steps": 5948800, "episode_reward": 0.24582991003990173, "value_loss": 0.008494501933455467, "policy_loss": -0.0010860533995050048, "dist_entropy": 0.35374361276626587, "actor_grad_norm": 0.09454236924648285, "critic_grad_norm": 0.04896998032927513, "ratio": 0.999969482421875, "entropy": 0.35374361276626587, "incre_win_rate": 0.6976744186046512, "step": 1859}
{"time": 1767087557.0542967, "phase": "train", "update": 1860, "total_env_steps": 5952000, "episode_reward": 0.246526300907135, "value_loss": 0.009980814345180989, "policy_loss": -0.0011924429954381032, "dist_entropy": 0.35556658506393435, "actor_grad_norm": 0.10079294443130493, "critic_grad_norm": 0.047865163534879684, "ratio": 1.0001119375228882, "entropy": 0.35556658506393435, "incre_win_rate": 0.7441860465116279, "step": 1860}
{"time": 1767087561.7994065, "phase": "train", "update": 1861, "total_env_steps": 5955200, "episode_reward": 0.22825486958026886, "value_loss": 0.012426427565515041, "policy_loss": -0.0012626368146257505, "dist_entropy": 0.3551989495754242, "actor_grad_norm": 0.13833217322826385, "critic_grad_norm": 0.03984919935464859, "ratio": 1.0000394582748413, "entropy": 0.3551989495754242, "incre_win_rate": 0.6666666666666666, "step": 1861}
{"time": 1767087572.981013, "phase": "eval", "update": 1861, "total_env_steps": 5955200, "eval_win_rate": 0.8125, "eval_episode_reward": 18.980753311258276, "step": 1861}
{"time": 1767087577.6742864, "phase": "train", "update": 1862, "total_env_steps": 5958400, "episode_reward": 0.24642540514469147, "value_loss": 0.009385187923908234, "policy_loss": -0.0012756497317361949, "dist_entropy": 0.3354342818260193, "actor_grad_norm": 0.14394669234752655, "critic_grad_norm": 0.12121522426605225, "ratio": 1.0001649856567383, "entropy": 0.3354342818260193, "incre_win_rate": 0.75, "step": 1862}
{"time": 1767087582.387736, "phase": "train", "update": 1863, "total_env_steps": 5961600, "episode_reward": 0.23254244029521942, "value_loss": 0.008299826830625533, "policy_loss": -0.0013434873402495384, "dist_entropy": 0.36468765139579773, "actor_grad_norm": 0.10018692165613174, "critic_grad_norm": 0.08133188635110855, "ratio": 1.0001322031021118, "entropy": 0.36468765139579773, "incre_win_rate": 0.717948717948718, "step": 1863}
{"time": 1767087587.1083174, "phase": "train", "update": 1864, "total_env_steps": 5964800, "episode_reward": 0.2430913746356964, "value_loss": 0.008709850907325744, "policy_loss": -0.0012692262405792575, "dist_entropy": 0.3357126832008362, "actor_grad_norm": 0.14485551416873932, "critic_grad_norm": 0.04441240057349205, "ratio": 0.9998990893363953, "entropy": 0.3357126832008362, "incre_win_rate": 0.7045454545454546, "step": 1864}
{"time": 1767087591.8957658, "phase": "train", "update": 1865, "total_env_steps": 5968000, "episode_reward": 0.2540123164653778, "value_loss": 0.008761576376855373, "policy_loss": -0.0013421015071145349, "dist_entropy": 0.351763641834259, "actor_grad_norm": 0.1019299253821373, "critic_grad_norm": 0.031015200540423393, "ratio": 1.0001418590545654, "entropy": 0.351763641834259, "incre_win_rate": 0.7560975609756098, "step": 1865}
{"time": 1767087596.6649926, "phase": "train", "update": 1866, "total_env_steps": 5971200, "episode_reward": 0.2353927046060562, "value_loss": 0.009335256740450859, "policy_loss": -0.0010743672426769102, "dist_entropy": 0.35568744540214536, "actor_grad_norm": 0.13065330684185028, "critic_grad_norm": 0.024832667782902718, "ratio": 1.0003165006637573, "entropy": 0.35568744540214536, "incre_win_rate": 0.6976744186046512, "step": 1866}
{"time": 1767087601.5874455, "phase": "train", "update": 1867, "total_env_steps": 5974400, "episode_reward": 0.23966889083385468, "value_loss": 0.00916973538696766, "policy_loss": -0.0017004100464134808, "dist_entropy": 0.36735799908638, "actor_grad_norm": 0.1300799548625946, "critic_grad_norm": 0.027582461014389992, "ratio": 1.000048279762268, "entropy": 0.36735799908638, "incre_win_rate": 0.6829268292682927, "step": 1867}
{"time": 1767087606.600068, "phase": "train", "update": 1868, "total_env_steps": 5977600, "episode_reward": 0.24044859409332275, "value_loss": 0.00835441667586565, "policy_loss": -0.001347940725073471, "dist_entropy": 0.3491754114627838, "actor_grad_norm": 0.1395130157470703, "critic_grad_norm": 0.03238527104258537, "ratio": 0.9995366334915161, "entropy": 0.3491754114627838, "incre_win_rate": 0.6363636363636364, "step": 1868}
{"time": 1767087611.3128097, "phase": "train", "update": 1869, "total_env_steps": 5980800, "episode_reward": 0.25940966606140137, "value_loss": 0.007339994888752699, "policy_loss": -0.001562603053464784, "dist_entropy": 0.3514612913131714, "actor_grad_norm": 0.13276128470897675, "critic_grad_norm": 0.03995336964726448, "ratio": 1.0000221729278564, "entropy": 0.3514612913131714, "incre_win_rate": 0.8333333333333334, "step": 1869}
{"time": 1767087616.0114348, "phase": "train", "update": 1870, "total_env_steps": 5984000, "episode_reward": 0.22265057265758514, "value_loss": 0.011132355406880378, "policy_loss": -0.0011788950045627188, "dist_entropy": 0.3641269087791443, "actor_grad_norm": 0.1344129592180252, "critic_grad_norm": 0.03963140770792961, "ratio": 0.9997633099555969, "entropy": 0.3641269087791443, "incre_win_rate": 0.7073170731707317, "step": 1870}
{"time": 1767087620.6835346, "phase": "train", "update": 1871, "total_env_steps": 5987200, "episode_reward": 0.24187499284744263, "value_loss": 0.01099300179630518, "policy_loss": -0.0012857465748922436, "dist_entropy": 0.36123569011688234, "actor_grad_norm": 0.14774015545845032, "critic_grad_norm": 0.029409309849143028, "ratio": 0.9997214674949646, "entropy": 0.36123569011688234, "incre_win_rate": 0.7435897435897436, "step": 1871}
{"time": 1767087625.4987326, "phase": "train", "update": 1872, "total_env_steps": 5990400, "episode_reward": 0.23541027307510376, "value_loss": 0.009657173044979572, "policy_loss": -0.0014717078348454038, "dist_entropy": 0.36552904844284057, "actor_grad_norm": 0.12531660497188568, "critic_grad_norm": 0.028324587270617485, "ratio": 1.000035285949707, "entropy": 0.36552904844284057, "incre_win_rate": 0.5909090909090909, "step": 1872}
{"time": 1767087630.1855187, "phase": "train", "update": 1873, "total_env_steps": 5993600, "episode_reward": 0.2389994114637375, "value_loss": 0.007091363240033388, "policy_loss": -0.0012372520825245203, "dist_entropy": 0.35374548435211184, "actor_grad_norm": 0.13193732500076294, "critic_grad_norm": 0.018962720409035683, "ratio": 0.9993559122085571, "entropy": 0.35374548435211184, "incre_win_rate": 0.7073170731707317, "step": 1873}
{"time": 1767087634.8428364, "phase": "train", "update": 1874, "total_env_steps": 5996800, "episode_reward": 0.21060794591903687, "value_loss": 0.012313961423933506, "policy_loss": -0.0013016932571158434, "dist_entropy": 0.3781844139099121, "actor_grad_norm": 0.10947854816913605, "critic_grad_norm": 0.07574345171451569, "ratio": 0.9999330639839172, "entropy": 0.3781844139099121, "incre_win_rate": 0.5641025641025641, "step": 1874}
{"time": 1767087639.6227741, "phase": "train", "update": 1875, "total_env_steps": 6000000, "episode_reward": 0.2359670102596283, "value_loss": 0.012892225198447705, "policy_loss": -0.001212754178506792, "dist_entropy": 0.36526267528533934, "actor_grad_norm": 0.11466483026742935, "critic_grad_norm": 0.07182477414608002, "ratio": 0.9998604655265808, "entropy": 0.36526267528533934, "incre_win_rate": 0.5, "step": 1875}
{"time": 1767087644.3898964, "phase": "train", "update": 1876, "total_env_steps": 6003200, "episode_reward": 0.24795271456241608, "value_loss": 0.009881730936467648, "policy_loss": -0.0010736153735962262, "dist_entropy": 0.3514478147029877, "actor_grad_norm": 0.1171858087182045, "critic_grad_norm": 0.04225572943687439, "ratio": 1.000110387802124, "entropy": 0.3514478147029877, "incre_win_rate": 0.7209302325581395, "step": 1876}
{"time": 1767087649.0640547, "phase": "train", "update": 1877, "total_env_steps": 6006400, "episode_reward": 0.23072746396064758, "value_loss": 0.009601367823779582, "policy_loss": -0.0014393750409311679, "dist_entropy": 0.35557687282562256, "actor_grad_norm": 0.14071200788021088, "critic_grad_norm": 0.04789261892437935, "ratio": 0.9995737075805664, "entropy": 0.35557687282562256, "incre_win_rate": 0.5365853658536586, "step": 1877}
{"time": 1767087653.8178267, "phase": "train", "update": 1878, "total_env_steps": 6009600, "episode_reward": 0.24384211003780365, "value_loss": 0.00939379632472992, "policy_loss": -0.0008239256791881644, "dist_entropy": 0.3470519185066223, "actor_grad_norm": 0.12107069790363312, "critic_grad_norm": 0.04791265353560448, "ratio": 0.9997885823249817, "entropy": 0.3470519185066223, "incre_win_rate": 0.7209302325581395, "step": 1878}
{"time": 1767087658.5701814, "phase": "train", "update": 1879, "total_env_steps": 6012800, "episode_reward": 0.23703227937221527, "value_loss": 0.010406071506440639, "policy_loss": -0.0013622605262455067, "dist_entropy": 0.351527202129364, "actor_grad_norm": 0.13741786777973175, "critic_grad_norm": 0.038097407668828964, "ratio": 0.9998548626899719, "entropy": 0.351527202129364, "incre_win_rate": 0.6904761904761905, "step": 1879}
{"time": 1767087663.457544, "phase": "train", "update": 1880, "total_env_steps": 6016000, "episode_reward": 0.23733703792095184, "value_loss": 0.01011930163949728, "policy_loss": -0.0009392588580282357, "dist_entropy": 0.36287997364997865, "actor_grad_norm": 0.11900116503238678, "critic_grad_norm": 0.02488073706626892, "ratio": 0.9997620582580566, "entropy": 0.36287997364997865, "incre_win_rate": 0.7142857142857143, "step": 1880}
{"time": 1767087668.1990514, "phase": "train", "update": 1881, "total_env_steps": 6019200, "episode_reward": 0.22313690185546875, "value_loss": 0.016395367868244647, "policy_loss": -0.0012994845569494374, "dist_entropy": 0.3695694863796234, "actor_grad_norm": 0.14607200026512146, "critic_grad_norm": 0.15972371399402618, "ratio": 0.9997751116752625, "entropy": 0.3695694863796234, "incre_win_rate": 0.5, "step": 1881}
{"time": 1767087679.238486, "phase": "eval", "update": 1881, "total_env_steps": 6019200, "eval_win_rate": 0.71875, "eval_episode_reward": 18.525558774834437, "step": 1881}
{"time": 1767087683.9659832, "phase": "train", "update": 1882, "total_env_steps": 6022400, "episode_reward": 0.24537666141986847, "value_loss": 0.010229831002652645, "policy_loss": -0.0012208167000657966, "dist_entropy": 0.36719260215759275, "actor_grad_norm": 0.10460076481103897, "critic_grad_norm": 0.09098529815673828, "ratio": 0.9999933242797852, "entropy": 0.36719260215759275, "incre_win_rate": 0.6097560975609756, "step": 1882}
{"time": 1767087688.643797, "phase": "train", "update": 1883, "total_env_steps": 6025600, "episode_reward": 0.2444526106119156, "value_loss": 0.005771593004465103, "policy_loss": -0.001001093526441821, "dist_entropy": 0.3756898880004883, "actor_grad_norm": 0.1177755817770958, "critic_grad_norm": 0.05275264009833336, "ratio": 0.999711811542511, "entropy": 0.3756898880004883, "incre_win_rate": 0.7441860465116279, "step": 1883}
{"time": 1767087693.3598166, "phase": "train", "update": 1884, "total_env_steps": 6028800, "episode_reward": 0.23491308093070984, "value_loss": 0.008846593461930752, "policy_loss": -0.001665391050497078, "dist_entropy": 0.38604047894477844, "actor_grad_norm": 0.125178262591362, "critic_grad_norm": 0.04594961553812027, "ratio": 1.0000966787338257, "entropy": 0.38604047894477844, "incre_win_rate": 0.6923076923076923, "step": 1884}
{"time": 1767087698.0655155, "phase": "train", "update": 1885, "total_env_steps": 6032000, "episode_reward": 0.2218206822872162, "value_loss": 0.009472862258553505, "policy_loss": -0.001185238823642898, "dist_entropy": 0.384267121553421, "actor_grad_norm": 0.1235080137848854, "critic_grad_norm": 0.11233406513929367, "ratio": 0.9997482299804688, "entropy": 0.384267121553421, "incre_win_rate": 0.5609756097560976, "step": 1885}
{"time": 1767087702.8345783, "phase": "train", "update": 1886, "total_env_steps": 6035200, "episode_reward": 0.2610539495944977, "value_loss": 0.007510545756667852, "policy_loss": -0.0010979592264291683, "dist_entropy": 0.3650137186050415, "actor_grad_norm": 0.12569454312324524, "critic_grad_norm": 0.07592923194169998, "ratio": 1.0002955198287964, "entropy": 0.3650137186050415, "incre_win_rate": 0.7777777777777778, "step": 1886}
{"time": 1767087707.5079095, "phase": "train", "update": 1887, "total_env_steps": 6038400, "episode_reward": 0.23070365190505981, "value_loss": 0.009051375091075897, "policy_loss": -0.0012345006333191577, "dist_entropy": 0.38300507664680483, "actor_grad_norm": 0.12014728784561157, "critic_grad_norm": 0.04575393721461296, "ratio": 1.0000802278518677, "entropy": 0.38300507664680483, "incre_win_rate": 0.6486486486486487, "step": 1887}
{"time": 1767087712.2321851, "phase": "train", "update": 1888, "total_env_steps": 6041600, "episode_reward": 0.2160709798336029, "value_loss": 0.009872928448021411, "policy_loss": -0.0015098380945715918, "dist_entropy": 0.3747995734214783, "actor_grad_norm": 0.12577708065509796, "critic_grad_norm": 0.029093656688928604, "ratio": 1.0000208616256714, "entropy": 0.3747995734214783, "incre_win_rate": 0.6829268292682927, "step": 1888}
{"time": 1767087716.9731998, "phase": "train", "update": 1889, "total_env_steps": 6044800, "episode_reward": 0.24318191409111023, "value_loss": 0.008915061876177788, "policy_loss": -0.0012377626760681436, "dist_entropy": 0.35628021955490113, "actor_grad_norm": 0.14038953185081482, "critic_grad_norm": 0.03463139757514, "ratio": 0.9998656511306763, "entropy": 0.35628021955490113, "incre_win_rate": 0.6666666666666666, "step": 1889}
{"time": 1767087721.6948612, "phase": "train", "update": 1890, "total_env_steps": 6048000, "episode_reward": 0.2338731437921524, "value_loss": 0.00984854083508253, "policy_loss": -0.00135276264791937, "dist_entropy": 0.36309415102005005, "actor_grad_norm": 0.13711659610271454, "critic_grad_norm": 0.02815472148358822, "ratio": 0.9997780919075012, "entropy": 0.36309415102005005, "incre_win_rate": 0.6341463414634146, "step": 1890}
{"time": 1767087726.4206977, "phase": "train", "update": 1891, "total_env_steps": 6051200, "episode_reward": 0.23926585912704468, "value_loss": 0.008551598154008388, "policy_loss": -0.001158661416781115, "dist_entropy": 0.37357224225997926, "actor_grad_norm": 0.10923466831445694, "critic_grad_norm": 0.030738135799765587, "ratio": 0.9999969601631165, "entropy": 0.37357224225997926, "incre_win_rate": 0.6097560975609756, "step": 1891}
{"time": 1767087731.1529276, "phase": "train", "update": 1892, "total_env_steps": 6054400, "episode_reward": 0.23898179829120636, "value_loss": 0.009626192785799504, "policy_loss": -0.0012628837956278004, "dist_entropy": 0.36054853200912473, "actor_grad_norm": 0.1123698279261589, "critic_grad_norm": 0.041572410613298416, "ratio": 0.9999710321426392, "entropy": 0.36054853200912473, "incre_win_rate": 0.627906976744186, "step": 1892}
{"time": 1767087735.8606732, "phase": "train", "update": 1893, "total_env_steps": 6057600, "episode_reward": 0.23701728880405426, "value_loss": 0.01239552889019251, "policy_loss": -0.001248077224416022, "dist_entropy": 0.37005649209022523, "actor_grad_norm": 0.14473995566368103, "critic_grad_norm": 0.030762633308768272, "ratio": 0.9999673962593079, "entropy": 0.37005649209022523, "incre_win_rate": 0.7073170731707317, "step": 1893}
{"time": 1767087740.453529, "phase": "train", "update": 1894, "total_env_steps": 6060800, "episode_reward": 0.1947123408317566, "value_loss": 0.011716749891638756, "policy_loss": -0.001313544608218109, "dist_entropy": 0.3695526897907257, "actor_grad_norm": 0.12977775931358337, "critic_grad_norm": 0.03136317804455757, "ratio": 0.9999650120735168, "entropy": 0.3695526897907257, "incre_win_rate": 0.47368421052631576, "step": 1894}
{"time": 1767087745.26771, "phase": "train", "update": 1895, "total_env_steps": 6064000, "episode_reward": 0.24383848905563354, "value_loss": 0.009411940351128578, "policy_loss": -0.001011705523519879, "dist_entropy": 0.36558595299720764, "actor_grad_norm": 0.13468025624752045, "critic_grad_norm": 0.06539871543645859, "ratio": 0.9999626278877258, "entropy": 0.36558595299720764, "incre_win_rate": 0.6585365853658537, "step": 1895}
{"time": 1767087750.0356429, "phase": "train", "update": 1896, "total_env_steps": 6067200, "episode_reward": 0.23872776329517365, "value_loss": 0.008778545074164867, "policy_loss": -0.0008654715429031512, "dist_entropy": 0.3624534606933594, "actor_grad_norm": 0.10697861015796661, "critic_grad_norm": 0.04930126667022705, "ratio": 1.0003197193145752, "entropy": 0.3624534606933594, "incre_win_rate": 0.6666666666666666, "step": 1896}
{"time": 1767087754.7814796, "phase": "train", "update": 1897, "total_env_steps": 6070400, "episode_reward": 0.24773387610912323, "value_loss": 0.008513910695910454, "policy_loss": -0.0012974451191084314, "dist_entropy": 0.3527584671974182, "actor_grad_norm": 0.13262750208377838, "critic_grad_norm": 0.045434556901454926, "ratio": 0.9995638728141785, "entropy": 0.3527584671974182, "incre_win_rate": 0.7727272727272727, "step": 1897}
{"time": 1767087759.50945, "phase": "train", "update": 1898, "total_env_steps": 6073600, "episode_reward": 0.24451935291290283, "value_loss": 0.00748177757486701, "policy_loss": -0.001103575929258227, "dist_entropy": 0.35121634006500246, "actor_grad_norm": 0.1439320594072342, "critic_grad_norm": 0.06064079329371452, "ratio": 1.000096321105957, "entropy": 0.35121634006500246, "incre_win_rate": 0.7105263157894737, "step": 1898}
{"time": 1767087764.244944, "phase": "train", "update": 1899, "total_env_steps": 6076800, "episode_reward": 0.23171772062778473, "value_loss": 0.00887063778936863, "policy_loss": -0.0012671967829263053, "dist_entropy": 0.36137444972991944, "actor_grad_norm": 0.1305558979511261, "critic_grad_norm": 0.06570861488580704, "ratio": 0.9997376799583435, "entropy": 0.36137444972991944, "incre_win_rate": 0.7142857142857143, "step": 1899}
{"time": 1767087768.9432316, "phase": "train", "update": 1900, "total_env_steps": 6080000, "episode_reward": 0.23631879687309265, "value_loss": 0.010251177847385407, "policy_loss": -0.0013384161264696104, "dist_entropy": 0.36309981942176817, "actor_grad_norm": 0.12061744183301926, "critic_grad_norm": 0.078567735850811, "ratio": 0.9998778700828552, "entropy": 0.36309981942176817, "incre_win_rate": 0.5348837209302325, "step": 1900}
{"time": 1767087773.6371865, "phase": "train", "update": 1901, "total_env_steps": 6083200, "episode_reward": 0.23129864037036896, "value_loss": 0.009753730334341525, "policy_loss": -0.0014844810462209424, "dist_entropy": 0.3715116739273071, "actor_grad_norm": 0.13092292845249176, "critic_grad_norm": 0.031306251883506775, "ratio": 0.9996564984321594, "entropy": 0.3715116739273071, "incre_win_rate": 0.717948717948718, "step": 1901}
{"time": 1767087784.547629, "phase": "eval", "update": 1901, "total_env_steps": 6083200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.672081953642383, "step": 1901}
{"time": 1767087789.3168314, "phase": "train", "update": 1902, "total_env_steps": 6086400, "episode_reward": 0.2431488037109375, "value_loss": 0.01077587939798832, "policy_loss": -0.0013348779589250626, "dist_entropy": 0.3551490306854248, "actor_grad_norm": 0.13329802453517914, "critic_grad_norm": 0.03359837085008621, "ratio": 1.000160813331604, "entropy": 0.3551490306854248, "incre_win_rate": 0.6511627906976745, "step": 1902}
{"time": 1767087794.0418909, "phase": "train", "update": 1903, "total_env_steps": 6089600, "episode_reward": 0.2248184084892273, "value_loss": 0.0137929430231452, "policy_loss": -0.0013588817095552485, "dist_entropy": 0.3752503156661987, "actor_grad_norm": 0.15902332961559296, "critic_grad_norm": 0.029725363478064537, "ratio": 0.9998558163642883, "entropy": 0.3752503156661987, "incre_win_rate": 0.5365853658536586, "step": 1903}
{"time": 1767087798.782268, "phase": "train", "update": 1904, "total_env_steps": 6092800, "episode_reward": 0.24706746637821198, "value_loss": 0.008316141739487647, "policy_loss": -0.0011106681022440058, "dist_entropy": 0.3557801365852356, "actor_grad_norm": 0.12236332148313522, "critic_grad_norm": 0.08223073184490204, "ratio": 0.999944806098938, "entropy": 0.3557801365852356, "incre_win_rate": 0.8095238095238095, "step": 1904}
{"time": 1767087803.577616, "phase": "train", "update": 1905, "total_env_steps": 6096000, "episode_reward": 0.25116825103759766, "value_loss": 0.009371613897383214, "policy_loss": -0.0011455467133600905, "dist_entropy": 0.3815541803836823, "actor_grad_norm": 0.12043465673923492, "critic_grad_norm": 0.054776836186647415, "ratio": 1.0000126361846924, "entropy": 0.3815541803836823, "incre_win_rate": 0.7209302325581395, "step": 1905}
{"time": 1767087808.3300211, "phase": "train", "update": 1906, "total_env_steps": 6099200, "episode_reward": 0.2536931037902832, "value_loss": 0.00740766953676939, "policy_loss": -0.0010519665372953567, "dist_entropy": 0.3498967170715332, "actor_grad_norm": 0.10744493454694748, "critic_grad_norm": 0.052834101021289825, "ratio": 0.9997264742851257, "entropy": 0.3498967170715332, "incre_win_rate": 0.7441860465116279, "step": 1906}
{"time": 1767087813.0412946, "phase": "train", "update": 1907, "total_env_steps": 6102400, "episode_reward": 0.2450983077287674, "value_loss": 0.01126665212213993, "policy_loss": -0.0013961840406004455, "dist_entropy": 0.3582258880138397, "actor_grad_norm": 0.13634872436523438, "critic_grad_norm": 0.05341292545199394, "ratio": 0.9998279809951782, "entropy": 0.3582258880138397, "incre_win_rate": 0.75, "step": 1907}
{"time": 1767087817.9456115, "phase": "train", "update": 1908, "total_env_steps": 6105600, "episode_reward": 0.2335430532693863, "value_loss": 0.011360507644712924, "policy_loss": -0.001241766446055692, "dist_entropy": 0.3536351084709167, "actor_grad_norm": 0.14061573147773743, "critic_grad_norm": 0.03999838978052139, "ratio": 1.0001940727233887, "entropy": 0.3536351084709167, "incre_win_rate": 0.6341463414634146, "step": 1908}
{"time": 1767087822.6433442, "phase": "train", "update": 1909, "total_env_steps": 6108800, "episode_reward": 0.24481943249702454, "value_loss": 0.008851690962910653, "policy_loss": -0.001175984181604406, "dist_entropy": 0.35715541839599607, "actor_grad_norm": 0.14211095869541168, "critic_grad_norm": 0.040590476244688034, "ratio": 0.9997186064720154, "entropy": 0.35715541839599607, "incre_win_rate": 0.7380952380952381, "step": 1909}
{"time": 1767087827.4602263, "phase": "train", "update": 1910, "total_env_steps": 6112000, "episode_reward": 0.2606689929962158, "value_loss": 0.011544307135045529, "policy_loss": -0.001530388743741895, "dist_entropy": 0.35280110239982604, "actor_grad_norm": 0.1738758534193039, "critic_grad_norm": 0.04711060971021652, "ratio": 0.9999138116836548, "entropy": 0.35280110239982604, "incre_win_rate": 0.7272727272727273, "step": 1910}
{"time": 1767087832.1516142, "phase": "train", "update": 1911, "total_env_steps": 6115200, "episode_reward": 0.2070276290178299, "value_loss": 0.011345253139734269, "policy_loss": -0.0013691556158960338, "dist_entropy": 0.38142303228378294, "actor_grad_norm": 0.1449727714061737, "critic_grad_norm": 0.030127454549074173, "ratio": 1.0003141164779663, "entropy": 0.38142303228378294, "incre_win_rate": 0.5675675675675675, "step": 1911}
{"time": 1767087836.9643438, "phase": "train", "update": 1912, "total_env_steps": 6118400, "episode_reward": 0.23615999519824982, "value_loss": 0.012133512832224368, "policy_loss": -0.001381291002032725, "dist_entropy": 0.368888795375824, "actor_grad_norm": 0.12005779892206192, "critic_grad_norm": 0.03073207475244999, "ratio": 0.9998086094856262, "entropy": 0.368888795375824, "incre_win_rate": 0.6511627906976745, "step": 1912}
{"time": 1767087841.7269886, "phase": "train", "update": 1913, "total_env_steps": 6121600, "episode_reward": 0.2352721393108368, "value_loss": 0.010170957073569298, "policy_loss": -0.0013718890432386388, "dist_entropy": 0.3887990415096283, "actor_grad_norm": 0.15608586370944977, "critic_grad_norm": 0.03221222758293152, "ratio": 0.9999210238456726, "entropy": 0.3887990415096283, "incre_win_rate": 0.6666666666666666, "step": 1913}
{"time": 1767087846.4545906, "phase": "train", "update": 1914, "total_env_steps": 6124800, "episode_reward": 0.23931965231895447, "value_loss": 0.010538299940526486, "policy_loss": -0.0010536854682211328, "dist_entropy": 0.38050506114959715, "actor_grad_norm": 0.12700961530208588, "critic_grad_norm": 0.032470375299453735, "ratio": 0.9998942613601685, "entropy": 0.38050506114959715, "incre_win_rate": 0.725, "step": 1914}
{"time": 1767087851.1946895, "phase": "train", "update": 1915, "total_env_steps": 6128000, "episode_reward": 0.2409675270318985, "value_loss": 0.007975715212523937, "policy_loss": -0.001373266765806136, "dist_entropy": 0.3688972949981689, "actor_grad_norm": 0.13896803557872772, "critic_grad_norm": 0.025798458606004715, "ratio": 1.000122308731079, "entropy": 0.3688972949981689, "incre_win_rate": 0.6590909090909091, "step": 1915}
{"time": 1767087855.9576218, "phase": "train", "update": 1916, "total_env_steps": 6131200, "episode_reward": 0.24551787972450256, "value_loss": 0.00729592377319932, "policy_loss": -0.0012850173549196597, "dist_entropy": 0.36448808908462527, "actor_grad_norm": 0.15608251094818115, "critic_grad_norm": 0.05780337005853653, "ratio": 0.9999859929084778, "entropy": 0.36448808908462527, "incre_win_rate": 0.8536585365853658, "step": 1916}
{"time": 1767087860.6806593, "phase": "train", "update": 1917, "total_env_steps": 6134400, "episode_reward": 0.24650299549102783, "value_loss": 0.009424006566405296, "policy_loss": -0.0012815128555615728, "dist_entropy": 0.35970139503479004, "actor_grad_norm": 0.12717843055725098, "critic_grad_norm": 0.062326427549123764, "ratio": 0.999509334564209, "entropy": 0.35970139503479004, "incre_win_rate": 0.7560975609756098, "step": 1917}
{"time": 1767087865.4232156, "phase": "train", "update": 1918, "total_env_steps": 6137600, "episode_reward": 0.2492022067308426, "value_loss": 0.00810402985662222, "policy_loss": -0.0010421514357901174, "dist_entropy": 0.3659616470336914, "actor_grad_norm": 0.10413037985563278, "critic_grad_norm": 0.03551754355430603, "ratio": 0.9995908141136169, "entropy": 0.3659616470336914, "incre_win_rate": 0.7857142857142857, "step": 1918}
{"time": 1767087870.226748, "phase": "train", "update": 1919, "total_env_steps": 6140800, "episode_reward": 0.2573106586933136, "value_loss": 0.006211917102336884, "policy_loss": -0.0013499154878786612, "dist_entropy": 0.3752756416797638, "actor_grad_norm": 0.14405976235866547, "critic_grad_norm": 0.022872796282172203, "ratio": 0.9997835159301758, "entropy": 0.3752756416797638, "incre_win_rate": 0.8837209302325582, "step": 1919}
{"time": 1767087874.963555, "phase": "train", "update": 1920, "total_env_steps": 6144000, "episode_reward": 0.2414988875389099, "value_loss": 0.00899242889136076, "policy_loss": -0.001281179100114116, "dist_entropy": 0.37717023491859436, "actor_grad_norm": 0.17266161739826202, "critic_grad_norm": 0.03420607000589371, "ratio": 0.9998292326927185, "entropy": 0.37717023491859436, "incre_win_rate": 0.7560975609756098, "step": 1920}
{"time": 1767087879.7163303, "phase": "train", "update": 1921, "total_env_steps": 6147200, "episode_reward": 0.2436128854751587, "value_loss": 0.010109546221792698, "policy_loss": -0.0010973361274757565, "dist_entropy": 0.354813951253891, "actor_grad_norm": 0.12384004890918732, "critic_grad_norm": 0.053028710186481476, "ratio": 1.0000025033950806, "entropy": 0.354813951253891, "incre_win_rate": 0.6428571428571429, "step": 1921}
{"time": 1767087890.528555, "phase": "eval", "update": 1921, "total_env_steps": 6147200, "eval_win_rate": 0.8125, "eval_episode_reward": 18.91432119205298, "step": 1921}
{"time": 1767087895.3558166, "phase": "train", "update": 1922, "total_env_steps": 6150400, "episode_reward": 0.2448023557662964, "value_loss": 0.009478826448321343, "policy_loss": -0.0017805343295094645, "dist_entropy": 0.3652027308940887, "actor_grad_norm": 0.1335524171590805, "critic_grad_norm": 0.049478061497211456, "ratio": 1.000193476676941, "entropy": 0.3652027308940887, "incre_win_rate": 0.7380952380952381, "step": 1922}
{"time": 1767087900.2409055, "phase": "train", "update": 1923, "total_env_steps": 6153600, "episode_reward": 0.24837853014469147, "value_loss": 0.009449769742786884, "policy_loss": -0.0014621894355443033, "dist_entropy": 0.3693650484085083, "actor_grad_norm": 0.1354287713766098, "critic_grad_norm": 0.044899869710206985, "ratio": 1.0001347064971924, "entropy": 0.3693650484085083, "incre_win_rate": 0.75, "step": 1923}
{"time": 1767087904.9719853, "phase": "train", "update": 1924, "total_env_steps": 6156800, "episode_reward": 0.2435441017150879, "value_loss": 0.008060993254184723, "policy_loss": -0.0016030718249027132, "dist_entropy": 0.36179556846618655, "actor_grad_norm": 0.15402431786060333, "critic_grad_norm": 0.0409812405705452, "ratio": 0.9995982050895691, "entropy": 0.36179556846618655, "incre_win_rate": 0.8, "step": 1924}
{"time": 1767087909.9896173, "phase": "train", "update": 1925, "total_env_steps": 6160000, "episode_reward": 0.2453073263168335, "value_loss": 0.007819745410233735, "policy_loss": -0.001427134395915175, "dist_entropy": 0.3814211845397949, "actor_grad_norm": 0.12977294623851776, "critic_grad_norm": 0.03255443647503853, "ratio": 0.9997349977493286, "entropy": 0.3814211845397949, "incre_win_rate": 0.7142857142857143, "step": 1925}
{"time": 1767087914.9196644, "phase": "train", "update": 1926, "total_env_steps": 6163200, "episode_reward": 0.23043617606163025, "value_loss": 0.01086567360907793, "policy_loss": -0.0013795638591858506, "dist_entropy": 0.3830309212207794, "actor_grad_norm": 0.1248866468667984, "critic_grad_norm": 0.07493364065885544, "ratio": 0.9998232126235962, "entropy": 0.3830309212207794, "incre_win_rate": 0.5952380952380952, "step": 1926}
{"time": 1767087919.7297926, "phase": "train", "update": 1927, "total_env_steps": 6166400, "episode_reward": 0.22815242409706116, "value_loss": 0.010675402358174324, "policy_loss": -0.0012103816403287837, "dist_entropy": 0.3789695143699646, "actor_grad_norm": 0.13003471493721008, "critic_grad_norm": 0.07107234001159668, "ratio": 0.9996863603591919, "entropy": 0.3789695143699646, "incre_win_rate": 0.6341463414634146, "step": 1927}
{"time": 1767087924.5077007, "phase": "train", "update": 1928, "total_env_steps": 6169600, "episode_reward": 0.24158993363380432, "value_loss": 0.009391036443412304, "policy_loss": -0.0014876920422546291, "dist_entropy": 0.3792818486690521, "actor_grad_norm": 0.14174185693264008, "critic_grad_norm": 0.02699453942477703, "ratio": 1.0000232458114624, "entropy": 0.3792818486690521, "incre_win_rate": 0.6428571428571429, "step": 1928}
{"time": 1767087929.3268492, "phase": "train", "update": 1929, "total_env_steps": 6172800, "episode_reward": 0.22980444133281708, "value_loss": 0.013304879888892174, "policy_loss": -0.0014652079617125224, "dist_entropy": 0.40202716588973997, "actor_grad_norm": 0.12523600459098816, "critic_grad_norm": 0.03194404020905495, "ratio": 0.9994495511054993, "entropy": 0.40202716588973997, "incre_win_rate": 0.717948717948718, "step": 1929}
{"time": 1767087934.0548272, "phase": "train", "update": 1930, "total_env_steps": 6176000, "episode_reward": 0.22969061136245728, "value_loss": 0.013358057476580143, "policy_loss": -0.0013496737099742973, "dist_entropy": 0.37610067129135133, "actor_grad_norm": 0.14276933670043945, "critic_grad_norm": 0.03147692605853081, "ratio": 1.0002821683883667, "entropy": 0.37610067129135133, "incre_win_rate": 0.6046511627906976, "step": 1930}
{"time": 1767087938.8016474, "phase": "train", "update": 1931, "total_env_steps": 6179200, "episode_reward": 0.2429356426000595, "value_loss": 0.009267310425639153, "policy_loss": -0.001421653530726985, "dist_entropy": 0.3923925757408142, "actor_grad_norm": 0.13746030628681183, "critic_grad_norm": 0.10514867305755615, "ratio": 0.9997650384902954, "entropy": 0.3923925757408142, "incre_win_rate": 0.7073170731707317, "step": 1931}
{"time": 1767087943.5126443, "phase": "train", "update": 1932, "total_env_steps": 6182400, "episode_reward": 0.2554191052913666, "value_loss": 0.01112813428044319, "policy_loss": -0.0014188456967415774, "dist_entropy": 0.38607252240180967, "actor_grad_norm": 0.11950083076953888, "critic_grad_norm": 0.07421615719795227, "ratio": 1.0000066757202148, "entropy": 0.38607252240180967, "incre_win_rate": 0.8372093023255814, "step": 1932}
{"time": 1767087948.292998, "phase": "train", "update": 1933, "total_env_steps": 6185600, "episode_reward": 0.24447742104530334, "value_loss": 0.011186365596950054, "policy_loss": -0.0013620517361488283, "dist_entropy": 0.39002894759178164, "actor_grad_norm": 0.14176936447620392, "critic_grad_norm": 0.05288485810160637, "ratio": 1.000105619430542, "entropy": 0.39002894759178164, "incre_win_rate": 0.6511627906976745, "step": 1933}
{"time": 1767087953.0187683, "phase": "train", "update": 1934, "total_env_steps": 6188800, "episode_reward": 0.2454397827386856, "value_loss": 0.01028147917240858, "policy_loss": -0.0012624746015257315, "dist_entropy": 0.38313913345336914, "actor_grad_norm": 0.13273487985134125, "critic_grad_norm": 0.04016614705324173, "ratio": 1.0002597570419312, "entropy": 0.38313913345336914, "incre_win_rate": 0.7857142857142857, "step": 1934}
{"time": 1767087958.1258993, "phase": "train", "update": 1935, "total_env_steps": 6192000, "episode_reward": 0.231843963265419, "value_loss": 0.011865500174462796, "policy_loss": -0.0015984267232372674, "dist_entropy": 0.38813736438751223, "actor_grad_norm": 0.14936812222003937, "critic_grad_norm": 0.07584299892187119, "ratio": 1.0001814365386963, "entropy": 0.38813736438751223, "incre_win_rate": 0.6829268292682927, "step": 1935}
{"time": 1767087962.7938712, "phase": "train", "update": 1936, "total_env_steps": 6195200, "episode_reward": 0.24412821233272552, "value_loss": 0.011409343779087066, "policy_loss": -0.0013271332264935154, "dist_entropy": 0.3828011751174927, "actor_grad_norm": 0.11505048722028732, "critic_grad_norm": 0.08584070950746536, "ratio": 0.9999839663505554, "entropy": 0.3828011751174927, "incre_win_rate": 0.7619047619047619, "step": 1936}
{"time": 1767087967.6258001, "phase": "train", "update": 1937, "total_env_steps": 6198400, "episode_reward": 0.2393755167722702, "value_loss": 0.009516949579119683, "policy_loss": -0.0011597591240388283, "dist_entropy": 0.37155506014823914, "actor_grad_norm": 0.1014610305428505, "critic_grad_norm": 0.05857348442077637, "ratio": 0.999969482421875, "entropy": 0.37155506014823914, "incre_win_rate": 0.6585365853658537, "step": 1937}
{"time": 1767087972.3994896, "phase": "train", "update": 1938, "total_env_steps": 6201600, "episode_reward": 0.24340179562568665, "value_loss": 0.010561106726527214, "policy_loss": -0.0014318518719306894, "dist_entropy": 0.36809766888618467, "actor_grad_norm": 0.10400424152612686, "critic_grad_norm": 0.06290563941001892, "ratio": 0.9999082684516907, "entropy": 0.36809766888618467, "incre_win_rate": 0.6976744186046512, "step": 1938}
{"time": 1767087977.1700969, "phase": "train", "update": 1939, "total_env_steps": 6204800, "episode_reward": 0.24252794682979584, "value_loss": 0.009574943594634533, "policy_loss": -0.0013405731579535286, "dist_entropy": 0.35443747639656065, "actor_grad_norm": 0.10770994424819946, "critic_grad_norm": 0.050589341670274734, "ratio": 0.9998487830162048, "entropy": 0.35443747639656065, "incre_win_rate": 0.6136363636363636, "step": 1939}
{"time": 1767087981.7212253, "phase": "train", "update": 1940, "total_env_steps": 6208000, "episode_reward": 0.2392280548810959, "value_loss": 0.008903359621763229, "policy_loss": -0.0011237286360739063, "dist_entropy": 0.3657120048999786, "actor_grad_norm": 0.09056568145751953, "critic_grad_norm": 0.03127313405275345, "ratio": 0.9997563362121582, "entropy": 0.3657120048999786, "incre_win_rate": 0.7380952380952381, "step": 1940}
{"time": 1767087986.223525, "phase": "train", "update": 1941, "total_env_steps": 6211200, "episode_reward": 0.23546305298805237, "value_loss": 0.009736406058073044, "policy_loss": -0.0013949950649728038, "dist_entropy": 0.36203905940055847, "actor_grad_norm": 0.11713927984237671, "critic_grad_norm": 0.023929601535201073, "ratio": 1.0001331567764282, "entropy": 0.36203905940055847, "incre_win_rate": 0.7105263157894737, "step": 1941}
{"time": 1767087996.5639641, "phase": "eval", "update": 1941, "total_env_steps": 6211200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.677566225165563, "step": 1941}
{"time": 1767088001.230915, "phase": "train", "update": 1942, "total_env_steps": 6214400, "episode_reward": 0.23119311034679413, "value_loss": 0.011514360085129738, "policy_loss": -0.0010553563757504491, "dist_entropy": 0.36957432627677916, "actor_grad_norm": 0.1201103925704956, "critic_grad_norm": 0.029401937499642372, "ratio": 0.9998371005058289, "entropy": 0.36957432627677916, "incre_win_rate": 0.5227272727272727, "step": 1942}
{"time": 1767088005.7559657, "phase": "train", "update": 1943, "total_env_steps": 6217600, "episode_reward": 0.22703486680984497, "value_loss": 0.010383916087448597, "policy_loss": -0.0015121215094081818, "dist_entropy": 0.37098793387413026, "actor_grad_norm": 0.13013774156570435, "critic_grad_norm": 0.03771724924445152, "ratio": 0.9998205304145813, "entropy": 0.37098793387413026, "incre_win_rate": 0.7105263157894737, "step": 1943}
{"time": 1767088010.327966, "phase": "train", "update": 1944, "total_env_steps": 6220800, "episode_reward": 0.2330411970615387, "value_loss": 0.008863128535449506, "policy_loss": -0.001502523921357124, "dist_entropy": 0.3656462550163269, "actor_grad_norm": 0.13356542587280273, "critic_grad_norm": 0.03480222821235657, "ratio": 0.9997091293334961, "entropy": 0.3656462550163269, "incre_win_rate": 0.6590909090909091, "step": 1944}
{"time": 1767088014.8884296, "phase": "train", "update": 1945, "total_env_steps": 6224000, "episode_reward": 0.2187081128358841, "value_loss": 0.01181333139538765, "policy_loss": -0.0009342139065736888, "dist_entropy": 0.39843512177467344, "actor_grad_norm": 0.1382441371679306, "critic_grad_norm": 0.0351775698363781, "ratio": 1.0002360343933105, "entropy": 0.39843512177467344, "incre_win_rate": 0.6111111111111112, "step": 1945}
{"time": 1767088019.4254692, "phase": "train", "update": 1946, "total_env_steps": 6227200, "episode_reward": 0.2267482578754425, "value_loss": 0.00870398674160242, "policy_loss": -0.0015298744941091512, "dist_entropy": 0.3830863833427429, "actor_grad_norm": 0.14760778844356537, "critic_grad_norm": 0.02625373937189579, "ratio": 0.99952632188797, "entropy": 0.3830863833427429, "incre_win_rate": 0.627906976744186, "step": 1946}
{"time": 1767088024.0005987, "phase": "train", "update": 1947, "total_env_steps": 6230400, "episode_reward": 0.24607667326927185, "value_loss": 0.009865969233214856, "policy_loss": -0.0012054889173484184, "dist_entropy": 0.35257089138031006, "actor_grad_norm": 0.16703784465789795, "critic_grad_norm": 0.09396711736917496, "ratio": 0.9998375773429871, "entropy": 0.35257089138031006, "incre_win_rate": 0.75, "step": 1947}
{"time": 1767088028.526041, "phase": "train", "update": 1948, "total_env_steps": 6233600, "episode_reward": 0.24578644335269928, "value_loss": 0.00782218985259533, "policy_loss": -0.0009101889446803569, "dist_entropy": 0.387074613571167, "actor_grad_norm": 0.11833546310663223, "critic_grad_norm": 0.08257696777582169, "ratio": 1.000037431716919, "entropy": 0.387074613571167, "incre_win_rate": 0.8333333333333334, "step": 1948}
{"time": 1767088033.1165318, "phase": "train", "update": 1949, "total_env_steps": 6236800, "episode_reward": 0.2533733546733856, "value_loss": 0.007733025029301644, "policy_loss": -0.0012663354761635048, "dist_entropy": 0.3416526436805725, "actor_grad_norm": 0.1188386082649231, "critic_grad_norm": 0.019672300666570663, "ratio": 1.000010371208191, "entropy": 0.3416526436805725, "incre_win_rate": 0.7674418604651163, "step": 1949}
{"time": 1767088037.6744351, "phase": "train", "update": 1950, "total_env_steps": 6240000, "episode_reward": 0.23344215750694275, "value_loss": 0.008971892669796944, "policy_loss": -0.0011906088052768382, "dist_entropy": 0.3607922732830048, "actor_grad_norm": 0.12260439246892929, "critic_grad_norm": 0.0858578160405159, "ratio": 0.9998241662979126, "entropy": 0.3607922732830048, "incre_win_rate": 0.65, "step": 1950}
{"time": 1767088042.1692178, "phase": "train", "update": 1951, "total_env_steps": 6243200, "episode_reward": 0.23620033264160156, "value_loss": 0.008554291911423206, "policy_loss": -0.0010406382773922474, "dist_entropy": 0.3563047111034393, "actor_grad_norm": 0.13044528663158417, "critic_grad_norm": 0.06930691748857498, "ratio": 0.9999077916145325, "entropy": 0.3563047111034393, "incre_win_rate": 0.7435897435897436, "step": 1951}
{"time": 1767088046.7183614, "phase": "train", "update": 1952, "total_env_steps": 6246400, "episode_reward": 0.23817260563373566, "value_loss": 0.008321643248200417, "policy_loss": -0.0010192269561676514, "dist_entropy": 0.34898967742919923, "actor_grad_norm": 0.11062061786651611, "critic_grad_norm": 0.028343265876173973, "ratio": 0.9998273253440857, "entropy": 0.34898967742919923, "incre_win_rate": 0.6511627906976745, "step": 1952}
{"time": 1767088051.2736986, "phase": "train", "update": 1953, "total_env_steps": 6249600, "episode_reward": 0.25280630588531494, "value_loss": 0.010302620194852351, "policy_loss": -0.0012871852260126105, "dist_entropy": 0.34169224500656126, "actor_grad_norm": 0.12732277810573578, "critic_grad_norm": 0.046428926289081573, "ratio": 0.9998316168785095, "entropy": 0.34169224500656126, "incre_win_rate": 0.7906976744186046, "step": 1953}
{"time": 1767088055.7728822, "phase": "train", "update": 1954, "total_env_steps": 6252800, "episode_reward": 0.23103372752666473, "value_loss": 0.009323637001216412, "policy_loss": -0.001274652191449377, "dist_entropy": 0.35778886675834654, "actor_grad_norm": 0.10334557294845581, "critic_grad_norm": 0.04605450853705406, "ratio": 0.9999153017997742, "entropy": 0.35778886675834654, "incre_win_rate": 0.7073170731707317, "step": 1954}
{"time": 1767088060.2969456, "phase": "train", "update": 1955, "total_env_steps": 6256000, "episode_reward": 0.2207750529050827, "value_loss": 0.009622881188988686, "policy_loss": -0.0015041488488179767, "dist_entropy": 0.35311137437820433, "actor_grad_norm": 0.11177436262369156, "critic_grad_norm": 0.059558313339948654, "ratio": 1.0001637935638428, "entropy": 0.35311137437820433, "incre_win_rate": 0.631578947368421, "step": 1955}
{"time": 1767088064.8242946, "phase": "train", "update": 1956, "total_env_steps": 6259200, "episode_reward": 0.23938637971878052, "value_loss": 0.009533982910215854, "policy_loss": -0.0009796981291017915, "dist_entropy": 0.3426308989524841, "actor_grad_norm": 0.1255572885274887, "critic_grad_norm": 0.03943366929888725, "ratio": 0.9998999834060669, "entropy": 0.3426308989524841, "incre_win_rate": 0.7619047619047619, "step": 1956}
{"time": 1767088069.398775, "phase": "train", "update": 1957, "total_env_steps": 6262400, "episode_reward": 0.24478942155838013, "value_loss": 0.007162448577582836, "policy_loss": -0.001300586478269139, "dist_entropy": 0.3508032917976379, "actor_grad_norm": 0.10909461975097656, "critic_grad_norm": 0.059491273015737534, "ratio": 0.9997526407241821, "entropy": 0.3508032917976379, "incre_win_rate": 0.775, "step": 1957}
{"time": 1767088073.9729197, "phase": "train", "update": 1958, "total_env_steps": 6265600, "episode_reward": 0.2520669400691986, "value_loss": 0.007734552677720785, "policy_loss": -0.0010566347664152432, "dist_entropy": 0.3452838659286499, "actor_grad_norm": 0.12791697680950165, "critic_grad_norm": 0.05397365614771843, "ratio": 1.0000438690185547, "entropy": 0.3452838659286499, "incre_win_rate": 0.75, "step": 1958}
{"time": 1767088078.5012403, "phase": "train", "update": 1959, "total_env_steps": 6268800, "episode_reward": 0.23865221440792084, "value_loss": 0.013172362931072712, "policy_loss": -0.001472276998072175, "dist_entropy": 0.3667414128780365, "actor_grad_norm": 0.13036960363388062, "critic_grad_norm": 0.04929300397634506, "ratio": 0.9998154044151306, "entropy": 0.3667414128780365, "incre_win_rate": 0.8, "step": 1959}
{"time": 1767088083.0398736, "phase": "train", "update": 1960, "total_env_steps": 6272000, "episode_reward": 0.24396419525146484, "value_loss": 0.00961160808801651, "policy_loss": -0.0010792642576650025, "dist_entropy": 0.3681426167488098, "actor_grad_norm": 0.11309459060430527, "critic_grad_norm": 0.027738917618989944, "ratio": 0.9998014569282532, "entropy": 0.3681426167488098, "incre_win_rate": 0.7209302325581395, "step": 1960}
{"time": 1767088087.616256, "phase": "train", "update": 1961, "total_env_steps": 6275200, "episode_reward": 0.23721803724765778, "value_loss": 0.008844025246798993, "policy_loss": -0.001346025476763657, "dist_entropy": 0.3821546912193298, "actor_grad_norm": 0.12482229620218277, "critic_grad_norm": 0.03009999357163906, "ratio": 0.9998824000358582, "entropy": 0.3821546912193298, "incre_win_rate": 0.75, "step": 1961}
{"time": 1767088098.977908, "phase": "eval", "update": 1961, "total_env_steps": 6275200, "eval_win_rate": 0.84375, "eval_episode_reward": 19.32843543046357, "step": 1961}
{"time": 1767088138.262129, "phase": "train", "update": 1962, "total_env_steps": 6278400, "episode_reward": 0.2214704006910324, "value_loss": 0.057609451562166215, "policy_loss": -0.0017004956724122166, "dist_entropy": 0.3818502604961395, "actor_grad_norm": 0.14743928611278534, "critic_grad_norm": 0.25479409098625183, "ratio": 1.0002940893173218, "entropy": 0.3818502604961395, "incre_win_rate": 0.6111111111111112, "step": 1962}
{"time": 1767088142.7289512, "phase": "train", "update": 1963, "total_env_steps": 6281600, "episode_reward": 0.2127462774515152, "value_loss": 0.011976075358688831, "policy_loss": -0.00137415962173435, "dist_entropy": 0.3759750247001648, "actor_grad_norm": 0.16077207028865814, "critic_grad_norm": 0.13850371539592743, "ratio": 0.9999414682388306, "entropy": 0.3759750247001648, "incre_win_rate": 0.5641025641025641, "step": 1963}
{"time": 1767088147.1954706, "phase": "train", "update": 1964, "total_env_steps": 6284800, "episode_reward": 0.2471843957901001, "value_loss": 0.007522472366690636, "policy_loss": -0.001162620584603502, "dist_entropy": 0.36056609749794005, "actor_grad_norm": 0.12696419656276703, "critic_grad_norm": 0.14082305133342743, "ratio": 1.0002979040145874, "entropy": 0.36056609749794005, "incre_win_rate": 0.775, "step": 1964}
{"time": 1767088151.6996374, "phase": "train", "update": 1965, "total_env_steps": 6288000, "episode_reward": 0.24058309197425842, "value_loss": 0.008431387506425381, "policy_loss": -0.0011395022907429108, "dist_entropy": 0.35952767729759216, "actor_grad_norm": 0.1219453439116478, "critic_grad_norm": 0.06724107265472412, "ratio": 1.0000797510147095, "entropy": 0.35952767729759216, "incre_win_rate": 0.6818181818181818, "step": 1965}
{"time": 1767088156.207537, "phase": "train", "update": 1966, "total_env_steps": 6291200, "episode_reward": 0.25201210379600525, "value_loss": 0.00803601797670126, "policy_loss": -0.0010516069385513305, "dist_entropy": 0.36053932905197145, "actor_grad_norm": 0.13012291491031647, "critic_grad_norm": 0.021982666105031967, "ratio": 0.9999759793281555, "entropy": 0.36053932905197145, "incre_win_rate": 0.8048780487804879, "step": 1966}
{"time": 1767088160.7223063, "phase": "train", "update": 1967, "total_env_steps": 6294400, "episode_reward": 0.24986238777637482, "value_loss": 0.00978563390672207, "policy_loss": -0.001211754828615952, "dist_entropy": 0.3523950695991516, "actor_grad_norm": 0.15428295731544495, "critic_grad_norm": 0.05450313165783882, "ratio": 1.0000426769256592, "entropy": 0.3523950695991516, "incre_win_rate": 0.6976744186046512, "step": 1967}
{"time": 1767088165.2548451, "phase": "train", "update": 1968, "total_env_steps": 6297600, "episode_reward": 0.24791494011878967, "value_loss": 0.009219326823949815, "policy_loss": -0.0010888031800860177, "dist_entropy": 0.35900395512580874, "actor_grad_norm": 0.14068818092346191, "critic_grad_norm": 0.039293255656957626, "ratio": 0.9997308850288391, "entropy": 0.35900395512580874, "incre_win_rate": 0.7272727272727273, "step": 1968}
{"time": 1767088169.767847, "phase": "train", "update": 1969, "total_env_steps": 6300800, "episode_reward": 0.23032180964946747, "value_loss": 0.009986318461596966, "policy_loss": -0.0011679007229560058, "dist_entropy": 0.3459435701370239, "actor_grad_norm": 0.1372452825307846, "critic_grad_norm": 0.044981829822063446, "ratio": 1.0001708269119263, "entropy": 0.3459435701370239, "incre_win_rate": 0.5853658536585366, "step": 1969}
{"time": 1767088174.2351692, "phase": "train", "update": 1970, "total_env_steps": 6304000, "episode_reward": 0.22629503905773163, "value_loss": 0.011274189874529838, "policy_loss": -0.001407444062696328, "dist_entropy": 0.3593948185443878, "actor_grad_norm": 0.139060378074646, "critic_grad_norm": 0.04292289540171623, "ratio": 0.999628484249115, "entropy": 0.3593948185443878, "incre_win_rate": 0.625, "step": 1970}
{"time": 1767088178.7595508, "phase": "train", "update": 1971, "total_env_steps": 6307200, "episode_reward": 0.24924048781394958, "value_loss": 0.0072404353879392145, "policy_loss": -0.0011324397342932003, "dist_entropy": 0.35873920321464536, "actor_grad_norm": 0.17113961279392242, "critic_grad_norm": 0.06719094514846802, "ratio": 1.0000635385513306, "entropy": 0.35873920321464536, "incre_win_rate": 0.8095238095238095, "step": 1971}
{"time": 1767088183.283756, "phase": "train", "update": 1972, "total_env_steps": 6310400, "episode_reward": 0.2290738821029663, "value_loss": 0.00785543080419302, "policy_loss": -0.0010978883865871759, "dist_entropy": 0.3564462661743164, "actor_grad_norm": 0.17356805503368378, "critic_grad_norm": 0.04604381322860718, "ratio": 1.000141978263855, "entropy": 0.3564462661743164, "incre_win_rate": 0.6666666666666666, "step": 1972}
{"time": 1767088187.7935617, "phase": "train", "update": 1973, "total_env_steps": 6313600, "episode_reward": 0.245433047413826, "value_loss": 0.00797292562201619, "policy_loss": -0.0013346971973609457, "dist_entropy": 0.35376115441322326, "actor_grad_norm": 0.11547621339559555, "critic_grad_norm": 0.030641067773103714, "ratio": 0.9996861815452576, "entropy": 0.35376115441322326, "incre_win_rate": 0.8095238095238095, "step": 1973}
{"time": 1767088192.3155837, "phase": "train", "update": 1974, "total_env_steps": 6316800, "episode_reward": 0.23547030985355377, "value_loss": 0.00896659418940544, "policy_loss": -0.0014947291193621482, "dist_entropy": 0.3587072312831879, "actor_grad_norm": 0.10295426100492477, "critic_grad_norm": 0.03112189471721649, "ratio": 1.0001075267791748, "entropy": 0.3587072312831879, "incre_win_rate": 0.6829268292682927, "step": 1974}
{"time": 1767088196.8260663, "phase": "train", "update": 1975, "total_env_steps": 6320000, "episode_reward": 0.23084025084972382, "value_loss": 0.009251049906015395, "policy_loss": -0.0014752108967932998, "dist_entropy": 0.3560063064098358, "actor_grad_norm": 0.10278651863336563, "critic_grad_norm": 0.0578276701271534, "ratio": 0.9998406767845154, "entropy": 0.3560063064098358, "incre_win_rate": 0.65, "step": 1975}
{"time": 1767088201.398638, "phase": "train", "update": 1976, "total_env_steps": 6323200, "episode_reward": 0.24096493422985077, "value_loss": 0.009427022002637387, "policy_loss": -0.0016855584192057905, "dist_entropy": 0.3471198916435242, "actor_grad_norm": 0.11327393352985382, "critic_grad_norm": 0.04573556408286095, "ratio": 0.9998779296875, "entropy": 0.3471198916435242, "incre_win_rate": 0.7142857142857143, "step": 1976}
{"time": 1767088205.9202168, "phase": "train", "update": 1977, "total_env_steps": 6326400, "episode_reward": 0.24341680109500885, "value_loss": 0.008240355364978313, "policy_loss": -0.0010609674199464792, "dist_entropy": 0.3574808597564697, "actor_grad_norm": 0.10343959182500839, "critic_grad_norm": 0.03148757293820381, "ratio": 1.0000958442687988, "entropy": 0.3574808597564697, "incre_win_rate": 0.6888888888888889, "step": 1977}
{"time": 1767088210.4879751, "phase": "train", "update": 1978, "total_env_steps": 6329600, "episode_reward": 0.25041288137435913, "value_loss": 0.008860739693045617, "policy_loss": -0.0011512078702512695, "dist_entropy": 0.35474419593811035, "actor_grad_norm": 0.10602555423974991, "critic_grad_norm": 0.03136328235268593, "ratio": 1.000015139579773, "entropy": 0.35474419593811035, "incre_win_rate": 0.7692307692307693, "step": 1978}
{"time": 1767088215.0458114, "phase": "train", "update": 1979, "total_env_steps": 6332800, "episode_reward": 0.24440345168113708, "value_loss": 0.009971298836171627, "policy_loss": -0.0014792481648491674, "dist_entropy": 0.35066148042678835, "actor_grad_norm": 0.14553271234035492, "critic_grad_norm": 0.05932837724685669, "ratio": 0.9999303817749023, "entropy": 0.35066148042678835, "incre_win_rate": 0.6666666666666666, "step": 1979}
{"time": 1767088219.5970047, "phase": "train", "update": 1980, "total_env_steps": 6336000, "episode_reward": 0.24092406034469604, "value_loss": 0.011281664855778218, "policy_loss": -0.001743832544172008, "dist_entropy": 0.3656753182411194, "actor_grad_norm": 0.11921365559101105, "critic_grad_norm": 0.044331979006528854, "ratio": 0.999943733215332, "entropy": 0.3656753182411194, "incre_win_rate": 0.7317073170731707, "step": 1980}
{"time": 1767088224.2022479, "phase": "train", "update": 1981, "total_env_steps": 6339200, "episode_reward": 0.2380789816379547, "value_loss": 0.011561695672571658, "policy_loss": -0.0016495383907795258, "dist_entropy": 0.3398078203201294, "actor_grad_norm": 0.2201915979385376, "critic_grad_norm": 0.058500200510025024, "ratio": 0.9993192553520203, "entropy": 0.3398078203201294, "incre_win_rate": 0.5909090909090909, "step": 1981}
{"time": 1767088235.1873245, "phase": "eval", "update": 1981, "total_env_steps": 6339200, "eval_win_rate": 0.8125, "eval_episode_reward": 19.258485099337747, "step": 1981}
{"time": 1767088239.7010698, "phase": "train", "update": 1982, "total_env_steps": 6342400, "episode_reward": 0.24248448014259338, "value_loss": 0.01101413331925869, "policy_loss": -0.0014125116428360229, "dist_entropy": 0.35107611417770385, "actor_grad_norm": 0.125632643699646, "critic_grad_norm": 0.07996469736099243, "ratio": 1.000014305114746, "entropy": 0.35107611417770385, "incre_win_rate": 0.7380952380952381, "step": 1982}
{"time": 1767088244.205446, "phase": "train", "update": 1983, "total_env_steps": 6345600, "episode_reward": 0.23526905477046967, "value_loss": 0.009781293757259845, "policy_loss": -0.001514181192020203, "dist_entropy": 0.3415450692176819, "actor_grad_norm": 0.10934358835220337, "critic_grad_norm": 0.05740164592862129, "ratio": 1.0000344514846802, "entropy": 0.3415450692176819, "incre_win_rate": 0.7317073170731707, "step": 1983}
{"time": 1767088248.7243617, "phase": "train", "update": 1984, "total_env_steps": 6348800, "episode_reward": 0.273232102394104, "value_loss": 0.0074715173803269865, "policy_loss": -0.0012021807833860975, "dist_entropy": 0.3462406277656555, "actor_grad_norm": 0.1046023890376091, "critic_grad_norm": 0.05484739691019058, "ratio": 0.9996293187141418, "entropy": 0.3462406277656555, "incre_win_rate": 0.9302325581395349, "step": 1984}
{"time": 1767088253.2364318, "phase": "train", "update": 1985, "total_env_steps": 6352000, "episode_reward": 0.236153244972229, "value_loss": 0.007320715673267841, "policy_loss": -0.0015145297965268867, "dist_entropy": 0.35298041105270384, "actor_grad_norm": 0.1296047568321228, "critic_grad_norm": 0.027716193348169327, "ratio": 0.9996404647827148, "entropy": 0.35298041105270384, "incre_win_rate": 0.7073170731707317, "step": 1985}
{"time": 1767088257.7919972, "phase": "train", "update": 1986, "total_env_steps": 6355200, "episode_reward": 0.26073572039604187, "value_loss": 0.00818282999098301, "policy_loss": -0.0011703221567387345, "dist_entropy": 0.33221353888511657, "actor_grad_norm": 0.1077793762087822, "critic_grad_norm": 0.020315352827310562, "ratio": 1.0002328157424927, "entropy": 0.33221353888511657, "incre_win_rate": 0.8, "step": 1986}
{"time": 1767088262.3990471, "phase": "train", "update": 1987, "total_env_steps": 6358400, "episode_reward": 0.26122206449508667, "value_loss": 0.009057315811514855, "policy_loss": -0.0014326482875233637, "dist_entropy": 0.3383725047111511, "actor_grad_norm": 0.15271954238414764, "critic_grad_norm": 0.02274753339588642, "ratio": 0.9998905062675476, "entropy": 0.3383725047111511, "incre_win_rate": 0.7333333333333333, "step": 1987}
{"time": 1767088266.9822588, "phase": "train", "update": 1988, "total_env_steps": 6361600, "episode_reward": 0.2623121738433838, "value_loss": 0.010737250931560994, "policy_loss": -0.000932211219713519, "dist_entropy": 0.34170064330101013, "actor_grad_norm": 0.14802412688732147, "critic_grad_norm": 0.04901106283068657, "ratio": 1.000051736831665, "entropy": 0.34170064330101013, "incre_win_rate": 0.7608695652173914, "step": 1988}
{"time": 1767088271.536789, "phase": "train", "update": 1989, "total_env_steps": 6364800, "episode_reward": 0.2702726721763611, "value_loss": 0.007334483135491609, "policy_loss": -0.0011123441706672565, "dist_entropy": 0.3475612819194794, "actor_grad_norm": 0.16327224671840668, "critic_grad_norm": 0.03172442689538002, "ratio": 1.0000077486038208, "entropy": 0.3475612819194794, "incre_win_rate": 0.813953488372093, "step": 1989}
{"time": 1767088276.0063872, "phase": "train", "update": 1990, "total_env_steps": 6368000, "episode_reward": 0.2187422513961792, "value_loss": 0.009560156427323819, "policy_loss": -0.0012603123598807996, "dist_entropy": 0.3663753092288971, "actor_grad_norm": 0.11242511123418808, "critic_grad_norm": 0.04935230687260628, "ratio": 0.9998796582221985, "entropy": 0.3663753092288971, "incre_win_rate": 0.7105263157894737, "step": 1990}
{"time": 1767088280.5045469, "phase": "train", "update": 1991, "total_env_steps": 6371200, "episode_reward": 0.24823002517223358, "value_loss": 0.007741599250584841, "policy_loss": -0.0012650240131705458, "dist_entropy": 0.34285798072814944, "actor_grad_norm": 0.1422741860151291, "critic_grad_norm": 0.04920974001288414, "ratio": 0.9998500943183899, "entropy": 0.34285798072814944, "incre_win_rate": 0.7272727272727273, "step": 1991}
{"time": 1767088285.090185, "phase": "train", "update": 1992, "total_env_steps": 6374400, "episode_reward": 0.26840493083000183, "value_loss": 0.011317634768784047, "policy_loss": -0.0009882372230975878, "dist_entropy": 0.3493318259716034, "actor_grad_norm": 0.11958806961774826, "critic_grad_norm": 0.06614261865615845, "ratio": 1.0001720190048218, "entropy": 0.3493318259716034, "incre_win_rate": 0.8181818181818182, "step": 1992}
{"time": 1767088289.640071, "phase": "train", "update": 1993, "total_env_steps": 6377600, "episode_reward": 0.2593899965286255, "value_loss": 0.006360035575926304, "policy_loss": -0.000988610683855029, "dist_entropy": 0.3575281322002411, "actor_grad_norm": 0.10332509130239487, "critic_grad_norm": 0.03721727430820465, "ratio": 0.9999544024467468, "entropy": 0.3575281322002411, "incre_win_rate": 0.8181818181818182, "step": 1993}
{"time": 1767088294.2395308, "phase": "train", "update": 1994, "total_env_steps": 6380800, "episode_reward": 0.26651594042778015, "value_loss": 0.006925734970718622, "policy_loss": -0.0013761418150465942, "dist_entropy": 0.34872803688049314, "actor_grad_norm": 0.11644196510314941, "critic_grad_norm": 0.041221387684345245, "ratio": 1.0002130270004272, "entropy": 0.34872803688049314, "incre_win_rate": 0.8666666666666667, "step": 1994}
{"time": 1767088298.7459202, "phase": "train", "update": 1995, "total_env_steps": 6384000, "episode_reward": 0.24385863542556763, "value_loss": 0.011507544480264188, "policy_loss": -0.0016912744373009047, "dist_entropy": 0.3564267337322235, "actor_grad_norm": 0.16955581307411194, "critic_grad_norm": 0.06162632256746292, "ratio": 0.9995266795158386, "entropy": 0.3564267337322235, "incre_win_rate": 0.6511627906976745, "step": 1995}
{"time": 1767088303.3000488, "phase": "train", "update": 1996, "total_env_steps": 6387200, "episode_reward": 0.2590283453464508, "value_loss": 0.007019184995442629, "policy_loss": -0.0009001434118019347, "dist_entropy": 0.3523986339569092, "actor_grad_norm": 0.13818582892417908, "critic_grad_norm": 0.050005197525024414, "ratio": 0.9998970031738281, "entropy": 0.3523986339569092, "incre_win_rate": 0.7857142857142857, "step": 1996}
{"time": 1767088307.8154163, "phase": "train", "update": 1997, "total_env_steps": 6390400, "episode_reward": 0.25081953406333923, "value_loss": 0.010342079401016235, "policy_loss": -0.0012424613159836896, "dist_entropy": 0.3581326365470886, "actor_grad_norm": 0.1271257847547531, "critic_grad_norm": 0.060296814888715744, "ratio": 0.9998764395713806, "entropy": 0.3581326365470886, "incre_win_rate": 0.7333333333333333, "step": 1997}
{"time": 1767088312.3575695, "phase": "train", "update": 1998, "total_env_steps": 6393600, "episode_reward": 0.2470742017030716, "value_loss": 0.009600573964416981, "policy_loss": -0.001210604246529101, "dist_entropy": 0.3578345239162445, "actor_grad_norm": 0.11589636653661728, "critic_grad_norm": 0.04754446819424629, "ratio": 0.9998332262039185, "entropy": 0.3578345239162445, "incre_win_rate": 0.7142857142857143, "step": 1998}
{"time": 1767088316.913073, "phase": "train", "update": 1999, "total_env_steps": 6396800, "episode_reward": 0.24930155277252197, "value_loss": 0.01005005706101656, "policy_loss": -0.001488187115476336, "dist_entropy": 0.3618341386318207, "actor_grad_norm": 0.12296285480260849, "critic_grad_norm": 0.028289148584008217, "ratio": 0.9999844431877136, "entropy": 0.3618341386318207, "incre_win_rate": 0.6888888888888889, "step": 1999}
{"time": 1767088321.4440145, "phase": "train", "update": 2000, "total_env_steps": 6400000, "episode_reward": 0.22812293469905853, "value_loss": 0.01150720678269863, "policy_loss": -0.0013859089529262292, "dist_entropy": 0.3740228831768036, "actor_grad_norm": 0.11025633662939072, "critic_grad_norm": 0.032043807208538055, "ratio": 0.9998255968093872, "entropy": 0.3740228831768036, "incre_win_rate": 0.55, "step": 2000}
{"time": 1767088325.9655979, "phase": "train", "update": 2001, "total_env_steps": 6403200, "episode_reward": 0.25728994607925415, "value_loss": 0.007923257164657116, "policy_loss": -0.0010784047509226013, "dist_entropy": 0.35952168703079224, "actor_grad_norm": 0.09222447872161865, "critic_grad_norm": 0.03481360897421837, "ratio": 0.9996512532234192, "entropy": 0.35952168703079224, "incre_win_rate": 0.7333333333333333, "step": 2001}
{"time": 1767088336.428597, "phase": "eval", "update": 2001, "total_env_steps": 6403200, "eval_win_rate": 0.84375, "eval_episode_reward": 19.27116100993377, "step": 2001}
{"time": 1767088340.9616928, "phase": "train", "update": 2002, "total_env_steps": 6406400, "episode_reward": 0.25789323449134827, "value_loss": 0.009856034070253372, "policy_loss": -0.0014022129728765264, "dist_entropy": 0.3749150812625885, "actor_grad_norm": 0.12119770050048828, "critic_grad_norm": 0.04250071197748184, "ratio": 0.9999480247497559, "entropy": 0.3749150812625885, "incre_win_rate": 0.8333333333333334, "step": 2002}
{"time": 1767088345.550521, "phase": "train", "update": 2003, "total_env_steps": 6409600, "episode_reward": 0.22502484917640686, "value_loss": 0.01011742390692234, "policy_loss": -0.001655590300039833, "dist_entropy": 0.3767521381378174, "actor_grad_norm": 0.1185571700334549, "critic_grad_norm": 0.04395585134625435, "ratio": 0.9999851584434509, "entropy": 0.3767521381378174, "incre_win_rate": 0.6341463414634146, "step": 2003}
{"time": 1767088349.9890816, "phase": "train", "update": 2004, "total_env_steps": 6412800, "episode_reward": 0.22535908222198486, "value_loss": 0.00869851429015398, "policy_loss": -0.0017044128715848928, "dist_entropy": 0.38386695384979247, "actor_grad_norm": 0.1442951261997223, "critic_grad_norm": 0.042866211384534836, "ratio": 0.9998676180839539, "entropy": 0.38386695384979247, "incre_win_rate": 0.6216216216216216, "step": 2004}
{"time": 1767088354.5688453, "phase": "train", "update": 2005, "total_env_steps": 6416000, "episode_reward": 0.24676582217216492, "value_loss": 0.009091497212648392, "policy_loss": -0.0013861598547039832, "dist_entropy": 0.376092791557312, "actor_grad_norm": 0.1544269174337387, "critic_grad_norm": 0.04447135329246521, "ratio": 1.0000286102294922, "entropy": 0.376092791557312, "incre_win_rate": 0.6222222222222222, "step": 2005}
{"time": 1767088359.0750642, "phase": "train", "update": 2006, "total_env_steps": 6419200, "episode_reward": 0.2399684339761734, "value_loss": 0.009919805638492107, "policy_loss": -0.001352203289209797, "dist_entropy": 0.37694695591926575, "actor_grad_norm": 0.11276253312826157, "critic_grad_norm": 0.03888653591275215, "ratio": 0.9999799132347107, "entropy": 0.37694695591926575, "incre_win_rate": 0.627906976744186, "step": 2006}
{"time": 1767088363.6486435, "phase": "train", "update": 2007, "total_env_steps": 6422400, "episode_reward": 0.25862425565719604, "value_loss": 0.01018473505973816, "policy_loss": -0.0013571940600453302, "dist_entropy": 0.3741170227527618, "actor_grad_norm": 0.16277386248111725, "critic_grad_norm": 0.048733390867710114, "ratio": 1.0001939535140991, "entropy": 0.3741170227527618, "incre_win_rate": 0.7727272727272727, "step": 2007}
{"time": 1767088368.1957786, "phase": "train", "update": 2008, "total_env_steps": 6425600, "episode_reward": 0.2642870247364044, "value_loss": 0.006036279816180467, "policy_loss": -0.0009280819406075836, "dist_entropy": 0.38888147473335266, "actor_grad_norm": 0.11444894224405289, "critic_grad_norm": 0.08645079284906387, "ratio": 0.9998839497566223, "entropy": 0.38888147473335266, "incre_win_rate": 0.813953488372093, "step": 2008}
{"time": 1767088372.7430062, "phase": "train", "update": 2009, "total_env_steps": 6428800, "episode_reward": 0.23005950450897217, "value_loss": 0.007836834620684385, "policy_loss": -0.001500530594486804, "dist_entropy": 0.39331880807876585, "actor_grad_norm": 0.13804548978805542, "critic_grad_norm": 0.05752819404006004, "ratio": 1.0001564025878906, "entropy": 0.39331880807876585, "incre_win_rate": 0.8205128205128205, "step": 2009}
{"time": 1767088377.264705, "phase": "train", "update": 2010, "total_env_steps": 6432000, "episode_reward": 0.2297464907169342, "value_loss": 0.010669391229748726, "policy_loss": -0.001208302088821256, "dist_entropy": 0.38193426132202146, "actor_grad_norm": 0.13505791127681732, "critic_grad_norm": 0.10766812413930893, "ratio": 0.9998273849487305, "entropy": 0.38193426132202146, "incre_win_rate": 0.5476190476190477, "step": 2010}
{"time": 1767088381.7883341, "phase": "train", "update": 2011, "total_env_steps": 6435200, "episode_reward": 0.23401646316051483, "value_loss": 0.015386568568646907, "policy_loss": -0.001564951130055192, "dist_entropy": 0.3722216010093689, "actor_grad_norm": 0.16685305535793304, "critic_grad_norm": 0.08384078741073608, "ratio": 1.0001667737960815, "entropy": 0.3722216010093689, "incre_win_rate": 0.6097560975609756, "step": 2011}
{"time": 1767088386.3088305, "phase": "train", "update": 2012, "total_env_steps": 6438400, "episode_reward": 0.23250414431095123, "value_loss": 0.009528211131691933, "policy_loss": -0.0015416479270768946, "dist_entropy": 0.3855831801891327, "actor_grad_norm": 0.10553423315286636, "critic_grad_norm": 0.05736431106925011, "ratio": 0.9998012781143188, "entropy": 0.3855831801891327, "incre_win_rate": 0.6585365853658537, "step": 2012}
{"time": 1767088390.7814438, "phase": "train", "update": 2013, "total_env_steps": 6441600, "episode_reward": 0.2175450176000595, "value_loss": 0.011371706239879131, "policy_loss": -0.00156469856065371, "dist_entropy": 0.4043553054332733, "actor_grad_norm": 0.1303333044052124, "critic_grad_norm": 0.05911041423678398, "ratio": 0.9998180270195007, "entropy": 0.4043553054332733, "incre_win_rate": 0.575, "step": 2013}
{"time": 1767088395.3628497, "phase": "train", "update": 2014, "total_env_steps": 6444800, "episode_reward": 0.25773850083351135, "value_loss": 0.007671059668064117, "policy_loss": -0.0012916283044745569, "dist_entropy": 0.3862094283103943, "actor_grad_norm": 0.10950644314289093, "critic_grad_norm": 0.05864466354250908, "ratio": 0.9996724128723145, "entropy": 0.3862094283103943, "incre_win_rate": 0.7272727272727273, "step": 2014}
{"time": 1767088399.914635, "phase": "train", "update": 2015, "total_env_steps": 6448000, "episode_reward": 0.24136382341384888, "value_loss": 0.009598219022154807, "policy_loss": -0.001400276368968889, "dist_entropy": 0.3906411290168762, "actor_grad_norm": 0.09684418886899948, "critic_grad_norm": 0.06624989956617355, "ratio": 0.9998349547386169, "entropy": 0.3906411290168762, "incre_win_rate": 0.5777777777777777, "step": 2015}
{"time": 1767088404.426667, "phase": "train", "update": 2016, "total_env_steps": 6451200, "episode_reward": 0.2331255078315735, "value_loss": 0.008830767683684826, "policy_loss": -0.001303020905672625, "dist_entropy": 0.39555182456970217, "actor_grad_norm": 0.1049472838640213, "critic_grad_norm": 0.05040190368890762, "ratio": 1.0001696348190308, "entropy": 0.39555182456970217, "incre_win_rate": 0.7297297297297297, "step": 2016}
{"time": 1767088409.0082684, "phase": "train", "update": 2017, "total_env_steps": 6454400, "episode_reward": 0.24526336789131165, "value_loss": 0.010109539702534675, "policy_loss": -0.0015192913287962906, "dist_entropy": 0.4119168043136597, "actor_grad_norm": 0.1345691978931427, "critic_grad_norm": 0.03187856078147888, "ratio": 0.9997828602790833, "entropy": 0.4119168043136597, "incre_win_rate": 0.7045454545454546, "step": 2017}
{"time": 1767088413.495884, "phase": "train", "update": 2018, "total_env_steps": 6457600, "episode_reward": 0.21402786672115326, "value_loss": 0.012018425948917865, "policy_loss": -0.0015726891211066628, "dist_entropy": 0.407017719745636, "actor_grad_norm": 0.10533330589532852, "critic_grad_norm": 0.020965754985809326, "ratio": 1.0000381469726562, "entropy": 0.407017719745636, "incre_win_rate": 0.5263157894736842, "step": 2018}
{"time": 1767088418.0922396, "phase": "train", "update": 2019, "total_env_steps": 6460800, "episode_reward": 0.2552022933959961, "value_loss": 0.00860270783305168, "policy_loss": -0.0014039825299695607, "dist_entropy": 0.4041531801223755, "actor_grad_norm": 0.13960348069667816, "critic_grad_norm": 0.05737271532416344, "ratio": 0.9999052882194519, "entropy": 0.4041531801223755, "incre_win_rate": 0.7391304347826086, "step": 2019}
{"time": 1767088422.6294632, "phase": "train", "update": 2020, "total_env_steps": 6464000, "episode_reward": 0.25339511036872864, "value_loss": 0.007909339014440775, "policy_loss": -0.001650441081452314, "dist_entropy": 0.40789470076560974, "actor_grad_norm": 0.09582775086164474, "critic_grad_norm": 0.04452601075172424, "ratio": 0.9998219609260559, "entropy": 0.40789470076560974, "incre_win_rate": 0.7560975609756098, "step": 2020}
{"time": 1767088427.277938, "phase": "train", "update": 2021, "total_env_steps": 6467200, "episode_reward": 0.2547718286514282, "value_loss": 0.008305651135742664, "policy_loss": -0.0012757745161351864, "dist_entropy": 0.4035191535949707, "actor_grad_norm": 0.1134159117937088, "critic_grad_norm": 0.028179029002785683, "ratio": 0.9996580481529236, "entropy": 0.4035191535949707, "incre_win_rate": 0.7111111111111111, "step": 2021}
{"time": 1767088438.0828886, "phase": "eval", "update": 2021, "total_env_steps": 6467200, "eval_win_rate": 0.78125, "eval_episode_reward": 18.931963990066222, "step": 2021}
{"time": 1767088442.5634217, "phase": "train", "update": 2022, "total_env_steps": 6470400, "episode_reward": 0.2438979595899582, "value_loss": 0.011463716253638267, "policy_loss": -0.0018144446489170463, "dist_entropy": 0.4071511685848236, "actor_grad_norm": 0.11566001176834106, "critic_grad_norm": 0.059730447828769684, "ratio": 0.999923050403595, "entropy": 0.4071511685848236, "incre_win_rate": 0.6829268292682927, "step": 2022}
{"time": 1767088447.1545663, "phase": "train", "update": 2023, "total_env_steps": 6473600, "episode_reward": 0.246299147605896, "value_loss": 0.01047082468867302, "policy_loss": -0.0013767290874646676, "dist_entropy": 0.4123197078704834, "actor_grad_norm": 0.11108054965734482, "critic_grad_norm": 0.04363764449954033, "ratio": 0.9994622468948364, "entropy": 0.4123197078704834, "incre_win_rate": 0.6888888888888889, "step": 2023}
{"time": 1767088451.636193, "phase": "train", "update": 2024, "total_env_steps": 6476800, "episode_reward": 0.2264331430196762, "value_loss": 0.009803304076194763, "policy_loss": -0.001684392316328598, "dist_entropy": 0.4131943345069885, "actor_grad_norm": 0.09685400873422623, "critic_grad_norm": 0.03054143488407135, "ratio": 1.0000673532485962, "entropy": 0.4131943345069885, "incre_win_rate": 0.6216216216216216, "step": 2024}
{"time": 1767088456.196836, "phase": "train", "update": 2025, "total_env_steps": 6480000, "episode_reward": 0.248951256275177, "value_loss": 0.006469009816646576, "policy_loss": -0.0015015802864681404, "dist_entropy": 0.3891470193862915, "actor_grad_norm": 0.12899631261825562, "critic_grad_norm": 0.04889042675495148, "ratio": 0.9997485280036926, "entropy": 0.3891470193862915, "incre_win_rate": 0.7727272727272727, "step": 2025}
{"time": 1767088460.6777582, "phase": "train", "update": 2026, "total_env_steps": 6483200, "episode_reward": 0.2315361201763153, "value_loss": 0.011060207895934582, "policy_loss": -0.0013709657342232616, "dist_entropy": 0.38551840782165525, "actor_grad_norm": 0.12105832248926163, "critic_grad_norm": 0.061439771205186844, "ratio": 0.9999803900718689, "entropy": 0.38551840782165525, "incre_win_rate": 0.5853658536585366, "step": 2026}
{"time": 1767088465.255955, "phase": "train", "update": 2027, "total_env_steps": 6486400, "episode_reward": 0.24915872514247894, "value_loss": 0.010795335844159126, "policy_loss": -0.001220184599185359, "dist_entropy": 0.37965102195739747, "actor_grad_norm": 0.10565225034952164, "critic_grad_norm": 0.05790727213025093, "ratio": 1.0000544786453247, "entropy": 0.37965102195739747, "incre_win_rate": 0.6521739130434783, "step": 2027}
{"time": 1767088469.7543144, "phase": "train", "update": 2028, "total_env_steps": 6489600, "episode_reward": 0.23703795671463013, "value_loss": 0.009805208630859851, "policy_loss": -0.0014534075131450662, "dist_entropy": 0.38387843370437624, "actor_grad_norm": 0.09628891199827194, "critic_grad_norm": 0.047030579298734665, "ratio": 1.0000648498535156, "entropy": 0.38387843370437624, "incre_win_rate": 0.7105263157894737, "step": 2028}
{"time": 1767088474.2843668, "phase": "train", "update": 2029, "total_env_steps": 6492800, "episode_reward": 0.261749267578125, "value_loss": 0.008880105055868625, "policy_loss": -0.0013422688225884992, "dist_entropy": 0.37748308181762696, "actor_grad_norm": 0.1008995771408081, "critic_grad_norm": 0.043731529265642166, "ratio": 1.0000245571136475, "entropy": 0.37748308181762696, "incre_win_rate": 0.8260869565217391, "step": 2029}
{"time": 1767088478.8317935, "phase": "train", "update": 2030, "total_env_steps": 6496000, "episode_reward": 0.23268264532089233, "value_loss": 0.011099626310169697, "policy_loss": -0.001420004190869406, "dist_entropy": 0.38496845960617065, "actor_grad_norm": 0.10066491365432739, "critic_grad_norm": 0.04990735277533531, "ratio": 0.9998794794082642, "entropy": 0.38496845960617065, "incre_win_rate": 0.5714285714285714, "step": 2030}
{"time": 1767088483.3363714, "phase": "train", "update": 2031, "total_env_steps": 6499200, "episode_reward": 0.24976302683353424, "value_loss": 0.00867095310240984, "policy_loss": -0.0012943066207448338, "dist_entropy": 0.3775684177875519, "actor_grad_norm": 0.1504592001438141, "critic_grad_norm": 0.039598818868398666, "ratio": 0.9997184872627258, "entropy": 0.3775684177875519, "incre_win_rate": 0.7804878048780488, "step": 2031}
{"time": 1767088487.8545003, "phase": "train", "update": 2032, "total_env_steps": 6502400, "episode_reward": 0.24308258295059204, "value_loss": 0.0073015764355659485, "policy_loss": -0.0016778324350251949, "dist_entropy": 0.3886626958847046, "actor_grad_norm": 0.12664487957954407, "critic_grad_norm": 0.038103144615888596, "ratio": 0.9998311400413513, "entropy": 0.3886626958847046, "incre_win_rate": 0.775, "step": 2032}
{"time": 1767088492.369217, "phase": "train", "update": 2033, "total_env_steps": 6505600, "episode_reward": 0.24685122072696686, "value_loss": 0.007058867905288935, "policy_loss": -0.001141333636768671, "dist_entropy": 0.37610782980918883, "actor_grad_norm": 0.09944134205579758, "critic_grad_norm": 0.01701679639518261, "ratio": 1.000091314315796, "entropy": 0.37610782980918883, "incre_win_rate": 0.7727272727272727, "step": 2033}
{"time": 1767088496.9342113, "phase": "train", "update": 2034, "total_env_steps": 6508800, "episode_reward": 0.25746792554855347, "value_loss": 0.008117383904755115, "policy_loss": -0.0012817776404489222, "dist_entropy": 0.3622563362121582, "actor_grad_norm": 0.09835155308246613, "critic_grad_norm": 0.02983151376247406, "ratio": 1.0001784563064575, "entropy": 0.3622563362121582, "incre_win_rate": 0.7857142857142857, "step": 2034}
{"time": 1767088501.3954995, "phase": "train", "update": 2035, "total_env_steps": 6512000, "episode_reward": 0.2451086789369583, "value_loss": 0.00916319377720356, "policy_loss": -0.0011254168886999593, "dist_entropy": 0.3682789981365204, "actor_grad_norm": 0.1263251155614853, "critic_grad_norm": 0.04954270273447037, "ratio": 0.9999899864196777, "entropy": 0.3682789981365204, "incre_win_rate": 0.75, "step": 2035}
{"time": 1767088505.906317, "phase": "train", "update": 2036, "total_env_steps": 6515200, "episode_reward": 0.2465759813785553, "value_loss": 0.0069068452343344685, "policy_loss": -0.0015082621421166563, "dist_entropy": 0.37991071939468385, "actor_grad_norm": 0.10896667093038559, "critic_grad_norm": 0.05135894939303398, "ratio": 0.9994720816612244, "entropy": 0.37991071939468385, "incre_win_rate": 0.8, "step": 2036}
{"time": 1767088510.418226, "phase": "train", "update": 2037, "total_env_steps": 6518400, "episode_reward": 0.2556011974811554, "value_loss": 0.006480979733169079, "policy_loss": -0.0013049303645559008, "dist_entropy": 0.37093169093132017, "actor_grad_norm": 0.09205851703882217, "critic_grad_norm": 0.03702767193317413, "ratio": 0.9999176263809204, "entropy": 0.37093169093132017, "incre_win_rate": 0.8181818181818182, "step": 2037}
{"time": 1767088514.9705434, "phase": "train", "update": 2038, "total_env_steps": 6521600, "episode_reward": 0.2610006034374237, "value_loss": 0.006878561433404684, "policy_loss": -0.0013366630872909014, "dist_entropy": 0.37969797253608706, "actor_grad_norm": 0.10579308122396469, "critic_grad_norm": 0.040256351232528687, "ratio": 1.0002081394195557, "entropy": 0.37969797253608706, "incre_win_rate": 0.8333333333333334, "step": 2038}
{"time": 1767088519.473511, "phase": "train", "update": 2039, "total_env_steps": 6524800, "episode_reward": 0.23595406115055084, "value_loss": 0.010901451669633388, "policy_loss": -0.0016692374785321818, "dist_entropy": 0.3809326708316803, "actor_grad_norm": 0.11148183792829514, "critic_grad_norm": 0.026269955560564995, "ratio": 0.9998127818107605, "entropy": 0.3809326708316803, "incre_win_rate": 0.65, "step": 2039}
{"time": 1767088523.9778597, "phase": "train", "update": 2040, "total_env_steps": 6528000, "episode_reward": 0.24582214653491974, "value_loss": 0.009816447831690311, "policy_loss": -0.0012853835211629415, "dist_entropy": 0.3732038140296936, "actor_grad_norm": 0.1193750724196434, "critic_grad_norm": 0.0369640588760376, "ratio": 1.0000733137130737, "entropy": 0.3732038140296936, "incre_win_rate": 0.7674418604651163, "step": 2040}
{"time": 1767088528.6073744, "phase": "train", "update": 2041, "total_env_steps": 6531200, "episode_reward": 0.23976822197437286, "value_loss": 0.008580173924565315, "policy_loss": -0.0012826268018649501, "dist_entropy": 0.3732124209403992, "actor_grad_norm": 0.09766587615013123, "critic_grad_norm": 0.05056660994887352, "ratio": 0.9997088313102722, "entropy": 0.3732124209403992, "incre_win_rate": 0.6511627906976745, "step": 2041}
{"time": 1767088538.727475, "phase": "eval", "update": 2041, "total_env_steps": 6531200, "eval_win_rate": 1.0, "eval_episode_reward": 20.00620860927152, "step": 2041}
{"time": 1767088543.281936, "phase": "train", "update": 2042, "total_env_steps": 6534400, "episode_reward": 0.25801944732666016, "value_loss": 0.006583919934928417, "policy_loss": -0.0012633424581279585, "dist_entropy": 0.35918947458267214, "actor_grad_norm": 0.0924895629286766, "critic_grad_norm": 0.08116023242473602, "ratio": 1.0002506971359253, "entropy": 0.35918947458267214, "incre_win_rate": 0.8444444444444444, "step": 2042}
{"time": 1767088547.844055, "phase": "train", "update": 2043, "total_env_steps": 6537600, "episode_reward": 0.2537645101547241, "value_loss": 0.010265349224209786, "policy_loss": -0.0012288308067098797, "dist_entropy": 0.395002681016922, "actor_grad_norm": 0.10179004818201065, "critic_grad_norm": 0.06202671676874161, "ratio": 1.0000784397125244, "entropy": 0.395002681016922, "incre_win_rate": 0.7209302325581395, "step": 2043}
{"time": 1767088552.3576272, "phase": "train", "update": 2044, "total_env_steps": 6540800, "episode_reward": 0.24176636338233948, "value_loss": 0.010183518379926681, "policy_loss": -0.0013623695986495932, "dist_entropy": 0.3639377236366272, "actor_grad_norm": 0.14414602518081665, "critic_grad_norm": 0.04294710233807564, "ratio": 1.000055193901062, "entropy": 0.3639377236366272, "incre_win_rate": 0.6818181818181818, "step": 2044}
{"time": 1767088556.9801388, "phase": "train", "update": 2045, "total_env_steps": 6544000, "episode_reward": 0.2571285367012024, "value_loss": 0.008694400079548359, "policy_loss": -0.0014588938609442436, "dist_entropy": 0.3764231979846954, "actor_grad_norm": 0.13221628963947296, "critic_grad_norm": 0.017334675416350365, "ratio": 0.9997454881668091, "entropy": 0.3764231979846954, "incre_win_rate": 0.8, "step": 2045}
{"time": 1767088561.4393277, "phase": "train", "update": 2046, "total_env_steps": 6547200, "episode_reward": 0.23390313982963562, "value_loss": 0.010533451102674007, "policy_loss": -0.0014954307084545705, "dist_entropy": 0.3801277995109558, "actor_grad_norm": 0.11326934397220612, "critic_grad_norm": 0.03639084845781326, "ratio": 0.9998664855957031, "entropy": 0.3801277995109558, "incre_win_rate": 0.7209302325581395, "step": 2046}
{"time": 1767088566.0153754, "phase": "train", "update": 2047, "total_env_steps": 6550400, "episode_reward": 0.21845251321792603, "value_loss": 0.011974131688475609, "policy_loss": -0.0018836793037735333, "dist_entropy": 0.3846175134181976, "actor_grad_norm": 0.10712889581918716, "critic_grad_norm": 0.06783829629421234, "ratio": 0.9999468922615051, "entropy": 0.3846175134181976, "incre_win_rate": 0.625, "step": 2047}
{"time": 1767088570.5549266, "phase": "train", "update": 2048, "total_env_steps": 6553600, "episode_reward": 0.24729150533676147, "value_loss": 0.009974353574216365, "policy_loss": -0.0015361343031486286, "dist_entropy": 0.3807872712612152, "actor_grad_norm": 0.1124681755900383, "critic_grad_norm": 0.039820846170186996, "ratio": 0.99988853931427, "entropy": 0.3807872712612152, "incre_win_rate": 0.725, "step": 2048}
{"time": 1767088575.0563776, "phase": "train", "update": 2049, "total_env_steps": 6556800, "episode_reward": 0.24038752913475037, "value_loss": 0.009241010062396526, "policy_loss": -0.0015250423904113574, "dist_entropy": 0.36822919845581054, "actor_grad_norm": 0.15269938111305237, "critic_grad_norm": 0.03582214191555977, "ratio": 0.999657928943634, "entropy": 0.36822919845581054, "incre_win_rate": 0.7142857142857143, "step": 2049}
{"time": 1767088579.5342374, "phase": "train", "update": 2050, "total_env_steps": 6560000, "episode_reward": 0.23299823701381683, "value_loss": 0.00820375606417656, "policy_loss": -0.001620947626788194, "dist_entropy": 0.35989253520965575, "actor_grad_norm": 0.13658927381038666, "critic_grad_norm": 0.030202073976397514, "ratio": 0.999872624874115, "entropy": 0.35989253520965575, "incre_win_rate": 0.6511627906976745, "step": 2050}
{"time": 1767088584.0336318, "phase": "train", "update": 2051, "total_env_steps": 6563200, "episode_reward": 0.2503393888473511, "value_loss": 0.009979809634387493, "policy_loss": -0.001623566275074495, "dist_entropy": 0.36589322090148924, "actor_grad_norm": 0.13345082104206085, "critic_grad_norm": 0.032945338636636734, "ratio": 1.0000200271606445, "entropy": 0.36589322090148924, "incre_win_rate": 0.7435897435897436, "step": 2051}
{"time": 1767088588.5270998, "phase": "train", "update": 2052, "total_env_steps": 6566400, "episode_reward": 0.2105380892753601, "value_loss": 0.010750497691333294, "policy_loss": -0.0015565622714836635, "dist_entropy": 0.3639304578304291, "actor_grad_norm": 0.12427865713834763, "critic_grad_norm": 0.04841619357466698, "ratio": 1.0001901388168335, "entropy": 0.3639304578304291, "incre_win_rate": 0.7, "step": 2052}
{"time": 1767088593.0354655, "phase": "train", "update": 2053, "total_env_steps": 6569600, "episode_reward": 0.24006415903568268, "value_loss": 0.012064584344625474, "policy_loss": -0.0013389263334449453, "dist_entropy": 0.3715545177459717, "actor_grad_norm": 0.12078755348920822, "critic_grad_norm": 0.053646136075258255, "ratio": 0.9998320937156677, "entropy": 0.3715545177459717, "incre_win_rate": 0.7073170731707317, "step": 2053}
{"time": 1767088597.5360382, "phase": "train", "update": 2054, "total_env_steps": 6572800, "episode_reward": 0.227641761302948, "value_loss": 0.01103066150099039, "policy_loss": -0.0013015398244377251, "dist_entropy": 0.3442809283733368, "actor_grad_norm": 0.14042596518993378, "critic_grad_norm": 0.039921462535858154, "ratio": 1.0001420974731445, "entropy": 0.3442809283733368, "incre_win_rate": 0.6097560975609756, "step": 2054}
{"time": 1767088602.0025032, "phase": "train", "update": 2055, "total_env_steps": 6576000, "episode_reward": 0.2330598086118698, "value_loss": 0.008996588923037053, "policy_loss": -0.0014045448229282442, "dist_entropy": 0.34678341150283815, "actor_grad_norm": 0.13312578201293945, "critic_grad_norm": 0.06895816326141357, "ratio": 0.9998356699943542, "entropy": 0.34678341150283815, "incre_win_rate": 0.6428571428571429, "step": 2055}
{"time": 1767088606.5873299, "phase": "train", "update": 2056, "total_env_steps": 6579200, "episode_reward": 0.26032182574272156, "value_loss": 0.007549808453768491, "policy_loss": -0.001300420420914783, "dist_entropy": 0.36111319065093994, "actor_grad_norm": 0.1869371384382248, "critic_grad_norm": 0.07973204553127289, "ratio": 1.0002007484436035, "entropy": 0.36111319065093994, "incre_win_rate": 0.813953488372093, "step": 2056}
{"time": 1767088611.1212347, "phase": "train", "update": 2057, "total_env_steps": 6582400, "episode_reward": 0.2526293694972992, "value_loss": 0.007690637931227684, "policy_loss": -0.0014219357865866479, "dist_entropy": 0.3632344424724579, "actor_grad_norm": 0.19463053345680237, "critic_grad_norm": 0.030528461560606956, "ratio": 1.0001581907272339, "entropy": 0.3632344424724579, "incre_win_rate": 0.7727272727272727, "step": 2057}
{"time": 1767088615.65269, "phase": "train", "update": 2058, "total_env_steps": 6585600, "episode_reward": 0.23478993773460388, "value_loss": 0.012802482023835183, "policy_loss": -0.0012749807049289076, "dist_entropy": 0.38795787692070005, "actor_grad_norm": 0.19834640622138977, "critic_grad_norm": 0.08597227931022644, "ratio": 1.0003424882888794, "entropy": 0.38795787692070005, "incre_win_rate": 0.627906976744186, "step": 2058}
{"time": 1767088620.2145896, "phase": "train", "update": 2059, "total_env_steps": 6588800, "episode_reward": 0.26348045468330383, "value_loss": 0.009385197609663009, "policy_loss": -0.0011655917439885144, "dist_entropy": 0.36583065390586855, "actor_grad_norm": 0.11122315376996994, "critic_grad_norm": 0.06500118225812912, "ratio": 0.9995831847190857, "entropy": 0.36583065390586855, "incre_win_rate": 0.813953488372093, "step": 2059}
{"time": 1767088624.6948016, "phase": "train", "update": 2060, "total_env_steps": 6592000, "episode_reward": 0.23628725111484528, "value_loss": 0.00712949987500906, "policy_loss": -0.001349602557733931, "dist_entropy": 0.3706196367740631, "actor_grad_norm": 0.09813126176595688, "critic_grad_norm": 0.04049312695860863, "ratio": 1.0001806020736694, "entropy": 0.3706196367740631, "incre_win_rate": 0.7, "step": 2060}
{"time": 1767088629.1970403, "phase": "train", "update": 2061, "total_env_steps": 6595200, "episode_reward": 0.22635139524936676, "value_loss": 0.011487622372806072, "policy_loss": -0.0015658175339652303, "dist_entropy": 0.3916385114192963, "actor_grad_norm": 0.11897116899490356, "critic_grad_norm": 0.06934826821088791, "ratio": 0.9998834729194641, "entropy": 0.3916385114192963, "incre_win_rate": 0.6341463414634146, "step": 2061}
{"time": 1767088639.2632918, "phase": "eval", "update": 2061, "total_env_steps": 6595200, "eval_win_rate": 0.8125, "eval_episode_reward": 18.68868998344371, "step": 2061}
{"time": 1767088643.7961729, "phase": "train", "update": 2062, "total_env_steps": 6598400, "episode_reward": 0.2698530852794647, "value_loss": 0.0064578307792544365, "policy_loss": -0.0012150220123295697, "dist_entropy": 0.3698059320449829, "actor_grad_norm": 0.12008170038461685, "critic_grad_norm": 0.10704904794692993, "ratio": 1.0004099607467651, "entropy": 0.3698059320449829, "incre_win_rate": 0.8837209302325582, "step": 2062}
{"time": 1767088648.316479, "phase": "train", "update": 2063, "total_env_steps": 6601600, "episode_reward": 0.23538029193878174, "value_loss": 0.009250609017908574, "policy_loss": -0.0017252758744348284, "dist_entropy": 0.38206239938735964, "actor_grad_norm": 0.14872415363788605, "critic_grad_norm": 0.07576257735490799, "ratio": 0.9998367428779602, "entropy": 0.38206239938735964, "incre_win_rate": 0.6585365853658537, "step": 2063}
{"time": 1767088652.7665558, "phase": "train", "update": 2064, "total_env_steps": 6604800, "episode_reward": 0.22846390306949615, "value_loss": 0.008343848958611488, "policy_loss": -0.001591575418832747, "dist_entropy": 0.37217770218849183, "actor_grad_norm": 0.14967750012874603, "critic_grad_norm": 0.061030156910419464, "ratio": 1.000128984451294, "entropy": 0.37217770218849183, "incre_win_rate": 0.65, "step": 2064}
{"time": 1767088657.3327076, "phase": "train", "update": 2065, "total_env_steps": 6608000, "episode_reward": 0.2573830485343933, "value_loss": 0.009552891552448272, "policy_loss": -0.0011285623755718176, "dist_entropy": 0.3669744849205017, "actor_grad_norm": 0.13050736486911774, "critic_grad_norm": 0.05412595346570015, "ratio": 1.0001026391983032, "entropy": 0.3669744849205017, "incre_win_rate": 0.7555555555555555, "step": 2065}
{"time": 1767088661.8841336, "phase": "train", "update": 2066, "total_env_steps": 6611200, "episode_reward": 0.2659561336040497, "value_loss": 0.007706993818283081, "policy_loss": -0.0011326034830787535, "dist_entropy": 0.36144787073135376, "actor_grad_norm": 0.11849483102560043, "critic_grad_norm": 0.049312859773635864, "ratio": 0.9999715685844421, "entropy": 0.36144787073135376, "incre_win_rate": 0.8809523809523809, "step": 2066}
{"time": 1767088666.4503093, "phase": "train", "update": 2067, "total_env_steps": 6614400, "episode_reward": 0.2375103384256363, "value_loss": 0.008900223486125469, "policy_loss": -0.0015040917250942697, "dist_entropy": 0.38371399641036985, "actor_grad_norm": 0.12426121532917023, "critic_grad_norm": 0.03582533076405525, "ratio": 1.0000388622283936, "entropy": 0.38371399641036985, "incre_win_rate": 0.6590909090909091, "step": 2067}
{"time": 1767088670.9985354, "phase": "train", "update": 2068, "total_env_steps": 6617600, "episode_reward": 0.25954779982566833, "value_loss": 0.008312917314469814, "policy_loss": -0.0013576746868483093, "dist_entropy": 0.36787974238395693, "actor_grad_norm": 0.145870640873909, "critic_grad_norm": 0.024305220693349838, "ratio": 1.0001085996627808, "entropy": 0.36787974238395693, "incre_win_rate": 0.7906976744186046, "step": 2068}
{"time": 1767088675.5324795, "phase": "train", "update": 2069, "total_env_steps": 6620800, "episode_reward": 0.25354355573654175, "value_loss": 0.008407125435769557, "policy_loss": -0.0011135098169148705, "dist_entropy": 0.369442355632782, "actor_grad_norm": 0.12630394101142883, "critic_grad_norm": 0.028862837702035904, "ratio": 0.9999901056289673, "entropy": 0.369442355632782, "incre_win_rate": 0.8333333333333334, "step": 2069}
{"time": 1767088680.0580971, "phase": "train", "update": 2070, "total_env_steps": 6624000, "episode_reward": 0.2574699819087982, "value_loss": 0.006419503409415483, "policy_loss": -0.001468860252465376, "dist_entropy": 0.3741017937660217, "actor_grad_norm": 0.12452953308820724, "critic_grad_norm": 0.028484687209129333, "ratio": 1.0001353025436401, "entropy": 0.3741017937660217, "incre_win_rate": 0.8, "step": 2070}
{"time": 1767088684.5380158, "phase": "train", "update": 2071, "total_env_steps": 6627200, "episode_reward": 0.2358531802892685, "value_loss": 0.011002941057085991, "policy_loss": -0.0016634760533118965, "dist_entropy": 0.38594948053359984, "actor_grad_norm": 0.19428887963294983, "critic_grad_norm": 0.06882604956626892, "ratio": 0.9998192191123962, "entropy": 0.38594948053359984, "incre_win_rate": 0.675, "step": 2071}
{"time": 1767088689.1188817, "phase": "train", "update": 2072, "total_env_steps": 6630400, "episode_reward": 0.25146421790122986, "value_loss": 0.010086707770824432, "policy_loss": -0.0018392088712516851, "dist_entropy": 0.3486092507839203, "actor_grad_norm": 0.1275586485862732, "critic_grad_norm": 0.062025368213653564, "ratio": 0.9997382164001465, "entropy": 0.3486092507839203, "incre_win_rate": 0.75, "step": 2072}
{"time": 1767088693.5855246, "phase": "train", "update": 2073, "total_env_steps": 6633600, "episode_reward": 0.24701263010501862, "value_loss": 0.00746335843577981, "policy_loss": -0.001218114896553857, "dist_entropy": 0.3895746111869812, "actor_grad_norm": 0.11543279141187668, "critic_grad_norm": 0.058574020862579346, "ratio": 1.000179648399353, "entropy": 0.3895746111869812, "incre_win_rate": 0.7380952380952381, "step": 2073}
{"time": 1767088698.1230395, "phase": "train", "update": 2074, "total_env_steps": 6636800, "episode_reward": 0.24662356078624725, "value_loss": 0.009525089152157306, "policy_loss": -0.0013929775998782646, "dist_entropy": 0.3733246386051178, "actor_grad_norm": 0.12713240087032318, "critic_grad_norm": 0.03799634054303169, "ratio": 0.999974250793457, "entropy": 0.3733246386051178, "incre_win_rate": 0.7380952380952381, "step": 2074}
{"time": 1767088702.639337, "phase": "train", "update": 2075, "total_env_steps": 6640000, "episode_reward": 0.2380799800157547, "value_loss": 0.009921635873615742, "policy_loss": -0.0014322180451088683, "dist_entropy": 0.3815110743045807, "actor_grad_norm": 0.1466895341873169, "critic_grad_norm": 0.050011832267045975, "ratio": 0.9996612668037415, "entropy": 0.3815110743045807, "incre_win_rate": 0.6904761904761905, "step": 2075}
{"time": 1767088707.148617, "phase": "train", "update": 2076, "total_env_steps": 6643200, "episode_reward": 0.22448419034481049, "value_loss": 0.012953760661184787, "policy_loss": -0.0018233385249459388, "dist_entropy": 0.3859664976596832, "actor_grad_norm": 0.1275605708360672, "critic_grad_norm": 0.04902048408985138, "ratio": 1.0000636577606201, "entropy": 0.3859664976596832, "incre_win_rate": 0.6666666666666666, "step": 2076}
{"time": 1767088711.644277, "phase": "train", "update": 2077, "total_env_steps": 6646400, "episode_reward": 0.22296151518821716, "value_loss": 0.010486547835171223, "policy_loss": -0.001762474377507317, "dist_entropy": 0.4082262873649597, "actor_grad_norm": 0.13867656886577606, "critic_grad_norm": 0.05411502718925476, "ratio": 0.9998265504837036, "entropy": 0.4082262873649597, "incre_win_rate": 0.6341463414634146, "step": 2077}
{"time": 1767088716.1400585, "phase": "train", "update": 2078, "total_env_steps": 6649600, "episode_reward": 0.2469603717327118, "value_loss": 0.008186632022261619, "policy_loss": -0.0011920011509580775, "dist_entropy": 0.3797202050685883, "actor_grad_norm": 0.12597541511058807, "critic_grad_norm": 0.06338264793157578, "ratio": 1.0000150203704834, "entropy": 0.3797202050685883, "incre_win_rate": 0.775, "step": 2078}
{"time": 1767088720.6970994, "phase": "train", "update": 2079, "total_env_steps": 6652800, "episode_reward": 0.23859375715255737, "value_loss": 0.011150114051997662, "policy_loss": -0.0015380410258714506, "dist_entropy": 0.40275458097457884, "actor_grad_norm": 0.13720081746578217, "critic_grad_norm": 0.08132290840148926, "ratio": 0.9998379945755005, "entropy": 0.40275458097457884, "incre_win_rate": 0.6511627906976745, "step": 2079}
{"time": 1767088725.2820246, "phase": "train", "update": 2080, "total_env_steps": 6656000, "episode_reward": 0.2631855309009552, "value_loss": 0.009123165905475617, "policy_loss": -0.0009313541240800304, "dist_entropy": 0.382664692401886, "actor_grad_norm": 0.11806203424930573, "critic_grad_norm": 0.07085584849119186, "ratio": 0.9997669458389282, "entropy": 0.382664692401886, "incre_win_rate": 0.7674418604651163, "step": 2080}
{"time": 1767088729.8525405, "phase": "train", "update": 2081, "total_env_steps": 6659200, "episode_reward": 0.24800963699817657, "value_loss": 0.009055310115218162, "policy_loss": -0.001544161439326608, "dist_entropy": 0.38757368326187136, "actor_grad_norm": 0.13507716357707977, "critic_grad_norm": 0.06371933221817017, "ratio": 1.000010371208191, "entropy": 0.38757368326187136, "incre_win_rate": 0.7272727272727273, "step": 2081}
{"time": 1767088740.7394075, "phase": "eval", "update": 2081, "total_env_steps": 6659200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.510554635761586, "step": 2081}
{"time": 1767088745.2605634, "phase": "train", "update": 2082, "total_env_steps": 6662400, "episode_reward": 0.25132349133491516, "value_loss": 0.010033389553427696, "policy_loss": -0.0010083208105427844, "dist_entropy": 0.37914846539497377, "actor_grad_norm": 0.13269077241420746, "critic_grad_norm": 0.02889733575284481, "ratio": 1.000084400177002, "entropy": 0.37914846539497377, "incre_win_rate": 0.7619047619047619, "step": 2082}
{"time": 1767088749.7924464, "phase": "train", "update": 2083, "total_env_steps": 6665600, "episode_reward": 0.2392953336238861, "value_loss": 0.008987489342689513, "policy_loss": -0.001336728192741532, "dist_entropy": 0.39397708773612977, "actor_grad_norm": 0.15034006536006927, "critic_grad_norm": 0.02983654849231243, "ratio": 1.0000779628753662, "entropy": 0.39397708773612977, "incre_win_rate": 0.7619047619047619, "step": 2083}
{"time": 1767088754.2723696, "phase": "train", "update": 2084, "total_env_steps": 6668800, "episode_reward": 0.23914062976837158, "value_loss": 0.008720779046416282, "policy_loss": -0.0015994061200487407, "dist_entropy": 0.3739048182964325, "actor_grad_norm": 0.15427890419960022, "critic_grad_norm": 0.03515090048313141, "ratio": 0.9999252557754517, "entropy": 0.3739048182964325, "incre_win_rate": 0.75, "step": 2084}
{"time": 1767088758.7787826, "phase": "train", "update": 2085, "total_env_steps": 6672000, "episode_reward": 0.23958401381969452, "value_loss": 0.009503051824867725, "policy_loss": -0.0011468570635457809, "dist_entropy": 0.378934508562088, "actor_grad_norm": 0.14745444059371948, "critic_grad_norm": 0.02852562442421913, "ratio": 0.9999025464057922, "entropy": 0.378934508562088, "incre_win_rate": 0.7073170731707317, "step": 2085}
{"time": 1767088763.302429, "phase": "train", "update": 2086, "total_env_steps": 6675200, "episode_reward": 0.25219112634658813, "value_loss": 0.008688025921583176, "policy_loss": -0.0012265319759869441, "dist_entropy": 0.3870193064212799, "actor_grad_norm": 0.14042295515537262, "critic_grad_norm": 0.041183050721883774, "ratio": 0.9998165965080261, "entropy": 0.3870193064212799, "incre_win_rate": 0.7111111111111111, "step": 2086}
{"time": 1767088767.8151383, "phase": "train", "update": 2087, "total_env_steps": 6678400, "episode_reward": 0.2376277893781662, "value_loss": 0.009674373641610145, "policy_loss": -0.0014213309365203486, "dist_entropy": 0.4049020290374756, "actor_grad_norm": 0.12988264858722687, "critic_grad_norm": 0.03483172878623009, "ratio": 1.000180721282959, "entropy": 0.4049020290374756, "incre_win_rate": 0.725, "step": 2087}
{"time": 1767088772.3294063, "phase": "train", "update": 2088, "total_env_steps": 6681600, "episode_reward": 0.24102236330509186, "value_loss": 0.008563893660902978, "policy_loss": -0.001456004652671794, "dist_entropy": 0.3895889222621918, "actor_grad_norm": 0.11196698248386383, "critic_grad_norm": 0.03908137232065201, "ratio": 0.9996480345726013, "entropy": 0.3895889222621918, "incre_win_rate": 0.7804878048780488, "step": 2088}
{"time": 1767088776.8518565, "phase": "train", "update": 2089, "total_env_steps": 6684800, "episode_reward": 0.2554263174533844, "value_loss": 0.008126152027398349, "policy_loss": -0.0013964459030752607, "dist_entropy": 0.3994052529335022, "actor_grad_norm": 0.1209062859416008, "critic_grad_norm": 0.033397022634744644, "ratio": 0.9997619986534119, "entropy": 0.3994052529335022, "incre_win_rate": 0.813953488372093, "step": 2089}
{"time": 1767088781.3679852, "phase": "train", "update": 2090, "total_env_steps": 6688000, "episode_reward": 0.2347516566514969, "value_loss": 0.011758808419108391, "policy_loss": -0.001379218040148089, "dist_entropy": 0.37357288002967837, "actor_grad_norm": 0.1158829927444458, "critic_grad_norm": 0.05222850665450096, "ratio": 1.0001633167266846, "entropy": 0.37357288002967837, "incre_win_rate": 0.6190476190476191, "step": 2090}
{"time": 1767088785.9594944, "phase": "train", "update": 2091, "total_env_steps": 6691200, "episode_reward": 0.2531576156616211, "value_loss": 0.00940528865903616, "policy_loss": -0.001368434140694319, "dist_entropy": 0.3743924260139465, "actor_grad_norm": 0.11710672825574875, "critic_grad_norm": 0.0386197529733181, "ratio": 0.9997914433479309, "entropy": 0.3743924260139465, "incre_win_rate": 0.6976744186046512, "step": 2091}
{"time": 1767088790.47276, "phase": "train", "update": 2092, "total_env_steps": 6694400, "episode_reward": 0.2525833249092102, "value_loss": 0.009003856964409352, "policy_loss": -0.0013635979207435867, "dist_entropy": 0.3809069752693176, "actor_grad_norm": 0.1241377741098404, "critic_grad_norm": 0.06894879788160324, "ratio": 1.0000461339950562, "entropy": 0.3809069752693176, "incre_win_rate": 0.8372093023255814, "step": 2092}
{"time": 1767088795.0633838, "phase": "train", "update": 2093, "total_env_steps": 6697600, "episode_reward": 0.2635720372200012, "value_loss": 0.007623060699552297, "policy_loss": -0.001481787871962581, "dist_entropy": 0.37015276551246645, "actor_grad_norm": 0.1849164068698883, "critic_grad_norm": 0.057486068457365036, "ratio": 0.9999229311943054, "entropy": 0.37015276551246645, "incre_win_rate": 0.7777777777777778, "step": 2093}
{"time": 1767088799.641039, "phase": "train", "update": 2094, "total_env_steps": 6700800, "episode_reward": 0.2639564573764801, "value_loss": 0.006018359400331974, "policy_loss": -0.0013412795145470112, "dist_entropy": 0.3677383244037628, "actor_grad_norm": 0.1900317221879959, "critic_grad_norm": 0.04703601822257042, "ratio": 0.9998180270195007, "entropy": 0.3677383244037628, "incre_win_rate": 0.8409090909090909, "step": 2094}
{"time": 1767088804.2230344, "phase": "train", "update": 2095, "total_env_steps": 6704000, "episode_reward": 0.25316381454467773, "value_loss": 0.008782887272536755, "policy_loss": -0.0015110232991297323, "dist_entropy": 0.37093132734298706, "actor_grad_norm": 0.17093613743782043, "critic_grad_norm": 0.037634722888469696, "ratio": 0.9996782541275024, "entropy": 0.37093132734298706, "incre_win_rate": 0.825, "step": 2095}
{"time": 1767088808.875947, "phase": "train", "update": 2096, "total_env_steps": 6707200, "episode_reward": 0.2538069188594818, "value_loss": 0.005611348152160645, "policy_loss": -0.0014325351990677859, "dist_entropy": 0.36610684990882875, "actor_grad_norm": 0.1571505069732666, "critic_grad_norm": 0.034928254783153534, "ratio": 1.0004360675811768, "entropy": 0.36610684990882875, "incre_win_rate": 0.8, "step": 2096}
{"time": 1767088813.381449, "phase": "train", "update": 2097, "total_env_steps": 6710400, "episode_reward": 0.2500072419643402, "value_loss": 0.006672289967536926, "policy_loss": -0.0014860722686890425, "dist_entropy": 0.36072495579719543, "actor_grad_norm": 0.16169267892837524, "critic_grad_norm": 0.03641238436102867, "ratio": 0.9999635815620422, "entropy": 0.36072495579719543, "incre_win_rate": 0.8095238095238095, "step": 2097}
{"time": 1767088817.8481812, "phase": "train", "update": 2098, "total_env_steps": 6713600, "episode_reward": 0.23792323470115662, "value_loss": 0.009279793314635753, "policy_loss": -0.0019479718651336242, "dist_entropy": 0.37172272205352785, "actor_grad_norm": 0.15393587946891785, "critic_grad_norm": 0.08633359521627426, "ratio": 0.9995754361152649, "entropy": 0.37172272205352785, "incre_win_rate": 0.75, "step": 2098}
{"time": 1767088822.3471978, "phase": "train", "update": 2099, "total_env_steps": 6716800, "episode_reward": 0.22779075801372528, "value_loss": 0.007695770636200905, "policy_loss": -0.0013574380395510843, "dist_entropy": 0.36651466488838197, "actor_grad_norm": 0.13086017966270447, "critic_grad_norm": 0.052720095962285995, "ratio": 0.9994945526123047, "entropy": 0.36651466488838197, "incre_win_rate": 0.6923076923076923, "step": 2099}
{"time": 1767088826.888753, "phase": "train", "update": 2100, "total_env_steps": 6720000, "episode_reward": 0.2495286762714386, "value_loss": 0.007253196928650141, "policy_loss": -0.0010580065467834742, "dist_entropy": 0.3565418243408203, "actor_grad_norm": 0.1335388422012329, "critic_grad_norm": 0.040371235460042953, "ratio": 0.9997442364692688, "entropy": 0.3565418243408203, "incre_win_rate": 0.7906976744186046, "step": 2100}
{"time": 1767088831.4159107, "phase": "train", "update": 2101, "total_env_steps": 6723200, "episode_reward": 0.2548597753047943, "value_loss": 0.006644724868237972, "policy_loss": -0.0016432104908929545, "dist_entropy": 0.34687801599502566, "actor_grad_norm": 0.13614559173583984, "critic_grad_norm": 0.038040321320295334, "ratio": 1.000076174736023, "entropy": 0.34687801599502566, "incre_win_rate": 0.8571428571428571, "step": 2101}
{"time": 1767088841.9150887, "phase": "eval", "update": 2101, "total_env_steps": 6723200, "eval_win_rate": 0.84375, "eval_episode_reward": 19.256415562913908, "step": 2101}
{"time": 1767088846.4064093, "phase": "train", "update": 2102, "total_env_steps": 6726400, "episode_reward": 0.2493993192911148, "value_loss": 0.005852970201522112, "policy_loss": -0.0016369304412350515, "dist_entropy": 0.36699460744857787, "actor_grad_norm": 0.11568816751241684, "critic_grad_norm": 0.034770071506500244, "ratio": 1.0002110004425049, "entropy": 0.36699460744857787, "incre_win_rate": 0.7619047619047619, "step": 2102}
{"time": 1767088850.9453485, "phase": "train", "update": 2103, "total_env_steps": 6729600, "episode_reward": 0.2410016655921936, "value_loss": 0.010145859979093074, "policy_loss": -0.0016793745871922284, "dist_entropy": 0.361198228597641, "actor_grad_norm": 0.10922747105360031, "critic_grad_norm": 0.04321368783712387, "ratio": 1.0001410245895386, "entropy": 0.361198228597641, "incre_win_rate": 0.7317073170731707, "step": 2103}
{"time": 1767088855.451824, "phase": "train", "update": 2104, "total_env_steps": 6732800, "episode_reward": 0.2459302544593811, "value_loss": 0.008329318091273307, "policy_loss": -0.0011561018803312173, "dist_entropy": 0.358479768037796, "actor_grad_norm": 0.20325739681720734, "critic_grad_norm": 0.04436011239886284, "ratio": 1.0001273155212402, "entropy": 0.358479768037796, "incre_win_rate": 0.7209302325581395, "step": 2104}
{"time": 1767088860.0098085, "phase": "train", "update": 2105, "total_env_steps": 6736000, "episode_reward": 0.25016453862190247, "value_loss": 0.006385309528559447, "policy_loss": -0.0015058647547981252, "dist_entropy": 0.3614632189273834, "actor_grad_norm": 0.17490318417549133, "critic_grad_norm": 0.03668414428830147, "ratio": 0.9998053908348083, "entropy": 0.3614632189273834, "incre_win_rate": 0.7906976744186046, "step": 2105}
{"time": 1767088864.5039787, "phase": "train", "update": 2106, "total_env_steps": 6739200, "episode_reward": 0.2547619938850403, "value_loss": 0.005285310558974743, "policy_loss": -0.0013090305727985196, "dist_entropy": 0.37177722454071044, "actor_grad_norm": 0.1481725126504898, "critic_grad_norm": 0.027388839051127434, "ratio": 0.999846875667572, "entropy": 0.37177722454071044, "incre_win_rate": 0.8780487804878049, "step": 2106}
{"time": 1767088869.0406592, "phase": "train", "update": 2107, "total_env_steps": 6742400, "episode_reward": 0.2598680853843689, "value_loss": 0.0062370670959353445, "policy_loss": -0.0012177956884897867, "dist_entropy": 0.3565837681293488, "actor_grad_norm": 0.13409344851970673, "critic_grad_norm": 0.02641746960580349, "ratio": 0.9999087452888489, "entropy": 0.3565837681293488, "incre_win_rate": 0.8604651162790697, "step": 2107}
{"time": 1767088873.561917, "phase": "train", "update": 2108, "total_env_steps": 6745600, "episode_reward": 0.2367425411939621, "value_loss": 0.008067955821752548, "policy_loss": -0.0013442089883547227, "dist_entropy": 0.3581850349903107, "actor_grad_norm": 0.17183052003383636, "critic_grad_norm": 0.046635132282972336, "ratio": 0.9996759295463562, "entropy": 0.3581850349903107, "incre_win_rate": 0.7073170731707317, "step": 2108}
{"time": 1767088878.0914364, "phase": "train", "update": 2109, "total_env_steps": 6748800, "episode_reward": 0.22915200889110565, "value_loss": 0.010109987482428551, "policy_loss": -0.001509760085966505, "dist_entropy": 0.35799271464347837, "actor_grad_norm": 0.19260382652282715, "critic_grad_norm": 0.07437510788440704, "ratio": 0.9998337030410767, "entropy": 0.35799271464347837, "incre_win_rate": 0.525, "step": 2109}
{"time": 1767088882.6326547, "phase": "train", "update": 2110, "total_env_steps": 6752000, "episode_reward": 0.25363409519195557, "value_loss": 0.007849319465458393, "policy_loss": -0.0014396344041820441, "dist_entropy": 0.3502197742462158, "actor_grad_norm": 0.16982415318489075, "critic_grad_norm": 0.0544702522456646, "ratio": 0.9999191164970398, "entropy": 0.3502197742462158, "incre_win_rate": 0.8, "step": 2110}
{"time": 1767088887.1274583, "phase": "train", "update": 2111, "total_env_steps": 6755200, "episode_reward": 0.2283743917942047, "value_loss": 0.009738289564847947, "policy_loss": -0.0017745015996112556, "dist_entropy": 0.37833069562911986, "actor_grad_norm": 0.22836942970752716, "critic_grad_norm": 0.045488011091947556, "ratio": 0.9999853372573853, "entropy": 0.37833069562911986, "incre_win_rate": 0.717948717948718, "step": 2111}
{"time": 1767088891.6201565, "phase": "train", "update": 2112, "total_env_steps": 6758400, "episode_reward": 0.23140054941177368, "value_loss": 0.011152193322777748, "policy_loss": -0.001358024312698447, "dist_entropy": 0.37771650552749636, "actor_grad_norm": 0.1732579469680786, "critic_grad_norm": 0.04410785436630249, "ratio": 1.000174641609192, "entropy": 0.37771650552749636, "incre_win_rate": 0.717948717948718, "step": 2112}
{"time": 1767088896.069799, "phase": "train", "update": 2113, "total_env_steps": 6761600, "episode_reward": 0.2427007555961609, "value_loss": 0.009441640228033066, "policy_loss": -0.0018767667859187042, "dist_entropy": 0.37435991764068605, "actor_grad_norm": 0.17423586547374725, "critic_grad_norm": 0.04320243000984192, "ratio": 0.9999990463256836, "entropy": 0.37435991764068605, "incre_win_rate": 0.7906976744186046, "step": 2113}
{"time": 1767088900.6328611, "phase": "train", "update": 2114, "total_env_steps": 6764800, "episode_reward": 0.2452271431684494, "value_loss": 0.00826158318668604, "policy_loss": -0.0015103703390050073, "dist_entropy": 0.3744509220123291, "actor_grad_norm": 0.129146009683609, "critic_grad_norm": 0.05071282014250755, "ratio": 1.0000051259994507, "entropy": 0.3744509220123291, "incre_win_rate": 0.7619047619047619, "step": 2114}
{"time": 1767088905.2597573, "phase": "train", "update": 2115, "total_env_steps": 6768000, "episode_reward": 0.23756469786167145, "value_loss": 0.011279485747218132, "policy_loss": -0.0017031847792281952, "dist_entropy": 0.3930699110031128, "actor_grad_norm": 0.14459381997585297, "critic_grad_norm": 0.030351419001817703, "ratio": 1.0001252889633179, "entropy": 0.3930699110031128, "incre_win_rate": 0.7, "step": 2115}
{"time": 1767088910.011271, "phase": "train", "update": 2116, "total_env_steps": 6771200, "episode_reward": 0.24354098737239838, "value_loss": 0.008312448486685753, "policy_loss": -0.0016015236114938602, "dist_entropy": 0.38203164339065554, "actor_grad_norm": 0.1864483803510666, "critic_grad_norm": 0.025723934173583984, "ratio": 0.999747097492218, "entropy": 0.38203164339065554, "incre_win_rate": 0.7441860465116279, "step": 2116}
{"time": 1767088914.595725, "phase": "train", "update": 2117, "total_env_steps": 6774400, "episode_reward": 0.2538425922393799, "value_loss": 0.007524356711655855, "policy_loss": -0.0010771405614519835, "dist_entropy": 0.3767309069633484, "actor_grad_norm": 0.15690866112709045, "critic_grad_norm": 0.04669018089771271, "ratio": 0.9999271631240845, "entropy": 0.3767309069633484, "incre_win_rate": 0.8095238095238095, "step": 2117}
{"time": 1767088919.1197784, "phase": "train", "update": 2118, "total_env_steps": 6777600, "episode_reward": 0.24820831418037415, "value_loss": 0.005038191098719835, "policy_loss": -0.0014078092658849073, "dist_entropy": 0.3852291703224182, "actor_grad_norm": 0.12463386356830597, "critic_grad_norm": 0.03496074676513672, "ratio": 0.9997491836547852, "entropy": 0.3852291703224182, "incre_win_rate": 0.8571428571428571, "step": 2118}
{"time": 1767088923.6935103, "phase": "train", "update": 2119, "total_env_steps": 6780800, "episode_reward": 0.25053083896636963, "value_loss": 0.008396494388580322, "policy_loss": -0.001462662945576909, "dist_entropy": 0.3775495529174805, "actor_grad_norm": 0.1047368049621582, "critic_grad_norm": 0.028544221073389053, "ratio": 0.9999276995658875, "entropy": 0.3775495529174805, "incre_win_rate": 0.7804878048780488, "step": 2119}
{"time": 1767088928.1842027, "phase": "train", "update": 2120, "total_env_steps": 6784000, "episode_reward": 0.25185275077819824, "value_loss": 0.0064716202206909655, "policy_loss": -0.0012815621740394079, "dist_entropy": 0.37581139206886294, "actor_grad_norm": 0.11225235462188721, "critic_grad_norm": 0.034305449575185776, "ratio": 0.9998856782913208, "entropy": 0.37581139206886294, "incre_win_rate": 0.7954545454545454, "step": 2120}
{"time": 1767088932.769301, "phase": "train", "update": 2121, "total_env_steps": 6787200, "episode_reward": 0.2437489926815033, "value_loss": 0.009757318533957005, "policy_loss": -0.0014805381503125935, "dist_entropy": 0.37572929859161375, "actor_grad_norm": 0.1434497982263565, "critic_grad_norm": 0.07177968323230743, "ratio": 1.0002702474594116, "entropy": 0.37572929859161375, "incre_win_rate": 0.6666666666666666, "step": 2121}
{"time": 1767088943.5870261, "phase": "eval", "update": 2121, "total_env_steps": 6787200, "eval_win_rate": 0.875, "eval_episode_reward": 19.459799254966885, "step": 2121}
{"time": 1767088948.0779934, "phase": "train", "update": 2122, "total_env_steps": 6790400, "episode_reward": 0.25115689635276794, "value_loss": 0.008669645711779594, "policy_loss": -0.0013013470444626306, "dist_entropy": 0.38275948762893675, "actor_grad_norm": 0.161407932639122, "critic_grad_norm": 0.059870388358831406, "ratio": 0.9998775720596313, "entropy": 0.38275948762893675, "incre_win_rate": 0.8780487804878049, "step": 2122}
{"time": 1767088952.6014404, "phase": "train", "update": 2123, "total_env_steps": 6793600, "episode_reward": 0.23695571720600128, "value_loss": 0.008287819102406502, "policy_loss": -0.001722969241649963, "dist_entropy": 0.3856279194355011, "actor_grad_norm": 0.12272846698760986, "critic_grad_norm": 0.03253002092242241, "ratio": 1.0001500844955444, "entropy": 0.3856279194355011, "incre_win_rate": 0.8, "step": 2123}
{"time": 1767088957.1096869, "phase": "train", "update": 2124, "total_env_steps": 6796800, "episode_reward": 0.250540167093277, "value_loss": 0.005439644865691662, "policy_loss": -0.0013897849772611438, "dist_entropy": 0.3819040358066559, "actor_grad_norm": 0.1098233014345169, "critic_grad_norm": 0.05230442434549332, "ratio": 0.9998942613601685, "entropy": 0.3819040358066559, "incre_win_rate": 0.8222222222222222, "step": 2124}
{"time": 1767088997.4751482, "phase": "train", "update": 2125, "total_env_steps": 6800000, "episode_reward": 0.23177826404571533, "value_loss": 0.034272085130214694, "policy_loss": -0.0022206323338400226, "dist_entropy": 0.39489926099777223, "actor_grad_norm": 0.1600818932056427, "critic_grad_norm": 0.2319210320711136, "ratio": 0.999852180480957, "entropy": 0.39489926099777223, "incre_win_rate": 0.75, "step": 2125}
{"time": 1767089002.7019434, "phase": "train", "update": 2126, "total_env_steps": 6803200, "episode_reward": 0.25322744250297546, "value_loss": 0.006989233288913965, "policy_loss": -0.001006380522011341, "dist_entropy": 0.38108829259872434, "actor_grad_norm": 0.1191936507821083, "critic_grad_norm": 0.14726881682872772, "ratio": 0.9997512698173523, "entropy": 0.38108829259872434, "incre_win_rate": 0.8372093023255814, "step": 2126}
{"time": 1767089007.9190357, "phase": "train", "update": 2127, "total_env_steps": 6806400, "episode_reward": 0.2549431025981903, "value_loss": 0.009318920783698559, "policy_loss": -0.001757235810943314, "dist_entropy": 0.3849122762680054, "actor_grad_norm": 0.1489637941122055, "critic_grad_norm": 0.11469803005456924, "ratio": 0.9998900294303894, "entropy": 0.3849122762680054, "incre_win_rate": 0.8372093023255814, "step": 2127}
{"time": 1767089012.9278255, "phase": "train", "update": 2128, "total_env_steps": 6809600, "episode_reward": 0.25840699672698975, "value_loss": 0.00823945989832282, "policy_loss": -0.0011203279689052438, "dist_entropy": 0.374092698097229, "actor_grad_norm": 0.146279439330101, "critic_grad_norm": 0.0953100323677063, "ratio": 0.9996803402900696, "entropy": 0.374092698097229, "incre_win_rate": 0.8571428571428571, "step": 2128}
{"time": 1767089018.4482985, "phase": "train", "update": 2129, "total_env_steps": 6812800, "episode_reward": 0.2430272102355957, "value_loss": 0.009083352610468864, "policy_loss": -0.0014195752065358392, "dist_entropy": 0.39123358130455016, "actor_grad_norm": 0.15196196734905243, "critic_grad_norm": 0.07499527186155319, "ratio": 1.0000685453414917, "entropy": 0.39123358130455016, "incre_win_rate": 0.7380952380952381, "step": 2129}
{"time": 1767089023.6353977, "phase": "train", "update": 2130, "total_env_steps": 6816000, "episode_reward": 0.25643831491470337, "value_loss": 0.00625712526962161, "policy_loss": -0.0017694900411152404, "dist_entropy": 0.38451706171035765, "actor_grad_norm": 0.12655411660671234, "critic_grad_norm": 0.06430790573358536, "ratio": 0.9998696446418762, "entropy": 0.38451706171035765, "incre_win_rate": 0.8536585365853658, "step": 2130}
{"time": 1767089028.4837193, "phase": "train", "update": 2131, "total_env_steps": 6819200, "episode_reward": 0.23754501342773438, "value_loss": 0.010732351988554, "policy_loss": -0.0015834521689082949, "dist_entropy": 0.3899152338504791, "actor_grad_norm": 0.13568246364593506, "critic_grad_norm": 0.09732204675674438, "ratio": 1.0002086162567139, "entropy": 0.3899152338504791, "incre_win_rate": 0.6888888888888889, "step": 2131}
{"time": 1767089033.4463437, "phase": "train", "update": 2132, "total_env_steps": 6822400, "episode_reward": 0.24978424608707428, "value_loss": 0.0071729269810020925, "policy_loss": -0.001376146568637182, "dist_entropy": 0.3985637903213501, "actor_grad_norm": 0.12787149846553802, "critic_grad_norm": 0.06294165551662445, "ratio": 1.0001314878463745, "entropy": 0.3985637903213501, "incre_win_rate": 0.8, "step": 2132}
{"time": 1767089038.3428247, "phase": "train", "update": 2133, "total_env_steps": 6825600, "episode_reward": 0.24223197996616364, "value_loss": 0.011566697806119918, "policy_loss": -0.0016308475262520883, "dist_entropy": 0.3945769429206848, "actor_grad_norm": 0.12502607703208923, "critic_grad_norm": 0.050920166075229645, "ratio": 0.9997639656066895, "entropy": 0.3945769429206848, "incre_win_rate": 0.7619047619047619, "step": 2133}
{"time": 1767089043.2797716, "phase": "train", "update": 2134, "total_env_steps": 6828800, "episode_reward": 0.2433842122554779, "value_loss": 0.007013000641018152, "policy_loss": -0.0016121970127009888, "dist_entropy": 0.38032448291778564, "actor_grad_norm": 0.1383010596036911, "critic_grad_norm": 0.054810117930173874, "ratio": 1.0001336336135864, "entropy": 0.38032448291778564, "incre_win_rate": 0.7560975609756098, "step": 2134}
{"time": 1767089048.1403444, "phase": "train", "update": 2135, "total_env_steps": 6832000, "episode_reward": 0.26324039697647095, "value_loss": 0.006077815406024456, "policy_loss": -0.0014454441551542629, "dist_entropy": 0.39380419850349424, "actor_grad_norm": 0.11951164156198502, "critic_grad_norm": 0.051115501672029495, "ratio": 0.9998841285705566, "entropy": 0.39380419850349424, "incre_win_rate": 0.8181818181818182, "step": 2135}
{"time": 1767089052.9795475, "phase": "train", "update": 2136, "total_env_steps": 6835200, "episode_reward": 0.24309396743774414, "value_loss": 0.007581089809536934, "policy_loss": -0.0018332564827190367, "dist_entropy": 0.38401140570640563, "actor_grad_norm": 0.11943160742521286, "critic_grad_norm": 0.027843967080116272, "ratio": 0.9999985694885254, "entropy": 0.38401140570640563, "incre_win_rate": 0.7857142857142857, "step": 2136}
{"time": 1767089057.8288376, "phase": "train", "update": 2137, "total_env_steps": 6838400, "episode_reward": 0.2567094564437866, "value_loss": 0.003832729533314705, "policy_loss": -0.001067276285574792, "dist_entropy": 0.39948952198028564, "actor_grad_norm": 0.12233364582061768, "critic_grad_norm": 0.05358624458312988, "ratio": 1.0002927780151367, "entropy": 0.39948952198028564, "incre_win_rate": 0.8837209302325582, "step": 2137}
{"time": 1767089062.726222, "phase": "train", "update": 2138, "total_env_steps": 6841600, "episode_reward": 0.25035908818244934, "value_loss": 0.00836138315498829, "policy_loss": -0.001747149304242157, "dist_entropy": 0.3869615435600281, "actor_grad_norm": 0.163793683052063, "critic_grad_norm": 0.08758573979139328, "ratio": 0.9996771216392517, "entropy": 0.3869615435600281, "incre_win_rate": 0.7441860465116279, "step": 2138}
{"time": 1767089067.6034667, "phase": "train", "update": 2139, "total_env_steps": 6844800, "episode_reward": 0.26088786125183105, "value_loss": 0.006527137663215399, "policy_loss": -0.001266633498373082, "dist_entropy": 0.39786527752876283, "actor_grad_norm": 0.16931062936782837, "critic_grad_norm": 0.07014182209968567, "ratio": 1.0000120401382446, "entropy": 0.39786527752876283, "incre_win_rate": 0.8809523809523809, "step": 2139}
{"time": 1767089072.5487413, "phase": "train", "update": 2140, "total_env_steps": 6848000, "episode_reward": 0.2519789934158325, "value_loss": 0.007811816781759262, "policy_loss": -0.0013371188707502312, "dist_entropy": 0.4034875214099884, "actor_grad_norm": 0.17482922971248627, "critic_grad_norm": 0.05077595263719559, "ratio": 0.9997145533561707, "entropy": 0.4034875214099884, "incre_win_rate": 0.7674418604651163, "step": 2140}
{"time": 1767089077.392115, "phase": "train", "update": 2141, "total_env_steps": 6851200, "episode_reward": 0.24390418827533722, "value_loss": 0.005891437176615, "policy_loss": -0.0012970036179158484, "dist_entropy": 0.41857784390449526, "actor_grad_norm": 0.14096586406230927, "critic_grad_norm": 0.043206896632909775, "ratio": 0.9998170137405396, "entropy": 0.41857784390449526, "incre_win_rate": 0.8717948717948718, "step": 2141}
{"time": 1767089088.9321427, "phase": "eval", "update": 2141, "total_env_steps": 6851200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.576003725165563, "step": 2141}
{"time": 1767089094.9012127, "phase": "train", "update": 2142, "total_env_steps": 6854400, "episode_reward": 0.24752122163772583, "value_loss": 0.007579691335558891, "policy_loss": -0.001637900278267068, "dist_entropy": 0.40523110032081605, "actor_grad_norm": 0.18850676715373993, "critic_grad_norm": 0.03902789577841759, "ratio": 1.000055193901062, "entropy": 0.40523110032081605, "incre_win_rate": 0.7906976744186046, "step": 2142}
{"time": 1767089100.0875244, "phase": "train", "update": 2143, "total_env_steps": 6857600, "episode_reward": 0.23675911128520966, "value_loss": 0.008187886513769626, "policy_loss": -0.001731181164041118, "dist_entropy": 0.404323947429657, "actor_grad_norm": 0.18596655130386353, "critic_grad_norm": 0.03588305041193962, "ratio": 0.9996742606163025, "entropy": 0.404323947429657, "incre_win_rate": 0.7317073170731707, "step": 2143}
{"time": 1767089104.9527164, "phase": "train", "update": 2144, "total_env_steps": 6860800, "episode_reward": 0.22265833616256714, "value_loss": 0.00938284806907177, "policy_loss": -0.0014404028996636952, "dist_entropy": 0.4073067009449005, "actor_grad_norm": 0.20973919332027435, "critic_grad_norm": 0.042095206677913666, "ratio": 1.0001319646835327, "entropy": 0.4073067009449005, "incre_win_rate": 0.5641025641025641, "step": 2144}
{"time": 1767089109.7909179, "phase": "train", "update": 2145, "total_env_steps": 6864000, "episode_reward": 0.24205918610095978, "value_loss": 0.007841011881828308, "policy_loss": -0.0012579251186778605, "dist_entropy": 0.41278685331344606, "actor_grad_norm": 0.16289089620113373, "critic_grad_norm": 0.043617989867925644, "ratio": 0.999781608581543, "entropy": 0.41278685331344606, "incre_win_rate": 0.7906976744186046, "step": 2145}
{"time": 1767089114.646164, "phase": "train", "update": 2146, "total_env_steps": 6867200, "episode_reward": 0.2392347753047943, "value_loss": 0.0063391227275133135, "policy_loss": -0.0012131188002911131, "dist_entropy": 0.40681350231170654, "actor_grad_norm": 0.12709708511829376, "critic_grad_norm": 0.03920070454478264, "ratio": 1.000122308731079, "entropy": 0.40681350231170654, "incre_win_rate": 0.8205128205128205, "step": 2146}
{"time": 1767089119.4818375, "phase": "train", "update": 2147, "total_env_steps": 6870400, "episode_reward": 0.2527318000793457, "value_loss": 0.00528522152453661, "policy_loss": -0.0014115258758302218, "dist_entropy": 0.41567357778549197, "actor_grad_norm": 0.13753937184810638, "critic_grad_norm": 0.04319905862212181, "ratio": 1.0001174211502075, "entropy": 0.41567357778549197, "incre_win_rate": 0.8780487804878049, "step": 2147}
{"time": 1767089124.4054794, "phase": "train", "update": 2148, "total_env_steps": 6873600, "episode_reward": 0.2527209222316742, "value_loss": 0.006605667993426323, "policy_loss": -0.0012949485534605287, "dist_entropy": 0.39780558943748473, "actor_grad_norm": 0.12934240698814392, "critic_grad_norm": 0.02854686789214611, "ratio": 1.000179409980774, "entropy": 0.39780558943748473, "incre_win_rate": 0.7380952380952381, "step": 2148}
{"time": 1767089129.2546525, "phase": "train", "update": 2149, "total_env_steps": 6876800, "episode_reward": 0.23761329054832458, "value_loss": 0.008957264199852943, "policy_loss": -0.0011792361963586019, "dist_entropy": 0.413888144493103, "actor_grad_norm": 0.13317154347896576, "critic_grad_norm": 0.02295832335948944, "ratio": 0.9997450113296509, "entropy": 0.413888144493103, "incre_win_rate": 0.7209302325581395, "step": 2149}
{"time": 1767089134.204281, "phase": "train", "update": 2150, "total_env_steps": 6880000, "episode_reward": 0.2517482340335846, "value_loss": 0.006833667494356632, "policy_loss": -0.0015122876835231835, "dist_entropy": 0.4188400089740753, "actor_grad_norm": 0.13120470941066742, "critic_grad_norm": 0.031030192971229553, "ratio": 0.9995909929275513, "entropy": 0.4188400089740753, "incre_win_rate": 0.8333333333333334, "step": 2150}
{"time": 1767089139.2350147, "phase": "train", "update": 2151, "total_env_steps": 6883200, "episode_reward": 0.22909457981586456, "value_loss": 0.011364149861037731, "policy_loss": -0.0012190112511561324, "dist_entropy": 0.4158598959445953, "actor_grad_norm": 0.1276216357946396, "critic_grad_norm": 0.10494661331176758, "ratio": 0.9999759793281555, "entropy": 0.4158598959445953, "incre_win_rate": 0.5384615384615384, "step": 2151}
{"time": 1767089144.199267, "phase": "train", "update": 2152, "total_env_steps": 6886400, "episode_reward": 0.23458091914653778, "value_loss": 0.008829543180763722, "policy_loss": -0.0014416680573155817, "dist_entropy": 0.422178053855896, "actor_grad_norm": 0.14995665848255157, "critic_grad_norm": 0.06783249229192734, "ratio": 0.9996349215507507, "entropy": 0.422178053855896, "incre_win_rate": 0.6341463414634146, "step": 2152}
{"time": 1767089149.037656, "phase": "train", "update": 2153, "total_env_steps": 6889600, "episode_reward": 0.24389953911304474, "value_loss": 0.006539811659604311, "policy_loss": -0.0013173248726786823, "dist_entropy": 0.408404678106308, "actor_grad_norm": 0.154163658618927, "critic_grad_norm": 0.07712108641862869, "ratio": 0.9998111724853516, "entropy": 0.408404678106308, "incre_win_rate": 0.8292682926829268, "step": 2153}
{"time": 1767089154.0206609, "phase": "train", "update": 2154, "total_env_steps": 6892800, "episode_reward": 0.25080713629722595, "value_loss": 0.006007529050111771, "policy_loss": -0.0013087928066756404, "dist_entropy": 0.41246298551559446, "actor_grad_norm": 0.1328979879617691, "critic_grad_norm": 0.048813577741384506, "ratio": 1.0000823736190796, "entropy": 0.41246298551559446, "incre_win_rate": 0.8095238095238095, "step": 2154}
{"time": 1767089158.939684, "phase": "train", "update": 2155, "total_env_steps": 6896000, "episode_reward": 0.22905990481376648, "value_loss": 0.008451414667069912, "policy_loss": -0.0015796771726801495, "dist_entropy": 0.415856671333313, "actor_grad_norm": 0.13971352577209473, "critic_grad_norm": 0.059218596667051315, "ratio": 0.9998824000358582, "entropy": 0.415856671333313, "incre_win_rate": 0.65, "step": 2155}
{"time": 1767089163.8030696, "phase": "train", "update": 2156, "total_env_steps": 6899200, "episode_reward": 0.24345354735851288, "value_loss": 0.006032487843185663, "policy_loss": -0.0016854441847982571, "dist_entropy": 0.4123240292072296, "actor_grad_norm": 0.1540241241455078, "critic_grad_norm": 0.04724026471376419, "ratio": 0.9998494386672974, "entropy": 0.4123240292072296, "incre_win_rate": 0.7560975609756098, "step": 2156}
{"time": 1767089168.653685, "phase": "train", "update": 2157, "total_env_steps": 6902400, "episode_reward": 0.23119670152664185, "value_loss": 0.00897902026772499, "policy_loss": -0.0013989306188797457, "dist_entropy": 0.42738608717918397, "actor_grad_norm": 0.14461323618888855, "critic_grad_norm": 0.030991965904831886, "ratio": 0.9998481869697571, "entropy": 0.42738608717918397, "incre_win_rate": 0.7073170731707317, "step": 2157}
{"time": 1767089173.5773785, "phase": "train", "update": 2158, "total_env_steps": 6905600, "episode_reward": 0.25672444701194763, "value_loss": 0.008550133556127548, "policy_loss": -0.0016334864342772092, "dist_entropy": 0.42000244855880736, "actor_grad_norm": 0.15437281131744385, "critic_grad_norm": 0.025894880294799805, "ratio": 0.9996887445449829, "entropy": 0.42000244855880736, "incre_win_rate": 0.8409090909090909, "step": 2158}
{"time": 1767089178.4352791, "phase": "train", "update": 2159, "total_env_steps": 6908800, "episode_reward": 0.23976613581180573, "value_loss": 0.007794048450887203, "policy_loss": -0.0017833328229187374, "dist_entropy": 0.4312108516693115, "actor_grad_norm": 0.13150426745414734, "critic_grad_norm": 0.03191457316279411, "ratio": 1.000221610069275, "entropy": 0.4312108516693115, "incre_win_rate": 0.7435897435897436, "step": 2159}
{"time": 1767089183.2908702, "phase": "train", "update": 2160, "total_env_steps": 6912000, "episode_reward": 0.23714609444141388, "value_loss": 0.00763425026088953, "policy_loss": -0.0015770295026300118, "dist_entropy": 0.4226225018501282, "actor_grad_norm": 0.22155705094337463, "critic_grad_norm": 0.03412770852446556, "ratio": 0.9999389052391052, "entropy": 0.4226225018501282, "incre_win_rate": 0.7209302325581395, "step": 2160}
{"time": 1767089188.1595545, "phase": "train", "update": 2161, "total_env_steps": 6915200, "episode_reward": 0.23668046295642853, "value_loss": 0.00970287062227726, "policy_loss": -0.001901925515996794, "dist_entropy": 0.44284013509750364, "actor_grad_norm": 0.171339750289917, "critic_grad_norm": 0.024331586435437202, "ratio": 1.0002617835998535, "entropy": 0.44284013509750364, "incre_win_rate": 0.7, "step": 2161}
{"time": 1767089199.7357082, "phase": "eval", "update": 2161, "total_env_steps": 6915200, "eval_win_rate": 0.875, "eval_episode_reward": 19.48799668874172, "step": 2161}
{"time": 1767089204.6024709, "phase": "train", "update": 2162, "total_env_steps": 6918400, "episode_reward": 0.23795118927955627, "value_loss": 0.006419415213167667, "policy_loss": -0.0017427977764583602, "dist_entropy": 0.41951924562454224, "actor_grad_norm": 0.1427096128463745, "critic_grad_norm": 0.018816744908690453, "ratio": 0.999983012676239, "entropy": 0.41951924562454224, "incre_win_rate": 0.6829268292682927, "step": 2162}
{"time": 1767089209.506353, "phase": "train", "update": 2163, "total_env_steps": 6921600, "episode_reward": 0.2366820126771927, "value_loss": 0.010116721317172051, "policy_loss": -0.0014327609234712213, "dist_entropy": 0.4097147524356842, "actor_grad_norm": 0.1367090791463852, "critic_grad_norm": 0.06894882768392563, "ratio": 1.0000087022781372, "entropy": 0.4097147524356842, "incre_win_rate": 0.6428571428571429, "step": 2163}
{"time": 1767089214.410075, "phase": "train", "update": 2164, "total_env_steps": 6924800, "episode_reward": 0.24763453006744385, "value_loss": 0.008255233429372311, "policy_loss": -0.001458538281996269, "dist_entropy": 0.40550472140312194, "actor_grad_norm": 0.12957631051540375, "critic_grad_norm": 0.0433245413005352, "ratio": 0.9995431303977966, "entropy": 0.40550472140312194, "incre_win_rate": 0.6744186046511628, "step": 2164}
{"time": 1767089219.30948, "phase": "train", "update": 2165, "total_env_steps": 6928000, "episode_reward": 0.25589457154273987, "value_loss": 0.004329724051058292, "policy_loss": -0.0016708701804297732, "dist_entropy": 0.4293354332447052, "actor_grad_norm": 0.13202564418315887, "critic_grad_norm": 0.05773215368390083, "ratio": 0.9996687173843384, "entropy": 0.4293354332447052, "incre_win_rate": 0.8809523809523809, "step": 2165}
{"time": 1767089224.1207745, "phase": "train", "update": 2166, "total_env_steps": 6931200, "episode_reward": 0.23680980503559113, "value_loss": 0.00855375938117504, "policy_loss": -0.0014725127515973213, "dist_entropy": 0.4201704740524292, "actor_grad_norm": 0.1714019775390625, "critic_grad_norm": 0.05864408612251282, "ratio": 1.0002106428146362, "entropy": 0.4201704740524292, "incre_win_rate": 0.6428571428571429, "step": 2166}
{"time": 1767089229.0068965, "phase": "train", "update": 2167, "total_env_steps": 6934400, "episode_reward": 0.2453378438949585, "value_loss": 0.010543094389140606, "policy_loss": -0.0020730210955917983, "dist_entropy": 0.4223743140697479, "actor_grad_norm": 0.19786296784877777, "critic_grad_norm": 0.05856921151280403, "ratio": 0.9994739890098572, "entropy": 0.4223743140697479, "incre_win_rate": 0.6428571428571429, "step": 2167}
{"time": 1767089233.8787177, "phase": "train", "update": 2168, "total_env_steps": 6937600, "episode_reward": 0.23670272529125214, "value_loss": 0.0094367153942585, "policy_loss": -0.0015006813808739138, "dist_entropy": 0.43210989236831665, "actor_grad_norm": 0.16297058761119843, "critic_grad_norm": 0.01874520443379879, "ratio": 0.9998985528945923, "entropy": 0.43210989236831665, "incre_win_rate": 0.6136363636363636, "step": 2168}
{"time": 1767089238.8557506, "phase": "train", "update": 2169, "total_env_steps": 6940800, "episode_reward": 0.2516866624355316, "value_loss": 0.008097586501389743, "policy_loss": -0.00152132187061369, "dist_entropy": 0.4189929664134979, "actor_grad_norm": 0.1512800008058548, "critic_grad_norm": 0.08992239832878113, "ratio": 1.000246286392212, "entropy": 0.4189929664134979, "incre_win_rate": 0.7857142857142857, "step": 2169}
{"time": 1767089243.713737, "phase": "train", "update": 2170, "total_env_steps": 6944000, "episode_reward": 0.22978529334068298, "value_loss": 0.008531293086707591, "policy_loss": -0.0013308523881448765, "dist_entropy": 0.4182437837123871, "actor_grad_norm": 0.1688809096813202, "critic_grad_norm": 0.06740613281726837, "ratio": 0.9998636245727539, "entropy": 0.4182437837123871, "incre_win_rate": 0.7, "step": 2170}
{"time": 1767089248.5574937, "phase": "train", "update": 2171, "total_env_steps": 6947200, "episode_reward": 0.2399420589208603, "value_loss": 0.006427598837763071, "policy_loss": -0.0016081646210835744, "dist_entropy": 0.42257357239723203, "actor_grad_norm": 0.11574943363666534, "critic_grad_norm": 0.06011280417442322, "ratio": 0.9998829960823059, "entropy": 0.42257357239723203, "incre_win_rate": 0.8205128205128205, "step": 2171}
{"time": 1767089253.4692657, "phase": "train", "update": 2172, "total_env_steps": 6950400, "episode_reward": 0.23338626325130463, "value_loss": 0.01116550136357546, "policy_loss": -0.0017744774521943896, "dist_entropy": 0.4154302000999451, "actor_grad_norm": 0.13431105017662048, "critic_grad_norm": 0.08745238184928894, "ratio": 0.999970555305481, "entropy": 0.4154302000999451, "incre_win_rate": 0.6363636363636364, "step": 2172}
{"time": 1767089258.3926258, "phase": "train", "update": 2173, "total_env_steps": 6953600, "episode_reward": 0.24308879673480988, "value_loss": 0.009298706613481044, "policy_loss": -0.0016126792477592744, "dist_entropy": 0.42538580298423767, "actor_grad_norm": 0.11984272301197052, "critic_grad_norm": 0.06752696633338928, "ratio": 1.0000227689743042, "entropy": 0.42538580298423767, "incre_win_rate": 0.6428571428571429, "step": 2173}
{"time": 1767089263.3137097, "phase": "train", "update": 2174, "total_env_steps": 6956800, "episode_reward": 0.2447480410337448, "value_loss": 0.007609784789383412, "policy_loss": -0.001935300653151728, "dist_entropy": 0.4080891370773315, "actor_grad_norm": 0.12201794236898422, "critic_grad_norm": 0.06426868587732315, "ratio": 0.9997870326042175, "entropy": 0.4080891370773315, "incre_win_rate": 0.7804878048780488, "step": 2174}
{"time": 1767089268.2391148, "phase": "train", "update": 2175, "total_env_steps": 6960000, "episode_reward": 0.2367767095565796, "value_loss": 0.008632261119782925, "policy_loss": -0.0018258973998640294, "dist_entropy": 0.40048004388809205, "actor_grad_norm": 0.17617875337600708, "critic_grad_norm": 0.03208049759268761, "ratio": 0.9997979998588562, "entropy": 0.40048004388809205, "incre_win_rate": 0.7073170731707317, "step": 2175}
{"time": 1767089273.1436331, "phase": "train", "update": 2176, "total_env_steps": 6963200, "episode_reward": 0.25497567653656006, "value_loss": 0.006065925490111113, "policy_loss": -0.0016455807921460063, "dist_entropy": 0.39558525681495665, "actor_grad_norm": 0.175261452794075, "critic_grad_norm": 0.026610717177391052, "ratio": 0.9994989633560181, "entropy": 0.39558525681495665, "incre_win_rate": 0.7954545454545454, "step": 2176}
{"time": 1767089278.0655527, "phase": "train", "update": 2177, "total_env_steps": 6966400, "episode_reward": 0.24979305267333984, "value_loss": 0.008999157510697842, "policy_loss": -0.0018539180612734186, "dist_entropy": 0.3992108225822449, "actor_grad_norm": 0.16572929918766022, "critic_grad_norm": 0.026595309376716614, "ratio": 0.9998993277549744, "entropy": 0.3992108225822449, "incre_win_rate": 0.7674418604651163, "step": 2177}
{"time": 1767089282.9133956, "phase": "train", "update": 2178, "total_env_steps": 6969600, "episode_reward": 0.24366721510887146, "value_loss": 0.008616704121232032, "policy_loss": -0.0015876742726554482, "dist_entropy": 0.4055434226989746, "actor_grad_norm": 0.15070141851902008, "critic_grad_norm": 0.02999512292444706, "ratio": 1.0000154972076416, "entropy": 0.4055434226989746, "incre_win_rate": 0.6904761904761905, "step": 2178}
{"time": 1767089287.8350105, "phase": "train", "update": 2179, "total_env_steps": 6972800, "episode_reward": 0.2352757602930069, "value_loss": 0.007597185857594013, "policy_loss": -0.0017776580127090824, "dist_entropy": 0.4123152792453766, "actor_grad_norm": 0.15071336925029755, "critic_grad_norm": 0.06633470952510834, "ratio": 0.9999122619628906, "entropy": 0.4123152792453766, "incre_win_rate": 0.725, "step": 2179}
{"time": 1767089292.763249, "phase": "train", "update": 2180, "total_env_steps": 6976000, "episode_reward": 0.25202038884162903, "value_loss": 0.009574815817177295, "policy_loss": -0.0017431357253464342, "dist_entropy": 0.3989760220050812, "actor_grad_norm": 0.12749570608139038, "critic_grad_norm": 0.05304102227091789, "ratio": 1.0003845691680908, "entropy": 0.3989760220050812, "incre_win_rate": 0.7441860465116279, "step": 2180}
{"time": 1767089297.656125, "phase": "train", "update": 2181, "total_env_steps": 6979200, "episode_reward": 0.2319852113723755, "value_loss": 0.008115186914801597, "policy_loss": -0.0016533422013822018, "dist_entropy": 0.4063837468624115, "actor_grad_norm": 0.1683703511953354, "critic_grad_norm": 0.04174819216132164, "ratio": 0.9999286532402039, "entropy": 0.4063837468624115, "incre_win_rate": 0.7, "step": 2181}
{"time": 1767089308.93092, "phase": "eval", "update": 2181, "total_env_steps": 6979200, "eval_win_rate": 1.0, "eval_episode_reward": 20.016556291390728, "step": 2181}
{"time": 1767089313.72948, "phase": "train", "update": 2182, "total_env_steps": 6982400, "episode_reward": 0.2229449450969696, "value_loss": 0.010609248653054237, "policy_loss": -0.0016809478692330515, "dist_entropy": 0.3944615602493286, "actor_grad_norm": 0.11829811334609985, "critic_grad_norm": 0.06690285354852676, "ratio": 1.0002543926239014, "entropy": 0.3944615602493286, "incre_win_rate": 0.5714285714285714, "step": 2182}
{"time": 1767089318.6366365, "phase": "train", "update": 2183, "total_env_steps": 6985600, "episode_reward": 0.25116100907325745, "value_loss": 0.007156648300588131, "policy_loss": -0.0015404792629217568, "dist_entropy": 0.39146019220352174, "actor_grad_norm": 0.15706467628479004, "critic_grad_norm": 0.07426454871892929, "ratio": 0.9996620416641235, "entropy": 0.39146019220352174, "incre_win_rate": 0.8048780487804879, "step": 2183}
{"time": 1767089323.5413237, "phase": "train", "update": 2184, "total_env_steps": 6988800, "episode_reward": 0.25338733196258545, "value_loss": 0.007018274627625942, "policy_loss": -0.0017724776369902884, "dist_entropy": 0.3909448981285095, "actor_grad_norm": 0.13103726506233215, "critic_grad_norm": 0.06641142815351486, "ratio": 1.0001388788223267, "entropy": 0.3909448981285095, "incre_win_rate": 0.813953488372093, "step": 2184}
{"time": 1767089328.4714105, "phase": "train", "update": 2185, "total_env_steps": 6992000, "episode_reward": 0.2356172502040863, "value_loss": 0.007439238112419843, "policy_loss": -0.0014764189655650738, "dist_entropy": 0.3868043541908264, "actor_grad_norm": 0.1569410115480423, "critic_grad_norm": 0.030408157035708427, "ratio": 1.0001424551010132, "entropy": 0.3868043541908264, "incre_win_rate": 0.7073170731707317, "step": 2185}
{"time": 1767089333.336726, "phase": "train", "update": 2186, "total_env_steps": 6995200, "episode_reward": 0.25088006258010864, "value_loss": 0.007356207445263862, "policy_loss": -0.001714823157709411, "dist_entropy": 0.39428316354751586, "actor_grad_norm": 0.1590263694524765, "critic_grad_norm": 0.0221229437738657, "ratio": 1.000137209892273, "entropy": 0.39428316354751586, "incre_win_rate": 0.7619047619047619, "step": 2186}
{"time": 1767089338.3018286, "phase": "train", "update": 2187, "total_env_steps": 6998400, "episode_reward": 0.25218647718429565, "value_loss": 0.009252911247313023, "policy_loss": -0.0015234719472626778, "dist_entropy": 0.40474855303764345, "actor_grad_norm": 0.14664559066295624, "critic_grad_norm": 0.036835964769124985, "ratio": 0.9998003244400024, "entropy": 0.40474855303764345, "incre_win_rate": 0.7777777777777778, "step": 2187}
{"time": 1767089343.2005339, "phase": "train", "update": 2188, "total_env_steps": 7001600, "episode_reward": 0.2516457736492157, "value_loss": 0.008611811138689519, "policy_loss": -0.001522681112447799, "dist_entropy": 0.4037619709968567, "actor_grad_norm": 0.11061709374189377, "critic_grad_norm": 0.04958898946642876, "ratio": 1.000009298324585, "entropy": 0.4037619709968567, "incre_win_rate": 0.7142857142857143, "step": 2188}
{"time": 1767089348.3103657, "phase": "train", "update": 2189, "total_env_steps": 7004800, "episode_reward": 0.2517751455307007, "value_loss": 0.00796224707737565, "policy_loss": -0.0016039242368222518, "dist_entropy": 0.40095539689064025, "actor_grad_norm": 0.12095648050308228, "critic_grad_norm": 0.04357578232884407, "ratio": 0.9999927878379822, "entropy": 0.40095539689064025, "incre_win_rate": 0.7209302325581395, "step": 2189}
{"time": 1767089353.1992064, "phase": "train", "update": 2190, "total_env_steps": 7008000, "episode_reward": 0.2573173940181732, "value_loss": 0.007962760888040066, "policy_loss": -0.0014688506473731877, "dist_entropy": 0.4054283142089844, "actor_grad_norm": 0.13689614832401276, "critic_grad_norm": 0.029302997514605522, "ratio": 1.0001333951950073, "entropy": 0.4054283142089844, "incre_win_rate": 0.7777777777777778, "step": 2190}
{"time": 1767089358.111277, "phase": "train", "update": 2191, "total_env_steps": 7011200, "episode_reward": 0.2404278814792633, "value_loss": 0.007214956171810627, "policy_loss": -0.0012733739893761253, "dist_entropy": 0.39673882722854614, "actor_grad_norm": 0.13419879972934723, "critic_grad_norm": 0.024572359398007393, "ratio": 0.999727725982666, "entropy": 0.39673882722854614, "incre_win_rate": 0.7317073170731707, "step": 2191}
{"time": 1767089362.944708, "phase": "train", "update": 2192, "total_env_steps": 7014400, "episode_reward": 0.25163647532463074, "value_loss": 0.0075549928471446036, "policy_loss": -0.0017265304733399488, "dist_entropy": 0.3990389287471771, "actor_grad_norm": 0.13147705793380737, "critic_grad_norm": 0.02565893344581127, "ratio": 1.000250220298767, "entropy": 0.3990389287471771, "incre_win_rate": 0.7560975609756098, "step": 2192}
{"time": 1767089368.088069, "phase": "train", "update": 2193, "total_env_steps": 7017600, "episode_reward": 0.2508598566055298, "value_loss": 0.007407102920114994, "policy_loss": -0.0014587303251246907, "dist_entropy": 0.4025170564651489, "actor_grad_norm": 0.1095787063241005, "critic_grad_norm": 0.02313798852264881, "ratio": 1.0000263452529907, "entropy": 0.4025170564651489, "incre_win_rate": 0.7777777777777778, "step": 2193}
{"time": 1767089372.9222543, "phase": "train", "update": 2194, "total_env_steps": 7020800, "episode_reward": 0.235256627202034, "value_loss": 0.007793678063899278, "policy_loss": -0.0013824267774282361, "dist_entropy": 0.4021878182888031, "actor_grad_norm": 0.14812250435352325, "critic_grad_norm": 0.025860557332634926, "ratio": 0.9997291564941406, "entropy": 0.4021878182888031, "incre_win_rate": 0.7631578947368421, "step": 2194}
{"time": 1767089377.833756, "phase": "train", "update": 2195, "total_env_steps": 7024000, "episode_reward": 0.25253361463546753, "value_loss": 0.007399471197277308, "policy_loss": -0.0013084157430212073, "dist_entropy": 0.3913967192173004, "actor_grad_norm": 0.12402590364217758, "critic_grad_norm": 0.024591118097305298, "ratio": 1.0001635551452637, "entropy": 0.3913967192173004, "incre_win_rate": 0.7727272727272727, "step": 2195}
{"time": 1767089382.631326, "phase": "train", "update": 2196, "total_env_steps": 7027200, "episode_reward": 0.24615894258022308, "value_loss": 0.006371637154370546, "policy_loss": -0.001675159761981604, "dist_entropy": 0.40464903712272643, "actor_grad_norm": 0.13371630012989044, "critic_grad_norm": 0.019976353272795677, "ratio": 1.0000685453414917, "entropy": 0.40464903712272643, "incre_win_rate": 0.7560975609756098, "step": 2196}
{"time": 1767089387.520833, "phase": "train", "update": 2197, "total_env_steps": 7030400, "episode_reward": 0.24485152959823608, "value_loss": 0.007480109483003617, "policy_loss": -0.0019318092475081982, "dist_entropy": 0.4006446301937103, "actor_grad_norm": 0.16284362971782684, "critic_grad_norm": 0.023557446897029877, "ratio": 0.999832808971405, "entropy": 0.4006446301937103, "incre_win_rate": 0.75, "step": 2197}
{"time": 1767089392.4336717, "phase": "train", "update": 2198, "total_env_steps": 7033600, "episode_reward": 0.2557388246059418, "value_loss": 0.006747716665267944, "policy_loss": -0.0017973379514335975, "dist_entropy": 0.3992616057395935, "actor_grad_norm": 0.15398617088794708, "critic_grad_norm": 0.018325073644518852, "ratio": 1.0002403259277344, "entropy": 0.3992616057395935, "incre_win_rate": 0.7804878048780488, "step": 2198}
{"time": 1767089397.3776205, "phase": "train", "update": 2199, "total_env_steps": 7036800, "episode_reward": 0.2441214919090271, "value_loss": 0.007524112425744534, "policy_loss": -0.00142117674293587, "dist_entropy": 0.3956983327865601, "actor_grad_norm": 0.12713591754436493, "critic_grad_norm": 0.016553983092308044, "ratio": 1.0000982284545898, "entropy": 0.3956983327865601, "incre_win_rate": 0.813953488372093, "step": 2199}
{"time": 1767089402.2752964, "phase": "train", "update": 2200, "total_env_steps": 7040000, "episode_reward": 0.23223094642162323, "value_loss": 0.007795165106654167, "policy_loss": -0.001825662800048633, "dist_entropy": 0.4110631883144379, "actor_grad_norm": 0.13202986121177673, "critic_grad_norm": 0.04488023743033409, "ratio": 1.0001084804534912, "entropy": 0.4110631883144379, "incre_win_rate": 0.6578947368421053, "step": 2200}
{"time": 1767089407.3219223, "phase": "train", "update": 2201, "total_env_steps": 7043200, "episode_reward": 0.24498863518238068, "value_loss": 0.009184315055608749, "policy_loss": -0.0016968441767687636, "dist_entropy": 0.3892956256866455, "actor_grad_norm": 0.15437661111354828, "critic_grad_norm": 0.03889122232794762, "ratio": 1.000264286994934, "entropy": 0.3892956256866455, "incre_win_rate": 0.7045454545454546, "step": 2201}
{"time": 1767089419.0225828, "phase": "eval", "update": 2201, "total_env_steps": 7043200, "eval_win_rate": 0.84375, "eval_episode_reward": 19.007191639072843, "step": 2201}
{"time": 1767089423.9106529, "phase": "train", "update": 2202, "total_env_steps": 7046400, "episode_reward": 0.2504175305366516, "value_loss": 0.008443700335919856, "policy_loss": -0.0014518449667008325, "dist_entropy": 0.4067931294441223, "actor_grad_norm": 0.19680474698543549, "critic_grad_norm": 0.06366779655218124, "ratio": 0.9999818205833435, "entropy": 0.4067931294441223, "incre_win_rate": 0.7727272727272727, "step": 2202}
{"time": 1767089428.844679, "phase": "train", "update": 2203, "total_env_steps": 7049600, "episode_reward": 0.23312139511108398, "value_loss": 0.007886539958417416, "policy_loss": -0.0011872401501385355, "dist_entropy": 0.38448764085769654, "actor_grad_norm": 0.15109552443027496, "critic_grad_norm": 0.04422194883227348, "ratio": 0.9999644160270691, "entropy": 0.38448764085769654, "incre_win_rate": 0.6842105263157895, "step": 2203}
{"time": 1767089433.7092419, "phase": "train", "update": 2204, "total_env_steps": 7052800, "episode_reward": 0.2497904747724533, "value_loss": 0.007870400045067071, "policy_loss": -0.0014006490575951603, "dist_entropy": 0.40151225328445433, "actor_grad_norm": 0.20217981934547424, "critic_grad_norm": 0.03662913292646408, "ratio": 0.9996561408042908, "entropy": 0.40151225328445433, "incre_win_rate": 0.7209302325581395, "step": 2204}
{"time": 1767089438.6614678, "phase": "train", "update": 2205, "total_env_steps": 7056000, "episode_reward": 0.26002949476242065, "value_loss": 0.006632725242525339, "policy_loss": -0.000844853891831221, "dist_entropy": 0.3899872124195099, "actor_grad_norm": 0.1992918998003006, "critic_grad_norm": 0.041003044694662094, "ratio": 0.9998547434806824, "entropy": 0.3899872124195099, "incre_win_rate": 0.8444444444444444, "step": 2205}
{"time": 1767089443.5449078, "phase": "train", "update": 2206, "total_env_steps": 7059200, "episode_reward": 0.2513110637664795, "value_loss": 0.007990773301571608, "policy_loss": -0.0011582326024438317, "dist_entropy": 0.3895614266395569, "actor_grad_norm": 0.1994524747133255, "critic_grad_norm": 0.043760668486356735, "ratio": 0.999721348285675, "entropy": 0.3895614266395569, "incre_win_rate": 0.7804878048780488, "step": 2206}
{"time": 1767089448.4914606, "phase": "train", "update": 2207, "total_env_steps": 7062400, "episode_reward": 0.2449798434972763, "value_loss": 0.00829269364476204, "policy_loss": -0.0015078982201089275, "dist_entropy": 0.3990680694580078, "actor_grad_norm": 0.16721662878990173, "critic_grad_norm": 0.06441511958837509, "ratio": 0.9996965527534485, "entropy": 0.3990680694580078, "incre_win_rate": 0.7333333333333333, "step": 2207}
{"time": 1767089453.3342676, "phase": "train", "update": 2208, "total_env_steps": 7065600, "episode_reward": 0.2632905840873718, "value_loss": 0.006587617471814156, "policy_loss": -0.0013762698276195806, "dist_entropy": 0.387667191028595, "actor_grad_norm": 0.18189974129199982, "critic_grad_norm": 0.061433881521224976, "ratio": 0.9997941255569458, "entropy": 0.387667191028595, "incre_win_rate": 0.8372093023255814, "step": 2208}
{"time": 1767089458.2532022, "phase": "train", "update": 2209, "total_env_steps": 7068800, "episode_reward": 0.24747775495052338, "value_loss": 0.006364932563155889, "policy_loss": -0.0010160026566808256, "dist_entropy": 0.39630343914031985, "actor_grad_norm": 0.14085911214351654, "critic_grad_norm": 0.045077499002218246, "ratio": 0.999980092048645, "entropy": 0.39630343914031985, "incre_win_rate": 0.8048780487804879, "step": 2209}
{"time": 1767089463.2199047, "phase": "train", "update": 2210, "total_env_steps": 7072000, "episode_reward": 0.25440913438796997, "value_loss": 0.007776429783552885, "policy_loss": -0.001198604312504159, "dist_entropy": 0.3975785613059998, "actor_grad_norm": 0.20729613304138184, "critic_grad_norm": 0.025629162788391113, "ratio": 1.0000232458114624, "entropy": 0.3975785613059998, "incre_win_rate": 0.7674418604651163, "step": 2210}
{"time": 1767089468.080927, "phase": "train", "update": 2211, "total_env_steps": 7075200, "episode_reward": 0.2131524235010147, "value_loss": 0.010665245726704598, "policy_loss": -0.0014611587424354865, "dist_entropy": 0.42503013014793395, "actor_grad_norm": 0.25832873582839966, "critic_grad_norm": 0.06695101410150528, "ratio": 0.9996859431266785, "entropy": 0.42503013014793395, "incre_win_rate": 0.5384615384615384, "step": 2211}
{"time": 1767089473.4812791, "phase": "train", "update": 2212, "total_env_steps": 7078400, "episode_reward": 0.2504361569881439, "value_loss": 0.007298044860363007, "policy_loss": -0.0012912417125178876, "dist_entropy": 0.4122437059879303, "actor_grad_norm": 0.20954374969005585, "critic_grad_norm": 0.05046718940138817, "ratio": 0.9997388124465942, "entropy": 0.4122437059879303, "incre_win_rate": 0.7857142857142857, "step": 2212}
{"time": 1767089478.9902542, "phase": "train", "update": 2213, "total_env_steps": 7081600, "episode_reward": 0.2406110316514969, "value_loss": 0.007252202555537224, "policy_loss": -0.0013399293670179446, "dist_entropy": 0.425676167011261, "actor_grad_norm": 0.18271367251873016, "critic_grad_norm": 0.055005479604005814, "ratio": 0.9999300241470337, "entropy": 0.425676167011261, "incre_win_rate": 0.6666666666666666, "step": 2213}
{"time": 1767089484.526869, "phase": "train", "update": 2214, "total_env_steps": 7084800, "episode_reward": 0.23274265229701996, "value_loss": 0.008805713430047036, "policy_loss": -0.0014815898603558254, "dist_entropy": 0.4190900444984436, "actor_grad_norm": 0.17208018898963928, "critic_grad_norm": 0.04963187128305435, "ratio": 0.9997979998588562, "entropy": 0.4190900444984436, "incre_win_rate": 0.6341463414634146, "step": 2214}
{"time": 1767089489.5246444, "phase": "train", "update": 2215, "total_env_steps": 7088000, "episode_reward": 0.25393781065940857, "value_loss": 0.006993321795016527, "policy_loss": -0.0015344587698827184, "dist_entropy": 0.42326202392578127, "actor_grad_norm": 0.14211095869541168, "critic_grad_norm": 0.04970254376530647, "ratio": 0.999675452709198, "entropy": 0.42326202392578127, "incre_win_rate": 0.8372093023255814, "step": 2215}
{"time": 1767089494.3814447, "phase": "train", "update": 2216, "total_env_steps": 7091200, "episode_reward": 0.23937758803367615, "value_loss": 0.007708803005516529, "policy_loss": -0.001630765956110025, "dist_entropy": 0.4288502812385559, "actor_grad_norm": 0.15133607387542725, "critic_grad_norm": 0.03717885538935661, "ratio": 0.9997504353523254, "entropy": 0.4288502812385559, "incre_win_rate": 0.7560975609756098, "step": 2216}
{"time": 1767089499.3899543, "phase": "train", "update": 2217, "total_env_steps": 7094400, "episode_reward": 0.25908058881759644, "value_loss": 0.009877068176865577, "policy_loss": -0.0016400202891858839, "dist_entropy": 0.4118399560451508, "actor_grad_norm": 0.12316783517599106, "critic_grad_norm": 0.03528059646487236, "ratio": 1.0001369714736938, "entropy": 0.4118399560451508, "incre_win_rate": 0.7727272727272727, "step": 2217}
{"time": 1767089504.361249, "phase": "train", "update": 2218, "total_env_steps": 7097600, "episode_reward": 0.250410795211792, "value_loss": 0.006847367528825999, "policy_loss": -0.0014113948954367571, "dist_entropy": 0.41804130673408507, "actor_grad_norm": 0.13753420114517212, "critic_grad_norm": 0.056495796889066696, "ratio": 0.9998311996459961, "entropy": 0.41804130673408507, "incre_win_rate": 0.7954545454545454, "step": 2218}
{"time": 1767089509.3466105, "phase": "train", "update": 2219, "total_env_steps": 7100800, "episode_reward": 0.2551935315132141, "value_loss": 0.0072505797259509565, "policy_loss": -0.0017060786124654449, "dist_entropy": 0.40503581762313845, "actor_grad_norm": 0.13423264026641846, "critic_grad_norm": 0.047606825828552246, "ratio": 0.9997671246528625, "entropy": 0.40503581762313845, "incre_win_rate": 0.8095238095238095, "step": 2219}
{"time": 1767089514.2698312, "phase": "train", "update": 2220, "total_env_steps": 7104000, "episode_reward": 0.24324245750904083, "value_loss": 0.007522344961762429, "policy_loss": -0.0013840021024549287, "dist_entropy": 0.4159706950187683, "actor_grad_norm": 0.1575784981250763, "critic_grad_norm": 0.022107455879449844, "ratio": 0.9998978972434998, "entropy": 0.4159706950187683, "incre_win_rate": 0.7073170731707317, "step": 2220}
{"time": 1767089519.2324886, "phase": "train", "update": 2221, "total_env_steps": 7107200, "episode_reward": 0.24272817373275757, "value_loss": 0.010686764866113663, "policy_loss": -0.001367066655861393, "dist_entropy": 0.40811690092086794, "actor_grad_norm": 0.1051906943321228, "critic_grad_norm": 0.08543900400400162, "ratio": 0.9999048113822937, "entropy": 0.40811690092086794, "incre_win_rate": 0.6976744186046512, "step": 2221}
{"time": 1767089530.6798832, "phase": "eval", "update": 2221, "total_env_steps": 7107200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.107615894039732, "step": 2221}
{"time": 1767089535.5510378, "phase": "train", "update": 2222, "total_env_steps": 7110400, "episode_reward": 0.24468544125556946, "value_loss": 0.009987000562250613, "policy_loss": -0.0015354567119914009, "dist_entropy": 0.4193066477775574, "actor_grad_norm": 0.126027449965477, "critic_grad_norm": 0.0590936616063118, "ratio": 1.0000008344650269, "entropy": 0.4193066477775574, "incre_win_rate": 0.725, "step": 2222}
{"time": 1767089540.4537957, "phase": "train", "update": 2223, "total_env_steps": 7113600, "episode_reward": 0.22612634301185608, "value_loss": 0.008004049398005008, "policy_loss": -0.0013289771697749587, "dist_entropy": 0.41635230779647825, "actor_grad_norm": 0.1208282932639122, "critic_grad_norm": 0.07518664747476578, "ratio": 1.0000253915786743, "entropy": 0.41635230779647825, "incre_win_rate": 0.6666666666666666, "step": 2223}
{"time": 1767089545.4329834, "phase": "train", "update": 2224, "total_env_steps": 7116800, "episode_reward": 0.2445477992296219, "value_loss": 0.00835573859512806, "policy_loss": -0.0012077459090198417, "dist_entropy": 0.4150649905204773, "actor_grad_norm": 0.09302648901939392, "critic_grad_norm": 0.037509188055992126, "ratio": 0.999982476234436, "entropy": 0.4150649905204773, "incre_win_rate": 0.7380952380952381, "step": 2224}
{"time": 1767089550.3463619, "phase": "train", "update": 2225, "total_env_steps": 7120000, "episode_reward": 0.23715852200984955, "value_loss": 0.00811690678820014, "policy_loss": -0.0012815549638162337, "dist_entropy": 0.40472651124000547, "actor_grad_norm": 0.12014026939868927, "critic_grad_norm": 0.03221872076392174, "ratio": 0.9999296069145203, "entropy": 0.40472651124000547, "incre_win_rate": 0.6923076923076923, "step": 2225}
{"time": 1767089555.2036798, "phase": "train", "update": 2226, "total_env_steps": 7123200, "episode_reward": 0.24823933839797974, "value_loss": 0.005823264550417662, "policy_loss": -0.0012095300380423168, "dist_entropy": 0.4032495617866516, "actor_grad_norm": 0.11073316633701324, "critic_grad_norm": 0.03430565819144249, "ratio": 1.0002336502075195, "entropy": 0.4032495617866516, "incre_win_rate": 0.7272727272727273, "step": 2226}
{"time": 1767089560.2328928, "phase": "train", "update": 2227, "total_env_steps": 7126400, "episode_reward": 0.26220664381980896, "value_loss": 0.006240309681743383, "policy_loss": -0.0015884075237309503, "dist_entropy": 0.4137476205825806, "actor_grad_norm": 0.11784040927886963, "critic_grad_norm": 0.016564901918172836, "ratio": 0.9998122453689575, "entropy": 0.4137476205825806, "incre_win_rate": 0.8333333333333334, "step": 2227}
{"time": 1767089566.113103, "phase": "train", "update": 2228, "total_env_steps": 7129600, "episode_reward": 0.2455955147743225, "value_loss": 0.006589640025049448, "policy_loss": -0.001364046965827015, "dist_entropy": 0.42807826995849607, "actor_grad_norm": 0.1123792752623558, "critic_grad_norm": 0.03304313123226166, "ratio": 1.0000511407852173, "entropy": 0.42807826995849607, "incre_win_rate": 0.7674418604651163, "step": 2228}
{"time": 1767089571.3394392, "phase": "train", "update": 2229, "total_env_steps": 7132800, "episode_reward": 0.25433051586151123, "value_loss": 0.0059840518049895765, "policy_loss": -0.0015337360227396068, "dist_entropy": 0.41912705898284913, "actor_grad_norm": 0.11739790439605713, "critic_grad_norm": 0.028365585952997208, "ratio": 0.9999492764472961, "entropy": 0.41912705898284913, "incre_win_rate": 0.8333333333333334, "step": 2229}
{"time": 1767089576.458622, "phase": "train", "update": 2230, "total_env_steps": 7136000, "episode_reward": 0.25208401679992676, "value_loss": 0.006301579251885414, "policy_loss": -0.0015454623044540484, "dist_entropy": 0.42484175562858584, "actor_grad_norm": 0.19526247680187225, "critic_grad_norm": 0.03839433938264847, "ratio": 0.9997048377990723, "entropy": 0.42484175562858584, "incre_win_rate": 0.8636363636363636, "step": 2230}
{"time": 1767089581.648231, "phase": "train", "update": 2231, "total_env_steps": 7139200, "episode_reward": 0.2555779218673706, "value_loss": 0.006427478324621916, "policy_loss": -0.0012966560514939829, "dist_entropy": 0.4118052899837494, "actor_grad_norm": 0.14750215411186218, "critic_grad_norm": 0.018223779276013374, "ratio": 1.000165581703186, "entropy": 0.4118052899837494, "incre_win_rate": 0.85, "step": 2231}
{"time": 1767089586.8850148, "phase": "train", "update": 2232, "total_env_steps": 7142400, "episode_reward": 0.24826985597610474, "value_loss": 0.006714222859591246, "policy_loss": -0.0011302880145748872, "dist_entropy": 0.43171268701553345, "actor_grad_norm": 0.1221141591668129, "critic_grad_norm": 0.016320141032338142, "ratio": 1.000040888786316, "entropy": 0.43171268701553345, "incre_win_rate": 0.7272727272727273, "step": 2232}
{"time": 1767089592.0051475, "phase": "train", "update": 2233, "total_env_steps": 7145600, "episode_reward": 0.2574627697467804, "value_loss": 0.0068874791264534, "policy_loss": -0.0015734251641802643, "dist_entropy": 0.41822363138198854, "actor_grad_norm": 0.14998343586921692, "critic_grad_norm": 0.022477401420474052, "ratio": 1.0000336170196533, "entropy": 0.41822363138198854, "incre_win_rate": 0.8292682926829268, "step": 2233}
{"time": 1767089597.1931393, "phase": "train", "update": 2234, "total_env_steps": 7148800, "episode_reward": 0.24173273146152496, "value_loss": 0.0052310463041067125, "policy_loss": -0.0014660525747061115, "dist_entropy": 0.4228464186191559, "actor_grad_norm": 0.11311646550893784, "critic_grad_norm": 0.026994986459612846, "ratio": 0.999970555305481, "entropy": 0.4228464186191559, "incre_win_rate": 0.7674418604651163, "step": 2234}
{"time": 1767089602.5635083, "phase": "train", "update": 2235, "total_env_steps": 7152000, "episode_reward": 0.24904078245162964, "value_loss": 0.008319261483848095, "policy_loss": -0.0016497764503583313, "dist_entropy": 0.43022586703300475, "actor_grad_norm": 0.10662801563739777, "critic_grad_norm": 0.040599845349788666, "ratio": 0.999833881855011, "entropy": 0.43022586703300475, "incre_win_rate": 0.7441860465116279, "step": 2235}
{"time": 1767089608.0425234, "phase": "train", "update": 2236, "total_env_steps": 7155200, "episode_reward": 0.26102131605148315, "value_loss": 0.0069737863726913926, "policy_loss": -0.0011339601740404603, "dist_entropy": 0.4126652359962463, "actor_grad_norm": 0.10315147787332535, "critic_grad_norm": 0.033980585634708405, "ratio": 1.0002938508987427, "entropy": 0.4126652359962463, "incre_win_rate": 0.8333333333333334, "step": 2236}
{"time": 1767089613.0071995, "phase": "train", "update": 2237, "total_env_steps": 7158400, "episode_reward": 0.23850217461585999, "value_loss": 0.006724931113421917, "policy_loss": -0.0012749791581882163, "dist_entropy": 0.41596213579177854, "actor_grad_norm": 0.13543494045734406, "critic_grad_norm": 0.015208862721920013, "ratio": 1.0002902746200562, "entropy": 0.41596213579177854, "incre_win_rate": 0.6976744186046512, "step": 2237}
{"time": 1767089618.1519637, "phase": "train", "update": 2238, "total_env_steps": 7161600, "episode_reward": 0.2541644275188446, "value_loss": 0.006724337209016084, "policy_loss": -0.0018712057373722502, "dist_entropy": 0.4226264715194702, "actor_grad_norm": 0.14025406539440155, "critic_grad_norm": 0.02437690459191799, "ratio": 1.000109314918518, "entropy": 0.4226264715194702, "incre_win_rate": 0.775, "step": 2238}
{"time": 1767089623.2865365, "phase": "train", "update": 2239, "total_env_steps": 7164800, "episode_reward": 0.24969269335269928, "value_loss": 0.008132290467619896, "policy_loss": -0.0013680595405531903, "dist_entropy": 0.4018908143043518, "actor_grad_norm": 0.10769269615411758, "critic_grad_norm": 0.03795800730586052, "ratio": 1.000018835067749, "entropy": 0.4018908143043518, "incre_win_rate": 0.7111111111111111, "step": 2239}
{"time": 1767089628.4614878, "phase": "train", "update": 2240, "total_env_steps": 7168000, "episode_reward": 0.2527778446674347, "value_loss": 0.0113646836951375, "policy_loss": -0.0013408134853278852, "dist_entropy": 0.4021413266658783, "actor_grad_norm": 0.13229994475841522, "critic_grad_norm": 0.03251577168703079, "ratio": 1.0000213384628296, "entropy": 0.4021413266658783, "incre_win_rate": 0.6976744186046512, "step": 2240}
{"time": 1767089633.4336908, "phase": "train", "update": 2241, "total_env_steps": 7171200, "episode_reward": 0.2387712299823761, "value_loss": 0.008825827203691006, "policy_loss": -0.0015907119526801239, "dist_entropy": 0.40487155318260193, "actor_grad_norm": 0.13094459474086761, "critic_grad_norm": 0.08152001351118088, "ratio": 0.9998036623001099, "entropy": 0.40487155318260193, "incre_win_rate": 0.7142857142857143, "step": 2241}
{"time": 1767089644.2741778, "phase": "eval", "update": 2241, "total_env_steps": 7171200, "eval_win_rate": 0.84375, "eval_episode_reward": 19.340024834437088, "step": 2241}
{"time": 1767089649.049936, "phase": "train", "update": 2242, "total_env_steps": 7174400, "episode_reward": 0.24891763925552368, "value_loss": 0.006422183942049742, "policy_loss": -0.0012012936713283295, "dist_entropy": 0.4196425497531891, "actor_grad_norm": 0.16448010504245758, "critic_grad_norm": 0.084113709628582, "ratio": 0.9999510049819946, "entropy": 0.4196425497531891, "incre_win_rate": 0.7380952380952381, "step": 2242}
{"time": 1767089654.2412996, "phase": "train", "update": 2243, "total_env_steps": 7177600, "episode_reward": 0.23173272609710693, "value_loss": 0.009837313368916512, "policy_loss": -0.0017211305394638997, "dist_entropy": 0.4081497609615326, "actor_grad_norm": 0.13125787675380707, "critic_grad_norm": 0.06444864720106125, "ratio": 0.999793529510498, "entropy": 0.4081497609615326, "incre_win_rate": 0.725, "step": 2243}
{"time": 1767089658.9684086, "phase": "train", "update": 2244, "total_env_steps": 7180800, "episode_reward": 0.25347474217414856, "value_loss": 0.007750480249524116, "policy_loss": -0.0013982255056873782, "dist_entropy": 0.4121231734752655, "actor_grad_norm": 0.1095656305551529, "critic_grad_norm": 0.05284581333398819, "ratio": 0.9998311400413513, "entropy": 0.4121231734752655, "incre_win_rate": 0.7674418604651163, "step": 2244}
{"time": 1767089663.7151544, "phase": "train", "update": 2245, "total_env_steps": 7184000, "episode_reward": 0.2493155151605606, "value_loss": 0.005916715040802956, "policy_loss": -0.0012111288068904712, "dist_entropy": 0.40043650269508363, "actor_grad_norm": 0.0953843742609024, "critic_grad_norm": 0.08115474134683609, "ratio": 1.000035285949707, "entropy": 0.40043650269508363, "incre_win_rate": 0.7619047619047619, "step": 2245}
{"time": 1767089668.4214654, "phase": "train", "update": 2246, "total_env_steps": 7187200, "episode_reward": 0.2435358166694641, "value_loss": 0.006711441278457642, "policy_loss": -0.0013005589029219777, "dist_entropy": 0.3989357888698578, "actor_grad_norm": 0.11917721480131149, "critic_grad_norm": 0.04818061366677284, "ratio": 1.0002596378326416, "entropy": 0.3989357888698578, "incre_win_rate": 0.7560975609756098, "step": 2246}
{"time": 1767089672.9936297, "phase": "train", "update": 2247, "total_env_steps": 7190400, "episode_reward": 0.2571543753147125, "value_loss": 0.006888579484075308, "policy_loss": -0.0016057412125356052, "dist_entropy": 0.40871169567108157, "actor_grad_norm": 0.12849976122379303, "critic_grad_norm": 0.053755249828100204, "ratio": 0.9998003840446472, "entropy": 0.40871169567108157, "incre_win_rate": 0.7954545454545454, "step": 2247}
{"time": 1767089677.8572316, "phase": "train", "update": 2248, "total_env_steps": 7193600, "episode_reward": 0.24924825131893158, "value_loss": 0.007974589616060257, "policy_loss": -0.0012548240836210312, "dist_entropy": 0.4100246250629425, "actor_grad_norm": 0.13182124495506287, "critic_grad_norm": 0.06376446038484573, "ratio": 1.0000278949737549, "entropy": 0.4100246250629425, "incre_win_rate": 0.7380952380952381, "step": 2248}
{"time": 1767089682.5703032, "phase": "train", "update": 2249, "total_env_steps": 7196800, "episode_reward": 0.2394976168870926, "value_loss": 0.009358657896518708, "policy_loss": -0.001475308598493541, "dist_entropy": 0.4040153205394745, "actor_grad_norm": 0.1318388432264328, "critic_grad_norm": 0.053760021924972534, "ratio": 0.9999961853027344, "entropy": 0.4040153205394745, "incre_win_rate": 0.6976744186046512, "step": 2249}
{"time": 1767089687.2700737, "phase": "train", "update": 2250, "total_env_steps": 7200000, "episode_reward": 0.2503714859485626, "value_loss": 0.007635392993688583, "policy_loss": -0.0013099293075505614, "dist_entropy": 0.4198384821414948, "actor_grad_norm": 0.09638706594705582, "critic_grad_norm": 0.030612004920840263, "ratio": 1.0001237392425537, "entropy": 0.4198384821414948, "incre_win_rate": 0.775, "step": 2250}
{"time": 1767089692.3375447, "phase": "train", "update": 2251, "total_env_steps": 7203200, "episode_reward": 0.2498856782913208, "value_loss": 0.005524390935897827, "policy_loss": -0.0016561199901047984, "dist_entropy": 0.41742693185806273, "actor_grad_norm": 0.11591004580259323, "critic_grad_norm": 0.06186017394065857, "ratio": 0.9998236894607544, "entropy": 0.41742693185806273, "incre_win_rate": 0.8292682926829268, "step": 2251}
{"time": 1767089697.7687066, "phase": "train", "update": 2252, "total_env_steps": 7206400, "episode_reward": 0.254862904548645, "value_loss": 0.005899588763713837, "policy_loss": -0.0014669112880763891, "dist_entropy": 0.40316835045814514, "actor_grad_norm": 0.11850818246603012, "critic_grad_norm": 0.0407165102660656, "ratio": 0.9999439120292664, "entropy": 0.40316835045814514, "incre_win_rate": 0.7391304347826086, "step": 2252}
{"time": 1767089703.0173662, "phase": "train", "update": 2253, "total_env_steps": 7209600, "episode_reward": 0.2671435475349426, "value_loss": 0.006734647136181593, "policy_loss": -0.0015026040322652535, "dist_entropy": 0.4133345246315002, "actor_grad_norm": 0.14171066880226135, "critic_grad_norm": 0.032605934888124466, "ratio": 0.9994369745254517, "entropy": 0.4133345246315002, "incre_win_rate": 0.8571428571428571, "step": 2253}
{"time": 1767089708.1559913, "phase": "train", "update": 2254, "total_env_steps": 7212800, "episode_reward": 0.24505329132080078, "value_loss": 0.008292939141392707, "policy_loss": -0.0014293590414183655, "dist_entropy": 0.42521644234657285, "actor_grad_norm": 0.13578206300735474, "critic_grad_norm": 0.0183159988373518, "ratio": 0.9997265934944153, "entropy": 0.42521644234657285, "incre_win_rate": 0.7142857142857143, "step": 2254}
{"time": 1767089713.454035, "phase": "train", "update": 2255, "total_env_steps": 7216000, "episode_reward": 0.2543506920337677, "value_loss": 0.0073325465433299545, "policy_loss": -0.0014251283892800614, "dist_entropy": 0.4091225266456604, "actor_grad_norm": 0.12294378131628036, "critic_grad_norm": 0.023689977824687958, "ratio": 0.9998393058776855, "entropy": 0.4091225266456604, "incre_win_rate": 0.7727272727272727, "step": 2255}
{"time": 1767089718.4975233, "phase": "train", "update": 2256, "total_env_steps": 7219200, "episode_reward": 0.25495755672454834, "value_loss": 0.00637340983375907, "policy_loss": -0.0014738955339552717, "dist_entropy": 0.42138475775718687, "actor_grad_norm": 0.1657208800315857, "critic_grad_norm": 0.018151629716157913, "ratio": 0.9998809099197388, "entropy": 0.42138475775718687, "incre_win_rate": 0.7727272727272727, "step": 2256}
{"time": 1767089723.5881157, "phase": "train", "update": 2257, "total_env_steps": 7222400, "episode_reward": 0.26364344358444214, "value_loss": 0.00575187262147665, "policy_loss": -0.0014803035036508483, "dist_entropy": 0.39556837677955625, "actor_grad_norm": 0.10788825899362564, "critic_grad_norm": 0.05034146457910538, "ratio": 0.9998391270637512, "entropy": 0.39556837677955625, "incre_win_rate": 0.8863636363636364, "step": 2257}
{"time": 1767089728.6149168, "phase": "train", "update": 2258, "total_env_steps": 7225600, "episode_reward": 0.2569505274295807, "value_loss": 0.007870301604270935, "policy_loss": -0.0010919329344559968, "dist_entropy": 0.4067362308502197, "actor_grad_norm": 0.10182994604110718, "critic_grad_norm": 0.038110729306936264, "ratio": 1.0001178979873657, "entropy": 0.4067362308502197, "incre_win_rate": 0.8292682926829268, "step": 2258}
{"time": 1767089733.7932014, "phase": "train", "update": 2259, "total_env_steps": 7228800, "episode_reward": 0.25085732340812683, "value_loss": 0.008342016860842705, "policy_loss": -0.0015948910078506628, "dist_entropy": 0.4236409544944763, "actor_grad_norm": 0.13477782905101776, "critic_grad_norm": 0.04817910119891167, "ratio": 0.9996626973152161, "entropy": 0.4236409544944763, "incre_win_rate": 0.7333333333333333, "step": 2259}
{"time": 1767089738.4885774, "phase": "train", "update": 2260, "total_env_steps": 7232000, "episode_reward": 0.24373655021190643, "value_loss": 0.010881011746823788, "policy_loss": -0.0014964090766595994, "dist_entropy": 0.3947755455970764, "actor_grad_norm": 0.16190123558044434, "critic_grad_norm": 0.04364660754799843, "ratio": 0.9996541142463684, "entropy": 0.3947755455970764, "incre_win_rate": 0.6136363636363636, "step": 2260}
{"time": 1767089743.1228292, "phase": "train", "update": 2261, "total_env_steps": 7235200, "episode_reward": 0.24787253141403198, "value_loss": 0.009113483317196368, "policy_loss": -0.0016507791208688616, "dist_entropy": 0.40608806610107423, "actor_grad_norm": 0.14189186692237854, "critic_grad_norm": 0.03438088297843933, "ratio": 0.999661922454834, "entropy": 0.40608806610107423, "incre_win_rate": 0.7857142857142857, "step": 2261}
{"time": 1767089754.0041478, "phase": "eval", "update": 2261, "total_env_steps": 7235200, "eval_win_rate": 0.75, "eval_episode_reward": 18.864704056291387, "step": 2261}
{"time": 1767089759.081412, "phase": "train", "update": 2262, "total_env_steps": 7238400, "episode_reward": 0.25186359882354736, "value_loss": 0.007123606000095606, "policy_loss": -0.0014241775065531037, "dist_entropy": 0.4052931249141693, "actor_grad_norm": 0.11198709160089493, "critic_grad_norm": 0.038839370012283325, "ratio": 1.0001248121261597, "entropy": 0.4052931249141693, "incre_win_rate": 0.7380952380952381, "step": 2262}
{"time": 1767089764.0366743, "phase": "train", "update": 2263, "total_env_steps": 7241600, "episode_reward": 0.24705764651298523, "value_loss": 0.009649570472538472, "policy_loss": -0.0014316203721971732, "dist_entropy": 0.4139379858970642, "actor_grad_norm": 0.10611430555582047, "critic_grad_norm": 0.03848418593406677, "ratio": 1.0000463724136353, "entropy": 0.4139379858970642, "incre_win_rate": 0.7441860465116279, "step": 2263}
{"time": 1767089769.1355166, "phase": "train", "update": 2264, "total_env_steps": 7244800, "episode_reward": 0.21996742486953735, "value_loss": 0.010272724740207195, "policy_loss": -0.001742722923724216, "dist_entropy": 0.40937111973762513, "actor_grad_norm": 0.12652572989463806, "critic_grad_norm": 0.03342543914914131, "ratio": 0.9999594688415527, "entropy": 0.40937111973762513, "incre_win_rate": 0.5384615384615384, "step": 2264}
{"time": 1767089774.0377078, "phase": "train", "update": 2265, "total_env_steps": 7248000, "episode_reward": 0.2501945197582245, "value_loss": 0.008724924176931381, "policy_loss": -0.0015065269175522644, "dist_entropy": 0.4047990024089813, "actor_grad_norm": 0.1703808605670929, "critic_grad_norm": 0.04879188537597656, "ratio": 1.0000848770141602, "entropy": 0.4047990024089813, "incre_win_rate": 0.6818181818181818, "step": 2265}
{"time": 1767089778.7899418, "phase": "train", "update": 2266, "total_env_steps": 7251200, "episode_reward": 0.24580037593841553, "value_loss": 0.007207784056663513, "policy_loss": -0.0015157886904660245, "dist_entropy": 0.41776097416877744, "actor_grad_norm": 0.16015195846557617, "critic_grad_norm": 0.033335745334625244, "ratio": 1.0004228353500366, "entropy": 0.41776097416877744, "incre_win_rate": 0.7045454545454546, "step": 2266}
{"time": 1767089784.1701527, "phase": "train", "update": 2267, "total_env_steps": 7254400, "episode_reward": 0.2607041597366333, "value_loss": 0.0073188886977732185, "policy_loss": -0.0014884167921923818, "dist_entropy": 0.40331814885139466, "actor_grad_norm": 0.13062436878681183, "critic_grad_norm": 0.059255730360746384, "ratio": 0.9995956420898438, "entropy": 0.40331814885139466, "incre_win_rate": 0.8571428571428571, "step": 2267}
{"time": 1767089789.3928409, "phase": "train", "update": 2268, "total_env_steps": 7257600, "episode_reward": 0.247111976146698, "value_loss": 0.009002114087343216, "policy_loss": -0.0013442455679431476, "dist_entropy": 0.40547863245010374, "actor_grad_norm": 0.13377045094966888, "critic_grad_norm": 0.060911696404218674, "ratio": 0.9997243881225586, "entropy": 0.40547863245010374, "incre_win_rate": 0.5909090909090909, "step": 2268}
{"time": 1767089794.4249008, "phase": "train", "update": 2269, "total_env_steps": 7260800, "episode_reward": 0.24846388399600983, "value_loss": 0.008164760004729033, "policy_loss": -0.0011352219048703204, "dist_entropy": 0.42136524319648744, "actor_grad_norm": 0.13043047487735748, "critic_grad_norm": 0.05123449116945267, "ratio": 0.9999410510063171, "entropy": 0.42136524319648744, "incre_win_rate": 0.7441860465116279, "step": 2269}
{"time": 1767089799.6390133, "phase": "train", "update": 2270, "total_env_steps": 7264000, "episode_reward": 0.24646835029125214, "value_loss": 0.011271800100803375, "policy_loss": -0.001632785788049773, "dist_entropy": 0.4142211973667145, "actor_grad_norm": 0.1223905086517334, "critic_grad_norm": 0.05303521826863289, "ratio": 0.9998825192451477, "entropy": 0.4142211973667145, "incre_win_rate": 0.6976744186046512, "step": 2270}
{"time": 1767089804.966761, "phase": "train", "update": 2271, "total_env_steps": 7267200, "episode_reward": 0.2454744577407837, "value_loss": 0.008851619996130466, "policy_loss": -0.001260049046490508, "dist_entropy": 0.41015387177467344, "actor_grad_norm": 0.13060562312602997, "critic_grad_norm": 0.07230237126350403, "ratio": 1.000410795211792, "entropy": 0.41015387177467344, "incre_win_rate": 0.6590909090909091, "step": 2271}
{"time": 1767089809.9091582, "phase": "train", "update": 2272, "total_env_steps": 7270400, "episode_reward": 0.23881210386753082, "value_loss": 0.008872603625059127, "policy_loss": -0.0011578482169966263, "dist_entropy": 0.41380310654640196, "actor_grad_norm": 0.1348295956850052, "critic_grad_norm": 0.05920003727078438, "ratio": 1.000020146369934, "entropy": 0.41380310654640196, "incre_win_rate": 0.6666666666666666, "step": 2272}
{"time": 1767089814.97806, "phase": "train", "update": 2273, "total_env_steps": 7273600, "episode_reward": 0.24809551239013672, "value_loss": 0.008108505979180336, "policy_loss": -0.0012836664762701845, "dist_entropy": 0.4210556149482727, "actor_grad_norm": 0.14421020448207855, "critic_grad_norm": 0.049639731645584106, "ratio": 1.0003608465194702, "entropy": 0.4210556149482727, "incre_win_rate": 0.7954545454545454, "step": 2273}
{"time": 1767089819.8462386, "phase": "train", "update": 2274, "total_env_steps": 7276800, "episode_reward": 0.20350734889507294, "value_loss": 0.012409225292503833, "policy_loss": -0.002072501653827885, "dist_entropy": 0.4420173168182373, "actor_grad_norm": 0.12899473309516907, "critic_grad_norm": 0.11766419559717178, "ratio": 1.0001965761184692, "entropy": 0.4420173168182373, "incre_win_rate": 0.47368421052631576, "step": 2274}
{"time": 1767089824.837411, "phase": "train", "update": 2275, "total_env_steps": 7280000, "episode_reward": 0.25312912464141846, "value_loss": 0.007927929796278477, "policy_loss": -0.0011834702199667647, "dist_entropy": 0.400774085521698, "actor_grad_norm": 0.12075082212686539, "critic_grad_norm": 0.09048475325107574, "ratio": 1.000357985496521, "entropy": 0.400774085521698, "incre_win_rate": 0.6976744186046512, "step": 2275}
{"time": 1767089829.4304073, "phase": "train", "update": 2276, "total_env_steps": 7283200, "episode_reward": 0.24560017883777618, "value_loss": 0.009210919216275214, "policy_loss": -0.0013269426075225965, "dist_entropy": 0.4056154191493988, "actor_grad_norm": 0.10051947832107544, "critic_grad_norm": 0.061961133033037186, "ratio": 1.000004768371582, "entropy": 0.4056154191493988, "incre_win_rate": 0.7209302325581395, "step": 2276}
{"time": 1767089834.102584, "phase": "train", "update": 2277, "total_env_steps": 7286400, "episode_reward": 0.23261691629886627, "value_loss": 0.00988110974431038, "policy_loss": -0.0018046603880819134, "dist_entropy": 0.4066669762134552, "actor_grad_norm": 0.12268707901239395, "critic_grad_norm": 0.024319827556610107, "ratio": 0.9999408721923828, "entropy": 0.4066669762134552, "incre_win_rate": 0.6341463414634146, "step": 2277}
{"time": 1767089838.7071884, "phase": "train", "update": 2278, "total_env_steps": 7289600, "episode_reward": 0.24730806052684784, "value_loss": 0.010527252964675427, "policy_loss": -0.0015232065254366489, "dist_entropy": 0.39425874352455137, "actor_grad_norm": 0.15408872067928314, "critic_grad_norm": 0.03914286196231842, "ratio": 1.0000265836715698, "entropy": 0.39425874352455137, "incre_win_rate": 0.6666666666666666, "step": 2278}
{"time": 1767089843.3563232, "phase": "train", "update": 2279, "total_env_steps": 7292800, "episode_reward": 0.24888038635253906, "value_loss": 0.00879100002348423, "policy_loss": -0.0013628907882335284, "dist_entropy": 0.39797031283378603, "actor_grad_norm": 0.11115415394306183, "critic_grad_norm": 0.04926960542798042, "ratio": 0.9998093843460083, "entropy": 0.39797031283378603, "incre_win_rate": 0.7142857142857143, "step": 2279}
{"time": 1767089848.1074889, "phase": "train", "update": 2280, "total_env_steps": 7296000, "episode_reward": 0.2654532194137573, "value_loss": 0.005742891598492861, "policy_loss": -0.0014076746654978934, "dist_entropy": 0.40320574641227724, "actor_grad_norm": 0.10035079717636108, "critic_grad_norm": 0.05713868886232376, "ratio": 0.9999820590019226, "entropy": 0.40320574641227724, "incre_win_rate": 0.8888888888888888, "step": 2280}
{"time": 1767089852.7435858, "phase": "train", "update": 2281, "total_env_steps": 7299200, "episode_reward": 0.24693813920021057, "value_loss": 0.00827285386621952, "policy_loss": -0.0014256962087557667, "dist_entropy": 0.40119083523750304, "actor_grad_norm": 0.12635701894760132, "critic_grad_norm": 0.03631320968270302, "ratio": 0.9995372891426086, "entropy": 0.40119083523750304, "incre_win_rate": 0.6511627906976745, "step": 2281}
{"time": 1767089865.2671502, "phase": "eval", "update": 2281, "total_env_steps": 7299200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.694846854304636, "step": 2281}
{"time": 1767089870.4663982, "phase": "train", "update": 2282, "total_env_steps": 7302400, "episode_reward": 0.2461770623922348, "value_loss": 0.009632459841668606, "policy_loss": -0.001601922252143595, "dist_entropy": 0.40418691039085386, "actor_grad_norm": 0.11266787350177765, "critic_grad_norm": 0.0559372678399086, "ratio": 0.9999879002571106, "entropy": 0.40418691039085386, "incre_win_rate": 0.6666666666666666, "step": 2282}
{"time": 1767089875.902594, "phase": "train", "update": 2283, "total_env_steps": 7305600, "episode_reward": 0.2492668777704239, "value_loss": 0.010334392450749874, "policy_loss": -0.0011763510922918386, "dist_entropy": 0.3987208366394043, "actor_grad_norm": 0.11693388223648071, "critic_grad_norm": 0.05275503545999527, "ratio": 1.0003072023391724, "entropy": 0.3987208366394043, "incre_win_rate": 0.6666666666666666, "step": 2283}
{"time": 1767089881.0237448, "phase": "train", "update": 2284, "total_env_steps": 7308800, "episode_reward": 0.2318781316280365, "value_loss": 0.009495239146053791, "policy_loss": -0.0015294121684412687, "dist_entropy": 0.42744598984718324, "actor_grad_norm": 0.10785185545682907, "critic_grad_norm": 0.03277846798300743, "ratio": 0.9999675154685974, "entropy": 0.42744598984718324, "incre_win_rate": 0.6, "step": 2284}
{"time": 1767089886.1941676, "phase": "train", "update": 2285, "total_env_steps": 7312000, "episode_reward": 0.25179117918014526, "value_loss": 0.008056412264704705, "policy_loss": -0.0014111094299011028, "dist_entropy": 0.41869828701019285, "actor_grad_norm": 0.17341791093349457, "critic_grad_norm": 0.03357675299048424, "ratio": 0.9995924234390259, "entropy": 0.41869828701019285, "incre_win_rate": 0.6744186046511628, "step": 2285}
{"time": 1767089891.055034, "phase": "train", "update": 2286, "total_env_steps": 7315200, "episode_reward": 0.2482326179742813, "value_loss": 0.008100462704896927, "policy_loss": -0.0015705134243219731, "dist_entropy": 0.42003234624862673, "actor_grad_norm": 0.1257663369178772, "critic_grad_norm": 0.03295403718948364, "ratio": 1.0000413656234741, "entropy": 0.42003234624862673, "incre_win_rate": 0.7619047619047619, "step": 2286}
{"time": 1767089895.8846812, "phase": "train", "update": 2287, "total_env_steps": 7318400, "episode_reward": 0.25332728028297424, "value_loss": 0.008665620535612106, "policy_loss": -0.0014758073600688703, "dist_entropy": 0.42142717242240907, "actor_grad_norm": 0.15001901984214783, "critic_grad_norm": 0.02899775840342045, "ratio": 0.9999606013298035, "entropy": 0.42142717242240907, "incre_win_rate": 0.7333333333333333, "step": 2287}
{"time": 1767089926.5402775, "phase": "train", "update": 2288, "total_env_steps": 7321600, "episode_reward": 0.2376919537782669, "value_loss": 0.05231403410434723, "policy_loss": -0.00131899954804382, "dist_entropy": 0.4174161791801453, "actor_grad_norm": 0.0979216918349266, "critic_grad_norm": 0.2194254845380783, "ratio": 1.000009536743164, "entropy": 0.4174161791801453, "incre_win_rate": 0.6842105263157895, "step": 2288}
{"time": 1767089931.1637707, "phase": "train", "update": 2289, "total_env_steps": 7324800, "episode_reward": 0.25246119499206543, "value_loss": 0.009403521195054054, "policy_loss": -0.0017189292221026164, "dist_entropy": 0.404080867767334, "actor_grad_norm": 0.12778674066066742, "critic_grad_norm": 0.13479484617710114, "ratio": 1.0001047849655151, "entropy": 0.404080867767334, "incre_win_rate": 0.7142857142857143, "step": 2289}
{"time": 1767089935.8537717, "phase": "train", "update": 2290, "total_env_steps": 7328000, "episode_reward": 0.23789478838443756, "value_loss": 0.008881497383117675, "policy_loss": -0.001373013171871662, "dist_entropy": 0.40512661933898925, "actor_grad_norm": 0.12504711747169495, "critic_grad_norm": 0.1147070899605751, "ratio": 1.0000513792037964, "entropy": 0.40512661933898925, "incre_win_rate": 0.7560975609756098, "step": 2290}
{"time": 1767089940.4075317, "phase": "train", "update": 2291, "total_env_steps": 7331200, "episode_reward": 0.22502897679805756, "value_loss": 0.01007877103984356, "policy_loss": -0.0016751698145711202, "dist_entropy": 0.42184128761291506, "actor_grad_norm": 0.15145505964756012, "critic_grad_norm": 0.050256457179784775, "ratio": 0.9998828172683716, "entropy": 0.42184128761291506, "incre_win_rate": 0.625, "step": 2291}
{"time": 1767089944.9946334, "phase": "train", "update": 2292, "total_env_steps": 7334400, "episode_reward": 0.25021523237228394, "value_loss": 0.009449442476034164, "policy_loss": -0.0011785374030566231, "dist_entropy": 0.4068774163722992, "actor_grad_norm": 0.10598099231719971, "critic_grad_norm": 0.03746466711163521, "ratio": 0.999829888343811, "entropy": 0.4068774163722992, "incre_win_rate": 0.7209302325581395, "step": 2292}
{"time": 1767089949.6051025, "phase": "train", "update": 2293, "total_env_steps": 7337600, "episode_reward": 0.2606462240219116, "value_loss": 0.009467050991952419, "policy_loss": -0.0014958207137368618, "dist_entropy": 0.4122089684009552, "actor_grad_norm": 0.16498111188411713, "critic_grad_norm": 0.04302329570055008, "ratio": 1.000146508216858, "entropy": 0.4122089684009552, "incre_win_rate": 0.8, "step": 2293}
{"time": 1767089954.1831083, "phase": "train", "update": 2294, "total_env_steps": 7340800, "episode_reward": 0.23148851096630096, "value_loss": 0.007428075931966305, "policy_loss": -0.0017388378962138519, "dist_entropy": 0.42465407848358155, "actor_grad_norm": 0.13079963624477386, "critic_grad_norm": 0.037591006606817245, "ratio": 0.9998368620872498, "entropy": 0.42465407848358155, "incre_win_rate": 0.6666666666666666, "step": 2294}
{"time": 1767089958.8429337, "phase": "train", "update": 2295, "total_env_steps": 7344000, "episode_reward": 0.24350889027118683, "value_loss": 0.01099532824009657, "policy_loss": -0.001619874996837467, "dist_entropy": 0.44304349422454836, "actor_grad_norm": 0.10447706282138824, "critic_grad_norm": 0.05060432106256485, "ratio": 0.9997262954711914, "entropy": 0.44304349422454836, "incre_win_rate": 0.717948717948718, "step": 2295}
{"time": 1767089963.4206407, "phase": "train", "update": 2296, "total_env_steps": 7347200, "episode_reward": 0.24158473312854767, "value_loss": 0.011638737097382546, "policy_loss": -0.0017189746053105637, "dist_entropy": 0.42543032169342043, "actor_grad_norm": 0.11841946840286255, "critic_grad_norm": 0.04548594728112221, "ratio": 0.9996509552001953, "entropy": 0.42543032169342043, "incre_win_rate": 0.6888888888888889, "step": 2296}
{"time": 1767089967.9595473, "phase": "train", "update": 2297, "total_env_steps": 7350400, "episode_reward": 0.22218440473079681, "value_loss": 0.010019676387310028, "policy_loss": -0.0022667335918029607, "dist_entropy": 0.43157002329826355, "actor_grad_norm": 0.15547585487365723, "critic_grad_norm": 0.04763389751315117, "ratio": 0.9999207854270935, "entropy": 0.43157002329826355, "incre_win_rate": 0.7027027027027027, "step": 2297}
{"time": 1767089972.4365377, "phase": "train", "update": 2298, "total_env_steps": 7353600, "episode_reward": 0.20955713093280792, "value_loss": 0.010460690595209599, "policy_loss": -0.00177525549197739, "dist_entropy": 0.41849200129508973, "actor_grad_norm": 0.1388804018497467, "critic_grad_norm": 0.03181612119078636, "ratio": 0.9999451041221619, "entropy": 0.41849200129508973, "incre_win_rate": 0.631578947368421, "step": 2298}
{"time": 1767089977.1137996, "phase": "train", "update": 2299, "total_env_steps": 7356800, "episode_reward": 0.2221812754869461, "value_loss": 0.009782994911074639, "policy_loss": -0.0016323279870675833, "dist_entropy": 0.4316490888595581, "actor_grad_norm": 0.15038150548934937, "critic_grad_norm": 0.04969748482108116, "ratio": 0.9996703267097473, "entropy": 0.4316490888595581, "incre_win_rate": 0.6666666666666666, "step": 2299}
{"time": 1767089982.136585, "phase": "train", "update": 2300, "total_env_steps": 7360000, "episode_reward": 0.24029439687728882, "value_loss": 0.00921759381890297, "policy_loss": -0.0015393790420592524, "dist_entropy": 0.41953806281089784, "actor_grad_norm": 0.10500414669513702, "critic_grad_norm": 0.03173176199197769, "ratio": 0.9997758269309998, "entropy": 0.41953806281089784, "incre_win_rate": 0.6829268292682927, "step": 2300}
{"time": 1767089987.014054, "phase": "train", "update": 2301, "total_env_steps": 7363200, "episode_reward": 0.2404092401266098, "value_loss": 0.010260619781911373, "policy_loss": -0.0014628853352746773, "dist_entropy": 0.4260918438434601, "actor_grad_norm": 0.1233028694987297, "critic_grad_norm": 0.04740122705698013, "ratio": 1.0002577304840088, "entropy": 0.4260918438434601, "incre_win_rate": 0.6744186046511628, "step": 2301}
{"time": 1767089999.948152, "phase": "eval", "update": 2301, "total_env_steps": 7363200, "eval_win_rate": 0.78125, "eval_episode_reward": 18.857408940397345, "step": 2301}
{"time": 1767090005.0826597, "phase": "train", "update": 2302, "total_env_steps": 7366400, "episode_reward": 0.2319691777229309, "value_loss": 0.013981015793979168, "policy_loss": -0.001633016641596452, "dist_entropy": 0.4200240135192871, "actor_grad_norm": 0.14387524127960205, "critic_grad_norm": 0.05455000326037407, "ratio": 0.9997913241386414, "entropy": 0.4200240135192871, "incre_win_rate": 0.6341463414634146, "step": 2302}
{"time": 1767090010.5843549, "phase": "train", "update": 2303, "total_env_steps": 7369600, "episode_reward": 0.23913493752479553, "value_loss": 0.00862331986427307, "policy_loss": -0.0017315709678186408, "dist_entropy": 0.4183682262897491, "actor_grad_norm": 0.1302722841501236, "critic_grad_norm": 0.09849333763122559, "ratio": 1.0000885725021362, "entropy": 0.4183682262897491, "incre_win_rate": 0.7317073170731707, "step": 2303}
{"time": 1767090016.1394198, "phase": "train", "update": 2304, "total_env_steps": 7372800, "episode_reward": 0.24326056241989136, "value_loss": 0.0071526837535202505, "policy_loss": -0.001676463509147652, "dist_entropy": 0.42425539493560793, "actor_grad_norm": 0.13434426486492157, "critic_grad_norm": 0.037853505462408066, "ratio": 1.0000097751617432, "entropy": 0.42425539493560793, "incre_win_rate": 0.7804878048780488, "step": 2304}
{"time": 1767090021.0046277, "phase": "train", "update": 2305, "total_env_steps": 7376000, "episode_reward": 0.2534846067428589, "value_loss": 0.006377429608255625, "policy_loss": -0.0013542266995514752, "dist_entropy": 0.4189024746417999, "actor_grad_norm": 0.11962395906448364, "critic_grad_norm": 0.01873806305229664, "ratio": 0.9998491406440735, "entropy": 0.4189024746417999, "incre_win_rate": 0.8095238095238095, "step": 2305}
{"time": 1767090025.6534252, "phase": "train", "update": 2306, "total_env_steps": 7379200, "episode_reward": 0.22509416937828064, "value_loss": 0.006818924378603697, "policy_loss": -0.0016029233794895958, "dist_entropy": 0.43247848749160767, "actor_grad_norm": 0.11894463747739792, "critic_grad_norm": 0.04983634874224663, "ratio": 0.999821662902832, "entropy": 0.43247848749160767, "incre_win_rate": 0.625, "step": 2306}
{"time": 1767090030.3544858, "phase": "train", "update": 2307, "total_env_steps": 7382400, "episode_reward": 0.24622207880020142, "value_loss": 0.007221090979874134, "policy_loss": -0.0016217489785134375, "dist_entropy": 0.42601901292800903, "actor_grad_norm": 0.12117298692464828, "critic_grad_norm": 0.05322137102484703, "ratio": 1.000048279762268, "entropy": 0.42601901292800903, "incre_win_rate": 0.8, "step": 2307}
{"time": 1767090035.04582, "phase": "train", "update": 2308, "total_env_steps": 7385600, "episode_reward": 0.24389640986919403, "value_loss": 0.009459890983998775, "policy_loss": -0.001625502537891066, "dist_entropy": 0.417175954580307, "actor_grad_norm": 0.15520495176315308, "critic_grad_norm": 0.05681219696998596, "ratio": 1.000099539756775, "entropy": 0.417175954580307, "incre_win_rate": 0.7045454545454546, "step": 2308}
{"time": 1767090039.7065609, "phase": "train", "update": 2309, "total_env_steps": 7388800, "episode_reward": 0.22240790724754333, "value_loss": 0.00924350954592228, "policy_loss": -0.0015125503911107784, "dist_entropy": 0.45090712904930114, "actor_grad_norm": 0.16521446406841278, "critic_grad_norm": 0.03424159437417984, "ratio": 0.99970942735672, "entropy": 0.45090712904930114, "incre_win_rate": 0.6153846153846154, "step": 2309}
{"time": 1767090044.284707, "phase": "train", "update": 2310, "total_env_steps": 7392000, "episode_reward": 0.2389610856771469, "value_loss": 0.009208199940621853, "policy_loss": -0.0017956700721327933, "dist_entropy": 0.4177173852920532, "actor_grad_norm": 0.13447819650173187, "critic_grad_norm": 0.033162932842969894, "ratio": 1.0000089406967163, "entropy": 0.4177173852920532, "incre_win_rate": 0.6744186046511628, "step": 2310}
{"time": 1767090048.989728, "phase": "train", "update": 2311, "total_env_steps": 7395200, "episode_reward": 0.24348251521587372, "value_loss": 0.009304549172520637, "policy_loss": -0.0016621231879552667, "dist_entropy": 0.40368747115135195, "actor_grad_norm": 0.14254894852638245, "critic_grad_norm": 0.04534178972244263, "ratio": 0.9993749856948853, "entropy": 0.40368747115135195, "incre_win_rate": 0.7894736842105263, "step": 2311}
{"time": 1767090053.7084074, "phase": "train", "update": 2312, "total_env_steps": 7398400, "episode_reward": 0.25760090351104736, "value_loss": 0.006763417553156614, "policy_loss": -0.0016635848670880193, "dist_entropy": 0.40926583409309386, "actor_grad_norm": 0.11044160276651382, "critic_grad_norm": 0.039386674761772156, "ratio": 0.9996880888938904, "entropy": 0.40926583409309386, "incre_win_rate": 0.8, "step": 2312}
{"time": 1767090058.4850621, "phase": "train", "update": 2313, "total_env_steps": 7401600, "episode_reward": 0.2533164322376251, "value_loss": 0.007455326244235038, "policy_loss": -0.0014460856559281865, "dist_entropy": 0.4000198423862457, "actor_grad_norm": 0.09863676875829697, "critic_grad_norm": 0.02114453911781311, "ratio": 0.9993998408317566, "entropy": 0.4000198423862457, "incre_win_rate": 0.8372093023255814, "step": 2313}
{"time": 1767090063.4939344, "phase": "train", "update": 2314, "total_env_steps": 7404800, "episode_reward": 0.259940505027771, "value_loss": 0.006521164998412132, "policy_loss": -0.0017260395164804265, "dist_entropy": 0.4017867028713226, "actor_grad_norm": 0.11521772295236588, "critic_grad_norm": 0.02635682187974453, "ratio": 1.0000219345092773, "entropy": 0.4017867028713226, "incre_win_rate": 0.7555555555555555, "step": 2314}
{"time": 1767090068.610647, "phase": "train", "update": 2315, "total_env_steps": 7408000, "episode_reward": 0.2587282955646515, "value_loss": 0.0076934689655900005, "policy_loss": -0.00147200688440563, "dist_entropy": 0.4157633066177368, "actor_grad_norm": 0.10800223797559738, "critic_grad_norm": 0.020448170602321625, "ratio": 1.0000098943710327, "entropy": 0.4157633066177368, "incre_win_rate": 0.813953488372093, "step": 2315}
{"time": 1767090074.0043433, "phase": "train", "update": 2316, "total_env_steps": 7411200, "episode_reward": 0.26616308093070984, "value_loss": 0.00573109881952405, "policy_loss": -0.0017044028174499459, "dist_entropy": 0.40855143070220945, "actor_grad_norm": 0.14357736706733704, "critic_grad_norm": 0.015010622330009937, "ratio": 1.0000989437103271, "entropy": 0.40855143070220945, "incre_win_rate": 0.813953488372093, "step": 2316}
{"time": 1767090079.3363674, "phase": "train", "update": 2317, "total_env_steps": 7414400, "episode_reward": 0.24485719203948975, "value_loss": 0.010523485951125622, "policy_loss": -0.0017262800576077098, "dist_entropy": 0.42047889828681945, "actor_grad_norm": 0.11063384264707565, "critic_grad_norm": 0.05989048629999161, "ratio": 0.9998422861099243, "entropy": 0.42047889828681945, "incre_win_rate": 0.75, "step": 2317}
{"time": 1767090084.7230158, "phase": "train", "update": 2318, "total_env_steps": 7417600, "episode_reward": 0.2467244565486908, "value_loss": 0.008519212529063225, "policy_loss": -0.0015711210740054326, "dist_entropy": 0.43647952675819396, "actor_grad_norm": 0.15189234912395477, "critic_grad_norm": 0.0659792572259903, "ratio": 0.9999602437019348, "entropy": 0.43647952675819396, "incre_win_rate": 0.6976744186046512, "step": 2318}
{"time": 1767090090.0326595, "phase": "train", "update": 2319, "total_env_steps": 7420800, "episode_reward": 0.24162769317626953, "value_loss": 0.007775333151221276, "policy_loss": -0.0012878634675844935, "dist_entropy": 0.4216491520404816, "actor_grad_norm": 0.16089797019958496, "critic_grad_norm": 0.05641248822212219, "ratio": 1.0000935792922974, "entropy": 0.4216491520404816, "incre_win_rate": 0.775, "step": 2319}
{"time": 1767090095.2402897, "phase": "train", "update": 2320, "total_env_steps": 7424000, "episode_reward": 0.26023852825164795, "value_loss": 0.005030581075698137, "policy_loss": -0.0018431930078039115, "dist_entropy": 0.43357169032096865, "actor_grad_norm": 0.11236647516489029, "critic_grad_norm": 0.023356769233942032, "ratio": 0.9999489188194275, "entropy": 0.43357169032096865, "incre_win_rate": 0.8372093023255814, "step": 2320}
{"time": 1767090100.0978014, "phase": "train", "update": 2321, "total_env_steps": 7427200, "episode_reward": 0.25215956568717957, "value_loss": 0.009067251719534397, "policy_loss": -0.001227073649144117, "dist_entropy": 0.4108868598937988, "actor_grad_norm": 0.0952540934085846, "critic_grad_norm": 0.05949988588690758, "ratio": 0.9999316334724426, "entropy": 0.4108868598937988, "incre_win_rate": 0.7111111111111111, "step": 2321}
{"time": 1767090111.666738, "phase": "eval", "update": 2321, "total_env_steps": 7427200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.733340231788077, "step": 2321}
{"time": 1767090116.7368517, "phase": "train", "update": 2322, "total_env_steps": 7430400, "episode_reward": 0.2598540782928467, "value_loss": 0.006938725709915161, "policy_loss": -0.0014013662421049843, "dist_entropy": 0.4287997126579285, "actor_grad_norm": 0.11888816207647324, "critic_grad_norm": 0.058316972106695175, "ratio": 1.0000488758087158, "entropy": 0.4287997126579285, "incre_win_rate": 0.813953488372093, "step": 2322}
{"time": 1767090121.8811514, "phase": "train", "update": 2323, "total_env_steps": 7433600, "episode_reward": 0.2350470870733261, "value_loss": 0.007839431054890156, "policy_loss": -0.0017110425424760934, "dist_entropy": 0.4391357123851776, "actor_grad_norm": 0.17806553840637207, "critic_grad_norm": 0.05079340934753418, "ratio": 1.0000933408737183, "entropy": 0.4391357123851776, "incre_win_rate": 0.675, "step": 2323}
{"time": 1767090126.6703947, "phase": "train", "update": 2324, "total_env_steps": 7436800, "episode_reward": 0.2354470193386078, "value_loss": 0.009862595424056052, "policy_loss": -0.001781694069329376, "dist_entropy": 0.43665966391563416, "actor_grad_norm": 0.11680976301431656, "critic_grad_norm": 0.05466237664222717, "ratio": 0.9995433688163757, "entropy": 0.43665966391563416, "incre_win_rate": 0.6976744186046512, "step": 2324}
{"time": 1767090131.4888494, "phase": "train", "update": 2325, "total_env_steps": 7440000, "episode_reward": 0.24130898714065552, "value_loss": 0.008557934686541558, "policy_loss": -0.0016186237488497568, "dist_entropy": 0.4183772087097168, "actor_grad_norm": 0.14193227887153625, "critic_grad_norm": 0.026996392756700516, "ratio": 1.0002456903457642, "entropy": 0.4183772087097168, "incre_win_rate": 0.7073170731707317, "step": 2325}
{"time": 1767090136.326341, "phase": "train", "update": 2326, "total_env_steps": 7443200, "episode_reward": 0.23914062976837158, "value_loss": 0.01063487995415926, "policy_loss": -0.0018208499682756951, "dist_entropy": 0.41881117820739744, "actor_grad_norm": 0.11999896913766861, "critic_grad_norm": 0.025623535737395287, "ratio": 0.9997478723526001, "entropy": 0.41881117820739744, "incre_win_rate": 0.775, "step": 2326}
{"time": 1767090141.1857316, "phase": "train", "update": 2327, "total_env_steps": 7446400, "episode_reward": 0.2408883422613144, "value_loss": 0.00866117626428604, "policy_loss": -0.0016949379445753364, "dist_entropy": 0.41432964205741885, "actor_grad_norm": 0.14116041362285614, "critic_grad_norm": 0.039583947509527206, "ratio": 0.9998788833618164, "entropy": 0.41432964205741885, "incre_win_rate": 0.6046511627906976, "step": 2327}
{"time": 1767090146.205016, "phase": "train", "update": 2328, "total_env_steps": 7449600, "episode_reward": 0.25741100311279297, "value_loss": 0.009636180847883225, "policy_loss": -0.0015846639200375989, "dist_entropy": 0.4096225082874298, "actor_grad_norm": 0.12374415248632431, "critic_grad_norm": 0.05366058275103569, "ratio": 0.9997144937515259, "entropy": 0.4096225082874298, "incre_win_rate": 0.8372093023255814, "step": 2328}
{"time": 1767090151.10018, "phase": "train", "update": 2329, "total_env_steps": 7452800, "episode_reward": 0.2384064495563507, "value_loss": 0.007337599527090788, "policy_loss": -0.0015930787128048962, "dist_entropy": 0.4180059254169464, "actor_grad_norm": 0.13880273699760437, "critic_grad_norm": 0.06873057782649994, "ratio": 1.000146746635437, "entropy": 0.4180059254169464, "incre_win_rate": 0.7073170731707317, "step": 2329}
{"time": 1767090156.398919, "phase": "train", "update": 2330, "total_env_steps": 7456000, "episode_reward": 0.26020434498786926, "value_loss": 0.005784631334245205, "policy_loss": -0.001386391238258966, "dist_entropy": 0.4077358305454254, "actor_grad_norm": 0.12333913147449493, "critic_grad_norm": 0.034128621220588684, "ratio": 1.0001312494277954, "entropy": 0.4077358305454254, "incre_win_rate": 0.8409090909090909, "step": 2330}
{"time": 1767090161.678866, "phase": "train", "update": 2331, "total_env_steps": 7459200, "episode_reward": 0.22612427175045013, "value_loss": 0.009651887975633145, "policy_loss": -0.0016842707370006594, "dist_entropy": 0.4375615298748016, "actor_grad_norm": 0.14188826084136963, "critic_grad_norm": 0.08625158667564392, "ratio": 0.9999158978462219, "entropy": 0.4375615298748016, "incre_win_rate": 0.625, "step": 2331}
{"time": 1767090166.9041386, "phase": "train", "update": 2332, "total_env_steps": 7462400, "episode_reward": 0.26319071650505066, "value_loss": 0.008863275311887265, "policy_loss": -0.001669546312891157, "dist_entropy": 0.4056469023227692, "actor_grad_norm": 0.12303522974252701, "critic_grad_norm": 0.06032974645495415, "ratio": 0.9998650550842285, "entropy": 0.4056469023227692, "incre_win_rate": 0.8444444444444444, "step": 2332}
{"time": 1767090171.9234455, "phase": "train", "update": 2333, "total_env_steps": 7465600, "episode_reward": 0.26488152146339417, "value_loss": 0.006534899771213532, "policy_loss": -0.001945150138727314, "dist_entropy": 0.4090129673480988, "actor_grad_norm": 0.1611415296792984, "critic_grad_norm": 0.09615591168403625, "ratio": 1.0004417896270752, "entropy": 0.4090129673480988, "incre_win_rate": 0.7954545454545454, "step": 2333}
{"time": 1767090177.1107829, "phase": "train", "update": 2334, "total_env_steps": 7468800, "episode_reward": 0.2506767511367798, "value_loss": 0.008152792695909739, "policy_loss": -0.0011565386008101086, "dist_entropy": 0.4054889023303986, "actor_grad_norm": 0.11281271278858185, "critic_grad_norm": 0.06024590879678726, "ratio": 0.9998626112937927, "entropy": 0.4054889023303986, "incre_win_rate": 0.7674418604651163, "step": 2334}
{"time": 1767090181.9263997, "phase": "train", "update": 2335, "total_env_steps": 7472000, "episode_reward": 0.24876347184181213, "value_loss": 0.012550923973321915, "policy_loss": -0.0016826918135961933, "dist_entropy": 0.4104264140129089, "actor_grad_norm": 0.15978340804576874, "critic_grad_norm": 0.08460614085197449, "ratio": 1.000064492225647, "entropy": 0.4104264140129089, "incre_win_rate": 0.7142857142857143, "step": 2335}
{"time": 1767090186.5741062, "phase": "train", "update": 2336, "total_env_steps": 7475200, "episode_reward": 0.25294703245162964, "value_loss": 0.010166836157441139, "policy_loss": -0.0018341702322500098, "dist_entropy": 0.4188664197921753, "actor_grad_norm": 0.14084498584270477, "critic_grad_norm": 0.06288082152605057, "ratio": 0.9999435544013977, "entropy": 0.4188664197921753, "incre_win_rate": 0.7333333333333333, "step": 2336}
{"time": 1767090191.3909175, "phase": "train", "update": 2337, "total_env_steps": 7478400, "episode_reward": 0.2643176019191742, "value_loss": 0.005873123276978731, "policy_loss": -0.0013366834246255621, "dist_entropy": 0.4023307502269745, "actor_grad_norm": 0.1401423066854477, "critic_grad_norm": 0.058377642184495926, "ratio": 0.9997679591178894, "entropy": 0.4023307502269745, "incre_win_rate": 0.8409090909090909, "step": 2337}
{"time": 1767090196.1684415, "phase": "train", "update": 2338, "total_env_steps": 7481600, "episode_reward": 0.25249534845352173, "value_loss": 0.005904848873615265, "policy_loss": -0.0016008281509350298, "dist_entropy": 0.4313095390796661, "actor_grad_norm": 0.1220335140824318, "critic_grad_norm": 0.022983646020293236, "ratio": 1.0001780986785889, "entropy": 0.4313095390796661, "incre_win_rate": 0.8536585365853658, "step": 2338}
{"time": 1767090201.0673876, "phase": "train", "update": 2339, "total_env_steps": 7484800, "episode_reward": 0.23988410830497742, "value_loss": 0.01007867306470871, "policy_loss": -0.0016437287805061373, "dist_entropy": 0.431867253780365, "actor_grad_norm": 0.11445639282464981, "critic_grad_norm": 0.09296813607215881, "ratio": 0.9996742606163025, "entropy": 0.431867253780365, "incre_win_rate": 0.6904761904761905, "step": 2339}
{"time": 1767090206.03875, "phase": "train", "update": 2340, "total_env_steps": 7488000, "episode_reward": 0.2531436085700989, "value_loss": 0.006217325385659933, "policy_loss": -0.0017881268352141432, "dist_entropy": 0.3944950759410858, "actor_grad_norm": 0.11121436208486557, "critic_grad_norm": 0.06377339363098145, "ratio": 0.9996829032897949, "entropy": 0.3944950759410858, "incre_win_rate": 0.8333333333333334, "step": 2340}
{"time": 1767090211.3430443, "phase": "train", "update": 2341, "total_env_steps": 7491200, "episode_reward": 0.2573064863681793, "value_loss": 0.00762714222073555, "policy_loss": -0.0016535098847775486, "dist_entropy": 0.3877511262893677, "actor_grad_norm": 0.13047783076763153, "critic_grad_norm": 0.0572575218975544, "ratio": 0.9999314546585083, "entropy": 0.3877511262893677, "incre_win_rate": 0.7727272727272727, "step": 2341}
{"time": 1767090227.870603, "phase": "eval", "update": 2341, "total_env_steps": 7491200, "eval_win_rate": 0.875, "eval_episode_reward": 18.996999172185433, "step": 2341}
{"time": 1767090232.7181933, "phase": "train", "update": 2342, "total_env_steps": 7494400, "episode_reward": 0.2674834728240967, "value_loss": 0.00657162070274353, "policy_loss": -0.0012357731885487056, "dist_entropy": 0.3918060302734375, "actor_grad_norm": 0.12005980312824249, "critic_grad_norm": 0.0721115693449974, "ratio": 1.000205397605896, "entropy": 0.3918060302734375, "incre_win_rate": 0.8409090909090909, "step": 2342}
{"time": 1767090237.751992, "phase": "train", "update": 2343, "total_env_steps": 7497600, "episode_reward": 0.2713136374950409, "value_loss": 0.004581138864159584, "policy_loss": -0.0014491687258292528, "dist_entropy": 0.3926040053367615, "actor_grad_norm": 0.13155131042003632, "critic_grad_norm": 0.06937868893146515, "ratio": 1.0000971555709839, "entropy": 0.3926040053367615, "incre_win_rate": 0.9318181818181818, "step": 2343}
{"time": 1767090242.4707665, "phase": "train", "update": 2344, "total_env_steps": 7500800, "episode_reward": 0.26126915216445923, "value_loss": 0.00594775341451168, "policy_loss": -0.0013499445462230141, "dist_entropy": 0.4049308478832245, "actor_grad_norm": 0.17026077210903168, "critic_grad_norm": 0.045697618275880814, "ratio": 0.9999376535415649, "entropy": 0.4049308478832245, "incre_win_rate": 0.8604651162790697, "step": 2344}
{"time": 1767090247.41769, "phase": "train", "update": 2345, "total_env_steps": 7504000, "episode_reward": 0.259697824716568, "value_loss": 0.0061651931144297125, "policy_loss": -0.0011858374405061766, "dist_entropy": 0.40138227343559263, "actor_grad_norm": 0.09981872886419296, "critic_grad_norm": 0.0438276082277298, "ratio": 1.0000191926956177, "entropy": 0.40138227343559263, "incre_win_rate": 0.7954545454545454, "step": 2345}
{"time": 1767090252.3936222, "phase": "train", "update": 2346, "total_env_steps": 7507200, "episode_reward": 0.25678861141204834, "value_loss": 0.008164713438600302, "policy_loss": -0.001413241608653948, "dist_entropy": 0.4177340388298035, "actor_grad_norm": 0.1320183277130127, "critic_grad_norm": 0.0296919047832489, "ratio": 1.0001546144485474, "entropy": 0.4177340388298035, "incre_win_rate": 0.75, "step": 2346}
{"time": 1767090257.1945095, "phase": "train", "update": 2347, "total_env_steps": 7510400, "episode_reward": 0.2723882496356964, "value_loss": 0.005975820869207382, "policy_loss": -0.00152841335284144, "dist_entropy": 0.4095843851566315, "actor_grad_norm": 0.12899914383888245, "critic_grad_norm": 0.036286164075136185, "ratio": 0.9999178051948547, "entropy": 0.4095843851566315, "incre_win_rate": 0.8888888888888888, "step": 2347}
{"time": 1767090261.922013, "phase": "train", "update": 2348, "total_env_steps": 7513600, "episode_reward": 0.26058411598205566, "value_loss": 0.0065129614435136315, "policy_loss": -0.0016017450360749307, "dist_entropy": 0.39976551532745364, "actor_grad_norm": 0.1813480257987976, "critic_grad_norm": 0.022545872256159782, "ratio": 0.9997803568840027, "entropy": 0.39976551532745364, "incre_win_rate": 0.8181818181818182, "step": 2348}
{"time": 1767090267.0011053, "phase": "train", "update": 2349, "total_env_steps": 7516800, "episode_reward": 0.27084749937057495, "value_loss": 0.004981200210750103, "policy_loss": -0.0011307650578625595, "dist_entropy": 0.4058787405490875, "actor_grad_norm": 0.11286850273609161, "critic_grad_norm": 0.032181091606616974, "ratio": 0.9996786117553711, "entropy": 0.4058787405490875, "incre_win_rate": 0.9302325581395349, "step": 2349}
{"time": 1767090272.0223348, "phase": "train", "update": 2350, "total_env_steps": 7520000, "episode_reward": 0.28409767150878906, "value_loss": 0.003691945178434253, "policy_loss": -0.0015735416207414588, "dist_entropy": 0.3904155671596527, "actor_grad_norm": 0.12590472400188446, "critic_grad_norm": 0.024998947978019714, "ratio": 0.9999364018440247, "entropy": 0.3904155671596527, "incre_win_rate": 0.9782608695652174, "step": 2350}
{"time": 1767090276.7343025, "phase": "train", "update": 2351, "total_env_steps": 7523200, "episode_reward": 0.25652629137039185, "value_loss": 0.006422280613332987, "policy_loss": -0.0016579828304131184, "dist_entropy": 0.4066291213035583, "actor_grad_norm": 0.15296734869480133, "critic_grad_norm": 0.040371157228946686, "ratio": 0.9996806979179382, "entropy": 0.4066291213035583, "incre_win_rate": 0.8409090909090909, "step": 2351}
{"time": 1767090281.481124, "phase": "train", "update": 2352, "total_env_steps": 7526400, "episode_reward": 0.2556932866573334, "value_loss": 0.005690517649054527, "policy_loss": -0.0015534656407083958, "dist_entropy": 0.42410714030265806, "actor_grad_norm": 0.10817289352416992, "critic_grad_norm": 0.021799111738801003, "ratio": 1.0000131130218506, "entropy": 0.42410714030265806, "incre_win_rate": 0.8571428571428571, "step": 2352}
{"time": 1767090286.7326136, "phase": "train", "update": 2353, "total_env_steps": 7529600, "episode_reward": 0.2681658864021301, "value_loss": 0.0064278004691004755, "policy_loss": -0.0014431896505804787, "dist_entropy": 0.4074352324008942, "actor_grad_norm": 0.13706915080547333, "critic_grad_norm": 0.0327889584004879, "ratio": 1.0001897811889648, "entropy": 0.4074352324008942, "incre_win_rate": 0.813953488372093, "step": 2353}
{"time": 1767090291.9288697, "phase": "train", "update": 2354, "total_env_steps": 7532800, "episode_reward": 0.26752328872680664, "value_loss": 0.006333630438894034, "policy_loss": -0.0014160611207941543, "dist_entropy": 0.4006220757961273, "actor_grad_norm": 0.11959892511367798, "critic_grad_norm": 0.025350481271743774, "ratio": 0.999748170375824, "entropy": 0.4006220757961273, "incre_win_rate": 0.9318181818181818, "step": 2354}
{"time": 1767090296.6431017, "phase": "train", "update": 2355, "total_env_steps": 7536000, "episode_reward": 0.24134933948516846, "value_loss": 0.005591569468379021, "policy_loss": -0.0017808615321733613, "dist_entropy": 0.4258814811706543, "actor_grad_norm": 0.12162786722183228, "critic_grad_norm": 0.027784839272499084, "ratio": 0.9999386668205261, "entropy": 0.4258814811706543, "incre_win_rate": 0.8604651162790697, "step": 2355}
{"time": 1767090301.4479709, "phase": "train", "update": 2356, "total_env_steps": 7539200, "episode_reward": 0.26589715480804443, "value_loss": 0.006369708757847548, "policy_loss": -0.00148483219751796, "dist_entropy": 0.3926373362541199, "actor_grad_norm": 0.1543339341878891, "critic_grad_norm": 0.03488367423415184, "ratio": 0.9998323321342468, "entropy": 0.3926373362541199, "incre_win_rate": 0.8292682926829268, "step": 2356}
{"time": 1767090306.3731382, "phase": "train", "update": 2357, "total_env_steps": 7542400, "episode_reward": 0.25794756412506104, "value_loss": 0.004892484936863184, "policy_loss": -0.0014680675361731232, "dist_entropy": 0.40039135217666627, "actor_grad_norm": 0.13092343509197235, "critic_grad_norm": 0.02166079729795456, "ratio": 0.9998540878295898, "entropy": 0.40039135217666627, "incre_win_rate": 0.7954545454545454, "step": 2357}
{"time": 1767090311.0070286, "phase": "train", "update": 2358, "total_env_steps": 7545600, "episode_reward": 0.25374743342399597, "value_loss": 0.00836020614951849, "policy_loss": -0.001476197158388004, "dist_entropy": 0.4110571265220642, "actor_grad_norm": 0.13742053508758545, "critic_grad_norm": 0.03261805325746536, "ratio": 1.0001863241195679, "entropy": 0.4110571265220642, "incre_win_rate": 0.7857142857142857, "step": 2358}
{"time": 1767090315.6998448, "phase": "train", "update": 2359, "total_env_steps": 7548800, "episode_reward": 0.2434038668870926, "value_loss": 0.009025071747601032, "policy_loss": -0.0013399744631811927, "dist_entropy": 0.4107614040374756, "actor_grad_norm": 0.12409485876560211, "critic_grad_norm": 0.02409440279006958, "ratio": 0.9998487830162048, "entropy": 0.4107614040374756, "incre_win_rate": 0.6976744186046512, "step": 2359}
{"time": 1767090320.4122767, "phase": "train", "update": 2360, "total_env_steps": 7552000, "episode_reward": 0.255767285823822, "value_loss": 0.008013950474560261, "policy_loss": -0.0013723107031339055, "dist_entropy": 0.4053042471408844, "actor_grad_norm": 0.15618173778057098, "critic_grad_norm": 0.02650955319404602, "ratio": 1.00014066696167, "entropy": 0.4053042471408844, "incre_win_rate": 0.7906976744186046, "step": 2360}
{"time": 1767090324.9965456, "phase": "train", "update": 2361, "total_env_steps": 7555200, "episode_reward": 0.2609354257583618, "value_loss": 0.00754553647711873, "policy_loss": -0.0012991868891560898, "dist_entropy": 0.39789379239082334, "actor_grad_norm": 0.11972662061452866, "critic_grad_norm": 0.03400116786360741, "ratio": 0.9997416734695435, "entropy": 0.39789379239082334, "incre_win_rate": 0.813953488372093, "step": 2361}
{"time": 1767090335.4703805, "phase": "eval", "update": 2361, "total_env_steps": 7555200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.73152938741722, "step": 2361}
{"time": 1767090340.2095635, "phase": "train", "update": 2362, "total_env_steps": 7558400, "episode_reward": 0.258192777633667, "value_loss": 0.005653171148151159, "policy_loss": -0.0013999599666760787, "dist_entropy": 0.3922355592250824, "actor_grad_norm": 0.11882344633340836, "critic_grad_norm": 0.02116328850388527, "ratio": 1.0003676414489746, "entropy": 0.3922355592250824, "incre_win_rate": 0.8043478260869565, "step": 2362}
{"time": 1767090344.975623, "phase": "train", "update": 2363, "total_env_steps": 7561600, "episode_reward": 0.2606850266456604, "value_loss": 0.006944908201694489, "policy_loss": -0.001355999735373814, "dist_entropy": 0.4032809376716614, "actor_grad_norm": 0.1547507643699646, "critic_grad_norm": 0.031195005401968956, "ratio": 1.0000498294830322, "entropy": 0.4032809376716614, "incre_win_rate": 0.875, "step": 2363}
{"time": 1767090350.0812953, "phase": "train", "update": 2364, "total_env_steps": 7564800, "episode_reward": 0.2617948353290558, "value_loss": 0.005307918135076761, "policy_loss": -0.0015355377973662598, "dist_entropy": 0.3953128635883331, "actor_grad_norm": 0.1481323093175888, "critic_grad_norm": 0.036245618015527725, "ratio": 1.0004987716674805, "entropy": 0.3953128635883331, "incre_win_rate": 0.8863636363636364, "step": 2364}
{"time": 1767090354.7317896, "phase": "train", "update": 2365, "total_env_steps": 7568000, "episode_reward": 0.26486700773239136, "value_loss": 0.005133139155805111, "policy_loss": -0.0011484820881918268, "dist_entropy": 0.4061826467514038, "actor_grad_norm": 0.1239161267876625, "critic_grad_norm": 0.01500503160059452, "ratio": 0.9998475313186646, "entropy": 0.4061826467514038, "incre_win_rate": 0.8636363636363636, "step": 2365}
{"time": 1767090359.4007194, "phase": "train", "update": 2366, "total_env_steps": 7571200, "episode_reward": 0.2617073953151703, "value_loss": 0.006427709758281708, "policy_loss": -0.0015615676195089635, "dist_entropy": 0.3980745315551758, "actor_grad_norm": 0.11259382218122482, "critic_grad_norm": 0.05099201947450638, "ratio": 1.0001112222671509, "entropy": 0.3980745315551758, "incre_win_rate": 0.7954545454545454, "step": 2366}
{"time": 1767090364.109544, "phase": "train", "update": 2367, "total_env_steps": 7574400, "episode_reward": 0.26554688811302185, "value_loss": 0.006121640745550394, "policy_loss": -0.0014457788629272273, "dist_entropy": 0.3981074750423431, "actor_grad_norm": 0.13704437017440796, "critic_grad_norm": 0.03139576315879822, "ratio": 0.9997542500495911, "entropy": 0.3981074750423431, "incre_win_rate": 0.8444444444444444, "step": 2367}
{"time": 1767090368.9401085, "phase": "train", "update": 2368, "total_env_steps": 7577600, "episode_reward": 0.272070050239563, "value_loss": 0.005026338528841734, "policy_loss": -0.0013502637213363756, "dist_entropy": 0.3843955993652344, "actor_grad_norm": 0.14172682166099548, "critic_grad_norm": 0.024288535118103027, "ratio": 0.9999039769172668, "entropy": 0.3843955993652344, "incre_win_rate": 0.8863636363636364, "step": 2368}
{"time": 1767090373.7881327, "phase": "train", "update": 2369, "total_env_steps": 7580800, "episode_reward": 0.26014384627342224, "value_loss": 0.006583997793495655, "policy_loss": -0.0014728536148588488, "dist_entropy": 0.38900419473648074, "actor_grad_norm": 0.12018436193466187, "critic_grad_norm": 0.01919202320277691, "ratio": 1.0000067949295044, "entropy": 0.38900419473648074, "incre_win_rate": 0.7906976744186046, "step": 2369}
{"time": 1767090378.5224912, "phase": "train", "update": 2370, "total_env_steps": 7584000, "episode_reward": 0.23977495729923248, "value_loss": 0.007852836605161428, "policy_loss": -0.0018394399927675665, "dist_entropy": 0.3963712155818939, "actor_grad_norm": 0.10444976389408112, "critic_grad_norm": 0.014830860309302807, "ratio": 0.9997734427452087, "entropy": 0.3963712155818939, "incre_win_rate": 0.7619047619047619, "step": 2370}
{"time": 1767090383.179161, "phase": "train", "update": 2371, "total_env_steps": 7587200, "episode_reward": 0.26777368783950806, "value_loss": 0.005875397752970457, "policy_loss": -0.0016256214989688544, "dist_entropy": 0.38838023543357847, "actor_grad_norm": 0.10750728845596313, "critic_grad_norm": 0.04553791880607605, "ratio": 0.9996089935302734, "entropy": 0.38838023543357847, "incre_win_rate": 0.8636363636363636, "step": 2371}
{"time": 1767090387.77633, "phase": "train", "update": 2372, "total_env_steps": 7590400, "episode_reward": 0.25138556957244873, "value_loss": 0.006565815955400467, "policy_loss": -0.0016066625275215074, "dist_entropy": 0.3888211905956268, "actor_grad_norm": 0.1260625571012497, "critic_grad_norm": 0.032471057027578354, "ratio": 1.000157356262207, "entropy": 0.3888211905956268, "incre_win_rate": 0.8095238095238095, "step": 2372}
{"time": 1767090392.3672328, "phase": "train", "update": 2373, "total_env_steps": 7593600, "episode_reward": 0.2585766613483429, "value_loss": 0.004414105042815209, "policy_loss": -0.001210764217667304, "dist_entropy": 0.39583120942115785, "actor_grad_norm": 0.09220270067453384, "critic_grad_norm": 0.017000069841742516, "ratio": 1.0000423192977905, "entropy": 0.39583120942115785, "incre_win_rate": 0.8809523809523809, "step": 2373}
{"time": 1767090397.3947656, "phase": "train", "update": 2374, "total_env_steps": 7596800, "episode_reward": 0.2769065797328949, "value_loss": 0.006100173201411962, "policy_loss": -0.0013511887334928473, "dist_entropy": 0.3651322662830353, "actor_grad_norm": 0.14881651103496552, "critic_grad_norm": 0.017666319385170937, "ratio": 1.0000118017196655, "entropy": 0.3651322662830353, "incre_win_rate": 0.7916666666666666, "step": 2374}
{"time": 1767090402.1615424, "phase": "train", "update": 2375, "total_env_steps": 7600000, "episode_reward": 0.2534731924533844, "value_loss": 0.008341319300234318, "policy_loss": -0.0015999245927014627, "dist_entropy": 0.3823497772216797, "actor_grad_norm": 0.11531324684619904, "critic_grad_norm": 0.03671089932322502, "ratio": 0.9999377131462097, "entropy": 0.3823497772216797, "incre_win_rate": 0.7857142857142857, "step": 2375}
{"time": 1767090406.8918867, "phase": "train", "update": 2376, "total_env_steps": 7603200, "episode_reward": 0.2534851133823395, "value_loss": 0.007896254677325487, "policy_loss": -0.0014115175397069635, "dist_entropy": 0.37448365688323976, "actor_grad_norm": 0.09496057033538818, "critic_grad_norm": 0.023566819727420807, "ratio": 1.0000836849212646, "entropy": 0.37448365688323976, "incre_win_rate": 0.75, "step": 2376}
{"time": 1767090411.6809256, "phase": "train", "update": 2377, "total_env_steps": 7606400, "episode_reward": 0.24523955583572388, "value_loss": 0.008924726024270057, "policy_loss": -0.0017803032819486476, "dist_entropy": 0.38229934573173524, "actor_grad_norm": 0.10850732773542404, "critic_grad_norm": 0.035573553293943405, "ratio": 1.0000306367874146, "entropy": 0.38229934573173524, "incre_win_rate": 0.8, "step": 2377}
{"time": 1767090416.3061275, "phase": "train", "update": 2378, "total_env_steps": 7609600, "episode_reward": 0.24183259904384613, "value_loss": 0.008353113383054733, "policy_loss": -0.0016230322341456826, "dist_entropy": 0.41410485506057737, "actor_grad_norm": 0.13722103834152222, "critic_grad_norm": 0.03198285773396492, "ratio": 0.999973475933075, "entropy": 0.41410485506057737, "incre_win_rate": 0.6818181818181818, "step": 2378}
{"time": 1767090421.201244, "phase": "train", "update": 2379, "total_env_steps": 7612800, "episode_reward": 0.26993170380592346, "value_loss": 0.006786768976598978, "policy_loss": -0.0013300068275896137, "dist_entropy": 0.3771767199039459, "actor_grad_norm": 0.14275330305099487, "critic_grad_norm": 0.021489331498742104, "ratio": 1.000080943107605, "entropy": 0.3771767199039459, "incre_win_rate": 0.8809523809523809, "step": 2379}
{"time": 1767090425.9282393, "phase": "train", "update": 2380, "total_env_steps": 7616000, "episode_reward": 0.2592228949069977, "value_loss": 0.008635567687451839, "policy_loss": -0.001401472579979668, "dist_entropy": 0.3898594260215759, "actor_grad_norm": 0.16511324048042297, "critic_grad_norm": 0.023495206609368324, "ratio": 0.9999794363975525, "entropy": 0.3898594260215759, "incre_win_rate": 0.8444444444444444, "step": 2380}
{"time": 1767090430.5605645, "phase": "train", "update": 2381, "total_env_steps": 7619200, "episode_reward": 0.2616421580314636, "value_loss": 0.0070291651412844654, "policy_loss": -0.0013442954145375552, "dist_entropy": 0.37468937039375305, "actor_grad_norm": 0.10207425802946091, "critic_grad_norm": 0.05423060059547424, "ratio": 0.9998784065246582, "entropy": 0.37468937039375305, "incre_win_rate": 0.8, "step": 2381}
{"time": 1767090441.6323664, "phase": "eval", "update": 2381, "total_env_steps": 7619200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.69205298013245, "step": 2381}
{"time": 1767090446.2420707, "phase": "train", "update": 2382, "total_env_steps": 7622400, "episode_reward": 0.2582641839981079, "value_loss": 0.0066341754049062725, "policy_loss": -0.0016857533767165478, "dist_entropy": 0.3951747179031372, "actor_grad_norm": 0.1080915704369545, "critic_grad_norm": 0.03604065999388695, "ratio": 0.9999454617500305, "entropy": 0.3951747179031372, "incre_win_rate": 0.8095238095238095, "step": 2382}
{"time": 1767090450.898127, "phase": "train", "update": 2383, "total_env_steps": 7625600, "episode_reward": 0.25936827063560486, "value_loss": 0.007132658176124096, "policy_loss": -0.0013842783489458554, "dist_entropy": 0.3894678294658661, "actor_grad_norm": 0.09320425242185593, "critic_grad_norm": 0.025450099259614944, "ratio": 1.0001423358917236, "entropy": 0.3894678294658661, "incre_win_rate": 0.782608695652174, "step": 2383}
{"time": 1767090455.6521876, "phase": "train", "update": 2384, "total_env_steps": 7628800, "episode_reward": 0.24683257937431335, "value_loss": 0.009480424411594867, "policy_loss": -0.0016595935348380664, "dist_entropy": 0.39618914723396303, "actor_grad_norm": 0.09480471909046173, "critic_grad_norm": 0.06488045305013657, "ratio": 0.9999094009399414, "entropy": 0.39618914723396303, "incre_win_rate": 0.6904761904761905, "step": 2384}
{"time": 1767090460.4368575, "phase": "train", "update": 2385, "total_env_steps": 7632000, "episode_reward": 0.25689831376075745, "value_loss": 0.0056116399355232716, "policy_loss": -0.001378275084714531, "dist_entropy": 0.3869234800338745, "actor_grad_norm": 0.1560913473367691, "critic_grad_norm": 0.04893463850021362, "ratio": 0.9998248219490051, "entropy": 0.3869234800338745, "incre_win_rate": 0.9069767441860465, "step": 2385}
{"time": 1767090465.230155, "phase": "train", "update": 2386, "total_env_steps": 7635200, "episode_reward": 0.2506648302078247, "value_loss": 0.005828598979860544, "policy_loss": -0.001615374251869639, "dist_entropy": 0.38316530585289, "actor_grad_norm": 0.09468550980091095, "critic_grad_norm": 0.04142170771956444, "ratio": 1.0001671314239502, "entropy": 0.38316530585289, "incre_win_rate": 0.7619047619047619, "step": 2386}
{"time": 1767090470.19417, "phase": "train", "update": 2387, "total_env_steps": 7638400, "episode_reward": 0.24665923416614532, "value_loss": 0.007473656348884106, "policy_loss": -0.001534136775968875, "dist_entropy": 0.39159108996391295, "actor_grad_norm": 0.12112615257501602, "critic_grad_norm": 0.020146755501627922, "ratio": 0.9998885989189148, "entropy": 0.39159108996391295, "incre_win_rate": 0.7619047619047619, "step": 2387}
{"time": 1767090475.1343477, "phase": "train", "update": 2388, "total_env_steps": 7641600, "episode_reward": 0.25448885560035706, "value_loss": 0.007783373072743416, "policy_loss": -0.001641072670388155, "dist_entropy": 0.3965544104576111, "actor_grad_norm": 0.18805313110351562, "critic_grad_norm": 0.025547722354531288, "ratio": 0.9999937415122986, "entropy": 0.3965544104576111, "incre_win_rate": 0.7272727272727273, "step": 2388}
{"time": 1767090479.96132, "phase": "train", "update": 2389, "total_env_steps": 7644800, "episode_reward": 0.27220457792282104, "value_loss": 0.004903365951031446, "policy_loss": -0.001073652258992297, "dist_entropy": 0.3896430492401123, "actor_grad_norm": 0.11391714960336685, "critic_grad_norm": 0.04007809981703758, "ratio": 0.9998553395271301, "entropy": 0.3896430492401123, "incre_win_rate": 0.8863636363636364, "step": 2389}
{"time": 1767090486.0149984, "phase": "train", "update": 2390, "total_env_steps": 7648000, "episode_reward": 0.25154387950897217, "value_loss": 0.008915194869041443, "policy_loss": -0.0012178354891418052, "dist_entropy": 0.37686246633529663, "actor_grad_norm": 0.10722991079092026, "critic_grad_norm": 0.059703197330236435, "ratio": 1.0000813007354736, "entropy": 0.37686246633529663, "incre_win_rate": 0.7857142857142857, "step": 2390}
{"time": 1767090490.942232, "phase": "train", "update": 2391, "total_env_steps": 7651200, "episode_reward": 0.26572901010513306, "value_loss": 0.005849782843142748, "policy_loss": -0.001645317431216853, "dist_entropy": 0.38687528371810914, "actor_grad_norm": 0.14150585234165192, "critic_grad_norm": 0.05340417101979256, "ratio": 0.9999709129333496, "entropy": 0.38687528371810914, "incre_win_rate": 0.8478260869565217, "step": 2391}
{"time": 1767090495.7709894, "phase": "train", "update": 2392, "total_env_steps": 7654400, "episode_reward": 0.2615785598754883, "value_loss": 0.006410546787083149, "policy_loss": -0.0013528443881419606, "dist_entropy": 0.4026843190193176, "actor_grad_norm": 0.1290615200996399, "critic_grad_norm": 0.04854957386851311, "ratio": 0.9998693466186523, "entropy": 0.4026843190193176, "incre_win_rate": 0.7111111111111111, "step": 2392}
{"time": 1767090500.8762636, "phase": "train", "update": 2393, "total_env_steps": 7657600, "episode_reward": 0.2514253854751587, "value_loss": 0.006209309305995702, "policy_loss": -0.0011740699927732302, "dist_entropy": 0.400691431760788, "actor_grad_norm": 0.1179923340678215, "critic_grad_norm": 0.038573287427425385, "ratio": 0.9998835921287537, "entropy": 0.400691431760788, "incre_win_rate": 0.85, "step": 2393}
{"time": 1767090506.428864, "phase": "train", "update": 2394, "total_env_steps": 7660800, "episode_reward": 0.2523261606693268, "value_loss": 0.009340190142393113, "policy_loss": -0.0015931954753833466, "dist_entropy": 0.3935672163963318, "actor_grad_norm": 0.13308770954608917, "critic_grad_norm": 0.06268852204084396, "ratio": 0.9999643564224243, "entropy": 0.3935672163963318, "incre_win_rate": 0.7804878048780488, "step": 2394}
{"time": 1767090511.3474739, "phase": "train", "update": 2395, "total_env_steps": 7664000, "episode_reward": 0.2611232399940491, "value_loss": 0.009146745316684246, "policy_loss": -0.0012141805471756583, "dist_entropy": 0.40191721320152285, "actor_grad_norm": 0.1445244699716568, "critic_grad_norm": 0.049599599093198776, "ratio": 1.0000909566879272, "entropy": 0.40191721320152285, "incre_win_rate": 0.6938775510204082, "step": 2395}
{"time": 1767090516.294591, "phase": "train", "update": 2396, "total_env_steps": 7667200, "episode_reward": 0.2616763412952423, "value_loss": 0.008547461591660976, "policy_loss": -0.001638341016324052, "dist_entropy": 0.41966022849082946, "actor_grad_norm": 0.13794474303722382, "critic_grad_norm": 0.036403533071279526, "ratio": 0.9999256134033203, "entropy": 0.41966022849082946, "incre_win_rate": 0.8, "step": 2396}
{"time": 1767090521.4736578, "phase": "train", "update": 2397, "total_env_steps": 7670400, "episode_reward": 0.25892746448516846, "value_loss": 0.00896738599985838, "policy_loss": -0.0011279434413069111, "dist_entropy": 0.4077791631221771, "actor_grad_norm": 0.1312965452671051, "critic_grad_norm": 0.021835146471858025, "ratio": 0.9998874664306641, "entropy": 0.4077791631221771, "incre_win_rate": 0.7380952380952381, "step": 2397}
{"time": 1767090526.3230972, "phase": "train", "update": 2398, "total_env_steps": 7673600, "episode_reward": 0.2686196267604828, "value_loss": 0.006348211690783501, "policy_loss": -0.00165004464408689, "dist_entropy": 0.39451982975006106, "actor_grad_norm": 0.10508518666028976, "critic_grad_norm": 0.027151355519890785, "ratio": 0.9998013377189636, "entropy": 0.39451982975006106, "incre_win_rate": 0.8478260869565217, "step": 2398}
{"time": 1767090531.4564276, "phase": "train", "update": 2399, "total_env_steps": 7676800, "episode_reward": 0.2567099630832672, "value_loss": 0.008569992706179618, "policy_loss": -0.001792922275680553, "dist_entropy": 0.4195690035820007, "actor_grad_norm": 0.13477250933647156, "critic_grad_norm": 0.020912086591124535, "ratio": 1.0001620054244995, "entropy": 0.4195690035820007, "incre_win_rate": 0.8095238095238095, "step": 2399}
{"time": 1767090536.0686665, "phase": "train", "update": 2400, "total_env_steps": 7680000, "episode_reward": 0.24725009500980377, "value_loss": 0.006780471187084913, "policy_loss": -0.0016065456715864458, "dist_entropy": 0.39975678324699404, "actor_grad_norm": 0.11503443866968155, "critic_grad_norm": 0.04146532341837883, "ratio": 0.9999423027038574, "entropy": 0.39975678324699404, "incre_win_rate": 0.6521739130434783, "step": 2400}
{"time": 1767090540.7512145, "phase": "train", "update": 2401, "total_env_steps": 7683200, "episode_reward": 0.2526324689388275, "value_loss": 0.006927051395177841, "policy_loss": -0.001471703234284405, "dist_entropy": 0.3954337537288666, "actor_grad_norm": 0.10247751325368881, "critic_grad_norm": 0.03822294995188713, "ratio": 0.9999494552612305, "entropy": 0.3954337537288666, "incre_win_rate": 0.8, "step": 2401}
{"time": 1767090551.7711658, "phase": "eval", "update": 2401, "total_env_steps": 7683200, "eval_win_rate": 0.875, "eval_episode_reward": 19.36144453642384, "step": 2401}
{"time": 1767090556.5223923, "phase": "train", "update": 2402, "total_env_steps": 7686400, "episode_reward": 0.2551262676715851, "value_loss": 0.008688845485448838, "policy_loss": -0.0016626575977475965, "dist_entropy": 0.4044294536113739, "actor_grad_norm": 0.1217832937836647, "critic_grad_norm": 0.04313681274652481, "ratio": 0.999612033367157, "entropy": 0.4044294536113739, "incre_win_rate": 0.7727272727272727, "step": 2402}
{"time": 1767090561.1720943, "phase": "train", "update": 2403, "total_env_steps": 7689600, "episode_reward": 0.26697638630867004, "value_loss": 0.008746425807476043, "policy_loss": -0.0012989375888253108, "dist_entropy": 0.4124628186225891, "actor_grad_norm": 0.12341165542602539, "critic_grad_norm": 0.03734447807073593, "ratio": 0.999921977519989, "entropy": 0.4124628186225891, "incre_win_rate": 0.8, "step": 2403}
{"time": 1767090565.983961, "phase": "train", "update": 2404, "total_env_steps": 7692800, "episode_reward": 0.2525124251842499, "value_loss": 0.010066833160817624, "policy_loss": -0.001501962672392665, "dist_entropy": 0.39675858020782473, "actor_grad_norm": 0.12292615324258804, "critic_grad_norm": 0.053249526768922806, "ratio": 1.0000337362289429, "entropy": 0.39675858020782473, "incre_win_rate": 0.7272727272727273, "step": 2404}
{"time": 1767090570.6471276, "phase": "train", "update": 2405, "total_env_steps": 7696000, "episode_reward": 0.2567673921585083, "value_loss": 0.009459530003368855, "policy_loss": -0.001172341442453728, "dist_entropy": 0.41034701466560364, "actor_grad_norm": 0.15785212814807892, "critic_grad_norm": 0.04325944185256958, "ratio": 1.0000017881393433, "entropy": 0.41034701466560364, "incre_win_rate": 0.7727272727272727, "step": 2405}
{"time": 1767090575.3275664, "phase": "train", "update": 2406, "total_env_steps": 7699200, "episode_reward": 0.24283424019813538, "value_loss": 0.008418782614171505, "policy_loss": -0.0014737039520824168, "dist_entropy": 0.4051308572292328, "actor_grad_norm": 0.1171984001994133, "critic_grad_norm": 0.024999065324664116, "ratio": 0.9997488856315613, "entropy": 0.4051308572292328, "incre_win_rate": 0.8095238095238095, "step": 2406}
{"time": 1767090580.4664724, "phase": "train", "update": 2407, "total_env_steps": 7702400, "episode_reward": 0.24504554271697998, "value_loss": 0.01105527300387621, "policy_loss": -0.0017844928415456708, "dist_entropy": 0.4040487349033356, "actor_grad_norm": 0.16281959414482117, "critic_grad_norm": 0.027283085510134697, "ratio": 0.999852180480957, "entropy": 0.4040487349033356, "incre_win_rate": 0.5813953488372093, "step": 2407}
{"time": 1767090585.4994946, "phase": "train", "update": 2408, "total_env_steps": 7705600, "episode_reward": 0.2641540765762329, "value_loss": 0.007647622190415859, "policy_loss": -0.001123776088869022, "dist_entropy": 0.3943815290927887, "actor_grad_norm": 0.1310768574476242, "critic_grad_norm": 0.018520351499319077, "ratio": 1.0002987384796143, "entropy": 0.3943815290927887, "incre_win_rate": 0.7777777777777778, "step": 2408}
{"time": 1767090590.3804827, "phase": "train", "update": 2409, "total_env_steps": 7708800, "episode_reward": 0.25528818368911743, "value_loss": 0.009811684675514697, "policy_loss": -0.001809066718870156, "dist_entropy": 0.4073939859867096, "actor_grad_norm": 0.1597958356142044, "critic_grad_norm": 0.03196392208337784, "ratio": 0.9997007250785828, "entropy": 0.4073939859867096, "incre_win_rate": 0.75, "step": 2409}
{"time": 1767090595.8746269, "phase": "train", "update": 2410, "total_env_steps": 7712000, "episode_reward": 0.24740171432495117, "value_loss": 0.009486011043190957, "policy_loss": -0.001353765540278573, "dist_entropy": 0.416484659910202, "actor_grad_norm": 0.1377176195383072, "critic_grad_norm": 0.029091034084558487, "ratio": 0.9996695518493652, "entropy": 0.416484659910202, "incre_win_rate": 0.6904761904761905, "step": 2410}
{"time": 1767090600.838264, "phase": "train", "update": 2411, "total_env_steps": 7715200, "episode_reward": 0.26910388469696045, "value_loss": 0.005767702683806419, "policy_loss": -0.0013514035040454787, "dist_entropy": 0.4067229270935059, "actor_grad_norm": 0.12624454498291016, "critic_grad_norm": 0.06268548220396042, "ratio": 1.0001288652420044, "entropy": 0.4067229270935059, "incre_win_rate": 0.8666666666666667, "step": 2411}
{"time": 1767090606.7375484, "phase": "train", "update": 2412, "total_env_steps": 7718400, "episode_reward": 0.25357306003570557, "value_loss": 0.007929773349314929, "policy_loss": -0.0014341534327286353, "dist_entropy": 0.4192362904548645, "actor_grad_norm": 0.14425157010555267, "critic_grad_norm": 0.06414365023374557, "ratio": 1.0000818967819214, "entropy": 0.4192362904548645, "incre_win_rate": 0.7619047619047619, "step": 2412}
{"time": 1767090612.168285, "phase": "train", "update": 2413, "total_env_steps": 7721600, "episode_reward": 0.24984531104564667, "value_loss": 0.0072425583377480505, "policy_loss": -0.0012061719402511883, "dist_entropy": 0.4209249973297119, "actor_grad_norm": 0.1637021154165268, "critic_grad_norm": 0.050974290817976, "ratio": 0.9999315142631531, "entropy": 0.4209249973297119, "incre_win_rate": 0.7954545454545454, "step": 2413}
{"time": 1767090617.015207, "phase": "train", "update": 2414, "total_env_steps": 7724800, "episode_reward": 0.2584783434867859, "value_loss": 0.005498246755450964, "policy_loss": -0.0013637756082189867, "dist_entropy": 0.42737152576446535, "actor_grad_norm": 0.10566931217908859, "critic_grad_norm": 0.04683700203895569, "ratio": 0.9999542236328125, "entropy": 0.42737152576446535, "incre_win_rate": 0.8095238095238095, "step": 2414}
{"time": 1767090621.7191677, "phase": "train", "update": 2415, "total_env_steps": 7728000, "episode_reward": 0.2413710653781891, "value_loss": 0.008405175618827343, "policy_loss": -0.0016364354204256415, "dist_entropy": 0.42580134272575376, "actor_grad_norm": 0.1439291536808014, "critic_grad_norm": 0.0498470738530159, "ratio": 0.9999896287918091, "entropy": 0.42580134272575376, "incre_win_rate": 0.7142857142857143, "step": 2415}
{"time": 1767090626.3743696, "phase": "train", "update": 2416, "total_env_steps": 7731200, "episode_reward": 0.2466861605644226, "value_loss": 0.008135579805821181, "policy_loss": -0.0018052394495071233, "dist_entropy": 0.4114193916320801, "actor_grad_norm": 0.15236465632915497, "critic_grad_norm": 0.07039224356412888, "ratio": 0.9996442794799805, "entropy": 0.4114193916320801, "incre_win_rate": 0.6744186046511628, "step": 2416}
{"time": 1767090631.0688448, "phase": "train", "update": 2417, "total_env_steps": 7734400, "episode_reward": 0.24606166779994965, "value_loss": 0.013752298802137375, "policy_loss": -0.0019146121889804136, "dist_entropy": 0.4453273475170135, "actor_grad_norm": 0.1994236558675766, "critic_grad_norm": 0.08331865072250366, "ratio": 0.999359130859375, "entropy": 0.4453273475170135, "incre_win_rate": 0.6976744186046512, "step": 2417}
{"time": 1767090635.9590342, "phase": "train", "update": 2418, "total_env_steps": 7737600, "episode_reward": 0.24601148068904877, "value_loss": 0.010874565690755844, "policy_loss": -0.0014642504727000016, "dist_entropy": 0.42010408639907837, "actor_grad_norm": 0.1687536984682083, "critic_grad_norm": 0.054050009697675705, "ratio": 0.999832808971405, "entropy": 0.42010408639907837, "incre_win_rate": 0.6739130434782609, "step": 2418}
{"time": 1767090640.6568553, "phase": "train", "update": 2419, "total_env_steps": 7740800, "episode_reward": 0.2565087080001831, "value_loss": 0.0075180668383836744, "policy_loss": -0.0015324016929966432, "dist_entropy": 0.4188656687736511, "actor_grad_norm": 0.14956963062286377, "critic_grad_norm": 0.10649970918893814, "ratio": 0.9998130798339844, "entropy": 0.4188656687736511, "incre_win_rate": 0.8, "step": 2419}
{"time": 1767090645.2908874, "phase": "train", "update": 2420, "total_env_steps": 7744000, "episode_reward": 0.23829521238803864, "value_loss": 0.0091681357473135, "policy_loss": -0.0015318193328326402, "dist_entropy": 0.40652753710746764, "actor_grad_norm": 0.1014418974518776, "critic_grad_norm": 0.05558217316865921, "ratio": 1.000030279159546, "entropy": 0.40652753710746764, "incre_win_rate": 0.7209302325581395, "step": 2420}
{"time": 1767090649.9544754, "phase": "train", "update": 2421, "total_env_steps": 7747200, "episode_reward": 0.23675599694252014, "value_loss": 0.009270995296537876, "policy_loss": -0.001953400976153219, "dist_entropy": 0.4227141380310059, "actor_grad_norm": 0.09951355308294296, "critic_grad_norm": 0.0484379418194294, "ratio": 0.9999219179153442, "entropy": 0.4227141380310059, "incre_win_rate": 0.6666666666666666, "step": 2421}
{"time": 1767090661.0111327, "phase": "eval", "update": 2421, "total_env_steps": 7747200, "eval_win_rate": 0.84375, "eval_episode_reward": 19.1497309602649, "step": 2421}
{"time": 1767090665.6017022, "phase": "train", "update": 2422, "total_env_steps": 7750400, "episode_reward": 0.2415035218000412, "value_loss": 0.00883762091398239, "policy_loss": -0.0015337639105162282, "dist_entropy": 0.4165660858154297, "actor_grad_norm": 0.12065392732620239, "critic_grad_norm": 0.020385917276144028, "ratio": 0.9998418688774109, "entropy": 0.4165660858154297, "incre_win_rate": 0.6829268292682927, "step": 2422}
{"time": 1767090670.323813, "phase": "train", "update": 2423, "total_env_steps": 7753600, "episode_reward": 0.23510658740997314, "value_loss": 0.00813440103083849, "policy_loss": -0.001927148263392553, "dist_entropy": 0.4267796158790588, "actor_grad_norm": 0.15679609775543213, "critic_grad_norm": 0.025029515847563744, "ratio": 0.9999975562095642, "entropy": 0.4267796158790588, "incre_win_rate": 0.675, "step": 2423}
{"time": 1767090675.0928164, "phase": "train", "update": 2424, "total_env_steps": 7756800, "episode_reward": 0.26290303468704224, "value_loss": 0.007712631206959486, "policy_loss": -0.0017865521379789584, "dist_entropy": 0.4275504767894745, "actor_grad_norm": 0.11130919307470322, "critic_grad_norm": 0.023816300556063652, "ratio": 0.9996248483657837, "entropy": 0.4275504767894745, "incre_win_rate": 0.8444444444444444, "step": 2424}
{"time": 1767090680.2459247, "phase": "train", "update": 2425, "total_env_steps": 7760000, "episode_reward": 0.2590392231941223, "value_loss": 0.006814100034534931, "policy_loss": -0.0018151941914096082, "dist_entropy": 0.43348931670188906, "actor_grad_norm": 0.16594897210597992, "critic_grad_norm": 0.04924827814102173, "ratio": 0.9999871253967285, "entropy": 0.43348931670188906, "incre_win_rate": 0.8181818181818182, "step": 2425}
{"time": 1767090685.1095011, "phase": "train", "update": 2426, "total_env_steps": 7763200, "episode_reward": 0.260130375623703, "value_loss": 0.0065388791263103485, "policy_loss": -0.0016558739877307715, "dist_entropy": 0.4360651791095734, "actor_grad_norm": 0.1677972376346588, "critic_grad_norm": 0.035553738474845886, "ratio": 0.9996647238731384, "entropy": 0.4360651791095734, "incre_win_rate": 0.813953488372093, "step": 2426}
{"time": 1767090689.942268, "phase": "train", "update": 2427, "total_env_steps": 7766400, "episode_reward": 0.25733134150505066, "value_loss": 0.01016544010490179, "policy_loss": -0.0018418342821831858, "dist_entropy": 0.429382199048996, "actor_grad_norm": 0.12091530859470367, "critic_grad_norm": 0.039016980677843094, "ratio": 0.9998249411582947, "entropy": 0.429382199048996, "incre_win_rate": 0.8809523809523809, "step": 2427}
{"time": 1767090694.91376, "phase": "train", "update": 2428, "total_env_steps": 7769600, "episode_reward": 0.23841319978237152, "value_loss": 0.009171324037015437, "policy_loss": -0.001842566229428222, "dist_entropy": 0.43451365232467654, "actor_grad_norm": 0.12392556667327881, "critic_grad_norm": 0.07772578299045563, "ratio": 1.0001033544540405, "entropy": 0.43451365232467654, "incre_win_rate": 0.6511627906976745, "step": 2428}
{"time": 1767090699.8816447, "phase": "train", "update": 2429, "total_env_steps": 7772800, "episode_reward": 0.25497931241989136, "value_loss": 0.00829729698598385, "policy_loss": -0.0017379276115997212, "dist_entropy": 0.40439985394477845, "actor_grad_norm": 0.11503928899765015, "critic_grad_norm": 0.06411806493997574, "ratio": 0.9999473690986633, "entropy": 0.40439985394477845, "incre_win_rate": 0.7777777777777778, "step": 2429}
{"time": 1767090704.6650586, "phase": "train", "update": 2430, "total_env_steps": 7776000, "episode_reward": 0.25843751430511475, "value_loss": 0.008373386971652508, "policy_loss": -0.0017780177496115712, "dist_entropy": 0.42232553362846376, "actor_grad_norm": 0.18315757811069489, "critic_grad_norm": 0.04491191729903221, "ratio": 0.9997385144233704, "entropy": 0.42232553362846376, "incre_win_rate": 0.8780487804878049, "step": 2430}
{"time": 1767090709.493901, "phase": "train", "update": 2431, "total_env_steps": 7779200, "episode_reward": 0.25057533383369446, "value_loss": 0.009201542846858502, "policy_loss": -0.0014486888006716824, "dist_entropy": 0.41017434000968933, "actor_grad_norm": 0.13748496770858765, "critic_grad_norm": 0.03276822715997696, "ratio": 0.999830424785614, "entropy": 0.41017434000968933, "incre_win_rate": 0.7777777777777778, "step": 2431}
{"time": 1767090714.3405201, "phase": "train", "update": 2432, "total_env_steps": 7782400, "episode_reward": 0.26279231905937195, "value_loss": 0.007408125698566437, "policy_loss": -0.0013925672019340142, "dist_entropy": 0.41770467162132263, "actor_grad_norm": 0.11514709144830704, "critic_grad_norm": 0.05153049901127815, "ratio": 1.0000656843185425, "entropy": 0.41770467162132263, "incre_win_rate": 0.813953488372093, "step": 2432}
{"time": 1767090719.0917435, "phase": "train", "update": 2433, "total_env_steps": 7785600, "episode_reward": 0.25865843892097473, "value_loss": 0.0071035707369446754, "policy_loss": -0.001667618906066437, "dist_entropy": 0.40042335987091066, "actor_grad_norm": 0.13169564306735992, "critic_grad_norm": 0.03430602699518204, "ratio": 1.000101923942566, "entropy": 0.40042335987091066, "incre_win_rate": 0.8181818181818182, "step": 2433}
{"time": 1767090723.6867392, "phase": "train", "update": 2434, "total_env_steps": 7788800, "episode_reward": 0.24985253810882568, "value_loss": 0.01020856611430645, "policy_loss": -0.0017860968774890296, "dist_entropy": 0.42336365580558777, "actor_grad_norm": 0.19376932084560394, "critic_grad_norm": 0.055848896503448486, "ratio": 0.999563992023468, "entropy": 0.42336365580558777, "incre_win_rate": 0.7857142857142857, "step": 2434}
{"time": 1767090728.446375, "phase": "train", "update": 2435, "total_env_steps": 7792000, "episode_reward": 0.24441485106945038, "value_loss": 0.007248940318822861, "policy_loss": -0.0017313138010734974, "dist_entropy": 0.41422958970069884, "actor_grad_norm": 0.1090298444032669, "critic_grad_norm": 0.04678058624267578, "ratio": 0.9996625781059265, "entropy": 0.41422958970069884, "incre_win_rate": 0.7674418604651163, "step": 2435}
{"time": 1767090733.1366985, "phase": "train", "update": 2436, "total_env_steps": 7795200, "episode_reward": 0.2618600130081177, "value_loss": 0.006477060448378325, "policy_loss": -0.0017899568486399176, "dist_entropy": 0.4174251139163971, "actor_grad_norm": 0.13143347203731537, "critic_grad_norm": 0.044274866580963135, "ratio": 0.9994196891784668, "entropy": 0.4174251139163971, "incre_win_rate": 0.8837209302325582, "step": 2436}
{"time": 1767090738.1292682, "phase": "train", "update": 2437, "total_env_steps": 7798400, "episode_reward": 0.24756725132465363, "value_loss": 0.008602096140384674, "policy_loss": -0.001446888527014778, "dist_entropy": 0.42006872296333314, "actor_grad_norm": 0.10055594891309738, "critic_grad_norm": 0.034183938056230545, "ratio": 1.000030517578125, "entropy": 0.42006872296333314, "incre_win_rate": 0.75, "step": 2437}
{"time": 1767090743.1844974, "phase": "train", "update": 2438, "total_env_steps": 7801600, "episode_reward": 0.24251241981983185, "value_loss": 0.009351649694144726, "policy_loss": -0.0015036855757784907, "dist_entropy": 0.4129518806934357, "actor_grad_norm": 0.13349638879299164, "critic_grad_norm": 0.02533397637307644, "ratio": 0.9999774098396301, "entropy": 0.4129518806934357, "incre_win_rate": 0.7441860465116279, "step": 2438}
{"time": 1767090748.0240088, "phase": "train", "update": 2439, "total_env_steps": 7804800, "episode_reward": 0.23825901746749878, "value_loss": 0.0063372313976287845, "policy_loss": -0.0017457625218298745, "dist_entropy": 0.4031008303165436, "actor_grad_norm": 0.1552334874868393, "critic_grad_norm": 0.018760565668344498, "ratio": 1.0001224279403687, "entropy": 0.4031008303165436, "incre_win_rate": 0.7560975609756098, "step": 2439}
{"time": 1767090752.6541567, "phase": "train", "update": 2440, "total_env_steps": 7808000, "episode_reward": 0.24400661885738373, "value_loss": 0.010630486905574799, "policy_loss": -0.0014802101598633045, "dist_entropy": 0.4290061116218567, "actor_grad_norm": 0.1644182652235031, "critic_grad_norm": 0.024423426017165184, "ratio": 0.9994472861289978, "entropy": 0.4290061116218567, "incre_win_rate": 0.8048780487804879, "step": 2440}
{"time": 1767090757.715332, "phase": "train", "update": 2441, "total_env_steps": 7811200, "episode_reward": 0.24062345921993256, "value_loss": 0.007521245814859867, "policy_loss": -0.0016574117563145307, "dist_entropy": 0.42655923366546633, "actor_grad_norm": 0.12289512157440186, "critic_grad_norm": 0.037479471415281296, "ratio": 1.0002588033676147, "entropy": 0.42655923366546633, "incre_win_rate": 0.8292682926829268, "step": 2441}
{"time": 1767090770.3339314, "phase": "eval", "update": 2441, "total_env_steps": 7811200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.89797185430463, "step": 2441}
{"time": 1767090775.4813066, "phase": "train", "update": 2442, "total_env_steps": 7814400, "episode_reward": 0.26332470774650574, "value_loss": 0.005733429361134768, "policy_loss": -0.0016347592218298956, "dist_entropy": 0.4251831233501434, "actor_grad_norm": 0.14082439243793488, "critic_grad_norm": 0.03891604766249657, "ratio": 0.9994488954544067, "entropy": 0.4251831233501434, "incre_win_rate": 0.9302325581395349, "step": 2442}
{"time": 1767090780.7760293, "phase": "train", "update": 2443, "total_env_steps": 7817600, "episode_reward": 0.25242289900779724, "value_loss": 0.006401330046355724, "policy_loss": -0.0014853919330704457, "dist_entropy": 0.41066771149635317, "actor_grad_norm": 0.12744104862213135, "critic_grad_norm": 0.028118669986724854, "ratio": 1.0001837015151978, "entropy": 0.41066771149635317, "incre_win_rate": 0.8536585365853658, "step": 2443}
{"time": 1767090785.5793922, "phase": "train", "update": 2444, "total_env_steps": 7820800, "episode_reward": 0.2465081810951233, "value_loss": 0.007139070425182581, "policy_loss": -0.0016564114505044358, "dist_entropy": 0.40870052576065063, "actor_grad_norm": 0.13832350075244904, "critic_grad_norm": 0.030169367790222168, "ratio": 1.000165581703186, "entropy": 0.40870052576065063, "incre_win_rate": 0.7954545454545454, "step": 2444}
{"time": 1767090790.3386073, "phase": "train", "update": 2445, "total_env_steps": 7824000, "episode_reward": 0.2662893235683441, "value_loss": 0.005151638947427273, "policy_loss": -0.0013569165996160759, "dist_entropy": 0.3966977119445801, "actor_grad_norm": 0.13917005062103271, "critic_grad_norm": 0.04154416546225548, "ratio": 0.9999567866325378, "entropy": 0.3966977119445801, "incre_win_rate": 0.9069767441860465, "step": 2445}
{"time": 1767090795.3589845, "phase": "train", "update": 2446, "total_env_steps": 7827200, "episode_reward": 0.25122517347335815, "value_loss": 0.008287978358566761, "policy_loss": -0.0017577644632467582, "dist_entropy": 0.41801226139068604, "actor_grad_norm": 0.10973035544157028, "critic_grad_norm": 0.03946366533637047, "ratio": 0.9998367428779602, "entropy": 0.41801226139068604, "incre_win_rate": 0.8048780487804879, "step": 2446}
{"time": 1767090800.1099844, "phase": "train", "update": 2447, "total_env_steps": 7830400, "episode_reward": 0.2516975700855255, "value_loss": 0.007795092556625605, "policy_loss": -0.001933032622355313, "dist_entropy": 0.4192694962024689, "actor_grad_norm": 0.12391052395105362, "critic_grad_norm": 0.07705721259117126, "ratio": 0.9994927644729614, "entropy": 0.4192694962024689, "incre_win_rate": 0.7777777777777778, "step": 2447}
{"time": 1767090804.8083177, "phase": "train", "update": 2448, "total_env_steps": 7833600, "episode_reward": 0.2531948387622833, "value_loss": 0.007055577822029591, "policy_loss": -0.001482805335366777, "dist_entropy": 0.39919854402542115, "actor_grad_norm": 0.11718221008777618, "critic_grad_norm": 0.04897693172097206, "ratio": 1.0000218152999878, "entropy": 0.39919854402542115, "incre_win_rate": 0.8048780487804879, "step": 2448}
{"time": 1767090809.908351, "phase": "train", "update": 2449, "total_env_steps": 7836800, "episode_reward": 0.24926221370697021, "value_loss": 0.006871373392641544, "policy_loss": -0.0016189354934475376, "dist_entropy": 0.4078402280807495, "actor_grad_norm": 0.11805307120084763, "critic_grad_norm": 0.03206374868750572, "ratio": 1.0002943277359009, "entropy": 0.4078402280807495, "incre_win_rate": 0.8095238095238095, "step": 2449}
{"time": 1767090814.6208425, "phase": "train", "update": 2450, "total_env_steps": 7840000, "episode_reward": 0.25077763199806213, "value_loss": 0.006311594229191542, "policy_loss": -0.0013851255415318064, "dist_entropy": 0.4177540004253387, "actor_grad_norm": 0.18001776933670044, "critic_grad_norm": 0.03857455775141716, "ratio": 1.0000429153442383, "entropy": 0.4177540004253387, "incre_win_rate": 0.8292682926829268, "step": 2450}
{"time": 1767090819.497945, "phase": "train", "update": 2451, "total_env_steps": 7843200, "episode_reward": 0.2597351372241974, "value_loss": 0.005056249164044857, "policy_loss": -0.0013428015560450035, "dist_entropy": 0.40823649764060976, "actor_grad_norm": 0.1177687793970108, "critic_grad_norm": 0.03779418393969536, "ratio": 1.0002686977386475, "entropy": 0.40823649764060976, "incre_win_rate": 0.8444444444444444, "step": 2451}
{"time": 1767090854.5089426, "phase": "train", "update": 2452, "total_env_steps": 7846400, "episode_reward": 0.24262210726737976, "value_loss": 0.0405845083296299, "policy_loss": -0.0017268705305752974, "dist_entropy": 0.4168495416641235, "actor_grad_norm": 0.09798834472894669, "critic_grad_norm": 0.15141867101192474, "ratio": 1.0001094341278076, "entropy": 0.4168495416641235, "incre_win_rate": 0.8181818181818182, "step": 2452}
{"time": 1767090859.5421822, "phase": "train", "update": 2453, "total_env_steps": 7849600, "episode_reward": 0.2452923208475113, "value_loss": 0.007501289714127779, "policy_loss": -0.0018675057815492834, "dist_entropy": 0.43227759599685667, "actor_grad_norm": 0.12713193893432617, "critic_grad_norm": 0.11746986955404282, "ratio": 1.0001085996627808, "entropy": 0.43227759599685667, "incre_win_rate": 0.7954545454545454, "step": 2453}
{"time": 1767090864.8041973, "phase": "train", "update": 2454, "total_env_steps": 7852800, "episode_reward": 0.247134730219841, "value_loss": 0.006447938550263643, "policy_loss": -0.0013248600918933206, "dist_entropy": 0.434407377243042, "actor_grad_norm": 0.15325260162353516, "critic_grad_norm": 0.09840855747461319, "ratio": 0.9996285438537598, "entropy": 0.434407377243042, "incre_win_rate": 0.8048780487804879, "step": 2454}
{"time": 1767090870.0653498, "phase": "train", "update": 2455, "total_env_steps": 7856000, "episode_reward": 0.25591424107551575, "value_loss": 0.006841403618454933, "policy_loss": -0.0014065381672544674, "dist_entropy": 0.42155114412307737, "actor_grad_norm": 0.13574126362800598, "critic_grad_norm": 0.043996669352054596, "ratio": 0.9999297261238098, "entropy": 0.42155114412307737, "incre_win_rate": 0.8809523809523809, "step": 2455}
{"time": 1767090875.3237617, "phase": "train", "update": 2456, "total_env_steps": 7859200, "episode_reward": 0.2470664530992508, "value_loss": 0.01102295909076929, "policy_loss": -0.001511419641019529, "dist_entropy": 0.4219667613506317, "actor_grad_norm": 0.1362166851758957, "critic_grad_norm": 0.042653780430555344, "ratio": 0.9999502301216125, "entropy": 0.4219667613506317, "incre_win_rate": 0.7209302325581395, "step": 2456}
{"time": 1767090880.677543, "phase": "train", "update": 2457, "total_env_steps": 7862400, "episode_reward": 0.25028663873672485, "value_loss": 0.008574690297245979, "policy_loss": -0.0012982245180054974, "dist_entropy": 0.4175338089466095, "actor_grad_norm": 0.12720191478729248, "critic_grad_norm": 0.033161718398332596, "ratio": 0.9995479583740234, "entropy": 0.4175338089466095, "incre_win_rate": 0.7857142857142857, "step": 2457}
{"time": 1767090885.9555087, "phase": "train", "update": 2458, "total_env_steps": 7865600, "episode_reward": 0.25829780101776123, "value_loss": 0.005474373511970043, "policy_loss": -0.001567610239380901, "dist_entropy": 0.43134477734565735, "actor_grad_norm": 0.18814943730831146, "critic_grad_norm": 0.026462862268090248, "ratio": 0.9995859265327454, "entropy": 0.43134477734565735, "incre_win_rate": 0.8372093023255814, "step": 2458}
{"time": 1767090891.239984, "phase": "train", "update": 2459, "total_env_steps": 7868800, "episode_reward": 0.24823054671287537, "value_loss": 0.007268717046827078, "policy_loss": -0.0014351823712694055, "dist_entropy": 0.44523462653160095, "actor_grad_norm": 0.1291118562221527, "critic_grad_norm": 0.022916020825505257, "ratio": 1.0000461339950562, "entropy": 0.44523462653160095, "incre_win_rate": 0.7857142857142857, "step": 2459}
{"time": 1767090896.5343227, "phase": "train", "update": 2460, "total_env_steps": 7872000, "episode_reward": 0.24882295727729797, "value_loss": 0.007174752652645111, "policy_loss": -0.0018761289462446485, "dist_entropy": 0.4406886398792267, "actor_grad_norm": 0.13636739552021027, "critic_grad_norm": 0.022907637059688568, "ratio": 0.9999145865440369, "entropy": 0.4406886398792267, "incre_win_rate": 0.8292682926829268, "step": 2460}
{"time": 1767090901.1754959, "phase": "train", "update": 2461, "total_env_steps": 7875200, "episode_reward": 0.2269919365644455, "value_loss": 0.009328309819102288, "policy_loss": -0.0013685870136601608, "dist_entropy": 0.47274239659309386, "actor_grad_norm": 0.15844343602657318, "critic_grad_norm": 0.03281015902757645, "ratio": 1.0004472732543945, "entropy": 0.47274239659309386, "incre_win_rate": 0.7435897435897436, "step": 2461}
{"time": 1767090912.028056, "phase": "eval", "update": 2461, "total_env_steps": 7875200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.699503311258276, "step": 2461}
{"time": 1767090916.5661888, "phase": "train", "update": 2462, "total_env_steps": 7878400, "episode_reward": 0.24049152433872223, "value_loss": 0.007840155623853207, "policy_loss": -0.0019277250046940253, "dist_entropy": 0.4501386761665344, "actor_grad_norm": 0.12802369892597198, "critic_grad_norm": 0.02577776275575161, "ratio": 1.0000704526901245, "entropy": 0.4501386761665344, "incre_win_rate": 0.7380952380952381, "step": 2462}
{"time": 1767090921.3839564, "phase": "train", "update": 2463, "total_env_steps": 7881600, "episode_reward": 0.23819588124752045, "value_loss": 0.007562016695737838, "policy_loss": -0.0018299900366179234, "dist_entropy": 0.44159197211265566, "actor_grad_norm": 0.12240155041217804, "critic_grad_norm": 0.022517004981637, "ratio": 0.9998366236686707, "entropy": 0.44159197211265566, "incre_win_rate": 0.725, "step": 2463}
{"time": 1767090926.2826774, "phase": "train", "update": 2464, "total_env_steps": 7884800, "episode_reward": 0.24530990421772003, "value_loss": 0.008052241988480091, "policy_loss": -0.0015656918926183038, "dist_entropy": 0.43721613883972166, "actor_grad_norm": 0.12239322811365128, "critic_grad_norm": 0.02739700675010681, "ratio": 0.9996896982192993, "entropy": 0.43721613883972166, "incre_win_rate": 0.7142857142857143, "step": 2464}
{"time": 1767090931.1596828, "phase": "train", "update": 2465, "total_env_steps": 7888000, "episode_reward": 0.25945571064949036, "value_loss": 0.006936066690832377, "policy_loss": -0.0015995621558346329, "dist_entropy": 0.4279178142547607, "actor_grad_norm": 0.12999527156352997, "critic_grad_norm": 0.045985933393239975, "ratio": 0.9997798800468445, "entropy": 0.4279178142547607, "incre_win_rate": 0.8222222222222222, "step": 2465}
{"time": 1767090936.2255936, "phase": "train", "update": 2466, "total_env_steps": 7891200, "episode_reward": 0.25488877296447754, "value_loss": 0.006332006491720677, "policy_loss": -0.0015203557798265876, "dist_entropy": 0.41986043453216554, "actor_grad_norm": 0.10923979431390762, "critic_grad_norm": 0.02869953028857708, "ratio": 1.0001167058944702, "entropy": 0.41986043453216554, "incre_win_rate": 0.8780487804878049, "step": 2466}
{"time": 1767090941.075488, "phase": "train", "update": 2467, "total_env_steps": 7894400, "episode_reward": 0.2575082778930664, "value_loss": 0.005283770337700844, "policy_loss": -0.0015042548508031218, "dist_entropy": 0.40910564064979554, "actor_grad_norm": 0.09758315235376358, "critic_grad_norm": 0.02071862481534481, "ratio": 1.0004034042358398, "entropy": 0.40910564064979554, "incre_win_rate": 0.8604651162790697, "step": 2467}
{"time": 1767090945.8094363, "phase": "train", "update": 2468, "total_env_steps": 7897600, "episode_reward": 0.25503775477409363, "value_loss": 0.005607785005122423, "policy_loss": -0.0012515104883206619, "dist_entropy": 0.43668549656867983, "actor_grad_norm": 0.10365426540374756, "critic_grad_norm": 0.033974479883909225, "ratio": 1.0002073049545288, "entropy": 0.43668549656867983, "incre_win_rate": 0.8536585365853658, "step": 2468}
{"time": 1767090950.5236712, "phase": "train", "update": 2469, "total_env_steps": 7900800, "episode_reward": 0.2585192620754242, "value_loss": 0.008822707645595073, "policy_loss": -0.001651840887649314, "dist_entropy": 0.4259333431720734, "actor_grad_norm": 0.13314150273799896, "critic_grad_norm": 0.03297259658575058, "ratio": 1.0001715421676636, "entropy": 0.4259333431720734, "incre_win_rate": 0.8636363636363636, "step": 2469}
{"time": 1767090955.4956508, "phase": "train", "update": 2470, "total_env_steps": 7904000, "episode_reward": 0.26797547936439514, "value_loss": 0.005532048363238573, "policy_loss": -0.00176405390887453, "dist_entropy": 0.43309580683708193, "actor_grad_norm": 0.1151571050286293, "critic_grad_norm": 0.018615704029798508, "ratio": 0.9997979998588562, "entropy": 0.43309580683708193, "incre_win_rate": 0.9069767441860465, "step": 2470}
{"time": 1767090960.581111, "phase": "train", "update": 2471, "total_env_steps": 7907200, "episode_reward": 0.2542642652988434, "value_loss": 0.006850540172308683, "policy_loss": -0.0016750686247945623, "dist_entropy": 0.439822793006897, "actor_grad_norm": 0.14731179177761078, "critic_grad_norm": 0.02625671587884426, "ratio": 0.9999496340751648, "entropy": 0.439822793006897, "incre_win_rate": 0.8372093023255814, "step": 2471}
{"time": 1767090965.4710543, "phase": "train", "update": 2472, "total_env_steps": 7910400, "episode_reward": 0.2535114884376526, "value_loss": 0.004979141801595688, "policy_loss": -0.001540929534096591, "dist_entropy": 0.43662876486778257, "actor_grad_norm": 0.11090792715549469, "critic_grad_norm": 0.029277533292770386, "ratio": 1.0000702142715454, "entropy": 0.43662876486778257, "incre_win_rate": 0.8780487804878049, "step": 2472}
{"time": 1767090970.1774158, "phase": "train", "update": 2473, "total_env_steps": 7913600, "episode_reward": 0.2711123526096344, "value_loss": 0.005259086471050977, "policy_loss": -0.0018270491239888997, "dist_entropy": 0.42011001110076907, "actor_grad_norm": 0.13270263373851776, "critic_grad_norm": 0.022210638970136642, "ratio": 0.9998747110366821, "entropy": 0.42011001110076907, "incre_win_rate": 0.9318181818181818, "step": 2473}
{"time": 1767090974.9166117, "phase": "train", "update": 2474, "total_env_steps": 7916800, "episode_reward": 0.26576367020606995, "value_loss": 0.00490645170211792, "policy_loss": -0.001375901640506072, "dist_entropy": 0.425803142786026, "actor_grad_norm": 0.13265453279018402, "critic_grad_norm": 0.023863419890403748, "ratio": 1.0000934600830078, "entropy": 0.425803142786026, "incre_win_rate": 0.9069767441860465, "step": 2474}
{"time": 1767090979.5630436, "phase": "train", "update": 2475, "total_env_steps": 7920000, "episode_reward": 0.24241051077842712, "value_loss": 0.006711418926715851, "policy_loss": -0.0015586065702535735, "dist_entropy": 0.4127050280570984, "actor_grad_norm": 0.13603898882865906, "critic_grad_norm": 0.057176198810338974, "ratio": 1.0001497268676758, "entropy": 0.4127050280570984, "incre_win_rate": 0.7441860465116279, "step": 2475}
{"time": 1767090984.4037173, "phase": "train", "update": 2476, "total_env_steps": 7923200, "episode_reward": 0.2565252482891083, "value_loss": 0.006298516225069761, "policy_loss": -0.0015361108268773904, "dist_entropy": 0.4211743652820587, "actor_grad_norm": 0.1386176198720932, "critic_grad_norm": 0.04418858885765076, "ratio": 1.0002684593200684, "entropy": 0.4211743652820587, "incre_win_rate": 0.8780487804878049, "step": 2476}
{"time": 1767090989.034068, "phase": "train", "update": 2477, "total_env_steps": 7926400, "episode_reward": 0.23590022325515747, "value_loss": 0.0076675377786159515, "policy_loss": -0.0016428673014758032, "dist_entropy": 0.4167626082897186, "actor_grad_norm": 0.12661691009998322, "critic_grad_norm": 0.06356420367956161, "ratio": 0.999893307685852, "entropy": 0.4167626082897186, "incre_win_rate": 0.775, "step": 2477}
{"time": 1767090993.8566356, "phase": "train", "update": 2478, "total_env_steps": 7929600, "episode_reward": 0.25473353266716003, "value_loss": 0.006253139674663543, "policy_loss": -0.0015941645314271114, "dist_entropy": 0.4025298535823822, "actor_grad_norm": 0.12730075418949127, "critic_grad_norm": 0.04928412660956383, "ratio": 0.9999924898147583, "entropy": 0.4025298535823822, "incre_win_rate": 0.8837209302325582, "step": 2478}
{"time": 1767090998.414795, "phase": "train", "update": 2479, "total_env_steps": 7932800, "episode_reward": 0.22542840242385864, "value_loss": 0.007659241370856762, "policy_loss": -0.0018295812435923154, "dist_entropy": 0.44062850475311277, "actor_grad_norm": 0.12740805745124817, "critic_grad_norm": 0.03523816540837288, "ratio": 1.0001026391983032, "entropy": 0.44062850475311277, "incre_win_rate": 0.717948717948718, "step": 2479}
{"time": 1767091003.3300369, "phase": "train", "update": 2480, "total_env_steps": 7936000, "episode_reward": 0.25551068782806396, "value_loss": 0.00820879489183426, "policy_loss": -0.001413916940418858, "dist_entropy": 0.42199347019195554, "actor_grad_norm": 0.12558747828006744, "critic_grad_norm": 0.04199286922812462, "ratio": 0.9995595812797546, "entropy": 0.42199347019195554, "incre_win_rate": 0.813953488372093, "step": 2480}
{"time": 1767091008.1418684, "phase": "train", "update": 2481, "total_env_steps": 7939200, "episode_reward": 0.2734147310256958, "value_loss": 0.006655471120029688, "policy_loss": -0.0014086430902096937, "dist_entropy": 0.4160828530788422, "actor_grad_norm": 0.1275757998228073, "critic_grad_norm": 0.052920788526535034, "ratio": 1.0001739263534546, "entropy": 0.4160828530788422, "incre_win_rate": 0.8723404255319149, "step": 2481}
{"time": 1767091019.1096392, "phase": "eval", "update": 2481, "total_env_steps": 7939200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.752276490066222, "step": 2481}
{"time": 1767091023.7509675, "phase": "train", "update": 2482, "total_env_steps": 7942400, "episode_reward": 0.26390573382377625, "value_loss": 0.008463639952242374, "policy_loss": -0.0015047952482660776, "dist_entropy": 0.4107216238975525, "actor_grad_norm": 0.11468241363763809, "critic_grad_norm": 0.03511206433176994, "ratio": 0.9996230006217957, "entropy": 0.4107216238975525, "incre_win_rate": 0.8333333333333334, "step": 2482}
{"time": 1767091028.2758987, "phase": "train", "update": 2483, "total_env_steps": 7945600, "episode_reward": 0.25543099641799927, "value_loss": 0.008433862030506134, "policy_loss": -0.0016219864723943545, "dist_entropy": 0.4011187970638275, "actor_grad_norm": 0.12211325019598007, "critic_grad_norm": 0.04773949459195137, "ratio": 1.0004016160964966, "entropy": 0.4011187970638275, "incre_win_rate": 0.7045454545454546, "step": 2483}
{"time": 1767091032.8753831, "phase": "train", "update": 2484, "total_env_steps": 7948800, "episode_reward": 0.24713318049907684, "value_loss": 0.011703623272478581, "policy_loss": -0.001436166843616604, "dist_entropy": 0.4195344090461731, "actor_grad_norm": 0.13095998764038086, "critic_grad_norm": 0.0504249706864357, "ratio": 0.9999547004699707, "entropy": 0.4195344090461731, "incre_win_rate": 0.7674418604651163, "step": 2484}
{"time": 1767091037.5035512, "phase": "train", "update": 2485, "total_env_steps": 7952000, "episode_reward": 0.24419081211090088, "value_loss": 0.008634001947939396, "policy_loss": -0.0016178543439437476, "dist_entropy": 0.4282558262348175, "actor_grad_norm": 0.16431133449077606, "critic_grad_norm": 0.030324647203087807, "ratio": 1.0000276565551758, "entropy": 0.4282558262348175, "incre_win_rate": 0.7142857142857143, "step": 2485}
{"time": 1767091042.154793, "phase": "train", "update": 2486, "total_env_steps": 7955200, "episode_reward": 0.24530835449695587, "value_loss": 0.008928622119128704, "policy_loss": -0.0013406835619719005, "dist_entropy": 0.42803468108177184, "actor_grad_norm": 0.15759821236133575, "critic_grad_norm": 0.02689077891409397, "ratio": 0.9996110796928406, "entropy": 0.42803468108177184, "incre_win_rate": 0.6976744186046512, "step": 2486}
{"time": 1767091046.6695788, "phase": "train", "update": 2487, "total_env_steps": 7958400, "episode_reward": 0.23723459243774414, "value_loss": 0.009676553122699261, "policy_loss": -0.0019057958096070139, "dist_entropy": 0.4361364781856537, "actor_grad_norm": 0.1519235521554947, "critic_grad_norm": 0.03752240911126137, "ratio": 1.0003365278244019, "entropy": 0.4361364781856537, "incre_win_rate": 0.7317073170731707, "step": 2487}
{"time": 1767091051.4861422, "phase": "train", "update": 2488, "total_env_steps": 7961600, "episode_reward": 0.2539823055267334, "value_loss": 0.007960173208266497, "policy_loss": -0.0016657470270345699, "dist_entropy": 0.4275308966636658, "actor_grad_norm": 0.13737623393535614, "critic_grad_norm": 0.04363406449556351, "ratio": 0.9998373985290527, "entropy": 0.4275308966636658, "incre_win_rate": 0.75, "step": 2488}
{"time": 1767091056.3672674, "phase": "train", "update": 2489, "total_env_steps": 7964800, "episode_reward": 0.25102856755256653, "value_loss": 0.007469646446406841, "policy_loss": -0.0016423670182604156, "dist_entropy": 0.4521926403045654, "actor_grad_norm": 0.1144125834107399, "critic_grad_norm": 0.06605110317468643, "ratio": 1.0001806020736694, "entropy": 0.4521926403045654, "incre_win_rate": 0.8048780487804879, "step": 2489}
{"time": 1767091061.15096, "phase": "train", "update": 2490, "total_env_steps": 7968000, "episode_reward": 0.23693504929542542, "value_loss": 0.008251631818711757, "policy_loss": -0.0014302699353237359, "dist_entropy": 0.41977246999740603, "actor_grad_norm": 0.11866635084152222, "critic_grad_norm": 0.04701394960284233, "ratio": 1.0000311136245728, "entropy": 0.41977246999740603, "incre_win_rate": 0.6744186046511628, "step": 2490}
{"time": 1767091066.183941, "phase": "train", "update": 2491, "total_env_steps": 7971200, "episode_reward": 0.2459566444158554, "value_loss": 0.008124163188040257, "policy_loss": -0.0017916349302133483, "dist_entropy": 0.42840214967727663, "actor_grad_norm": 0.11818130314350128, "critic_grad_norm": 0.03609054908156395, "ratio": 1.000177264213562, "entropy": 0.42840214967727663, "incre_win_rate": 0.7857142857142857, "step": 2491}
{"time": 1767091071.6045403, "phase": "train", "update": 2492, "total_env_steps": 7974400, "episode_reward": 0.2484116554260254, "value_loss": 0.008764564245939254, "policy_loss": -0.0015401696860841696, "dist_entropy": 0.4222071826457977, "actor_grad_norm": 0.11733774095773697, "critic_grad_norm": 0.031116032972931862, "ratio": 0.9992286562919617, "entropy": 0.4222071826457977, "incre_win_rate": 0.6904761904761905, "step": 2492}
{"time": 1767091076.870014, "phase": "train", "update": 2493, "total_env_steps": 7977600, "episode_reward": 0.2519712448120117, "value_loss": 0.007984747085720301, "policy_loss": -0.0012709746026430934, "dist_entropy": 0.41792739033699033, "actor_grad_norm": 0.1129443421959877, "critic_grad_norm": 0.06276870518922806, "ratio": 1.0000790357589722, "entropy": 0.41792739033699033, "incre_win_rate": 0.7619047619047619, "step": 2493}
{"time": 1767091082.1755502, "phase": "train", "update": 2494, "total_env_steps": 7980800, "episode_reward": 0.24216163158416748, "value_loss": 0.007263702061027289, "policy_loss": -0.0013902363468375257, "dist_entropy": 0.43219215273857114, "actor_grad_norm": 0.12929289042949677, "critic_grad_norm": 0.04982377216219902, "ratio": 1.0000114440917969, "entropy": 0.43219215273857114, "incre_win_rate": 0.725, "step": 2494}
{"time": 1767091087.6578326, "phase": "train", "update": 2495, "total_env_steps": 7984000, "episode_reward": 0.25865066051483154, "value_loss": 0.005941096134483815, "policy_loss": -0.0012733903766566357, "dist_entropy": 0.42446696758270264, "actor_grad_norm": 0.13554881513118744, "critic_grad_norm": 0.03334374353289604, "ratio": 0.9999567270278931, "entropy": 0.42446696758270264, "incre_win_rate": 0.8478260869565217, "step": 2495}
{"time": 1767091092.8704767, "phase": "train", "update": 2496, "total_env_steps": 7987200, "episode_reward": 0.2561015188694, "value_loss": 0.0055993407033383845, "policy_loss": -0.001126336332505673, "dist_entropy": 0.43924368619918824, "actor_grad_norm": 0.15075182914733887, "critic_grad_norm": 0.022104432806372643, "ratio": 1.000221848487854, "entropy": 0.43924368619918824, "incre_win_rate": 0.8292682926829268, "step": 2496}
{"time": 1767091097.5570116, "phase": "train", "update": 2497, "total_env_steps": 7990400, "episode_reward": 0.23860099911689758, "value_loss": 0.009427565336227416, "policy_loss": -0.0019644246745778916, "dist_entropy": 0.4690070629119873, "actor_grad_norm": 0.12731622159481049, "critic_grad_norm": 0.04036602005362511, "ratio": 0.9997429251670837, "entropy": 0.4690070629119873, "incre_win_rate": 0.8157894736842105, "step": 2497}
{"time": 1767091102.3402536, "phase": "train", "update": 2498, "total_env_steps": 7993600, "episode_reward": 0.25265002250671387, "value_loss": 0.008582919277250767, "policy_loss": -0.0013851902079281332, "dist_entropy": 0.42131868600845335, "actor_grad_norm": 0.10998685657978058, "critic_grad_norm": 0.02002525143325329, "ratio": 0.9996544718742371, "entropy": 0.42131868600845335, "incre_win_rate": 0.8222222222222222, "step": 2498}
{"time": 1767091106.9569957, "phase": "train", "update": 2499, "total_env_steps": 7996800, "episode_reward": 0.2398732304573059, "value_loss": 0.008647621795535087, "policy_loss": -0.0014788198688535203, "dist_entropy": 0.43916829228401183, "actor_grad_norm": 0.13365428149700165, "critic_grad_norm": 0.02284015715122223, "ratio": 0.9998391270637512, "entropy": 0.43916829228401183, "incre_win_rate": 0.7692307692307693, "step": 2499}
{"time": 1767091111.6952558, "phase": "train", "update": 2500, "total_env_steps": 8000000, "episode_reward": 0.24192312359809875, "value_loss": 0.007786995172500611, "policy_loss": -0.0014809077472136777, "dist_entropy": 0.428935045003891, "actor_grad_norm": 0.16099590063095093, "critic_grad_norm": 0.021557405591011047, "ratio": 1.0000556707382202, "entropy": 0.428935045003891, "incre_win_rate": 0.6818181818181818, "step": 2500}
{"time": 1767091116.4111729, "phase": "train", "update": 2501, "total_env_steps": 8003200, "episode_reward": 0.23865585029125214, "value_loss": 0.0072523083537817, "policy_loss": -0.0014821667247204573, "dist_entropy": 0.42787808179855347, "actor_grad_norm": 0.14376293122768402, "critic_grad_norm": 0.025444645434617996, "ratio": 0.9998344779014587, "entropy": 0.42787808179855347, "incre_win_rate": 0.725, "step": 2501}
{"time": 1767091127.4034553, "phase": "eval", "update": 2501, "total_env_steps": 8003200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.876862582781456, "step": 2501}
{"time": 1767091132.368369, "phase": "train", "update": 2502, "total_env_steps": 8006400, "episode_reward": 0.24591320753097534, "value_loss": 0.009864457510411739, "policy_loss": -0.001557332730016303, "dist_entropy": 0.4256501793861389, "actor_grad_norm": 0.12027986347675323, "critic_grad_norm": 0.06331617385149002, "ratio": 1.000245451927185, "entropy": 0.4256501793861389, "incre_win_rate": 0.6363636363636364, "step": 2502}
{"time": 1767091137.4398167, "phase": "train", "update": 2503, "total_env_steps": 8009600, "episode_reward": 0.26063328981399536, "value_loss": 0.009307027049362659, "policy_loss": -0.0014766034529563044, "dist_entropy": 0.42444761395454406, "actor_grad_norm": 0.10496413707733154, "critic_grad_norm": 0.058364588767290115, "ratio": 0.9998311400413513, "entropy": 0.42444761395454406, "incre_win_rate": 0.7954545454545454, "step": 2503}
{"time": 1767091142.616955, "phase": "train", "update": 2504, "total_env_steps": 8012800, "episode_reward": 0.23890109360218048, "value_loss": 0.011696460843086242, "policy_loss": -0.0017503006607583415, "dist_entropy": 0.4571352005004883, "actor_grad_norm": 0.10885921865701675, "critic_grad_norm": 0.07603300362825394, "ratio": 0.9994155168533325, "entropy": 0.4571352005004883, "incre_win_rate": 0.6511627906976745, "step": 2504}
{"time": 1767091147.2296722, "phase": "train", "update": 2505, "total_env_steps": 8016000, "episode_reward": 0.24022041261196136, "value_loss": 0.009228280000388622, "policy_loss": -0.0015628198314686869, "dist_entropy": 0.4334607064723969, "actor_grad_norm": 0.11989658325910568, "critic_grad_norm": 0.05617745593190193, "ratio": 0.9999346137046814, "entropy": 0.4334607064723969, "incre_win_rate": 0.7073170731707317, "step": 2505}
{"time": 1767091151.961177, "phase": "train", "update": 2506, "total_env_steps": 8019200, "episode_reward": 0.2541370093822479, "value_loss": 0.009984546713531018, "policy_loss": -0.0018046088062625642, "dist_entropy": 0.4362784862518311, "actor_grad_norm": 0.11995663493871689, "critic_grad_norm": 0.04674030467867851, "ratio": 0.9999724626541138, "entropy": 0.4362784862518311, "incre_win_rate": 0.7555555555555555, "step": 2506}
{"time": 1767091156.5567663, "phase": "train", "update": 2507, "total_env_steps": 8022400, "episode_reward": 0.23377999663352966, "value_loss": 0.011131201311945916, "policy_loss": -0.0019325202040480604, "dist_entropy": 0.4209261298179626, "actor_grad_norm": 0.11862555891275406, "critic_grad_norm": 0.040088776499032974, "ratio": 1.000224232673645, "entropy": 0.4209261298179626, "incre_win_rate": 0.5853658536585366, "step": 2507}
{"time": 1767091161.194233, "phase": "train", "update": 2508, "total_env_steps": 8025600, "episode_reward": 0.24280835688114166, "value_loss": 0.006587802246212959, "policy_loss": -0.0018033805608496322, "dist_entropy": 0.44105427861213686, "actor_grad_norm": 0.11259632557630539, "critic_grad_norm": 0.07297804206609726, "ratio": 0.9998494982719421, "entropy": 0.44105427861213686, "incre_win_rate": 0.825, "step": 2508}
{"time": 1767091165.982388, "phase": "train", "update": 2509, "total_env_steps": 8028800, "episode_reward": 0.2513757348060608, "value_loss": 0.007670261990278959, "policy_loss": -0.0013762376315966662, "dist_entropy": 0.415960693359375, "actor_grad_norm": 0.10894810408353806, "critic_grad_norm": 0.040150176733732224, "ratio": 1.000198245048523, "entropy": 0.415960693359375, "incre_win_rate": 0.7045454545454546, "step": 2509}
{"time": 1767091170.6057057, "phase": "train", "update": 2510, "total_env_steps": 8032000, "episode_reward": 0.26068246364593506, "value_loss": 0.005803174618631601, "policy_loss": -0.0012028131105651595, "dist_entropy": 0.42700599431991576, "actor_grad_norm": 0.12216899544000626, "critic_grad_norm": 0.030311990529298782, "ratio": 1.0002166032791138, "entropy": 0.42700599431991576, "incre_win_rate": 0.7777777777777778, "step": 2510}
{"time": 1767091175.2992518, "phase": "train", "update": 2511, "total_env_steps": 8035200, "episode_reward": 0.25482359528541565, "value_loss": 0.006742953695356846, "policy_loss": -0.0016688561990335416, "dist_entropy": 0.41292505264282225, "actor_grad_norm": 0.15015898644924164, "critic_grad_norm": 0.025743601843714714, "ratio": 0.999900758266449, "entropy": 0.41292505264282225, "incre_win_rate": 0.8048780487804879, "step": 2511}
{"time": 1767091180.0758848, "phase": "train", "update": 2512, "total_env_steps": 8038400, "episode_reward": 0.24547186493873596, "value_loss": 0.009567704796791077, "policy_loss": -0.0014452765751656216, "dist_entropy": 0.42960883378982545, "actor_grad_norm": 0.1688661128282547, "critic_grad_norm": 0.04700392112135887, "ratio": 0.9996065497398376, "entropy": 0.42960883378982545, "incre_win_rate": 0.6956521739130435, "step": 2512}
{"time": 1767091184.8847365, "phase": "train", "update": 2513, "total_env_steps": 8041600, "episode_reward": 0.24120396375656128, "value_loss": 0.009303366392850876, "policy_loss": -0.0013977542517991993, "dist_entropy": 0.42718989253044126, "actor_grad_norm": 0.10643637180328369, "critic_grad_norm": 0.036257438361644745, "ratio": 1.0000392198562622, "entropy": 0.42718989253044126, "incre_win_rate": 0.6829268292682927, "step": 2513}
{"time": 1767091189.583709, "phase": "train", "update": 2514, "total_env_steps": 8044800, "episode_reward": 0.24849289655685425, "value_loss": 0.009517594799399376, "policy_loss": -0.0016051754180161026, "dist_entropy": 0.4217507541179657, "actor_grad_norm": 0.1528104543685913, "critic_grad_norm": 0.02573707140982151, "ratio": 0.9999223947525024, "entropy": 0.4217507541179657, "incre_win_rate": 0.7111111111111111, "step": 2514}
{"time": 1767091194.3850527, "phase": "train", "update": 2515, "total_env_steps": 8048000, "episode_reward": 0.2564062476158142, "value_loss": 0.008906661160290241, "policy_loss": -0.0013480364878549977, "dist_entropy": 0.42419142127037046, "actor_grad_norm": 0.11004357784986496, "critic_grad_norm": 0.04156971722841263, "ratio": 1.0000437498092651, "entropy": 0.42419142127037046, "incre_win_rate": 0.7906976744186046, "step": 2515}
{"time": 1767091199.3050766, "phase": "train", "update": 2516, "total_env_steps": 8051200, "episode_reward": 0.25807738304138184, "value_loss": 0.009103354066610336, "policy_loss": -0.0013376820046019588, "dist_entropy": 0.4216619074344635, "actor_grad_norm": 0.13487093150615692, "critic_grad_norm": 0.04149283096194267, "ratio": 1.0001168251037598, "entropy": 0.4216619074344635, "incre_win_rate": 0.7954545454545454, "step": 2516}
{"time": 1767091204.1200013, "phase": "train", "update": 2517, "total_env_steps": 8054400, "episode_reward": 0.2576872706413269, "value_loss": 0.006865527760237455, "policy_loss": -0.0013881889687326066, "dist_entropy": 0.4421412110328674, "actor_grad_norm": 0.1581754982471466, "critic_grad_norm": 0.055823732167482376, "ratio": 0.9998607635498047, "entropy": 0.4421412110328674, "incre_win_rate": 0.8095238095238095, "step": 2517}
{"time": 1767091208.7119942, "phase": "train", "update": 2518, "total_env_steps": 8057600, "episode_reward": 0.2618258595466614, "value_loss": 0.007675925549119711, "policy_loss": -0.0013751237141676142, "dist_entropy": 0.4367819845676422, "actor_grad_norm": 0.11114349216222763, "critic_grad_norm": 0.049148377031087875, "ratio": 0.9995620846748352, "entropy": 0.4367819845676422, "incre_win_rate": 0.8444444444444444, "step": 2518}
{"time": 1767091213.4212766, "phase": "train", "update": 2519, "total_env_steps": 8060800, "episode_reward": 0.26150351762771606, "value_loss": 0.005691646505147219, "policy_loss": -0.0016350433161392175, "dist_entropy": 0.44498148560523987, "actor_grad_norm": 0.13262704014778137, "critic_grad_norm": 0.04951976612210274, "ratio": 1.0001286268234253, "entropy": 0.44498148560523987, "incre_win_rate": 0.8571428571428571, "step": 2519}
{"time": 1767091218.1971586, "phase": "train", "update": 2520, "total_env_steps": 8064000, "episode_reward": 0.2707895338535309, "value_loss": 0.004342305101454258, "policy_loss": -0.001620476218086253, "dist_entropy": 0.4518157780170441, "actor_grad_norm": 0.1385091096162796, "critic_grad_norm": 0.026569122448563576, "ratio": 0.9997853636741638, "entropy": 0.4518157780170441, "incre_win_rate": 0.9318181818181818, "step": 2520}
{"time": 1767091223.392695, "phase": "train", "update": 2521, "total_env_steps": 8067200, "episode_reward": 0.2514740228652954, "value_loss": 0.0074456118047237395, "policy_loss": -0.0017667124896199482, "dist_entropy": 0.45222426652908326, "actor_grad_norm": 0.14996187388896942, "critic_grad_norm": 0.043038781732320786, "ratio": 0.9994551539421082, "entropy": 0.45222426652908326, "incre_win_rate": 0.7619047619047619, "step": 2521}
{"time": 1767091236.046355, "phase": "eval", "update": 2521, "total_env_steps": 8067200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.502638658940395, "step": 2521}
{"time": 1767091241.3223493, "phase": "train", "update": 2522, "total_env_steps": 8070400, "episode_reward": 0.25252068042755127, "value_loss": 0.007041655667126179, "policy_loss": -0.0010997486697370106, "dist_entropy": 0.46155649423599243, "actor_grad_norm": 0.13380451500415802, "critic_grad_norm": 0.024993643164634705, "ratio": 1.0002411603927612, "entropy": 0.46155649423599243, "incre_win_rate": 0.8333333333333334, "step": 2522}
{"time": 1767091246.0952697, "phase": "train", "update": 2523, "total_env_steps": 8073600, "episode_reward": 0.25073572993278503, "value_loss": 0.007735185790807009, "policy_loss": -0.0012902610004335458, "dist_entropy": 0.44814183115959166, "actor_grad_norm": 0.12180489301681519, "critic_grad_norm": 0.03395844250917435, "ratio": 0.999605119228363, "entropy": 0.44814183115959166, "incre_win_rate": 0.7906976744186046, "step": 2523}
{"time": 1767091251.131196, "phase": "train", "update": 2524, "total_env_steps": 8076800, "episode_reward": 0.2605867087841034, "value_loss": 0.005820303875952959, "policy_loss": -0.0011954704127177251, "dist_entropy": 0.4407334566116333, "actor_grad_norm": 0.11456290632486343, "critic_grad_norm": 0.04846414923667908, "ratio": 0.9998942613601685, "entropy": 0.4407334566116333, "incre_win_rate": 0.8372093023255814, "step": 2524}
{"time": 1767091256.0449286, "phase": "train", "update": 2525, "total_env_steps": 8080000, "episode_reward": 0.23799876868724823, "value_loss": 0.0072259224019944664, "policy_loss": -0.0013611237960020617, "dist_entropy": 0.445010644197464, "actor_grad_norm": 0.1614082306623459, "critic_grad_norm": 0.033947017043828964, "ratio": 0.9998155832290649, "entropy": 0.445010644197464, "incre_win_rate": 0.7441860465116279, "step": 2525}
{"time": 1767091260.650579, "phase": "train", "update": 2526, "total_env_steps": 8083200, "episode_reward": 0.25865891575813293, "value_loss": 0.004819659795612097, "policy_loss": -0.0014858675948957512, "dist_entropy": 0.43644489645957946, "actor_grad_norm": 0.11245416849851608, "critic_grad_norm": 0.02958071045577526, "ratio": 0.9995951056480408, "entropy": 0.43644489645957946, "incre_win_rate": 0.8536585365853658, "step": 2526}
{"time": 1767091265.3300133, "phase": "train", "update": 2527, "total_env_steps": 8086400, "episode_reward": 0.26607874035835266, "value_loss": 0.0051826655864715574, "policy_loss": -0.001403048074054425, "dist_entropy": 0.42885716557502745, "actor_grad_norm": 0.11041367053985596, "critic_grad_norm": 0.028434811159968376, "ratio": 0.9998246431350708, "entropy": 0.42885716557502745, "incre_win_rate": 0.9302325581395349, "step": 2527}
{"time": 1767091269.9121, "phase": "train", "update": 2528, "total_env_steps": 8089600, "episode_reward": 0.255685031414032, "value_loss": 0.006090142484754324, "policy_loss": -0.0017502667197177857, "dist_entropy": 0.4416826665401459, "actor_grad_norm": 0.12714740633964539, "critic_grad_norm": 0.030036363750696182, "ratio": 1.0001057386398315, "entropy": 0.4416826665401459, "incre_win_rate": 0.7857142857142857, "step": 2528}
{"time": 1767091274.5429995, "phase": "train", "update": 2529, "total_env_steps": 8092800, "episode_reward": 0.257653146982193, "value_loss": 0.00628927480429411, "policy_loss": -0.0017769095099410491, "dist_entropy": 0.4490391194820404, "actor_grad_norm": 0.11766922473907471, "critic_grad_norm": 0.01698680780827999, "ratio": 0.9998392462730408, "entropy": 0.4490391194820404, "incre_win_rate": 0.8444444444444444, "step": 2529}
{"time": 1767091279.1293652, "phase": "train", "update": 2530, "total_env_steps": 8096000, "episode_reward": 0.2579791247844696, "value_loss": 0.006740250438451767, "policy_loss": -0.0016947102971926141, "dist_entropy": 0.4431403338909149, "actor_grad_norm": 0.10991670191287994, "critic_grad_norm": 0.019947649911046028, "ratio": 1.0002201795578003, "entropy": 0.4431403338909149, "incre_win_rate": 0.7619047619047619, "step": 2530}
{"time": 1767091283.7014961, "phase": "train", "update": 2531, "total_env_steps": 8099200, "episode_reward": 0.237042635679245, "value_loss": 0.006565031502395869, "policy_loss": -0.0015685970483424682, "dist_entropy": 0.44351508021354674, "actor_grad_norm": 0.12876339256763458, "critic_grad_norm": 0.03614956885576248, "ratio": 1.0001109838485718, "entropy": 0.44351508021354674, "incre_win_rate": 0.7209302325581395, "step": 2531}
{"time": 1767091288.3541083, "phase": "train", "update": 2532, "total_env_steps": 8102400, "episode_reward": 0.25700539350509644, "value_loss": 0.005816619377583265, "policy_loss": -0.0016282489652848398, "dist_entropy": 0.4503389596939087, "actor_grad_norm": 0.0965489000082016, "critic_grad_norm": 0.04243190214037895, "ratio": 0.9998844265937805, "entropy": 0.4503389596939087, "incre_win_rate": 0.9024390243902439, "step": 2532}
{"time": 1767091293.0848873, "phase": "train", "update": 2533, "total_env_steps": 8105600, "episode_reward": 0.2635922133922577, "value_loss": 0.0050444423221051695, "policy_loss": -0.0014505595523239378, "dist_entropy": 0.4496889889240265, "actor_grad_norm": 0.12355392426252365, "critic_grad_norm": 0.03156418353319168, "ratio": 0.9996501803398132, "entropy": 0.4496889889240265, "incre_win_rate": 0.8604651162790697, "step": 2533}
{"time": 1767091298.0565321, "phase": "train", "update": 2534, "total_env_steps": 8108800, "episode_reward": 0.2437986433506012, "value_loss": 0.009370404109358788, "policy_loss": -0.0018816853348411656, "dist_entropy": 0.4582859516143799, "actor_grad_norm": 0.15319250524044037, "critic_grad_norm": 0.03565271943807602, "ratio": 0.9997459650039673, "entropy": 0.4582859516143799, "incre_win_rate": 0.7727272727272727, "step": 2534}
{"time": 1767091303.1708484, "phase": "train", "update": 2535, "total_env_steps": 8112000, "episode_reward": 0.25289785861968994, "value_loss": 0.006041898112744093, "policy_loss": -0.0015069750081067924, "dist_entropy": 0.4358621060848236, "actor_grad_norm": 0.1654789000749588, "critic_grad_norm": 0.019645486027002335, "ratio": 1.0002402067184448, "entropy": 0.4358621060848236, "incre_win_rate": 0.8292682926829268, "step": 2535}
{"time": 1767091308.3235154, "phase": "train", "update": 2536, "total_env_steps": 8115200, "episode_reward": 0.2635994553565979, "value_loss": 0.006405847799032927, "policy_loss": -0.001747759936875859, "dist_entropy": 0.437470942735672, "actor_grad_norm": 0.11857712268829346, "critic_grad_norm": 0.023294946178793907, "ratio": 0.9999613165855408, "entropy": 0.437470942735672, "incre_win_rate": 0.8444444444444444, "step": 2536}
{"time": 1767091313.3343935, "phase": "train", "update": 2537, "total_env_steps": 8118400, "episode_reward": 0.2556550204753876, "value_loss": 0.00665883682668209, "policy_loss": -0.0013258814631626592, "dist_entropy": 0.4543569624423981, "actor_grad_norm": 0.11857818812131882, "critic_grad_norm": 0.030284618958830833, "ratio": 0.999921977519989, "entropy": 0.4543569624423981, "incre_win_rate": 0.7560975609756098, "step": 2537}
{"time": 1767091318.3268576, "phase": "train", "update": 2538, "total_env_steps": 8121600, "episode_reward": 0.2410585582256317, "value_loss": 0.008039154578000307, "policy_loss": -0.001725393494849925, "dist_entropy": 0.4417844533920288, "actor_grad_norm": 0.1429026573896408, "critic_grad_norm": 0.04288015514612198, "ratio": 0.9995347857475281, "entropy": 0.4417844533920288, "incre_win_rate": 0.75, "step": 2538}
{"time": 1767091323.3758142, "phase": "train", "update": 2539, "total_env_steps": 8124800, "episode_reward": 0.26121169328689575, "value_loss": 0.007252679392695427, "policy_loss": -0.0016195213201783075, "dist_entropy": 0.4406136810779572, "actor_grad_norm": 0.10507214069366455, "critic_grad_norm": 0.02971748076379299, "ratio": 0.9997418522834778, "entropy": 0.4406136810779572, "incre_win_rate": 0.8571428571428571, "step": 2539}
{"time": 1767091328.2241108, "phase": "train", "update": 2540, "total_env_steps": 8128000, "episode_reward": 0.2507683038711548, "value_loss": 0.008820078894495964, "policy_loss": -0.0016474309839097146, "dist_entropy": 0.4339491307735443, "actor_grad_norm": 0.1191486343741417, "critic_grad_norm": 0.0240971427410841, "ratio": 1.0001856088638306, "entropy": 0.4339491307735443, "incre_win_rate": 0.8333333333333334, "step": 2540}
{"time": 1767091332.7878838, "phase": "train", "update": 2541, "total_env_steps": 8131200, "episode_reward": 0.2449079006910324, "value_loss": 0.008269263617694377, "policy_loss": -0.0017437448046933924, "dist_entropy": 0.43729150891304014, "actor_grad_norm": 0.14731743931770325, "critic_grad_norm": 0.022494850680232048, "ratio": 1.0002244710922241, "entropy": 0.43729150891304014, "incre_win_rate": 0.7560975609756098, "step": 2541}
{"time": 1767091343.7449539, "phase": "eval", "update": 2541, "total_env_steps": 8131200, "eval_win_rate": 0.84375, "eval_episode_reward": 18.93046357615894, "step": 2541}
{"time": 1767091348.2979534, "phase": "train", "update": 2542, "total_env_steps": 8134400, "episode_reward": 0.24017231166362762, "value_loss": 0.00703543247655034, "policy_loss": -0.0015591302820169516, "dist_entropy": 0.4365089774131775, "actor_grad_norm": 0.17248554527759552, "critic_grad_norm": 0.025570986792445183, "ratio": 0.9997147917747498, "entropy": 0.4365089774131775, "incre_win_rate": 0.6744186046511628, "step": 2542}
{"time": 1767091352.928145, "phase": "train", "update": 2543, "total_env_steps": 8137600, "episode_reward": 0.25005900859832764, "value_loss": 0.0068371200002729894, "policy_loss": -0.0016485046362411993, "dist_entropy": 0.43246949315071104, "actor_grad_norm": 0.11408688127994537, "critic_grad_norm": 0.04185357317328453, "ratio": 1.0001567602157593, "entropy": 0.43246949315071104, "incre_win_rate": 0.6976744186046512, "step": 2543}
{"time": 1767091357.716047, "phase": "train", "update": 2544, "total_env_steps": 8140800, "episode_reward": 0.2579993009567261, "value_loss": 0.005874340794980526, "policy_loss": -0.0017163628747184135, "dist_entropy": 0.4414361178874969, "actor_grad_norm": 0.13341985642910004, "critic_grad_norm": 0.047013383358716965, "ratio": 0.9998366236686707, "entropy": 0.4414361178874969, "incre_win_rate": 0.8372093023255814, "step": 2544}
{"time": 1767091362.4279447, "phase": "train", "update": 2545, "total_env_steps": 8144000, "episode_reward": 0.2589150369167328, "value_loss": 0.006047789193689823, "policy_loss": -0.0017259120449075738, "dist_entropy": 0.4381437301635742, "actor_grad_norm": 0.15040819346904755, "critic_grad_norm": 0.03635874390602112, "ratio": 0.9998589754104614, "entropy": 0.4381437301635742, "incre_win_rate": 0.7857142857142857, "step": 2545}
{"time": 1767091367.329097, "phase": "train", "update": 2546, "total_env_steps": 8147200, "episode_reward": 0.24442985653877258, "value_loss": 0.008151874877512455, "policy_loss": -0.0017762391073588902, "dist_entropy": 0.45105727314949035, "actor_grad_norm": 0.11618473380804062, "critic_grad_norm": 0.025967156514525414, "ratio": 0.9995083212852478, "entropy": 0.45105727314949035, "incre_win_rate": 0.7804878048780488, "step": 2546}
{"time": 1767091372.040202, "phase": "train", "update": 2547, "total_env_steps": 8150400, "episode_reward": 0.24216942489147186, "value_loss": 0.009067416377365588, "policy_loss": -0.0016607919886947541, "dist_entropy": 0.4429015159606934, "actor_grad_norm": 0.11782504618167877, "critic_grad_norm": 0.048336248844861984, "ratio": 0.9998722076416016, "entropy": 0.4429015159606934, "incre_win_rate": 0.6511627906976745, "step": 2547}
{"time": 1767091376.8009431, "phase": "train", "update": 2548, "total_env_steps": 8153600, "episode_reward": 0.23760193586349487, "value_loss": 0.0072809201665222645, "policy_loss": -0.0016942379324802915, "dist_entropy": 0.4378375470638275, "actor_grad_norm": 0.15316744148731232, "critic_grad_norm": 0.05146172270178795, "ratio": 1.0001181364059448, "entropy": 0.4378375470638275, "incre_win_rate": 0.7142857142857143, "step": 2548}
{"time": 1767091381.504957, "phase": "train", "update": 2549, "total_env_steps": 8156800, "episode_reward": 0.25094109773635864, "value_loss": 0.010207889042794705, "policy_loss": -0.0014866430631130356, "dist_entropy": 0.43492165207862854, "actor_grad_norm": 0.14474228024482727, "critic_grad_norm": 0.02418963424861431, "ratio": 1.000062346458435, "entropy": 0.43492165207862854, "incre_win_rate": 0.7045454545454546, "step": 2549}
{"time": 1767091386.378133, "phase": "train", "update": 2550, "total_env_steps": 8160000, "episode_reward": 0.2486967146396637, "value_loss": 0.008240089751780033, "policy_loss": -0.0013949445619914514, "dist_entropy": 0.4393871188163757, "actor_grad_norm": 0.09592761844396591, "critic_grad_norm": 0.036704517900943756, "ratio": 1.0000406503677368, "entropy": 0.4393871188163757, "incre_win_rate": 0.7560975609756098, "step": 2550}
{"time": 1767091391.2121449, "phase": "train", "update": 2551, "total_env_steps": 8163200, "episode_reward": 0.2475181221961975, "value_loss": 0.009826005809009076, "policy_loss": -0.0013382148022969887, "dist_entropy": 0.43558871150016787, "actor_grad_norm": 0.10732769966125488, "critic_grad_norm": 0.02757994271814823, "ratio": 0.9998478293418884, "entropy": 0.43558871150016787, "incre_win_rate": 0.75, "step": 2551}
{"time": 1767091395.9071207, "phase": "train", "update": 2552, "total_env_steps": 8166400, "episode_reward": 0.26679328083992004, "value_loss": 0.005580583401024341, "policy_loss": -0.0015657842472479367, "dist_entropy": 0.4247907757759094, "actor_grad_norm": 0.11292123794555664, "critic_grad_norm": 0.036187756806612015, "ratio": 0.9997579455375671, "entropy": 0.4247907757759094, "incre_win_rate": 0.8222222222222222, "step": 2552}
{"time": 1767091400.6270053, "phase": "train", "update": 2553, "total_env_steps": 8169600, "episode_reward": 0.25150763988494873, "value_loss": 0.007106245402246714, "policy_loss": -0.0017536880984645009, "dist_entropy": 0.45545299649238585, "actor_grad_norm": 0.1457863450050354, "critic_grad_norm": 0.03369729965925217, "ratio": 0.999798595905304, "entropy": 0.45545299649238585, "incre_win_rate": 0.85, "step": 2553}
{"time": 1767091405.2685745, "phase": "train", "update": 2554, "total_env_steps": 8172800, "episode_reward": 0.24636070430278778, "value_loss": 0.005899265222251415, "policy_loss": -0.0016495000455826413, "dist_entropy": 0.4483404576778412, "actor_grad_norm": 0.11712159216403961, "critic_grad_norm": 0.02962544560432434, "ratio": 0.9998800158500671, "entropy": 0.4483404576778412, "incre_win_rate": 0.7555555555555555, "step": 2554}
{"time": 1767091410.1935472, "phase": "train", "update": 2555, "total_env_steps": 8176000, "episode_reward": 0.25833043456077576, "value_loss": 0.006602993234992027, "policy_loss": -0.001643894249221578, "dist_entropy": 0.4543705999851227, "actor_grad_norm": 0.13984009623527527, "critic_grad_norm": 0.022371118888258934, "ratio": 0.9999361038208008, "entropy": 0.4543705999851227, "incre_win_rate": 0.8780487804878049, "step": 2555}
{"time": 1767091415.2018936, "phase": "train", "update": 2556, "total_env_steps": 8179200, "episode_reward": 0.25465232133865356, "value_loss": 0.0059020834974944595, "policy_loss": -0.0015190189646382634, "dist_entropy": 0.45009965300559995, "actor_grad_norm": 0.12954306602478027, "critic_grad_norm": 0.02370278723537922, "ratio": 0.9997448325157166, "entropy": 0.45009965300559995, "incre_win_rate": 0.8181818181818182, "step": 2556}
{"time": 1767091419.9809165, "phase": "train", "update": 2557, "total_env_steps": 8182400, "episode_reward": 0.2584473192691803, "value_loss": 0.0092774523422122, "policy_loss": -0.002082639243521811, "dist_entropy": 0.4430185675621033, "actor_grad_norm": 0.1199047788977623, "critic_grad_norm": 0.01867513172328472, "ratio": 1.0000544786453247, "entropy": 0.4430185675621033, "incre_win_rate": 0.8809523809523809, "step": 2557}
{"time": 1767091424.7559772, "phase": "train", "update": 2558, "total_env_steps": 8185600, "episode_reward": 0.2550843358039856, "value_loss": 0.005519890133291483, "policy_loss": -0.0011392656527572597, "dist_entropy": 0.4537355124950409, "actor_grad_norm": 0.09341845661401749, "critic_grad_norm": 0.03480922803282738, "ratio": 1.000014305114746, "entropy": 0.4537355124950409, "incre_win_rate": 0.8604651162790697, "step": 2558}
{"time": 1767091429.5482054, "phase": "train", "update": 2559, "total_env_steps": 8188800, "episode_reward": 0.25555258989334106, "value_loss": 0.006108271237462759, "policy_loss": -0.0018289758101886378, "dist_entropy": 0.44116916656494143, "actor_grad_norm": 0.12564288079738617, "critic_grad_norm": 0.021637989208102226, "ratio": 0.9999080896377563, "entropy": 0.44116916656494143, "incre_win_rate": 0.8372093023255814, "step": 2559}
{"time": 1767091434.4639506, "phase": "train", "update": 2560, "total_env_steps": 8192000, "episode_reward": 0.2516757845878601, "value_loss": 0.006774734333157539, "policy_loss": -0.001499049388457152, "dist_entropy": 0.4490674316883087, "actor_grad_norm": 0.13853874802589417, "critic_grad_norm": 0.019393259659409523, "ratio": 1.0000488758087158, "entropy": 0.4490674316883087, "incre_win_rate": 0.8461538461538461, "step": 2560}
{"time": 1767091439.2337224, "phase": "train", "update": 2561, "total_env_steps": 8195200, "episode_reward": 0.25892800092697144, "value_loss": 0.004295520484447479, "policy_loss": -0.0017527517612222709, "dist_entropy": 0.43899274468421934, "actor_grad_norm": 0.1109011173248291, "critic_grad_norm": 0.020342247560620308, "ratio": 0.9997603297233582, "entropy": 0.43899274468421934, "incre_win_rate": 0.8260869565217391, "step": 2561}
{"time": 1767091451.3693552, "phase": "eval", "update": 2561, "total_env_steps": 8195200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.837179221854303, "step": 2561}
{"time": 1767091456.1238647, "phase": "train", "update": 2562, "total_env_steps": 8198400, "episode_reward": 0.26958245038986206, "value_loss": 0.0057709415443241594, "policy_loss": -0.0012274771761646263, "dist_entropy": 0.4540667712688446, "actor_grad_norm": 0.11851811408996582, "critic_grad_norm": 0.03883061930537224, "ratio": 1.0000170469284058, "entropy": 0.4540667712688446, "incre_win_rate": 0.9512195121951219, "step": 2562}
{"time": 1767091460.7510607, "phase": "train", "update": 2563, "total_env_steps": 8201600, "episode_reward": 0.25100839138031006, "value_loss": 0.009824514202773572, "policy_loss": -0.0018950666243597424, "dist_entropy": 0.4586106240749359, "actor_grad_norm": 0.12515242397785187, "critic_grad_norm": 0.03623618558049202, "ratio": 0.9992691874504089, "entropy": 0.4586106240749359, "incre_win_rate": 0.8181818181818182, "step": 2563}
{"time": 1767091465.7869253, "phase": "train", "update": 2564, "total_env_steps": 8204800, "episode_reward": 0.25203436613082886, "value_loss": 0.0048063256777822975, "policy_loss": -0.0013534990957341897, "dist_entropy": 0.45063084959983823, "actor_grad_norm": 0.12197419255971909, "critic_grad_norm": 0.03108195774257183, "ratio": 1.0001825094223022, "entropy": 0.45063084959983823, "incre_win_rate": 0.8333333333333334, "step": 2564}
{"time": 1767091470.5852854, "phase": "train", "update": 2565, "total_env_steps": 8208000, "episode_reward": 0.2548375427722931, "value_loss": 0.005205200519412756, "policy_loss": -0.0015181163264784913, "dist_entropy": 0.4525632321834564, "actor_grad_norm": 0.1329917162656784, "critic_grad_norm": 0.019512509927153587, "ratio": 1.000588297843933, "entropy": 0.4525632321834564, "incre_win_rate": 0.7906976744186046, "step": 2565}
{"time": 1767091475.2650306, "phase": "train", "update": 2566, "total_env_steps": 8211200, "episode_reward": 0.2511330842971802, "value_loss": 0.010037827305495739, "policy_loss": -0.0011267319802072961, "dist_entropy": 0.45401700139045714, "actor_grad_norm": 0.13189326226711273, "critic_grad_norm": 0.054413020610809326, "ratio": 1.0000848770141602, "entropy": 0.45401700139045714, "incre_win_rate": 0.7619047619047619, "step": 2566}
{"time": 1767091480.0084991, "phase": "train", "update": 2567, "total_env_steps": 8214400, "episode_reward": 0.2500760555267334, "value_loss": 0.0066572845913469795, "policy_loss": -0.001474809794277121, "dist_entropy": 0.46549107432365416, "actor_grad_norm": 0.12376870214939117, "critic_grad_norm": 0.04845467954874039, "ratio": 0.9999544024467468, "entropy": 0.46549107432365416, "incre_win_rate": 0.8048780487804879, "step": 2567}
{"time": 1767091484.8167717, "phase": "train", "update": 2568, "total_env_steps": 8217600, "episode_reward": 0.24426893889904022, "value_loss": 0.00899541899561882, "policy_loss": -0.0016871120523816786, "dist_entropy": 0.4539385557174683, "actor_grad_norm": 0.17291991412639618, "critic_grad_norm": 0.0422944612801075, "ratio": 0.9996426701545715, "entropy": 0.4539385557174683, "incre_win_rate": 0.7333333333333333, "step": 2568}
{"time": 1767091489.5954738, "phase": "train", "update": 2569, "total_env_steps": 8220800, "episode_reward": 0.25146782398223877, "value_loss": 0.007795127481222153, "policy_loss": -0.0016808088985875713, "dist_entropy": 0.46185106635093687, "actor_grad_norm": 0.10490413010120392, "critic_grad_norm": 0.03653811290860176, "ratio": 1.0000537633895874, "entropy": 0.46185106635093687, "incre_win_rate": 0.7317073170731707, "step": 2569}
{"time": 1767091494.2926023, "phase": "train", "update": 2570, "total_env_steps": 8224000, "episode_reward": 0.2672283947467804, "value_loss": 0.006968018785119057, "policy_loss": -0.001556885322669821, "dist_entropy": 0.44474108815193175, "actor_grad_norm": 0.10089864581823349, "critic_grad_norm": 0.0269408468157053, "ratio": 1.0002354383468628, "entropy": 0.44474108815193175, "incre_win_rate": 0.8913043478260869, "step": 2570}
{"time": 1767091499.0637767, "phase": "train", "update": 2571, "total_env_steps": 8227200, "episode_reward": 0.25608599185943604, "value_loss": 0.006655798386782407, "policy_loss": -0.0016463988708991905, "dist_entropy": 0.4592645227909088, "actor_grad_norm": 0.1132282242178917, "critic_grad_norm": 0.023739656433463097, "ratio": 1.0003042221069336, "entropy": 0.4592645227909088, "incre_win_rate": 0.8536585365853658, "step": 2571}
{"time": 1767091503.8753247, "phase": "train", "update": 2572, "total_env_steps": 8230400, "episode_reward": 0.25515055656433105, "value_loss": 0.006835598777979612, "policy_loss": -0.0012941033940080614, "dist_entropy": 0.4575441002845764, "actor_grad_norm": 0.11015881597995758, "critic_grad_norm": 0.03850683197379112, "ratio": 0.9998807907104492, "entropy": 0.4575441002845764, "incre_win_rate": 0.8043478260869565, "step": 2572}
{"time": 1767091508.508881, "phase": "train", "update": 2573, "total_env_steps": 8233600, "episode_reward": 0.2603802978992462, "value_loss": 0.006091500725597143, "policy_loss": -0.001565186132805252, "dist_entropy": 0.46999728083610537, "actor_grad_norm": 0.1165219321846962, "critic_grad_norm": 0.03900212049484253, "ratio": 1.0000277757644653, "entropy": 0.46999728083610537, "incre_win_rate": 0.9, "step": 2573}
{"time": 1767091513.079706, "phase": "train", "update": 2574, "total_env_steps": 8236800, "episode_reward": 0.261749804019928, "value_loss": 0.004865692090243101, "policy_loss": -0.0018366154326482586, "dist_entropy": 0.44698763489723203, "actor_grad_norm": 0.12569229304790497, "critic_grad_norm": 0.026495052501559258, "ratio": 0.999682605266571, "entropy": 0.44698763489723203, "incre_win_rate": 0.8444444444444444, "step": 2574}
{"time": 1767091517.7051423, "phase": "train", "update": 2575, "total_env_steps": 8240000, "episode_reward": 0.2579232156276703, "value_loss": 0.00554708456620574, "policy_loss": -0.0012058119452738937, "dist_entropy": 0.4423220694065094, "actor_grad_norm": 0.11236748844385147, "critic_grad_norm": 0.0464843325316906, "ratio": 0.999921441078186, "entropy": 0.4423220694065094, "incre_win_rate": 0.8095238095238095, "step": 2575}
{"time": 1767091522.337766, "phase": "train", "update": 2576, "total_env_steps": 8243200, "episode_reward": 0.24328693747520447, "value_loss": 0.008758377842605114, "policy_loss": -0.001664976176921229, "dist_entropy": 0.46150822639465333, "actor_grad_norm": 0.15056322515010834, "critic_grad_norm": 0.05655083805322647, "ratio": 1.0000929832458496, "entropy": 0.46150822639465333, "incre_win_rate": 0.7857142857142857, "step": 2576}
{"time": 1767091527.2987368, "phase": "train", "update": 2577, "total_env_steps": 8246400, "episode_reward": 0.2511734664440155, "value_loss": 0.008364700712263584, "policy_loss": -0.0015569935319945216, "dist_entropy": 0.44540812373161315, "actor_grad_norm": 0.1302875131368637, "critic_grad_norm": 0.03204342722892761, "ratio": 0.9996964335441589, "entropy": 0.44540812373161315, "incre_win_rate": 0.8095238095238095, "step": 2577}
{"time": 1767091532.2555416, "phase": "train", "update": 2578, "total_env_steps": 8249600, "episode_reward": 0.24803704023361206, "value_loss": 0.008102127723395825, "policy_loss": -0.001412010364025207, "dist_entropy": 0.4526421368122101, "actor_grad_norm": 0.12198751419782639, "critic_grad_norm": 0.061906225979328156, "ratio": 0.9997210502624512, "entropy": 0.4526421368122101, "incre_win_rate": 0.7560975609756098, "step": 2578}
{"time": 1767091537.468993, "phase": "train", "update": 2579, "total_env_steps": 8252800, "episode_reward": 0.2576179802417755, "value_loss": 0.005227400735020637, "policy_loss": -0.0015751096717359302, "dist_entropy": 0.42975214719772337, "actor_grad_norm": 0.1010272279381752, "critic_grad_norm": 0.05045458301901817, "ratio": 1.0001262426376343, "entropy": 0.42975214719772337, "incre_win_rate": 0.8043478260869565, "step": 2579}
{"time": 1767091542.2895796, "phase": "train", "update": 2580, "total_env_steps": 8256000, "episode_reward": 0.2603554427623749, "value_loss": 0.006519748922437429, "policy_loss": -0.001514236884243303, "dist_entropy": 0.43320977687835693, "actor_grad_norm": 0.134842187166214, "critic_grad_norm": 0.045653171837329865, "ratio": 0.9996978640556335, "entropy": 0.43320977687835693, "incre_win_rate": 0.8048780487804879, "step": 2580}
{"time": 1767091547.0587482, "phase": "train", "update": 2581, "total_env_steps": 8259200, "episode_reward": 0.2603062689304352, "value_loss": 0.006642053835093975, "policy_loss": -0.0018530232998756446, "dist_entropy": 0.43266298770904543, "actor_grad_norm": 0.14727053046226501, "critic_grad_norm": 0.034101709723472595, "ratio": 0.9997879266738892, "entropy": 0.43266298770904543, "incre_win_rate": 0.8863636363636364, "step": 2581}
{"time": 1767091559.1962469, "phase": "eval", "update": 2581, "total_env_steps": 8259200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.78652731788079, "step": 2581}
{"time": 1767091564.355154, "phase": "train", "update": 2582, "total_env_steps": 8262400, "episode_reward": 0.2494262307882309, "value_loss": 0.007500448729842901, "policy_loss": -0.0014699721492121398, "dist_entropy": 0.4288546860218048, "actor_grad_norm": 0.12052925676107407, "critic_grad_norm": 0.03726774826645851, "ratio": 1.0000721216201782, "entropy": 0.4288546860218048, "incre_win_rate": 0.7727272727272727, "step": 2582}
{"time": 1767091569.7444267, "phase": "train", "update": 2583, "total_env_steps": 8265600, "episode_reward": 0.26446712017059326, "value_loss": 0.004942607413977384, "policy_loss": -0.0019219399854968344, "dist_entropy": 0.4318496108055115, "actor_grad_norm": 0.10952088981866837, "critic_grad_norm": 0.047200363129377365, "ratio": 1.0000139474868774, "entropy": 0.4318496108055115, "incre_win_rate": 0.9024390243902439, "step": 2583}
{"time": 1767091574.6981957, "phase": "train", "update": 2584, "total_env_steps": 8268800, "episode_reward": 0.250751256942749, "value_loss": 0.007001161575317383, "policy_loss": -0.0014868127812803777, "dist_entropy": 0.4537132799625397, "actor_grad_norm": 0.0933031439781189, "critic_grad_norm": 0.038248445838689804, "ratio": 0.9996682405471802, "entropy": 0.4537132799625397, "incre_win_rate": 0.8863636363636364, "step": 2584}
{"time": 1767091579.3648796, "phase": "train", "update": 2585, "total_env_steps": 8272000, "episode_reward": 0.25353217124938965, "value_loss": 0.008113174699246883, "policy_loss": -0.0012790036119611158, "dist_entropy": 0.43655826449394225, "actor_grad_norm": 0.09282483905553818, "critic_grad_norm": 0.03346893936395645, "ratio": 1.0001835823059082, "entropy": 0.43655826449394225, "incre_win_rate": 0.7073170731707317, "step": 2585}
{"time": 1767091584.0414977, "phase": "train", "update": 2586, "total_env_steps": 8275200, "episode_reward": 0.22822175920009613, "value_loss": 0.010088249668478965, "policy_loss": -0.0012396631406559778, "dist_entropy": 0.44220286011695864, "actor_grad_norm": 0.11066603660583496, "critic_grad_norm": 0.03712163865566254, "ratio": 0.9994456171989441, "entropy": 0.44220286011695864, "incre_win_rate": 0.6590909090909091, "step": 2586}
{"time": 1767091588.8227277, "phase": "train", "update": 2587, "total_env_steps": 8278400, "episode_reward": 0.23328176140785217, "value_loss": 0.007459865603595972, "policy_loss": -0.0016260335128229996, "dist_entropy": 0.4500654637813568, "actor_grad_norm": 0.12485835701227188, "critic_grad_norm": 0.0376351997256279, "ratio": 1.0002130270004272, "entropy": 0.4500654637813568, "incre_win_rate": 0.7777777777777778, "step": 2587}
{"time": 1767091593.659152, "phase": "train", "update": 2588, "total_env_steps": 8281600, "episode_reward": 0.26013195514678955, "value_loss": 0.005370206106454134, "policy_loss": -0.0017560840212961892, "dist_entropy": 0.43671722412109376, "actor_grad_norm": 0.1372525542974472, "critic_grad_norm": 0.03945539519190788, "ratio": 0.9999088644981384, "entropy": 0.43671722412109376, "incre_win_rate": 0.8863636363636364, "step": 2588}
{"time": 1767091598.7063527, "phase": "train", "update": 2589, "total_env_steps": 8284800, "episode_reward": 0.271263986825943, "value_loss": 0.004603076633065939, "policy_loss": -0.0011616609971653701, "dist_entropy": 0.4264936804771423, "actor_grad_norm": 0.10557476431131363, "critic_grad_norm": 0.060969896614551544, "ratio": 1.0000090599060059, "entropy": 0.4264936804771423, "incre_win_rate": 0.9545454545454546, "step": 2589}
{"time": 1767091603.414333, "phase": "train", "update": 2590, "total_env_steps": 8288000, "episode_reward": 0.2617575526237488, "value_loss": 0.005387891363352537, "policy_loss": -0.0014738854441390004, "dist_entropy": 0.4241275429725647, "actor_grad_norm": 0.11579908430576324, "critic_grad_norm": 0.03634033724665642, "ratio": 0.9997795224189758, "entropy": 0.4241275429725647, "incre_win_rate": 0.8604651162790697, "step": 2590}
{"time": 1767091608.0435562, "phase": "train", "update": 2591, "total_env_steps": 8291200, "episode_reward": 0.24837438762187958, "value_loss": 0.009207944013178348, "policy_loss": -0.0015341889770004614, "dist_entropy": 0.438581770658493, "actor_grad_norm": 0.13730546832084656, "critic_grad_norm": 0.06123082712292671, "ratio": 0.9997221827507019, "entropy": 0.438581770658493, "incre_win_rate": 0.8048780487804879, "step": 2591}
{"time": 1767091612.6708434, "phase": "train", "update": 2592, "total_env_steps": 8294400, "episode_reward": 0.25221386551856995, "value_loss": 0.005582042038440704, "policy_loss": -0.0013160926994004285, "dist_entropy": 0.4330963730812073, "actor_grad_norm": 0.12084390968084335, "critic_grad_norm": 0.06286919116973877, "ratio": 0.9998036623001099, "entropy": 0.4330963730812073, "incre_win_rate": 0.8444444444444444, "step": 2592}
{"time": 1767091617.4273434, "phase": "train", "update": 2593, "total_env_steps": 8297600, "episode_reward": 0.2340143918991089, "value_loss": 0.008219145331531763, "policy_loss": -0.001397052351118333, "dist_entropy": 0.4259438455104828, "actor_grad_norm": 0.1400303840637207, "critic_grad_norm": 0.09664304554462433, "ratio": 0.9997769594192505, "entropy": 0.4259438455104828, "incre_win_rate": 0.5897435897435898, "step": 2593}
{"time": 1767091622.2772443, "phase": "train", "update": 2594, "total_env_steps": 8300800, "episode_reward": 0.24379657208919525, "value_loss": 0.00850336104631424, "policy_loss": -0.0014406712699255309, "dist_entropy": 0.4304990112781525, "actor_grad_norm": 0.1524703949689865, "critic_grad_norm": 0.07440955191850662, "ratio": 0.9995338320732117, "entropy": 0.4304990112781525, "incre_win_rate": 0.7142857142857143, "step": 2594}
{"time": 1767091627.003401, "phase": "train", "update": 2595, "total_env_steps": 8304000, "episode_reward": 0.25110772252082825, "value_loss": 0.0076912431046366695, "policy_loss": -0.0010591710493145002, "dist_entropy": 0.43194336295127866, "actor_grad_norm": 0.1466054469347, "critic_grad_norm": 0.042243603616952896, "ratio": 0.9999176263809204, "entropy": 0.43194336295127866, "incre_win_rate": 0.7209302325581395, "step": 2595}
{"time": 1767091631.829289, "phase": "train", "update": 2596, "total_env_steps": 8307200, "episode_reward": 0.25146162509918213, "value_loss": 0.006987949926406145, "policy_loss": -0.0016121734933008725, "dist_entropy": 0.4378420114517212, "actor_grad_norm": 0.11801093071699142, "critic_grad_norm": 0.030935494229197502, "ratio": 0.9998159408569336, "entropy": 0.4378420114517212, "incre_win_rate": 0.6888888888888889, "step": 2596}
{"time": 1767091636.6192958, "phase": "train", "update": 2597, "total_env_steps": 8310400, "episode_reward": 0.25814464688301086, "value_loss": 0.008632052689790726, "policy_loss": -0.0014106414735977069, "dist_entropy": 0.44696228504180907, "actor_grad_norm": 0.1323915719985962, "critic_grad_norm": 0.05220142751932144, "ratio": 1.0002259016036987, "entropy": 0.44696228504180907, "incre_win_rate": 0.7391304347826086, "step": 2597}
{"time": 1767091641.2441719, "phase": "train", "update": 2598, "total_env_steps": 8313600, "episode_reward": 0.2531772553920746, "value_loss": 0.007447216100990773, "policy_loss": -0.0011280261536292357, "dist_entropy": 0.4385253608226776, "actor_grad_norm": 0.14698931574821472, "critic_grad_norm": 0.03871208429336548, "ratio": 1.0002257823944092, "entropy": 0.4385253608226776, "incre_win_rate": 0.7317073170731707, "step": 2598}
{"time": 1767091645.8748114, "phase": "train", "update": 2599, "total_env_steps": 8316800, "episode_reward": 0.2528130114078522, "value_loss": 0.008470478281378747, "policy_loss": -0.0017688082564035312, "dist_entropy": 0.4442165970802307, "actor_grad_norm": 0.1275538057088852, "critic_grad_norm": 0.0259602852165699, "ratio": 0.9997121095657349, "entropy": 0.4442165970802307, "incre_win_rate": 0.723404255319149, "step": 2599}
{"time": 1767091650.604912, "phase": "train", "update": 2600, "total_env_steps": 8320000, "episode_reward": 0.26087334752082825, "value_loss": 0.008273066952824593, "policy_loss": -0.0014651725682924166, "dist_entropy": 0.44005764126777647, "actor_grad_norm": 0.12923821806907654, "critic_grad_norm": 0.019595693796873093, "ratio": 0.9998855590820312, "entropy": 0.44005764126777647, "incre_win_rate": 0.7674418604651163, "step": 2600}
{"time": 1767091655.3990507, "phase": "train", "update": 2601, "total_env_steps": 8323200, "episode_reward": 0.24844837188720703, "value_loss": 0.007218791544437409, "policy_loss": -0.0015234290154424457, "dist_entropy": 0.4488226413726807, "actor_grad_norm": 0.11350550502538681, "critic_grad_norm": 0.024268267676234245, "ratio": 0.9997928738594055, "entropy": 0.4488226413726807, "incre_win_rate": 0.7948717948717948, "step": 2601}
{"time": 1767091666.6421387, "phase": "eval", "update": 2601, "total_env_steps": 8323200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.903145695364238, "step": 2601}
{"time": 1767091671.6960616, "phase": "train", "update": 2602, "total_env_steps": 8326400, "episode_reward": 0.2723209857940674, "value_loss": 0.0046286540105938915, "policy_loss": -0.0012842076342650444, "dist_entropy": 0.4415071964263916, "actor_grad_norm": 0.09606336057186127, "critic_grad_norm": 0.0380464605987072, "ratio": 0.9995668530464172, "entropy": 0.4415071964263916, "incre_win_rate": 0.9574468085106383, "step": 2602}
{"time": 1767091676.5852435, "phase": "train", "update": 2603, "total_env_steps": 8329600, "episode_reward": 0.2571968138217926, "value_loss": 0.007595892995595932, "policy_loss": -0.0017751073049907973, "dist_entropy": 0.43368529081344603, "actor_grad_norm": 0.14103154838085175, "critic_grad_norm": 0.02265562303364277, "ratio": 0.9998350143432617, "entropy": 0.43368529081344603, "incre_win_rate": 0.7857142857142857, "step": 2603}
{"time": 1767091681.3055263, "phase": "train", "update": 2604, "total_env_steps": 8332800, "episode_reward": 0.2360057830810547, "value_loss": 0.005734867509454488, "policy_loss": -0.0017077348996615172, "dist_entropy": 0.44368923306465147, "actor_grad_norm": 0.16092973947525024, "critic_grad_norm": 0.03344995900988579, "ratio": 0.9998907446861267, "entropy": 0.44368923306465147, "incre_win_rate": 0.7560975609756098, "step": 2604}
{"time": 1767091685.9509795, "phase": "train", "update": 2605, "total_env_steps": 8336000, "episode_reward": 0.25457629561424255, "value_loss": 0.006992882024496794, "policy_loss": -0.0014417156241336216, "dist_entropy": 0.4333839416503906, "actor_grad_norm": 0.11209332197904587, "critic_grad_norm": 0.045341771095991135, "ratio": 0.9997984766960144, "entropy": 0.4333839416503906, "incre_win_rate": 0.813953488372093, "step": 2605}
{"time": 1767091690.8017817, "phase": "train", "update": 2606, "total_env_steps": 8339200, "episode_reward": 0.26028043031692505, "value_loss": 0.006233212444931269, "policy_loss": -0.0015347714216630947, "dist_entropy": 0.4387629747390747, "actor_grad_norm": 0.1441594511270523, "critic_grad_norm": 0.03900490328669548, "ratio": 1.0000134706497192, "entropy": 0.4387629747390747, "incre_win_rate": 0.8095238095238095, "step": 2606}
{"time": 1767091695.7892008, "phase": "train", "update": 2607, "total_env_steps": 8342400, "episode_reward": 0.2596130073070526, "value_loss": 0.007626336440443993, "policy_loss": -0.0015241890700540494, "dist_entropy": 0.44835970997810365, "actor_grad_norm": 0.12372592836618423, "critic_grad_norm": 0.02828875556588173, "ratio": 0.999921977519989, "entropy": 0.44835970997810365, "incre_win_rate": 0.8222222222222222, "step": 2607}
{"time": 1767091700.5310786, "phase": "train", "update": 2608, "total_env_steps": 8345600, "episode_reward": 0.2410099357366562, "value_loss": 0.00691749956458807, "policy_loss": -0.0015931052394709156, "dist_entropy": 0.4473012924194336, "actor_grad_norm": 0.13183103501796722, "critic_grad_norm": 0.034981243312358856, "ratio": 0.9998583793640137, "entropy": 0.4473012924194336, "incre_win_rate": 0.7209302325581395, "step": 2608}
{"time": 1767091705.1894073, "phase": "train", "update": 2609, "total_env_steps": 8348800, "episode_reward": 0.23303188383579254, "value_loss": 0.0079952672123909, "policy_loss": -0.001319123014516066, "dist_entropy": 0.4523021697998047, "actor_grad_norm": 0.12511619925498962, "critic_grad_norm": 0.034831441938877106, "ratio": 0.9999021887779236, "entropy": 0.4523021697998047, "incre_win_rate": 0.7631578947368421, "step": 2609}
{"time": 1767091710.3409753, "phase": "train", "update": 2610, "total_env_steps": 8352000, "episode_reward": 0.24530267715454102, "value_loss": 0.007428533304482699, "policy_loss": -0.0013040258155548657, "dist_entropy": 0.4421552777290344, "actor_grad_norm": 0.12123095244169235, "critic_grad_norm": 0.03247179836034775, "ratio": 1.0002788305282593, "entropy": 0.4421552777290344, "incre_win_rate": 0.7142857142857143, "step": 2610}
{"time": 1767091715.2741952, "phase": "train", "update": 2611, "total_env_steps": 8355200, "episode_reward": 0.24705559015274048, "value_loss": 0.005596422962844372, "policy_loss": -0.0012887513192026746, "dist_entropy": 0.4516618847846985, "actor_grad_norm": 0.10608440637588501, "critic_grad_norm": 0.027468541637063026, "ratio": 0.9997607469558716, "entropy": 0.4516618847846985, "incre_win_rate": 0.6904761904761905, "step": 2611}
{"time": 1767091720.0722435, "phase": "train", "update": 2612, "total_env_steps": 8358400, "episode_reward": 0.24637830257415771, "value_loss": 0.006416700687259436, "policy_loss": -0.0012576051478319528, "dist_entropy": 0.448110967874527, "actor_grad_norm": 0.11650016158819199, "critic_grad_norm": 0.023665282875299454, "ratio": 0.9998197555541992, "entropy": 0.448110967874527, "incre_win_rate": 0.7857142857142857, "step": 2612}
{"time": 1767091724.8971882, "phase": "train", "update": 2613, "total_env_steps": 8361600, "episode_reward": 0.2663193643093109, "value_loss": 0.0054618771187961105, "policy_loss": -0.0016494184355131836, "dist_entropy": 0.4504045367240906, "actor_grad_norm": 0.1229325532913208, "critic_grad_norm": 0.03350940719246864, "ratio": 1.0000978708267212, "entropy": 0.4504045367240906, "incre_win_rate": 0.8181818181818182, "step": 2613}
{"time": 1767091729.687224, "phase": "train", "update": 2614, "total_env_steps": 8364800, "episode_reward": 0.2332155555486679, "value_loss": 0.008349791914224625, "policy_loss": -0.0017750145246921533, "dist_entropy": 0.4401382505893707, "actor_grad_norm": 0.10509903728961945, "critic_grad_norm": 0.05432729795575142, "ratio": 0.9999109506607056, "entropy": 0.4401382505893707, "incre_win_rate": 0.6585365853658537, "step": 2614}
{"time": 1767091769.4933424, "phase": "train", "update": 2615, "total_env_steps": 8368000, "episode_reward": 0.23349803686141968, "value_loss": 0.04788344949483871, "policy_loss": -0.001457831422320055, "dist_entropy": 0.4605419397354126, "actor_grad_norm": 0.1018424779176712, "critic_grad_norm": 0.2000693380832672, "ratio": 1.0001829862594604, "entropy": 0.4605419397354126, "incre_win_rate": 0.725, "step": 2615}
{"time": 1767091774.5255675, "phase": "train", "update": 2616, "total_env_steps": 8371200, "episode_reward": 0.2472376823425293, "value_loss": 0.007933315262198449, "policy_loss": -0.0017775509352457419, "dist_entropy": 0.45990635752677916, "actor_grad_norm": 0.10733914375305176, "critic_grad_norm": 0.11911644786596298, "ratio": 0.9999247789382935, "entropy": 0.45990635752677916, "incre_win_rate": 0.65, "step": 2616}
{"time": 1767091779.0951772, "phase": "train", "update": 2617, "total_env_steps": 8374400, "episode_reward": 0.2503621578216553, "value_loss": 0.008068851754069328, "policy_loss": -0.0017828933223330346, "dist_entropy": 0.4703804075717926, "actor_grad_norm": 0.1694154143333435, "critic_grad_norm": 0.08724822849035263, "ratio": 1.0000355243682861, "entropy": 0.4703804075717926, "incre_win_rate": 0.7954545454545454, "step": 2617}
{"time": 1767091783.7438662, "phase": "train", "update": 2618, "total_env_steps": 8377600, "episode_reward": 0.2577333152294159, "value_loss": 0.008486244082450866, "policy_loss": -0.0018607251644187528, "dist_entropy": 0.45412707328796387, "actor_grad_norm": 0.11607997864484787, "critic_grad_norm": 0.057276736944913864, "ratio": 0.9998987317085266, "entropy": 0.45412707328796387, "incre_win_rate": 0.8181818181818182, "step": 2618}
{"time": 1767091788.410686, "phase": "train", "update": 2619, "total_env_steps": 8380800, "episode_reward": 0.25253209471702576, "value_loss": 0.007966373208910226, "policy_loss": -0.0019716857163558643, "dist_entropy": 0.451508492231369, "actor_grad_norm": 0.1399180293083191, "critic_grad_norm": 0.03738139197230339, "ratio": 0.9999033212661743, "entropy": 0.451508492231369, "incre_win_rate": 0.8048780487804879, "step": 2619}
{"time": 1767091792.9886608, "phase": "train", "update": 2620, "total_env_steps": 8384000, "episode_reward": 0.2509762942790985, "value_loss": 0.005592784099280834, "policy_loss": -0.0018912963417065498, "dist_entropy": 0.4752024054527283, "actor_grad_norm": 0.12270158529281616, "critic_grad_norm": 0.020698880776762962, "ratio": 1.0000839233398438, "entropy": 0.4752024054527283, "incre_win_rate": 0.8333333333333334, "step": 2620}
{"time": 1767091797.5681374, "phase": "train", "update": 2621, "total_env_steps": 8387200, "episode_reward": 0.2550279498100281, "value_loss": 0.007878123223781586, "policy_loss": -0.002124972511823131, "dist_entropy": 0.4418234646320343, "actor_grad_norm": 0.13948078453540802, "critic_grad_norm": 0.03235610947012901, "ratio": 0.9999130368232727, "entropy": 0.4418234646320343, "incre_win_rate": 0.7674418604651163, "step": 2621}
{"time": 1767091808.3792832, "phase": "eval", "update": 2621, "total_env_steps": 8387200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.59690604304636, "step": 2621}
{"time": 1767091812.919374, "phase": "train", "update": 2622, "total_env_steps": 8390400, "episode_reward": 0.25633642077445984, "value_loss": 0.004960477538406849, "policy_loss": -0.001293673711541743, "dist_entropy": 0.4540455400943756, "actor_grad_norm": 0.14529094099998474, "critic_grad_norm": 0.03661094233393669, "ratio": 1.0001827478408813, "entropy": 0.4540455400943756, "incre_win_rate": 0.8536585365853658, "step": 2622}
{"time": 1767091817.6332905, "phase": "train", "update": 2623, "total_env_steps": 8393600, "episode_reward": 0.2592291235923767, "value_loss": 0.006349991261959076, "policy_loss": -0.0017813172735230865, "dist_entropy": 0.453734415769577, "actor_grad_norm": 0.15515410900115967, "critic_grad_norm": 0.02943907491862774, "ratio": 1.0002434253692627, "entropy": 0.453734415769577, "incre_win_rate": 0.8695652173913043, "step": 2623}
{"time": 1767091822.5313678, "phase": "train", "update": 2624, "total_env_steps": 8396800, "episode_reward": 0.24879087507724762, "value_loss": 0.006642224825918674, "policy_loss": -0.001766274696126402, "dist_entropy": 0.45200122594833375, "actor_grad_norm": 0.11677638441324234, "critic_grad_norm": 0.0313376784324646, "ratio": 0.9999961853027344, "entropy": 0.45200122594833375, "incre_win_rate": 0.7560975609756098, "step": 2624}
{"time": 1767091827.11671, "phase": "train", "update": 2625, "total_env_steps": 8400000, "episode_reward": 0.24701832234859467, "value_loss": 0.006145377922803163, "policy_loss": -0.0016605762493981046, "dist_entropy": 0.4621796190738678, "actor_grad_norm": 0.12466523796319962, "critic_grad_norm": 0.03650099039077759, "ratio": 0.9998720288276672, "entropy": 0.4621796190738678, "incre_win_rate": 0.7857142857142857, "step": 2625}
{"time": 1767091831.8078258, "phase": "train", "update": 2626, "total_env_steps": 8403200, "episode_reward": 0.2574881315231323, "value_loss": 0.005733238253742457, "policy_loss": -0.001588014653869152, "dist_entropy": 0.4449250757694244, "actor_grad_norm": 0.10969489067792892, "critic_grad_norm": 0.046504270285367966, "ratio": 1.0001405477523804, "entropy": 0.4449250757694244, "incre_win_rate": 0.8333333333333334, "step": 2626}
{"time": 1767091836.7718205, "phase": "train", "update": 2627, "total_env_steps": 8406400, "episode_reward": 0.25329574942588806, "value_loss": 0.007581307180225849, "policy_loss": -0.0014371888005557665, "dist_entropy": 0.459948855638504, "actor_grad_norm": 0.13111546635627747, "critic_grad_norm": 0.03851526603102684, "ratio": 1.0000180006027222, "entropy": 0.459948855638504, "incre_win_rate": 0.7857142857142857, "step": 2627}
{"time": 1767091841.6110651, "phase": "train", "update": 2628, "total_env_steps": 8409600, "episode_reward": 0.25380122661590576, "value_loss": 0.005871706735342741, "policy_loss": -0.0013553765057537693, "dist_entropy": 0.45185247659683225, "actor_grad_norm": 0.13108262419700623, "critic_grad_norm": 0.056951869279146194, "ratio": 0.9999163746833801, "entropy": 0.45185247659683225, "incre_win_rate": 0.7391304347826086, "step": 2628}
{"time": 1767091846.633312, "phase": "train", "update": 2629, "total_env_steps": 8412800, "episode_reward": 0.2463638186454773, "value_loss": 0.007735109236091375, "policy_loss": -0.0013422106743007588, "dist_entropy": 0.4432683289051056, "actor_grad_norm": 0.10726826637983322, "critic_grad_norm": 0.03945127874612808, "ratio": 1.000405192375183, "entropy": 0.4432683289051056, "incre_win_rate": 0.775, "step": 2629}
{"time": 1767091851.2846828, "phase": "train", "update": 2630, "total_env_steps": 8416000, "episode_reward": 0.23652061820030212, "value_loss": 0.009658299945294857, "policy_loss": -0.0018557764438682511, "dist_entropy": 0.4747125685214996, "actor_grad_norm": 0.14015668630599976, "critic_grad_norm": 0.04090685397386551, "ratio": 0.9999611973762512, "entropy": 0.4747125685214996, "incre_win_rate": 0.775, "step": 2630}
{"time": 1767091855.9250321, "phase": "train", "update": 2631, "total_env_steps": 8419200, "episode_reward": 0.2675129175186157, "value_loss": 0.0046236786991357805, "policy_loss": -0.0015550630747583228, "dist_entropy": 0.4494858801364899, "actor_grad_norm": 0.14503882825374603, "critic_grad_norm": 0.03199943155050278, "ratio": 0.9998874664306641, "entropy": 0.4494858801364899, "incre_win_rate": 0.8636363636363636, "step": 2631}
{"time": 1767091860.5437596, "phase": "train", "update": 2632, "total_env_steps": 8422400, "episode_reward": 0.2582041621208191, "value_loss": 0.00567644378170371, "policy_loss": -0.001799350532391486, "dist_entropy": 0.45900753140449524, "actor_grad_norm": 0.1367817372083664, "critic_grad_norm": 0.03511166200041771, "ratio": 0.9996508955955505, "entropy": 0.45900753140449524, "incre_win_rate": 0.8444444444444444, "step": 2632}
{"time": 1767091865.1585937, "phase": "train", "update": 2633, "total_env_steps": 8425600, "episode_reward": 0.23935844004154205, "value_loss": 0.00875354241579771, "policy_loss": -0.001673271682167865, "dist_entropy": 0.4570626974105835, "actor_grad_norm": 0.12344882637262344, "critic_grad_norm": 0.05781536176800728, "ratio": 0.9998587965965271, "entropy": 0.4570626974105835, "incre_win_rate": 0.6190476190476191, "step": 2633}
{"time": 1767091869.7988646, "phase": "train", "update": 2634, "total_env_steps": 8428800, "episode_reward": 0.2677271068096161, "value_loss": 0.007151383068412542, "policy_loss": -0.001508584857552364, "dist_entropy": 0.47569175362586974, "actor_grad_norm": 0.13055865466594696, "critic_grad_norm": 0.04675928130745888, "ratio": 0.9996680617332458, "entropy": 0.47569175362586974, "incre_win_rate": 0.9069767441860465, "step": 2634}
{"time": 1767091874.6028368, "phase": "train", "update": 2635, "total_env_steps": 8432000, "episode_reward": 0.2594453692436218, "value_loss": 0.009190038777887821, "policy_loss": -0.001667983905041126, "dist_entropy": 0.46090750098228456, "actor_grad_norm": 0.10941918939352036, "critic_grad_norm": 0.047561343759298325, "ratio": 0.9997871518135071, "entropy": 0.46090750098228456, "incre_win_rate": 0.7555555555555555, "step": 2635}
{"time": 1767091879.5116274, "phase": "train", "update": 2636, "total_env_steps": 8435200, "episode_reward": 0.2563689947128296, "value_loss": 0.006693404540419579, "policy_loss": -0.0014753194100507016, "dist_entropy": 0.45372194647789, "actor_grad_norm": 0.15018592774868011, "critic_grad_norm": 0.03958961367607117, "ratio": 0.9999732971191406, "entropy": 0.45372194647789, "incre_win_rate": 0.75, "step": 2636}
{"time": 1767091884.1302865, "phase": "train", "update": 2637, "total_env_steps": 8438400, "episode_reward": 0.25253620743751526, "value_loss": 0.006920508481562138, "policy_loss": -0.0018300174560721416, "dist_entropy": 0.46634751558303833, "actor_grad_norm": 0.11486267298460007, "critic_grad_norm": 0.028447775170207024, "ratio": 1.0000993013381958, "entropy": 0.46634751558303833, "incre_win_rate": 0.8095238095238095, "step": 2637}
{"time": 1767091888.68961, "phase": "train", "update": 2638, "total_env_steps": 8441600, "episode_reward": 0.2567306458950043, "value_loss": 0.0065923046320676805, "policy_loss": -0.002023510189805222, "dist_entropy": 0.485467267036438, "actor_grad_norm": 0.13115297257900238, "critic_grad_norm": 0.02588026225566864, "ratio": 0.9994126558303833, "entropy": 0.485467267036438, "incre_win_rate": 0.8372093023255814, "step": 2638}
{"time": 1767091893.3092484, "phase": "train", "update": 2639, "total_env_steps": 8444800, "episode_reward": 0.2543434500694275, "value_loss": 0.005282624904066324, "policy_loss": -0.001622394695472451, "dist_entropy": 0.4710934519767761, "actor_grad_norm": 0.2096181958913803, "critic_grad_norm": 0.010763964615762234, "ratio": 0.9992498755455017, "entropy": 0.4710934519767761, "incre_win_rate": 0.813953488372093, "step": 2639}
{"time": 1767091897.8855057, "phase": "train", "update": 2640, "total_env_steps": 8448000, "episode_reward": 0.24797342717647552, "value_loss": 0.0038619365077465773, "policy_loss": -0.001321382530607451, "dist_entropy": 0.47574421763420105, "actor_grad_norm": 0.1721348613500595, "critic_grad_norm": 0.021556207910180092, "ratio": 0.9999788403511047, "entropy": 0.47574421763420105, "incre_win_rate": 0.8048780487804879, "step": 2640}
{"time": 1767091902.5219915, "phase": "train", "update": 2641, "total_env_steps": 8451200, "episode_reward": 0.2568693161010742, "value_loss": 0.004677730891853571, "policy_loss": -0.001652591727596242, "dist_entropy": 0.47469399571418763, "actor_grad_norm": 0.16271786391735077, "critic_grad_norm": 0.01905466429889202, "ratio": 1.0000663995742798, "entropy": 0.47469399571418763, "incre_win_rate": 0.8333333333333334, "step": 2641}
{"time": 1767091913.0859442, "phase": "eval", "update": 2641, "total_env_steps": 8451200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.838731374172184, "step": 2641}
{"time": 1767091917.7413266, "phase": "train", "update": 2642, "total_env_steps": 8454400, "episode_reward": 0.2575739920139313, "value_loss": 0.0056255685165524484, "policy_loss": -0.001379055386487238, "dist_entropy": 0.4589210212230682, "actor_grad_norm": 0.13795305788516998, "critic_grad_norm": 0.014663397334516048, "ratio": 0.9999410510063171, "entropy": 0.4589210212230682, "incre_win_rate": 0.8372093023255814, "step": 2642}
{"time": 1767091922.7401524, "phase": "train", "update": 2643, "total_env_steps": 8457600, "episode_reward": 0.25611135363578796, "value_loss": 0.005006242264062166, "policy_loss": -0.001558244345151749, "dist_entropy": 0.4549530684947968, "actor_grad_norm": 0.10033579915761948, "critic_grad_norm": 0.013069571927189827, "ratio": 0.9999462366104126, "entropy": 0.4549530684947968, "incre_win_rate": 0.8536585365853658, "step": 2643}
{"time": 1767091927.4389374, "phase": "train", "update": 2644, "total_env_steps": 8460800, "episode_reward": 0.2603425085544586, "value_loss": 0.004920864570885896, "policy_loss": -0.0015634178719338364, "dist_entropy": 0.4534378290176392, "actor_grad_norm": 0.13363686203956604, "critic_grad_norm": 0.01839551329612732, "ratio": 0.9997537732124329, "entropy": 0.4534378290176392, "incre_win_rate": 0.8837209302325582, "step": 2644}
{"time": 1767091932.3159397, "phase": "train", "update": 2645, "total_env_steps": 8464000, "episode_reward": 0.2623841166496277, "value_loss": 0.006099045742303133, "policy_loss": -0.0016038887092378218, "dist_entropy": 0.4568069577217102, "actor_grad_norm": 0.14013536274433136, "critic_grad_norm": 0.018641402944922447, "ratio": 0.9995004534721375, "entropy": 0.4568069577217102, "incre_win_rate": 0.8444444444444444, "step": 2645}
{"time": 1767091936.9054637, "phase": "train", "update": 2646, "total_env_steps": 8467200, "episode_reward": 0.2526707351207733, "value_loss": 0.007464366778731346, "policy_loss": -0.0018134114271617819, "dist_entropy": 0.462053644657135, "actor_grad_norm": 0.15088380873203278, "critic_grad_norm": 0.03573852404952049, "ratio": 1.000030279159546, "entropy": 0.462053644657135, "incre_win_rate": 0.7142857142857143, "step": 2646}
{"time": 1767091941.7096982, "phase": "train", "update": 2647, "total_env_steps": 8470400, "episode_reward": 0.2600889801979065, "value_loss": 0.008849305845797063, "policy_loss": -0.0014224572293485948, "dist_entropy": 0.4472486972808838, "actor_grad_norm": 0.17448000609874725, "critic_grad_norm": 0.03379393368959427, "ratio": 0.9998754858970642, "entropy": 0.4472486972808838, "incre_win_rate": 0.7777777777777778, "step": 2647}
{"time": 1767091946.655194, "phase": "train", "update": 2648, "total_env_steps": 8473600, "episode_reward": 0.27030888199806213, "value_loss": 0.005385649111121893, "policy_loss": -0.0016319608278237752, "dist_entropy": 0.4581788659095764, "actor_grad_norm": 0.12328644841909409, "critic_grad_norm": 0.015772247686982155, "ratio": 0.999926745891571, "entropy": 0.4581788659095764, "incre_win_rate": 0.8936170212765957, "step": 2648}
{"time": 1767091951.7286892, "phase": "train", "update": 2649, "total_env_steps": 8476800, "episode_reward": 0.27041855454444885, "value_loss": 0.00689683360978961, "policy_loss": -0.0016893985849552706, "dist_entropy": 0.4577442228794098, "actor_grad_norm": 0.16033177077770233, "critic_grad_norm": 0.02191327139735222, "ratio": 1.0000096559524536, "entropy": 0.4577442228794098, "incre_win_rate": 0.9047619047619048, "step": 2649}
{"time": 1767091956.8628113, "phase": "train", "update": 2650, "total_env_steps": 8480000, "episode_reward": 0.25832006335258484, "value_loss": 0.005008529033511877, "policy_loss": -0.0018272306844313135, "dist_entropy": 0.4689188301563263, "actor_grad_norm": 0.11163754761219025, "critic_grad_norm": 0.020691391080617905, "ratio": 1.0003703832626343, "entropy": 0.4689188301563263, "incre_win_rate": 0.8333333333333334, "step": 2650}
{"time": 1767091961.6587398, "phase": "train", "update": 2651, "total_env_steps": 8483200, "episode_reward": 0.2658578157424927, "value_loss": 0.00533425323665142, "policy_loss": -0.0017371871279523888, "dist_entropy": 0.4626236081123352, "actor_grad_norm": 0.10956986993551254, "critic_grad_norm": 0.01720794476568699, "ratio": 0.9998049736022949, "entropy": 0.4626236081123352, "incre_win_rate": 0.8666666666666667, "step": 2651}
{"time": 1767091966.4812121, "phase": "train", "update": 2652, "total_env_steps": 8486400, "episode_reward": 0.2612660527229309, "value_loss": 0.00522783100605011, "policy_loss": -0.0016087913407847765, "dist_entropy": 0.4626125693321228, "actor_grad_norm": 0.11236969381570816, "critic_grad_norm": 0.02010689675807953, "ratio": 0.9999366998672485, "entropy": 0.4626125693321228, "incre_win_rate": 0.8636363636363636, "step": 2652}
{"time": 1767091971.0156593, "phase": "train", "update": 2653, "total_env_steps": 8489600, "episode_reward": 0.26760968565940857, "value_loss": 0.006084768380969763, "policy_loss": -0.0017207225400657222, "dist_entropy": 0.4488557815551758, "actor_grad_norm": 0.14766843616962433, "critic_grad_norm": 0.055955447256565094, "ratio": 0.9996744990348816, "entropy": 0.4488557815551758, "incre_win_rate": 0.8837209302325582, "step": 2653}
{"time": 1767091975.664765, "phase": "train", "update": 2654, "total_env_steps": 8492800, "episode_reward": 0.2668977677822113, "value_loss": 0.005010270886123181, "policy_loss": -0.0014468263365671418, "dist_entropy": 0.45169842839241026, "actor_grad_norm": 0.12863574922084808, "critic_grad_norm": 0.044910978525877, "ratio": 1.0000555515289307, "entropy": 0.45169842839241026, "incre_win_rate": 0.9318181818181818, "step": 2654}
{"time": 1767091980.2792475, "phase": "train", "update": 2655, "total_env_steps": 8496000, "episode_reward": 0.2577255666255951, "value_loss": 0.004758008196949959, "policy_loss": -0.0014240378790702835, "dist_entropy": 0.45501349568367006, "actor_grad_norm": 0.13441981375217438, "critic_grad_norm": 0.026886655017733574, "ratio": 0.9999475479125977, "entropy": 0.45501349568367006, "incre_win_rate": 0.7954545454545454, "step": 2655}
{"time": 1767091984.909066, "phase": "train", "update": 2656, "total_env_steps": 8499200, "episode_reward": 0.26229098439216614, "value_loss": 0.0069970452226698395, "policy_loss": -0.0013558372056706957, "dist_entropy": 0.44911985397338866, "actor_grad_norm": 0.15171031653881073, "critic_grad_norm": 0.06418344378471375, "ratio": 1.0002217292785645, "entropy": 0.44911985397338866, "incre_win_rate": 0.813953488372093, "step": 2656}
{"time": 1767091989.545145, "phase": "train", "update": 2657, "total_env_steps": 8502400, "episode_reward": 0.25192779302597046, "value_loss": 0.00851456206291914, "policy_loss": -0.0015093724925490549, "dist_entropy": 0.4456202626228333, "actor_grad_norm": 0.13961680233478546, "critic_grad_norm": 0.06126981973648071, "ratio": 1.0001853704452515, "entropy": 0.4456202626228333, "incre_win_rate": 0.7857142857142857, "step": 2657}
{"time": 1767091994.470513, "phase": "train", "update": 2658, "total_env_steps": 8505600, "episode_reward": 0.2505044639110565, "value_loss": 0.007795158959925175, "policy_loss": -0.0016020678746639482, "dist_entropy": 0.4383958637714386, "actor_grad_norm": 0.14171181619167328, "critic_grad_norm": 0.031172795221209526, "ratio": 1.0000677108764648, "entropy": 0.4383958637714386, "incre_win_rate": 0.6363636363636364, "step": 2658}
{"time": 1767091999.035308, "phase": "train", "update": 2659, "total_env_steps": 8508800, "episode_reward": 0.24866360425949097, "value_loss": 0.006153131183236837, "policy_loss": -0.0017053625704278375, "dist_entropy": 0.45938795804977417, "actor_grad_norm": 0.15625129640102386, "critic_grad_norm": 0.039097800850868225, "ratio": 1.000104546546936, "entropy": 0.45938795804977417, "incre_win_rate": 0.7674418604651163, "step": 2659}
{"time": 1767092003.723681, "phase": "train", "update": 2660, "total_env_steps": 8512000, "episode_reward": 0.26621636748313904, "value_loss": 0.005030703637748957, "policy_loss": -0.001632621152938185, "dist_entropy": 0.4651136636734009, "actor_grad_norm": 0.1667851060628891, "critic_grad_norm": 0.048364680260419846, "ratio": 0.9995939135551453, "entropy": 0.4651136636734009, "incre_win_rate": 0.8222222222222222, "step": 2660}
{"time": 1767092008.3545702, "phase": "train", "update": 2661, "total_env_steps": 8515200, "episode_reward": 0.24482204020023346, "value_loss": 0.008008776977658272, "policy_loss": -0.0016796646504730005, "dist_entropy": 0.45818703770637514, "actor_grad_norm": 0.15919511020183563, "critic_grad_norm": 0.10988036543130875, "ratio": 0.9996965527534485, "entropy": 0.45818703770637514, "incre_win_rate": 0.7380952380952381, "step": 2661}
{"time": 1767092019.306823, "phase": "eval", "update": 2661, "total_env_steps": 8515200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.48499586092715, "step": 2661}
{"time": 1767092023.9016762, "phase": "train", "update": 2662, "total_env_steps": 8518400, "episode_reward": 0.2441597729921341, "value_loss": 0.008195162285119295, "policy_loss": -0.0015683167928230545, "dist_entropy": 0.4566422700881958, "actor_grad_norm": 0.1293495148420334, "critic_grad_norm": 0.06880519539117813, "ratio": 0.9999483227729797, "entropy": 0.4566422700881958, "incre_win_rate": 0.7804878048780488, "step": 2662}
{"time": 1767092028.5573916, "phase": "train", "update": 2663, "total_env_steps": 8521600, "episode_reward": 0.27269452810287476, "value_loss": 0.005063872784376144, "policy_loss": -0.0012337252856731596, "dist_entropy": 0.44807056784629823, "actor_grad_norm": 0.11788065731525421, "critic_grad_norm": 0.06964464485645294, "ratio": 0.9996005892753601, "entropy": 0.44807056784629823, "incre_win_rate": 0.9130434782608695, "step": 2663}
{"time": 1767092033.394103, "phase": "train", "update": 2664, "total_env_steps": 8524800, "episode_reward": 0.270101934671402, "value_loss": 0.003310352796688676, "policy_loss": -0.0016965312368498076, "dist_entropy": 0.4573442280292511, "actor_grad_norm": 0.09417535364627838, "critic_grad_norm": 0.023754779249429703, "ratio": 0.9998432397842407, "entropy": 0.4573442280292511, "incre_win_rate": 0.9069767441860465, "step": 2664}
{"time": 1767092038.0691266, "phase": "train", "update": 2665, "total_env_steps": 8528000, "episode_reward": 0.2629905045032501, "value_loss": 0.00436731269583106, "policy_loss": -0.0013278023258155968, "dist_entropy": 0.4432590425014496, "actor_grad_norm": 0.194981649518013, "critic_grad_norm": 0.021022027358412743, "ratio": 1.0001676082611084, "entropy": 0.4432590425014496, "incre_win_rate": 0.8863636363636364, "step": 2665}
{"time": 1767092042.6388717, "phase": "train", "update": 2666, "total_env_steps": 8531200, "episode_reward": 0.2663120925426483, "value_loss": 0.005481324717402458, "policy_loss": -0.0020618273726128677, "dist_entropy": 0.4438077986240387, "actor_grad_norm": 0.13001064956188202, "critic_grad_norm": 0.019478505477309227, "ratio": 0.9998674392700195, "entropy": 0.4438077986240387, "incre_win_rate": 0.8636363636363636, "step": 2666}
{"time": 1767092047.274028, "phase": "train", "update": 2667, "total_env_steps": 8534400, "episode_reward": 0.2663933038711548, "value_loss": 0.006095551233738661, "policy_loss": -0.001308580246957547, "dist_entropy": 0.4545046091079712, "actor_grad_norm": 0.14670024812221527, "critic_grad_norm": 0.013294631615281105, "ratio": 0.999882698059082, "entropy": 0.4545046091079712, "incre_win_rate": 0.8604651162790697, "step": 2667}
{"time": 1767092051.9397657, "phase": "train", "update": 2668, "total_env_steps": 8537600, "episode_reward": 0.2618139684200287, "value_loss": 0.00696345129981637, "policy_loss": -0.0015931829678514475, "dist_entropy": 0.45428590178489686, "actor_grad_norm": 0.16499657928943634, "critic_grad_norm": 0.02756388857960701, "ratio": 1.0001319646835327, "entropy": 0.45428590178489686, "incre_win_rate": 0.8478260869565217, "step": 2668}
{"time": 1767092056.8955028, "phase": "train", "update": 2669, "total_env_steps": 8540800, "episode_reward": 0.2616758346557617, "value_loss": 0.006614084262400866, "policy_loss": -0.001620371412427346, "dist_entropy": 0.45636666417121885, "actor_grad_norm": 0.1194298043847084, "critic_grad_norm": 0.018294377252459526, "ratio": 0.9999966621398926, "entropy": 0.45636666417121885, "incre_win_rate": 0.8372093023255814, "step": 2669}
{"time": 1767092061.4815931, "phase": "train", "update": 2670, "total_env_steps": 8544000, "episode_reward": 0.26733702421188354, "value_loss": 0.004500891175121069, "policy_loss": -0.0014549428773733553, "dist_entropy": 0.46074665188789365, "actor_grad_norm": 0.12442012876272202, "critic_grad_norm": 0.01673225872218609, "ratio": 1.0001157522201538, "entropy": 0.46074665188789365, "incre_win_rate": 0.9069767441860465, "step": 2670}
{"time": 1767092066.0880837, "phase": "train", "update": 2671, "total_env_steps": 8547200, "episode_reward": 0.2595824897289276, "value_loss": 0.005245813634246588, "policy_loss": -0.0018757190889665764, "dist_entropy": 0.45113399624824524, "actor_grad_norm": 0.1679835021495819, "critic_grad_norm": 0.022328734397888184, "ratio": 1.0004560947418213, "entropy": 0.45113399624824524, "incre_win_rate": 0.8, "step": 2671}
{"time": 1767092070.5914025, "phase": "train", "update": 2672, "total_env_steps": 8550400, "episode_reward": 0.25885969400405884, "value_loss": 0.005544821545481682, "policy_loss": -0.001595385308618802, "dist_entropy": 0.4419156014919281, "actor_grad_norm": 0.17707860469818115, "critic_grad_norm": 0.021098926663398743, "ratio": 1.0004390478134155, "entropy": 0.4419156014919281, "incre_win_rate": 0.8333333333333334, "step": 2672}
{"time": 1767092075.1969895, "phase": "train", "update": 2673, "total_env_steps": 8553600, "episode_reward": 0.2582119107246399, "value_loss": 0.005824081506580115, "policy_loss": -0.001617681610102295, "dist_entropy": 0.45535832047462466, "actor_grad_norm": 0.13690119981765747, "critic_grad_norm": 0.01081651821732521, "ratio": 0.999904453754425, "entropy": 0.45535832047462466, "incre_win_rate": 0.813953488372093, "step": 2673}
{"time": 1767092079.802236, "phase": "train", "update": 2674, "total_env_steps": 8556800, "episode_reward": 0.25095096230506897, "value_loss": 0.007542066369205713, "policy_loss": -0.0019678719876708326, "dist_entropy": 0.4583126425743103, "actor_grad_norm": 0.12499415874481201, "critic_grad_norm": 0.020208904519677162, "ratio": 0.9997305274009705, "entropy": 0.4583126425743103, "incre_win_rate": 0.7906976744186046, "step": 2674}
{"time": 1767092084.4193108, "phase": "train", "update": 2675, "total_env_steps": 8560000, "episode_reward": 0.25562191009521484, "value_loss": 0.005494900234043598, "policy_loss": -0.0020912382624402428, "dist_entropy": 0.4562281906604767, "actor_grad_norm": 0.12893567979335785, "critic_grad_norm": 0.03314777836203575, "ratio": 0.999783456325531, "entropy": 0.4562281906604767, "incre_win_rate": 0.813953488372093, "step": 2675}
{"time": 1767092089.1414168, "phase": "train", "update": 2676, "total_env_steps": 8563200, "episode_reward": 0.2542368471622467, "value_loss": 0.007274662237614393, "policy_loss": -0.0016235865520656035, "dist_entropy": 0.4496158242225647, "actor_grad_norm": 0.13139477372169495, "critic_grad_norm": 0.03816339373588562, "ratio": 1.000195860862732, "entropy": 0.4496158242225647, "incre_win_rate": 0.8095238095238095, "step": 2676}
{"time": 1767092093.7016, "phase": "train", "update": 2677, "total_env_steps": 8566400, "episode_reward": 0.26052308082580566, "value_loss": 0.00541958436369896, "policy_loss": -0.0017513682350376314, "dist_entropy": 0.4624006271362305, "actor_grad_norm": 0.1356246918439865, "critic_grad_norm": 0.032885897904634476, "ratio": 1.0001691579818726, "entropy": 0.4624006271362305, "incre_win_rate": 0.8837209302325582, "step": 2677}
{"time": 1767092098.6302073, "phase": "train", "update": 2678, "total_env_steps": 8569600, "episode_reward": 0.2598189115524292, "value_loss": 0.005023275874555111, "policy_loss": -0.0017985969141680158, "dist_entropy": 0.4677156627178192, "actor_grad_norm": 0.11083394289016724, "critic_grad_norm": 0.029405126348137856, "ratio": 0.9998341798782349, "entropy": 0.4677156627178192, "incre_win_rate": 0.8372093023255814, "step": 2678}
{"time": 1767092103.4670134, "phase": "train", "update": 2679, "total_env_steps": 8572800, "episode_reward": 0.27093905210494995, "value_loss": 0.004212253540754318, "policy_loss": -0.0017129066107621326, "dist_entropy": 0.46605242490768434, "actor_grad_norm": 0.1503300964832306, "critic_grad_norm": 0.031700294464826584, "ratio": 1.000054955482483, "entropy": 0.46605242490768434, "incre_win_rate": 0.9333333333333333, "step": 2679}
{"time": 1767092108.1456916, "phase": "train", "update": 2680, "total_env_steps": 8576000, "episode_reward": 0.2679423391819, "value_loss": 0.004011882981285453, "policy_loss": -0.001658655429153555, "dist_entropy": 0.4617907524108887, "actor_grad_norm": 0.16798043251037598, "critic_grad_norm": 0.026464378461241722, "ratio": 0.9997017979621887, "entropy": 0.4617907524108887, "incre_win_rate": 0.9069767441860465, "step": 2680}
{"time": 1767092113.0762258, "phase": "train", "update": 2681, "total_env_steps": 8579200, "episode_reward": 0.2577405869960785, "value_loss": 0.005200187116861344, "policy_loss": -0.0016911280875518742, "dist_entropy": 0.4606330096721649, "actor_grad_norm": 0.19913546741008759, "critic_grad_norm": 0.03001761995255947, "ratio": 0.9996709823608398, "entropy": 0.4606330096721649, "incre_win_rate": 0.7727272727272727, "step": 2681}
{"time": 1767092124.5147607, "phase": "eval", "update": 2681, "total_env_steps": 8579200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.843594784768207, "step": 2681}
{"time": 1767092129.3372548, "phase": "train", "update": 2682, "total_env_steps": 8582400, "episode_reward": 0.2498437464237213, "value_loss": 0.0073208496905863285, "policy_loss": -0.0018580431175749367, "dist_entropy": 0.4557558596134186, "actor_grad_norm": 0.1955658346414566, "critic_grad_norm": 0.04496133327484131, "ratio": 0.9999181032180786, "entropy": 0.4557558596134186, "incre_win_rate": 0.813953488372093, "step": 2682}
{"time": 1767092133.994801, "phase": "train", "update": 2683, "total_env_steps": 8585600, "episode_reward": 0.2673194408416748, "value_loss": 0.005058907810598612, "policy_loss": -0.0019716928955702427, "dist_entropy": 0.44892617464065554, "actor_grad_norm": 0.17573487758636475, "critic_grad_norm": 0.056825485080480576, "ratio": 0.9996488690376282, "entropy": 0.44892617464065554, "incre_win_rate": 0.9285714285714286, "step": 2683}
{"time": 1767092138.856777, "phase": "train", "update": 2684, "total_env_steps": 8588800, "episode_reward": 0.2570219337940216, "value_loss": 0.00626622661948204, "policy_loss": -0.0014222871860990693, "dist_entropy": 0.46539401412010195, "actor_grad_norm": 0.2905079126358032, "critic_grad_norm": 0.0430670790374279, "ratio": 0.9998335838317871, "entropy": 0.46539401412010195, "incre_win_rate": 0.8260869565217391, "step": 2684}
{"time": 1767092144.1692495, "phase": "train", "update": 2685, "total_env_steps": 8592000, "episode_reward": 0.24571608006954193, "value_loss": 0.008752255141735077, "policy_loss": -0.0018661602234658404, "dist_entropy": 0.44886749386787417, "actor_grad_norm": 0.1864306926727295, "critic_grad_norm": 0.027879342436790466, "ratio": 0.9998565912246704, "entropy": 0.44886749386787417, "incre_win_rate": 0.8, "step": 2685}
{"time": 1767092149.9397123, "phase": "train", "update": 2686, "total_env_steps": 8595200, "episode_reward": 0.2545778155326843, "value_loss": 0.005399355664849281, "policy_loss": -0.0020904406107476346, "dist_entropy": 0.4481381833553314, "actor_grad_norm": 0.16156291961669922, "critic_grad_norm": 0.029903141781687737, "ratio": 0.9998407363891602, "entropy": 0.4481381833553314, "incre_win_rate": 0.8292682926829268, "step": 2686}
{"time": 1767092154.7758362, "phase": "train", "update": 2687, "total_env_steps": 8598400, "episode_reward": 0.2548075318336487, "value_loss": 0.0057358467020094395, "policy_loss": -0.0016345918636034185, "dist_entropy": 0.4519926249980927, "actor_grad_norm": 0.1433924436569214, "critic_grad_norm": 0.023204170167446136, "ratio": 1.0004971027374268, "entropy": 0.4519926249980927, "incre_win_rate": 0.7906976744186046, "step": 2687}
{"time": 1767092159.4971836, "phase": "train", "update": 2688, "total_env_steps": 8601600, "episode_reward": 0.26591527462005615, "value_loss": 0.006072998698800802, "policy_loss": -0.0015183859369813034, "dist_entropy": 0.45326476693153384, "actor_grad_norm": 0.1629725694656372, "critic_grad_norm": 0.022565850988030434, "ratio": 1.0000715255737305, "entropy": 0.45326476693153384, "incre_win_rate": 0.8863636363636364, "step": 2688}
{"time": 1767092164.371043, "phase": "train", "update": 2689, "total_env_steps": 8604800, "episode_reward": 0.2634809613227844, "value_loss": 0.004997954145073891, "policy_loss": -0.0015973852273251765, "dist_entropy": 0.4512757658958435, "actor_grad_norm": 0.11197929829359055, "critic_grad_norm": 0.016709834337234497, "ratio": 0.9999869465827942, "entropy": 0.4512757658958435, "incre_win_rate": 0.9090909090909091, "step": 2689}
{"time": 1767092169.0912147, "phase": "train", "update": 2690, "total_env_steps": 8608000, "episode_reward": 0.2623158097267151, "value_loss": 0.00457307118922472, "policy_loss": -0.001730813982679802, "dist_entropy": 0.4586981534957886, "actor_grad_norm": 0.11822061985731125, "critic_grad_norm": 0.016294045373797417, "ratio": 1.0000146627426147, "entropy": 0.4586981534957886, "incre_win_rate": 0.9024390243902439, "step": 2690}
{"time": 1767092173.8877268, "phase": "train", "update": 2691, "total_env_steps": 8611200, "episode_reward": 0.24252121150493622, "value_loss": 0.007583098858594895, "policy_loss": -0.0014549193458549326, "dist_entropy": 0.458220899105072, "actor_grad_norm": 0.13016414642333984, "critic_grad_norm": 0.07498545199632645, "ratio": 0.9995803833007812, "entropy": 0.458220899105072, "incre_win_rate": 0.7441860465116279, "step": 2691}
{"time": 1767092178.626387, "phase": "train", "update": 2692, "total_env_steps": 8614400, "episode_reward": 0.2649229168891907, "value_loss": 0.0044607861898839475, "policy_loss": -0.001545423685912084, "dist_entropy": 0.45849254727363586, "actor_grad_norm": 0.12184502184391022, "critic_grad_norm": 0.06457983702421188, "ratio": 0.9998611807823181, "entropy": 0.45849254727363586, "incre_win_rate": 0.8863636363636364, "step": 2692}
{"time": 1767092183.2792964, "phase": "train", "update": 2693, "total_env_steps": 8617600, "episode_reward": 0.2493729144334793, "value_loss": 0.009393261931836604, "policy_loss": -0.0015583440845603036, "dist_entropy": 0.4594418525695801, "actor_grad_norm": 0.12356603145599365, "critic_grad_norm": 0.06059669330716133, "ratio": 0.9995515942573547, "entropy": 0.4594418525695801, "incre_win_rate": 0.7209302325581395, "step": 2693}
{"time": 1767092188.0963721, "phase": "train", "update": 2694, "total_env_steps": 8620800, "episode_reward": 0.2558402121067047, "value_loss": 0.0065028793178498745, "policy_loss": -0.001882514458181106, "dist_entropy": 0.4744706153869629, "actor_grad_norm": 0.1135236993432045, "critic_grad_norm": 0.04365239664912224, "ratio": 0.9999001622200012, "entropy": 0.4744706153869629, "incre_win_rate": 0.8095238095238095, "step": 2694}
{"time": 1767092192.7026207, "phase": "train", "update": 2695, "total_env_steps": 8624000, "episode_reward": 0.2463628053665161, "value_loss": 0.0071904190815985205, "policy_loss": -0.002119526916632708, "dist_entropy": 0.46217923164367675, "actor_grad_norm": 0.14739444851875305, "critic_grad_norm": 0.04128996282815933, "ratio": 0.9997817873954773, "entropy": 0.46217923164367675, "incre_win_rate": 0.6818181818181818, "step": 2695}
{"time": 1767092197.304893, "phase": "train", "update": 2696, "total_env_steps": 8627200, "episode_reward": 0.24918615818023682, "value_loss": 0.0061012102290987965, "policy_loss": -0.0017579860678310411, "dist_entropy": 0.46092302799224855, "actor_grad_norm": 0.13696150481700897, "critic_grad_norm": 0.03742373734712601, "ratio": 0.9994560480117798, "entropy": 0.46092302799224855, "incre_win_rate": 0.7804878048780488, "step": 2696}
{"time": 1767092201.9684975, "phase": "train", "update": 2697, "total_env_steps": 8630400, "episode_reward": 0.26379862427711487, "value_loss": 0.0033881393261253833, "policy_loss": -0.001687517381770931, "dist_entropy": 0.4573294878005981, "actor_grad_norm": 0.1312795728445053, "critic_grad_norm": 0.056337881833314896, "ratio": 0.9997739195823669, "entropy": 0.4573294878005981, "incre_win_rate": 0.9069767441860465, "step": 2697}
{"time": 1767092206.6668992, "phase": "train", "update": 2698, "total_env_steps": 8633600, "episode_reward": 0.2580592632293701, "value_loss": 0.0063545994460582735, "policy_loss": -0.0019045389035227344, "dist_entropy": 0.4661548912525177, "actor_grad_norm": 0.13359101116657257, "critic_grad_norm": 0.034974467009305954, "ratio": 0.9999266862869263, "entropy": 0.4661548912525177, "incre_win_rate": 0.8604651162790697, "step": 2698}
{"time": 1767092211.5622983, "phase": "train", "update": 2699, "total_env_steps": 8636800, "episode_reward": 0.26604098081588745, "value_loss": 0.0032718558330088856, "policy_loss": -0.0015840197015364766, "dist_entropy": 0.4665218949317932, "actor_grad_norm": 0.16165292263031006, "critic_grad_norm": 0.035278718918561935, "ratio": 0.9996277093887329, "entropy": 0.4665218949317932, "incre_win_rate": 0.9318181818181818, "step": 2699}
{"time": 1767092216.4014952, "phase": "train", "update": 2700, "total_env_steps": 8640000, "episode_reward": 0.2659545838832855, "value_loss": 0.003278352366760373, "policy_loss": -0.0016934256399878222, "dist_entropy": 0.4788446187973022, "actor_grad_norm": 0.1335175484418869, "critic_grad_norm": 0.02823968604207039, "ratio": 1.0001204013824463, "entropy": 0.4788446187973022, "incre_win_rate": 0.9512195121951219, "step": 2700}
{"time": 1767092221.2745733, "phase": "train", "update": 2701, "total_env_steps": 8643200, "episode_reward": 0.2618657052516937, "value_loss": 0.004929241444915533, "policy_loss": -0.001577109564068735, "dist_entropy": 0.4570251703262329, "actor_grad_norm": 0.1389038860797882, "critic_grad_norm": 0.029844442382454872, "ratio": 0.9998180270195007, "entropy": 0.4570251703262329, "incre_win_rate": 0.8444444444444444, "step": 2701}
{"time": 1767092232.7876537, "phase": "eval", "update": 2701, "total_env_steps": 8643200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.843077400662253, "step": 2701}
{"time": 1767092238.1382759, "phase": "train", "update": 2702, "total_env_steps": 8646400, "episode_reward": 0.2618972659111023, "value_loss": 0.005553897935897112, "policy_loss": -0.0016706312347750441, "dist_entropy": 0.46555750370025634, "actor_grad_norm": 0.15188519656658173, "critic_grad_norm": 0.0278546754270792, "ratio": 1.000130534172058, "entropy": 0.46555750370025634, "incre_win_rate": 0.8372093023255814, "step": 2702}
{"time": 1767092242.666242, "phase": "train", "update": 2703, "total_env_steps": 8649600, "episode_reward": 0.26072537899017334, "value_loss": 0.0037788691464811564, "policy_loss": -0.0014589419188183682, "dist_entropy": 0.46938601732254026, "actor_grad_norm": 0.13541850447654724, "critic_grad_norm": 0.025283679366111755, "ratio": 1.000008463859558, "entropy": 0.46938601732254026, "incre_win_rate": 0.9285714285714286, "step": 2703}
{"time": 1767092248.1978843, "phase": "train", "update": 2704, "total_env_steps": 8652800, "episode_reward": 0.2578088939189911, "value_loss": 0.003920154692605138, "policy_loss": -0.001847287100186179, "dist_entropy": 0.46328256726264955, "actor_grad_norm": 0.14615581929683685, "critic_grad_norm": 0.02292630821466446, "ratio": 0.9996713995933533, "entropy": 0.46328256726264955, "incre_win_rate": 0.9047619047619048, "step": 2704}
{"time": 1767092253.1478407, "phase": "train", "update": 2705, "total_env_steps": 8656000, "episode_reward": 0.2574136257171631, "value_loss": 0.0030228490941226482, "policy_loss": -0.0014033599537455644, "dist_entropy": 0.4677399218082428, "actor_grad_norm": 0.13725748658180237, "critic_grad_norm": 0.036200109869241714, "ratio": 1.0001472234725952, "entropy": 0.4677399218082428, "incre_win_rate": 0.9069767441860465, "step": 2705}
{"time": 1767092257.958712, "phase": "train", "update": 2706, "total_env_steps": 8659200, "episode_reward": 0.254262238740921, "value_loss": 0.0043560944497585295, "policy_loss": -0.0020631241473989094, "dist_entropy": 0.475797700881958, "actor_grad_norm": 0.13708680868148804, "critic_grad_norm": 0.040555961430072784, "ratio": 0.9998461008071899, "entropy": 0.475797700881958, "incre_win_rate": 0.8571428571428571, "step": 2706}
{"time": 1767092262.972629, "phase": "train", "update": 2707, "total_env_steps": 8662400, "episode_reward": 0.2535911798477173, "value_loss": 0.004081103019416332, "policy_loss": -0.001889356280268828, "dist_entropy": 0.4922423899173737, "actor_grad_norm": 0.11358437687158585, "critic_grad_norm": 0.03195904940366745, "ratio": 1.0002835988998413, "entropy": 0.4922423899173737, "incre_win_rate": 0.925, "step": 2707}
{"time": 1767092267.9372163, "phase": "train", "update": 2708, "total_env_steps": 8665600, "episode_reward": 0.25690916180610657, "value_loss": 0.005405659973621369, "policy_loss": -0.0016666614849281558, "dist_entropy": 0.4641807734966278, "actor_grad_norm": 0.10315995663404465, "critic_grad_norm": 0.016852054744958878, "ratio": 0.9998993277549744, "entropy": 0.4641807734966278, "incre_win_rate": 0.8571428571428571, "step": 2708}
{"time": 1767092272.6139348, "phase": "train", "update": 2709, "total_env_steps": 8668800, "episode_reward": 0.26256880164146423, "value_loss": 0.004017806611955166, "policy_loss": -0.002068788578407066, "dist_entropy": 0.4694062054157257, "actor_grad_norm": 0.14338946342468262, "critic_grad_norm": 0.03226497769355774, "ratio": 0.9996216893196106, "entropy": 0.4694062054157257, "incre_win_rate": 0.8666666666666667, "step": 2709}
{"time": 1767092277.3354921, "phase": "train", "update": 2710, "total_env_steps": 8672000, "episode_reward": 0.26856890320777893, "value_loss": 0.002115952456369996, "policy_loss": -0.0015810365323893905, "dist_entropy": 0.4599542796611786, "actor_grad_norm": 0.13184140622615814, "critic_grad_norm": 0.03957366943359375, "ratio": 1.000173807144165, "entropy": 0.4599542796611786, "incre_win_rate": 0.9534883720930233, "step": 2710}
{"time": 1767092281.9477856, "phase": "train", "update": 2711, "total_env_steps": 8675200, "episode_reward": 0.2625698447227478, "value_loss": 0.005396929383277893, "policy_loss": -0.001866085739555956, "dist_entropy": 0.47332216501235963, "actor_grad_norm": 0.1281031221151352, "critic_grad_norm": 0.03120618872344494, "ratio": 0.9996461868286133, "entropy": 0.47332216501235963, "incre_win_rate": 0.8809523809523809, "step": 2711}
{"time": 1767092286.496883, "phase": "train", "update": 2712, "total_env_steps": 8678400, "episode_reward": 0.26007866859436035, "value_loss": 0.006368997599929571, "policy_loss": -0.0019197113472237959, "dist_entropy": 0.4720567584037781, "actor_grad_norm": 0.14795106649398804, "critic_grad_norm": 0.027672434225678444, "ratio": 1.0000768899917603, "entropy": 0.4720567584037781, "incre_win_rate": 0.8913043478260869, "step": 2712}
{"time": 1767092291.1591146, "phase": "train", "update": 2713, "total_env_steps": 8681600, "episode_reward": 0.2627633810043335, "value_loss": 0.0051441465504467486, "policy_loss": -0.0015878198817169675, "dist_entropy": 0.4788311779499054, "actor_grad_norm": 0.12323029339313507, "critic_grad_norm": 0.018074356019496918, "ratio": 1.0000351667404175, "entropy": 0.4788311779499054, "incre_win_rate": 0.926829268292683, "step": 2713}
{"time": 1767092295.7075415, "phase": "train", "update": 2714, "total_env_steps": 8684800, "episode_reward": 0.2561548054218292, "value_loss": 0.004488777834922075, "policy_loss": -0.0017485823274260071, "dist_entropy": 0.4817002534866333, "actor_grad_norm": 0.1250714212656021, "critic_grad_norm": 0.018042897805571556, "ratio": 1.0003644227981567, "entropy": 0.4817002534866333, "incre_win_rate": 0.8372093023255814, "step": 2714}
{"time": 1767092300.3192608, "phase": "train", "update": 2715, "total_env_steps": 8688000, "episode_reward": 0.26917529106140137, "value_loss": 0.003924560220912099, "policy_loss": -0.001539742342712458, "dist_entropy": 0.47924564480781556, "actor_grad_norm": 0.1578139215707779, "critic_grad_norm": 0.018758997321128845, "ratio": 0.9996590614318848, "entropy": 0.47924564480781556, "incre_win_rate": 0.8863636363636364, "step": 2715}
{"time": 1767092304.9215145, "phase": "train", "update": 2716, "total_env_steps": 8691200, "episode_reward": 0.264309287071228, "value_loss": 0.003643366601318121, "policy_loss": -0.001968708734337099, "dist_entropy": 0.4856034815311432, "actor_grad_norm": 0.10692830383777618, "critic_grad_norm": 0.010999740101397038, "ratio": 1.0000767707824707, "entropy": 0.4856034815311432, "incre_win_rate": 0.8863636363636364, "step": 2716}
{"time": 1767092309.6005776, "phase": "train", "update": 2717, "total_env_steps": 8694400, "episode_reward": 0.2695353925228119, "value_loss": 0.0026546740438789128, "policy_loss": -0.00156741601709669, "dist_entropy": 0.4905573487281799, "actor_grad_norm": 0.12162232398986816, "critic_grad_norm": 0.02533916011452675, "ratio": 0.9998008012771606, "entropy": 0.4905573487281799, "incre_win_rate": 0.9523809523809523, "step": 2717}
{"time": 1767092314.115331, "phase": "train", "update": 2718, "total_env_steps": 8697600, "episode_reward": 0.2716354429721832, "value_loss": 0.003661998314782977, "policy_loss": -0.002162150181748501, "dist_entropy": 0.4879820644855499, "actor_grad_norm": 0.14110800623893738, "critic_grad_norm": 0.03588087856769562, "ratio": 1.0001335144042969, "entropy": 0.4879820644855499, "incre_win_rate": 0.9555555555555556, "step": 2718}
{"time": 1767092318.7554147, "phase": "train", "update": 2719, "total_env_steps": 8700800, "episode_reward": 0.2591991126537323, "value_loss": 0.005352921411395073, "policy_loss": -0.0018571620833824909, "dist_entropy": 0.5022395133972168, "actor_grad_norm": 0.1419738382101059, "critic_grad_norm": 0.039775457233190536, "ratio": 0.9999438524246216, "entropy": 0.5022395133972168, "incre_win_rate": 0.8409090909090909, "step": 2719}
{"time": 1767092323.5278106, "phase": "train", "update": 2720, "total_env_steps": 8704000, "episode_reward": 0.2557026147842407, "value_loss": 0.004310770984739065, "policy_loss": -0.0018699549280675853, "dist_entropy": 0.48605703711509707, "actor_grad_norm": 0.15279291570186615, "critic_grad_norm": 0.022862566635012627, "ratio": 1.0002658367156982, "entropy": 0.48605703711509707, "incre_win_rate": 0.8095238095238095, "step": 2720}
{"time": 1767092328.5437036, "phase": "train", "update": 2721, "total_env_steps": 8707200, "episode_reward": 0.2551065981388092, "value_loss": 0.004498987272381782, "policy_loss": -0.0015190932249566913, "dist_entropy": 0.5074503064155579, "actor_grad_norm": 0.14923304319381714, "critic_grad_norm": 0.018980801105499268, "ratio": 0.9998258948326111, "entropy": 0.5074503064155579, "incre_win_rate": 0.8604651162790697, "step": 2721}
{"time": 1767092339.140576, "phase": "eval", "update": 2721, "total_env_steps": 8707200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.85533940397351, "step": 2721}
{"time": 1767092343.726052, "phase": "train", "update": 2722, "total_env_steps": 8710400, "episode_reward": 0.2681053578853607, "value_loss": 0.004248692467808723, "policy_loss": -0.0018196392948439666, "dist_entropy": 0.49443084597587583, "actor_grad_norm": 0.13778051733970642, "critic_grad_norm": 0.013745916076004505, "ratio": 0.999768078327179, "entropy": 0.49443084597587583, "incre_win_rate": 0.8837209302325582, "step": 2722}
{"time": 1767092348.2956862, "phase": "train", "update": 2723, "total_env_steps": 8713600, "episode_reward": 0.2552390396595001, "value_loss": 0.00624488964676857, "policy_loss": -0.001970087950881805, "dist_entropy": 0.4951310932636261, "actor_grad_norm": 0.14926914870738983, "critic_grad_norm": 0.04564714804291725, "ratio": 1.000139594078064, "entropy": 0.4951310932636261, "incre_win_rate": 0.813953488372093, "step": 2723}
{"time": 1767092352.8681493, "phase": "train", "update": 2724, "total_env_steps": 8716800, "episode_reward": 0.24279078841209412, "value_loss": 0.009599391929805278, "policy_loss": -0.0017488834152345589, "dist_entropy": 0.49428576827049253, "actor_grad_norm": 0.11370857805013657, "critic_grad_norm": 0.05617743358016014, "ratio": 0.9999659657478333, "entropy": 0.49428576827049253, "incre_win_rate": 0.7142857142857143, "step": 2724}
{"time": 1767092357.3986406, "phase": "train", "update": 2725, "total_env_steps": 8720000, "episode_reward": 0.2418832927942276, "value_loss": 0.007261175382882357, "policy_loss": -0.002008471814362878, "dist_entropy": 0.4899589538574219, "actor_grad_norm": 0.18010878562927246, "critic_grad_norm": 0.055568575859069824, "ratio": 0.9997812509536743, "entropy": 0.4899589538574219, "incre_win_rate": 0.7142857142857143, "step": 2725}
{"time": 1767092361.9623246, "phase": "train", "update": 2726, "total_env_steps": 8723200, "episode_reward": 0.25134211778640747, "value_loss": 0.007091806828975677, "policy_loss": -0.0016757980813437712, "dist_entropy": 0.48882657289505005, "actor_grad_norm": 0.14172503352165222, "critic_grad_norm": 0.0540817454457283, "ratio": 1.0001477003097534, "entropy": 0.48882657289505005, "incre_win_rate": 0.7857142857142857, "step": 2726}
{"time": 1767092366.5143216, "phase": "train", "update": 2727, "total_env_steps": 8726400, "episode_reward": 0.24618014693260193, "value_loss": 0.00545744076371193, "policy_loss": -0.00191859911574781, "dist_entropy": 0.5304678797721862, "actor_grad_norm": 0.20300403237342834, "critic_grad_norm": 0.021328603848814964, "ratio": 0.999534547328949, "entropy": 0.5304678797721862, "incre_win_rate": 0.8048780487804879, "step": 2727}
{"time": 1767092371.085243, "phase": "train", "update": 2728, "total_env_steps": 8729600, "episode_reward": 0.24954210221767426, "value_loss": 0.004963943921029568, "policy_loss": -0.0019262542889407542, "dist_entropy": 0.5090517401695251, "actor_grad_norm": 0.17999103665351868, "critic_grad_norm": 0.014027828350663185, "ratio": 0.9996089935302734, "entropy": 0.5090517401695251, "incre_win_rate": 0.7804878048780488, "step": 2728}
{"time": 1767092375.6058602, "phase": "train", "update": 2729, "total_env_steps": 8732800, "episode_reward": 0.23601098358631134, "value_loss": 0.011684839054942131, "policy_loss": -0.002201719176009931, "dist_entropy": 0.5282849907875061, "actor_grad_norm": 0.19671817123889923, "critic_grad_norm": 0.08668723702430725, "ratio": 0.999656617641449, "entropy": 0.5282849907875061, "incre_win_rate": 0.7209302325581395, "step": 2729}
{"time": 1767092380.1714077, "phase": "train", "update": 2730, "total_env_steps": 8736000, "episode_reward": 0.23888814449310303, "value_loss": 0.008921454846858978, "policy_loss": -0.0016852516055962496, "dist_entropy": 0.4971547365188599, "actor_grad_norm": 0.17875553667545319, "critic_grad_norm": 0.055937718600034714, "ratio": 0.9997528195381165, "entropy": 0.4971547365188599, "incre_win_rate": 0.5853658536585366, "step": 2730}
{"time": 1767092384.7391634, "phase": "train", "update": 2731, "total_env_steps": 8739200, "episode_reward": 0.24516969919204712, "value_loss": 0.007925641257315874, "policy_loss": -0.0015955601664817466, "dist_entropy": 0.5088077545166015, "actor_grad_norm": 0.21101084351539612, "critic_grad_norm": 0.03867033123970032, "ratio": 0.9995383620262146, "entropy": 0.5088077545166015, "incre_win_rate": 0.7380952380952381, "step": 2731}
{"time": 1767092389.3458476, "phase": "train", "update": 2732, "total_env_steps": 8742400, "episode_reward": 0.25005900859832764, "value_loss": 0.006648793630301952, "policy_loss": -0.0017357599270070522, "dist_entropy": 0.503515648841858, "actor_grad_norm": 0.17015336453914642, "critic_grad_norm": 0.04270477220416069, "ratio": 1.0003575086593628, "entropy": 0.503515648841858, "incre_win_rate": 0.7906976744186046, "step": 2732}
{"time": 1767092393.8643954, "phase": "train", "update": 2733, "total_env_steps": 8745600, "episode_reward": 0.250082790851593, "value_loss": 0.006606025062501431, "policy_loss": -0.001823863368751688, "dist_entropy": 0.5051888227462769, "actor_grad_norm": 0.1260257065296173, "critic_grad_norm": 0.03350706398487091, "ratio": 1.0002899169921875, "entropy": 0.5051888227462769, "incre_win_rate": 0.7674418604651163, "step": 2733}
{"time": 1767092398.4016721, "phase": "train", "update": 2734, "total_env_steps": 8748800, "episode_reward": 0.25561726093292236, "value_loss": 0.006943753641098738, "policy_loss": -0.0017911080298567584, "dist_entropy": 0.4976056575775146, "actor_grad_norm": 0.13001297414302826, "critic_grad_norm": 0.032920073717832565, "ratio": 1.0001018047332764, "entropy": 0.4976056575775146, "incre_win_rate": 0.8292682926829268, "step": 2734}
{"time": 1767092402.9710634, "phase": "train", "update": 2735, "total_env_steps": 8752000, "episode_reward": 0.2432781606912613, "value_loss": 0.009257961250841617, "policy_loss": -0.0021453101266089903, "dist_entropy": 0.5102111577987671, "actor_grad_norm": 0.1871516853570938, "critic_grad_norm": 0.04815437272191048, "ratio": 0.9995490908622742, "entropy": 0.5102111577987671, "incre_win_rate": 0.7111111111111111, "step": 2735}
{"time": 1767092407.5013316, "phase": "train", "update": 2736, "total_env_steps": 8755200, "episode_reward": 0.24736084043979645, "value_loss": 0.00939783751964569, "policy_loss": -0.0017737443977615896, "dist_entropy": 0.512257170677185, "actor_grad_norm": 0.11114682257175446, "critic_grad_norm": 0.0476488433778286, "ratio": 0.9996795058250427, "entropy": 0.512257170677185, "incre_win_rate": 0.8292682926829268, "step": 2736}
{"time": 1767092412.0920863, "phase": "train", "update": 2737, "total_env_steps": 8758400, "episode_reward": 0.2534245550632477, "value_loss": 0.007236699666827917, "policy_loss": -0.0020044926207589244, "dist_entropy": 0.49127247333526614, "actor_grad_norm": 0.1478438824415207, "critic_grad_norm": 0.03914375230669975, "ratio": 1.0000108480453491, "entropy": 0.49127247333526614, "incre_win_rate": 0.8, "step": 2737}
{"time": 1767092416.547857, "phase": "train", "update": 2738, "total_env_steps": 8761600, "episode_reward": 0.2501671314239502, "value_loss": 0.005505511630326509, "policy_loss": -0.0019794163133944665, "dist_entropy": 0.4772632658481598, "actor_grad_norm": 0.14546553790569305, "critic_grad_norm": 0.042209383100271225, "ratio": 0.9994325041770935, "entropy": 0.4772632658481598, "incre_win_rate": 0.8837209302325582, "step": 2738}
{"time": 1767092421.0938954, "phase": "train", "update": 2739, "total_env_steps": 8764800, "episode_reward": 0.2557176351547241, "value_loss": 0.0057080483064055445, "policy_loss": -0.0016106218082398982, "dist_entropy": 0.4846187949180603, "actor_grad_norm": 0.14637532830238342, "critic_grad_norm": 0.04160945490002632, "ratio": 1.0007184743881226, "entropy": 0.4846187949180603, "incre_win_rate": 0.8809523809523809, "step": 2739}
{"time": 1767092425.5477479, "phase": "train", "update": 2740, "total_env_steps": 8768000, "episode_reward": 0.24883121252059937, "value_loss": 0.006460142508149147, "policy_loss": -0.0019953594667356358, "dist_entropy": 0.4891694962978363, "actor_grad_norm": 0.12221463024616241, "critic_grad_norm": 0.031058678403496742, "ratio": 0.9997789263725281, "entropy": 0.4891694962978363, "incre_win_rate": 0.8372093023255814, "step": 2740}
{"time": 1767092430.1061862, "phase": "train", "update": 2741, "total_env_steps": 8771200, "episode_reward": 0.2524658441543579, "value_loss": 0.007434756215661764, "policy_loss": -0.002279588972414359, "dist_entropy": 0.4818680942058563, "actor_grad_norm": 0.16884742677211761, "critic_grad_norm": 0.0587584488093853, "ratio": 0.9993730783462524, "entropy": 0.4818680942058563, "incre_win_rate": 0.7619047619047619, "step": 2741}
{"time": 1767092441.013789, "phase": "eval", "update": 2741, "total_env_steps": 8771200, "eval_win_rate": 1.0, "eval_episode_reward": 20.027110927152318, "step": 2741}
{"time": 1767092445.5311632, "phase": "train", "update": 2742, "total_env_steps": 8774400, "episode_reward": 0.25086820125579834, "value_loss": 0.007350999675691128, "policy_loss": -0.001861312875351473, "dist_entropy": 0.4892305493354797, "actor_grad_norm": 0.1612124890089035, "critic_grad_norm": 0.060677655041217804, "ratio": 0.9999602437019348, "entropy": 0.4892305493354797, "incre_win_rate": 0.8780487804878049, "step": 2742}
{"time": 1767092450.0102124, "phase": "train", "update": 2743, "total_env_steps": 8777600, "episode_reward": 0.2474239468574524, "value_loss": 0.005337534099817276, "policy_loss": -0.0017979057158495238, "dist_entropy": 0.48557934165000916, "actor_grad_norm": 0.2028433382511139, "critic_grad_norm": 0.038713276386260986, "ratio": 0.9996575713157654, "entropy": 0.48557934165000916, "incre_win_rate": 0.7380952380952381, "step": 2743}
{"time": 1767092454.5126083, "phase": "train", "update": 2744, "total_env_steps": 8780800, "episode_reward": 0.25838109850883484, "value_loss": 0.0034355330280959606, "policy_loss": -0.0021188898188795324, "dist_entropy": 0.4902539312839508, "actor_grad_norm": 0.17739622294902802, "critic_grad_norm": 0.06177838519215584, "ratio": 0.9998299479484558, "entropy": 0.4902539312839508, "incre_win_rate": 0.9534883720930233, "step": 2744}
{"time": 1767092459.0109298, "phase": "train", "update": 2745, "total_env_steps": 8784000, "episode_reward": 0.2547614872455597, "value_loss": 0.004093108419328928, "policy_loss": -0.0017142451616635412, "dist_entropy": 0.48650516867637633, "actor_grad_norm": 0.20191355049610138, "critic_grad_norm": 0.04066043719649315, "ratio": 1.000026822090149, "entropy": 0.48650516867637633, "incre_win_rate": 0.8837209302325582, "step": 2745}
{"time": 1767092463.539585, "phase": "train", "update": 2746, "total_env_steps": 8787200, "episode_reward": 0.2568439543247223, "value_loss": 0.004462381824851036, "policy_loss": -0.0016893813832520976, "dist_entropy": 0.5030529499053955, "actor_grad_norm": 0.18434365093708038, "critic_grad_norm": 0.03036642074584961, "ratio": 1.0000535249710083, "entropy": 0.5030529499053955, "incre_win_rate": 0.925, "step": 2746}
{"time": 1767092468.0409138, "phase": "train", "update": 2747, "total_env_steps": 8790400, "episode_reward": 0.25665047764778137, "value_loss": 0.006120174378156662, "policy_loss": -0.0014608976972496635, "dist_entropy": 0.47729896306991576, "actor_grad_norm": 0.18843963742256165, "critic_grad_norm": 0.038037579506635666, "ratio": 0.9998747110366821, "entropy": 0.47729896306991576, "incre_win_rate": 0.8333333333333334, "step": 2747}
{"time": 1767092472.6170108, "phase": "train", "update": 2748, "total_env_steps": 8793600, "episode_reward": 0.26388609409332275, "value_loss": 0.006142972037196159, "policy_loss": -0.0016087164403479903, "dist_entropy": 0.4692040503025055, "actor_grad_norm": 0.15525850653648376, "critic_grad_norm": 0.029314473271369934, "ratio": 0.9997957348823547, "entropy": 0.4692040503025055, "incre_win_rate": 0.8695652173913043, "step": 2748}
{"time": 1767092477.0701096, "phase": "train", "update": 2749, "total_env_steps": 8796800, "episode_reward": 0.25642848014831543, "value_loss": 0.0053667577914893625, "policy_loss": -0.0018284883542278862, "dist_entropy": 0.4943035185337067, "actor_grad_norm": 0.12574560940265656, "critic_grad_norm": 0.038032032549381256, "ratio": 0.9995477795600891, "entropy": 0.4943035185337067, "incre_win_rate": 0.9, "step": 2749}
{"time": 1767092481.6087768, "phase": "train", "update": 2750, "total_env_steps": 8800000, "episode_reward": 0.2535156309604645, "value_loss": 0.0048551206476986405, "policy_loss": -0.0018955150442799607, "dist_entropy": 0.47508251667022705, "actor_grad_norm": 0.16596263647079468, "critic_grad_norm": 0.02614528313279152, "ratio": 1.0005037784576416, "entropy": 0.47508251667022705, "incre_win_rate": 0.8636363636363636, "step": 2750}
{"time": 1767092486.1147313, "phase": "train", "update": 2751, "total_env_steps": 8803200, "episode_reward": 0.25612789392471313, "value_loss": 0.005041342787444591, "policy_loss": -0.0016502883270153035, "dist_entropy": 0.4911364674568176, "actor_grad_norm": 0.21778450906276703, "critic_grad_norm": 0.01249766256660223, "ratio": 1.0001249313354492, "entropy": 0.4911364674568176, "incre_win_rate": 0.8095238095238095, "step": 2751}
{"time": 1767092490.6540225, "phase": "train", "update": 2752, "total_env_steps": 8806400, "episode_reward": 0.2562805414199829, "value_loss": 0.005686206743121147, "policy_loss": -0.0013500261361485855, "dist_entropy": 0.4800621449947357, "actor_grad_norm": 0.20397606492042542, "critic_grad_norm": 0.028798062354326248, "ratio": 0.999844491481781, "entropy": 0.4800621449947357, "incre_win_rate": 0.8571428571428571, "step": 2752}
{"time": 1767092495.1810248, "phase": "train", "update": 2753, "total_env_steps": 8809600, "episode_reward": 0.24850578606128693, "value_loss": 0.008979266323149205, "policy_loss": -0.001397713816055557, "dist_entropy": 0.4769149124622345, "actor_grad_norm": 0.2153674215078354, "critic_grad_norm": 0.04506528750061989, "ratio": 0.9999942779541016, "entropy": 0.4769149124622345, "incre_win_rate": 0.7857142857142857, "step": 2753}
{"time": 1767092499.7713137, "phase": "train", "update": 2754, "total_env_steps": 8812800, "episode_reward": 0.24849805235862732, "value_loss": 0.004665718227624893, "policy_loss": -0.0018003238043502456, "dist_entropy": 0.4764780938625336, "actor_grad_norm": 0.15540622174739838, "critic_grad_norm": 0.02667316235601902, "ratio": 0.9997633099555969, "entropy": 0.4764780938625336, "incre_win_rate": 0.7380952380952381, "step": 2754}
{"time": 1767092504.3340037, "phase": "train", "update": 2755, "total_env_steps": 8816000, "episode_reward": 0.2599368989467621, "value_loss": 0.005572585947811603, "policy_loss": -0.0015134624333928315, "dist_entropy": 0.4732909321784973, "actor_grad_norm": 0.12309950590133667, "critic_grad_norm": 0.023902418091893196, "ratio": 0.999842643737793, "entropy": 0.4732909321784973, "incre_win_rate": 0.8863636363636364, "step": 2755}
{"time": 1767092508.86581, "phase": "train", "update": 2756, "total_env_steps": 8819200, "episode_reward": 0.24407337605953217, "value_loss": 0.0055055560544133185, "policy_loss": -0.0020675894261387383, "dist_entropy": 0.481929337978363, "actor_grad_norm": 0.13947153091430664, "critic_grad_norm": 0.02380256913602352, "ratio": 1.000045657157898, "entropy": 0.481929337978363, "incre_win_rate": 0.775, "step": 2756}
{"time": 1767092513.3901882, "phase": "train", "update": 2757, "total_env_steps": 8822400, "episode_reward": 0.24814674258232117, "value_loss": 0.0077919671311974525, "policy_loss": -0.0022519617804189094, "dist_entropy": 0.49184160232543944, "actor_grad_norm": 0.15890315175056458, "critic_grad_norm": 0.03588820621371269, "ratio": 1.0001120567321777, "entropy": 0.49184160232543944, "incre_win_rate": 0.8409090909090909, "step": 2757}
{"time": 1767092517.8672478, "phase": "train", "update": 2758, "total_env_steps": 8825600, "episode_reward": 0.2511403262615204, "value_loss": 0.006279824022203684, "policy_loss": -0.0018020457141808776, "dist_entropy": 0.48567294478416445, "actor_grad_norm": 0.14846795797348022, "critic_grad_norm": 0.04061225801706314, "ratio": 1.000122308731079, "entropy": 0.48567294478416445, "incre_win_rate": 0.775, "step": 2758}
{"time": 1767092522.449352, "phase": "train", "update": 2759, "total_env_steps": 8828800, "episode_reward": 0.24928444623947144, "value_loss": 0.006922875344753265, "policy_loss": -0.0014447855445826718, "dist_entropy": 0.484821742773056, "actor_grad_norm": 0.18397319316864014, "critic_grad_norm": 0.0365256629884243, "ratio": 0.9998704195022583, "entropy": 0.484821742773056, "incre_win_rate": 0.7272727272727273, "step": 2759}
{"time": 1767092526.906576, "phase": "train", "update": 2760, "total_env_steps": 8832000, "episode_reward": 0.2488260716199875, "value_loss": 0.005091941356658936, "policy_loss": -0.0019123929162503828, "dist_entropy": 0.4964474976062775, "actor_grad_norm": 0.18536822497844696, "critic_grad_norm": 0.022736547514796257, "ratio": 0.9992493987083435, "entropy": 0.4964474976062775, "incre_win_rate": 0.8780487804878049, "step": 2760}
{"time": 1767092531.4945076, "phase": "train", "update": 2761, "total_env_steps": 8835200, "episode_reward": 0.26442983746528625, "value_loss": 0.005247006844729185, "policy_loss": -0.0018806393850530512, "dist_entropy": 0.4779064118862152, "actor_grad_norm": 0.12334054708480835, "critic_grad_norm": 0.0226146187633276, "ratio": 0.999584972858429, "entropy": 0.4779064118862152, "incre_win_rate": 0.8604651162790697, "step": 2761}
{"time": 1767092542.2183075, "phase": "eval", "update": 2761, "total_env_steps": 8835200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.578228476821188, "step": 2761}
{"time": 1767092546.7311745, "phase": "train", "update": 2762, "total_env_steps": 8838400, "episode_reward": 0.2545059025287628, "value_loss": 0.004960259236395359, "policy_loss": -0.001970448135105585, "dist_entropy": 0.4770176112651825, "actor_grad_norm": 0.13838820159435272, "critic_grad_norm": 0.010997789911925793, "ratio": 1.000226378440857, "entropy": 0.4770176112651825, "incre_win_rate": 0.813953488372093, "step": 2762}
{"time": 1767092551.2267566, "phase": "train", "update": 2763, "total_env_steps": 8841600, "episode_reward": 0.24475322663784027, "value_loss": 0.010340232588350772, "policy_loss": -0.0020169112064962746, "dist_entropy": 0.4825317621231079, "actor_grad_norm": 0.1702079474925995, "critic_grad_norm": 0.05012262985110283, "ratio": 0.9995982050895691, "entropy": 0.4825317621231079, "incre_win_rate": 0.6585365853658537, "step": 2763}
{"time": 1767092555.6752331, "phase": "train", "update": 2764, "total_env_steps": 8844800, "episode_reward": 0.24537304043769836, "value_loss": 0.005833357106894255, "policy_loss": -0.001970573193278824, "dist_entropy": 0.4783164322376251, "actor_grad_norm": 0.12850511074066162, "critic_grad_norm": 0.06025175377726555, "ratio": 0.9998877644538879, "entropy": 0.4783164322376251, "incre_win_rate": 0.6511627906976745, "step": 2764}
{"time": 1767092560.1565812, "phase": "train", "update": 2765, "total_env_steps": 8848000, "episode_reward": 0.24760401248931885, "value_loss": 0.007439817488193512, "policy_loss": -0.0017345642186489263, "dist_entropy": 0.48311556577682496, "actor_grad_norm": 0.1310509741306305, "critic_grad_norm": 0.04478238523006439, "ratio": 0.9994236826896667, "entropy": 0.48311556577682496, "incre_win_rate": 0.75, "step": 2765}
{"time": 1767092564.6857002, "phase": "train", "update": 2766, "total_env_steps": 8851200, "episode_reward": 0.2515650987625122, "value_loss": 0.0071024465374648574, "policy_loss": -0.002118561515905526, "dist_entropy": 0.4783078610897064, "actor_grad_norm": 0.12221550941467285, "critic_grad_norm": 0.027452563866972923, "ratio": 0.9997695088386536, "entropy": 0.4783078610897064, "incre_win_rate": 0.7804878048780488, "step": 2766}
{"time": 1767092569.1653066, "phase": "train", "update": 2767, "total_env_steps": 8854400, "episode_reward": 0.251572847366333, "value_loss": 0.007279474195092917, "policy_loss": -0.0015292950594080422, "dist_entropy": 0.47924805879592897, "actor_grad_norm": 0.14497485756874084, "critic_grad_norm": 0.026775924488902092, "ratio": 1.0003265142440796, "entropy": 0.47924805879592897, "incre_win_rate": 0.7777777777777778, "step": 2767}
{"time": 1767092574.0415385, "phase": "train", "update": 2768, "total_env_steps": 8857600, "episode_reward": 0.2545333206653595, "value_loss": 0.005708409752696752, "policy_loss": -0.001879426226075509, "dist_entropy": 0.46104541420936584, "actor_grad_norm": 0.12347345799207687, "critic_grad_norm": 0.03249238058924675, "ratio": 0.9997683763504028, "entropy": 0.46104541420936584, "incre_win_rate": 0.775, "step": 2768}
{"time": 1767092578.5699005, "phase": "train", "update": 2769, "total_env_steps": 8860800, "episode_reward": 0.25505900382995605, "value_loss": 0.007178440224379301, "policy_loss": -0.0017272723252986567, "dist_entropy": 0.4653308570384979, "actor_grad_norm": 0.13399942219257355, "critic_grad_norm": 0.03039945662021637, "ratio": 0.9992538690567017, "entropy": 0.4653308570384979, "incre_win_rate": 0.6888888888888889, "step": 2769}
{"time": 1767092583.148833, "phase": "train", "update": 2770, "total_env_steps": 8864000, "episode_reward": 0.2524053156375885, "value_loss": 0.008766170404851437, "policy_loss": -0.0014774364517407435, "dist_entropy": 0.46643521785736086, "actor_grad_norm": 0.12440955638885498, "critic_grad_norm": 0.027374953031539917, "ratio": 0.9996746182441711, "entropy": 0.46643521785736086, "incre_win_rate": 0.7906976744186046, "step": 2770}
{"time": 1767092587.7289476, "phase": "train", "update": 2771, "total_env_steps": 8867200, "episode_reward": 0.248594269156456, "value_loss": 0.00890911091119051, "policy_loss": -0.0017738528351387117, "dist_entropy": 0.47261629700660707, "actor_grad_norm": 0.13568247854709625, "critic_grad_norm": 0.017798295244574547, "ratio": 0.9999330639839172, "entropy": 0.47261629700660707, "incre_win_rate": 0.8048780487804879, "step": 2771}
{"time": 1767092592.3711088, "phase": "train", "update": 2772, "total_env_steps": 8870400, "episode_reward": 0.24833092093467712, "value_loss": 0.008091728948056699, "policy_loss": -0.0017672147895892276, "dist_entropy": 0.4481637477874756, "actor_grad_norm": 0.15870597958564758, "critic_grad_norm": 0.022622182965278625, "ratio": 0.9999507069587708, "entropy": 0.4481637477874756, "incre_win_rate": 0.7111111111111111, "step": 2772}
{"time": 1767092597.1018426, "phase": "train", "update": 2773, "total_env_steps": 8873600, "episode_reward": 0.26318812370300293, "value_loss": 0.007721162308007479, "policy_loss": -0.001830325679395628, "dist_entropy": 0.4534638524055481, "actor_grad_norm": 0.12670724093914032, "critic_grad_norm": 0.028517350554466248, "ratio": 0.99964839220047, "entropy": 0.4534638524055481, "incre_win_rate": 0.8372093023255814, "step": 2773}
{"time": 1767092601.660553, "phase": "train", "update": 2774, "total_env_steps": 8876800, "episode_reward": 0.25912201404571533, "value_loss": 0.005004388652741909, "policy_loss": -0.0019125317124910168, "dist_entropy": 0.4601954758167267, "actor_grad_norm": 0.13117054104804993, "critic_grad_norm": 0.0245035570114851, "ratio": 1.000594139099121, "entropy": 0.4601954758167267, "incre_win_rate": 0.8863636363636364, "step": 2774}
{"time": 1767092606.2294905, "phase": "train", "update": 2775, "total_env_steps": 8880000, "episode_reward": 0.26058050990104675, "value_loss": 0.006230826675891876, "policy_loss": -0.001614810560777613, "dist_entropy": 0.4629129827022552, "actor_grad_norm": 0.15078233182430267, "critic_grad_norm": 0.02040538564324379, "ratio": 1.0002448558807373, "entropy": 0.4629129827022552, "incre_win_rate": 0.8780487804878049, "step": 2775}
{"time": 1767092610.798855, "phase": "train", "update": 2776, "total_env_steps": 8883200, "episode_reward": 0.25102698802948, "value_loss": 0.007129066344350577, "policy_loss": -0.0018667492613268165, "dist_entropy": 0.45832033157348634, "actor_grad_norm": 0.16174070537090302, "critic_grad_norm": 0.022798608988523483, "ratio": 1.0001558065414429, "entropy": 0.45832033157348634, "incre_win_rate": 0.8181818181818182, "step": 2776}
{"time": 1767092615.3224282, "phase": "train", "update": 2777, "total_env_steps": 8886400, "episode_reward": 0.2462681233882904, "value_loss": 0.005978338420391083, "policy_loss": -0.0015264581728587246, "dist_entropy": 0.46361224055290223, "actor_grad_norm": 0.1348903477191925, "critic_grad_norm": 0.022353699430823326, "ratio": 1.0001070499420166, "entropy": 0.46361224055290223, "incre_win_rate": 0.8048780487804879, "step": 2777}
{"time": 1767092645.3852744, "phase": "train", "update": 2778, "total_env_steps": 8889600, "episode_reward": 0.26103684306144714, "value_loss": 0.06394225358963013, "policy_loss": -0.0015149393613441476, "dist_entropy": 0.46600749492645266, "actor_grad_norm": 0.13280919194221497, "critic_grad_norm": 0.16862820088863373, "ratio": 1.0003067255020142, "entropy": 0.46600749492645266, "incre_win_rate": 0.825, "step": 2778}
{"time": 1767092649.8521154, "phase": "train", "update": 2779, "total_env_steps": 8892800, "episode_reward": 0.2599410116672516, "value_loss": 0.006935676466673613, "policy_loss": -0.0014524717623430662, "dist_entropy": 0.4491840124130249, "actor_grad_norm": 0.14845329523086548, "critic_grad_norm": 0.13548101484775543, "ratio": 0.999717652797699, "entropy": 0.4491840124130249, "incre_win_rate": 0.8, "step": 2779}
{"time": 1767092654.3926656, "phase": "train", "update": 2780, "total_env_steps": 8896000, "episode_reward": 0.2659369707107544, "value_loss": 0.007741670310497284, "policy_loss": -0.002026180703035152, "dist_entropy": 0.43525505661964414, "actor_grad_norm": 0.15392416715621948, "critic_grad_norm": 0.11281025409698486, "ratio": 1.0000863075256348, "entropy": 0.43525505661964414, "incre_win_rate": 0.8666666666666667, "step": 2780}
{"time": 1767092658.9037957, "phase": "train", "update": 2781, "total_env_steps": 8899200, "episode_reward": 0.2652607858181, "value_loss": 0.005132307857275009, "policy_loss": -0.0015083691678032807, "dist_entropy": 0.458463180065155, "actor_grad_norm": 0.12937049567699432, "critic_grad_norm": 0.07448814809322357, "ratio": 0.9999088644981384, "entropy": 0.458463180065155, "incre_win_rate": 0.8604651162790697, "step": 2781}
{"time": 1767092669.8694093, "phase": "eval", "update": 2781, "total_env_steps": 8899200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.705556705298015, "step": 2781}
{"time": 1767092674.3609486, "phase": "train", "update": 2782, "total_env_steps": 8902400, "episode_reward": 0.25573158264160156, "value_loss": 0.006348368898034096, "policy_loss": -0.001596732310091653, "dist_entropy": 0.452458930015564, "actor_grad_norm": 0.14964042603969574, "critic_grad_norm": 0.05356748029589653, "ratio": 1.000301718711853, "entropy": 0.452458930015564, "incre_win_rate": 0.8095238095238095, "step": 2782}
{"time": 1767092678.8418064, "phase": "train", "update": 2783, "total_env_steps": 8905600, "episode_reward": 0.2541877031326294, "value_loss": 0.005362302623689174, "policy_loss": -0.0020398698378755855, "dist_entropy": 0.44630421996116637, "actor_grad_norm": 0.1508752554655075, "critic_grad_norm": 0.04650437831878662, "ratio": 0.9996492266654968, "entropy": 0.44630421996116637, "incre_win_rate": 0.8181818181818182, "step": 2783}
{"time": 1767092683.4226146, "phase": "train", "update": 2784, "total_env_steps": 8908800, "episode_reward": 0.26594164967536926, "value_loss": 0.008777316100895405, "policy_loss": -0.0014458916520858622, "dist_entropy": 0.44958829283714297, "actor_grad_norm": 0.16261766850948334, "critic_grad_norm": 0.0235303845256567, "ratio": 0.99965900182724, "entropy": 0.44958829283714297, "incre_win_rate": 0.8478260869565217, "step": 2784}
{"time": 1767092687.9526348, "phase": "train", "update": 2785, "total_env_steps": 8912000, "episode_reward": 0.25953641533851624, "value_loss": 0.006216880958527326, "policy_loss": -0.0018696583206242678, "dist_entropy": 0.4481578886508942, "actor_grad_norm": 0.1604941189289093, "critic_grad_norm": 0.046456146985292435, "ratio": 1.0002202987670898, "entropy": 0.4481578886508942, "incre_win_rate": 0.825, "step": 2785}
{"time": 1767092692.4835956, "phase": "train", "update": 2786, "total_env_steps": 8915200, "episode_reward": 0.2435859888792038, "value_loss": 0.011238958872854709, "policy_loss": -0.0017471079927815936, "dist_entropy": 0.4472822308540344, "actor_grad_norm": 0.14761075377464294, "critic_grad_norm": 0.11347109079360962, "ratio": 0.9996264576911926, "entropy": 0.4472822308540344, "incre_win_rate": 0.7209302325581395, "step": 2786}
{"time": 1767092697.5615268, "phase": "train", "update": 2787, "total_env_steps": 8918400, "episode_reward": 0.2581612169742584, "value_loss": 0.006372311338782311, "policy_loss": -0.0013864563961504927, "dist_entropy": 0.4284056067466736, "actor_grad_norm": 0.1527431160211563, "critic_grad_norm": 0.07803639024496078, "ratio": 0.9996177554130554, "entropy": 0.4284056067466736, "incre_win_rate": 0.7608695652173914, "step": 2787}
{"time": 1767092702.118712, "phase": "train", "update": 2788, "total_env_steps": 8921600, "episode_reward": 0.2583935260772705, "value_loss": 0.007873969338834285, "policy_loss": -0.0017130842196678487, "dist_entropy": 0.4437104642391205, "actor_grad_norm": 0.12788954377174377, "critic_grad_norm": 0.05371614173054695, "ratio": 1.0000724792480469, "entropy": 0.4437104642391205, "incre_win_rate": 0.7619047619047619, "step": 2788}
{"time": 1767092706.6210077, "phase": "train", "update": 2789, "total_env_steps": 8924800, "episode_reward": 0.26561930775642395, "value_loss": 0.0064108029939234255, "policy_loss": -0.0017082362930047168, "dist_entropy": 0.4413662075996399, "actor_grad_norm": 0.14459435641765594, "critic_grad_norm": 0.07369843125343323, "ratio": 0.9997462630271912, "entropy": 0.4413662075996399, "incre_win_rate": 0.8695652173913043, "step": 2789}
{"time": 1767092711.0924842, "phase": "train", "update": 2790, "total_env_steps": 8928000, "episode_reward": 0.2649798095226288, "value_loss": 0.004909427091479302, "policy_loss": -0.001671668703689022, "dist_entropy": 0.45368788242340086, "actor_grad_norm": 0.18669527769088745, "critic_grad_norm": 0.06667978316545486, "ratio": 1.0001869201660156, "entropy": 0.45368788242340086, "incre_win_rate": 0.9024390243902439, "step": 2790}
{"time": 1767092715.7051709, "phase": "train", "update": 2791, "total_env_steps": 8931200, "episode_reward": 0.25372105836868286, "value_loss": 0.005973549652844667, "policy_loss": -0.0018397104048631264, "dist_entropy": 0.44568679928779603, "actor_grad_norm": 0.13378334045410156, "critic_grad_norm": 0.05684451013803482, "ratio": 0.9999589920043945, "entropy": 0.44568679928779603, "incre_win_rate": 0.7906976744186046, "step": 2791}
{"time": 1767092720.20943, "phase": "train", "update": 2792, "total_env_steps": 8934400, "episode_reward": 0.2666318416595459, "value_loss": 0.006217637285590172, "policy_loss": -0.0017432519984627247, "dist_entropy": 0.42944168448448183, "actor_grad_norm": 0.14553292095661163, "critic_grad_norm": 0.034893959760665894, "ratio": 0.9999018907546997, "entropy": 0.42944168448448183, "incre_win_rate": 0.8222222222222222, "step": 2792}
{"time": 1767092724.795701, "phase": "train", "update": 2793, "total_env_steps": 8937600, "episode_reward": 0.26520851254463196, "value_loss": 0.007563950680196285, "policy_loss": -0.0014555631944162429, "dist_entropy": 0.4548616766929626, "actor_grad_norm": 0.12749196588993073, "critic_grad_norm": 0.03226536884903908, "ratio": 0.9995965361595154, "entropy": 0.4548616766929626, "incre_win_rate": 0.75, "step": 2793}
{"time": 1767092729.3501384, "phase": "train", "update": 2794, "total_env_steps": 8940800, "episode_reward": 0.27905476093292236, "value_loss": 0.004791601188480854, "policy_loss": -0.0014585624694305466, "dist_entropy": 0.42870388031005857, "actor_grad_norm": 0.12663215398788452, "critic_grad_norm": 0.04149046912789345, "ratio": 0.9998083114624023, "entropy": 0.42870388031005857, "incre_win_rate": 0.9166666666666666, "step": 2794}
{"time": 1767092733.8829656, "phase": "train", "update": 2795, "total_env_steps": 8944000, "episode_reward": 0.2584100663661957, "value_loss": 0.008497131802141667, "policy_loss": -0.0016127898939988228, "dist_entropy": 0.4440603256225586, "actor_grad_norm": 0.16231127083301544, "critic_grad_norm": 0.07663922756910324, "ratio": 0.9996835589408875, "entropy": 0.4440603256225586, "incre_win_rate": 0.7209302325581395, "step": 2795}
{"time": 1767092738.5630631, "phase": "train", "update": 2796, "total_env_steps": 8947200, "episode_reward": 0.24595199525356293, "value_loss": 0.008448057249188424, "policy_loss": -0.0015362505772984036, "dist_entropy": 0.42487323880195615, "actor_grad_norm": 0.13777978718280792, "critic_grad_norm": 0.05895233899354935, "ratio": 0.9999597668647766, "entropy": 0.42487323880195615, "incre_win_rate": 0.6511627906976745, "step": 2796}
{"time": 1767092743.1605694, "phase": "train", "update": 2797, "total_env_steps": 8950400, "episode_reward": 0.26230132579803467, "value_loss": 0.009252935275435447, "policy_loss": -0.001299488735247678, "dist_entropy": 0.4230606496334076, "actor_grad_norm": 0.13380341231822968, "critic_grad_norm": 0.03675530105829239, "ratio": 1.0002084970474243, "entropy": 0.4230606496334076, "incre_win_rate": 0.782608695652174, "step": 2797}
{"time": 1767092747.6993978, "phase": "train", "update": 2798, "total_env_steps": 8953600, "episode_reward": 0.26896679401397705, "value_loss": 0.008337489329278469, "policy_loss": -0.0014589999387325746, "dist_entropy": 0.42377540469169617, "actor_grad_norm": 0.13480666279792786, "critic_grad_norm": 0.057051535695791245, "ratio": 1.000083088874817, "entropy": 0.42377540469169617, "incre_win_rate": 0.8636363636363636, "step": 2798}
{"time": 1767092752.2755814, "phase": "train", "update": 2799, "total_env_steps": 8956800, "episode_reward": 0.266066312789917, "value_loss": 0.006248132232576609, "policy_loss": -0.0011246291023667254, "dist_entropy": 0.4327900230884552, "actor_grad_norm": 0.13318200409412384, "critic_grad_norm": 0.05064379796385765, "ratio": 1.0003994703292847, "entropy": 0.4327900230884552, "incre_win_rate": 0.7777777777777778, "step": 2799}
{"time": 1767092756.8543983, "phase": "train", "update": 2800, "total_env_steps": 8960000, "episode_reward": 0.26426273584365845, "value_loss": 0.009143348410725593, "policy_loss": -0.0012320281176684488, "dist_entropy": 0.4357417643070221, "actor_grad_norm": 0.11062661558389664, "critic_grad_norm": 0.03655768558382988, "ratio": 0.9995651245117188, "entropy": 0.4357417643070221, "incre_win_rate": 0.717391304347826, "step": 2800}
{"time": 1767092761.4191291, "phase": "train", "update": 2801, "total_env_steps": 8963200, "episode_reward": 0.25986653566360474, "value_loss": 0.008104280941188336, "policy_loss": -0.0015586554995558055, "dist_entropy": 0.42817695140838624, "actor_grad_norm": 0.1568993330001831, "critic_grad_norm": 0.03378615155816078, "ratio": 1.0002572536468506, "entropy": 0.42817695140838624, "incre_win_rate": 0.7608695652173914, "step": 2801}
{"time": 1767092771.9427826, "phase": "eval", "update": 2801, "total_env_steps": 8963200, "eval_win_rate": 0.875, "eval_episode_reward": 19.41080298013245, "step": 2801}
{"time": 1767092776.5372493, "phase": "train", "update": 2802, "total_env_steps": 8966400, "episode_reward": 0.2720421254634857, "value_loss": 0.00747076440602541, "policy_loss": -0.001478658279847167, "dist_entropy": 0.43486756682395933, "actor_grad_norm": 0.14242397248744965, "critic_grad_norm": 0.03889885172247887, "ratio": 1.0001976490020752, "entropy": 0.43486756682395933, "incre_win_rate": 0.8409090909090909, "step": 2802}
{"time": 1767092781.0407236, "phase": "train", "update": 2803, "total_env_steps": 8969600, "episode_reward": 0.2527623474597931, "value_loss": 0.007605753373354673, "policy_loss": -0.001691470688056995, "dist_entropy": 0.4379105567932129, "actor_grad_norm": 0.15833982825279236, "critic_grad_norm": 0.03997449204325676, "ratio": 0.9997021555900574, "entropy": 0.4379105567932129, "incre_win_rate": 0.7209302325581395, "step": 2803}
{"time": 1767092785.576328, "phase": "train", "update": 2804, "total_env_steps": 8972800, "episode_reward": 0.2654309570789337, "value_loss": 0.007418739423155784, "policy_loss": -0.0016312832130353171, "dist_entropy": 0.43265987634658815, "actor_grad_norm": 0.16892501711845398, "critic_grad_norm": 0.0346115306019783, "ratio": 0.9994714856147766, "entropy": 0.43265987634658815, "incre_win_rate": 0.8666666666666667, "step": 2804}
{"time": 1767092790.094752, "phase": "train", "update": 2805, "total_env_steps": 8976000, "episode_reward": 0.2645602226257324, "value_loss": 0.006286969408392906, "policy_loss": -0.0016924369292851793, "dist_entropy": 0.44136322736740113, "actor_grad_norm": 0.17126992344856262, "critic_grad_norm": 0.021827291697263718, "ratio": 1.0003665685653687, "entropy": 0.44136322736740113, "incre_win_rate": 0.8409090909090909, "step": 2805}
{"time": 1767092794.666945, "phase": "train", "update": 2806, "total_env_steps": 8979200, "episode_reward": 0.2652949392795563, "value_loss": 0.00813676081597805, "policy_loss": -0.0018031418889961515, "dist_entropy": 0.4527243673801422, "actor_grad_norm": 0.16726572811603546, "critic_grad_norm": 0.0236786138266325, "ratio": 1.0000331401824951, "entropy": 0.4527243673801422, "incre_win_rate": 0.8222222222222222, "step": 2806}
{"time": 1767092799.234749, "phase": "train", "update": 2807, "total_env_steps": 8982400, "episode_reward": 0.27054375410079956, "value_loss": 0.005762527044862509, "policy_loss": -0.0014177299702538449, "dist_entropy": 0.46341278553009035, "actor_grad_norm": 0.12015974521636963, "critic_grad_norm": 0.044268812984228134, "ratio": 0.9999486804008484, "entropy": 0.46341278553009035, "incre_win_rate": 0.8222222222222222, "step": 2807}
{"time": 1767092803.815782, "phase": "train", "update": 2808, "total_env_steps": 8985600, "episode_reward": 0.26695212721824646, "value_loss": 0.007888324558734894, "policy_loss": -0.0017780649324578234, "dist_entropy": 0.4650274753570557, "actor_grad_norm": 0.12088458985090256, "critic_grad_norm": 0.04011513665318489, "ratio": 1.000036597251892, "entropy": 0.4650274753570557, "incre_win_rate": 0.8409090909090909, "step": 2808}
{"time": 1767092808.4284308, "phase": "train", "update": 2809, "total_env_steps": 8988800, "episode_reward": 0.26463422179222107, "value_loss": 0.0065931519493460655, "policy_loss": -0.0016149554900295015, "dist_entropy": 0.474104642868042, "actor_grad_norm": 0.14076630771160126, "critic_grad_norm": 0.02999199740588665, "ratio": 0.9994682669639587, "entropy": 0.474104642868042, "incre_win_rate": 0.8, "step": 2809}
{"time": 1767092813.0002992, "phase": "train", "update": 2810, "total_env_steps": 8992000, "episode_reward": 0.26801222562789917, "value_loss": 0.005166260991245508, "policy_loss": -0.0012976980442857666, "dist_entropy": 0.45020087957382204, "actor_grad_norm": 0.18226051330566406, "critic_grad_norm": 0.043186865746974945, "ratio": 1.000196099281311, "entropy": 0.45020087957382204, "incre_win_rate": 0.8695652173913043, "step": 2810}
{"time": 1767092817.5043056, "phase": "train", "update": 2811, "total_env_steps": 8995200, "episode_reward": 0.2595824897289276, "value_loss": 0.00703434394672513, "policy_loss": -0.0015524633048315194, "dist_entropy": 0.44528510570526125, "actor_grad_norm": 0.1513090580701828, "critic_grad_norm": 0.024002838879823685, "ratio": 1.0001877546310425, "entropy": 0.44528510570526125, "incre_win_rate": 0.8, "step": 2811}
{"time": 1767092822.0669186, "phase": "train", "update": 2812, "total_env_steps": 8998400, "episode_reward": 0.2704351544380188, "value_loss": 0.005937479250133037, "policy_loss": -0.0015161183378838317, "dist_entropy": 0.46372189521789553, "actor_grad_norm": 0.1417662352323532, "critic_grad_norm": 0.03602343797683716, "ratio": 0.9998594522476196, "entropy": 0.46372189521789553, "incre_win_rate": 0.851063829787234, "step": 2812}
{"time": 1767092826.6282337, "phase": "train", "update": 2813, "total_env_steps": 9001600, "episode_reward": 0.2660404443740845, "value_loss": 0.0070002139545977116, "policy_loss": -0.0016171116612838433, "dist_entropy": 0.4692904829978943, "actor_grad_norm": 0.11401522159576416, "critic_grad_norm": 0.03722365200519562, "ratio": 0.999762237071991, "entropy": 0.4692904829978943, "incre_win_rate": 0.8222222222222222, "step": 2813}
{"time": 1767092831.1396935, "phase": "train", "update": 2814, "total_env_steps": 9004800, "episode_reward": 0.256687730550766, "value_loss": 0.00669361287727952, "policy_loss": -0.0014034120673578343, "dist_entropy": 0.4711881816387177, "actor_grad_norm": 0.11460220813751221, "critic_grad_norm": 0.027970431372523308, "ratio": 0.9998165369033813, "entropy": 0.4711881816387177, "incre_win_rate": 0.813953488372093, "step": 2814}
{"time": 1767092835.7144117, "phase": "train", "update": 2815, "total_env_steps": 9008000, "episode_reward": 0.2632957398891449, "value_loss": 0.006354731600731611, "policy_loss": -0.0016447974387838293, "dist_entropy": 0.47055699229240416, "actor_grad_norm": 0.1205550953745842, "critic_grad_norm": 0.02083592116832733, "ratio": 0.9997633099555969, "entropy": 0.47055699229240416, "incre_win_rate": 0.782608695652174, "step": 2815}
{"time": 1767092840.280998, "phase": "train", "update": 2816, "total_env_steps": 9011200, "episode_reward": 0.25818657875061035, "value_loss": 0.008490265160799027, "policy_loss": -0.0018477372471658038, "dist_entropy": 0.485834413766861, "actor_grad_norm": 0.13344836235046387, "critic_grad_norm": 0.05784349516034126, "ratio": 1.0002373456954956, "entropy": 0.485834413766861, "incre_win_rate": 0.7045454545454546, "step": 2816}
{"time": 1767092844.815909, "phase": "train", "update": 2817, "total_env_steps": 9014400, "episode_reward": 0.2535642683506012, "value_loss": 0.009979789704084396, "policy_loss": -0.0016266771092972477, "dist_entropy": 0.4810189664363861, "actor_grad_norm": 0.13271747529506683, "critic_grad_norm": 0.07471281290054321, "ratio": 0.9998879432678223, "entropy": 0.4810189664363861, "incre_win_rate": 0.6521739130434783, "step": 2817}
{"time": 1767092849.309407, "phase": "train", "update": 2818, "total_env_steps": 9017600, "episode_reward": 0.2466297745704651, "value_loss": 0.011856263875961304, "policy_loss": -0.001987246344955551, "dist_entropy": 0.4701165437698364, "actor_grad_norm": 0.14898575842380524, "critic_grad_norm": 0.06825180351734161, "ratio": 1.0001288652420044, "entropy": 0.4701165437698364, "incre_win_rate": 0.6585365853658537, "step": 2818}
{"time": 1767092853.8590174, "phase": "train", "update": 2819, "total_env_steps": 9020800, "episode_reward": 0.25906768441200256, "value_loss": 0.008343124575912953, "policy_loss": -0.0016369203728971993, "dist_entropy": 0.46841809153556824, "actor_grad_norm": 0.13817234337329865, "critic_grad_norm": 0.08092136681079865, "ratio": 0.9997906684875488, "entropy": 0.46841809153556824, "incre_win_rate": 0.7954545454545454, "step": 2819}
{"time": 1767092858.3748417, "phase": "train", "update": 2820, "total_env_steps": 9024000, "episode_reward": 0.25840437412261963, "value_loss": 0.006982643157243729, "policy_loss": -0.0017758227306539976, "dist_entropy": 0.4836584985256195, "actor_grad_norm": 0.181972473859787, "critic_grad_norm": 0.041475728154182434, "ratio": 0.9999046325683594, "entropy": 0.4836584985256195, "incre_win_rate": 0.7441860465116279, "step": 2820}
{"time": 1767092863.22584, "phase": "train", "update": 2821, "total_env_steps": 9027200, "episode_reward": 0.24662044644355774, "value_loss": 0.011488715186715126, "policy_loss": -0.001527567138516872, "dist_entropy": 0.47793337106704714, "actor_grad_norm": 0.15029297769069672, "critic_grad_norm": 0.06993253529071808, "ratio": 1.0002331733703613, "entropy": 0.47793337106704714, "incre_win_rate": 0.6382978723404256, "step": 2821}
{"time": 1767092874.2571204, "phase": "eval", "update": 2821, "total_env_steps": 9027200, "eval_win_rate": 0.875, "eval_episode_reward": 19.467094370860927, "step": 2821}
{"time": 1767092878.7853746, "phase": "train", "update": 2822, "total_env_steps": 9030400, "episode_reward": 0.25114861130714417, "value_loss": 0.010308141820132732, "policy_loss": -0.001602937206956767, "dist_entropy": 0.48805553913116456, "actor_grad_norm": 0.16134817898273468, "critic_grad_norm": 0.04729348048567772, "ratio": 0.9994511604309082, "entropy": 0.48805553913116456, "incre_win_rate": 0.6428571428571429, "step": 2822}
{"time": 1767092883.354768, "phase": "train", "update": 2823, "total_env_steps": 9033600, "episode_reward": 0.2573406398296356, "value_loss": 0.009366331249475479, "policy_loss": -0.0016088393482974084, "dist_entropy": 0.4842650771141052, "actor_grad_norm": 0.18473640084266663, "critic_grad_norm": 0.08225030452013016, "ratio": 1.000106692314148, "entropy": 0.4842650771141052, "incre_win_rate": 0.7608695652173914, "step": 2823}
{"time": 1767092887.8742754, "phase": "train", "update": 2824, "total_env_steps": 9036800, "episode_reward": 0.2528192400932312, "value_loss": 0.009235559776425362, "policy_loss": -0.0012445311182219144, "dist_entropy": 0.48372607827186587, "actor_grad_norm": 0.1518944650888443, "critic_grad_norm": 0.061034370213747025, "ratio": 0.9997568130493164, "entropy": 0.48372607827186587, "incre_win_rate": 0.6744186046511628, "step": 2824}
{"time": 1767092892.4002123, "phase": "train", "update": 2825, "total_env_steps": 9040000, "episode_reward": 0.26082056760787964, "value_loss": 0.007607855461537838, "policy_loss": -0.001525430446131537, "dist_entropy": 0.4911226391792297, "actor_grad_norm": 0.18755966424942017, "critic_grad_norm": 0.04361123964190483, "ratio": 0.9999389052391052, "entropy": 0.4911226391792297, "incre_win_rate": 0.8, "step": 2825}
{"time": 1767092896.9192247, "phase": "train", "update": 2826, "total_env_steps": 9043200, "episode_reward": 0.24598044157028198, "value_loss": 0.0070975878275930885, "policy_loss": -0.0016108966984958784, "dist_entropy": 0.4739310622215271, "actor_grad_norm": 0.20060347020626068, "critic_grad_norm": 0.03240504488348961, "ratio": 1.0002204179763794, "entropy": 0.4739310622215271, "incre_win_rate": 0.7560975609756098, "step": 2826}
{"time": 1767092901.4339569, "phase": "train", "update": 2827, "total_env_steps": 9046400, "episode_reward": 0.25397300720214844, "value_loss": 0.0072677209042012695, "policy_loss": -0.001868322117900334, "dist_entropy": 0.48378905057907107, "actor_grad_norm": 0.1594436764717102, "critic_grad_norm": 0.02110138162970543, "ratio": 1.000278115272522, "entropy": 0.48378905057907107, "incre_win_rate": 0.7674418604651163, "step": 2827}
{"time": 1767092905.9829843, "phase": "train", "update": 2828, "total_env_steps": 9049600, "episode_reward": 0.25032493472099304, "value_loss": 0.004267607629299164, "policy_loss": -0.001568023469462787, "dist_entropy": 0.47783071398735044, "actor_grad_norm": 0.18835847079753876, "critic_grad_norm": 0.04381844401359558, "ratio": 1.0002928972244263, "entropy": 0.47783071398735044, "incre_win_rate": 0.8372093023255814, "step": 2828}
{"time": 1767092910.504482, "phase": "train", "update": 2829, "total_env_steps": 9052800, "episode_reward": 0.25662925839424133, "value_loss": 0.006539017148315907, "policy_loss": -0.0015131431260130058, "dist_entropy": 0.47861159443855283, "actor_grad_norm": 0.15588924288749695, "critic_grad_norm": 0.05752662941813469, "ratio": 0.9998995661735535, "entropy": 0.47861159443855283, "incre_win_rate": 0.6976744186046512, "step": 2829}
{"time": 1767092915.0709336, "phase": "train", "update": 2830, "total_env_steps": 9056000, "episode_reward": 0.2594795227050781, "value_loss": 0.008120362460613251, "policy_loss": -0.001452529337596964, "dist_entropy": 0.4750000834465027, "actor_grad_norm": 0.13360880315303802, "critic_grad_norm": 0.04204708710312843, "ratio": 0.9999842047691345, "entropy": 0.4750000834465027, "incre_win_rate": 0.7333333333333333, "step": 2830}
{"time": 1767092919.6340823, "phase": "train", "update": 2831, "total_env_steps": 9059200, "episode_reward": 0.2606782913208008, "value_loss": 0.010360061191022396, "policy_loss": -0.0014119792572200752, "dist_entropy": 0.4802040934562683, "actor_grad_norm": 0.1204724833369255, "critic_grad_norm": 0.03046785295009613, "ratio": 1.0001428127288818, "entropy": 0.4802040934562683, "incre_win_rate": 0.7391304347826086, "step": 2831}
{"time": 1767092924.2163556, "phase": "train", "update": 2832, "total_env_steps": 9062400, "episode_reward": 0.2603507936000824, "value_loss": 0.006884366180747748, "policy_loss": -0.001825991614389011, "dist_entropy": 0.4664390981197357, "actor_grad_norm": 0.14098791778087616, "critic_grad_norm": 0.06666353344917297, "ratio": 1.0000014305114746, "entropy": 0.4664390981197357, "incre_win_rate": 0.7906976744186046, "step": 2832}
{"time": 1767092928.7529054, "phase": "train", "update": 2833, "total_env_steps": 9065600, "episode_reward": 0.2571285367012024, "value_loss": 0.008010348118841649, "policy_loss": -0.0016648379391298817, "dist_entropy": 0.46454469561576844, "actor_grad_norm": 0.12229201942682266, "critic_grad_norm": 0.0499492846429348, "ratio": 1.0000073909759521, "entropy": 0.46454469561576844, "incre_win_rate": 0.8444444444444444, "step": 2833}
{"time": 1767092933.275168, "phase": "train", "update": 2834, "total_env_steps": 9068800, "episode_reward": 0.2446310967206955, "value_loss": 0.008677545189857482, "policy_loss": -0.0017231144671239207, "dist_entropy": 0.462307471036911, "actor_grad_norm": 0.15690404176712036, "critic_grad_norm": 0.04776110500097275, "ratio": 0.9997854232788086, "entropy": 0.462307471036911, "incre_win_rate": 0.55, "step": 2834}
{"time": 1767092937.8001146, "phase": "train", "update": 2835, "total_env_steps": 9072000, "episode_reward": 0.2657455503940582, "value_loss": 0.005808777362108231, "policy_loss": -0.0011641913604691467, "dist_entropy": 0.47620580792427064, "actor_grad_norm": 0.17596285045146942, "critic_grad_norm": 0.041392743587493896, "ratio": 1.0002995729446411, "entropy": 0.47620580792427064, "incre_win_rate": 0.851063829787234, "step": 2835}
{"time": 1767092943.0234165, "phase": "train", "update": 2836, "total_env_steps": 9075200, "episode_reward": 0.26254966855049133, "value_loss": 0.006677507143467665, "policy_loss": -0.0016425783883171619, "dist_entropy": 0.4736101388931274, "actor_grad_norm": 0.15041089057922363, "critic_grad_norm": 0.036729615181684494, "ratio": 0.9998831152915955, "entropy": 0.4736101388931274, "incre_win_rate": 0.8372093023255814, "step": 2836}
{"time": 1767092948.040956, "phase": "train", "update": 2837, "total_env_steps": 9078400, "episode_reward": 0.2679087221622467, "value_loss": 0.004758642334491014, "policy_loss": -0.0015065851411307563, "dist_entropy": 0.4651647925376892, "actor_grad_norm": 0.15211346745491028, "critic_grad_norm": 0.014605434611439705, "ratio": 1.0002299547195435, "entropy": 0.4651647925376892, "incre_win_rate": 0.8888888888888888, "step": 2837}
{"time": 1767092952.6206782, "phase": "train", "update": 2838, "total_env_steps": 9081600, "episode_reward": 0.26777005195617676, "value_loss": 0.0068661470897495745, "policy_loss": -0.0021206352302058917, "dist_entropy": 0.47292972803115846, "actor_grad_norm": 0.13587574660778046, "critic_grad_norm": 0.02197978086769581, "ratio": 1.0002434253692627, "entropy": 0.47292972803115846, "incre_win_rate": 0.8372093023255814, "step": 2838}
{"time": 1767092957.1997633, "phase": "train", "update": 2839, "total_env_steps": 9084800, "episode_reward": 0.2558821439743042, "value_loss": 0.007606986910104752, "policy_loss": -0.001674851384920828, "dist_entropy": 0.46344552040100095, "actor_grad_norm": 0.13621151447296143, "critic_grad_norm": 0.05116164684295654, "ratio": 1.0000510215759277, "entropy": 0.46344552040100095, "incre_win_rate": 0.75, "step": 2839}
{"time": 1767092961.744197, "phase": "train", "update": 2840, "total_env_steps": 9088000, "episode_reward": 0.27045321464538574, "value_loss": 0.005807949136942625, "policy_loss": -0.0014067302234568757, "dist_entropy": 0.4561839163303375, "actor_grad_norm": 0.16092561185359955, "critic_grad_norm": 0.05546323210000992, "ratio": 0.9997280240058899, "entropy": 0.4561839163303375, "incre_win_rate": 0.8863636363636364, "step": 2840}
{"time": 1767092966.5845227, "phase": "train", "update": 2841, "total_env_steps": 9091200, "episode_reward": 0.2610078752040863, "value_loss": 0.008457470312714576, "policy_loss": -0.001625144568924952, "dist_entropy": 0.45496368408203125, "actor_grad_norm": 0.15560562908649445, "critic_grad_norm": 0.04196709394454956, "ratio": 1.0003803968429565, "entropy": 0.45496368408203125, "incre_win_rate": 0.7954545454545454, "step": 2841}
{"time": 1767092979.7942412, "phase": "eval", "update": 2841, "total_env_steps": 9091200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.908526490066222, "step": 2841}
{"time": 1767092984.6498716, "phase": "train", "update": 2842, "total_env_steps": 9094400, "episode_reward": 0.2638995051383972, "value_loss": 0.006424475088715553, "policy_loss": -0.0015479841708483377, "dist_entropy": 0.4588810622692108, "actor_grad_norm": 0.15374445915222168, "critic_grad_norm": 0.030571982264518738, "ratio": 0.999947726726532, "entropy": 0.4588810622692108, "incre_win_rate": 0.7872340425531915, "step": 2842}
{"time": 1767092989.5073347, "phase": "train", "update": 2843, "total_env_steps": 9097600, "episode_reward": 0.26865583658218384, "value_loss": 0.007835290022194385, "policy_loss": -0.0014258084543193662, "dist_entropy": 0.4531751573085785, "actor_grad_norm": 0.160347580909729, "critic_grad_norm": 0.021464494988322258, "ratio": 0.9997366070747375, "entropy": 0.4531751573085785, "incre_win_rate": 0.8, "step": 2843}
{"time": 1767092994.2581427, "phase": "train", "update": 2844, "total_env_steps": 9100800, "episode_reward": 0.26295584440231323, "value_loss": 0.005419913399964571, "policy_loss": -0.0014489873173829438, "dist_entropy": 0.4447826504707336, "actor_grad_norm": 0.1167415902018547, "critic_grad_norm": 0.022180352360010147, "ratio": 0.9999217987060547, "entropy": 0.4447826504707336, "incre_win_rate": 0.7906976744186046, "step": 2844}
{"time": 1767092999.02767, "phase": "train", "update": 2845, "total_env_steps": 9104000, "episode_reward": 0.255577951669693, "value_loss": 0.007119016442447901, "policy_loss": -0.0018596526994514306, "dist_entropy": 0.46219195127487184, "actor_grad_norm": 0.13881652057170868, "critic_grad_norm": 0.04195345193147659, "ratio": 1.0001723766326904, "entropy": 0.46219195127487184, "incre_win_rate": 0.813953488372093, "step": 2845}
{"time": 1767093003.8070712, "phase": "train", "update": 2846, "total_env_steps": 9107200, "episode_reward": 0.26032647490501404, "value_loss": 0.006785736605525017, "policy_loss": -0.001597962496205696, "dist_entropy": 0.4654819488525391, "actor_grad_norm": 0.13164189457893372, "critic_grad_norm": 0.03408339247107506, "ratio": 0.9998211860656738, "entropy": 0.4654819488525391, "incre_win_rate": 0.7391304347826086, "step": 2846}
{"time": 1767093008.651137, "phase": "train", "update": 2847, "total_env_steps": 9110400, "episode_reward": 0.24959538877010345, "value_loss": 0.008190831635147333, "policy_loss": -0.001399102402891117, "dist_entropy": 0.47520374655723574, "actor_grad_norm": 0.1383843719959259, "critic_grad_norm": 0.03368646651506424, "ratio": 0.999848484992981, "entropy": 0.47520374655723574, "incre_win_rate": 0.8536585365853658, "step": 2847}
{"time": 1767093013.4701388, "phase": "train", "update": 2848, "total_env_steps": 9113600, "episode_reward": 0.25428083539009094, "value_loss": 0.008708202093839646, "policy_loss": -0.001977377440883288, "dist_entropy": 0.4548530995845795, "actor_grad_norm": 0.18879976868629456, "critic_grad_norm": 0.03267068415880203, "ratio": 0.9995681047439575, "entropy": 0.4548530995845795, "incre_win_rate": 0.7674418604651163, "step": 2848}
{"time": 1767093018.2727716, "phase": "train", "update": 2849, "total_env_steps": 9116800, "episode_reward": 0.2636372447013855, "value_loss": 0.006200817227363586, "policy_loss": -0.0015325816469029974, "dist_entropy": 0.4503394544124603, "actor_grad_norm": 0.1449873447418213, "critic_grad_norm": 0.05174712464213371, "ratio": 1.0000470876693726, "entropy": 0.4503394544124603, "incre_win_rate": 0.7954545454545454, "step": 2849}
{"time": 1767093022.9993584, "phase": "train", "update": 2850, "total_env_steps": 9120000, "episode_reward": 0.2720048427581787, "value_loss": 0.0035676895640790462, "policy_loss": -0.0013944581209059947, "dist_entropy": 0.4640292048454285, "actor_grad_norm": 0.1216079518198967, "critic_grad_norm": 0.030187293887138367, "ratio": 0.9997996687889099, "entropy": 0.4640292048454285, "incre_win_rate": 0.8666666666666667, "step": 2850}
{"time": 1767093027.726043, "phase": "train", "update": 2851, "total_env_steps": 9123200, "episode_reward": 0.2618212103843689, "value_loss": 0.006143761798739433, "policy_loss": -0.0012484422318024713, "dist_entropy": 0.4699596166610718, "actor_grad_norm": 0.1486062854528427, "critic_grad_norm": 0.05369690805673599, "ratio": 1.0002912282943726, "entropy": 0.4699596166610718, "incre_win_rate": 0.813953488372093, "step": 2851}
{"time": 1767093032.508644, "phase": "train", "update": 2852, "total_env_steps": 9126400, "episode_reward": 0.2574503421783447, "value_loss": 0.008365382440388203, "policy_loss": -0.0016070133683129483, "dist_entropy": 0.4687845826148987, "actor_grad_norm": 0.14271356165409088, "critic_grad_norm": 0.06051158905029297, "ratio": 0.9996032118797302, "entropy": 0.4687845826148987, "incre_win_rate": 0.7555555555555555, "step": 2852}
{"time": 1767093037.370057, "phase": "train", "update": 2853, "total_env_steps": 9129600, "episode_reward": 0.26362478733062744, "value_loss": 0.005429792962968349, "policy_loss": -0.0015247076811107263, "dist_entropy": 0.46525925397872925, "actor_grad_norm": 0.12984390556812286, "critic_grad_norm": 0.06196548417210579, "ratio": 0.9997183680534363, "entropy": 0.46525925397872925, "incre_win_rate": 0.7391304347826086, "step": 2853}
{"time": 1767093042.15508, "phase": "train", "update": 2854, "total_env_steps": 9132800, "episode_reward": 0.2728404402732849, "value_loss": 0.004689718410372734, "policy_loss": -0.0018282709158498277, "dist_entropy": 0.4731694459915161, "actor_grad_norm": 0.14705803990364075, "critic_grad_norm": 0.04233108088374138, "ratio": 0.9999398589134216, "entropy": 0.4731694459915161, "incre_win_rate": 0.9111111111111111, "step": 2854}
{"time": 1767093046.9960608, "phase": "train", "update": 2855, "total_env_steps": 9136000, "episode_reward": 0.27223923802375793, "value_loss": 0.0052327318117022514, "policy_loss": -0.0016007190720834785, "dist_entropy": 0.46622142791748045, "actor_grad_norm": 0.16931124031543732, "critic_grad_norm": 0.020931217819452286, "ratio": 0.9997690320014954, "entropy": 0.46622142791748045, "incre_win_rate": 0.8837209302325582, "step": 2855}
{"time": 1767093051.764495, "phase": "train", "update": 2856, "total_env_steps": 9139200, "episode_reward": 0.2628766894340515, "value_loss": 0.006117978598922491, "policy_loss": -0.0017622433704161723, "dist_entropy": 0.46811436414718627, "actor_grad_norm": 0.14616963267326355, "critic_grad_norm": 0.053237833082675934, "ratio": 0.9999977350234985, "entropy": 0.46811436414718627, "incre_win_rate": 0.7954545454545454, "step": 2856}
{"time": 1767093056.5496368, "phase": "train", "update": 2857, "total_env_steps": 9142400, "episode_reward": 0.2543776035308838, "value_loss": 0.006362925097346306, "policy_loss": -0.001337501993628365, "dist_entropy": 0.4658155620098114, "actor_grad_norm": 0.12899570167064667, "critic_grad_norm": 0.04834095016121864, "ratio": 0.9998659491539001, "entropy": 0.4658155620098114, "incre_win_rate": 0.75, "step": 2857}
{"time": 1767093061.3324604, "phase": "train", "update": 2858, "total_env_steps": 9145600, "episode_reward": 0.24842768907546997, "value_loss": 0.008295546285808086, "policy_loss": -0.0016546148156443507, "dist_entropy": 0.47015628814697263, "actor_grad_norm": 0.12838733196258545, "critic_grad_norm": 0.01879153586924076, "ratio": 0.9998321533203125, "entropy": 0.47015628814697263, "incre_win_rate": 0.7142857142857143, "step": 2858}
{"time": 1767093066.0944884, "phase": "train", "update": 2859, "total_env_steps": 9148800, "episode_reward": 0.2629278898239136, "value_loss": 0.007178336847573519, "policy_loss": -0.0016332440465369302, "dist_entropy": 0.45176801085472107, "actor_grad_norm": 0.14189989864826202, "critic_grad_norm": 0.04448021575808525, "ratio": 0.9998583197593689, "entropy": 0.45176801085472107, "incre_win_rate": 0.8222222222222222, "step": 2859}
{"time": 1767093070.8220205, "phase": "train", "update": 2860, "total_env_steps": 9152000, "episode_reward": 0.25483235716819763, "value_loss": 0.008797507546842099, "policy_loss": -0.001622120752159617, "dist_entropy": 0.45988562107086184, "actor_grad_norm": 0.12769369781017303, "critic_grad_norm": 0.03861421346664429, "ratio": 1.0000823736190796, "entropy": 0.45988562107086184, "incre_win_rate": 0.7857142857142857, "step": 2860}
{"time": 1767093075.5838325, "phase": "train", "update": 2861, "total_env_steps": 9155200, "episode_reward": 0.25352081656455994, "value_loss": 0.007060611713677644, "policy_loss": -0.0018575037777686988, "dist_entropy": 0.46003026366233823, "actor_grad_norm": 0.1301279515028, "critic_grad_norm": 0.04124706611037254, "ratio": 0.999890923500061, "entropy": 0.46003026366233823, "incre_win_rate": 0.8, "step": 2861}
{"time": 1767093087.6893914, "phase": "eval", "update": 2861, "total_env_steps": 9155200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.57796978476821, "step": 2861}
{"time": 1767093092.7568696, "phase": "train", "update": 2862, "total_env_steps": 9158400, "episode_reward": 0.24986806511878967, "value_loss": 0.006646626722067594, "policy_loss": -0.0017886009068918795, "dist_entropy": 0.4518208742141724, "actor_grad_norm": 0.12390649318695068, "critic_grad_norm": 0.042274508625268936, "ratio": 1.0000123977661133, "entropy": 0.4518208742141724, "incre_win_rate": 0.7317073170731707, "step": 2862}
{"time": 1767093097.9471467, "phase": "train", "update": 2863, "total_env_steps": 9161600, "episode_reward": 0.2601407468318939, "value_loss": 0.00691039077937603, "policy_loss": -0.0018065725895798578, "dist_entropy": 0.4732429802417755, "actor_grad_norm": 0.1353336125612259, "critic_grad_norm": 0.02592422068119049, "ratio": 0.9997982978820801, "entropy": 0.4732429802417755, "incre_win_rate": 0.7333333333333333, "step": 2863}
{"time": 1767093103.0345416, "phase": "train", "update": 2864, "total_env_steps": 9164800, "episode_reward": 0.26673582196235657, "value_loss": 0.006664496567100287, "policy_loss": -0.0017969994738450622, "dist_entropy": 0.463824725151062, "actor_grad_norm": 0.10897482931613922, "critic_grad_norm": 0.03409181162714958, "ratio": 0.9995641708374023, "entropy": 0.463824725151062, "incre_win_rate": 0.8409090909090909, "step": 2864}
{"time": 1767093108.118996, "phase": "train", "update": 2865, "total_env_steps": 9168000, "episode_reward": 0.24950382113456726, "value_loss": 0.007569885160773992, "policy_loss": -0.0014743938613728247, "dist_entropy": 0.4701089859008789, "actor_grad_norm": 0.13406924903392792, "critic_grad_norm": 0.03757009282708168, "ratio": 1.0000660419464111, "entropy": 0.4701089859008789, "incre_win_rate": 0.7674418604651163, "step": 2865}
{"time": 1767093113.158359, "phase": "train", "update": 2866, "total_env_steps": 9171200, "episode_reward": 0.25525403022766113, "value_loss": 0.0077120869420468805, "policy_loss": -0.001703768045445031, "dist_entropy": 0.48102150559425355, "actor_grad_norm": 0.10714869946241379, "critic_grad_norm": 0.034214939922094345, "ratio": 1.000370979309082, "entropy": 0.48102150559425355, "incre_win_rate": 0.7111111111111111, "step": 2866}
{"time": 1767093118.2668529, "phase": "train", "update": 2867, "total_env_steps": 9174400, "episode_reward": 0.25905007123947144, "value_loss": 0.007518087141215801, "policy_loss": -0.001540469108586251, "dist_entropy": 0.4664759814739227, "actor_grad_norm": 0.13806194067001343, "critic_grad_norm": 0.018857792019844055, "ratio": 1.0001353025436401, "entropy": 0.4664759814739227, "incre_win_rate": 0.7727272727272727, "step": 2867}
{"time": 1767093123.3288825, "phase": "train", "update": 2868, "total_env_steps": 9177600, "episode_reward": 0.25055205821990967, "value_loss": 0.008821727894246578, "policy_loss": -0.0017489500757285725, "dist_entropy": 0.4721140325069427, "actor_grad_norm": 0.12467359751462936, "critic_grad_norm": 0.026831740513443947, "ratio": 1.0003552436828613, "entropy": 0.4721140325069427, "incre_win_rate": 0.7619047619047619, "step": 2868}
{"time": 1767093128.4598477, "phase": "train", "update": 2869, "total_env_steps": 9180800, "episode_reward": 0.2539740204811096, "value_loss": 0.010029054433107375, "policy_loss": -0.0021121215991300344, "dist_entropy": 0.4562749326229095, "actor_grad_norm": 0.13465578854084015, "critic_grad_norm": 0.03414539620280266, "ratio": 1.0003101825714111, "entropy": 0.4562749326229095, "incre_win_rate": 0.7142857142857143, "step": 2869}
{"time": 1767093133.4241498, "phase": "train", "update": 2870, "total_env_steps": 9184000, "episode_reward": 0.24393367767333984, "value_loss": 0.007432596758008003, "policy_loss": -0.0014270739167812963, "dist_entropy": 0.4848197281360626, "actor_grad_norm": 0.1263895481824875, "critic_grad_norm": 0.02466828003525734, "ratio": 1.0000027418136597, "entropy": 0.4848197281360626, "incre_win_rate": 0.7272727272727273, "step": 2870}
{"time": 1767093138.4805207, "phase": "train", "update": 2871, "total_env_steps": 9187200, "episode_reward": 0.2591995894908905, "value_loss": 0.007061873283237219, "policy_loss": -0.0016749861079688344, "dist_entropy": 0.4708449125289917, "actor_grad_norm": 0.12685927748680115, "critic_grad_norm": 0.02155546098947525, "ratio": 1.000078558921814, "entropy": 0.4708449125289917, "incre_win_rate": 0.7954545454545454, "step": 2871}
{"time": 1767093143.5096753, "phase": "train", "update": 2872, "total_env_steps": 9190400, "episode_reward": 0.24661269783973694, "value_loss": 0.007340834382921458, "policy_loss": -0.0012544525222516257, "dist_entropy": 0.49042349457740786, "actor_grad_norm": 0.13159853219985962, "critic_grad_norm": 0.029266521334648132, "ratio": 0.9999896287918091, "entropy": 0.49042349457740786, "incre_win_rate": 0.813953488372093, "step": 2872}
{"time": 1767093148.6670732, "phase": "train", "update": 2873, "total_env_steps": 9193600, "episode_reward": 0.2607543468475342, "value_loss": 0.005981228873133659, "policy_loss": -0.0016373302285806802, "dist_entropy": 0.4907426774501801, "actor_grad_norm": 0.18346674740314484, "critic_grad_norm": 0.022748557850718498, "ratio": 1.0001722574234009, "entropy": 0.4907426774501801, "incre_win_rate": 0.8095238095238095, "step": 2873}
{"time": 1767093153.6867697, "phase": "train", "update": 2874, "total_env_steps": 9196800, "episode_reward": 0.2469220906496048, "value_loss": 0.010118095204234123, "policy_loss": -0.0017563609457596386, "dist_entropy": 0.4743447661399841, "actor_grad_norm": 0.11913557350635529, "critic_grad_norm": 0.0676024928689003, "ratio": 1.0002096891403198, "entropy": 0.4743447661399841, "incre_win_rate": 0.7111111111111111, "step": 2874}
{"time": 1767093158.706825, "phase": "train", "update": 2875, "total_env_steps": 9200000, "episode_reward": 0.23841163516044617, "value_loss": 0.00795128233730793, "policy_loss": -0.0014625596262689555, "dist_entropy": 0.4776536047458649, "actor_grad_norm": 0.16678206622600555, "critic_grad_norm": 0.06999345123767853, "ratio": 1.000529170036316, "entropy": 0.4776536047458649, "incre_win_rate": 0.717948717948718, "step": 2875}
{"time": 1767093163.7869697, "phase": "train", "update": 2876, "total_env_steps": 9203200, "episode_reward": 0.2425481081008911, "value_loss": 0.008298265933990478, "policy_loss": -0.0017770560903286991, "dist_entropy": 0.4832809567451477, "actor_grad_norm": 0.1662052720785141, "critic_grad_norm": 0.052639733999967575, "ratio": 1.000062108039856, "entropy": 0.4832809567451477, "incre_win_rate": 0.6511627906976745, "step": 2876}
{"time": 1767093168.8260727, "phase": "train", "update": 2877, "total_env_steps": 9206400, "episode_reward": 0.24580246210098267, "value_loss": 0.006809124443680048, "policy_loss": -0.001565351615158761, "dist_entropy": 0.4896560549736023, "actor_grad_norm": 0.12082462757825851, "critic_grad_norm": 0.025469601154327393, "ratio": 1.0000947713851929, "entropy": 0.4896560549736023, "incre_win_rate": 0.75, "step": 2877}
{"time": 1767093173.9161646, "phase": "train", "update": 2878, "total_env_steps": 9209600, "episode_reward": 0.2580448091030121, "value_loss": 0.0057448803447186945, "policy_loss": -0.001827107000480055, "dist_entropy": 0.46253650188446044, "actor_grad_norm": 0.12723542749881744, "critic_grad_norm": 0.03292157128453255, "ratio": 0.9997498393058777, "entropy": 0.46253650188446044, "incre_win_rate": 0.7608695652173914, "step": 2878}
{"time": 1767093178.955543, "phase": "train", "update": 2879, "total_env_steps": 9212800, "episode_reward": 0.25622105598449707, "value_loss": 0.007215221039950847, "policy_loss": -0.0015530189501305359, "dist_entropy": 0.470903217792511, "actor_grad_norm": 0.10308624804019928, "critic_grad_norm": 0.01656309701502323, "ratio": 0.999686062335968, "entropy": 0.470903217792511, "incre_win_rate": 0.8048780487804879, "step": 2879}
{"time": 1767093184.018169, "phase": "train", "update": 2880, "total_env_steps": 9216000, "episode_reward": 0.2507103681564331, "value_loss": 0.005274485424160957, "policy_loss": -0.002172533841951463, "dist_entropy": 0.47002583742141724, "actor_grad_norm": 0.12955665588378906, "critic_grad_norm": 0.023415712639689445, "ratio": 0.9996344447135925, "entropy": 0.47002583742141724, "incre_win_rate": 0.7555555555555555, "step": 2880}
{"time": 1767093189.0824883, "phase": "train", "update": 2881, "total_env_steps": 9219200, "episode_reward": 0.24995966255664825, "value_loss": 0.007720804959535599, "policy_loss": -0.0024644625807188625, "dist_entropy": 0.4816636621952057, "actor_grad_norm": 0.12103910744190216, "critic_grad_norm": 0.05463394150137901, "ratio": 1.000090479850769, "entropy": 0.4816636621952057, "incre_win_rate": 0.7560975609756098, "step": 2881}
{"time": 1767093201.0888312, "phase": "eval", "update": 2881, "total_env_steps": 9219200, "eval_win_rate": 0.875, "eval_episode_reward": 19.318708609271525, "step": 2881}
{"time": 1767093206.0976803, "phase": "train", "update": 2882, "total_env_steps": 9222400, "episode_reward": 0.25638657808303833, "value_loss": 0.0072408076375722885, "policy_loss": -0.0020469757768207587, "dist_entropy": 0.4559242844581604, "actor_grad_norm": 0.13345636427402496, "critic_grad_norm": 0.03659709915518761, "ratio": 0.999297559261322, "entropy": 0.4559242844581604, "incre_win_rate": 0.7608695652173914, "step": 2882}
{"time": 1767093211.1995716, "phase": "train", "update": 2883, "total_env_steps": 9225600, "episode_reward": 0.2458355873823166, "value_loss": 0.009077040292322636, "policy_loss": -0.0018850677353924538, "dist_entropy": 0.47192143797874453, "actor_grad_norm": 0.11373146623373032, "critic_grad_norm": 0.03200487419962883, "ratio": 0.9997642636299133, "entropy": 0.47192143797874453, "incre_win_rate": 0.6, "step": 2883}
{"time": 1767093216.3182166, "phase": "train", "update": 2884, "total_env_steps": 9228800, "episode_reward": 0.2593429684638977, "value_loss": 0.005766393803060055, "policy_loss": -0.0015955399957761074, "dist_entropy": 0.48131433725357053, "actor_grad_norm": 0.10673590004444122, "critic_grad_norm": 0.04043835029006004, "ratio": 1.0000596046447754, "entropy": 0.48131433725357053, "incre_win_rate": 0.7446808510638298, "step": 2884}
{"time": 1767093221.517472, "phase": "train", "update": 2885, "total_env_steps": 9232000, "episode_reward": 0.25320208072662354, "value_loss": 0.010525734350085258, "policy_loss": -0.0021486613423839173, "dist_entropy": 0.4825242578983307, "actor_grad_norm": 0.13321542739868164, "critic_grad_norm": 0.078382708132267, "ratio": 0.9999759793281555, "entropy": 0.4825242578983307, "incre_win_rate": 0.7111111111111111, "step": 2885}
{"time": 1767093226.5192077, "phase": "train", "update": 2886, "total_env_steps": 9235200, "episode_reward": 0.2238912582397461, "value_loss": 0.013308870233595371, "policy_loss": -0.0023664282085860576, "dist_entropy": 0.4762670695781708, "actor_grad_norm": 0.16031022369861603, "critic_grad_norm": 0.08939044922590256, "ratio": 0.9998640418052673, "entropy": 0.4762670695781708, "incre_win_rate": 0.5675675675675675, "step": 2886}
{"time": 1767093231.5564187, "phase": "train", "update": 2887, "total_env_steps": 9238400, "episode_reward": 0.2276345193386078, "value_loss": 0.010202057659626007, "policy_loss": -0.0016496019254347515, "dist_entropy": 0.48956283926963806, "actor_grad_norm": 0.12752443552017212, "critic_grad_norm": 0.043507229536771774, "ratio": 0.9996902346611023, "entropy": 0.48956283926963806, "incre_win_rate": 0.5714285714285714, "step": 2887}
{"time": 1767093236.6013534, "phase": "train", "update": 2888, "total_env_steps": 9241600, "episode_reward": 0.25665563344955444, "value_loss": 0.008428643830120564, "policy_loss": -0.0018083066171681761, "dist_entropy": 0.46562470197677613, "actor_grad_norm": 0.13049541413784027, "critic_grad_norm": 0.06978065520524979, "ratio": 0.9999634027481079, "entropy": 0.46562470197677613, "incre_win_rate": 0.7727272727272727, "step": 2888}
{"time": 1767093241.7379262, "phase": "train", "update": 2889, "total_env_steps": 9244800, "episode_reward": 0.2606436312198639, "value_loss": 0.006295353733003139, "policy_loss": -0.0017039868173078787, "dist_entropy": 0.48206353187561035, "actor_grad_norm": 0.1224244013428688, "critic_grad_norm": 0.08718793839216232, "ratio": 1.0001068115234375, "entropy": 0.48206353187561035, "incre_win_rate": 0.8604651162790697, "step": 2889}
{"time": 1767093246.806206, "phase": "train", "update": 2890, "total_env_steps": 9248000, "episode_reward": 0.24515575170516968, "value_loss": 0.010422993823885918, "policy_loss": -0.0015624441013486034, "dist_entropy": 0.46710057854652404, "actor_grad_norm": 0.10215380042791367, "critic_grad_norm": 0.09137053042650223, "ratio": 1.0000017881393433, "entropy": 0.46710057854652404, "incre_win_rate": 0.6888888888888889, "step": 2890}
{"time": 1767093252.1088665, "phase": "train", "update": 2891, "total_env_steps": 9251200, "episode_reward": 0.2375181019306183, "value_loss": 0.010126678086817265, "policy_loss": -0.0020544233451481376, "dist_entropy": 0.4741457521915436, "actor_grad_norm": 0.10441255569458008, "critic_grad_norm": 0.07062854617834091, "ratio": 1.0000156164169312, "entropy": 0.4741457521915436, "incre_win_rate": 0.7435897435897436, "step": 2891}
{"time": 1767093257.4066486, "phase": "train", "update": 2892, "total_env_steps": 9254400, "episode_reward": 0.24254967272281647, "value_loss": 0.008877715840935708, "policy_loss": -0.0021204471785228663, "dist_entropy": 0.46802322268486024, "actor_grad_norm": 0.1029590591788292, "critic_grad_norm": 0.025046436116099358, "ratio": 1.000015139579773, "entropy": 0.46802322268486024, "incre_win_rate": 0.7045454545454546, "step": 2892}
{"time": 1767093262.512991, "phase": "train", "update": 2893, "total_env_steps": 9257600, "episode_reward": 0.26501190662384033, "value_loss": 0.005695679970085621, "policy_loss": -0.0015182470838411178, "dist_entropy": 0.45771140456199644, "actor_grad_norm": 0.15815065801143646, "critic_grad_norm": 0.03488284721970558, "ratio": 0.9999076724052429, "entropy": 0.45771140456199644, "incre_win_rate": 0.8372093023255814, "step": 2893}
{"time": 1767093267.5628724, "phase": "train", "update": 2894, "total_env_steps": 9260800, "episode_reward": 0.2483324557542801, "value_loss": 0.009896384365856648, "policy_loss": -0.0015276586750815114, "dist_entropy": 0.4711652874946594, "actor_grad_norm": 0.19391398131847382, "critic_grad_norm": 0.021045882254838943, "ratio": 1.0001294612884521, "entropy": 0.4711652874946594, "incre_win_rate": 0.7209302325581395, "step": 2894}
{"time": 1767093272.6003087, "phase": "train", "update": 2895, "total_env_steps": 9264000, "episode_reward": 0.23648282885551453, "value_loss": 0.008918307907879352, "policy_loss": -0.0018962043293981878, "dist_entropy": 0.4795240521430969, "actor_grad_norm": 0.12105226516723633, "critic_grad_norm": 0.029330933466553688, "ratio": 1.0000622272491455, "entropy": 0.4795240521430969, "incre_win_rate": 0.7073170731707317, "step": 2895}
{"time": 1767093277.696554, "phase": "train", "update": 2896, "total_env_steps": 9267200, "episode_reward": 0.25576213002204895, "value_loss": 0.006840354483574629, "policy_loss": -0.0017207283233408254, "dist_entropy": 0.4725069046020508, "actor_grad_norm": 0.13275271654129028, "critic_grad_norm": 0.04103624448180199, "ratio": 0.9998364448547363, "entropy": 0.4725069046020508, "incre_win_rate": 0.813953488372093, "step": 2896}
{"time": 1767093282.7496982, "phase": "train", "update": 2897, "total_env_steps": 9270400, "episode_reward": 0.2603921592235565, "value_loss": 0.007292630895972252, "policy_loss": -0.0018096315975205002, "dist_entropy": 0.48317926526069643, "actor_grad_norm": 0.1590552031993866, "critic_grad_norm": 0.02547883428633213, "ratio": 1.000091791152954, "entropy": 0.48317926526069643, "incre_win_rate": 0.8409090909090909, "step": 2897}
{"time": 1767093287.9082227, "phase": "train", "update": 2898, "total_env_steps": 9273600, "episode_reward": 0.2667115032672882, "value_loss": 0.007614865619689226, "policy_loss": -0.0013113029988673474, "dist_entropy": 0.47225435376167296, "actor_grad_norm": 0.1527150422334671, "critic_grad_norm": 0.028275394812226295, "ratio": 0.999776303768158, "entropy": 0.47225435376167296, "incre_win_rate": 0.8636363636363636, "step": 2898}
{"time": 1767093293.008142, "phase": "train", "update": 2899, "total_env_steps": 9276800, "episode_reward": 0.24405941367149353, "value_loss": 0.009522389993071556, "policy_loss": -0.0016499041672734193, "dist_entropy": 0.48170808553695676, "actor_grad_norm": 0.17127282917499542, "critic_grad_norm": 0.07319841533899307, "ratio": 0.9999892115592957, "entropy": 0.48170808553695676, "incre_win_rate": 0.6829268292682927, "step": 2899}
{"time": 1767093298.159452, "phase": "train", "update": 2900, "total_env_steps": 9280000, "episode_reward": 0.25971338152885437, "value_loss": 0.00789229767397046, "policy_loss": -0.0017034167262380607, "dist_entropy": 0.46435015797615053, "actor_grad_norm": 0.173985555768013, "critic_grad_norm": 0.05534234270453453, "ratio": 1.0000145435333252, "entropy": 0.46435015797615053, "incre_win_rate": 0.7608695652173914, "step": 2900}
{"time": 1767093303.317747, "phase": "train", "update": 2901, "total_env_steps": 9283200, "episode_reward": 0.2490961253643036, "value_loss": 0.009562318585813046, "policy_loss": -0.0012667838817568722, "dist_entropy": 0.4717481255531311, "actor_grad_norm": 0.13198670744895935, "critic_grad_norm": 0.03309875354170799, "ratio": 0.9998462796211243, "entropy": 0.4717481255531311, "incre_win_rate": 0.7906976744186046, "step": 2901}
{"time": 1767093322.1820955, "phase": "eval", "update": 2901, "total_env_steps": 9283200, "eval_win_rate": 0.84375, "eval_episode_reward": 19.147971854304636, "step": 2901}
{"time": 1767093327.175028, "phase": "train", "update": 2902, "total_env_steps": 9286400, "episode_reward": 0.24768470227718353, "value_loss": 0.008324082382023335, "policy_loss": -0.0018311942821213733, "dist_entropy": 0.4668014943599701, "actor_grad_norm": 0.13579325377941132, "critic_grad_norm": 0.05086548253893852, "ratio": 0.9996376037597656, "entropy": 0.4668014943599701, "incre_win_rate": 0.6904761904761905, "step": 2902}
{"time": 1767093332.2369983, "phase": "train", "update": 2903, "total_env_steps": 9289600, "episode_reward": 0.2532879710197449, "value_loss": 0.006756703462451696, "policy_loss": -0.0014317332032661057, "dist_entropy": 0.4759828269481659, "actor_grad_norm": 0.1206323504447937, "critic_grad_norm": 0.057318396866321564, "ratio": 1.0001269578933716, "entropy": 0.4759828269481659, "incre_win_rate": 0.8095238095238095, "step": 2903}
{"time": 1767093337.3249314, "phase": "train", "update": 2904, "total_env_steps": 9292800, "episode_reward": 0.25169649720191956, "value_loss": 0.006747220363467932, "policy_loss": -0.0018998198290177016, "dist_entropy": 0.4604990482330322, "actor_grad_norm": 0.11901222914457321, "critic_grad_norm": 0.025576887652277946, "ratio": 1.0001286268234253, "entropy": 0.4604990482330322, "incre_win_rate": 0.7619047619047619, "step": 2904}
{"time": 1767093342.46009, "phase": "train", "update": 2905, "total_env_steps": 9296000, "episode_reward": 0.2552705705165863, "value_loss": 0.007698898576200009, "policy_loss": -0.001780982315300328, "dist_entropy": 0.4611799955368042, "actor_grad_norm": 0.11023733764886856, "critic_grad_norm": 0.07092658430337906, "ratio": 0.9997559785842896, "entropy": 0.4611799955368042, "incre_win_rate": 0.7391304347826086, "step": 2905}
{"time": 1767093347.54184, "phase": "train", "update": 2906, "total_env_steps": 9299200, "episode_reward": 0.25434863567352295, "value_loss": 0.00839545726776123, "policy_loss": -0.0017607753907002532, "dist_entropy": 0.45319737792015075, "actor_grad_norm": 0.13601438701152802, "critic_grad_norm": 0.05541721731424332, "ratio": 1.0002750158309937, "entropy": 0.45319737792015075, "incre_win_rate": 0.7674418604651163, "step": 2906}
{"time": 1767093352.6724122, "phase": "train", "update": 2907, "total_env_steps": 9302400, "episode_reward": 0.2518662214279175, "value_loss": 0.007089217659085989, "policy_loss": -0.0018406599122939404, "dist_entropy": 0.45192339420318606, "actor_grad_norm": 0.1441287249326706, "critic_grad_norm": 0.0442732572555542, "ratio": 0.9997856020927429, "entropy": 0.45192339420318606, "incre_win_rate": 0.6976744186046512, "step": 2907}
{"time": 1767093357.6674435, "phase": "train", "update": 2908, "total_env_steps": 9305600, "episode_reward": 0.24776853621006012, "value_loss": 0.007008921168744564, "policy_loss": -0.0013589432473651187, "dist_entropy": 0.4552175283432007, "actor_grad_norm": 0.13387082517147064, "critic_grad_norm": 0.04135068878531456, "ratio": 1.0000998973846436, "entropy": 0.4552175283432007, "incre_win_rate": 0.6976744186046512, "step": 2908}
{"time": 1767093362.7088852, "phase": "train", "update": 2909, "total_env_steps": 9308800, "episode_reward": 0.262464314699173, "value_loss": 0.005476366821676492, "policy_loss": -0.0016269778069911921, "dist_entropy": 0.45705938935279844, "actor_grad_norm": 0.14964652061462402, "critic_grad_norm": 0.04407700523734093, "ratio": 1.000441551208496, "entropy": 0.45705938935279844, "incre_win_rate": 0.8809523809523809, "step": 2909}
{"time": 1767093367.7328544, "phase": "train", "update": 2910, "total_env_steps": 9312000, "episode_reward": 0.2581612169742584, "value_loss": 0.006679867673665285, "policy_loss": -0.0017700217276836127, "dist_entropy": 0.45410747528076173, "actor_grad_norm": 0.14773157238960266, "critic_grad_norm": 0.028269821777939796, "ratio": 0.9999784827232361, "entropy": 0.45410747528076173, "incre_win_rate": 0.8409090909090909, "step": 2910}
{"time": 1767093372.809347, "phase": "train", "update": 2911, "total_env_steps": 9315200, "episode_reward": 0.25846442580223083, "value_loss": 0.0063545111566782, "policy_loss": -0.0015369314909108311, "dist_entropy": 0.4305984377861023, "actor_grad_norm": 0.1192944198846817, "critic_grad_norm": 0.026519669219851494, "ratio": 0.9998475313186646, "entropy": 0.4305984377861023, "incre_win_rate": 0.7857142857142857, "step": 2911}
{"time": 1767093377.8889503, "phase": "train", "update": 2912, "total_env_steps": 9318400, "episode_reward": 0.2590593993663788, "value_loss": 0.0057250170037150385, "policy_loss": -0.001573711390570054, "dist_entropy": 0.44484657049179077, "actor_grad_norm": 0.12083108723163605, "critic_grad_norm": 0.055653613060712814, "ratio": 0.9996680617332458, "entropy": 0.44484657049179077, "incre_win_rate": 0.8636363636363636, "step": 2912}
{"time": 1767093382.9886818, "phase": "train", "update": 2913, "total_env_steps": 9321600, "episode_reward": 0.25167685747146606, "value_loss": 0.006764353718608618, "policy_loss": -0.0016909273300448556, "dist_entropy": 0.44972382187843324, "actor_grad_norm": 0.10406819730997086, "critic_grad_norm": 0.036299508064985275, "ratio": 0.9996808171272278, "entropy": 0.44972382187843324, "incre_win_rate": 0.7674418604651163, "step": 2913}
{"time": 1767093388.0411134, "phase": "train", "update": 2914, "total_env_steps": 9324800, "episode_reward": 0.2586832642555237, "value_loss": 0.005966836586594582, "policy_loss": -0.0014641584333233482, "dist_entropy": 0.4543437957763672, "actor_grad_norm": 0.10805846750736237, "critic_grad_norm": 0.02544429898262024, "ratio": 0.9997194409370422, "entropy": 0.4543437957763672, "incre_win_rate": 0.8095238095238095, "step": 2914}
{"time": 1767093393.2109878, "phase": "train", "update": 2915, "total_env_steps": 9328000, "episode_reward": 0.26652318239212036, "value_loss": 0.005712221376597881, "policy_loss": -0.0018728497286573998, "dist_entropy": 0.43697360157966614, "actor_grad_norm": 0.12395330518484116, "critic_grad_norm": 0.03179513290524483, "ratio": 0.9995632171630859, "entropy": 0.43697360157966614, "incre_win_rate": 0.8181818181818182, "step": 2915}
{"time": 1767093398.011179, "phase": "train", "update": 2916, "total_env_steps": 9331200, "episode_reward": 0.2469676434993744, "value_loss": 0.0072650664485991, "policy_loss": -0.0017151288851465552, "dist_entropy": 0.4339529573917389, "actor_grad_norm": 0.11285986006259918, "critic_grad_norm": 0.041654322296381, "ratio": 1.0001957416534424, "entropy": 0.4339529573917389, "incre_win_rate": 0.7111111111111111, "step": 2916}
{"time": 1767093402.758135, "phase": "train", "update": 2917, "total_env_steps": 9334400, "episode_reward": 0.25282594561576843, "value_loss": 0.006971589662134648, "policy_loss": -0.0013049135371716147, "dist_entropy": 0.4523242175579071, "actor_grad_norm": 0.1094607338309288, "critic_grad_norm": 0.05135313421487808, "ratio": 0.999779999256134, "entropy": 0.4523242175579071, "incre_win_rate": 0.6829268292682927, "step": 2917}
{"time": 1767093407.550734, "phase": "train", "update": 2918, "total_env_steps": 9337600, "episode_reward": 0.263579785823822, "value_loss": 0.0054692204110324385, "policy_loss": -0.0018135177198878693, "dist_entropy": 0.4564063310623169, "actor_grad_norm": 0.11540620774030685, "critic_grad_norm": 0.03226465731859207, "ratio": 0.9999974370002747, "entropy": 0.4564063310623169, "incre_win_rate": 0.8666666666666667, "step": 2918}
{"time": 1767093412.271001, "phase": "train", "update": 2919, "total_env_steps": 9340800, "episode_reward": 0.24579420685768127, "value_loss": 0.006713954173028469, "policy_loss": -0.0015417757429010415, "dist_entropy": 0.45983744859695436, "actor_grad_norm": 0.10930005460977554, "critic_grad_norm": 0.03618570789694786, "ratio": 0.9999109506607056, "entropy": 0.45983744859695436, "incre_win_rate": 0.7619047619047619, "step": 2919}
{"time": 1767093416.9885702, "phase": "train", "update": 2920, "total_env_steps": 9344000, "episode_reward": 0.26046255230903625, "value_loss": 0.0072346625849604605, "policy_loss": -0.0017536365802204301, "dist_entropy": 0.4405878961086273, "actor_grad_norm": 0.16251157224178314, "critic_grad_norm": 0.03250163793563843, "ratio": 0.9997332692146301, "entropy": 0.4405878961086273, "incre_win_rate": 0.7674418604651163, "step": 2920}
{"time": 1767093421.7270849, "phase": "train", "update": 2921, "total_env_steps": 9347200, "episode_reward": 0.26712074875831604, "value_loss": 0.006946734432131052, "policy_loss": -0.0017224209533679869, "dist_entropy": 0.4626518189907074, "actor_grad_norm": 0.13706520199775696, "critic_grad_norm": 0.03076517954468727, "ratio": 1.0000702142715454, "entropy": 0.4626518189907074, "incre_win_rate": 0.8636363636363636, "step": 2921}
{"time": 1767093432.871002, "phase": "eval", "update": 2921, "total_env_steps": 9347200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.501914321192054, "step": 2921}
{"time": 1767093437.629702, "phase": "train", "update": 2922, "total_env_steps": 9350400, "episode_reward": 0.2559545934200287, "value_loss": 0.007636899780482054, "policy_loss": -0.001600347778609379, "dist_entropy": 0.4611654579639435, "actor_grad_norm": 0.13046659529209137, "critic_grad_norm": 0.026037810370326042, "ratio": 0.9999484419822693, "entropy": 0.4611654579639435, "incre_win_rate": 0.7391304347826086, "step": 2922}
{"time": 1767093442.3472946, "phase": "train", "update": 2923, "total_env_steps": 9353600, "episode_reward": 0.25709953904151917, "value_loss": 0.007272371556609869, "policy_loss": -0.0017592479643695925, "dist_entropy": 0.4449778914451599, "actor_grad_norm": 0.13389097154140472, "critic_grad_norm": 0.025328848510980606, "ratio": 0.9996978640556335, "entropy": 0.4449778914451599, "incre_win_rate": 0.8, "step": 2923}
{"time": 1767093447.020497, "phase": "train", "update": 2924, "total_env_steps": 9356800, "episode_reward": 0.2413855493068695, "value_loss": 0.00819086292758584, "policy_loss": -0.0016065082156686116, "dist_entropy": 0.4590644598007202, "actor_grad_norm": 0.15419669449329376, "critic_grad_norm": 0.030708415433764458, "ratio": 1.0003818273544312, "entropy": 0.4590644598007202, "incre_win_rate": 0.6222222222222222, "step": 2924}
{"time": 1767093451.7046778, "phase": "train", "update": 2925, "total_env_steps": 9360000, "episode_reward": 0.23628932237625122, "value_loss": 0.0077187538146972655, "policy_loss": -0.0016833802844786305, "dist_entropy": 0.4573397099971771, "actor_grad_norm": 0.12051814049482346, "critic_grad_norm": 0.033459629863500595, "ratio": 0.9999793171882629, "entropy": 0.4573397099971771, "incre_win_rate": 0.65, "step": 2925}
{"time": 1767093456.4304044, "phase": "train", "update": 2926, "total_env_steps": 9363200, "episode_reward": 0.2536812126636505, "value_loss": 0.009552504681050778, "policy_loss": -0.0017024872027207039, "dist_entropy": 0.46487110257148745, "actor_grad_norm": 0.14156198501586914, "critic_grad_norm": 0.04346239194273949, "ratio": 0.9992023706436157, "entropy": 0.46487110257148745, "incre_win_rate": 0.717391304347826, "step": 2926}
{"time": 1767093461.1844096, "phase": "train", "update": 2927, "total_env_steps": 9366400, "episode_reward": 0.24445419013500214, "value_loss": 0.010851618647575379, "policy_loss": -0.0016861083014049426, "dist_entropy": 0.46062893867492677, "actor_grad_norm": 0.13673196732997894, "critic_grad_norm": 0.05792728066444397, "ratio": 0.9999977946281433, "entropy": 0.46062893867492677, "incre_win_rate": 0.6190476190476191, "step": 2927}
{"time": 1767093465.900238, "phase": "train", "update": 2928, "total_env_steps": 9369600, "episode_reward": 0.2523990869522095, "value_loss": 0.00896637663245201, "policy_loss": -0.0017870099711331023, "dist_entropy": 0.46073771119117735, "actor_grad_norm": 0.13562028110027313, "critic_grad_norm": 0.05485926941037178, "ratio": 0.9997611045837402, "entropy": 0.46073771119117735, "incre_win_rate": 0.7111111111111111, "step": 2928}
{"time": 1767093470.6774426, "phase": "train", "update": 2929, "total_env_steps": 9372800, "episode_reward": 0.259909451007843, "value_loss": 0.0073040475137531756, "policy_loss": -0.0016288226374513216, "dist_entropy": 0.44659515619277956, "actor_grad_norm": 0.10208339989185333, "critic_grad_norm": 0.07648501545190811, "ratio": 0.9999924898147583, "entropy": 0.44659515619277956, "incre_win_rate": 0.8333333333333334, "step": 2929}
{"time": 1767093475.4275324, "phase": "train", "update": 2930, "total_env_steps": 9376000, "episode_reward": 0.26449763774871826, "value_loss": 0.008088909462094307, "policy_loss": -0.001986651853684407, "dist_entropy": 0.45598851442337035, "actor_grad_norm": 0.1250625103712082, "critic_grad_norm": 0.042797647416591644, "ratio": 0.9998647570610046, "entropy": 0.45598851442337035, "incre_win_rate": 0.8260869565217391, "step": 2930}
{"time": 1767093480.1465635, "phase": "train", "update": 2931, "total_env_steps": 9379200, "episode_reward": 0.2582527995109558, "value_loss": 0.008828174881637096, "policy_loss": -0.0013799936850389827, "dist_entropy": 0.4523049592971802, "actor_grad_norm": 0.12408743053674698, "critic_grad_norm": 0.03591976687312126, "ratio": 0.9999780654907227, "entropy": 0.4523049592971802, "incre_win_rate": 0.7555555555555555, "step": 2931}
{"time": 1767093484.894803, "phase": "train", "update": 2932, "total_env_steps": 9382400, "episode_reward": 0.2663514316082001, "value_loss": 0.0066428867168724535, "policy_loss": -0.0015116496040711524, "dist_entropy": 0.45763516426086426, "actor_grad_norm": 0.1343148797750473, "critic_grad_norm": 0.023201776668429375, "ratio": 0.9996390342712402, "entropy": 0.45763516426086426, "incre_win_rate": 0.8571428571428571, "step": 2932}
{"time": 1767093489.658997, "phase": "train", "update": 2933, "total_env_steps": 9385600, "episode_reward": 0.2604190707206726, "value_loss": 0.006986761651933193, "policy_loss": -0.001610330643992608, "dist_entropy": 0.45377113223075866, "actor_grad_norm": 0.12667782604694366, "critic_grad_norm": 0.019819295033812523, "ratio": 0.9999580383300781, "entropy": 0.45377113223075866, "incre_win_rate": 0.8085106382978723, "step": 2933}
{"time": 1767093494.404729, "phase": "train", "update": 2934, "total_env_steps": 9388800, "episode_reward": 0.24678082764148712, "value_loss": 0.008306187950074673, "policy_loss": -0.002053015699027583, "dist_entropy": 0.45090063810348513, "actor_grad_norm": 0.12573204934597015, "critic_grad_norm": 0.020216017961502075, "ratio": 1.0000808238983154, "entropy": 0.45090063810348513, "incre_win_rate": 0.6585365853658537, "step": 2934}
{"time": 1767093499.0884073, "phase": "train", "update": 2935, "total_env_steps": 9392000, "episode_reward": 0.2495023012161255, "value_loss": 0.008575868234038353, "policy_loss": -0.0016426773853112308, "dist_entropy": 0.46096824407577514, "actor_grad_norm": 0.12101053446531296, "critic_grad_norm": 0.03038589470088482, "ratio": 1.0002472400665283, "entropy": 0.46096824407577514, "incre_win_rate": 0.6666666666666666, "step": 2935}
{"time": 1767093503.8113074, "phase": "train", "update": 2936, "total_env_steps": 9395200, "episode_reward": 0.262979120016098, "value_loss": 0.006648602895438671, "policy_loss": -0.001778753734510019, "dist_entropy": 0.45870059728622437, "actor_grad_norm": 0.12252505868673325, "critic_grad_norm": 0.06468486785888672, "ratio": 0.9999725222587585, "entropy": 0.45870059728622437, "incre_win_rate": 0.8292682926829268, "step": 2936}
{"time": 1767093508.5113354, "phase": "train", "update": 2937, "total_env_steps": 9398400, "episode_reward": 0.2672056257724762, "value_loss": 0.004624596424400806, "policy_loss": -0.0015460115114763085, "dist_entropy": 0.4575771987438202, "actor_grad_norm": 0.14577616751194, "critic_grad_norm": 0.056248247623443604, "ratio": 0.9999291300773621, "entropy": 0.4575771987438202, "incre_win_rate": 0.8541666666666666, "step": 2937}
{"time": 1767093513.1631348, "phase": "train", "update": 2938, "total_env_steps": 9401600, "episode_reward": 0.2681296765804291, "value_loss": 0.00659621125087142, "policy_loss": -0.0017819330253196596, "dist_entropy": 0.4524927079677582, "actor_grad_norm": 0.12177425622940063, "critic_grad_norm": 0.024604646489024162, "ratio": 1.0000998973846436, "entropy": 0.4524927079677582, "incre_win_rate": 0.8536585365853658, "step": 2938}
{"time": 1767093517.9006567, "phase": "train", "update": 2939, "total_env_steps": 9404800, "episode_reward": 0.2565061151981354, "value_loss": 0.009360910020768642, "policy_loss": -0.0016648656530016126, "dist_entropy": 0.4718378663063049, "actor_grad_norm": 0.13215111196041107, "critic_grad_norm": 0.042307645082473755, "ratio": 0.999618649482727, "entropy": 0.4718378663063049, "incre_win_rate": 0.7608695652173914, "step": 2939}
{"time": 1767093522.6981447, "phase": "train", "update": 2940, "total_env_steps": 9408000, "episode_reward": 0.25788700580596924, "value_loss": 0.005647152476012707, "policy_loss": -0.001390789855608432, "dist_entropy": 0.46247257590293883, "actor_grad_norm": 0.10605597496032715, "critic_grad_norm": 0.043641626834869385, "ratio": 0.9995623826980591, "entropy": 0.46247257590293883, "incre_win_rate": 0.8095238095238095, "step": 2940}
{"time": 1767093552.6717975, "phase": "train", "update": 2941, "total_env_steps": 9411200, "episode_reward": 0.2667844593524933, "value_loss": 0.046608966588973996, "policy_loss": -0.0016224738264291716, "dist_entropy": 0.4490429997444153, "actor_grad_norm": 0.14494934678077698, "critic_grad_norm": 0.14418473839759827, "ratio": 1.000157356262207, "entropy": 0.4490429997444153, "incre_win_rate": 0.8888888888888888, "step": 2941}
{"time": 1767093563.5445979, "phase": "eval", "update": 2941, "total_env_steps": 9411200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.759726821192054, "step": 2941}
{"time": 1767093573.1584072, "phase": "train", "update": 2942, "total_env_steps": 9414400, "episode_reward": 0.2573297619819641, "value_loss": 0.008620638400316238, "policy_loss": -0.0014959109704545171, "dist_entropy": 0.45500882267951964, "actor_grad_norm": 0.11213188618421555, "critic_grad_norm": 0.1134822741150856, "ratio": 0.9999152421951294, "entropy": 0.45500882267951964, "incre_win_rate": 0.8, "step": 2942}
{"time": 1767093577.8785257, "phase": "train", "update": 2943, "total_env_steps": 9417600, "episode_reward": 0.2619536519050598, "value_loss": 0.008627357333898545, "policy_loss": -0.0018247019994412027, "dist_entropy": 0.4654338717460632, "actor_grad_norm": 0.1293090581893921, "critic_grad_norm": 0.08042671531438828, "ratio": 1.0003901720046997, "entropy": 0.4654338717460632, "incre_win_rate": 0.7777777777777778, "step": 2943}
{"time": 1767093582.620024, "phase": "train", "update": 2944, "total_env_steps": 9420800, "episode_reward": 0.25762471556663513, "value_loss": 0.00925950463861227, "policy_loss": -0.0014808149621728718, "dist_entropy": 0.4534518480300903, "actor_grad_norm": 0.1302834153175354, "critic_grad_norm": 0.05171961709856987, "ratio": 1.0000680685043335, "entropy": 0.4534518480300903, "incre_win_rate": 0.7954545454545454, "step": 2944}
{"time": 1767093587.3598833, "phase": "train", "update": 2945, "total_env_steps": 9424000, "episode_reward": 0.25142592191696167, "value_loss": 0.010680797509849072, "policy_loss": -0.0015114671140310065, "dist_entropy": 0.4564807116985321, "actor_grad_norm": 0.1352122724056244, "critic_grad_norm": 0.06794815510511398, "ratio": 1.0001777410507202, "entropy": 0.4564807116985321, "incre_win_rate": 0.6363636363636364, "step": 2945}
{"time": 1767093592.0888655, "phase": "train", "update": 2946, "total_env_steps": 9427200, "episode_reward": 0.2621678113937378, "value_loss": 0.008157305978238582, "policy_loss": -0.0016121633121905176, "dist_entropy": 0.4557607412338257, "actor_grad_norm": 0.12956520915031433, "critic_grad_norm": 0.06561238318681717, "ratio": 1.0005334615707397, "entropy": 0.4557607412338257, "incre_win_rate": 0.7954545454545454, "step": 2946}
{"time": 1767093596.8600533, "phase": "train", "update": 2947, "total_env_steps": 9430400, "episode_reward": 0.2568543255329132, "value_loss": 0.008225966431200504, "policy_loss": -0.001458940931517816, "dist_entropy": 0.46188828349113464, "actor_grad_norm": 0.14667664468288422, "critic_grad_norm": 0.0630154237151146, "ratio": 1.0006685256958008, "entropy": 0.46188828349113464, "incre_win_rate": 0.6888888888888889, "step": 2947}
{"time": 1767093601.570758, "phase": "train", "update": 2948, "total_env_steps": 9433600, "episode_reward": 0.26089611649513245, "value_loss": 0.007782392110675574, "policy_loss": -0.0018149778345094348, "dist_entropy": 0.47044249773025515, "actor_grad_norm": 0.17250646650791168, "critic_grad_norm": 0.01907186768949032, "ratio": 0.9994810223579407, "entropy": 0.47044249773025515, "incre_win_rate": 0.8043478260869565, "step": 2948}
{"time": 1767093606.2759283, "phase": "train", "update": 2949, "total_env_steps": 9436800, "episode_reward": 0.2625652253627777, "value_loss": 0.01026830319315195, "policy_loss": -0.0017477329499627104, "dist_entropy": 0.4676998913288116, "actor_grad_norm": 0.13727231323719025, "critic_grad_norm": 0.031039560213685036, "ratio": 0.9996439218521118, "entropy": 0.4676998913288116, "incre_win_rate": 0.75, "step": 2949}
{"time": 1767093610.9767134, "phase": "train", "update": 2950, "total_env_steps": 9440000, "episode_reward": 0.2581974267959595, "value_loss": 0.008613578043878078, "policy_loss": -0.0016200140452696133, "dist_entropy": 0.4698885440826416, "actor_grad_norm": 0.17285849153995514, "critic_grad_norm": 0.024400610476732254, "ratio": 0.9998415112495422, "entropy": 0.4698885440826416, "incre_win_rate": 0.7906976744186046, "step": 2950}
{"time": 1767093615.7632887, "phase": "train", "update": 2951, "total_env_steps": 9443200, "episode_reward": 0.26252949237823486, "value_loss": 0.007470062095671892, "policy_loss": -0.0016688326732692716, "dist_entropy": 0.4562276840209961, "actor_grad_norm": 0.1218462735414505, "critic_grad_norm": 0.015513353049755096, "ratio": 1.000030517578125, "entropy": 0.4562276840209961, "incre_win_rate": 0.8043478260869565, "step": 2951}
{"time": 1767093620.4781053, "phase": "train", "update": 2952, "total_env_steps": 9446400, "episode_reward": 0.25828438997268677, "value_loss": 0.009877756983041764, "policy_loss": -0.0014512598052171199, "dist_entropy": 0.4450350940227509, "actor_grad_norm": 0.15965712070465088, "critic_grad_norm": 0.02240448072552681, "ratio": 1.0002601146697998, "entropy": 0.4450350940227509, "incre_win_rate": 0.6739130434782609, "step": 2952}
{"time": 1767093625.169336, "phase": "train", "update": 2953, "total_env_steps": 9449600, "episode_reward": 0.26006418466567993, "value_loss": 0.009278467670083047, "policy_loss": -0.001597204876557612, "dist_entropy": 0.45002822279930116, "actor_grad_norm": 0.13285918533802032, "critic_grad_norm": 0.034881751984357834, "ratio": 0.9997650384902954, "entropy": 0.45002822279930116, "incre_win_rate": 0.6888888888888889, "step": 2953}
{"time": 1767093629.858215, "phase": "train", "update": 2954, "total_env_steps": 9452800, "episode_reward": 0.2628730535507202, "value_loss": 0.00831324402242899, "policy_loss": -0.0017437027865938148, "dist_entropy": 0.4481495261192322, "actor_grad_norm": 0.12172670662403107, "critic_grad_norm": 0.02394028939306736, "ratio": 0.9998598098754883, "entropy": 0.4481495261192322, "incre_win_rate": 0.7333333333333333, "step": 2954}
{"time": 1767093634.5596597, "phase": "train", "update": 2955, "total_env_steps": 9456000, "episode_reward": 0.26441690325737, "value_loss": 0.007602177187800407, "policy_loss": -0.0015778599998995447, "dist_entropy": 0.45269088745117186, "actor_grad_norm": 0.1896165907382965, "critic_grad_norm": 0.05006285384297371, "ratio": 1.0000203847885132, "entropy": 0.45269088745117186, "incre_win_rate": 0.8409090909090909, "step": 2955}
{"time": 1767093639.4094117, "phase": "train", "update": 2956, "total_env_steps": 9459200, "episode_reward": 0.25988152623176575, "value_loss": 0.006172576174139977, "policy_loss": -0.002235485455913633, "dist_entropy": 0.47865560054779055, "actor_grad_norm": 0.1154043897986412, "critic_grad_norm": 0.03393618389964104, "ratio": 0.9995552897453308, "entropy": 0.47865560054779055, "incre_win_rate": 0.8372093023255814, "step": 2956}
{"time": 1767093644.1681018, "phase": "train", "update": 2957, "total_env_steps": 9462400, "episode_reward": 0.25919029116630554, "value_loss": 0.01060882695019245, "policy_loss": -0.001460143545934045, "dist_entropy": 0.48332574367523196, "actor_grad_norm": 0.11684330552816391, "critic_grad_norm": 0.07759814709424973, "ratio": 1.0001276731491089, "entropy": 0.48332574367523196, "incre_win_rate": 0.6888888888888889, "step": 2957}
{"time": 1767093648.9069922, "phase": "train", "update": 2958, "total_env_steps": 9465600, "episode_reward": 0.2619536519050598, "value_loss": 0.013277340307831764, "policy_loss": -0.0020239336441321143, "dist_entropy": 0.46323317289352417, "actor_grad_norm": 0.14158682525157928, "critic_grad_norm": 0.08830922096967697, "ratio": 0.9997894167900085, "entropy": 0.46323317289352417, "incre_win_rate": 0.6382978723404256, "step": 2958}
{"time": 1767093653.652339, "phase": "train", "update": 2959, "total_env_steps": 9468800, "episode_reward": 0.2666618227958679, "value_loss": 0.010998380184173585, "policy_loss": -0.0016442500844391361, "dist_entropy": 0.464203292131424, "actor_grad_norm": 0.12210216373205185, "critic_grad_norm": 0.05530650168657303, "ratio": 0.9994735717773438, "entropy": 0.464203292131424, "incre_win_rate": 0.7659574468085106, "step": 2959}
{"time": 1767093658.3684437, "phase": "train", "update": 2960, "total_env_steps": 9472000, "episode_reward": 0.2720690071582794, "value_loss": 0.00934657920151949, "policy_loss": -0.0013307175957427476, "dist_entropy": 0.4572364926338196, "actor_grad_norm": 0.11209898442029953, "critic_grad_norm": 0.06693382561206818, "ratio": 0.9996016621589661, "entropy": 0.4572364926338196, "incre_win_rate": 0.7659574468085106, "step": 2960}
{"time": 1767093663.0974638, "phase": "train", "update": 2961, "total_env_steps": 9475200, "episode_reward": 0.26204782724380493, "value_loss": 0.009539111331105233, "policy_loss": -0.0018277369195545568, "dist_entropy": 0.46830328106880187, "actor_grad_norm": 0.13000831007957458, "critic_grad_norm": 0.034320931881666183, "ratio": 0.9995080232620239, "entropy": 0.46830328106880187, "incre_win_rate": 0.7727272727272727, "step": 2961}
{"time": 1767093673.6801689, "phase": "eval", "update": 2961, "total_env_steps": 9475200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.54154594370861, "step": 2961}
{"time": 1767093678.3936079, "phase": "train", "update": 2962, "total_env_steps": 9478400, "episode_reward": 0.2649839520454407, "value_loss": 0.007987869903445244, "policy_loss": -0.0018696377037841216, "dist_entropy": 0.47870066165924074, "actor_grad_norm": 0.1507929563522339, "critic_grad_norm": 0.028676006942987442, "ratio": 0.9998900294303894, "entropy": 0.47870066165924074, "incre_win_rate": 0.8222222222222222, "step": 2962}
{"time": 1767093683.1212754, "phase": "train", "update": 2963, "total_env_steps": 9481600, "episode_reward": 0.2720530033111572, "value_loss": 0.007851219549775124, "policy_loss": -0.001762139909894067, "dist_entropy": 0.47248753905296326, "actor_grad_norm": 0.13467463850975037, "critic_grad_norm": 0.02703140117228031, "ratio": 0.9995617866516113, "entropy": 0.47248753905296326, "incre_win_rate": 0.8913043478260869, "step": 2963}
{"time": 1767093687.8518655, "phase": "train", "update": 2964, "total_env_steps": 9484800, "episode_reward": 0.26099854707717896, "value_loss": 0.007480384036898613, "policy_loss": -0.001458458864662049, "dist_entropy": 0.4714261829853058, "actor_grad_norm": 0.1271495819091797, "critic_grad_norm": 0.03846206143498421, "ratio": 0.9998857378959656, "entropy": 0.4714261829853058, "incre_win_rate": 0.7906976744186046, "step": 2964}
{"time": 1767093692.5521746, "phase": "train", "update": 2965, "total_env_steps": 9488000, "episode_reward": 0.2635699510574341, "value_loss": 0.008623111620545387, "policy_loss": -0.0012631614444323703, "dist_entropy": 0.4684526324272156, "actor_grad_norm": 0.13009341061115265, "critic_grad_norm": 0.01843334548175335, "ratio": 1.0004085302352905, "entropy": 0.4684526324272156, "incre_win_rate": 0.782608695652174, "step": 2965}
{"time": 1767093697.2442646, "phase": "train", "update": 2966, "total_env_steps": 9491200, "episode_reward": 0.2616773545742035, "value_loss": 0.008410951867699624, "policy_loss": -0.0015927315628950112, "dist_entropy": 0.4710162341594696, "actor_grad_norm": 0.10871225595474243, "critic_grad_norm": 0.050935354083776474, "ratio": 1.0002764463424683, "entropy": 0.4710162341594696, "incre_win_rate": 0.8636363636363636, "step": 2966}
{"time": 1767093701.9316204, "phase": "train", "update": 2967, "total_env_steps": 9494400, "episode_reward": 0.24968181550502777, "value_loss": 0.00796271562576294, "policy_loss": -0.0014439647197487914, "dist_entropy": 0.458117413520813, "actor_grad_norm": 0.11416438966989517, "critic_grad_norm": 0.058930665254592896, "ratio": 1.0004546642303467, "entropy": 0.458117413520813, "incre_win_rate": 0.6666666666666666, "step": 2967}
{"time": 1767093706.7222457, "phase": "train", "update": 2968, "total_env_steps": 9497600, "episode_reward": 0.2602669894695282, "value_loss": 0.00805876925587654, "policy_loss": -0.001869685664281384, "dist_entropy": 0.45703176259994505, "actor_grad_norm": 0.1570330113172531, "critic_grad_norm": 0.04989716783165932, "ratio": 1.0003631114959717, "entropy": 0.45703176259994505, "incre_win_rate": 0.7555555555555555, "step": 2968}
{"time": 1767093711.414536, "phase": "train", "update": 2969, "total_env_steps": 9500800, "episode_reward": 0.2540464401245117, "value_loss": 0.008441610261797905, "policy_loss": -0.001243389414034457, "dist_entropy": 0.44909039735794065, "actor_grad_norm": 0.0995665043592453, "critic_grad_norm": 0.03359989449381828, "ratio": 1.0000423192977905, "entropy": 0.44909039735794065, "incre_win_rate": 0.7674418604651163, "step": 2969}
{"time": 1767093716.1468818, "phase": "train", "update": 2970, "total_env_steps": 9504000, "episode_reward": 0.2525957226753235, "value_loss": 0.009089076891541481, "policy_loss": -0.0017162562538253212, "dist_entropy": 0.46499760150909425, "actor_grad_norm": 0.12015372514724731, "critic_grad_norm": 0.03504765033721924, "ratio": 1.000200867652893, "entropy": 0.46499760150909425, "incre_win_rate": 0.6818181818181818, "step": 2970}
{"time": 1767093720.8474953, "phase": "train", "update": 2971, "total_env_steps": 9507200, "episode_reward": 0.2622118294239044, "value_loss": 0.009135667234659195, "policy_loss": -0.0014054793545810185, "dist_entropy": 0.4611772298812866, "actor_grad_norm": 0.12066918611526489, "critic_grad_norm": 0.06433980911970139, "ratio": 0.9999825358390808, "entropy": 0.4611772298812866, "incre_win_rate": 0.75, "step": 2971}
{"time": 1767093725.599751, "phase": "train", "update": 2972, "total_env_steps": 9510400, "episode_reward": 0.2736956775188446, "value_loss": 0.005496088415384293, "policy_loss": -0.0018524008433161044, "dist_entropy": 0.45635600090026857, "actor_grad_norm": 0.17260941863059998, "critic_grad_norm": 0.0592181496322155, "ratio": 0.9997426867485046, "entropy": 0.45635600090026857, "incre_win_rate": 0.851063829787234, "step": 2972}
{"time": 1767093730.3033977, "phase": "train", "update": 2973, "total_env_steps": 9513600, "episode_reward": 0.26707470417022705, "value_loss": 0.006302722077816725, "policy_loss": -0.0016160105422521553, "dist_entropy": 0.4715192437171936, "actor_grad_norm": 0.1502808779478073, "critic_grad_norm": 0.044703662395477295, "ratio": 0.9999500513076782, "entropy": 0.4715192437171936, "incre_win_rate": 0.8604651162790697, "step": 2973}
{"time": 1767093735.0533173, "phase": "train", "update": 2974, "total_env_steps": 9516800, "episode_reward": 0.2591540813446045, "value_loss": 0.007229915726929903, "policy_loss": -0.0013565459642549626, "dist_entropy": 0.4683859944343567, "actor_grad_norm": 0.1603727787733078, "critic_grad_norm": 0.040361832827329636, "ratio": 0.9997143745422363, "entropy": 0.4683859944343567, "incre_win_rate": 0.8409090909090909, "step": 2974}
{"time": 1767093739.7949872, "phase": "train", "update": 2975, "total_env_steps": 9520000, "episode_reward": 0.2642834186553955, "value_loss": 0.006385866925120354, "policy_loss": -0.0014973071924206493, "dist_entropy": 0.4518210172653198, "actor_grad_norm": 0.14399848878383636, "critic_grad_norm": 0.020153164863586426, "ratio": 1.0002001523971558, "entropy": 0.4518210172653198, "incre_win_rate": 0.8444444444444444, "step": 2975}
{"time": 1767093744.5159812, "phase": "train", "update": 2976, "total_env_steps": 9523200, "episode_reward": 0.2653782069683075, "value_loss": 0.00485207224264741, "policy_loss": -0.0016769415311557623, "dist_entropy": 0.4682397246360779, "actor_grad_norm": 0.1393750160932541, "critic_grad_norm": 0.030334651470184326, "ratio": 0.9997381567955017, "entropy": 0.4682397246360779, "incre_win_rate": 0.8604651162790697, "step": 2976}
{"time": 1767093749.189639, "phase": "train", "update": 2977, "total_env_steps": 9526400, "episode_reward": 0.2549974024295807, "value_loss": 0.006439989898353815, "policy_loss": -0.0015237380381488918, "dist_entropy": 0.4602739453315735, "actor_grad_norm": 0.14912240207195282, "critic_grad_norm": 0.07996340841054916, "ratio": 1.0004881620407104, "entropy": 0.4602739453315735, "incre_win_rate": 0.7727272727272727, "step": 2977}
{"time": 1767093753.893086, "phase": "train", "update": 2978, "total_env_steps": 9529600, "episode_reward": 0.26806601881980896, "value_loss": 0.00565558560192585, "policy_loss": -0.0014568033267593704, "dist_entropy": 0.45846139788627627, "actor_grad_norm": 0.15380452573299408, "critic_grad_norm": 0.05591058358550072, "ratio": 0.999907910823822, "entropy": 0.45846139788627627, "incre_win_rate": 0.8666666666666667, "step": 2978}
{"time": 1767093758.6646402, "phase": "train", "update": 2979, "total_env_steps": 9532800, "episode_reward": 0.2672024965286255, "value_loss": 0.004896987695246935, "policy_loss": -0.0014931842492472923, "dist_entropy": 0.4817967593669891, "actor_grad_norm": 0.12709857523441315, "critic_grad_norm": 0.04927131161093712, "ratio": 0.999735951423645, "entropy": 0.4817967593669891, "incre_win_rate": 0.9302325581395349, "step": 2979}
{"time": 1767093763.3707628, "phase": "train", "update": 2980, "total_env_steps": 9536000, "episode_reward": 0.27542009949684143, "value_loss": 0.004190020356327295, "policy_loss": -0.0013880741664380025, "dist_entropy": 0.4615073025226593, "actor_grad_norm": 0.11411922425031662, "critic_grad_norm": 0.03030722215771675, "ratio": 0.9998572468757629, "entropy": 0.4615073025226593, "incre_win_rate": 0.8863636363636364, "step": 2980}
{"time": 1767093768.106694, "phase": "train", "update": 2981, "total_env_steps": 9539200, "episode_reward": 0.26113152503967285, "value_loss": 0.006442750990390778, "policy_loss": -0.001473880966319996, "dist_entropy": 0.4724005699157715, "actor_grad_norm": 0.11630453914403915, "critic_grad_norm": 0.05550609156489372, "ratio": 1.000023603439331, "entropy": 0.4724005699157715, "incre_win_rate": 0.8372093023255814, "step": 2981}
{"time": 1767093778.9949334, "phase": "eval", "update": 2981, "total_env_steps": 9539200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.697433774834437, "step": 2981}
{"time": 1767093783.6711938, "phase": "train", "update": 2982, "total_env_steps": 9542400, "episode_reward": 0.2660461664199829, "value_loss": 0.0049472031183540825, "policy_loss": -0.0016333577412154909, "dist_entropy": 0.45264906883239747, "actor_grad_norm": 0.11766044050455093, "critic_grad_norm": 0.04236534982919693, "ratio": 0.9996658563613892, "entropy": 0.45264906883239747, "incre_win_rate": 0.851063829787234, "step": 2982}
{"time": 1767093788.3385522, "phase": "train", "update": 2983, "total_env_steps": 9545600, "episode_reward": 0.2778269648551941, "value_loss": 0.004401830676943064, "policy_loss": -0.0013642743831177029, "dist_entropy": 0.46734529733657837, "actor_grad_norm": 0.10200067609548569, "critic_grad_norm": 0.058028679341077805, "ratio": 0.9997798800468445, "entropy": 0.46734529733657837, "incre_win_rate": 0.9047619047619048, "step": 2983}
{"time": 1767093793.0443687, "phase": "train", "update": 2984, "total_env_steps": 9548800, "episode_reward": 0.2581115663051605, "value_loss": 0.00637444881722331, "policy_loss": -0.00161528556824031, "dist_entropy": 0.44985483288764955, "actor_grad_norm": 0.12248793989419937, "critic_grad_norm": 0.049514900892972946, "ratio": 0.9999276399612427, "entropy": 0.44985483288764955, "incre_win_rate": 0.8444444444444444, "step": 2984}
{"time": 1767093797.782603, "phase": "train", "update": 2985, "total_env_steps": 9552000, "episode_reward": 0.25766968727111816, "value_loss": 0.006118454132229089, "policy_loss": -0.0017954286545119658, "dist_entropy": 0.4733340978622437, "actor_grad_norm": 0.11825231462717056, "critic_grad_norm": 0.04128583148121834, "ratio": 1.0000745058059692, "entropy": 0.4733340978622437, "incre_win_rate": 0.8809523809523809, "step": 2985}
{"time": 1767093802.4690278, "phase": "train", "update": 2986, "total_env_steps": 9555200, "episode_reward": 0.2665066421031952, "value_loss": 0.004566446319222451, "policy_loss": -0.0015258337934714206, "dist_entropy": 0.45655292868614195, "actor_grad_norm": 0.0930350050330162, "critic_grad_norm": 0.019662218168377876, "ratio": 1.00009286403656, "entropy": 0.45655292868614195, "incre_win_rate": 0.8837209302325582, "step": 2986}
{"time": 1767093807.2092018, "phase": "train", "update": 2987, "total_env_steps": 9558400, "episode_reward": 0.2677348852157593, "value_loss": 0.006546287145465612, "policy_loss": -0.0015963705364217874, "dist_entropy": 0.45817484259605407, "actor_grad_norm": 0.11045368015766144, "critic_grad_norm": 0.023112578317523003, "ratio": 0.99994295835495, "entropy": 0.45817484259605407, "incre_win_rate": 0.8695652173913043, "step": 2987}
{"time": 1767093811.8847861, "phase": "train", "update": 2988, "total_env_steps": 9561600, "episode_reward": 0.25580400228500366, "value_loss": 0.0068694413639605045, "policy_loss": -0.0016610675665323705, "dist_entropy": 0.47475298047065734, "actor_grad_norm": 0.11806237697601318, "critic_grad_norm": 0.029851635918021202, "ratio": 1.0001329183578491, "entropy": 0.47475298047065734, "incre_win_rate": 0.85, "step": 2988}
{"time": 1767093816.680299, "phase": "train", "update": 2989, "total_env_steps": 9564800, "episode_reward": 0.25856995582580566, "value_loss": 0.006121573969721794, "policy_loss": -0.0019393640883023978, "dist_entropy": 0.4593015372753143, "actor_grad_norm": 0.1275976449251175, "critic_grad_norm": 0.039389628916978836, "ratio": 0.9997100830078125, "entropy": 0.4593015372753143, "incre_win_rate": 0.8043478260869565, "step": 2989}
{"time": 1767093821.4307568, "phase": "train", "update": 2990, "total_env_steps": 9568000, "episode_reward": 0.2579532265663147, "value_loss": 0.005630110297352076, "policy_loss": -0.0013681498270479153, "dist_entropy": 0.4755374312400818, "actor_grad_norm": 0.15785914659500122, "critic_grad_norm": 0.027398589998483658, "ratio": 1.0000972747802734, "entropy": 0.4755374312400818, "incre_win_rate": 0.8333333333333334, "step": 2990}
{"time": 1767093826.2231665, "phase": "train", "update": 2991, "total_env_steps": 9571200, "episode_reward": 0.2725936472415924, "value_loss": 0.0031232610810548065, "policy_loss": -0.0018528767443626748, "dist_entropy": 0.46816185116767883, "actor_grad_norm": 0.16636641323566437, "critic_grad_norm": 0.03103828802704811, "ratio": 1.0001670122146606, "entropy": 0.46816185116767883, "incre_win_rate": 0.9090909090909091, "step": 2991}
{"time": 1767093830.95453, "phase": "train", "update": 2992, "total_env_steps": 9574400, "episode_reward": 0.25557637214660645, "value_loss": 0.005441552866250277, "policy_loss": -0.001736647014201864, "dist_entropy": 0.47548204064369204, "actor_grad_norm": 0.09517044574022293, "critic_grad_norm": 0.027251048013567924, "ratio": 1.000072717666626, "entropy": 0.47548204064369204, "incre_win_rate": 0.8181818181818182, "step": 2992}
{"time": 1767093835.7109966, "phase": "train", "update": 2993, "total_env_steps": 9577600, "episode_reward": 0.2707884907722473, "value_loss": 0.005270909797400236, "policy_loss": -0.0017098590369045042, "dist_entropy": 0.4401691257953644, "actor_grad_norm": 0.1457785665988922, "critic_grad_norm": 0.018621807917952538, "ratio": 0.9997488260269165, "entropy": 0.4401691257953644, "incre_win_rate": 0.8181818181818182, "step": 2993}
{"time": 1767093840.4289026, "phase": "train", "update": 2994, "total_env_steps": 9580800, "episode_reward": 0.263831228017807, "value_loss": 0.005825992301106453, "policy_loss": -0.0017504730632055044, "dist_entropy": 0.46838225722312926, "actor_grad_norm": 0.12080174684524536, "critic_grad_norm": 0.04213954880833626, "ratio": 0.9999850392341614, "entropy": 0.46838225722312926, "incre_win_rate": 0.8636363636363636, "step": 2994}
{"time": 1767093845.1399274, "phase": "train", "update": 2995, "total_env_steps": 9584000, "episode_reward": 0.25328436493873596, "value_loss": 0.006910593807697296, "policy_loss": -0.0022124263923103626, "dist_entropy": 0.449645459651947, "actor_grad_norm": 0.1601266711950302, "critic_grad_norm": 0.04378391429781914, "ratio": 0.9998928904533386, "entropy": 0.449645459651947, "incre_win_rate": 0.8292682926829268, "step": 2995}
{"time": 1767093849.8587127, "phase": "train", "update": 2996, "total_env_steps": 9587200, "episode_reward": 0.26190653443336487, "value_loss": 0.004280639160424471, "policy_loss": -0.0014631596822653136, "dist_entropy": 0.45532819628715515, "actor_grad_norm": 0.1395430713891983, "critic_grad_norm": 0.04468223825097084, "ratio": 0.9998157620429993, "entropy": 0.45532819628715515, "incre_win_rate": 0.8478260869565217, "step": 2996}
{"time": 1767093854.5612764, "phase": "train", "update": 2997, "total_env_steps": 9590400, "episode_reward": 0.26052412390708923, "value_loss": 0.004613252263516188, "policy_loss": -0.001762528818205844, "dist_entropy": 0.4580294907093048, "actor_grad_norm": 0.1115022823214531, "critic_grad_norm": 0.014327570796012878, "ratio": 0.9998974204063416, "entropy": 0.4580294907093048, "incre_win_rate": 0.9047619047619048, "step": 2997}
{"time": 1767093859.3338497, "phase": "train", "update": 2998, "total_env_steps": 9593600, "episode_reward": 0.26487740874290466, "value_loss": 0.004446143563836813, "policy_loss": -0.0013022523656481156, "dist_entropy": 0.4602465331554413, "actor_grad_norm": 0.115208700299263, "critic_grad_norm": 0.025809360668063164, "ratio": 1.000044584274292, "entropy": 0.4602465331554413, "incre_win_rate": 0.8409090909090909, "step": 2998}
{"time": 1767093863.9828494, "phase": "train", "update": 2999, "total_env_steps": 9596800, "episode_reward": 0.2543087899684906, "value_loss": 0.005681789666414261, "policy_loss": -0.001757501415600693, "dist_entropy": 0.4475071787834167, "actor_grad_norm": 0.124825619161129, "critic_grad_norm": 0.017767155542969704, "ratio": 1.0002144575119019, "entropy": 0.4475071787834167, "incre_win_rate": 0.8536585365853658, "step": 2999}
{"time": 1767093868.718976, "phase": "train", "update": 3000, "total_env_steps": 9600000, "episode_reward": 0.27008745074272156, "value_loss": 0.00395758543163538, "policy_loss": -0.001988097868259331, "dist_entropy": 0.4536817491054535, "actor_grad_norm": 0.1087886318564415, "critic_grad_norm": 0.014903800562024117, "ratio": 0.9998841285705566, "entropy": 0.4536817491054535, "incre_win_rate": 0.8863636363636364, "step": 3000}
{"time": 1767093873.4074688, "phase": "train", "update": 3001, "total_env_steps": 9603200, "episode_reward": 0.2648680806159973, "value_loss": 0.005635364260524511, "policy_loss": -0.0014937009125191025, "dist_entropy": 0.4592400789260864, "actor_grad_norm": 0.10198747366666794, "critic_grad_norm": 0.03155932202935219, "ratio": 0.999627411365509, "entropy": 0.4592400789260864, "incre_win_rate": 0.8222222222222222, "step": 3001}
{"time": 1767093884.131629, "phase": "eval", "update": 3001, "total_env_steps": 9603200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.76417632450331, "step": 3001}
{"time": 1767093888.8224995, "phase": "train", "update": 3002, "total_env_steps": 9606400, "episode_reward": 0.250144362449646, "value_loss": 0.006591624021530152, "policy_loss": -0.001668708978489164, "dist_entropy": 0.47523324489593505, "actor_grad_norm": 0.12470920383930206, "critic_grad_norm": 0.030401840806007385, "ratio": 1.0000213384628296, "entropy": 0.47523324489593505, "incre_win_rate": 0.7906976744186046, "step": 3002}
{"time": 1767093893.4939842, "phase": "train", "update": 3003, "total_env_steps": 9609600, "episode_reward": 0.26397764682769775, "value_loss": 0.006317852810025215, "policy_loss": -0.0022807036312002538, "dist_entropy": 0.4711820542812347, "actor_grad_norm": 0.14749978482723236, "critic_grad_norm": 0.0259572621434927, "ratio": 0.9998592734336853, "entropy": 0.4711820542812347, "incre_win_rate": 0.8604651162790697, "step": 3003}
{"time": 1767093898.237538, "phase": "train", "update": 3004, "total_env_steps": 9612800, "episode_reward": 0.2699410319328308, "value_loss": 0.003953712340444326, "policy_loss": -0.0013245391186103462, "dist_entropy": 0.4833292424678802, "actor_grad_norm": 0.1342422068119049, "critic_grad_norm": 0.04281219467520714, "ratio": 0.9995408058166504, "entropy": 0.4833292424678802, "incre_win_rate": 0.8444444444444444, "step": 3004}
{"time": 1767093902.972386, "phase": "train", "update": 3005, "total_env_steps": 9616000, "episode_reward": 0.26103994250297546, "value_loss": 0.005231344420462847, "policy_loss": -0.0015646131469772228, "dist_entropy": 0.4730189561843872, "actor_grad_norm": 0.10586607456207275, "critic_grad_norm": 0.0271748136729002, "ratio": 0.9998049736022949, "entropy": 0.4730189561843872, "incre_win_rate": 0.8604651162790697, "step": 3005}
{"time": 1767093907.7097948, "phase": "train", "update": 3006, "total_env_steps": 9619200, "episode_reward": 0.259590744972229, "value_loss": 0.006434312555938959, "policy_loss": -0.0016850948453816627, "dist_entropy": 0.4661392390727997, "actor_grad_norm": 0.15375109016895294, "critic_grad_norm": 0.023521216586232185, "ratio": 1.0001403093338013, "entropy": 0.4661392390727997, "incre_win_rate": 0.7954545454545454, "step": 3006}
{"time": 1767093912.4671583, "phase": "train", "update": 3007, "total_env_steps": 9622400, "episode_reward": 0.27017590403556824, "value_loss": 0.005625619646161794, "policy_loss": -0.0014151077557372105, "dist_entropy": 0.47399001121520995, "actor_grad_norm": 0.09689779579639435, "critic_grad_norm": 0.02887621894478798, "ratio": 0.9997844099998474, "entropy": 0.47399001121520995, "incre_win_rate": 0.8888888888888888, "step": 3007}
{"time": 1767093917.2174754, "phase": "train", "update": 3008, "total_env_steps": 9625600, "episode_reward": 0.24495549499988556, "value_loss": 0.007636845670640468, "policy_loss": -0.0018060672096595453, "dist_entropy": 0.4744920492172241, "actor_grad_norm": 0.11476895958185196, "critic_grad_norm": 0.036426324397325516, "ratio": 0.9997053146362305, "entropy": 0.4744920492172241, "incre_win_rate": 0.7804878048780488, "step": 3008}
{"time": 1767093921.8768404, "phase": "train", "update": 3009, "total_env_steps": 9628800, "episode_reward": 0.2363089919090271, "value_loss": 0.0075952217914164065, "policy_loss": -0.001808443519233549, "dist_entropy": 0.463834285736084, "actor_grad_norm": 0.12502586841583252, "critic_grad_norm": 0.036408063024282455, "ratio": 0.9998812079429626, "entropy": 0.463834285736084, "incre_win_rate": 0.717948717948718, "step": 3009}
{"time": 1767093926.5731812, "phase": "train", "update": 3010, "total_env_steps": 9632000, "episode_reward": 0.2589905858039856, "value_loss": 0.006801825668662787, "policy_loss": -0.001671633016648144, "dist_entropy": 0.4573253393173218, "actor_grad_norm": 0.09860020875930786, "critic_grad_norm": 0.028076112270355225, "ratio": 1.0003246068954468, "entropy": 0.4573253393173218, "incre_win_rate": 0.7659574468085106, "step": 3010}
{"time": 1767093931.2342603, "phase": "train", "update": 3011, "total_env_steps": 9635200, "episode_reward": 0.26127585768699646, "value_loss": 0.005605094693601131, "policy_loss": -0.0018162291946204334, "dist_entropy": 0.44852983951568604, "actor_grad_norm": 0.0962664857506752, "critic_grad_norm": 0.05905381962656975, "ratio": 0.999988853931427, "entropy": 0.44852983951568604, "incre_win_rate": 0.8372093023255814, "step": 3011}
{"time": 1767093935.9555051, "phase": "train", "update": 3012, "total_env_steps": 9638400, "episode_reward": 0.25404492020606995, "value_loss": 0.00724780485033989, "policy_loss": -0.0020999049402064427, "dist_entropy": 0.46973432302474977, "actor_grad_norm": 0.1521729975938797, "critic_grad_norm": 0.054094474762678146, "ratio": 1.0002058744430542, "entropy": 0.46973432302474977, "incre_win_rate": 0.8048780487804879, "step": 3012}
{"time": 1767093940.663292, "phase": "train", "update": 3013, "total_env_steps": 9641600, "episode_reward": 0.2538990080356598, "value_loss": 0.007043060380965471, "policy_loss": -0.001783449579063756, "dist_entropy": 0.4874100685119629, "actor_grad_norm": 0.16003283858299255, "critic_grad_norm": 0.03813108429312706, "ratio": 0.9992858171463013, "entropy": 0.4874100685119629, "incre_win_rate": 0.7777777777777778, "step": 3013}
{"time": 1767093945.3988914, "phase": "train", "update": 3014, "total_env_steps": 9644800, "episode_reward": 0.2549777626991272, "value_loss": 0.007122236955910921, "policy_loss": -0.0013911573684097789, "dist_entropy": 0.4697694718837738, "actor_grad_norm": 0.10210835933685303, "critic_grad_norm": 0.030847696587443352, "ratio": 1.0000754594802856, "entropy": 0.4697694718837738, "incre_win_rate": 0.75, "step": 3014}
{"time": 1767093950.131813, "phase": "train", "update": 3015, "total_env_steps": 9648000, "episode_reward": 0.24507243931293488, "value_loss": 0.007845174800604583, "policy_loss": -0.002283469811990102, "dist_entropy": 0.47811627984046934, "actor_grad_norm": 0.13399875164031982, "critic_grad_norm": 0.027317315340042114, "ratio": 0.9997963309288025, "entropy": 0.47811627984046934, "incre_win_rate": 0.7692307692307693, "step": 3015}
{"time": 1767093954.8331048, "phase": "train", "update": 3016, "total_env_steps": 9651200, "episode_reward": 0.2574006915092468, "value_loss": 0.0047767780721187595, "policy_loss": -0.0016949349069889763, "dist_entropy": 0.4902466475963593, "actor_grad_norm": 0.11966504901647568, "critic_grad_norm": 0.03515518829226494, "ratio": 0.9997180104255676, "entropy": 0.4902466475963593, "incre_win_rate": 0.8222222222222222, "step": 3016}
{"time": 1767093959.600127, "phase": "train", "update": 3017, "total_env_steps": 9654400, "episode_reward": 0.25995033979415894, "value_loss": 0.005397921800613404, "policy_loss": -0.0014428448518464699, "dist_entropy": 0.48091097474098204, "actor_grad_norm": 0.11208448559045792, "critic_grad_norm": 0.026141691952943802, "ratio": 1.0002292394638062, "entropy": 0.48091097474098204, "incre_win_rate": 0.926829268292683, "step": 3017}
{"time": 1767093964.3395917, "phase": "train", "update": 3018, "total_env_steps": 9657600, "episode_reward": 0.24736808240413666, "value_loss": 0.010412439331412315, "policy_loss": -0.0019127667787945057, "dist_entropy": 0.47902498245239256, "actor_grad_norm": 0.1450769156217575, "critic_grad_norm": 0.09370781481266022, "ratio": 1.0001271963119507, "entropy": 0.47902498245239256, "incre_win_rate": 0.6222222222222222, "step": 3018}
{"time": 1767093969.078872, "phase": "train", "update": 3019, "total_env_steps": 9660800, "episode_reward": 0.27091214060783386, "value_loss": 0.006674881931394339, "policy_loss": -0.0018220636069131047, "dist_entropy": 0.461495178937912, "actor_grad_norm": 0.13116435706615448, "critic_grad_norm": 0.08586978167295456, "ratio": 0.9997590184211731, "entropy": 0.461495178937912, "incre_win_rate": 0.9111111111111111, "step": 3019}
{"time": 1767093973.8121583, "phase": "train", "update": 3020, "total_env_steps": 9664000, "episode_reward": 0.2550450265407562, "value_loss": 0.006672387570142746, "policy_loss": -0.0017175644758651743, "dist_entropy": 0.44076072573661806, "actor_grad_norm": 0.1457824558019638, "critic_grad_norm": 0.06380870193243027, "ratio": 0.9996747374534607, "entropy": 0.44076072573661806, "incre_win_rate": 0.7857142857142857, "step": 3020}
{"time": 1767093978.490673, "phase": "train", "update": 3021, "total_env_steps": 9667200, "episode_reward": 0.24232563376426697, "value_loss": 0.008942651376128197, "policy_loss": -0.0017373565206504793, "dist_entropy": 0.47168889045715334, "actor_grad_norm": 0.12150561064481735, "critic_grad_norm": 0.04937344416975975, "ratio": 0.9997255206108093, "entropy": 0.47168889045715334, "incre_win_rate": 0.7045454545454546, "step": 3021}
{"time": 1767093989.173473, "phase": "eval", "update": 3021, "total_env_steps": 9667200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.700434602649004, "step": 3021}
{"time": 1767093993.8380408, "phase": "train", "update": 3022, "total_env_steps": 9670400, "episode_reward": 0.25320571660995483, "value_loss": 0.00958169884979725, "policy_loss": -0.0017085034660269116, "dist_entropy": 0.45610408782958983, "actor_grad_norm": 0.12305672466754913, "critic_grad_norm": 0.026764968410134315, "ratio": 0.9998373985290527, "entropy": 0.45610408782958983, "incre_win_rate": 0.7317073170731707, "step": 3022}
{"time": 1767093998.5637887, "phase": "train", "update": 3023, "total_env_steps": 9673600, "episode_reward": 0.2583211064338684, "value_loss": 0.007061669323593378, "policy_loss": -0.0014163428474489592, "dist_entropy": 0.4583044469356537, "actor_grad_norm": 0.11749674379825592, "critic_grad_norm": 0.04147430136799812, "ratio": 0.9997629523277283, "entropy": 0.4583044469356537, "incre_win_rate": 0.8043478260869565, "step": 3023}
{"time": 1767094003.2861435, "phase": "train", "update": 3024, "total_env_steps": 9676800, "episode_reward": 0.25445571541786194, "value_loss": 0.00777029125019908, "policy_loss": -0.0019769974770454724, "dist_entropy": 0.4571260869503021, "actor_grad_norm": 0.13514375686645508, "critic_grad_norm": 0.03324874863028526, "ratio": 1.0001747608184814, "entropy": 0.4571260869503021, "incre_win_rate": 0.7619047619047619, "step": 3024}
{"time": 1767094008.0262074, "phase": "train", "update": 3025, "total_env_steps": 9680000, "episode_reward": 0.25128209590911865, "value_loss": 0.009282172471284867, "policy_loss": -0.0017592315789691781, "dist_entropy": 0.43853134512901304, "actor_grad_norm": 0.16572566330432892, "critic_grad_norm": 0.03399989381432533, "ratio": 1.0000137090682983, "entropy": 0.43853134512901304, "incre_win_rate": 0.7209302325581395, "step": 3025}
{"time": 1767094012.6831996, "phase": "train", "update": 3026, "total_env_steps": 9683200, "episode_reward": 0.22889021039009094, "value_loss": 0.010854461044073106, "policy_loss": -0.0018425929012252595, "dist_entropy": 0.45862857699394227, "actor_grad_norm": 0.15366217494010925, "critic_grad_norm": 0.025103075429797173, "ratio": 1.0003117322921753, "entropy": 0.45862857699394227, "incre_win_rate": 0.5952380952380952, "step": 3026}
{"time": 1767094017.530334, "phase": "train", "update": 3027, "total_env_steps": 9686400, "episode_reward": 0.25887158513069153, "value_loss": 0.008807266689836979, "policy_loss": -0.001475157882580902, "dist_entropy": 0.4426049470901489, "actor_grad_norm": 0.10772756487131119, "critic_grad_norm": 0.04645555466413498, "ratio": 0.9998411536216736, "entropy": 0.4426049470901489, "incre_win_rate": 0.7906976744186046, "step": 3027}
{"time": 1767094022.2867808, "phase": "train", "update": 3028, "total_env_steps": 9689600, "episode_reward": 0.27239754796028137, "value_loss": 0.00509446719661355, "policy_loss": -0.0020750741231893243, "dist_entropy": 0.45524080991745, "actor_grad_norm": 0.1095895767211914, "critic_grad_norm": 0.03491278365254402, "ratio": 1.0000983476638794, "entropy": 0.45524080991745, "incre_win_rate": 0.8913043478260869, "step": 3028}
{"time": 1767094026.9657934, "phase": "train", "update": 3029, "total_env_steps": 9692800, "episode_reward": 0.23951368033885956, "value_loss": 0.00957856085151434, "policy_loss": -0.0023032423451248007, "dist_entropy": 0.4656617283821106, "actor_grad_norm": 0.12455638498067856, "critic_grad_norm": 0.06662144511938095, "ratio": 0.9999291300773621, "entropy": 0.4656617283821106, "incre_win_rate": 0.7631578947368421, "step": 3029}
{"time": 1767094031.7106278, "phase": "train", "update": 3030, "total_env_steps": 9696000, "episode_reward": 0.2554418444633484, "value_loss": 0.007771643903106451, "policy_loss": -0.0017683099641402577, "dist_entropy": 0.46990045309066775, "actor_grad_norm": 0.13345113396644592, "critic_grad_norm": 0.036494698375463486, "ratio": 0.9999427199363708, "entropy": 0.46990045309066775, "incre_win_rate": 0.7446808510638298, "step": 3030}
{"time": 1767094036.40288, "phase": "train", "update": 3031, "total_env_steps": 9699200, "episode_reward": 0.25024884939193726, "value_loss": 0.011792878620326519, "policy_loss": -0.0018424403422372393, "dist_entropy": 0.4512714147567749, "actor_grad_norm": 0.11178623884916306, "critic_grad_norm": 0.03105715475976467, "ratio": 0.9996655583381653, "entropy": 0.4512714147567749, "incre_win_rate": 0.7380952380952381, "step": 3031}
{"time": 1767094041.148457, "phase": "train", "update": 3032, "total_env_steps": 9702400, "episode_reward": 0.23593956232070923, "value_loss": 0.007916472107172012, "policy_loss": -0.0018619915228569538, "dist_entropy": 0.4783750295639038, "actor_grad_norm": 0.16598884761333466, "critic_grad_norm": 0.02792198397219181, "ratio": 0.999946117401123, "entropy": 0.4783750295639038, "incre_win_rate": 0.7317073170731707, "step": 3032}
{"time": 1767094045.7979126, "phase": "train", "update": 3033, "total_env_steps": 9705600, "episode_reward": 0.24182532727718353, "value_loss": 0.010077360458672047, "policy_loss": -0.0013449785185937202, "dist_entropy": 0.4483219742774963, "actor_grad_norm": 0.10905956476926804, "critic_grad_norm": 0.033516813069581985, "ratio": 1.0005580186843872, "entropy": 0.4483219742774963, "incre_win_rate": 0.6904761904761905, "step": 3033}
{"time": 1767094050.5605822, "phase": "train", "update": 3034, "total_env_steps": 9708800, "episode_reward": 0.25817984342575073, "value_loss": 0.008408261463046074, "policy_loss": -0.001519045864175439, "dist_entropy": 0.45706346035003664, "actor_grad_norm": 0.17099691927433014, "critic_grad_norm": 0.030085880309343338, "ratio": 0.9999703764915466, "entropy": 0.45706346035003664, "incre_win_rate": 0.7555555555555555, "step": 3034}
{"time": 1767094055.2471354, "phase": "train", "update": 3035, "total_env_steps": 9712000, "episode_reward": 0.24125155806541443, "value_loss": 0.011115495674312114, "policy_loss": -0.0018368571005836997, "dist_entropy": 0.4760752320289612, "actor_grad_norm": 0.11414941400289536, "critic_grad_norm": 0.03147684037685394, "ratio": 0.9997453689575195, "entropy": 0.4760752320289612, "incre_win_rate": 0.7073170731707317, "step": 3035}
{"time": 1767094059.8783507, "phase": "train", "update": 3036, "total_env_steps": 9715200, "episode_reward": 0.22082212567329407, "value_loss": 0.011627738177776337, "policy_loss": -0.0018359148743513742, "dist_entropy": 0.4859796643257141, "actor_grad_norm": 0.12111379206180573, "critic_grad_norm": 0.023345889523625374, "ratio": 0.9998123049736023, "entropy": 0.4859796643257141, "incre_win_rate": 0.6341463414634146, "step": 3036}
{"time": 1767094064.6023588, "phase": "train", "update": 3037, "total_env_steps": 9718400, "episode_reward": 0.24966321885585785, "value_loss": 0.008828004449605941, "policy_loss": -0.0016192383265860144, "dist_entropy": 0.47568061351776125, "actor_grad_norm": 0.09946507960557938, "critic_grad_norm": 0.04060020670294762, "ratio": 1.0002044439315796, "entropy": 0.47568061351776125, "incre_win_rate": 0.8, "step": 3037}
{"time": 1767094069.3168147, "phase": "train", "update": 3038, "total_env_steps": 9721600, "episode_reward": 0.24080608785152435, "value_loss": 0.008036576118320227, "policy_loss": -0.0018107232527583505, "dist_entropy": 0.4943716287612915, "actor_grad_norm": 0.13057607412338257, "critic_grad_norm": 0.032381873577833176, "ratio": 0.9996936917304993, "entropy": 0.4943716287612915, "incre_win_rate": 0.6744186046511628, "step": 3038}
{"time": 1767094074.0581622, "phase": "train", "update": 3039, "total_env_steps": 9724800, "episode_reward": 0.24802877008914948, "value_loss": 0.009256971068680286, "policy_loss": -0.0016881532081473693, "dist_entropy": 0.45422797203063964, "actor_grad_norm": 0.1478164941072464, "critic_grad_norm": 0.025711894035339355, "ratio": 0.9996244311332703, "entropy": 0.45422797203063964, "incre_win_rate": 0.6444444444444445, "step": 3039}
{"time": 1767094078.7613819, "phase": "train", "update": 3040, "total_env_steps": 9728000, "episode_reward": 0.23823417723178864, "value_loss": 0.009074942208826542, "policy_loss": -0.0016457824268542253, "dist_entropy": 0.47488099336624146, "actor_grad_norm": 0.10609584301710129, "critic_grad_norm": 0.026746466755867004, "ratio": 1.0003910064697266, "entropy": 0.47488099336624146, "incre_win_rate": 0.75, "step": 3040}
{"time": 1767094083.3866982, "phase": "train", "update": 3041, "total_env_steps": 9731200, "episode_reward": 0.2303362786769867, "value_loss": 0.010879599861800671, "policy_loss": -0.0018802090130755288, "dist_entropy": 0.4629070222377777, "actor_grad_norm": 0.1150345429778099, "critic_grad_norm": 0.03657114878296852, "ratio": 1.0004953145980835, "entropy": 0.4629070222377777, "incre_win_rate": 0.6190476190476191, "step": 3041}
{"time": 1767094094.3836322, "phase": "eval", "update": 3041, "total_env_steps": 9731200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.833195364238406, "step": 3041}
{"time": 1767094099.0943794, "phase": "train", "update": 3042, "total_env_steps": 9734400, "episode_reward": 0.26139020919799805, "value_loss": 0.007595789711922407, "policy_loss": -0.001833422390944861, "dist_entropy": 0.46945883631706237, "actor_grad_norm": 0.1401674598455429, "critic_grad_norm": 0.03356030210852623, "ratio": 0.9996883273124695, "entropy": 0.46945883631706237, "incre_win_rate": 0.813953488372093, "step": 3042}
{"time": 1767094103.7396655, "phase": "train", "update": 3043, "total_env_steps": 9737600, "episode_reward": 0.2505044639110565, "value_loss": 0.009981562942266464, "policy_loss": -0.0016811408007798788, "dist_entropy": 0.46381303668022156, "actor_grad_norm": 0.13667228817939758, "critic_grad_norm": 0.03219559043645859, "ratio": 0.999966561794281, "entropy": 0.46381303668022156, "incre_win_rate": 0.7333333333333333, "step": 3043}
{"time": 1767094108.4139297, "phase": "train", "update": 3044, "total_env_steps": 9740800, "episode_reward": 0.24299977719783783, "value_loss": 0.011695094220340253, "policy_loss": -0.0021710539383491324, "dist_entropy": 0.4579270601272583, "actor_grad_norm": 0.1217011958360672, "critic_grad_norm": 0.06009737402200699, "ratio": 1.0001485347747803, "entropy": 0.4579270601272583, "incre_win_rate": 0.85, "step": 3044}
{"time": 1767094113.0852437, "phase": "train", "update": 3045, "total_env_steps": 9744000, "episode_reward": 0.23300188779830933, "value_loss": 0.007959405891597271, "policy_loss": -0.0019001534548984012, "dist_entropy": 0.4820606529712677, "actor_grad_norm": 0.1189902052283287, "critic_grad_norm": 0.04440988227725029, "ratio": 0.9999123811721802, "entropy": 0.4820606529712677, "incre_win_rate": 0.7380952380952381, "step": 3045}
{"time": 1767094117.7382493, "phase": "train", "update": 3046, "total_env_steps": 9747200, "episode_reward": 0.2302064448595047, "value_loss": 0.007561931945383548, "policy_loss": -0.001828853312592571, "dist_entropy": 0.4732120096683502, "actor_grad_norm": 0.10661180317401886, "critic_grad_norm": 0.0408528633415699, "ratio": 1.000074028968811, "entropy": 0.4732120096683502, "incre_win_rate": 0.675, "step": 3046}
{"time": 1767094122.4844751, "phase": "train", "update": 3047, "total_env_steps": 9750400, "episode_reward": 0.26351046562194824, "value_loss": 0.006077947374433279, "policy_loss": -0.0017478749117366022, "dist_entropy": 0.4710146844387054, "actor_grad_norm": 0.11529018729925156, "critic_grad_norm": 0.02861137129366398, "ratio": 0.9998106956481934, "entropy": 0.4710146844387054, "incre_win_rate": 0.8780487804878049, "step": 3047}
{"time": 1767094127.2136464, "phase": "train", "update": 3048, "total_env_steps": 9753600, "episode_reward": 0.2484721690416336, "value_loss": 0.007132556661963463, "policy_loss": -0.001781217905164567, "dist_entropy": 0.4695852518081665, "actor_grad_norm": 0.11669762432575226, "critic_grad_norm": 0.031348831951618195, "ratio": 1.0000184774398804, "entropy": 0.4695852518081665, "incre_win_rate": 0.7272727272727273, "step": 3048}
{"time": 1767094131.9649992, "phase": "train", "update": 3049, "total_env_steps": 9756800, "episode_reward": 0.25484272837638855, "value_loss": 0.007782577630132436, "policy_loss": -0.0015480414691381838, "dist_entropy": 0.4844998478889465, "actor_grad_norm": 0.10984640568494797, "critic_grad_norm": 0.02603822387754917, "ratio": 1.0001789331436157, "entropy": 0.4844998478889465, "incre_win_rate": 0.7209302325581395, "step": 3049}
{"time": 1767094136.6516783, "phase": "train", "update": 3050, "total_env_steps": 9760000, "episode_reward": 0.2599586248397827, "value_loss": 0.00823459941893816, "policy_loss": -0.0018301336623300912, "dist_entropy": 0.46383351683616636, "actor_grad_norm": 0.11557996273040771, "critic_grad_norm": 0.02689187601208687, "ratio": 1.0001558065414429, "entropy": 0.46383351683616636, "incre_win_rate": 0.813953488372093, "step": 3050}
{"time": 1767094141.3718038, "phase": "train", "update": 3051, "total_env_steps": 9763200, "episode_reward": 0.2544717490673065, "value_loss": 0.00749657591804862, "policy_loss": -0.0017863090045949549, "dist_entropy": 0.45872392058372496, "actor_grad_norm": 0.1223590299487114, "critic_grad_norm": 0.03503156453371048, "ratio": 1.000172734260559, "entropy": 0.45872392058372496, "incre_win_rate": 0.782608695652174, "step": 3051}
{"time": 1767094146.0930037, "phase": "train", "update": 3052, "total_env_steps": 9766400, "episode_reward": 0.255289763212204, "value_loss": 0.008422868885099888, "policy_loss": -0.0019947693149632074, "dist_entropy": 0.47718387842178345, "actor_grad_norm": 0.1133870854973793, "critic_grad_norm": 0.027404094114899635, "ratio": 0.9999694228172302, "entropy": 0.47718387842178345, "incre_win_rate": 0.7560975609756098, "step": 3052}
{"time": 1767094150.834548, "phase": "train", "update": 3053, "total_env_steps": 9769600, "episode_reward": 0.25244879722595215, "value_loss": 0.008566598035395145, "policy_loss": -0.0016700030568443935, "dist_entropy": 0.45704710483551025, "actor_grad_norm": 0.1079769879579544, "critic_grad_norm": 0.03306226432323456, "ratio": 0.9995176196098328, "entropy": 0.45704710483551025, "incre_win_rate": 0.7111111111111111, "step": 3053}
{"time": 1767094155.529146, "phase": "train", "update": 3054, "total_env_steps": 9772800, "episode_reward": 0.2516835927963257, "value_loss": 0.008366373926401138, "policy_loss": -0.0018445934755987991, "dist_entropy": 0.4809696197509766, "actor_grad_norm": 0.12865187227725983, "critic_grad_norm": 0.035561900585889816, "ratio": 1.000046730041504, "entropy": 0.4809696197509766, "incre_win_rate": 0.7441860465116279, "step": 3054}
{"time": 1767094160.2305012, "phase": "train", "update": 3055, "total_env_steps": 9776000, "episode_reward": 0.2525983154773712, "value_loss": 0.007234289683401585, "policy_loss": -0.0014785697958402011, "dist_entropy": 0.460733026266098, "actor_grad_norm": 0.15377715229988098, "critic_grad_norm": 0.02788468636572361, "ratio": 0.9996488690376282, "entropy": 0.460733026266098, "incre_win_rate": 0.7954545454545454, "step": 3055}
{"time": 1767094164.8982453, "phase": "train", "update": 3056, "total_env_steps": 9779200, "episode_reward": 0.2371978610754013, "value_loss": 0.011689956486225127, "policy_loss": -0.0019805819992569696, "dist_entropy": 0.46311894059181213, "actor_grad_norm": 0.11225023120641708, "critic_grad_norm": 0.07857363671064377, "ratio": 1.0001285076141357, "entropy": 0.46311894059181213, "incre_win_rate": 0.6341463414634146, "step": 3056}
{"time": 1767094169.5983863, "phase": "train", "update": 3057, "total_env_steps": 9782400, "episode_reward": 0.24449606239795685, "value_loss": 0.00976489596068859, "policy_loss": -0.001733093706029365, "dist_entropy": 0.4715084731578827, "actor_grad_norm": 0.12776559591293335, "critic_grad_norm": 0.05859280750155449, "ratio": 0.9999917149543762, "entropy": 0.4715084731578827, "incre_win_rate": 0.6818181818181818, "step": 3057}
{"time": 1767094174.304209, "phase": "train", "update": 3058, "total_env_steps": 9785600, "episode_reward": 0.24959488213062286, "value_loss": 0.00826383214443922, "policy_loss": -0.0017116433485767856, "dist_entropy": 0.473871636390686, "actor_grad_norm": 0.11491359770298004, "critic_grad_norm": 0.08178658038377762, "ratio": 1.0000642538070679, "entropy": 0.473871636390686, "incre_win_rate": 0.7317073170731707, "step": 3058}
{"time": 1767094179.2996914, "phase": "train", "update": 3059, "total_env_steps": 9788800, "episode_reward": 0.24991464614868164, "value_loss": 0.008029815554618836, "policy_loss": -0.001812176003284094, "dist_entropy": 0.4718397259712219, "actor_grad_norm": 0.15554706752300262, "critic_grad_norm": 0.035733308643102646, "ratio": 0.9998584985733032, "entropy": 0.4718397259712219, "incre_win_rate": 0.7111111111111111, "step": 3059}
{"time": 1767094184.3955433, "phase": "train", "update": 3060, "total_env_steps": 9792000, "episode_reward": 0.24329623579978943, "value_loss": 0.006928497646003962, "policy_loss": -0.002025146018851842, "dist_entropy": 0.49550833702087405, "actor_grad_norm": 0.15773330628871918, "critic_grad_norm": 0.03140717372298241, "ratio": 1.0001204013824463, "entropy": 0.49550833702087405, "incre_win_rate": 0.775, "step": 3060}
{"time": 1767094189.4405727, "phase": "train", "update": 3061, "total_env_steps": 9795200, "episode_reward": 0.2527778446674347, "value_loss": 0.008629204519093037, "policy_loss": -0.0016933118944855608, "dist_entropy": 0.45896939039230344, "actor_grad_norm": 0.12460888922214508, "critic_grad_norm": 0.01818729005753994, "ratio": 1.0001980066299438, "entropy": 0.45896939039230344, "incre_win_rate": 0.6739130434782609, "step": 3061}
{"time": 1767094200.5796027, "phase": "eval", "update": 3061, "total_env_steps": 9795200, "eval_win_rate": 0.78125, "eval_episode_reward": 18.816949503311257, "step": 3061}
{"time": 1767094205.3280485, "phase": "train", "update": 3062, "total_env_steps": 9798400, "episode_reward": 0.25208866596221924, "value_loss": 0.0103869853541255, "policy_loss": -0.001922130968891622, "dist_entropy": 0.4721923053264618, "actor_grad_norm": 0.1656823754310608, "critic_grad_norm": 0.028578100726008415, "ratio": 1.000006079673767, "entropy": 0.4721923053264618, "incre_win_rate": 0.6744186046511628, "step": 3062}
{"time": 1767094210.0371096, "phase": "train", "update": 3063, "total_env_steps": 9801600, "episode_reward": 0.24445468187332153, "value_loss": 0.008264824561774731, "policy_loss": -0.0019250335182888988, "dist_entropy": 0.4708731174468994, "actor_grad_norm": 0.1257036030292511, "critic_grad_norm": 0.043771274387836456, "ratio": 0.999906063079834, "entropy": 0.4708731174468994, "incre_win_rate": 0.6590909090909091, "step": 3063}
{"time": 1767094214.732888, "phase": "train", "update": 3064, "total_env_steps": 9804800, "episode_reward": 0.2603502869606018, "value_loss": 0.008550232276320457, "policy_loss": -0.0018192919221365678, "dist_entropy": 0.45318969488143923, "actor_grad_norm": 0.17402487993240356, "critic_grad_norm": 0.03985968604683876, "ratio": 1.0003465414047241, "entropy": 0.45318969488143923, "incre_win_rate": 0.7209302325581395, "step": 3064}
{"time": 1767094219.4657187, "phase": "train", "update": 3065, "total_env_steps": 9808000, "episode_reward": 0.24633176624774933, "value_loss": 0.007999969553202391, "policy_loss": -0.0015722410746590754, "dist_entropy": 0.4696322202682495, "actor_grad_norm": 0.1568015217781067, "critic_grad_norm": 0.03358471021056175, "ratio": 1.0001269578933716, "entropy": 0.4696322202682495, "incre_win_rate": 0.6888888888888889, "step": 3065}
{"time": 1767094224.2028468, "phase": "train", "update": 3066, "total_env_steps": 9811200, "episode_reward": 0.2617120146751404, "value_loss": 0.007292118109762669, "policy_loss": -0.0016461856254053942, "dist_entropy": 0.4619112014770508, "actor_grad_norm": 0.13024163246154785, "critic_grad_norm": 0.046167466789484024, "ratio": 0.999707818031311, "entropy": 0.4619112014770508, "incre_win_rate": 0.7906976744186046, "step": 3066}
{"time": 1767094228.8971035, "phase": "train", "update": 3067, "total_env_steps": 9814400, "episode_reward": 0.2577395737171173, "value_loss": 0.007957687601447105, "policy_loss": -0.0016020581931229573, "dist_entropy": 0.45929598808288574, "actor_grad_norm": 0.1296948790550232, "critic_grad_norm": 0.03693964332342148, "ratio": 0.9997166991233826, "entropy": 0.45929598808288574, "incre_win_rate": 0.8222222222222222, "step": 3067}
{"time": 1767094233.5833564, "phase": "train", "update": 3068, "total_env_steps": 9817600, "episode_reward": 0.2408987283706665, "value_loss": 0.006963048502802849, "policy_loss": -0.0020428626289856313, "dist_entropy": 0.4602574646472931, "actor_grad_norm": 0.12459593266248703, "critic_grad_norm": 0.03241968899965286, "ratio": 0.999829888343811, "entropy": 0.4602574646472931, "incre_win_rate": 0.625, "step": 3068}
{"time": 1767094238.2604933, "phase": "train", "update": 3069, "total_env_steps": 9820800, "episode_reward": 0.24858495593070984, "value_loss": 0.007906644232571125, "policy_loss": -0.0017585307999901545, "dist_entropy": 0.4727317810058594, "actor_grad_norm": 0.17082403600215912, "critic_grad_norm": 0.060916151851415634, "ratio": 0.9998332262039185, "entropy": 0.4727317810058594, "incre_win_rate": 0.6818181818181818, "step": 3069}
{"time": 1767094242.9782195, "phase": "train", "update": 3070, "total_env_steps": 9824000, "episode_reward": 0.25605547428131104, "value_loss": 0.008111311867833138, "policy_loss": -0.0017138884098585549, "dist_entropy": 0.44974350929260254, "actor_grad_norm": 0.14344964921474457, "critic_grad_norm": 0.0506073497235775, "ratio": 1.0003557205200195, "entropy": 0.44974350929260254, "incre_win_rate": 0.6444444444444445, "step": 3070}
{"time": 1767094248.1014595, "phase": "train", "update": 3071, "total_env_steps": 9827200, "episode_reward": 0.25548842549324036, "value_loss": 0.008810753375291825, "policy_loss": -0.0016150850621727386, "dist_entropy": 0.45511014461517335, "actor_grad_norm": 0.17680208384990692, "critic_grad_norm": 0.040859248489141464, "ratio": 1.0000759363174438, "entropy": 0.45511014461517335, "incre_win_rate": 0.6956521739130435, "step": 3071}
{"time": 1767094253.222296, "phase": "train", "update": 3072, "total_env_steps": 9830400, "episode_reward": 0.2647630274295807, "value_loss": 0.007227409537881613, "policy_loss": -0.0015440590761084394, "dist_entropy": 0.44325482845306396, "actor_grad_norm": 0.14020729064941406, "critic_grad_norm": 0.07804342359304428, "ratio": 0.9996682405471802, "entropy": 0.44325482845306396, "incre_win_rate": 0.7857142857142857, "step": 3072}
{"time": 1767094258.262145, "phase": "train", "update": 3073, "total_env_steps": 9833600, "episode_reward": 0.26062706112861633, "value_loss": 0.005829787533730269, "policy_loss": -0.0018839443881883966, "dist_entropy": 0.461089038848877, "actor_grad_norm": 0.13195860385894775, "critic_grad_norm": 0.06961539387702942, "ratio": 0.9999843835830688, "entropy": 0.461089038848877, "incre_win_rate": 0.8297872340425532, "step": 3073}
{"time": 1767094263.3502436, "phase": "train", "update": 3074, "total_env_steps": 9836800, "episode_reward": 0.25771525502204895, "value_loss": 0.007226014323532581, "policy_loss": -0.0017620451508491898, "dist_entropy": 0.44834354519844055, "actor_grad_norm": 0.19708964228630066, "critic_grad_norm": 0.025032952427864075, "ratio": 0.999866783618927, "entropy": 0.44834354519844055, "incre_win_rate": 0.725, "step": 3074}
{"time": 1767094268.3284373, "phase": "train", "update": 3075, "total_env_steps": 9840000, "episode_reward": 0.257226824760437, "value_loss": 0.007604361232370138, "policy_loss": -0.0012465580573639556, "dist_entropy": 0.44771971106529235, "actor_grad_norm": 0.21749566495418549, "critic_grad_norm": 0.02243790403008461, "ratio": 1.000160813331604, "entropy": 0.44771971106529235, "incre_win_rate": 0.7608695652173914, "step": 3075}
{"time": 1767094273.4047706, "phase": "train", "update": 3076, "total_env_steps": 9843200, "episode_reward": 0.2585156261920929, "value_loss": 0.009094887040555477, "policy_loss": -0.0015202353192279362, "dist_entropy": 0.4614571571350098, "actor_grad_norm": 0.12202432006597519, "critic_grad_norm": 0.019958961755037308, "ratio": 1.0002946853637695, "entropy": 0.4614571571350098, "incre_win_rate": 0.75, "step": 3076}
{"time": 1767094278.4305506, "phase": "train", "update": 3077, "total_env_steps": 9846400, "episode_reward": 0.2554687559604645, "value_loss": 0.006417979393154383, "policy_loss": -0.00153965688215294, "dist_entropy": 0.45131062269210814, "actor_grad_norm": 0.11718809604644775, "critic_grad_norm": 0.025270208716392517, "ratio": 0.9996902346611023, "entropy": 0.45131062269210814, "incre_win_rate": 0.8372093023255814, "step": 3077}
{"time": 1767094283.556367, "phase": "train", "update": 3078, "total_env_steps": 9849600, "episode_reward": 0.25943711400032043, "value_loss": 0.00576644679531455, "policy_loss": -0.0015816230720574254, "dist_entropy": 0.46279568076133726, "actor_grad_norm": 0.10222937911748886, "critic_grad_norm": 0.04474865272641182, "ratio": 0.9999589920043945, "entropy": 0.46279568076133726, "incre_win_rate": 0.8095238095238095, "step": 3078}
{"time": 1767094288.6103544, "phase": "train", "update": 3079, "total_env_steps": 9852800, "episode_reward": 0.25153714418411255, "value_loss": 0.006525007262825966, "policy_loss": -0.00183034687779724, "dist_entropy": 0.463500565290451, "actor_grad_norm": 0.12031686305999756, "critic_grad_norm": 0.02210927940905094, "ratio": 0.9997312426567078, "entropy": 0.463500565290451, "incre_win_rate": 0.7777777777777778, "step": 3079}
{"time": 1767094293.713997, "phase": "train", "update": 3080, "total_env_steps": 9856000, "episode_reward": 0.2600729763507843, "value_loss": 0.006392394006252289, "policy_loss": -0.0019166413045702767, "dist_entropy": 0.46817755699157715, "actor_grad_norm": 0.1497771143913269, "critic_grad_norm": 0.03022700920701027, "ratio": 0.9997621774673462, "entropy": 0.46817755699157715, "incre_win_rate": 0.7857142857142857, "step": 3080}
{"time": 1767094298.7489617, "phase": "train", "update": 3081, "total_env_steps": 9859200, "episode_reward": 0.25136175751686096, "value_loss": 0.007180208899080753, "policy_loss": -0.0021365772738967336, "dist_entropy": 0.44234858751296996, "actor_grad_norm": 0.1658065915107727, "critic_grad_norm": 0.025155603885650635, "ratio": 0.9998654723167419, "entropy": 0.44234858751296996, "incre_win_rate": 0.6888888888888889, "step": 3081}
{"time": 1767094310.617791, "phase": "eval", "update": 3081, "total_env_steps": 9859200, "eval_win_rate": 1.0, "eval_episode_reward": 20.007760761589402, "step": 3081}
{"time": 1767094315.6941237, "phase": "train", "update": 3082, "total_env_steps": 9862400, "episode_reward": 0.26544442772865295, "value_loss": 0.006478332262486219, "policy_loss": -0.0016720999140176218, "dist_entropy": 0.46125997304916383, "actor_grad_norm": 0.1503239870071411, "critic_grad_norm": 0.043942153453826904, "ratio": 0.9996381998062134, "entropy": 0.46125997304916383, "incre_win_rate": 0.8571428571428571, "step": 3082}
{"time": 1767094320.7961986, "phase": "train", "update": 3083, "total_env_steps": 9865600, "episode_reward": 0.2621978521347046, "value_loss": 0.0050416277721524235, "policy_loss": -0.00162570096327741, "dist_entropy": 0.44737704992294314, "actor_grad_norm": 0.1540205478668213, "critic_grad_norm": 0.03754744678735733, "ratio": 0.999653160572052, "entropy": 0.44737704992294314, "incre_win_rate": 0.8444444444444444, "step": 3083}
{"time": 1767094325.8436434, "phase": "train", "update": 3084, "total_env_steps": 9868800, "episode_reward": 0.25743842124938965, "value_loss": 0.005600687116384506, "policy_loss": -0.0013287071156085517, "dist_entropy": 0.4415225625038147, "actor_grad_norm": 0.11766507476568222, "critic_grad_norm": 0.03489863872528076, "ratio": 1.0001065731048584, "entropy": 0.4415225625038147, "incre_win_rate": 0.8780487804878049, "step": 3084}
{"time": 1767094330.9123037, "phase": "train", "update": 3085, "total_env_steps": 9872000, "episode_reward": 0.24587903916835785, "value_loss": 0.009012575820088386, "policy_loss": -0.0015693480064975062, "dist_entropy": 0.4485721290111542, "actor_grad_norm": 0.17603199183940887, "critic_grad_norm": 0.07091572135686874, "ratio": 0.9999361038208008, "entropy": 0.4485721290111542, "incre_win_rate": 0.6521739130434783, "step": 3085}
{"time": 1767094336.0133774, "phase": "train", "update": 3086, "total_env_steps": 9875200, "episode_reward": 0.2618775963783264, "value_loss": 0.007622869312763214, "policy_loss": -0.0017988128990609198, "dist_entropy": 0.43730835914611815, "actor_grad_norm": 0.14421050250530243, "critic_grad_norm": 0.052055735141038895, "ratio": 0.9997755289077759, "entropy": 0.43730835914611815, "incre_win_rate": 0.8048780487804879, "step": 3086}
{"time": 1767094341.0679095, "phase": "train", "update": 3087, "total_env_steps": 9878400, "episode_reward": 0.24847063422203064, "value_loss": 0.007130803726613522, "policy_loss": -0.0018037915630827682, "dist_entropy": 0.46424820423126223, "actor_grad_norm": 0.14082325994968414, "critic_grad_norm": 0.049833815544843674, "ratio": 0.9998543858528137, "entropy": 0.46424820423126223, "incre_win_rate": 0.7674418604651163, "step": 3087}
{"time": 1767094346.1825347, "phase": "train", "update": 3088, "total_env_steps": 9881600, "episode_reward": 0.264248251914978, "value_loss": 0.007873002719134093, "policy_loss": -0.0014465331333511245, "dist_entropy": 0.4631529748439789, "actor_grad_norm": 0.18885986506938934, "critic_grad_norm": 0.01886908710002899, "ratio": 1.0000916719436646, "entropy": 0.4631529748439789, "incre_win_rate": 0.8636363636363636, "step": 3088}
{"time": 1767094351.282379, "phase": "train", "update": 3089, "total_env_steps": 9884800, "episode_reward": 0.2537769079208374, "value_loss": 0.0077164326794445515, "policy_loss": -0.0021960123636887373, "dist_entropy": 0.4565039396286011, "actor_grad_norm": 0.15138943493366241, "critic_grad_norm": 0.05012151598930359, "ratio": 1.0000300407409668, "entropy": 0.4565039396286011, "incre_win_rate": 0.7111111111111111, "step": 3089}
{"time": 1767094356.4133308, "phase": "train", "update": 3090, "total_env_steps": 9888000, "episode_reward": 0.25806134939193726, "value_loss": 0.00795004153624177, "policy_loss": -0.001577925584285822, "dist_entropy": 0.46323567628860474, "actor_grad_norm": 0.11923851817846298, "critic_grad_norm": 0.03269818052649498, "ratio": 1.0001035928726196, "entropy": 0.46323567628860474, "incre_win_rate": 0.7954545454545454, "step": 3090}
{"time": 1767094361.4783049, "phase": "train", "update": 3091, "total_env_steps": 9891200, "episode_reward": 0.2535792589187622, "value_loss": 0.009340985119342804, "policy_loss": -0.0015230465307038087, "dist_entropy": 0.4642291009426117, "actor_grad_norm": 0.12700791656970978, "critic_grad_norm": 0.02535400353372097, "ratio": 0.999636173248291, "entropy": 0.4642291009426117, "incre_win_rate": 0.7209302325581395, "step": 3091}
{"time": 1767094366.6169484, "phase": "train", "update": 3092, "total_env_steps": 9894400, "episode_reward": 0.2655225694179535, "value_loss": 0.005815466213971376, "policy_loss": -0.0017137749957356618, "dist_entropy": 0.45618491172790526, "actor_grad_norm": 0.1153353676199913, "critic_grad_norm": 0.04384833574295044, "ratio": 0.9997916221618652, "entropy": 0.45618491172790526, "incre_win_rate": 0.8444444444444444, "step": 3092}
{"time": 1767094371.7537675, "phase": "train", "update": 3093, "total_env_steps": 9897600, "episode_reward": 0.2626272737979889, "value_loss": 0.007100955303758383, "policy_loss": -0.0013232535796817047, "dist_entropy": 0.4664758205413818, "actor_grad_norm": 0.12688994407653809, "critic_grad_norm": 0.03348343074321747, "ratio": 1.0000911951065063, "entropy": 0.4664758205413818, "incre_win_rate": 0.8095238095238095, "step": 3093}
{"time": 1767094376.8091197, "phase": "train", "update": 3094, "total_env_steps": 9900800, "episode_reward": 0.2516613304615021, "value_loss": 0.005585209932178259, "policy_loss": -0.0019625911395706906, "dist_entropy": 0.4709439933300018, "actor_grad_norm": 0.1312987059354782, "critic_grad_norm": 0.03915500268340111, "ratio": 0.9998230338096619, "entropy": 0.4709439933300018, "incre_win_rate": 0.813953488372093, "step": 3094}
{"time": 1767094381.9200683, "phase": "train", "update": 3095, "total_env_steps": 9904000, "episode_reward": 0.2659261226654053, "value_loss": 0.006109747104346752, "policy_loss": -0.0015652821055340382, "dist_entropy": 0.4554048955440521, "actor_grad_norm": 0.12683358788490295, "critic_grad_norm": 0.03835516422986984, "ratio": 0.9998365640640259, "entropy": 0.4554048955440521, "incre_win_rate": 0.8837209302325582, "step": 3095}
{"time": 1767094386.9682782, "phase": "train", "update": 3096, "total_env_steps": 9907200, "episode_reward": 0.2535451352596283, "value_loss": 0.006096816342324019, "policy_loss": -0.0019706955273932182, "dist_entropy": 0.43582419157028196, "actor_grad_norm": 0.12802861630916595, "critic_grad_norm": 0.039698053151369095, "ratio": 0.9999712109565735, "entropy": 0.43582419157028196, "incre_win_rate": 0.8181818181818182, "step": 3096}
{"time": 1767094392.1508005, "phase": "train", "update": 3097, "total_env_steps": 9910400, "episode_reward": 0.25308722257614136, "value_loss": 0.008572103083133697, "policy_loss": -0.0013794327249613048, "dist_entropy": 0.4502067804336548, "actor_grad_norm": 0.11606868356466293, "critic_grad_norm": 0.02738995850086212, "ratio": 0.9998717308044434, "entropy": 0.4502067804336548, "incre_win_rate": 0.7906976744186046, "step": 3097}
{"time": 1767094397.313035, "phase": "train", "update": 3098, "total_env_steps": 9913600, "episode_reward": 0.2648147940635681, "value_loss": 0.007397658377885819, "policy_loss": -0.002005045443188891, "dist_entropy": 0.4401312470436096, "actor_grad_norm": 0.12699250876903534, "critic_grad_norm": 0.03833288326859474, "ratio": 0.9997356534004211, "entropy": 0.4401312470436096, "incre_win_rate": 0.7954545454545454, "step": 3098}
{"time": 1767094402.394174, "phase": "train", "update": 3099, "total_env_steps": 9916800, "episode_reward": 0.26392799615859985, "value_loss": 0.0060480209067463875, "policy_loss": -0.0015649543419357314, "dist_entropy": 0.44355148673057554, "actor_grad_norm": 0.12933090329170227, "critic_grad_norm": 0.04759461060166359, "ratio": 1.0000108480453491, "entropy": 0.44355148673057554, "incre_win_rate": 0.8409090909090909, "step": 3099}
{"time": 1767094407.5098903, "phase": "train", "update": 3100, "total_env_steps": 9920000, "episode_reward": 0.27167168259620667, "value_loss": 0.007343547139316797, "policy_loss": -0.0014094112004244153, "dist_entropy": 0.45280986428260805, "actor_grad_norm": 0.1725999116897583, "critic_grad_norm": 0.05671073868870735, "ratio": 1.000138521194458, "entropy": 0.45280986428260805, "incre_win_rate": 0.8222222222222222, "step": 3100}
{"time": 1767094412.5759017, "phase": "train", "update": 3101, "total_env_steps": 9923200, "episode_reward": 0.24706076085567474, "value_loss": 0.010282732173800468, "policy_loss": -0.001822404217175233, "dist_entropy": 0.44526731967926025, "actor_grad_norm": 0.15078221261501312, "critic_grad_norm": 0.08806546777486801, "ratio": 0.9998558163642883, "entropy": 0.44526731967926025, "incre_win_rate": 0.6888888888888889, "step": 3101}
{"time": 1767094424.2486641, "phase": "eval", "update": 3101, "total_env_steps": 9923200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.73240894039735, "step": 3101}
{"time": 1767094429.37269, "phase": "train", "update": 3102, "total_env_steps": 9926400, "episode_reward": 0.2609349191188812, "value_loss": 0.009901594556868076, "policy_loss": -0.001324731865943818, "dist_entropy": 0.4341177999973297, "actor_grad_norm": 0.1153387576341629, "critic_grad_norm": 0.061603154987096786, "ratio": 1.0002245903015137, "entropy": 0.4341177999973297, "incre_win_rate": 0.7906976744186046, "step": 3102}
{"time": 1767094434.5571928, "phase": "train", "update": 3103, "total_env_steps": 9929600, "episode_reward": 0.26746121048927307, "value_loss": 0.0055972239002585415, "policy_loss": -0.0015221853352301196, "dist_entropy": 0.43248745799064636, "actor_grad_norm": 0.157409206032753, "critic_grad_norm": 0.05407474562525749, "ratio": 0.9999104738235474, "entropy": 0.43248745799064636, "incre_win_rate": 0.8409090909090909, "step": 3103}
{"time": 1767094439.6593075, "phase": "train", "update": 3104, "total_env_steps": 9932800, "episode_reward": 0.26808828115463257, "value_loss": 0.005412701144814491, "policy_loss": -0.0015079642637358503, "dist_entropy": 0.4421000421047211, "actor_grad_norm": 0.12473731487989426, "critic_grad_norm": 0.028804078698158264, "ratio": 0.9999479651451111, "entropy": 0.4421000421047211, "incre_win_rate": 0.8222222222222222, "step": 3104}
{"time": 1767094480.0857418, "phase": "train", "update": 3105, "total_env_steps": 9936000, "episode_reward": 0.25776436924934387, "value_loss": 0.04669477567076683, "policy_loss": -0.0015786071737167618, "dist_entropy": 0.4475106716156006, "actor_grad_norm": 0.13108980655670166, "critic_grad_norm": 0.18461449444293976, "ratio": 0.9998406767845154, "entropy": 0.4475106716156006, "incre_win_rate": 0.8048780487804879, "step": 3105}
{"time": 1767094485.2934668, "phase": "train", "update": 3106, "total_env_steps": 9939200, "episode_reward": 0.2669402062892914, "value_loss": 0.006459270138293505, "policy_loss": -0.001432968151635805, "dist_entropy": 0.4523219347000122, "actor_grad_norm": 0.12590041756629944, "critic_grad_norm": 0.17371514439582825, "ratio": 1.0002201795578003, "entropy": 0.4523219347000122, "incre_win_rate": 0.8666666666666667, "step": 3106}
{"time": 1767094490.3527925, "phase": "train", "update": 3107, "total_env_steps": 9942400, "episode_reward": 0.24590647220611572, "value_loss": 0.008481410797685385, "policy_loss": -0.001404044168833707, "dist_entropy": 0.45672047734260557, "actor_grad_norm": 0.10347466915845871, "critic_grad_norm": 0.11395125836133957, "ratio": 1.0003384351730347, "entropy": 0.45672047734260557, "incre_win_rate": 0.775, "step": 3107}
{"time": 1767094495.5290108, "phase": "train", "update": 3108, "total_env_steps": 9945600, "episode_reward": 0.2713632881641388, "value_loss": 0.006505477149039507, "policy_loss": -0.0013855252273387464, "dist_entropy": 0.4429058969020844, "actor_grad_norm": 0.09955013543367386, "critic_grad_norm": 0.07605015486478806, "ratio": 0.9997180104255676, "entropy": 0.4429058969020844, "incre_win_rate": 0.8666666666666667, "step": 3108}
{"time": 1767094500.5821526, "phase": "train", "update": 3109, "total_env_steps": 9948800, "episode_reward": 0.242110937833786, "value_loss": 0.008572735264897347, "policy_loss": -0.0018317288077383865, "dist_entropy": 0.4457456648349762, "actor_grad_norm": 0.1359906643629074, "critic_grad_norm": 0.07088174670934677, "ratio": 0.999646782875061, "entropy": 0.4457456648349762, "incre_win_rate": 0.825, "step": 3109}
{"time": 1767094505.6986148, "phase": "train", "update": 3110, "total_env_steps": 9952000, "episode_reward": 0.24443605542182922, "value_loss": 0.00717503521591425, "policy_loss": -0.0014091009197457539, "dist_entropy": 0.44261821508407595, "actor_grad_norm": 0.126565620303154, "critic_grad_norm": 0.04992207512259483, "ratio": 1.0000159740447998, "entropy": 0.44261821508407595, "incre_win_rate": 0.7045454545454546, "step": 3110}
{"time": 1767094510.7683117, "phase": "train", "update": 3111, "total_env_steps": 9955200, "episode_reward": 0.272235631942749, "value_loss": 0.005106386635452509, "policy_loss": -0.001519308576824585, "dist_entropy": 0.441562682390213, "actor_grad_norm": 0.11690749228000641, "critic_grad_norm": 0.04624881222844124, "ratio": 0.9998616576194763, "entropy": 0.441562682390213, "incre_win_rate": 0.8837209302325582, "step": 3111}
{"time": 1767094515.8858135, "phase": "train", "update": 3112, "total_env_steps": 9958400, "episode_reward": 0.26839613914489746, "value_loss": 0.004562738165259361, "policy_loss": -0.001753348854999537, "dist_entropy": 0.4360945701599121, "actor_grad_norm": 0.12338124960660934, "critic_grad_norm": 0.02341652847826481, "ratio": 0.9997230768203735, "entropy": 0.4360945701599121, "incre_win_rate": 0.8444444444444444, "step": 3112}
{"time": 1767094520.918862, "phase": "train", "update": 3113, "total_env_steps": 9961600, "episode_reward": 0.2637355327606201, "value_loss": 0.005671333055943251, "policy_loss": -0.001818429102662833, "dist_entropy": 0.43797311186790466, "actor_grad_norm": 0.11012716591358185, "critic_grad_norm": 0.03071911446750164, "ratio": 0.9999272227287292, "entropy": 0.43797311186790466, "incre_win_rate": 0.7727272727272727, "step": 3113}
{"time": 1767094525.941609, "phase": "train", "update": 3114, "total_env_steps": 9964800, "episode_reward": 0.2582605481147766, "value_loss": 0.006942756101489067, "policy_loss": -0.0016111262109227199, "dist_entropy": 0.4511703073978424, "actor_grad_norm": 0.12525497376918793, "critic_grad_norm": 0.024353861808776855, "ratio": 1.000073790550232, "entropy": 0.4511703073978424, "incre_win_rate": 0.8604651162790697, "step": 3114}
{"time": 1767094530.9073956, "phase": "train", "update": 3115, "total_env_steps": 9968000, "episode_reward": 0.22883225977420807, "value_loss": 0.00780176417902112, "policy_loss": -0.00201315808286342, "dist_entropy": 0.43991504311561586, "actor_grad_norm": 0.11534296721220016, "critic_grad_norm": 0.046884097158908844, "ratio": 1.0003331899642944, "entropy": 0.43991504311561586, "incre_win_rate": 0.7, "step": 3115}
{"time": 1767094535.962782, "phase": "train", "update": 3116, "total_env_steps": 9971200, "episode_reward": 0.2575879693031311, "value_loss": 0.008580485172569752, "policy_loss": -0.001660976057962671, "dist_entropy": 0.4388744175434113, "actor_grad_norm": 0.11281400918960571, "critic_grad_norm": 0.04535549506545067, "ratio": 1.0000003576278687, "entropy": 0.4388744175434113, "incre_win_rate": 0.7555555555555555, "step": 3116}
{"time": 1767094540.9551063, "phase": "train", "update": 3117, "total_env_steps": 9974400, "episode_reward": 0.22479307651519775, "value_loss": 0.0075953549705445765, "policy_loss": -0.001519602729018743, "dist_entropy": 0.44425839781761167, "actor_grad_norm": 0.10297396034002304, "critic_grad_norm": 0.03074072115123272, "ratio": 1.0000914335250854, "entropy": 0.44425839781761167, "incre_win_rate": 0.65, "step": 3117}
{"time": 1767094546.0855558, "phase": "train", "update": 3118, "total_env_steps": 9977600, "episode_reward": 0.24832625687122345, "value_loss": 0.007119305338710547, "policy_loss": -0.0017040593942134307, "dist_entropy": 0.4423341691493988, "actor_grad_norm": 0.14667674899101257, "critic_grad_norm": 0.05226850137114525, "ratio": 0.9996001124382019, "entropy": 0.4423341691493988, "incre_win_rate": 0.8048780487804879, "step": 3118}
{"time": 1767094551.0856164, "phase": "train", "update": 3119, "total_env_steps": 9980800, "episode_reward": 0.22924000024795532, "value_loss": 0.006460906751453876, "policy_loss": -0.001835134584278819, "dist_entropy": 0.45047447681427, "actor_grad_norm": 0.11155825108289719, "critic_grad_norm": 0.04996926710009575, "ratio": 1.000045657157898, "entropy": 0.45047447681427, "incre_win_rate": 0.75, "step": 3119}
{"time": 1767094556.1436317, "phase": "train", "update": 3120, "total_env_steps": 9984000, "episode_reward": 0.2550812363624573, "value_loss": 0.00813430491834879, "policy_loss": -0.001381854255573778, "dist_entropy": 0.46620344519615176, "actor_grad_norm": 0.10587626695632935, "critic_grad_norm": 0.0445997416973114, "ratio": 0.9999510049819946, "entropy": 0.46620344519615176, "incre_win_rate": 0.7727272727272727, "step": 3120}
{"time": 1767094561.1703167, "phase": "train", "update": 3121, "total_env_steps": 9987200, "episode_reward": 0.25715646147727966, "value_loss": 0.0062803588807582855, "policy_loss": -0.0016871750415020869, "dist_entropy": 0.44163007140159605, "actor_grad_norm": 0.11060553044080734, "critic_grad_norm": 0.03313903138041496, "ratio": 0.9994573593139648, "entropy": 0.44163007140159605, "incre_win_rate": 0.9047619047619048, "step": 3121}
{"time": 1767094573.1538315, "phase": "eval", "update": 3121, "total_env_steps": 9987200, "eval_win_rate": 0.875, "eval_episode_reward": 19.550186258278146, "step": 3121}
{"time": 1767094578.2562582, "phase": "train", "update": 3122, "total_env_steps": 9990400, "episode_reward": 0.25622206926345825, "value_loss": 0.0057807501405477526, "policy_loss": -0.0017242728173322065, "dist_entropy": 0.4635534524917603, "actor_grad_norm": 0.1446998566389084, "critic_grad_norm": 0.026562301442027092, "ratio": 0.9996929168701172, "entropy": 0.4635534524917603, "incre_win_rate": 0.8292682926829268, "step": 3122}
{"time": 1767094583.1623654, "phase": "train", "update": 3123, "total_env_steps": 9993600, "episode_reward": 0.22206644713878632, "value_loss": 0.007182880584150553, "policy_loss": -0.001712719697002285, "dist_entropy": 0.4493776082992554, "actor_grad_norm": 0.14141716063022614, "critic_grad_norm": 0.025394558906555176, "ratio": 0.9999557733535767, "entropy": 0.4493776082992554, "incre_win_rate": 0.6923076923076923, "step": 3123}
{"time": 1767094588.1968837, "phase": "train", "update": 3124, "total_env_steps": 9996800, "episode_reward": 0.25985100865364075, "value_loss": 0.005338320229202509, "policy_loss": -0.0015975606960004995, "dist_entropy": 0.46372109055519106, "actor_grad_norm": 0.12209432572126389, "critic_grad_norm": 0.015533416531980038, "ratio": 0.9999892115592957, "entropy": 0.46372109055519106, "incre_win_rate": 0.8372093023255814, "step": 3124}
{"time": 1767094593.177544, "phase": "train", "update": 3125, "total_env_steps": 10000000, "episode_reward": 0.23262107372283936, "value_loss": 0.006981653533875943, "policy_loss": -0.0021160715636170833, "dist_entropy": 0.4627916753292084, "actor_grad_norm": 0.11770891398191452, "critic_grad_norm": 0.06071948632597923, "ratio": 1.0000094175338745, "entropy": 0.4627916753292084, "incre_win_rate": 0.775, "step": 3125}
