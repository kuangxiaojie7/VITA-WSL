{"time": 1767151067.9446828, "phase": "train", "update": 1, "total_env_steps": 3200, "episode_reward": 0.0857548639178276, "value_loss": 0.8916215658187866, "policy_loss": -0.001572091919811669, "dist_entropy": 2.027926206588745, "actor_grad_norm": 0.06966444849967957, "critic_grad_norm": 4.635842800140381, "ratio": 0.9999815225601196, "entropy": 2.027926206588745, "incre_win_rate": 0.0, "step": 1}
{"time": 1767151079.9504683, "phase": "eval", "update": 1, "total_env_steps": 3200, "eval_win_rate": 0.0, "eval_episode_reward": 10.008329884105962, "step": 1}
{"time": 1767151084.3565574, "phase": "train", "update": 2, "total_env_steps": 6400, "episode_reward": 0.09423219412565231, "value_loss": 0.407882422208786, "policy_loss": -0.0009164760103857362, "dist_entropy": 2.05839056968689, "actor_grad_norm": 0.06032799556851387, "critic_grad_norm": 4.494030475616455, "ratio": 0.9999638795852661, "entropy": 2.05839056968689, "incre_win_rate": 0.0, "step": 2}
{"time": 1767151088.8141987, "phase": "train", "update": 3, "total_env_steps": 9600, "episode_reward": 0.09465284645557404, "value_loss": 0.19126191437244416, "policy_loss": -0.0010807931143204997, "dist_entropy": 2.0555984020233153, "actor_grad_norm": 0.09200796484947205, "critic_grad_norm": 1.448508620262146, "ratio": 1.000045657157898, "entropy": 2.0555984020233153, "incre_win_rate": 0.0, "step": 3}
{"time": 1767151093.2013578, "phase": "train", "update": 4, "total_env_steps": 12800, "episode_reward": 0.09258123487234116, "value_loss": 0.12608584016561508, "policy_loss": -0.001738884758602044, "dist_entropy": 2.029895782470703, "actor_grad_norm": 0.11527711153030396, "critic_grad_norm": 0.921203076839447, "ratio": 1.0000241994857788, "entropy": 2.029895782470703, "incre_win_rate": 0.0, "step": 4}
{"time": 1767151097.6462593, "phase": "train", "update": 5, "total_env_steps": 16000, "episode_reward": 0.08802203834056854, "value_loss": 0.10659479647874832, "policy_loss": -0.001937766248846584, "dist_entropy": 1.9861058473587037, "actor_grad_norm": 0.12106990814208984, "critic_grad_norm": 0.9833405613899231, "ratio": 1.0000313520431519, "entropy": 1.9861058473587037, "incre_win_rate": 0.0, "step": 5}
{"time": 1767151101.994036, "phase": "train", "update": 6, "total_env_steps": 19200, "episode_reward": 0.0847366526722908, "value_loss": 0.09196484982967376, "policy_loss": -0.002112470585874515, "dist_entropy": 1.93398597240448, "actor_grad_norm": 0.13259805738925934, "critic_grad_norm": 0.4962294101715088, "ratio": 1.0001224279403687, "entropy": 1.93398597240448, "incre_win_rate": 0.0, "step": 6}
{"time": 1767151106.3511827, "phase": "train", "update": 7, "total_env_steps": 22400, "episode_reward": 0.08432739973068237, "value_loss": 0.09456074386835098, "policy_loss": -0.0021933484815485293, "dist_entropy": 1.8813972473144531, "actor_grad_norm": 0.12133204936981201, "critic_grad_norm": 0.3632032871246338, "ratio": 0.9997071623802185, "entropy": 1.8813972473144531, "incre_win_rate": 0.0, "step": 7}
{"time": 1767151110.7035189, "phase": "train", "update": 8, "total_env_steps": 25600, "episode_reward": 0.08679532259702682, "value_loss": 0.10369177460670471, "policy_loss": -0.0017541588216015923, "dist_entropy": 1.8271406888961792, "actor_grad_norm": 0.10753760486841202, "critic_grad_norm": 0.44400396943092346, "ratio": 0.9999395608901978, "entropy": 1.8271406888961792, "incre_win_rate": 0.0, "step": 8}
{"time": 1767151115.066619, "phase": "train", "update": 9, "total_env_steps": 28800, "episode_reward": 0.09457987546920776, "value_loss": 0.1161484107375145, "policy_loss": -0.0012871653260887682, "dist_entropy": 1.779073166847229, "actor_grad_norm": 0.07755936682224274, "critic_grad_norm": 0.9045267105102539, "ratio": 1.0000451803207397, "entropy": 1.779073166847229, "incre_win_rate": 0.0, "step": 9}
{"time": 1767151119.4694388, "phase": "train", "update": 10, "total_env_steps": 32000, "episode_reward": 0.0993206724524498, "value_loss": 0.10780438184738159, "policy_loss": -0.002231848528154856, "dist_entropy": 1.7500452995300293, "actor_grad_norm": 0.14555512368679047, "critic_grad_norm": 0.5312098860740662, "ratio": 0.9998422861099243, "entropy": 1.7500452995300293, "incre_win_rate": 0.0, "step": 10}
{"time": 1767151123.8548887, "phase": "train", "update": 11, "total_env_steps": 35200, "episode_reward": 0.1070607453584671, "value_loss": 0.09029962718486786, "policy_loss": -0.0017388641725327504, "dist_entropy": 1.7016363143920898, "actor_grad_norm": 0.10969581454992294, "critic_grad_norm": 0.36452609300613403, "ratio": 0.9996623992919922, "entropy": 1.7016363143920898, "incre_win_rate": 0.0, "step": 11}
{"time": 1767151128.282447, "phase": "train", "update": 12, "total_env_steps": 38400, "episode_reward": 0.10897816717624664, "value_loss": 0.0754330188035965, "policy_loss": -0.0009179279268958451, "dist_entropy": 1.6521016120910645, "actor_grad_norm": 0.062377650290727615, "critic_grad_norm": 0.30074968934059143, "ratio": 0.9998010993003845, "entropy": 1.6521016120910645, "incre_win_rate": 0.0, "step": 12}
{"time": 1767151132.7074792, "phase": "train", "update": 13, "total_env_steps": 41600, "episode_reward": 0.10470663756132126, "value_loss": 0.06303994879126548, "policy_loss": -0.0013757159705251709, "dist_entropy": 1.6072716236114502, "actor_grad_norm": 0.08699732273817062, "critic_grad_norm": 0.43425971269607544, "ratio": 1.0000416040420532, "entropy": 1.6072716236114502, "incre_win_rate": 0.0, "step": 13}
{"time": 1767151137.3646352, "phase": "train", "update": 14, "total_env_steps": 44800, "episode_reward": 0.10280370712280273, "value_loss": 0.05196546688675881, "policy_loss": -0.0009036308808262561, "dist_entropy": 1.5433312892913817, "actor_grad_norm": 0.055007558315992355, "critic_grad_norm": 0.21313047409057617, "ratio": 0.9999918341636658, "entropy": 1.5433312892913817, "incre_win_rate": 0.0, "step": 14}
{"time": 1767151142.3049252, "phase": "train", "update": 15, "total_env_steps": 48000, "episode_reward": 0.10674203187227249, "value_loss": 0.04776922836899757, "policy_loss": -0.0010485617061059215, "dist_entropy": 1.5172510385513305, "actor_grad_norm": 0.06915336847305298, "critic_grad_norm": 0.2840842604637146, "ratio": 0.9998658299446106, "entropy": 1.5172510385513305, "incre_win_rate": 0.0, "step": 15}
{"time": 1767151146.7169118, "phase": "train", "update": 16, "total_env_steps": 51200, "episode_reward": 0.1052674874663353, "value_loss": 0.046430887281894685, "policy_loss": -0.0015076265255286269, "dist_entropy": 1.4680266380310059, "actor_grad_norm": 0.08421581983566284, "critic_grad_norm": 0.21841967105865479, "ratio": 1.0001869201660156, "entropy": 1.4680266380310059, "incre_win_rate": 0.0, "step": 16}
{"time": 1767151151.0911884, "phase": "train", "update": 17, "total_env_steps": 54400, "episode_reward": 0.10968802124261856, "value_loss": 0.041416753083467484, "policy_loss": -0.0010381359590084572, "dist_entropy": 1.4356727600097656, "actor_grad_norm": 0.06484387814998627, "critic_grad_norm": 0.13641326129436493, "ratio": 0.9999058842658997, "entropy": 1.4356727600097656, "incre_win_rate": 0.0, "step": 17}
{"time": 1767151155.5210712, "phase": "train", "update": 18, "total_env_steps": 57600, "episode_reward": 0.11338938772678375, "value_loss": 0.03773957416415215, "policy_loss": -0.0007731851742763141, "dist_entropy": 1.4097164154052735, "actor_grad_norm": 0.053679466247558594, "critic_grad_norm": 0.12757991254329681, "ratio": 1.000158429145813, "entropy": 1.4097164154052735, "incre_win_rate": 0.0, "step": 18}
{"time": 1767151159.892755, "phase": "train", "update": 19, "total_env_steps": 60800, "episode_reward": 0.10926686972379684, "value_loss": 0.037041591852903365, "policy_loss": -0.0006976391464680986, "dist_entropy": 1.3677706956863402, "actor_grad_norm": 0.05004580691456795, "critic_grad_norm": 0.13159498572349548, "ratio": 1.0001481771469116, "entropy": 1.3677706956863402, "incre_win_rate": 0.0, "step": 19}
{"time": 1767151164.3616116, "phase": "train", "update": 20, "total_env_steps": 64000, "episode_reward": 0.11381415277719498, "value_loss": 0.0342722661793232, "policy_loss": -0.000678047654847802, "dist_entropy": 1.3625514030456543, "actor_grad_norm": 0.06389805674552917, "critic_grad_norm": 0.11826183646917343, "ratio": 1.0000923871994019, "entropy": 1.3625514030456543, "incre_win_rate": 0.0, "step": 20}
{"time": 1767151168.7665164, "phase": "train", "update": 21, "total_env_steps": 67200, "episode_reward": 0.10554066300392151, "value_loss": 0.03911736905574799, "policy_loss": -0.0007767952781248866, "dist_entropy": 1.3386955261230469, "actor_grad_norm": 0.0626143217086792, "critic_grad_norm": 0.12638087570667267, "ratio": 0.9997072219848633, "entropy": 1.3386955261230469, "incre_win_rate": 0.0, "step": 21}
{"time": 1767151180.132961, "phase": "eval", "update": 21, "total_env_steps": 67200, "eval_win_rate": 0.0, "eval_episode_reward": 6.466732201986755, "step": 21}
{"time": 1767151184.7536721, "phase": "train", "update": 22, "total_env_steps": 70400, "episode_reward": 0.10288286209106445, "value_loss": 0.033384916931390764, "policy_loss": -0.0006128859250191354, "dist_entropy": 1.303921389579773, "actor_grad_norm": 0.06007194519042969, "critic_grad_norm": 0.21648243069648743, "ratio": 1.0003753900527954, "entropy": 1.303921389579773, "incre_win_rate": 0.0, "step": 22}
{"time": 1767151189.315653, "phase": "train", "update": 23, "total_env_steps": 73600, "episode_reward": 0.1028963178396225, "value_loss": 0.03474186733365059, "policy_loss": -0.0005665695225018919, "dist_entropy": 1.319514799118042, "actor_grad_norm": 0.05965225771069527, "critic_grad_norm": 0.14683133363723755, "ratio": 1.0002708435058594, "entropy": 1.319514799118042, "incre_win_rate": 0.0, "step": 23}
{"time": 1767151193.6955452, "phase": "train", "update": 24, "total_env_steps": 76800, "episode_reward": 0.09903766959905624, "value_loss": 0.037526323646306994, "policy_loss": -0.0006306129895329527, "dist_entropy": 1.3204932689666748, "actor_grad_norm": 0.07400404661893845, "critic_grad_norm": 0.1470147967338562, "ratio": 1.0001294612884521, "entropy": 1.3204932689666748, "incre_win_rate": 0.0, "step": 24}
{"time": 1767151198.0491405, "phase": "train", "update": 25, "total_env_steps": 80000, "episode_reward": 0.0976712629199028, "value_loss": 0.03343080282211304, "policy_loss": -0.0008342966017346853, "dist_entropy": 1.3266717433929442, "actor_grad_norm": 0.07157240808010101, "critic_grad_norm": 0.13905422389507294, "ratio": 0.9999926686286926, "entropy": 1.3266717433929442, "incre_win_rate": 0.0, "step": 25}
{"time": 1767151202.3802104, "phase": "train", "update": 26, "total_env_steps": 83200, "episode_reward": 0.09752637892961502, "value_loss": 0.03781728297472, "policy_loss": -0.0010257847243799745, "dist_entropy": 1.3264978408813477, "actor_grad_norm": 0.07503298670053482, "critic_grad_norm": 0.20244626700878143, "ratio": 0.9999045729637146, "entropy": 1.3264978408813477, "incre_win_rate": 0.0, "step": 26}
{"time": 1767151206.6664972, "phase": "train", "update": 27, "total_env_steps": 86400, "episode_reward": 0.09839818626642227, "value_loss": 0.04886646717786789, "policy_loss": -0.0008616576212478577, "dist_entropy": 1.2633758544921876, "actor_grad_norm": 0.054739829152822495, "critic_grad_norm": 0.2185746431350708, "ratio": 1.0002580881118774, "entropy": 1.2633758544921876, "incre_win_rate": 0.0, "step": 27}
{"time": 1767151210.9564729, "phase": "train", "update": 28, "total_env_steps": 89600, "episode_reward": 0.09427514672279358, "value_loss": 0.04294445961713791, "policy_loss": -0.0012584260392664247, "dist_entropy": 1.2815921783447266, "actor_grad_norm": 0.07341885566711426, "critic_grad_norm": 0.17944175004959106, "ratio": 1.0000710487365723, "entropy": 1.2815921783447266, "incre_win_rate": 0.0, "step": 28}
{"time": 1767151215.1515899, "phase": "train", "update": 29, "total_env_steps": 92800, "episode_reward": 0.08658578991889954, "value_loss": 0.053930096328258514, "policy_loss": -0.000866942581466712, "dist_entropy": 1.23447425365448, "actor_grad_norm": 0.06678695231676102, "critic_grad_norm": 0.16899557411670685, "ratio": 0.9997696280479431, "entropy": 1.23447425365448, "incre_win_rate": 0.0, "step": 29}
{"time": 1767151219.3691273, "phase": "train", "update": 30, "total_env_steps": 96000, "episode_reward": 0.08592817932367325, "value_loss": 0.049098940938711165, "policy_loss": -0.0012675051774007073, "dist_entropy": 1.2205167055130004, "actor_grad_norm": 0.07827400416135788, "critic_grad_norm": 0.18694479763507843, "ratio": 1.0004489421844482, "entropy": 1.2205167055130004, "incre_win_rate": 0.0, "step": 30}
{"time": 1767151223.6008737, "phase": "train", "update": 31, "total_env_steps": 99200, "episode_reward": 0.08566173911094666, "value_loss": 0.04477171748876572, "policy_loss": -0.0013751054044419675, "dist_entropy": 1.2047478199005126, "actor_grad_norm": 0.0774989053606987, "critic_grad_norm": 0.13476598262786865, "ratio": 0.9997186064720154, "entropy": 1.2047478199005126, "incre_win_rate": 0.0, "step": 31}
{"time": 1767151227.8595426, "phase": "train", "update": 32, "total_env_steps": 102400, "episode_reward": 0.07941018044948578, "value_loss": 0.060020283609628675, "policy_loss": -0.0008038604010614847, "dist_entropy": 1.1514658212661744, "actor_grad_norm": 0.07234426587820053, "critic_grad_norm": 0.6373791694641113, "ratio": 0.9991636276245117, "entropy": 1.1514658212661744, "incre_win_rate": 0.0, "step": 32}
{"time": 1767151232.1219583, "phase": "train", "update": 33, "total_env_steps": 105600, "episode_reward": 0.09116462618112564, "value_loss": 0.04484381452202797, "policy_loss": -0.0005367689179456292, "dist_entropy": 1.1519989967346191, "actor_grad_norm": 0.05178028345108032, "critic_grad_norm": 0.4410151541233063, "ratio": 0.9999556541442871, "entropy": 1.1519989967346191, "incre_win_rate": 0.0, "step": 33}
{"time": 1767151236.267453, "phase": "train", "update": 34, "total_env_steps": 108800, "episode_reward": 0.08001655340194702, "value_loss": 0.041739927232265474, "policy_loss": -0.0011026296757423281, "dist_entropy": 1.1647799015045166, "actor_grad_norm": 0.09443304687738419, "critic_grad_norm": 0.4279206693172455, "ratio": 0.999515175819397, "entropy": 1.1647799015045166, "incre_win_rate": 0.0, "step": 34}
{"time": 1767151240.5566986, "phase": "train", "update": 35, "total_env_steps": 112000, "episode_reward": 0.09780731797218323, "value_loss": 0.04604095369577408, "policy_loss": -0.0009238047924328363, "dist_entropy": 1.1979162454605103, "actor_grad_norm": 0.06272225081920624, "critic_grad_norm": 0.4673439562320709, "ratio": 1.000386118888855, "entropy": 1.1979162454605103, "incre_win_rate": 0.0, "step": 35}
{"time": 1767151244.7061431, "phase": "train", "update": 36, "total_env_steps": 115200, "episode_reward": 0.0880235880613327, "value_loss": 0.037124267965555194, "policy_loss": -0.0008166412948360068, "dist_entropy": 1.168313193321228, "actor_grad_norm": 0.07557488977909088, "critic_grad_norm": 0.3640580177307129, "ratio": 1.0000652074813843, "entropy": 1.168313193321228, "incre_win_rate": 0.0, "step": 36}
{"time": 1767151248.9923902, "phase": "train", "update": 37, "total_env_steps": 118400, "episode_reward": 0.10401231795549393, "value_loss": 0.04827206954360008, "policy_loss": -0.000672802806366235, "dist_entropy": 1.251660418510437, "actor_grad_norm": 0.05418899655342102, "critic_grad_norm": 0.4109981656074524, "ratio": 1.0002597570419312, "entropy": 1.251660418510437, "incre_win_rate": 0.0, "step": 37}
{"time": 1767151253.254521, "phase": "train", "update": 38, "total_env_steps": 121600, "episode_reward": 0.10227441787719727, "value_loss": 0.03358082920312881, "policy_loss": -0.0007102873108634888, "dist_entropy": 1.272520112991333, "actor_grad_norm": 0.0641089454293251, "critic_grad_norm": 0.23709379136562347, "ratio": 0.9998598098754883, "entropy": 1.272520112991333, "incre_win_rate": 0.0, "step": 38}
{"time": 1767151257.5884166, "phase": "train", "update": 39, "total_env_steps": 124800, "episode_reward": 0.10774317383766174, "value_loss": 0.04208173528313637, "policy_loss": -0.0009846208720961868, "dist_entropy": 1.263861107826233, "actor_grad_norm": 0.06711336225271225, "critic_grad_norm": 0.25179868936538696, "ratio": 0.9999182820320129, "entropy": 1.263861107826233, "incre_win_rate": 0.0, "step": 39}
{"time": 1767151261.9119816, "phase": "train", "update": 40, "total_env_steps": 128000, "episode_reward": 0.10152783989906311, "value_loss": 0.03579926714301109, "policy_loss": -0.0009036147770565605, "dist_entropy": 1.236143159866333, "actor_grad_norm": 0.06501028686761856, "critic_grad_norm": 0.22263813018798828, "ratio": 1.0000728368759155, "entropy": 1.236143159866333, "incre_win_rate": 0.0, "step": 40}
{"time": 1767151266.2110615, "phase": "train", "update": 41, "total_env_steps": 131200, "episode_reward": 0.10567259788513184, "value_loss": 0.030889210850000383, "policy_loss": -0.0008922023627795817, "dist_entropy": 1.233616328239441, "actor_grad_norm": 0.056762583553791046, "critic_grad_norm": 0.22011993825435638, "ratio": 0.9999972581863403, "entropy": 1.233616328239441, "incre_win_rate": 0.0, "step": 41}
{"time": 1767151278.6925442, "phase": "eval", "update": 41, "total_env_steps": 131200, "eval_win_rate": 0.0, "eval_episode_reward": 6.993274006622517, "step": 41}
{"time": 1767151282.9214501, "phase": "train", "update": 42, "total_env_steps": 134400, "episode_reward": 0.10721751302480698, "value_loss": 0.04570530876517296, "policy_loss": -0.0004556323378882565, "dist_entropy": 1.2166068077087402, "actor_grad_norm": 0.04509474337100983, "critic_grad_norm": 0.21948964893817902, "ratio": 0.9999845623970032, "entropy": 1.2166068077087402, "incre_win_rate": 0.0, "step": 42}
{"time": 1767151287.2377439, "phase": "train", "update": 43, "total_env_steps": 137600, "episode_reward": 0.11730805039405823, "value_loss": 0.036581090092658995, "policy_loss": -0.0007525938038476454, "dist_entropy": 1.286577534675598, "actor_grad_norm": 0.06724142283201218, "critic_grad_norm": 0.37936481833457947, "ratio": 0.999691903591156, "entropy": 1.286577534675598, "incre_win_rate": 0.0, "step": 43}
{"time": 1767151291.556001, "phase": "train", "update": 44, "total_env_steps": 140800, "episode_reward": 0.11688017845153809, "value_loss": 0.031396083533763885, "policy_loss": -0.0007241657753397135, "dist_entropy": 1.3089923143386841, "actor_grad_norm": 0.06039575859904289, "critic_grad_norm": 0.21874785423278809, "ratio": 0.9998981356620789, "entropy": 1.3089923143386841, "incre_win_rate": 0.0, "step": 44}
{"time": 1767151295.8702302, "phase": "train", "update": 45, "total_env_steps": 144000, "episode_reward": 0.11373291909694672, "value_loss": 0.02848929837346077, "policy_loss": -0.0011691165098454803, "dist_entropy": 1.2814876794815064, "actor_grad_norm": 0.05761134624481201, "critic_grad_norm": 0.3161593973636627, "ratio": 1.0002985000610352, "entropy": 1.2814876794815064, "incre_win_rate": 0.0, "step": 45}
{"time": 1767151300.1849163, "phase": "train", "update": 46, "total_env_steps": 147200, "episode_reward": 0.11257655918598175, "value_loss": 0.028431969135999678, "policy_loss": -0.000961665169543302, "dist_entropy": 1.228875756263733, "actor_grad_norm": 0.062331218272447586, "critic_grad_norm": 0.17538313567638397, "ratio": 1.0002297163009644, "entropy": 1.228875756263733, "incre_win_rate": 0.0, "step": 46}
{"time": 1767151304.4359083, "phase": "train", "update": 47, "total_env_steps": 150400, "episode_reward": 0.1171341985464096, "value_loss": 0.031317005306482314, "policy_loss": -0.0012927695341439006, "dist_entropy": 1.2341013431549073, "actor_grad_norm": 0.09349235147237778, "critic_grad_norm": 0.3446933925151825, "ratio": 0.9997780919075012, "entropy": 1.2341013431549073, "incre_win_rate": 0.0, "step": 47}
{"time": 1767151308.7610247, "phase": "train", "update": 48, "total_env_steps": 153600, "episode_reward": 0.11174514144659042, "value_loss": 0.028581155464053154, "policy_loss": -0.0004503519393798783, "dist_entropy": 1.2008151769638062, "actor_grad_norm": 0.06855885684490204, "critic_grad_norm": 0.16921983659267426, "ratio": 1.0001325607299805, "entropy": 1.2008151769638062, "incre_win_rate": 0.0, "step": 48}
{"time": 1767151313.0718253, "phase": "train", "update": 49, "total_env_steps": 156800, "episode_reward": 0.1117539331316948, "value_loss": 0.03227490708231926, "policy_loss": -0.0011334739570733276, "dist_entropy": 1.2164291858673095, "actor_grad_norm": 0.09171082824468613, "critic_grad_norm": 0.18703889846801758, "ratio": 0.9998685121536255, "entropy": 1.2164291858673095, "incre_win_rate": 0.0, "step": 49}
{"time": 1767151317.3790615, "phase": "train", "update": 50, "total_env_steps": 160000, "episode_reward": 0.09951366484165192, "value_loss": 0.044639676064252856, "policy_loss": -0.0008282645164856106, "dist_entropy": 1.1295926332473756, "actor_grad_norm": 0.06950408965349197, "critic_grad_norm": 0.6183380484580994, "ratio": 0.9999076128005981, "entropy": 1.1295926332473756, "incre_win_rate": 0.0, "step": 50}
{"time": 1767151321.7265248, "phase": "train", "update": 51, "total_env_steps": 163200, "episode_reward": 0.10729977488517761, "value_loss": 0.03902808129787445, "policy_loss": -0.0010491451829935273, "dist_entropy": 1.1858436346054078, "actor_grad_norm": 0.06999289989471436, "critic_grad_norm": 0.33961156010627747, "ratio": 0.9999712109565735, "entropy": 1.1858436346054078, "incre_win_rate": 0.0, "step": 51}
{"time": 1767151325.9914634, "phase": "train", "update": 52, "total_env_steps": 166400, "episode_reward": 0.11164890229701996, "value_loss": 0.03815754279494286, "policy_loss": -0.0005221132389834793, "dist_entropy": 1.188839602470398, "actor_grad_norm": 0.041578952223062515, "critic_grad_norm": 0.30424413084983826, "ratio": 1.0001078844070435, "entropy": 1.188839602470398, "incre_win_rate": 0.0, "step": 52}
{"time": 1767151330.30965, "phase": "train", "update": 53, "total_env_steps": 169600, "episode_reward": 0.12020747363567352, "value_loss": 0.04376214444637298, "policy_loss": -0.0010463071705903103, "dist_entropy": 1.1879661321640014, "actor_grad_norm": 0.05324811860918999, "critic_grad_norm": 0.5587100982666016, "ratio": 1.000105381011963, "entropy": 1.1879661321640014, "incre_win_rate": 0.0, "step": 53}
{"time": 1767151334.5532632, "phase": "train", "update": 54, "total_env_steps": 172800, "episode_reward": 0.11659353971481323, "value_loss": 0.03341934606432915, "policy_loss": -0.0008239720664646955, "dist_entropy": 1.198617696762085, "actor_grad_norm": 0.08100943267345428, "critic_grad_norm": 0.3270142376422882, "ratio": 0.9997941255569458, "entropy": 1.198617696762085, "incre_win_rate": 0.0, "step": 54}
{"time": 1767151338.8363433, "phase": "train", "update": 55, "total_env_steps": 176000, "episode_reward": 0.11820105463266373, "value_loss": 0.032657429575920105, "policy_loss": -0.0005197514377979218, "dist_entropy": 1.183038067817688, "actor_grad_norm": 0.059878911823034286, "critic_grad_norm": 0.2825861871242523, "ratio": 1.0000642538070679, "entropy": 1.183038067817688, "incre_win_rate": 0.0, "step": 55}
{"time": 1767151343.6133118, "phase": "train", "update": 56, "total_env_steps": 179200, "episode_reward": 0.11532232910394669, "value_loss": 0.03590693473815918, "policy_loss": -0.0003786515269894153, "dist_entropy": 1.1494623661041259, "actor_grad_norm": 0.06294857710599899, "critic_grad_norm": 0.22457222640514374, "ratio": 0.9999604225158691, "entropy": 1.1494623661041259, "incre_win_rate": 0.0, "step": 56}
{"time": 1767151348.185673, "phase": "train", "update": 57, "total_env_steps": 182400, "episode_reward": 0.10785699635744095, "value_loss": 0.03612748309969902, "policy_loss": -0.0008111979298304206, "dist_entropy": 1.1034990549087524, "actor_grad_norm": 0.07710622251033783, "critic_grad_norm": 0.1976611465215683, "ratio": 0.9998186230659485, "entropy": 1.1034990549087524, "incre_win_rate": 0.0, "step": 57}
{"time": 1767151352.508975, "phase": "train", "update": 58, "total_env_steps": 185600, "episode_reward": 0.11664476990699768, "value_loss": 0.029387849569320678, "policy_loss": -0.0005509427543204382, "dist_entropy": 1.1784945487976075, "actor_grad_norm": 0.07218088954687119, "critic_grad_norm": 0.23613111674785614, "ratio": 0.9999238848686218, "entropy": 1.1784945487976075, "incre_win_rate": 0.0, "step": 58}
{"time": 1767151356.7858605, "phase": "train", "update": 59, "total_env_steps": 188800, "episode_reward": 0.11843337118625641, "value_loss": 0.022669148445129395, "policy_loss": -0.0009083190502789052, "dist_entropy": 1.2040613412857055, "actor_grad_norm": 0.08496686071157455, "critic_grad_norm": 0.25468918681144714, "ratio": 0.9997988939285278, "entropy": 1.2040613412857055, "incre_win_rate": 0.0, "step": 59}
{"time": 1767151361.1202805, "phase": "train", "update": 60, "total_env_steps": 192000, "episode_reward": 0.11960679292678833, "value_loss": 0.029513294994831085, "policy_loss": -0.0003947107501157454, "dist_entropy": 1.1755941390991211, "actor_grad_norm": 0.07097455114126205, "critic_grad_norm": 0.17173753678798676, "ratio": 0.9997960329055786, "entropy": 1.1755941390991211, "incre_win_rate": 0.0, "step": 60}
{"time": 1767151365.4630926, "phase": "train", "update": 61, "total_env_steps": 195200, "episode_reward": 0.11865584552288055, "value_loss": 0.024852203205227852, "policy_loss": -0.00039760895709815, "dist_entropy": 1.1839007616043091, "actor_grad_norm": 0.08174750953912735, "critic_grad_norm": 0.16958771646022797, "ratio": 0.9997405409812927, "entropy": 1.1839007616043091, "incre_win_rate": 0.0, "step": 61}
{"time": 1767151376.497066, "phase": "eval", "update": 61, "total_env_steps": 195200, "eval_win_rate": 0.0, "eval_episode_reward": 9.4609375, "step": 61}
{"time": 1767151380.817509, "phase": "train", "update": 62, "total_env_steps": 198400, "episode_reward": 0.11798220872879028, "value_loss": 0.02836402989923954, "policy_loss": -0.0008378751182750221, "dist_entropy": 1.178580904006958, "actor_grad_norm": 0.11356072872877121, "critic_grad_norm": 0.1342058926820755, "ratio": 1.000324010848999, "entropy": 1.178580904006958, "incre_win_rate": 0.0, "step": 62}
{"time": 1767151385.0769727, "phase": "train", "update": 63, "total_env_steps": 201600, "episode_reward": 0.12129811942577362, "value_loss": 0.0208144411444664, "policy_loss": -0.0002072757411724524, "dist_entropy": 1.1904760360717774, "actor_grad_norm": 0.06854001432657242, "critic_grad_norm": 0.12962374091148376, "ratio": 1.000110149383545, "entropy": 1.1904760360717774, "incre_win_rate": 0.0, "step": 63}
{"time": 1767151389.3639326, "phase": "train", "update": 64, "total_env_steps": 204800, "episode_reward": 0.11856426298618317, "value_loss": 0.024381598085165025, "policy_loss": -0.0009367737269975862, "dist_entropy": 1.1423661231994628, "actor_grad_norm": 0.07040832936763763, "critic_grad_norm": 0.20805875957012177, "ratio": 0.999821662902832, "entropy": 1.1423661231994628, "incre_win_rate": 0.0, "step": 64}
{"time": 1767151393.7182798, "phase": "train", "update": 65, "total_env_steps": 208000, "episode_reward": 0.12388866394758224, "value_loss": 0.02330794297158718, "policy_loss": -0.0007561931660804433, "dist_entropy": 1.1863078355789185, "actor_grad_norm": 0.07568805664777756, "critic_grad_norm": 0.20271559059619904, "ratio": 0.9999518394470215, "entropy": 1.1863078355789185, "incre_win_rate": 0.0, "step": 65}
{"time": 1767151398.042002, "phase": "train", "update": 66, "total_env_steps": 211200, "episode_reward": 0.1166251003742218, "value_loss": 0.02615172378718853, "policy_loss": -0.0003011645418910192, "dist_entropy": 1.182072353363037, "actor_grad_norm": 0.07684013992547989, "critic_grad_norm": 0.16367855668067932, "ratio": 1.0003570318222046, "entropy": 1.182072353363037, "incre_win_rate": 0.0, "step": 66}
{"time": 1767151402.3678498, "phase": "train", "update": 67, "total_env_steps": 214400, "episode_reward": 0.11667683720588684, "value_loss": 0.01889953389763832, "policy_loss": -0.0005349866795993918, "dist_entropy": 1.1724048614501954, "actor_grad_norm": 0.08068384230136871, "critic_grad_norm": 0.12760604918003082, "ratio": 0.9998399019241333, "entropy": 1.1724048614501954, "incre_win_rate": 0.0, "step": 67}
{"time": 1767151406.6228192, "phase": "train", "update": 68, "total_env_steps": 217600, "episode_reward": 0.11567001044750214, "value_loss": 0.020666443184018134, "policy_loss": -0.0002839970552182436, "dist_entropy": 1.1830889701843261, "actor_grad_norm": 0.06621969491243362, "critic_grad_norm": 0.07138273864984512, "ratio": 0.9998264312744141, "entropy": 1.1830889701843261, "incre_win_rate": 0.0, "step": 68}
{"time": 1767151410.8524861, "phase": "train", "update": 69, "total_env_steps": 220800, "episode_reward": 0.11116566509008408, "value_loss": 0.022535133361816406, "policy_loss": -0.0005233744052272726, "dist_entropy": 1.1654529809951781, "actor_grad_norm": 0.08181490004062653, "critic_grad_norm": 0.0893031507730484, "ratio": 1.0001280307769775, "entropy": 1.1654529809951781, "incre_win_rate": 0.0, "step": 69}
{"time": 1767151415.1087406, "phase": "train", "update": 70, "total_env_steps": 224000, "episode_reward": 0.11554118990898132, "value_loss": 0.02244275137782097, "policy_loss": -0.00024899113317236046, "dist_entropy": 1.1473869323730468, "actor_grad_norm": 0.07142039388418198, "critic_grad_norm": 0.18801657855510712, "ratio": 1.0001047849655151, "entropy": 1.1473869323730468, "incre_win_rate": 0.0, "step": 70}
{"time": 1767151419.5141883, "phase": "train", "update": 71, "total_env_steps": 227200, "episode_reward": 0.12054532021284103, "value_loss": 0.02407136745750904, "policy_loss": -0.0011099186361082757, "dist_entropy": 1.1586599826812745, "actor_grad_norm": 0.0764903798699379, "critic_grad_norm": 0.10709784179925919, "ratio": 1.0000715255737305, "entropy": 1.1586599826812745, "incre_win_rate": 0.0, "step": 71}
{"time": 1767151424.0194778, "phase": "train", "update": 72, "total_env_steps": 230400, "episode_reward": 0.11525403708219528, "value_loss": 0.027505017817020416, "policy_loss": -0.00047836098444546947, "dist_entropy": 1.163895606994629, "actor_grad_norm": 0.09436804056167603, "critic_grad_norm": 0.21660538017749786, "ratio": 1.0000923871994019, "entropy": 1.163895606994629, "incre_win_rate": 0.0, "step": 72}
{"time": 1767151428.2859797, "phase": "train", "update": 73, "total_env_steps": 233600, "episode_reward": 0.11651283502578735, "value_loss": 0.02030893713235855, "policy_loss": -0.00019930306945106224, "dist_entropy": 1.1614676237106323, "actor_grad_norm": 0.05853345990180969, "critic_grad_norm": 0.20732812583446503, "ratio": 0.9999839067459106, "entropy": 1.1614676237106323, "incre_win_rate": 0.0, "step": 73}
{"time": 1767151432.5725062, "phase": "train", "update": 74, "total_env_steps": 236800, "episode_reward": 0.12366462498903275, "value_loss": 0.021561403572559357, "policy_loss": -0.0006742185338213247, "dist_entropy": 1.200955295562744, "actor_grad_norm": 0.07976212352514267, "critic_grad_norm": 0.29535824060440063, "ratio": 0.9996466040611267, "entropy": 1.200955295562744, "incre_win_rate": 0.0, "step": 74}
{"time": 1767151436.8723066, "phase": "train", "update": 75, "total_env_steps": 240000, "episode_reward": 0.12345147132873535, "value_loss": 0.02096012905240059, "policy_loss": -0.0008221871765641709, "dist_entropy": 1.1762489318847655, "actor_grad_norm": 0.06824411451816559, "critic_grad_norm": 0.34918567538261414, "ratio": 1.000082015991211, "entropy": 1.1762489318847655, "incre_win_rate": 0.0, "step": 75}
{"time": 1767151441.2629974, "phase": "train", "update": 76, "total_env_steps": 243200, "episode_reward": 0.1291080117225647, "value_loss": 0.023928027600049973, "policy_loss": -0.0006961060731285329, "dist_entropy": 1.2118541717529296, "actor_grad_norm": 0.06040669232606888, "critic_grad_norm": 0.21074996888637543, "ratio": 1.0002905130386353, "entropy": 1.2118541717529296, "incre_win_rate": 0.0, "step": 76}
{"time": 1767151445.6241524, "phase": "train", "update": 77, "total_env_steps": 246400, "episode_reward": 0.12803393602371216, "value_loss": 0.02856057807803154, "policy_loss": -0.000747502695691793, "dist_entropy": 1.169357919692993, "actor_grad_norm": 0.07729821652173996, "critic_grad_norm": 0.40968185663223267, "ratio": 0.9995050430297852, "entropy": 1.169357919692993, "incre_win_rate": 0.023255813953488372, "step": 77}
{"time": 1767151449.9723833, "phase": "train", "update": 78, "total_env_steps": 249600, "episode_reward": 0.12403301149606705, "value_loss": 0.025289104506373405, "policy_loss": -0.0005853706525535074, "dist_entropy": 1.179502582550049, "actor_grad_norm": 0.07259800285100937, "critic_grad_norm": 0.20431604981422424, "ratio": 0.9998193979263306, "entropy": 1.179502582550049, "incre_win_rate": 0.0, "step": 78}
{"time": 1767151454.2697704, "phase": "train", "update": 79, "total_env_steps": 252800, "episode_reward": 0.12202399969100952, "value_loss": 0.02126748487353325, "policy_loss": -0.0007996891752725333, "dist_entropy": 1.162958288192749, "actor_grad_norm": 0.07434025406837463, "critic_grad_norm": 0.21184766292572021, "ratio": 0.9999899864196777, "entropy": 1.162958288192749, "incre_win_rate": 0.0, "step": 79}
{"time": 1767151458.5406015, "phase": "train", "update": 80, "total_env_steps": 256000, "episode_reward": 0.11932533979415894, "value_loss": 0.02777416557073593, "policy_loss": -0.0007567376136766058, "dist_entropy": 1.1355869770050049, "actor_grad_norm": 0.06617762893438339, "critic_grad_norm": 0.22109441459178925, "ratio": 1.0000391006469727, "entropy": 1.1355869770050049, "incre_win_rate": 0.0, "step": 80}
{"time": 1767151462.9080114, "phase": "train", "update": 81, "total_env_steps": 259200, "episode_reward": 0.1275305300951004, "value_loss": 0.022667043283581732, "policy_loss": -0.0008747532112353795, "dist_entropy": 1.141874074935913, "actor_grad_norm": 0.05650220438838005, "critic_grad_norm": 0.14543047547340393, "ratio": 1.0000520944595337, "entropy": 1.141874074935913, "incre_win_rate": 0.0, "step": 81}
{"time": 1767151474.8965943, "phase": "eval", "update": 81, "total_env_steps": 259200, "eval_win_rate": 0.0, "eval_episode_reward": 9.332626241721853, "step": 81}
{"time": 1767151479.1906822, "phase": "train", "update": 82, "total_env_steps": 262400, "episode_reward": 0.12237945199012756, "value_loss": 0.025927216932177543, "policy_loss": -0.0008399287635391772, "dist_entropy": 1.1317662715911865, "actor_grad_norm": 0.06229923292994499, "critic_grad_norm": 0.3859542906284332, "ratio": 1.0002853870391846, "entropy": 1.1317662715911865, "incre_win_rate": 0.0, "step": 82}
{"time": 1767151483.5433526, "phase": "train", "update": 83, "total_env_steps": 265600, "episode_reward": 0.1217171922326088, "value_loss": 0.022266461700201034, "policy_loss": -0.0004171898872989743, "dist_entropy": 1.1015695810317994, "actor_grad_norm": 0.05580797418951988, "critic_grad_norm": 0.27643850445747375, "ratio": 0.9999472498893738, "entropy": 1.1015695810317994, "incre_win_rate": 0.0, "step": 83}
{"time": 1767151487.8297362, "phase": "train", "update": 84, "total_env_steps": 268800, "episode_reward": 0.12274109572172165, "value_loss": 0.026782288774847986, "policy_loss": -0.0004764592236556897, "dist_entropy": 1.076814889907837, "actor_grad_norm": 0.057389289140701294, "critic_grad_norm": 0.27461493015289307, "ratio": 1.0000097751617432, "entropy": 1.076814889907837, "incre_win_rate": 0.0, "step": 84}
{"time": 1767151492.1619384, "phase": "train", "update": 85, "total_env_steps": 272000, "episode_reward": 0.1215723305940628, "value_loss": 0.024252599850296975, "policy_loss": -0.0006396043225374015, "dist_entropy": 1.1128031492233277, "actor_grad_norm": 0.0703968033194542, "critic_grad_norm": 0.1858857125043869, "ratio": 1.000043272972107, "entropy": 1.1128031492233277, "incre_win_rate": 0.0, "step": 85}
{"time": 1767151496.4365575, "phase": "train", "update": 86, "total_env_steps": 275200, "episode_reward": 0.12691639363765717, "value_loss": 0.027324560284614562, "policy_loss": -0.0010148046573654312, "dist_entropy": 1.1190695762634277, "actor_grad_norm": 0.08237776905298233, "critic_grad_norm": 0.2503821551799774, "ratio": 0.999920666217804, "entropy": 1.1190695762634277, "incre_win_rate": 0.0, "step": 86}
{"time": 1767151500.728749, "phase": "train", "update": 87, "total_env_steps": 278400, "episode_reward": 0.12254812568426132, "value_loss": 0.020186923444271088, "policy_loss": -0.0006654701851406486, "dist_entropy": 1.1241389036178588, "actor_grad_norm": 0.08152136206626892, "critic_grad_norm": 0.19275926053524017, "ratio": 0.9999489188194275, "entropy": 1.1241389036178588, "incre_win_rate": 0.0, "step": 87}
{"time": 1767151504.996639, "phase": "train", "update": 88, "total_env_steps": 281600, "episode_reward": 0.12309913337230682, "value_loss": 0.024116800352931022, "policy_loss": -0.0003045841127338633, "dist_entropy": 1.118595027923584, "actor_grad_norm": 0.10669141262769699, "critic_grad_norm": 0.19813835620880127, "ratio": 1.0001041889190674, "entropy": 1.118595027923584, "incre_win_rate": 0.0, "step": 88}
{"time": 1767151509.3153098, "phase": "train", "update": 89, "total_env_steps": 284800, "episode_reward": 0.12736186385154724, "value_loss": 0.026926979050040246, "policy_loss": -0.0006266051539306261, "dist_entropy": 1.1371648788452149, "actor_grad_norm": 0.07594340294599533, "critic_grad_norm": 0.20314458012580872, "ratio": 1.0000149011611938, "entropy": 1.1371648788452149, "incre_win_rate": 0.0, "step": 89}
{"time": 1767151513.6206298, "phase": "train", "update": 90, "total_env_steps": 288000, "episode_reward": 0.1232181265950203, "value_loss": 0.025888862460851668, "policy_loss": -0.0007656079531841442, "dist_entropy": 1.0880340576171874, "actor_grad_norm": 0.06323441118001938, "critic_grad_norm": 0.21822018921375275, "ratio": 1.000129222869873, "entropy": 1.0880340576171874, "incre_win_rate": 0.0, "step": 90}
{"time": 1767151517.9478023, "phase": "train", "update": 91, "total_env_steps": 291200, "episode_reward": 0.1272035390138626, "value_loss": 0.025474709644913673, "policy_loss": -0.0007466016919046581, "dist_entropy": 1.1326340436935425, "actor_grad_norm": 0.05728648975491524, "critic_grad_norm": 0.1913232058286667, "ratio": 0.9999787211418152, "entropy": 1.1326340436935425, "incre_win_rate": 0.024390243902439025, "step": 91}
{"time": 1767151522.4249501, "phase": "train", "update": 92, "total_env_steps": 294400, "episode_reward": 0.13323622941970825, "value_loss": 0.024104518070816993, "policy_loss": -0.0007876006291006376, "dist_entropy": 1.15082585811615, "actor_grad_norm": 0.11489230394363403, "critic_grad_norm": 0.11540110409259796, "ratio": 1.0003010034561157, "entropy": 1.15082585811615, "incre_win_rate": 0.0, "step": 92}
{"time": 1767151526.726893, "phase": "train", "update": 93, "total_env_steps": 297600, "episode_reward": 0.12846232950687408, "value_loss": 0.023755504563450814, "policy_loss": -0.000652411621720006, "dist_entropy": 1.135414433479309, "actor_grad_norm": 0.07888292521238327, "critic_grad_norm": 0.11680199205875397, "ratio": 0.9998114705085754, "entropy": 1.135414433479309, "incre_win_rate": 0.0, "step": 93}
{"time": 1767151531.0515275, "phase": "train", "update": 94, "total_env_steps": 300800, "episode_reward": 0.13026541471481323, "value_loss": 0.02627672292292118, "policy_loss": -0.000349116171858288, "dist_entropy": 1.1420274257659913, "actor_grad_norm": 0.0743599534034729, "critic_grad_norm": 0.12497323751449585, "ratio": 1.000281572341919, "entropy": 1.1420274257659913, "incre_win_rate": 0.02564102564102564, "step": 94}
{"time": 1767151535.5122075, "phase": "train", "update": 95, "total_env_steps": 304000, "episode_reward": 0.1273934245109558, "value_loss": 0.026127249002456665, "policy_loss": -0.0006693008783440035, "dist_entropy": 1.1196486473083496, "actor_grad_norm": 0.07048431038856506, "critic_grad_norm": 0.19878220558166504, "ratio": 0.9999750256538391, "entropy": 1.1196486473083496, "incre_win_rate": 0.0, "step": 95}
{"time": 1767151539.850478, "phase": "train", "update": 96, "total_env_steps": 307200, "episode_reward": 0.12311983108520508, "value_loss": 0.029750253632664682, "policy_loss": -0.000493533475143515, "dist_entropy": 1.094677710533142, "actor_grad_norm": 0.06297396123409271, "critic_grad_norm": 0.2000335305929184, "ratio": 0.99969083070755, "entropy": 1.094677710533142, "incre_win_rate": 0.0, "step": 96}
{"time": 1767151544.201307, "phase": "train", "update": 97, "total_env_steps": 310400, "episode_reward": 0.13284458220005035, "value_loss": 0.029429635405540465, "policy_loss": -0.0008317112435776153, "dist_entropy": 1.1460365295410155, "actor_grad_norm": 0.061054911464452744, "critic_grad_norm": 0.21449902653694153, "ratio": 0.999871551990509, "entropy": 1.1460365295410155, "incre_win_rate": 0.02631578947368421, "step": 97}
{"time": 1767151548.5592995, "phase": "train", "update": 98, "total_env_steps": 313600, "episode_reward": 0.12212283164262772, "value_loss": 0.03930306434631348, "policy_loss": -0.001102730788802697, "dist_entropy": 1.117811131477356, "actor_grad_norm": 0.09535147994756699, "critic_grad_norm": 0.320835679769516, "ratio": 0.9998435378074646, "entropy": 1.117811131477356, "incre_win_rate": 0.025, "step": 98}
{"time": 1767151552.9303756, "phase": "train", "update": 99, "total_env_steps": 316800, "episode_reward": 0.13134260475635529, "value_loss": 0.030347334593534468, "policy_loss": -0.0010392086904886355, "dist_entropy": 1.1446485996246338, "actor_grad_norm": 0.07919729501008987, "critic_grad_norm": 0.41948530077934265, "ratio": 0.9999601244926453, "entropy": 1.1446485996246338, "incre_win_rate": 0.024390243902439025, "step": 99}
{"time": 1767151557.2341235, "phase": "train", "update": 100, "total_env_steps": 320000, "episode_reward": 0.12729564309120178, "value_loss": 0.02750173918902874, "policy_loss": -0.0007690258203658651, "dist_entropy": 1.1727849006652833, "actor_grad_norm": 0.1071479320526123, "critic_grad_norm": 0.356221079826355, "ratio": 1.000051498413086, "entropy": 1.1727849006652833, "incre_win_rate": 0.0, "step": 100}
{"time": 1767151561.588903, "phase": "train", "update": 101, "total_env_steps": 323200, "episode_reward": 0.13373500108718872, "value_loss": 0.022732889652252196, "policy_loss": -0.0008724155768373265, "dist_entropy": 1.1316488981246948, "actor_grad_norm": 0.08513753116130829, "critic_grad_norm": 0.39202627539634705, "ratio": 1.0004104375839233, "entropy": 1.1316488981246948, "incre_win_rate": 0.0, "step": 101}
{"time": 1767151572.8746479, "phase": "eval", "update": 101, "total_env_steps": 323200, "eval_win_rate": 0.0, "eval_episode_reward": 9.15335264900662, "step": 101}
{"time": 1767151577.1299453, "phase": "train", "update": 102, "total_env_steps": 326400, "episode_reward": 0.1313648670911789, "value_loss": 0.024390583112835883, "policy_loss": -0.00047408108162017015, "dist_entropy": 1.1201159000396728, "actor_grad_norm": 0.06604715436697006, "critic_grad_norm": 0.17480877041816711, "ratio": 0.9997417330741882, "entropy": 1.1201159000396728, "incre_win_rate": 0.0, "step": 102}
{"time": 1767151581.3697705, "phase": "train", "update": 103, "total_env_steps": 329600, "episode_reward": 0.12868067622184753, "value_loss": 0.029730474203825, "policy_loss": -0.0008245459578558823, "dist_entropy": 1.0950500965118408, "actor_grad_norm": 0.08900200575590134, "critic_grad_norm": 0.32765889167785645, "ratio": 0.9999942779541016, "entropy": 1.0950500965118408, "incre_win_rate": 0.024390243902439025, "step": 103}
{"time": 1767151585.6169987, "phase": "train", "update": 104, "total_env_steps": 332800, "episode_reward": 0.13214921951293945, "value_loss": 0.02593897394835949, "policy_loss": -0.0008267427547085759, "dist_entropy": 1.1168240785598755, "actor_grad_norm": 0.0942363291978836, "critic_grad_norm": 0.2625875174999237, "ratio": 1.0003012418746948, "entropy": 1.1168240785598755, "incre_win_rate": 0.025, "step": 104}
{"time": 1767151589.859836, "phase": "train", "update": 105, "total_env_steps": 336000, "episode_reward": 0.1315474957227707, "value_loss": 0.02425725609064102, "policy_loss": -0.0010092088407780864, "dist_entropy": 1.118577814102173, "actor_grad_norm": 0.08186712116003036, "critic_grad_norm": 0.23949889838695526, "ratio": 1.0003005266189575, "entropy": 1.118577814102173, "incre_win_rate": 0.0, "step": 105}
{"time": 1767151594.1567538, "phase": "train", "update": 106, "total_env_steps": 339200, "episode_reward": 0.12484737485647202, "value_loss": 0.023938898369669913, "policy_loss": -0.0009091807431500954, "dist_entropy": 1.109411883354187, "actor_grad_norm": 0.11162667721509933, "critic_grad_norm": 0.4944005012512207, "ratio": 1.0001314878463745, "entropy": 1.109411883354187, "incre_win_rate": 0.0, "step": 106}
{"time": 1767151598.406087, "phase": "train", "update": 107, "total_env_steps": 342400, "episode_reward": 0.12140055745840073, "value_loss": 0.03926151394844055, "policy_loss": -0.0005001803077554712, "dist_entropy": 1.0614038228988647, "actor_grad_norm": 0.09970279783010483, "critic_grad_norm": 0.332385390996933, "ratio": 0.9998642206192017, "entropy": 1.0614038228988647, "incre_win_rate": 0.0, "step": 107}
{"time": 1767151602.7086806, "phase": "train", "update": 108, "total_env_steps": 345600, "episode_reward": 0.13508018851280212, "value_loss": 0.0266895554959774, "policy_loss": -0.0004838488069342617, "dist_entropy": 1.1235510110855103, "actor_grad_norm": 0.07698161900043488, "critic_grad_norm": 0.4701231122016907, "ratio": 0.9996716380119324, "entropy": 1.1235510110855103, "incre_win_rate": 0.02564102564102564, "step": 108}
{"time": 1767151606.9701478, "phase": "train", "update": 109, "total_env_steps": 348800, "episode_reward": 0.13219164311885834, "value_loss": 0.035400689393281934, "policy_loss": -0.001223826032953923, "dist_entropy": 1.0837551832199097, "actor_grad_norm": 0.0952451154589653, "critic_grad_norm": 0.49835458397865295, "ratio": 1.0001318454742432, "entropy": 1.0837551832199097, "incre_win_rate": 0.025, "step": 109}
{"time": 1767151611.2119315, "phase": "train", "update": 110, "total_env_steps": 352000, "episode_reward": 0.13175030052661896, "value_loss": 0.027045369893312455, "policy_loss": -0.0006094303296713122, "dist_entropy": 1.0904670000076293, "actor_grad_norm": 0.052487559616565704, "critic_grad_norm": 0.37569811940193176, "ratio": 1.0000303983688354, "entropy": 1.0904670000076293, "incre_win_rate": 0.0, "step": 110}
{"time": 1767151615.4535222, "phase": "train", "update": 111, "total_env_steps": 355200, "episode_reward": 0.1276862621307373, "value_loss": 0.024243393167853355, "policy_loss": -0.0007118490836941049, "dist_entropy": 1.0726547479629516, "actor_grad_norm": 0.09675537794828415, "critic_grad_norm": 0.35956326127052307, "ratio": 1.0000303983688354, "entropy": 1.0726547479629516, "incre_win_rate": 0.0, "step": 111}
{"time": 1767151619.6650434, "phase": "train", "update": 112, "total_env_steps": 358400, "episode_reward": 0.1286589503288269, "value_loss": 0.028025178238749504, "policy_loss": -0.0007857163902372122, "dist_entropy": 1.0308842658996582, "actor_grad_norm": 0.08139822632074356, "critic_grad_norm": 0.17587880790233612, "ratio": 1.0000890493392944, "entropy": 1.0308842658996582, "incre_win_rate": 0.0, "step": 112}
{"time": 1767151623.912106, "phase": "train", "update": 113, "total_env_steps": 361600, "episode_reward": 0.14361290633678436, "value_loss": 0.0446728840470314, "policy_loss": -0.0007762085584410272, "dist_entropy": 1.076771068572998, "actor_grad_norm": 0.05363050103187561, "critic_grad_norm": 0.5838973522186279, "ratio": 0.9999856948852539, "entropy": 1.076771068572998, "incre_win_rate": 0.07692307692307693, "step": 113}
{"time": 1767151628.1446438, "phase": "train", "update": 114, "total_env_steps": 364800, "episode_reward": 0.1314905881881714, "value_loss": 0.03191566914319992, "policy_loss": -0.0007665314945043633, "dist_entropy": 1.0791731595993042, "actor_grad_norm": 0.06825780868530273, "critic_grad_norm": 0.5736932158470154, "ratio": 0.9998015761375427, "entropy": 1.0791731595993042, "incre_win_rate": 0.024390243902439025, "step": 114}
{"time": 1767151632.4280715, "phase": "train", "update": 115, "total_env_steps": 368000, "episode_reward": 0.13411113619804382, "value_loss": 0.026547199487686156, "policy_loss": -0.0007203101348558505, "dist_entropy": 1.0555128097534179, "actor_grad_norm": 0.1025414988398552, "critic_grad_norm": 0.5585018992424011, "ratio": 0.9999381303787231, "entropy": 1.0555128097534179, "incre_win_rate": 0.0, "step": 115}
{"time": 1767151636.665275, "phase": "train", "update": 116, "total_env_steps": 371200, "episode_reward": 0.12966370582580566, "value_loss": 0.021609710156917573, "policy_loss": -0.0008127345982643419, "dist_entropy": 1.0745867490768433, "actor_grad_norm": 0.0912090465426445, "critic_grad_norm": 0.348266065120697, "ratio": 0.9998689889907837, "entropy": 1.0745867490768433, "incre_win_rate": 0.0, "step": 116}
{"time": 1767151640.900906, "phase": "train", "update": 117, "total_env_steps": 374400, "episode_reward": 0.13112014532089233, "value_loss": 0.017352454364299774, "policy_loss": -0.0009381881004827619, "dist_entropy": 1.095236611366272, "actor_grad_norm": 0.07977467030286789, "critic_grad_norm": 0.42046746611595154, "ratio": 0.9998674392700195, "entropy": 1.095236611366272, "incre_win_rate": 0.0, "step": 117}
{"time": 1767151645.1675029, "phase": "train", "update": 118, "total_env_steps": 377600, "episode_reward": 0.1345224678516388, "value_loss": 0.022209581360220908, "policy_loss": -0.0010276288391995792, "dist_entropy": 1.10365948677063, "actor_grad_norm": 0.0901547372341156, "critic_grad_norm": 0.34028682112693787, "ratio": 0.9994401931762695, "entropy": 1.10365948677063, "incre_win_rate": 0.0, "step": 118}
{"time": 1767151649.4108636, "phase": "train", "update": 119, "total_env_steps": 380800, "episode_reward": 0.13190758228302002, "value_loss": 0.024663856998085976, "policy_loss": -0.0011607151273175021, "dist_entropy": 1.1036982536315918, "actor_grad_norm": 0.06153235584497452, "critic_grad_norm": 0.20093463361263275, "ratio": 1.0002096891403198, "entropy": 1.1036982536315918, "incre_win_rate": 0.023255813953488372, "step": 119}
{"time": 1767151653.636056, "phase": "train", "update": 120, "total_env_steps": 384000, "episode_reward": 0.13469526171684265, "value_loss": 0.02752950005233288, "policy_loss": -0.0007551971738656959, "dist_entropy": 1.0862802028656007, "actor_grad_norm": 0.07757940143346786, "critic_grad_norm": 0.1744966059923172, "ratio": 1.0001848936080933, "entropy": 1.0862802028656007, "incre_win_rate": 0.02631578947368421, "step": 120}
{"time": 1767151657.8500955, "phase": "train", "update": 121, "total_env_steps": 387200, "episode_reward": 0.1341990977525711, "value_loss": 0.02775384336709976, "policy_loss": -0.00081273721017876, "dist_entropy": 1.0826933145523072, "actor_grad_norm": 0.10963571071624756, "critic_grad_norm": 0.16523024439811707, "ratio": 1.000120997428894, "entropy": 1.0826933145523072, "incre_win_rate": 0.02631578947368421, "step": 121}
{"time": 1767151669.1336067, "phase": "eval", "update": 121, "total_env_steps": 387200, "eval_win_rate": 0.0625, "eval_episode_reward": 11.704159768211923, "step": 121}
{"time": 1767151673.4092188, "phase": "train", "update": 122, "total_env_steps": 390400, "episode_reward": 0.13487374782562256, "value_loss": 0.030006285384297372, "policy_loss": -0.0007101433533183155, "dist_entropy": 1.063868260383606, "actor_grad_norm": 0.06268350780010223, "critic_grad_norm": 0.3504446744918823, "ratio": 0.9999569058418274, "entropy": 1.063868260383606, "incre_win_rate": 0.05263157894736842, "step": 122}
{"time": 1767151677.9148257, "phase": "train", "update": 123, "total_env_steps": 393600, "episode_reward": 0.13221336901187897, "value_loss": 0.026170922070741655, "policy_loss": -0.0008770228246863576, "dist_entropy": 1.0512211322784424, "actor_grad_norm": 0.0567096546292305, "critic_grad_norm": 0.23255431652069092, "ratio": 1.0001137256622314, "entropy": 1.0512211322784424, "incre_win_rate": 0.0, "step": 123}
{"time": 1767151682.3796961, "phase": "train", "update": 124, "total_env_steps": 396800, "episode_reward": 0.13952192664146423, "value_loss": 0.026146193593740465, "policy_loss": -0.0010697988524324131, "dist_entropy": 1.0890033006668092, "actor_grad_norm": 0.07134483754634857, "critic_grad_norm": 0.21739350259304047, "ratio": 1.0002864599227905, "entropy": 1.0890033006668092, "incre_win_rate": 0.025, "step": 124}
{"time": 1767151686.5958064, "phase": "train", "update": 125, "total_env_steps": 400000, "episode_reward": 0.13194847106933594, "value_loss": 0.02369041331112385, "policy_loss": -0.0006211457250451247, "dist_entropy": 1.1082934141159058, "actor_grad_norm": 0.08258109539747238, "critic_grad_norm": 0.3945130407810211, "ratio": 0.9998487830162048, "entropy": 1.1082934141159058, "incre_win_rate": 0.0, "step": 125}
{"time": 1767151690.808922, "phase": "train", "update": 126, "total_env_steps": 403200, "episode_reward": 0.13475735485553741, "value_loss": 0.02100687175989151, "policy_loss": -0.0006756956368934475, "dist_entropy": 1.0872871637344361, "actor_grad_norm": 0.0711866170167923, "critic_grad_norm": 0.2355513572692871, "ratio": 0.9999135136604309, "entropy": 1.0872871637344361, "incre_win_rate": 0.0, "step": 126}
{"time": 1767151695.0377374, "phase": "train", "update": 127, "total_env_steps": 406400, "episode_reward": 0.131558358669281, "value_loss": 0.023814627900719643, "policy_loss": -0.0007820509650997565, "dist_entropy": 1.0908621311187745, "actor_grad_norm": 0.06776633113622665, "critic_grad_norm": 0.18061387538909912, "ratio": 0.9998307228088379, "entropy": 1.0908621311187745, "incre_win_rate": 0.0, "step": 127}
{"time": 1767151699.2599428, "phase": "train", "update": 128, "total_env_steps": 409600, "episode_reward": 0.1350124180316925, "value_loss": 0.02301001287996769, "policy_loss": -0.0007431108131886078, "dist_entropy": 1.0661170721054076, "actor_grad_norm": 0.08300581574440002, "critic_grad_norm": 0.2719889283180237, "ratio": 0.99992436170578, "entropy": 1.0661170721054076, "incre_win_rate": 0.0, "step": 128}
{"time": 1767151703.460917, "phase": "train", "update": 129, "total_env_steps": 412800, "episode_reward": 0.13527680933475494, "value_loss": 0.028098509833216666, "policy_loss": -0.0006474169973037291, "dist_entropy": 1.0536264657974244, "actor_grad_norm": 0.07124841213226318, "critic_grad_norm": 0.16100025177001953, "ratio": 0.9999690055847168, "entropy": 1.0536264657974244, "incre_win_rate": 0.0, "step": 129}
{"time": 1767151707.6712077, "phase": "train", "update": 130, "total_env_steps": 416000, "episode_reward": 0.13139435648918152, "value_loss": 0.02093457244336605, "policy_loss": -0.0006399395902585425, "dist_entropy": 1.0596451997756957, "actor_grad_norm": 0.08890033513307571, "critic_grad_norm": 0.23676656186580658, "ratio": 1.0001205205917358, "entropy": 1.0596451997756957, "incre_win_rate": 0.0, "step": 130}
{"time": 1767151711.934243, "phase": "train", "update": 131, "total_env_steps": 419200, "episode_reward": 0.1272837221622467, "value_loss": 0.026481816545128822, "policy_loss": -0.0005217312933996965, "dist_entropy": 1.0404361486434937, "actor_grad_norm": 0.10608940571546555, "critic_grad_norm": 0.11130882799625397, "ratio": 1.0001100301742554, "entropy": 1.0404361486434937, "incre_win_rate": 0.0, "step": 131}
{"time": 1767151716.1195388, "phase": "train", "update": 132, "total_env_steps": 422400, "episode_reward": 0.14335110783576965, "value_loss": 0.04058063924312592, "policy_loss": -0.0011417534732089507, "dist_entropy": 1.0378576517105103, "actor_grad_norm": 0.07155394554138184, "critic_grad_norm": 0.6194368600845337, "ratio": 0.9999012351036072, "entropy": 1.0378576517105103, "incre_win_rate": 0.05405405405405406, "step": 132}
{"time": 1767151720.3099234, "phase": "train", "update": 133, "total_env_steps": 425600, "episode_reward": 0.1456218957901001, "value_loss": 0.035278286784887314, "policy_loss": -0.0006905985515786028, "dist_entropy": 1.0781448841094972, "actor_grad_norm": 0.06308995187282562, "critic_grad_norm": 0.3545154631137848, "ratio": 0.9999236464500427, "entropy": 1.0781448841094972, "incre_win_rate": 0.07894736842105263, "step": 133}
{"time": 1767151724.4739866, "phase": "train", "update": 134, "total_env_steps": 428800, "episode_reward": 0.13421513140201569, "value_loss": 0.024713508784770966, "policy_loss": -0.0006204046024642195, "dist_entropy": 1.0688270807266236, "actor_grad_norm": 0.06858295947313309, "critic_grad_norm": 0.2505930960178375, "ratio": 1.0000734329223633, "entropy": 1.0688270807266236, "incre_win_rate": 0.02702702702702703, "step": 134}
{"time": 1767151728.8159988, "phase": "train", "update": 135, "total_env_steps": 432000, "episode_reward": 0.13662511110305786, "value_loss": 0.029300478845834733, "policy_loss": -0.0011028519263923896, "dist_entropy": 1.1091178894042968, "actor_grad_norm": 0.07575259357690811, "critic_grad_norm": 0.35726115107536316, "ratio": 0.9999610781669617, "entropy": 1.1091178894042968, "incre_win_rate": 0.02564102564102564, "step": 135}
{"time": 1767151733.47274, "phase": "train", "update": 136, "total_env_steps": 435200, "episode_reward": 0.132463276386261, "value_loss": 0.018795180693268777, "policy_loss": -0.0007213316026769334, "dist_entropy": 1.1314314126968383, "actor_grad_norm": 0.08116807788610458, "critic_grad_norm": 0.33350175619125366, "ratio": 0.9998747110366821, "entropy": 1.1314314126968383, "incre_win_rate": 0.0, "step": 136}
{"time": 1767151738.0392342, "phase": "train", "update": 137, "total_env_steps": 438400, "episode_reward": 0.13547754287719727, "value_loss": 0.022832230478525162, "policy_loss": -0.0011485566061885776, "dist_entropy": 1.1188942909240722, "actor_grad_norm": 0.08510535955429077, "critic_grad_norm": 0.2665231227874756, "ratio": 0.9998809695243835, "entropy": 1.1188942909240722, "incre_win_rate": 0.024390243902439025, "step": 137}
{"time": 1767151742.5414574, "phase": "train", "update": 138, "total_env_steps": 441600, "episode_reward": 0.13451209664344788, "value_loss": 0.022246664762496947, "policy_loss": -0.0003933878043240746, "dist_entropy": 1.104774808883667, "actor_grad_norm": 0.05231755971908569, "critic_grad_norm": 0.23625576496124268, "ratio": 0.9998432397842407, "entropy": 1.104774808883667, "incre_win_rate": 0.0, "step": 138}
{"time": 1767151747.1763914, "phase": "train", "update": 139, "total_env_steps": 444800, "episode_reward": 0.13384725153446198, "value_loss": 0.02449397072196007, "policy_loss": -0.001174729394566043, "dist_entropy": 1.0964516401290894, "actor_grad_norm": 0.06850550323724747, "critic_grad_norm": 0.20368646085262299, "ratio": 1.0000566244125366, "entropy": 1.0964516401290894, "incre_win_rate": 0.024390243902439025, "step": 139}
{"time": 1767151751.9115474, "phase": "train", "update": 140, "total_env_steps": 448000, "episode_reward": 0.13031716644763947, "value_loss": 0.025003306195139886, "policy_loss": -0.0011429618318329559, "dist_entropy": 1.1024085760116578, "actor_grad_norm": 0.15051411092281342, "critic_grad_norm": 0.28075918555259705, "ratio": 1.0000113248825073, "entropy": 1.1024085760116578, "incre_win_rate": 0.025, "step": 140}
{"time": 1767151756.4704928, "phase": "train", "update": 141, "total_env_steps": 451200, "episode_reward": 0.1416509747505188, "value_loss": 0.03566430136561394, "policy_loss": -0.0008490128098202377, "dist_entropy": 1.0911744832992554, "actor_grad_norm": 0.1411241739988327, "critic_grad_norm": 0.17121943831443787, "ratio": 1.000212550163269, "entropy": 1.0911744832992554, "incre_win_rate": 0.07692307692307693, "step": 141}
{"time": 1767151773.473556, "phase": "eval", "update": 141, "total_env_steps": 451200, "eval_win_rate": 0.15625, "eval_episode_reward": 11.742239238410596, "step": 141}
{"time": 1767151778.2830591, "phase": "train", "update": 142, "total_env_steps": 454400, "episode_reward": 0.13657905161380768, "value_loss": 0.0290450070053339, "policy_loss": -0.0007713792029885979, "dist_entropy": 1.1026325464248656, "actor_grad_norm": 0.07522602379322052, "critic_grad_norm": 0.13616549968719482, "ratio": 0.9997726678848267, "entropy": 1.1026325464248656, "incre_win_rate": 0.045454545454545456, "step": 142}
{"time": 1767151782.865368, "phase": "train", "update": 143, "total_env_steps": 457600, "episode_reward": 0.13105598092079163, "value_loss": 0.02877788059413433, "policy_loss": -0.000762516059045204, "dist_entropy": 1.1119393348693847, "actor_grad_norm": 0.12062480300664902, "critic_grad_norm": 0.13148191571235657, "ratio": 0.9998270869255066, "entropy": 1.1119393348693847, "incre_win_rate": 0.0, "step": 143}
{"time": 1767151787.1404955, "phase": "train", "update": 144, "total_env_steps": 460800, "episode_reward": 0.132956862449646, "value_loss": 0.025583108142018317, "policy_loss": -0.0012473326332987256, "dist_entropy": 1.1219098329544068, "actor_grad_norm": 0.07677704095840454, "critic_grad_norm": 0.12910988926887512, "ratio": 1.0000489950180054, "entropy": 1.1219098329544068, "incre_win_rate": 0.0, "step": 144}
{"time": 1767151791.4298162, "phase": "train", "update": 145, "total_env_steps": 464000, "episode_reward": 0.1318511962890625, "value_loss": 0.02772943452000618, "policy_loss": -0.0011501234037737617, "dist_entropy": 1.1119149446487426, "actor_grad_norm": 0.09761840105056763, "critic_grad_norm": 0.1539345234632492, "ratio": 1.0001718997955322, "entropy": 1.1119149446487426, "incre_win_rate": 0.02564102564102564, "step": 145}
{"time": 1767151795.7359972, "phase": "train", "update": 146, "total_env_steps": 467200, "episode_reward": 0.13408008217811584, "value_loss": 0.02610412649810314, "policy_loss": -0.001144371864202931, "dist_entropy": 1.072087287902832, "actor_grad_norm": 0.07353764772415161, "critic_grad_norm": 0.21611915528774261, "ratio": 0.9998817443847656, "entropy": 1.072087287902832, "incre_win_rate": 0.023809523809523808, "step": 146}
{"time": 1767151799.9849672, "phase": "train", "update": 147, "total_env_steps": 470400, "episode_reward": 0.13622154295444489, "value_loss": 0.03211646303534508, "policy_loss": -0.0010809632067868336, "dist_entropy": 1.0552222967147826, "actor_grad_norm": 0.1176009401679039, "critic_grad_norm": 0.20615743100643158, "ratio": 1.0000090599060059, "entropy": 1.0552222967147826, "incre_win_rate": 0.05, "step": 147}
{"time": 1767151804.2275395, "phase": "train", "update": 148, "total_env_steps": 473600, "episode_reward": 0.13355287909507751, "value_loss": 0.029910648241639137, "policy_loss": -0.00056513927233528, "dist_entropy": 1.0578577995300293, "actor_grad_norm": 0.07192089408636093, "critic_grad_norm": 0.13643161952495575, "ratio": 1.0001051425933838, "entropy": 1.0578577995300293, "incre_win_rate": 0.047619047619047616, "step": 148}
{"time": 1767151808.487975, "phase": "train", "update": 149, "total_env_steps": 476800, "episode_reward": 0.13931705057621002, "value_loss": 0.02643672414124012, "policy_loss": -0.0006943010270944683, "dist_entropy": 1.0675782918930055, "actor_grad_norm": 0.05745523050427437, "critic_grad_norm": 0.164535790681839, "ratio": 1.00005042552948, "entropy": 1.0675782918930055, "incre_win_rate": 0.02564102564102564, "step": 149}
{"time": 1767151812.785809, "phase": "train", "update": 150, "total_env_steps": 480000, "episode_reward": 0.13683515787124634, "value_loss": 0.02477181367576122, "policy_loss": -0.0010597687988596505, "dist_entropy": 1.101749348640442, "actor_grad_norm": 0.09098147600889206, "critic_grad_norm": 0.22286413609981537, "ratio": 1.0001052618026733, "entropy": 1.101749348640442, "incre_win_rate": 0.0, "step": 150}
{"time": 1767151817.0876787, "phase": "train", "update": 151, "total_env_steps": 483200, "episode_reward": 0.1387329250574112, "value_loss": 0.022638100385665893, "policy_loss": -0.0009541071951389313, "dist_entropy": 1.1063831329345704, "actor_grad_norm": 0.08358296751976013, "critic_grad_norm": 0.21246550977230072, "ratio": 0.9997760057449341, "entropy": 1.1063831329345704, "incre_win_rate": 0.022727272727272728, "step": 151}
{"time": 1767151821.3602564, "phase": "train", "update": 152, "total_env_steps": 486400, "episode_reward": 0.13892900943756104, "value_loss": 0.02308979593217373, "policy_loss": -0.001169812193365516, "dist_entropy": 1.0954615831375123, "actor_grad_norm": 0.11894343048334122, "critic_grad_norm": 0.12896372377872467, "ratio": 1.0000730752944946, "entropy": 1.0954615831375123, "incre_win_rate": 0.046511627906976744, "step": 152}
{"time": 1767151825.670856, "phase": "train", "update": 153, "total_env_steps": 489600, "episode_reward": 0.1400895118713379, "value_loss": 0.029792701080441474, "policy_loss": -0.00044682218568929953, "dist_entropy": 1.08687744140625, "actor_grad_norm": 0.06746777892112732, "critic_grad_norm": 0.2795298099517822, "ratio": 1.0000730752944946, "entropy": 1.08687744140625, "incre_win_rate": 0.04878048780487805, "step": 153}
{"time": 1767151829.958852, "phase": "train", "update": 154, "total_env_steps": 492800, "episode_reward": 0.13849855959415436, "value_loss": 0.021894292533397676, "policy_loss": -0.0008454998261949953, "dist_entropy": 1.0889729499816894, "actor_grad_norm": 0.07811707258224487, "critic_grad_norm": 0.16437308490276337, "ratio": 0.9998461604118347, "entropy": 1.0889729499816894, "incre_win_rate": 0.0, "step": 154}
{"time": 1767151834.264453, "phase": "train", "update": 155, "total_env_steps": 496000, "episode_reward": 0.14113308489322662, "value_loss": 0.027947935089468957, "policy_loss": -0.0005035422910090404, "dist_entropy": 1.0982784986495973, "actor_grad_norm": 0.06538325548171997, "critic_grad_norm": 0.16558332741260529, "ratio": 1.0002193450927734, "entropy": 1.0982784986495973, "incre_win_rate": 0.046511627906976744, "step": 155}
{"time": 1767151838.5147915, "phase": "train", "update": 156, "total_env_steps": 499200, "episode_reward": 0.1359819918870926, "value_loss": 0.024815460294485094, "policy_loss": -0.0008878613453642715, "dist_entropy": 1.0958736419677735, "actor_grad_norm": 0.08002734184265137, "critic_grad_norm": 0.2284744828939438, "ratio": 0.9997842907905579, "entropy": 1.0958736419677735, "incre_win_rate": 0.0, "step": 156}
{"time": 1767151842.7333395, "phase": "train", "update": 157, "total_env_steps": 502400, "episode_reward": 0.14208920300006866, "value_loss": 0.03740401789546013, "policy_loss": -0.0008635479974255844, "dist_entropy": 1.0650388240814208, "actor_grad_norm": 0.07716807723045349, "critic_grad_norm": 0.2897869050502777, "ratio": 1.0001592636108398, "entropy": 1.0650388240814208, "incre_win_rate": 0.10256410256410256, "step": 157}
{"time": 1767151847.074657, "phase": "train", "update": 158, "total_env_steps": 505600, "episode_reward": 0.1412484496831894, "value_loss": 0.03181353211402893, "policy_loss": -0.0014340487854170192, "dist_entropy": 1.0584723234176636, "actor_grad_norm": 0.13260331749916077, "critic_grad_norm": 0.2355969399213791, "ratio": 0.9997926950454712, "entropy": 1.0584723234176636, "incre_win_rate": 0.05, "step": 158}
{"time": 1767151851.387486, "phase": "train", "update": 159, "total_env_steps": 508800, "episode_reward": 0.13899265229701996, "value_loss": 0.04235712736845017, "policy_loss": -0.000940341805604561, "dist_entropy": 1.063512349128723, "actor_grad_norm": 0.10450541228055954, "critic_grad_norm": 0.4254738390445709, "ratio": 1.0000603199005127, "entropy": 1.063512349128723, "incre_win_rate": 0.05, "step": 159}
{"time": 1767151855.6431606, "phase": "train", "update": 160, "total_env_steps": 512000, "episode_reward": 0.12833350896835327, "value_loss": 0.03424027487635613, "policy_loss": -0.0005158011608699554, "dist_entropy": 1.058609700202942, "actor_grad_norm": 0.09531935304403305, "critic_grad_norm": 0.3809131979942322, "ratio": 0.9999575614929199, "entropy": 1.058609700202942, "incre_win_rate": 0.02631578947368421, "step": 160}
{"time": 1767151859.8877647, "phase": "train", "update": 161, "total_env_steps": 515200, "episode_reward": 0.13684707880020142, "value_loss": 0.031653206422925, "policy_loss": -0.0011791660527279645, "dist_entropy": 1.0416637420654298, "actor_grad_norm": 0.08139752596616745, "critic_grad_norm": 0.2883952260017395, "ratio": 1.0002201795578003, "entropy": 1.0416637420654298, "incre_win_rate": 0.0, "step": 161}
{"time": 1767151877.5263083, "phase": "eval", "update": 161, "total_env_steps": 515200, "eval_win_rate": 0.09375, "eval_episode_reward": 8.10921978476821, "step": 161}
{"time": 1767151881.8029819, "phase": "train", "update": 162, "total_env_steps": 518400, "episode_reward": 0.1381436288356781, "value_loss": 0.03325672373175621, "policy_loss": -0.0007512416339372052, "dist_entropy": 1.0350793600082397, "actor_grad_norm": 0.07087298482656479, "critic_grad_norm": 0.235566645860672, "ratio": 0.9998876452445984, "entropy": 1.0350793600082397, "incre_win_rate": 0.025, "step": 162}
{"time": 1767151886.0828764, "phase": "train", "update": 163, "total_env_steps": 521600, "episode_reward": 0.14336144924163818, "value_loss": 0.041713403165340425, "policy_loss": -0.0011794035380688684, "dist_entropy": 1.0423943519592285, "actor_grad_norm": 0.07544215023517609, "critic_grad_norm": 0.17856521904468536, "ratio": 0.9998459219932556, "entropy": 1.0423943519592285, "incre_win_rate": 0.07894736842105263, "step": 163}
{"time": 1767151910.3437662, "phase": "train", "update": 164, "total_env_steps": 524800, "episode_reward": 0.12356892228126526, "value_loss": 0.08044903129339218, "policy_loss": -0.0005426506442354651, "dist_entropy": 1.043724775314331, "actor_grad_norm": 0.07675085216760635, "critic_grad_norm": 0.7542427778244019, "ratio": 1.000217080116272, "entropy": 1.043724775314331, "incre_win_rate": 0.05555555555555555, "step": 164}
{"time": 1767151914.6229799, "phase": "train", "update": 165, "total_env_steps": 528000, "episode_reward": 0.13941484689712524, "value_loss": 0.038290342688560484, "policy_loss": -0.0005346611653912703, "dist_entropy": 1.0545637607574463, "actor_grad_norm": 0.06583593785762787, "critic_grad_norm": 0.2624642550945282, "ratio": 1.0000029802322388, "entropy": 1.0545637607574463, "incre_win_rate": 0.05128205128205128, "step": 165}
{"time": 1767151918.8622456, "phase": "train", "update": 166, "total_env_steps": 531200, "episode_reward": 0.138178288936615, "value_loss": 0.02966802716255188, "policy_loss": -0.00056461683706297, "dist_entropy": 1.0680353403091432, "actor_grad_norm": 0.1019473671913147, "critic_grad_norm": 0.2410321980714798, "ratio": 0.999978244304657, "entropy": 1.0680353403091432, "incre_win_rate": 0.02564102564102564, "step": 166}
{"time": 1767151923.1034172, "phase": "train", "update": 167, "total_env_steps": 534400, "episode_reward": 0.14267021417617798, "value_loss": 0.032296227663755415, "policy_loss": -0.0008549271948508519, "dist_entropy": 1.0573440790176392, "actor_grad_norm": 0.06666946411132812, "critic_grad_norm": 0.25809407234191895, "ratio": 1.000143051147461, "entropy": 1.0573440790176392, "incre_win_rate": 0.05555555555555555, "step": 167}
{"time": 1767151927.3987768, "phase": "train", "update": 168, "total_env_steps": 537600, "episode_reward": 0.1473540961742401, "value_loss": 0.03367048278450966, "policy_loss": -0.0009053150178612412, "dist_entropy": 1.0665959358215331, "actor_grad_norm": 0.0656815692782402, "critic_grad_norm": 0.33240950107574463, "ratio": 0.9998615384101868, "entropy": 1.0665959358215331, "incre_win_rate": 0.04878048780487805, "step": 168}
{"time": 1767151931.711595, "phase": "train", "update": 169, "total_env_steps": 540800, "episode_reward": 0.1386180818080902, "value_loss": 0.025344022363424302, "policy_loss": -0.0008467816635459258, "dist_entropy": 1.0772772312164307, "actor_grad_norm": 0.05790646746754646, "critic_grad_norm": 0.3893888592720032, "ratio": 0.9999548196792603, "entropy": 1.0772772312164307, "incre_win_rate": 0.024390243902439025, "step": 169}
{"time": 1767151936.0607865, "phase": "train", "update": 170, "total_env_steps": 544000, "episode_reward": 0.14452193677425385, "value_loss": 0.021880893036723137, "policy_loss": -0.000982470122548884, "dist_entropy": 1.0680007696151734, "actor_grad_norm": 0.08914091438055038, "critic_grad_norm": 0.1562611311674118, "ratio": 1.0001193284988403, "entropy": 1.0680007696151734, "incre_win_rate": 0.02564102564102564, "step": 170}
{"time": 1767151940.4525566, "phase": "train", "update": 171, "total_env_steps": 547200, "episode_reward": 0.13477958738803864, "value_loss": 0.02278667390346527, "policy_loss": -0.0008322130334825317, "dist_entropy": 1.0421369552612305, "actor_grad_norm": 0.07243901491165161, "critic_grad_norm": 0.14490559697151184, "ratio": 1.0001803636550903, "entropy": 1.0421369552612305, "incre_win_rate": 0.0, "step": 171}
{"time": 1767151945.068143, "phase": "train", "update": 172, "total_env_steps": 550400, "episode_reward": 0.1371026635169983, "value_loss": 0.02068632245063782, "policy_loss": -0.0010243856431998211, "dist_entropy": 1.0535242557525635, "actor_grad_norm": 0.07763379067182541, "critic_grad_norm": 0.13299089670181274, "ratio": 0.9999195337295532, "entropy": 1.0535242557525635, "incre_win_rate": 0.0, "step": 172}
{"time": 1767151949.5141268, "phase": "train", "update": 173, "total_env_steps": 553600, "episode_reward": 0.14333300292491913, "value_loss": 0.02084200009703636, "policy_loss": -0.0012021653962513313, "dist_entropy": 1.0171164274215698, "actor_grad_norm": 0.09766563028097153, "critic_grad_norm": 0.11011852324008942, "ratio": 0.9997220039367676, "entropy": 1.0171164274215698, "incre_win_rate": 0.025, "step": 173}
{"time": 1767151953.8101714, "phase": "train", "update": 174, "total_env_steps": 556800, "episode_reward": 0.13547909259796143, "value_loss": 0.02291686087846756, "policy_loss": -0.0003351811021346407, "dist_entropy": 0.9891053676605225, "actor_grad_norm": 0.06628892570734024, "critic_grad_norm": 0.2364652156829834, "ratio": 0.9998397827148438, "entropy": 0.9891053676605225, "incre_win_rate": 0.025, "step": 174}
{"time": 1767151958.0837262, "phase": "train", "update": 175, "total_env_steps": 560000, "episode_reward": 0.14394505321979523, "value_loss": 0.025355761498212816, "policy_loss": -0.001342470009224428, "dist_entropy": 1.0064515352249146, "actor_grad_norm": 0.09811695665121078, "critic_grad_norm": 0.2446558028459549, "ratio": 0.999525249004364, "entropy": 1.0064515352249146, "incre_win_rate": 0.05555555555555555, "step": 175}
{"time": 1767151962.3752923, "phase": "train", "update": 176, "total_env_steps": 563200, "episode_reward": 0.14552618563175201, "value_loss": 0.024066544696688653, "policy_loss": -0.0004419973004190503, "dist_entropy": 0.9942040205001831, "actor_grad_norm": 0.10174858570098877, "critic_grad_norm": 0.31709858775138855, "ratio": 1.0007078647613525, "entropy": 0.9942040205001831, "incre_win_rate": 0.025, "step": 176}
{"time": 1767151966.6415663, "phase": "train", "update": 177, "total_env_steps": 566400, "episode_reward": 0.13662563264369965, "value_loss": 0.022319001704454423, "policy_loss": -0.0007696890800385602, "dist_entropy": 0.9760403513908387, "actor_grad_norm": 0.09800677746534348, "critic_grad_norm": 0.13020598888397217, "ratio": 0.9998470544815063, "entropy": 0.9760403513908387, "incre_win_rate": 0.05128205128205128, "step": 177}
{"time": 1767151970.9108346, "phase": "train", "update": 178, "total_env_steps": 569600, "episode_reward": 0.14305825531482697, "value_loss": 0.024272125214338303, "policy_loss": -0.0006680104487529093, "dist_entropy": 0.9750887751579285, "actor_grad_norm": 0.0906568393111229, "critic_grad_norm": 0.1317051202058792, "ratio": 1.0001182556152344, "entropy": 0.9750887751579285, "incre_win_rate": 0.02631578947368421, "step": 178}
{"time": 1767151975.2052526, "phase": "train", "update": 179, "total_env_steps": 572800, "episode_reward": 0.14020074903964996, "value_loss": 0.021604562178254128, "policy_loss": -0.000983206213268062, "dist_entropy": 0.9994699716567993, "actor_grad_norm": 0.10598831623792648, "critic_grad_norm": 0.23632612824440002, "ratio": 0.9999732971191406, "entropy": 0.9994699716567993, "incre_win_rate": 0.025, "step": 179}
{"time": 1767151979.4595191, "phase": "train", "update": 180, "total_env_steps": 576000, "episode_reward": 0.14011642336845398, "value_loss": 0.02107972539961338, "policy_loss": -0.00044925111572915457, "dist_entropy": 0.9880334496498108, "actor_grad_norm": 0.08536817878484726, "critic_grad_norm": 0.21060530841350555, "ratio": 1.000252366065979, "entropy": 0.9880334496498108, "incre_win_rate": 0.05263157894736842, "step": 180}
{"time": 1767151983.7374237, "phase": "train", "update": 181, "total_env_steps": 579200, "episode_reward": 0.1419132947921753, "value_loss": 0.024912485852837563, "policy_loss": -0.0009679746457166516, "dist_entropy": 1.0060070753097534, "actor_grad_norm": 0.10942866653203964, "critic_grad_norm": 0.18952977657318115, "ratio": 1.0006098747253418, "entropy": 1.0060070753097534, "incre_win_rate": 0.05128205128205128, "step": 181}
{"time": 1767151996.340376, "phase": "eval", "update": 181, "total_env_steps": 579200, "eval_win_rate": 0.03125, "eval_episode_reward": 12.06063741721854, "step": 181}
{"time": 1767152000.578012, "phase": "train", "update": 182, "total_env_steps": 582400, "episode_reward": 0.13768626749515533, "value_loss": 0.026523007079958916, "policy_loss": -0.0008451834943201675, "dist_entropy": 0.984121561050415, "actor_grad_norm": 0.08478980511426926, "critic_grad_norm": 0.14967088401317596, "ratio": 1.0003106594085693, "entropy": 0.984121561050415, "incre_win_rate": 0.0, "step": 182}
{"time": 1767152004.8690927, "phase": "train", "update": 183, "total_env_steps": 585600, "episode_reward": 0.1434250771999359, "value_loss": 0.02319805733859539, "policy_loss": -0.0007123290341780164, "dist_entropy": 0.9932788252830506, "actor_grad_norm": 0.08174850791692734, "critic_grad_norm": 0.0884542316198349, "ratio": 0.9999305605888367, "entropy": 0.9932788252830506, "incre_win_rate": 0.05, "step": 183}
{"time": 1767152009.1684785, "phase": "train", "update": 184, "total_env_steps": 588800, "episode_reward": 0.1461951583623886, "value_loss": 0.02810455970466137, "policy_loss": -0.000983808405752562, "dist_entropy": 1.0089957952499389, "actor_grad_norm": 0.10511187463998795, "critic_grad_norm": 0.1508253812789917, "ratio": 1.0000933408737183, "entropy": 1.0089957952499389, "incre_win_rate": 0.05128205128205128, "step": 184}
{"time": 1767152013.4613752, "phase": "train", "update": 185, "total_env_steps": 592000, "episode_reward": 0.1352519690990448, "value_loss": 0.018837098404765128, "policy_loss": -0.0012837526641106933, "dist_entropy": 0.999261224269867, "actor_grad_norm": 0.08331523090600967, "critic_grad_norm": 0.2800740897655487, "ratio": 0.999666154384613, "entropy": 0.999261224269867, "incre_win_rate": 0.0, "step": 185}
{"time": 1767152017.700256, "phase": "train", "update": 186, "total_env_steps": 595200, "episode_reward": 0.13331592082977295, "value_loss": 0.020681970193982123, "policy_loss": -0.0006359605758412101, "dist_entropy": 1.0097859859466554, "actor_grad_norm": 0.10913877934217453, "critic_grad_norm": 0.14213687181472778, "ratio": 0.9998744130134583, "entropy": 1.0097859859466554, "incre_win_rate": 0.0, "step": 186}
{"time": 1767152022.2683222, "phase": "train", "update": 187, "total_env_steps": 598400, "episode_reward": 0.14456644654273987, "value_loss": 0.026676423475146295, "policy_loss": -0.0008524136015168437, "dist_entropy": 1.0402273178100585, "actor_grad_norm": 0.08203230798244476, "critic_grad_norm": 0.40807390213012695, "ratio": 0.9998536109924316, "entropy": 1.0402273178100585, "incre_win_rate": 0.07692307692307693, "step": 187}
{"time": 1767152026.4989889, "phase": "train", "update": 188, "total_env_steps": 601600, "episode_reward": 0.14233028888702393, "value_loss": 0.028111492097377778, "policy_loss": -0.0012095430712328436, "dist_entropy": 1.0215073823928833, "actor_grad_norm": 0.09033756703138351, "critic_grad_norm": 0.38366493582725525, "ratio": 1.0000724792480469, "entropy": 1.0215073823928833, "incre_win_rate": 0.025, "step": 188}
{"time": 1767152030.7379153, "phase": "train", "update": 189, "total_env_steps": 604800, "episode_reward": 0.14510399103164673, "value_loss": 0.019268868118524553, "policy_loss": -0.001015556519143246, "dist_entropy": 1.035649061203003, "actor_grad_norm": 0.08850453048944473, "critic_grad_norm": 0.34748104214668274, "ratio": 0.9995221495628357, "entropy": 1.035649061203003, "incre_win_rate": 0.0, "step": 189}
{"time": 1767152034.9934897, "phase": "train", "update": 190, "total_env_steps": 608000, "episode_reward": 0.14876604080200195, "value_loss": 0.026454658806324007, "policy_loss": -0.0011779068749578237, "dist_entropy": 1.0071244716644288, "actor_grad_norm": 0.08841477334499359, "critic_grad_norm": 0.249362513422966, "ratio": 0.9998698234558105, "entropy": 1.0071244716644288, "incre_win_rate": 0.047619047619047616, "step": 190}
{"time": 1767152039.1835394, "phase": "train", "update": 191, "total_env_steps": 611200, "episode_reward": 0.13734839856624603, "value_loss": 0.02124863155186176, "policy_loss": -0.001423318072195112, "dist_entropy": 0.9858888149261474, "actor_grad_norm": 0.09559761732816696, "critic_grad_norm": 0.13837072253227234, "ratio": 0.9999990463256836, "entropy": 0.9858888149261474, "incre_win_rate": 0.0, "step": 191}
{"time": 1767152043.3845596, "phase": "train", "update": 192, "total_env_steps": 614400, "episode_reward": 0.15319949388504028, "value_loss": 0.029836663976311684, "policy_loss": -0.0008364508575745333, "dist_entropy": 0.9798509955406189, "actor_grad_norm": 0.08362588286399841, "critic_grad_norm": 0.497909277677536, "ratio": 0.9998759627342224, "entropy": 0.9798509955406189, "incre_win_rate": 0.10256410256410256, "step": 192}
{"time": 1767152047.5088046, "phase": "train", "update": 193, "total_env_steps": 617600, "episode_reward": 0.13912975788116455, "value_loss": 0.022244039922952652, "policy_loss": -0.000830171516885514, "dist_entropy": 1.003333830833435, "actor_grad_norm": 0.07152930647134781, "critic_grad_norm": 0.3200858235359192, "ratio": 0.9999483227729797, "entropy": 1.003333830833435, "incre_win_rate": 0.02564102564102564, "step": 193}
{"time": 1767152051.6998215, "phase": "train", "update": 194, "total_env_steps": 620800, "episode_reward": 0.13765935599803925, "value_loss": 0.027467159554362297, "policy_loss": -0.0009069994588646324, "dist_entropy": 1.0080928325653076, "actor_grad_norm": 0.06694366782903671, "critic_grad_norm": 0.39029523730278015, "ratio": 0.9999380111694336, "entropy": 1.0080928325653076, "incre_win_rate": 0.02564102564102564, "step": 194}
{"time": 1767152055.8982553, "phase": "train", "update": 195, "total_env_steps": 624000, "episode_reward": 0.14428550004959106, "value_loss": 0.01748916655778885, "policy_loss": -0.0007434011216033376, "dist_entropy": 1.0532729625701904, "actor_grad_norm": 0.061549484729766846, "critic_grad_norm": 0.11664272844791412, "ratio": 0.999899685382843, "entropy": 1.0532729625701904, "incre_win_rate": 0.0, "step": 195}
{"time": 1767152060.1067991, "phase": "train", "update": 196, "total_env_steps": 627200, "episode_reward": 0.1487950086593628, "value_loss": 0.03262937292456627, "policy_loss": -0.000973092478739801, "dist_entropy": 1.015498971939087, "actor_grad_norm": 0.08108624815940857, "critic_grad_norm": 0.4282691180706024, "ratio": 1.0001730918884277, "entropy": 1.015498971939087, "incre_win_rate": 0.125, "step": 196}
{"time": 1767152064.3719676, "phase": "train", "update": 197, "total_env_steps": 630400, "episode_reward": 0.14314362406730652, "value_loss": 0.02946055047214031, "policy_loss": -0.0008893148299932818, "dist_entropy": 0.9975724220275879, "actor_grad_norm": 0.06567168235778809, "critic_grad_norm": 0.27590641379356384, "ratio": 0.9999608397483826, "entropy": 0.9975724220275879, "incre_win_rate": 0.08333333333333333, "step": 197}
{"time": 1767152068.6303797, "phase": "train", "update": 198, "total_env_steps": 633600, "episode_reward": 0.1432471126317978, "value_loss": 0.02827373333275318, "policy_loss": -0.000634996552203404, "dist_entropy": 0.9703222036361694, "actor_grad_norm": 0.06586837768554688, "critic_grad_norm": 0.18754048645496368, "ratio": 0.9997591972351074, "entropy": 0.9703222036361694, "incre_win_rate": 0.05128205128205128, "step": 198}
{"time": 1767152072.8670032, "phase": "train", "update": 199, "total_env_steps": 636800, "episode_reward": 0.13588525354862213, "value_loss": 0.032174141705036165, "policy_loss": -0.0012699409481598423, "dist_entropy": 0.9758744359016418, "actor_grad_norm": 0.0801084041595459, "critic_grad_norm": 0.4180128574371338, "ratio": 0.9997685551643372, "entropy": 0.9758744359016418, "incre_win_rate": 0.07692307692307693, "step": 199}
{"time": 1767152077.1694531, "phase": "train", "update": 200, "total_env_steps": 640000, "episode_reward": 0.13794805109500885, "value_loss": 0.02650887258350849, "policy_loss": -0.0007988498497496721, "dist_entropy": 1.0142396450042725, "actor_grad_norm": 0.13132810592651367, "critic_grad_norm": 0.3692049980163574, "ratio": 0.9999614953994751, "entropy": 1.0142396450042725, "incre_win_rate": 0.0, "step": 200}
{"time": 1767152081.4734502, "phase": "train", "update": 201, "total_env_steps": 643200, "episode_reward": 0.14061258733272552, "value_loss": 0.0261884119361639, "policy_loss": -0.0010586005867331493, "dist_entropy": 1.0103849649429322, "actor_grad_norm": 0.06838025897741318, "critic_grad_norm": 0.18086378276348114, "ratio": 0.9998032450675964, "entropy": 1.0103849649429322, "incre_win_rate": 0.05128205128205128, "step": 201}
{"time": 1767152096.5370069, "phase": "eval", "update": 201, "total_env_steps": 643200, "eval_win_rate": 0.1875, "eval_episode_reward": 11.105753311258278, "step": 201}
{"time": 1767152100.817129, "phase": "train", "update": 202, "total_env_steps": 646400, "episode_reward": 0.14590024948120117, "value_loss": 0.023869461938738824, "policy_loss": -0.0008224225945681951, "dist_entropy": 1.0099852561950684, "actor_grad_norm": 0.06405958533287048, "critic_grad_norm": 0.30784913897514343, "ratio": 1.0000543594360352, "entropy": 1.0099852561950684, "incre_win_rate": 0.05263157894736842, "step": 202}
{"time": 1767152105.0620983, "phase": "train", "update": 203, "total_env_steps": 649600, "episode_reward": 0.1316380500793457, "value_loss": 0.019848336279392243, "policy_loss": -0.0011333556555054968, "dist_entropy": 1.079230284690857, "actor_grad_norm": 0.07540393620729446, "critic_grad_norm": 0.48919254541397095, "ratio": 1.0000723600387573, "entropy": 1.079230284690857, "incre_win_rate": 0.022727272727272728, "step": 203}
{"time": 1767152109.2844937, "phase": "train", "update": 204, "total_env_steps": 652800, "episode_reward": 0.14675290882587433, "value_loss": 0.02833149880170822, "policy_loss": -0.0013697499157073524, "dist_entropy": 0.9831137537956238, "actor_grad_norm": 0.1731651872396469, "critic_grad_norm": 0.4368448257446289, "ratio": 1.000093698501587, "entropy": 0.9831137537956238, "incre_win_rate": 0.10526315789473684, "step": 204}
{"time": 1767152113.5030227, "phase": "train", "update": 205, "total_env_steps": 656000, "episode_reward": 0.14296771585941315, "value_loss": 0.022425758838653564, "policy_loss": -0.0008727843828680193, "dist_entropy": 0.9582555174827576, "actor_grad_norm": 0.05940055474638939, "critic_grad_norm": 0.3320527672767639, "ratio": 1.0000568628311157, "entropy": 0.9582555174827576, "incre_win_rate": 0.0, "step": 205}
{"time": 1767152117.7080355, "phase": "train", "update": 206, "total_env_steps": 659200, "episode_reward": 0.150945782661438, "value_loss": 0.03318885564804077, "policy_loss": -0.0007641221444198099, "dist_entropy": 0.93759126663208, "actor_grad_norm": 0.08517320454120636, "critic_grad_norm": 0.3254978358745575, "ratio": 0.9998494386672974, "entropy": 0.93759126663208, "incre_win_rate": 0.18421052631578946, "step": 206}
{"time": 1767152121.9362192, "phase": "train", "update": 207, "total_env_steps": 662400, "episode_reward": 0.15330815315246582, "value_loss": 0.03430199921131134, "policy_loss": -0.0009341058176062234, "dist_entropy": 0.916858184337616, "actor_grad_norm": 0.08818216621875763, "critic_grad_norm": 0.3328082859516144, "ratio": 1.0000797510147095, "entropy": 0.916858184337616, "incre_win_rate": 0.14285714285714285, "step": 207}
{"time": 1767152126.2145255, "phase": "train", "update": 208, "total_env_steps": 665600, "episode_reward": 0.1527612805366516, "value_loss": 0.027781900018453598, "policy_loss": -0.0010000810648221226, "dist_entropy": 0.9201470732688903, "actor_grad_norm": 0.09860920161008835, "critic_grad_norm": 0.30506405234336853, "ratio": 0.9999940991401672, "entropy": 0.9201470732688903, "incre_win_rate": 0.10526315789473684, "step": 208}
{"time": 1767152130.4730864, "phase": "train", "update": 209, "total_env_steps": 668800, "episode_reward": 0.14488926529884338, "value_loss": 0.0261700838804245, "policy_loss": -0.0010905121377039252, "dist_entropy": 0.9380529522895813, "actor_grad_norm": 0.1064283475279808, "critic_grad_norm": 0.37786197662353516, "ratio": 1.0002049207687378, "entropy": 0.9380529522895813, "incre_win_rate": 0.02857142857142857, "step": 209}
{"time": 1767152134.7148266, "phase": "train", "update": 210, "total_env_steps": 672000, "episode_reward": 0.14053550362586975, "value_loss": 0.04543452709913254, "policy_loss": -0.0010288509270194978, "dist_entropy": 0.884654438495636, "actor_grad_norm": 0.06723608821630478, "critic_grad_norm": 0.400033563375473, "ratio": 1.0000858306884766, "entropy": 0.884654438495636, "incre_win_rate": 0.1111111111111111, "step": 210}
{"time": 1767152138.9493752, "phase": "train", "update": 211, "total_env_steps": 675200, "episode_reward": 0.14794598519802094, "value_loss": 0.03357061073184013, "policy_loss": -0.0010097492755942739, "dist_entropy": 0.9268023729324341, "actor_grad_norm": 0.08827336132526398, "critic_grad_norm": 0.3697984516620636, "ratio": 0.9999552965164185, "entropy": 0.9268023729324341, "incre_win_rate": 0.1, "step": 211}
{"time": 1767152143.2053728, "phase": "train", "update": 212, "total_env_steps": 678400, "episode_reward": 0.1571130007505417, "value_loss": 0.03526161387562752, "policy_loss": -0.0008703135438690168, "dist_entropy": 0.9228957176208497, "actor_grad_norm": 0.09613388031721115, "critic_grad_norm": 0.3016218841075897, "ratio": 1.000173807144165, "entropy": 0.9228957176208497, "incre_win_rate": 0.16216216216216217, "step": 212}
{"time": 1767152147.4812794, "phase": "train", "update": 213, "total_env_steps": 681600, "episode_reward": 0.15119412541389465, "value_loss": 0.034840178489685056, "policy_loss": -0.0009322949340482723, "dist_entropy": 0.8940351963043213, "actor_grad_norm": 0.09230156987905502, "critic_grad_norm": 0.18185365200042725, "ratio": 0.9997714161872864, "entropy": 0.8940351963043213, "incre_win_rate": 0.18421052631578946, "step": 213}
{"time": 1767152151.7482042, "phase": "train", "update": 214, "total_env_steps": 684800, "episode_reward": 0.1595524698495865, "value_loss": 0.037542613595724104, "policy_loss": -0.0008810206433724988, "dist_entropy": 0.9021156191825866, "actor_grad_norm": 0.09964779019355774, "critic_grad_norm": 0.27834269404411316, "ratio": 1.0003870725631714, "entropy": 0.9021156191825866, "incre_win_rate": 0.19444444444444445, "step": 214}
{"time": 1767152155.9764555, "phase": "train", "update": 215, "total_env_steps": 688000, "episode_reward": 0.14143624901771545, "value_loss": 0.03345551267266274, "policy_loss": -0.0008217943765679081, "dist_entropy": 0.902335786819458, "actor_grad_norm": 0.12019322067499161, "critic_grad_norm": 0.2527880072593689, "ratio": 1.0004819631576538, "entropy": 0.902335786819458, "incre_win_rate": 0.05555555555555555, "step": 215}
{"time": 1767152160.218417, "phase": "train", "update": 216, "total_env_steps": 691200, "episode_reward": 0.15080402791500092, "value_loss": 0.036059580743312836, "policy_loss": -0.0009252732791765084, "dist_entropy": 0.8965898990631104, "actor_grad_norm": 0.07645603269338608, "critic_grad_norm": 0.3393087387084961, "ratio": 1.0002127885818481, "entropy": 0.8965898990631104, "incre_win_rate": 0.10256410256410256, "step": 216}
{"time": 1767152164.4456954, "phase": "train", "update": 217, "total_env_steps": 694400, "episode_reward": 0.1601603627204895, "value_loss": 0.033254726231098174, "policy_loss": -0.0007752081753645612, "dist_entropy": 0.9064467430114747, "actor_grad_norm": 0.08239807188510895, "critic_grad_norm": 0.2147609442472458, "ratio": 0.9997949600219727, "entropy": 0.9064467430114747, "incre_win_rate": 0.2, "step": 217}
{"time": 1767152168.6719766, "phase": "train", "update": 218, "total_env_steps": 697600, "episode_reward": 0.14321297407150269, "value_loss": 0.02624599598348141, "policy_loss": -0.0008434861603053179, "dist_entropy": 0.9127894163131713, "actor_grad_norm": 0.07443281263113022, "critic_grad_norm": 0.18315504491329193, "ratio": 0.9999637007713318, "entropy": 0.9127894163131713, "incre_win_rate": 0.0, "step": 218}
{"time": 1767152172.894839, "phase": "train", "update": 219, "total_env_steps": 700800, "episode_reward": 0.1396367996931076, "value_loss": 0.02784038856625557, "policy_loss": -0.0013445150021547114, "dist_entropy": 0.9151566505432129, "actor_grad_norm": 0.09484349191188812, "critic_grad_norm": 0.13600647449493408, "ratio": 0.9997650384902954, "entropy": 0.9151566505432129, "incre_win_rate": 0.10526315789473684, "step": 219}
{"time": 1767152177.144404, "phase": "train", "update": 220, "total_env_steps": 704000, "episode_reward": 0.14856165647506714, "value_loss": 0.02823062539100647, "policy_loss": -0.0012476920706852468, "dist_entropy": 0.894841980934143, "actor_grad_norm": 0.08944832533597946, "critic_grad_norm": 0.242484450340271, "ratio": 0.9998127818107605, "entropy": 0.894841980934143, "incre_win_rate": 0.08571428571428572, "step": 220}
{"time": 1767152181.445956, "phase": "train", "update": 221, "total_env_steps": 707200, "episode_reward": 0.15157026052474976, "value_loss": 0.032698352634906766, "policy_loss": -0.0007833162715769504, "dist_entropy": 0.9186609148979187, "actor_grad_norm": 0.06686226278543472, "critic_grad_norm": 0.1684560924768448, "ratio": 0.9998400807380676, "entropy": 0.9186609148979187, "incre_win_rate": 0.15384615384615385, "step": 221}
{"time": 1767152194.9987736, "phase": "eval", "update": 221, "total_env_steps": 707200, "eval_win_rate": 0.28125, "eval_episode_reward": 14.301117549668874, "step": 221}
{"time": 1767152199.2824335, "phase": "train", "update": 222, "total_env_steps": 710400, "episode_reward": 0.14953486621379852, "value_loss": 0.02599436342716217, "policy_loss": -0.000900388888883441, "dist_entropy": 0.8959281921386719, "actor_grad_norm": 0.08013743907213211, "critic_grad_norm": 0.12328683584928513, "ratio": 0.9995700716972351, "entropy": 0.8959281921386719, "incre_win_rate": 0.05555555555555555, "step": 222}
{"time": 1767152203.5260146, "phase": "train", "update": 223, "total_env_steps": 713600, "episode_reward": 0.15069381892681122, "value_loss": 0.028538454696536063, "policy_loss": -0.000652216264797012, "dist_entropy": 0.9079057216644287, "actor_grad_norm": 0.06833209842443466, "critic_grad_norm": 0.15777729451656342, "ratio": 0.999846875667572, "entropy": 0.9079057216644287, "incre_win_rate": 0.15384615384615385, "step": 223}
{"time": 1767152207.8188844, "phase": "train", "update": 224, "total_env_steps": 716800, "episode_reward": 0.15302255749702454, "value_loss": 0.027170077338814734, "policy_loss": -0.0011747463725717776, "dist_entropy": 0.8831992626190186, "actor_grad_norm": 0.09949660301208496, "critic_grad_norm": 0.17517761886119843, "ratio": 0.9998767971992493, "entropy": 0.8831992626190186, "incre_win_rate": 0.10810810810810811, "step": 224}
{"time": 1767152212.080178, "phase": "train", "update": 225, "total_env_steps": 720000, "episode_reward": 0.156424880027771, "value_loss": 0.03623395711183548, "policy_loss": -0.0010845161163139494, "dist_entropy": 0.8857222199440002, "actor_grad_norm": 0.08656879514455795, "critic_grad_norm": 0.2568281590938568, "ratio": 0.9999653100967407, "entropy": 0.8857222199440002, "incre_win_rate": 0.1891891891891892, "step": 225}
{"time": 1767152216.3806303, "phase": "train", "update": 226, "total_env_steps": 723200, "episode_reward": 0.15298841893672943, "value_loss": 0.06571372747421264, "policy_loss": -0.0011338293297548318, "dist_entropy": 0.8358252763748169, "actor_grad_norm": 0.07966511696577072, "critic_grad_norm": 0.4331659972667694, "ratio": 1.0002353191375732, "entropy": 0.8358252763748169, "incre_win_rate": 0.21212121212121213, "step": 226}
{"time": 1767152220.6785445, "phase": "train", "update": 227, "total_env_steps": 726400, "episode_reward": 0.15816432237625122, "value_loss": 0.038018496334552766, "policy_loss": -0.0009212546689326473, "dist_entropy": 0.8667274236679077, "actor_grad_norm": 0.137925386428833, "critic_grad_norm": 0.3182426393032074, "ratio": 0.9998442530632019, "entropy": 0.8667274236679077, "incre_win_rate": 0.21052631578947367, "step": 227}
{"time": 1767152224.963123, "phase": "train", "update": 228, "total_env_steps": 729600, "episode_reward": 0.1474110186100006, "value_loss": 0.049398656189441684, "policy_loss": -0.001164533054113548, "dist_entropy": 0.8539961814880371, "actor_grad_norm": 0.0968879982829094, "critic_grad_norm": 0.5958340764045715, "ratio": 1.0003303289413452, "entropy": 0.8539961814880371, "incre_win_rate": 0.1388888888888889, "step": 228}
{"time": 1767152229.243682, "phase": "train", "update": 229, "total_env_steps": 732800, "episode_reward": 0.15297546982765198, "value_loss": 0.039014965295791626, "policy_loss": -0.0013007703715132378, "dist_entropy": 0.8746867060661316, "actor_grad_norm": 0.11161400377750397, "critic_grad_norm": 0.48543891310691833, "ratio": 0.9996837973594666, "entropy": 0.8746867060661316, "incre_win_rate": 0.10810810810810811, "step": 229}
{"time": 1767152233.5380018, "phase": "train", "update": 230, "total_env_steps": 736000, "episode_reward": 0.15099544823169708, "value_loss": 0.04869003966450691, "policy_loss": -0.0008029625592513411, "dist_entropy": 0.8765778422355652, "actor_grad_norm": 0.09807336330413818, "critic_grad_norm": 0.44310298562049866, "ratio": 1.0001769065856934, "entropy": 0.8765778422355652, "incre_win_rate": 0.13513513513513514, "step": 230}
{"time": 1767152237.8472078, "phase": "train", "update": 231, "total_env_steps": 739200, "episode_reward": 0.15539735555648804, "value_loss": 0.030449748411774634, "policy_loss": -0.0012105644484528, "dist_entropy": 0.917975926399231, "actor_grad_norm": 0.09668370336294174, "critic_grad_norm": 0.28107306361198425, "ratio": 0.999851405620575, "entropy": 0.917975926399231, "incre_win_rate": 0.10526315789473684, "step": 231}
{"time": 1767152242.1398187, "phase": "train", "update": 232, "total_env_steps": 742400, "episode_reward": 0.14255328476428986, "value_loss": 0.02594105564057827, "policy_loss": -0.0011061740801658003, "dist_entropy": 0.9307358980178833, "actor_grad_norm": 0.09467443078756332, "critic_grad_norm": 0.39214882254600525, "ratio": 0.9996339678764343, "entropy": 0.9307358980178833, "incre_win_rate": 0.05128205128205128, "step": 232}
{"time": 1767152246.4575005, "phase": "train", "update": 233, "total_env_steps": 745600, "episode_reward": 0.16133329272270203, "value_loss": 0.028872223943471907, "policy_loss": -0.0006620949184203085, "dist_entropy": 0.9294494748115539, "actor_grad_norm": 0.09713580459356308, "critic_grad_norm": 0.38353830575942993, "ratio": 0.9999327659606934, "entropy": 0.9294494748115539, "incre_win_rate": 0.16216216216216217, "step": 233}
{"time": 1767152250.74807, "phase": "train", "update": 234, "total_env_steps": 748800, "episode_reward": 0.15826520323753357, "value_loss": 0.03728957548737526, "policy_loss": -0.0013370067867057855, "dist_entropy": 0.8901844501495362, "actor_grad_norm": 0.10239306837320328, "critic_grad_norm": 0.5095470547676086, "ratio": 1.00020170211792, "entropy": 0.8901844501495362, "incre_win_rate": 0.24324324324324326, "step": 234}
{"time": 1767152255.0471714, "phase": "train", "update": 235, "total_env_steps": 752000, "episode_reward": 0.14805567264556885, "value_loss": 0.023890887573361396, "policy_loss": -0.0010233051186755659, "dist_entropy": 0.9036646962165833, "actor_grad_norm": 0.11750098317861557, "critic_grad_norm": 0.20953841507434845, "ratio": 1.0001163482666016, "entropy": 0.9036646962165833, "incre_win_rate": 0.05714285714285714, "step": 235}
{"time": 1767152259.3421311, "phase": "train", "update": 236, "total_env_steps": 755200, "episode_reward": 0.15788958966732025, "value_loss": 0.034065235406160355, "policy_loss": -0.001087723464591761, "dist_entropy": 0.9135101556777954, "actor_grad_norm": 0.0990370661020279, "critic_grad_norm": 0.24964724481105804, "ratio": 0.9999377131462097, "entropy": 0.9135101556777954, "incre_win_rate": 0.2222222222222222, "step": 236}
{"time": 1767152263.631479, "phase": "train", "update": 237, "total_env_steps": 758400, "episode_reward": 0.149539515376091, "value_loss": 0.027238522842526435, "policy_loss": -0.0009007096200772224, "dist_entropy": 0.9244193434715271, "actor_grad_norm": 0.15957827866077423, "critic_grad_norm": 0.14454221725463867, "ratio": 0.9998602867126465, "entropy": 0.9244193434715271, "incre_win_rate": 0.02631578947368421, "step": 237}
{"time": 1767152268.2371051, "phase": "train", "update": 238, "total_env_steps": 761600, "episode_reward": 0.14412355422973633, "value_loss": 0.033304470032453536, "policy_loss": -0.0009890170102991648, "dist_entropy": 0.91629079580307, "actor_grad_norm": 0.09224098175764084, "critic_grad_norm": 0.10760774463415146, "ratio": 1.0001072883605957, "entropy": 0.91629079580307, "incre_win_rate": 0.17142857142857143, "step": 238}
{"time": 1767152272.6729572, "phase": "train", "update": 239, "total_env_steps": 764800, "episode_reward": 0.16458970308303833, "value_loss": 0.03415698781609535, "policy_loss": -0.0011844052861562204, "dist_entropy": 0.9143337726593017, "actor_grad_norm": 0.08729197829961777, "critic_grad_norm": 0.2814979553222656, "ratio": 0.9999272227287292, "entropy": 0.9143337726593017, "incre_win_rate": 0.20588235294117646, "step": 239}
{"time": 1767152277.0173578, "phase": "train", "update": 240, "total_env_steps": 768000, "episode_reward": 0.15272092819213867, "value_loss": 0.03305717781186104, "policy_loss": -0.001091918252604529, "dist_entropy": 0.9434167146682739, "actor_grad_norm": 0.07649631798267365, "critic_grad_norm": 0.369917094707489, "ratio": 1.0003694295883179, "entropy": 0.9434167146682739, "incre_win_rate": 0.20512820512820512, "step": 240}
{"time": 1767152281.2766814, "phase": "train", "update": 241, "total_env_steps": 771200, "episode_reward": 0.16256673634052277, "value_loss": 0.03384760320186615, "policy_loss": -0.00113361312143212, "dist_entropy": 0.917544162273407, "actor_grad_norm": 0.08930718898773193, "critic_grad_norm": 0.41121774911880493, "ratio": 1.0001896619796753, "entropy": 0.917544162273407, "incre_win_rate": 0.2903225806451613, "step": 241}
{"time": 1767152295.3725266, "phase": "eval", "update": 241, "total_env_steps": 771200, "eval_win_rate": 0.28125, "eval_episode_reward": 14.919339817880793, "step": 241}
{"time": 1767152299.586013, "phase": "train", "update": 242, "total_env_steps": 774400, "episode_reward": 0.1549772322177887, "value_loss": 0.03039267286658287, "policy_loss": -0.001560759435906256, "dist_entropy": 0.9757176876068115, "actor_grad_norm": 0.08022135496139526, "critic_grad_norm": 0.28992268443107605, "ratio": 0.999914288520813, "entropy": 0.9757176876068115, "incre_win_rate": 0.1891891891891892, "step": 242}
{"time": 1767152303.8447564, "phase": "train", "update": 243, "total_env_steps": 777600, "episode_reward": 0.15227441489696503, "value_loss": 0.04531245529651642, "policy_loss": -0.0009034728970549466, "dist_entropy": 0.9338691830635071, "actor_grad_norm": 0.08351054787635803, "critic_grad_norm": 0.3138582110404968, "ratio": 1.0005011558532715, "entropy": 0.9338691830635071, "incre_win_rate": 0.16666666666666666, "step": 243}
{"time": 1767152308.1249554, "phase": "train", "update": 244, "total_env_steps": 780800, "episode_reward": 0.15392902493476868, "value_loss": 0.028846450522542, "policy_loss": -0.0008417207887411848, "dist_entropy": 0.9471443176269532, "actor_grad_norm": 0.06299041956663132, "critic_grad_norm": 0.19128739833831787, "ratio": 1.0001137256622314, "entropy": 0.9471443176269532, "incre_win_rate": 0.10526315789473684, "step": 244}
{"time": 1767152312.4242482, "phase": "train", "update": 245, "total_env_steps": 784000, "episode_reward": 0.15527008473873138, "value_loss": 0.03301241472363472, "policy_loss": -0.0013649036518890156, "dist_entropy": 0.9627703189849853, "actor_grad_norm": 0.08596263825893402, "critic_grad_norm": 0.23771505057811737, "ratio": 0.9998399615287781, "entropy": 0.9627703189849853, "incre_win_rate": 0.13513513513513514, "step": 245}
{"time": 1767152316.704514, "phase": "train", "update": 246, "total_env_steps": 787200, "episode_reward": 0.14731530845165253, "value_loss": 0.03747302815318108, "policy_loss": -0.0012498277951635828, "dist_entropy": 0.9444689273834228, "actor_grad_norm": 0.0749511569738388, "critic_grad_norm": 0.27917444705963135, "ratio": 1.0001325607299805, "entropy": 0.9444689273834228, "incre_win_rate": 0.13513513513513514, "step": 246}
{"time": 1767152321.018361, "phase": "train", "update": 247, "total_env_steps": 790400, "episode_reward": 0.15136383473873138, "value_loss": 0.03851947262883186, "policy_loss": -0.0011424475801742773, "dist_entropy": 0.9573891520500183, "actor_grad_norm": 0.08717624098062515, "critic_grad_norm": 0.13018466532230377, "ratio": 0.9998799562454224, "entropy": 0.9573891520500183, "incre_win_rate": 0.15789473684210525, "step": 247}
{"time": 1767152325.2829835, "phase": "train", "update": 248, "total_env_steps": 793600, "episode_reward": 0.1476852297782898, "value_loss": 0.030015519261360167, "policy_loss": -0.0011923895906646108, "dist_entropy": 0.9551921248435974, "actor_grad_norm": 0.09196518361568451, "critic_grad_norm": 0.1642833799123764, "ratio": 1.0002434253692627, "entropy": 0.9551921248435974, "incre_win_rate": 0.08333333333333333, "step": 248}
{"time": 1767152329.575976, "phase": "train", "update": 249, "total_env_steps": 796800, "episode_reward": 0.14763762056827545, "value_loss": 0.04956945925951004, "policy_loss": -0.0010086676133781226, "dist_entropy": 0.9455190300941467, "actor_grad_norm": 0.12105150520801544, "critic_grad_norm": 0.19055595993995667, "ratio": 1.000258207321167, "entropy": 0.9455190300941467, "incre_win_rate": 0.16216216216216217, "step": 249}
{"time": 1767152333.834494, "phase": "train", "update": 250, "total_env_steps": 800000, "episode_reward": 0.15853993594646454, "value_loss": 0.0318745456635952, "policy_loss": -0.0009682620214210402, "dist_entropy": 0.9571633100509643, "actor_grad_norm": 0.08650233596563339, "critic_grad_norm": 0.20097127556800842, "ratio": 1.0001190900802612, "entropy": 0.9571633100509643, "incre_win_rate": 0.10526315789473684, "step": 250}
{"time": 1767152338.3775098, "phase": "train", "update": 251, "total_env_steps": 803200, "episode_reward": 0.15872153639793396, "value_loss": 0.03377521857619285, "policy_loss": -0.0009094842921925306, "dist_entropy": 0.9485438585281372, "actor_grad_norm": 0.10486455261707306, "critic_grad_norm": 0.1541241556406021, "ratio": 1.000190019607544, "entropy": 0.9485438585281372, "incre_win_rate": 0.21621621621621623, "step": 251}
{"time": 1767152342.597823, "phase": "train", "update": 252, "total_env_steps": 806400, "episode_reward": 0.16112220287322998, "value_loss": 0.03741235136985779, "policy_loss": -0.0009704674113137912, "dist_entropy": 0.909666645526886, "actor_grad_norm": 0.054853200912475586, "critic_grad_norm": 0.14107881486415863, "ratio": 0.9997501373291016, "entropy": 0.909666645526886, "incre_win_rate": 0.23076923076923078, "step": 252}
{"time": 1767152346.7951314, "phase": "train", "update": 253, "total_env_steps": 809600, "episode_reward": 0.15440449118614197, "value_loss": 0.0459039494395256, "policy_loss": -0.0012846348149189168, "dist_entropy": 0.9252533912658691, "actor_grad_norm": 0.09819541126489639, "critic_grad_norm": 0.22602000832557678, "ratio": 0.9998939633369446, "entropy": 0.9252533912658691, "incre_win_rate": 0.19444444444444445, "step": 253}
{"time": 1767152351.1794493, "phase": "train", "update": 254, "total_env_steps": 812800, "episode_reward": 0.15126706659793854, "value_loss": 0.028668640926480294, "policy_loss": -0.001171305632347952, "dist_entropy": 0.9289772391319275, "actor_grad_norm": 0.10216894000768661, "critic_grad_norm": 0.3849201798439026, "ratio": 0.999912679195404, "entropy": 0.9289772391319275, "incre_win_rate": 0.15789473684210525, "step": 254}
{"time": 1767152355.4466197, "phase": "train", "update": 255, "total_env_steps": 816000, "episode_reward": 0.15436621010303497, "value_loss": 0.030196044221520425, "policy_loss": -0.0013445512420624083, "dist_entropy": 0.9404453754425048, "actor_grad_norm": 0.09522121399641037, "critic_grad_norm": 0.2907096743583679, "ratio": 0.9999287724494934, "entropy": 0.9404453754425048, "incre_win_rate": 0.1111111111111111, "step": 255}
{"time": 1767152359.711568, "phase": "train", "update": 256, "total_env_steps": 819200, "episode_reward": 0.15677618980407715, "value_loss": 0.02958388887345791, "policy_loss": -0.0009838066335788654, "dist_entropy": 0.9339771509170532, "actor_grad_norm": 0.08671882748603821, "critic_grad_norm": 0.26754480600357056, "ratio": 0.999795138835907, "entropy": 0.9339771509170532, "incre_win_rate": 0.15384615384615385, "step": 256}
{"time": 1767152363.9946818, "phase": "train", "update": 257, "total_env_steps": 822400, "episode_reward": 0.15362168848514557, "value_loss": 0.026969343051314355, "policy_loss": -0.001267095734586121, "dist_entropy": 0.9404892921447754, "actor_grad_norm": 0.08178229629993439, "critic_grad_norm": 0.30084192752838135, "ratio": 1.0000965595245361, "entropy": 0.9404892921447754, "incre_win_rate": 0.07692307692307693, "step": 257}
{"time": 1767152368.2789962, "phase": "train", "update": 258, "total_env_steps": 825600, "episode_reward": 0.15238720178604126, "value_loss": 0.02815351039171219, "policy_loss": -0.0011284677113867047, "dist_entropy": 0.955313217639923, "actor_grad_norm": 0.07761259377002716, "critic_grad_norm": 0.19173628091812134, "ratio": 1.0000218152999878, "entropy": 0.955313217639923, "incre_win_rate": 0.13157894736842105, "step": 258}
{"time": 1767152372.5561526, "phase": "train", "update": 259, "total_env_steps": 828800, "episode_reward": 0.15634675323963165, "value_loss": 0.024759697914123534, "policy_loss": -0.0010508000650510496, "dist_entropy": 0.9633046746253967, "actor_grad_norm": 0.10582419484853745, "critic_grad_norm": 0.21818523108959198, "ratio": 1.0000633001327515, "entropy": 0.9633046746253967, "incre_win_rate": 0.05405405405405406, "step": 259}
{"time": 1767152376.7871578, "phase": "train", "update": 260, "total_env_steps": 832000, "episode_reward": 0.1596999168395996, "value_loss": 0.03157592788338661, "policy_loss": -0.0012466803508925039, "dist_entropy": 0.9372378826141358, "actor_grad_norm": 0.08951126784086227, "critic_grad_norm": 0.245689257979393, "ratio": 1.0000003576278687, "entropy": 0.9372378826141358, "incre_win_rate": 0.1891891891891892, "step": 260}
{"time": 1767152381.0166876, "phase": "train", "update": 261, "total_env_steps": 835200, "episode_reward": 0.15954522788524628, "value_loss": 0.0316507026553154, "policy_loss": -0.0013173691418217003, "dist_entropy": 0.9237301468849182, "actor_grad_norm": 0.09609337151050568, "critic_grad_norm": 0.16497944295406342, "ratio": 1.000195026397705, "entropy": 0.9237301468849182, "incre_win_rate": 0.2702702702702703, "step": 261}
{"time": 1767152395.762275, "phase": "eval", "update": 261, "total_env_steps": 835200, "eval_win_rate": 0.1875, "eval_episode_reward": 13.670943708609268, "step": 261}
{"time": 1767152399.9838433, "phase": "train", "update": 262, "total_env_steps": 838400, "episode_reward": 0.17134571075439453, "value_loss": 0.03749657869338989, "policy_loss": -0.001322469781447211, "dist_entropy": 0.9298841238021851, "actor_grad_norm": 0.16987673938274384, "critic_grad_norm": 0.10855865478515625, "ratio": 0.9998956918716431, "entropy": 0.9298841238021851, "incre_win_rate": 0.32432432432432434, "step": 262}
{"time": 1767152404.2479143, "phase": "train", "update": 263, "total_env_steps": 841600, "episode_reward": 0.17058826982975006, "value_loss": 0.03209531120955944, "policy_loss": -0.0010276923343507604, "dist_entropy": 0.9259385943412781, "actor_grad_norm": 0.12485053390264511, "critic_grad_norm": 0.17897717654705048, "ratio": 0.9998526573181152, "entropy": 0.9259385943412781, "incre_win_rate": 0.24324324324324326, "step": 263}
{"time": 1767152408.4227433, "phase": "train", "update": 264, "total_env_steps": 844800, "episode_reward": 0.1534794121980667, "value_loss": 0.03146390169858933, "policy_loss": -0.0012523752413344802, "dist_entropy": 0.8927201390266418, "actor_grad_norm": 0.15142855048179626, "critic_grad_norm": 0.27195438742637634, "ratio": 0.9998537302017212, "entropy": 0.8927201390266418, "incre_win_rate": 0.18421052631578946, "step": 264}
{"time": 1767152412.6583476, "phase": "train", "update": 265, "total_env_steps": 848000, "episode_reward": 0.1570974737405777, "value_loss": 0.03310340866446495, "policy_loss": -0.00139218134777086, "dist_entropy": 0.9457181930541992, "actor_grad_norm": 0.10353823751211166, "critic_grad_norm": 0.3427879512310028, "ratio": 1.0001050233840942, "entropy": 0.9457181930541992, "incre_win_rate": 0.14705882352941177, "step": 265}
{"time": 1767152416.8441741, "phase": "train", "update": 266, "total_env_steps": 851200, "episode_reward": 0.16891971230506897, "value_loss": 0.03477824777364731, "policy_loss": -0.0009907328795783598, "dist_entropy": 0.9329192638397217, "actor_grad_norm": 0.09865661710500717, "critic_grad_norm": 0.4489423930644989, "ratio": 1.0003048181533813, "entropy": 0.9329192638397217, "incre_win_rate": 0.3333333333333333, "step": 266}
{"time": 1767152421.0628722, "phase": "train", "update": 267, "total_env_steps": 854400, "episode_reward": 0.15431860089302063, "value_loss": 0.03013310320675373, "policy_loss": -0.0009901198696748547, "dist_entropy": 0.9244792580604553, "actor_grad_norm": 0.10770530998706818, "critic_grad_norm": 0.3748980462551117, "ratio": 0.9997854232788086, "entropy": 0.9244792580604553, "incre_win_rate": 0.15384615384615385, "step": 267}
{"time": 1767152425.2737713, "phase": "train", "update": 268, "total_env_steps": 857600, "episode_reward": 0.14647506177425385, "value_loss": 0.028415809199213982, "policy_loss": -0.0015089572796469497, "dist_entropy": 0.9229007482528686, "actor_grad_norm": 0.11842509359121323, "critic_grad_norm": 0.16686992347240448, "ratio": 0.9997602701187134, "entropy": 0.9229007482528686, "incre_win_rate": 0.12121212121212122, "step": 268}
{"time": 1767152429.5322576, "phase": "train", "update": 269, "total_env_steps": 860800, "episode_reward": 0.16093800961971283, "value_loss": 0.03127319104969502, "policy_loss": -0.0006717037413061178, "dist_entropy": 0.9037847757339478, "actor_grad_norm": 0.08823057264089584, "critic_grad_norm": 0.11950527876615524, "ratio": 0.9999305009841919, "entropy": 0.9037847757339478, "incre_win_rate": 0.25, "step": 269}
{"time": 1767152433.7638514, "phase": "train", "update": 270, "total_env_steps": 864000, "episode_reward": 0.1555655151605606, "value_loss": 0.03062576986849308, "policy_loss": -0.0011231260616192174, "dist_entropy": 0.912982952594757, "actor_grad_norm": 0.09694226831197739, "critic_grad_norm": 0.16213971376419067, "ratio": 1.0000395774841309, "entropy": 0.912982952594757, "incre_win_rate": 0.21052631578947367, "step": 270}
{"time": 1767152438.056108, "phase": "train", "update": 271, "total_env_steps": 867200, "episode_reward": 0.15396523475646973, "value_loss": 0.027510106936097144, "policy_loss": -0.0010554166391473884, "dist_entropy": 0.9040868401527404, "actor_grad_norm": 0.12988345324993134, "critic_grad_norm": 0.17209556698799133, "ratio": 1.000268816947937, "entropy": 0.9040868401527404, "incre_win_rate": 0.08571428571428572, "step": 271}
{"time": 1767152442.3386264, "phase": "train", "update": 272, "total_env_steps": 870400, "episode_reward": 0.16429118812084198, "value_loss": 0.030936353281140326, "policy_loss": -0.0009473302155534214, "dist_entropy": 0.9165653109550476, "actor_grad_norm": 0.0889529213309288, "critic_grad_norm": 0.17141611874103546, "ratio": 0.9996539354324341, "entropy": 0.9165653109550476, "incre_win_rate": 0.3157894736842105, "step": 272}
{"time": 1767152446.479328, "phase": "train", "update": 273, "total_env_steps": 873600, "episode_reward": 0.16540977358818054, "value_loss": 0.026926909014582633, "policy_loss": -0.0008309455532469201, "dist_entropy": 0.892657458782196, "actor_grad_norm": 0.09447211027145386, "critic_grad_norm": 0.37308451533317566, "ratio": 0.9998133778572083, "entropy": 0.892657458782196, "incre_win_rate": 0.2777777777777778, "step": 273}
{"time": 1767152450.650459, "phase": "train", "update": 274, "total_env_steps": 876800, "episode_reward": 0.1679878979921341, "value_loss": 0.031011369079351425, "policy_loss": -0.0012224355484377724, "dist_entropy": 0.9022397994995117, "actor_grad_norm": 0.2020144909620285, "critic_grad_norm": 0.24372123181819916, "ratio": 1.0001633167266846, "entropy": 0.9022397994995117, "incre_win_rate": 0.2857142857142857, "step": 274}
{"time": 1767152454.8436108, "phase": "train", "update": 275, "total_env_steps": 880000, "episode_reward": 0.1595172882080078, "value_loss": 0.034034702181816104, "policy_loss": -0.0010916608013076257, "dist_entropy": 0.9082726955413818, "actor_grad_norm": 0.11504849046468735, "critic_grad_norm": 0.19421297311782837, "ratio": 0.9998905062675476, "entropy": 0.9082726955413818, "incre_win_rate": 0.2571428571428571, "step": 275}
{"time": 1767152459.0953476, "phase": "train", "update": 276, "total_env_steps": 883200, "episode_reward": 0.15911786258220673, "value_loss": 0.030996056646108626, "policy_loss": -0.0013350248291597922, "dist_entropy": 0.8953777194023133, "actor_grad_norm": 0.11706842482089996, "critic_grad_norm": 0.14154748618602753, "ratio": 0.9997366070747375, "entropy": 0.8953777194023133, "incre_win_rate": 0.34285714285714286, "step": 276}
{"time": 1767152463.3178315, "phase": "train", "update": 277, "total_env_steps": 886400, "episode_reward": 0.177567258477211, "value_loss": 0.03117203079164028, "policy_loss": -0.0007053275132784976, "dist_entropy": 0.8822471976280213, "actor_grad_norm": 0.13219903409481049, "critic_grad_norm": 0.37213823199272156, "ratio": 0.9999305605888367, "entropy": 0.8822471976280213, "incre_win_rate": 0.4444444444444444, "step": 277}
{"time": 1767152467.6224296, "phase": "train", "update": 278, "total_env_steps": 889600, "episode_reward": 0.17765213549137115, "value_loss": 0.02986990176141262, "policy_loss": -0.0008147241133744209, "dist_entropy": 0.9032625913619995, "actor_grad_norm": 0.08459156006574631, "critic_grad_norm": 0.3445187509059906, "ratio": 0.9998458027839661, "entropy": 0.9032625913619995, "incre_win_rate": 0.38235294117647056, "step": 278}
{"time": 1767152471.8558526, "phase": "train", "update": 279, "total_env_steps": 892800, "episode_reward": 0.1601603925228119, "value_loss": 0.035203592479228975, "policy_loss": -0.0009786141981777518, "dist_entropy": 0.9098365187644959, "actor_grad_norm": 0.08391128480434418, "critic_grad_norm": 0.26479145884513855, "ratio": 0.999916672706604, "entropy": 0.9098365187644959, "incre_win_rate": 0.25, "step": 279}
{"time": 1767152476.0513237, "phase": "train", "update": 280, "total_env_steps": 896000, "episode_reward": 0.15063224732875824, "value_loss": 0.028586763143539428, "policy_loss": -0.0012810315377834059, "dist_entropy": 0.9103947162628174, "actor_grad_norm": 0.11254233121871948, "critic_grad_norm": 0.2156650573015213, "ratio": 0.9998319745063782, "entropy": 0.9103947162628174, "incre_win_rate": 0.18181818181818182, "step": 280}
{"time": 1767152480.2559018, "phase": "train", "update": 281, "total_env_steps": 899200, "episode_reward": 0.14896421134471893, "value_loss": 0.027279579639434816, "policy_loss": -0.0016303790237273575, "dist_entropy": 0.9479300618171692, "actor_grad_norm": 0.14520731568336487, "critic_grad_norm": 0.20460867881774902, "ratio": 0.999747097492218, "entropy": 0.9479300618171692, "incre_win_rate": 0.21212121212121213, "step": 281}
{"time": 1767152492.7809327, "phase": "eval", "update": 281, "total_env_steps": 899200, "eval_win_rate": 0.4375, "eval_episode_reward": 16.347940811258276, "step": 281}
{"time": 1767152497.0176835, "phase": "train", "update": 282, "total_env_steps": 902400, "episode_reward": 0.1609545648097992, "value_loss": 0.03043495789170265, "policy_loss": -0.0007559672389639615, "dist_entropy": 0.9152786016464234, "actor_grad_norm": 0.1551225483417511, "critic_grad_norm": 0.19222965836524963, "ratio": 0.9999001622200012, "entropy": 0.9152786016464234, "incre_win_rate": 0.19444444444444445, "step": 282}
{"time": 1767152501.2930567, "phase": "train", "update": 283, "total_env_steps": 905600, "episode_reward": 0.17396162450313568, "value_loss": 0.033070582896471024, "policy_loss": -0.0010116843316907876, "dist_entropy": 0.902219808101654, "actor_grad_norm": 0.1298999786376953, "critic_grad_norm": 0.2003270387649536, "ratio": 1.00007164478302, "entropy": 0.902219808101654, "incre_win_rate": 0.4117647058823529, "step": 283}
{"time": 1767152505.5777404, "phase": "train", "update": 284, "total_env_steps": 908800, "episode_reward": 0.18161840736865997, "value_loss": 0.036722023785114286, "policy_loss": -0.0007452682112173648, "dist_entropy": 0.8836650013923645, "actor_grad_norm": 0.10652442276477814, "critic_grad_norm": 0.30812564492225647, "ratio": 0.9999885559082031, "entropy": 0.8836650013923645, "incre_win_rate": 0.5833333333333334, "step": 284}
{"time": 1767152509.890693, "phase": "train", "update": 285, "total_env_steps": 912000, "episode_reward": 0.15538078546524048, "value_loss": 0.04312841519713402, "policy_loss": -0.001319460100949499, "dist_entropy": 0.8987461805343628, "actor_grad_norm": 0.15531621873378754, "critic_grad_norm": 0.28389132022857666, "ratio": 0.9998509287834167, "entropy": 0.8987461805343628, "incre_win_rate": 0.21875, "step": 285}
{"time": 1767152514.077986, "phase": "train", "update": 286, "total_env_steps": 915200, "episode_reward": 0.16150712966918945, "value_loss": 0.028326809778809546, "policy_loss": -0.0011567771622040368, "dist_entropy": 0.8970774173736572, "actor_grad_norm": 0.101803719997406, "critic_grad_norm": 0.28818002343177795, "ratio": 1.0000722408294678, "entropy": 0.8970774173736572, "incre_win_rate": 0.2631578947368421, "step": 286}
{"time": 1767152518.2902324, "phase": "train", "update": 287, "total_env_steps": 918400, "episode_reward": 0.1753290593624115, "value_loss": 0.028784070163965225, "policy_loss": -0.0008937489843319213, "dist_entropy": 0.9167734146118164, "actor_grad_norm": 0.1265316903591156, "critic_grad_norm": 0.2300097495317459, "ratio": 0.9999750256538391, "entropy": 0.9167734146118164, "incre_win_rate": 0.3235294117647059, "step": 287}
{"time": 1767152522.5308607, "phase": "train", "update": 288, "total_env_steps": 921600, "episode_reward": 0.17927774786949158, "value_loss": 0.03563763201236725, "policy_loss": -0.0010549723733340954, "dist_entropy": 0.8811269640922547, "actor_grad_norm": 0.11073475331068039, "critic_grad_norm": 0.37773892283439636, "ratio": 0.9999628067016602, "entropy": 0.8811269640922547, "incre_win_rate": 0.4857142857142857, "step": 288}
{"time": 1767152526.8258686, "phase": "train", "update": 289, "total_env_steps": 924800, "episode_reward": 0.16962696611881256, "value_loss": 0.03195045180618763, "policy_loss": -0.0012459015374957972, "dist_entropy": 0.9057836651802063, "actor_grad_norm": 0.15411698818206787, "critic_grad_norm": 0.2626461684703827, "ratio": 1.0000361204147339, "entropy": 0.9057836651802063, "incre_win_rate": 0.3611111111111111, "step": 289}
{"time": 1767152531.048172, "phase": "train", "update": 290, "total_env_steps": 928000, "episode_reward": 0.16369205713272095, "value_loss": 0.034232760220766066, "policy_loss": -0.0013337007603226425, "dist_entropy": 0.9215033650398254, "actor_grad_norm": 0.11396767944097519, "critic_grad_norm": 0.352861225605011, "ratio": 1.000056505203247, "entropy": 0.9215033650398254, "incre_win_rate": 0.2777777777777778, "step": 290}
{"time": 1767152535.275992, "phase": "train", "update": 291, "total_env_steps": 931200, "episode_reward": 0.16609789431095123, "value_loss": 0.029358845949172974, "policy_loss": -0.0009457828122208412, "dist_entropy": 0.8960391044616699, "actor_grad_norm": 0.07973986119031906, "critic_grad_norm": 0.13457901775836945, "ratio": 1.0000154972076416, "entropy": 0.8960391044616699, "incre_win_rate": 0.3142857142857143, "step": 291}
{"time": 1767152539.499678, "phase": "train", "update": 292, "total_env_steps": 934400, "episode_reward": 0.16753776371479034, "value_loss": 0.030104316771030426, "policy_loss": -0.001167827270370303, "dist_entropy": 0.8985116958618165, "actor_grad_norm": 0.09366186708211899, "critic_grad_norm": 0.10363584756851196, "ratio": 1.0000723600387573, "entropy": 0.8985116958618165, "incre_win_rate": 0.3142857142857143, "step": 292}
{"time": 1767152543.695632, "phase": "train", "update": 293, "total_env_steps": 937600, "episode_reward": 0.1616535633802414, "value_loss": 0.029301798716187478, "policy_loss": -0.0013004216739318508, "dist_entropy": 0.9025143623352051, "actor_grad_norm": 0.09052346646785736, "critic_grad_norm": 0.212781623005867, "ratio": 1.0003695487976074, "entropy": 0.9025143623352051, "incre_win_rate": 0.2647058823529412, "step": 293}
{"time": 1767152547.9601371, "phase": "train", "update": 294, "total_env_steps": 940800, "episode_reward": 0.17084644734859467, "value_loss": 0.03998298570513725, "policy_loss": -0.0012644776408606618, "dist_entropy": 0.8796988487243652, "actor_grad_norm": 0.11163156479597092, "critic_grad_norm": 0.280020147562027, "ratio": 0.9999789595603943, "entropy": 0.8796988487243652, "incre_win_rate": 0.36363636363636365, "step": 294}
{"time": 1767152552.176502, "phase": "train", "update": 295, "total_env_steps": 944000, "episode_reward": 0.1848287433385849, "value_loss": 0.03372598364949227, "policy_loss": -0.0009063108011538645, "dist_entropy": 0.8797649502754211, "actor_grad_norm": 0.1351144164800644, "critic_grad_norm": 0.3864470422267914, "ratio": 0.9997119307518005, "entropy": 0.8797649502754211, "incre_win_rate": 0.5135135135135135, "step": 295}
{"time": 1767152556.405271, "phase": "train", "update": 296, "total_env_steps": 947200, "episode_reward": 0.1640174835920334, "value_loss": 0.02871135175228119, "policy_loss": -0.0007972825713636666, "dist_entropy": 0.8585338115692138, "actor_grad_norm": 0.13877129554748535, "critic_grad_norm": 0.2467646598815918, "ratio": 1.0001076459884644, "entropy": 0.8585338115692138, "incre_win_rate": 0.2571428571428571, "step": 296}
{"time": 1767152560.6887577, "phase": "train", "update": 297, "total_env_steps": 950400, "episode_reward": 0.16634108126163483, "value_loss": 0.02962210737168789, "policy_loss": -0.001244929267252104, "dist_entropy": 0.89594886302948, "actor_grad_norm": 0.18501774966716766, "critic_grad_norm": 0.20900069177150726, "ratio": 0.9999530911445618, "entropy": 0.89594886302948, "incre_win_rate": 0.2222222222222222, "step": 297}
{"time": 1767152564.9024086, "phase": "train", "update": 298, "total_env_steps": 953600, "episode_reward": 0.17028352618217468, "value_loss": 0.03071618638932705, "policy_loss": -0.0009916200855695223, "dist_entropy": 0.8636698961257935, "actor_grad_norm": 0.13641849160194397, "critic_grad_norm": 0.2041708081960678, "ratio": 0.9999350905418396, "entropy": 0.8636698961257935, "incre_win_rate": 0.4166666666666667, "step": 298}
{"time": 1767152569.1832654, "phase": "train", "update": 299, "total_env_steps": 956800, "episode_reward": 0.17692777514457703, "value_loss": 0.027757196500897408, "policy_loss": -0.0011878844582064118, "dist_entropy": 0.8688315987586975, "actor_grad_norm": 0.12953002750873566, "critic_grad_norm": 0.38563355803489685, "ratio": 0.9998213052749634, "entropy": 0.8688315987586975, "incre_win_rate": 0.45454545454545453, "step": 299}
{"time": 1767152573.4174902, "phase": "train", "update": 300, "total_env_steps": 960000, "episode_reward": 0.18130847811698914, "value_loss": 0.029003336280584335, "policy_loss": -0.0009299512460215098, "dist_entropy": 0.853544282913208, "actor_grad_norm": 0.12347616255283356, "critic_grad_norm": 0.2892548739910126, "ratio": 0.9998499751091003, "entropy": 0.853544282913208, "incre_win_rate": 0.4857142857142857, "step": 300}
{"time": 1767152577.6897604, "phase": "train", "update": 301, "total_env_steps": 963200, "episode_reward": 0.15850943326950073, "value_loss": 0.029370731487870217, "policy_loss": -0.0010643556843875856, "dist_entropy": 0.9032373189926147, "actor_grad_norm": 0.1343430131673813, "critic_grad_norm": 0.38409504294395447, "ratio": 0.9997197389602661, "entropy": 0.9032373189926147, "incre_win_rate": 0.28125, "step": 301}
{"time": 1767152590.4880648, "phase": "eval", "update": 301, "total_env_steps": 963200, "eval_win_rate": 0.5, "eval_episode_reward": 16.328331953642383, "step": 301}
{"time": 1767152594.7428603, "phase": "train", "update": 302, "total_env_steps": 966400, "episode_reward": 0.17827816307544708, "value_loss": 0.033709601312875745, "policy_loss": -0.0010562602090502082, "dist_entropy": 0.894126582145691, "actor_grad_norm": 0.10445568710565567, "critic_grad_norm": 0.24425804615020752, "ratio": 0.9996220469474792, "entropy": 0.894126582145691, "incre_win_rate": 0.4594594594594595, "step": 302}
{"time": 1767152598.8719072, "phase": "train", "update": 303, "total_env_steps": 969600, "episode_reward": 0.15739186108112335, "value_loss": 0.029776090756058693, "policy_loss": -0.0014954416953763428, "dist_entropy": 0.882731294631958, "actor_grad_norm": 0.11009299010038376, "critic_grad_norm": 0.34970811009407043, "ratio": 1.0004385709762573, "entropy": 0.882731294631958, "incre_win_rate": 0.30303030303030304, "step": 303}
{"time": 1767152603.0722952, "phase": "train", "update": 304, "total_env_steps": 972800, "episode_reward": 0.1632983237504959, "value_loss": 0.04701232612133026, "policy_loss": -0.0006696412140058782, "dist_entropy": 0.8735671162605285, "actor_grad_norm": 0.12984392046928406, "critic_grad_norm": 0.29173949360847473, "ratio": 1.0001858472824097, "entropy": 0.8735671162605285, "incre_win_rate": 0.4411764705882353, "step": 304}
{"time": 1767152607.2808416, "phase": "train", "update": 305, "total_env_steps": 976000, "episode_reward": 0.1607796996831894, "value_loss": 0.032735908031463624, "policy_loss": -0.0007834758803383579, "dist_entropy": 0.8858965277671814, "actor_grad_norm": 0.09463942795991898, "critic_grad_norm": 0.11656886339187622, "ratio": 0.9999645352363586, "entropy": 0.8858965277671814, "incre_win_rate": 0.34375, "step": 305}
{"time": 1767152611.500579, "phase": "train", "update": 306, "total_env_steps": 979200, "episode_reward": 0.160909041762352, "value_loss": 0.04322599545121193, "policy_loss": -0.0007914643881807848, "dist_entropy": 0.8970302224159241, "actor_grad_norm": 0.11923778057098389, "critic_grad_norm": 0.2919400632381439, "ratio": 0.9999451041221619, "entropy": 0.8970302224159241, "incre_win_rate": 0.3142857142857143, "step": 306}
{"time": 1767152615.7356503, "phase": "train", "update": 307, "total_env_steps": 982400, "episode_reward": 0.16497725248336792, "value_loss": 0.03545110821723938, "policy_loss": -0.000917266402933592, "dist_entropy": 0.9172757983207702, "actor_grad_norm": 0.07821109145879745, "critic_grad_norm": 0.2700982391834259, "ratio": 0.9994639754295349, "entropy": 0.9172757983207702, "incre_win_rate": 0.3888888888888889, "step": 307}
{"time": 1767152619.984511, "phase": "train", "update": 308, "total_env_steps": 985600, "episode_reward": 0.16214093565940857, "value_loss": 0.030394231155514716, "policy_loss": -0.0011464431473378056, "dist_entropy": 0.927484107017517, "actor_grad_norm": 0.11076076328754425, "critic_grad_norm": 0.26870426535606384, "ratio": 0.9999738931655884, "entropy": 0.927484107017517, "incre_win_rate": 0.3939393939393939, "step": 308}
{"time": 1767152624.1902308, "phase": "train", "update": 309, "total_env_steps": 988800, "episode_reward": 0.14813794195652008, "value_loss": 0.027006515115499497, "policy_loss": -0.0011149981513054463, "dist_entropy": 0.9414424657821655, "actor_grad_norm": 0.13386501371860504, "critic_grad_norm": 0.2422676533460617, "ratio": 1.0002875328063965, "entropy": 0.9414424657821655, "incre_win_rate": 0.14705882352941177, "step": 309}
{"time": 1767152628.4428575, "phase": "train", "update": 310, "total_env_steps": 992000, "episode_reward": 0.169336199760437, "value_loss": 0.03623579889535904, "policy_loss": -0.0014017442778218481, "dist_entropy": 0.97044517993927, "actor_grad_norm": 0.10415688902139664, "critic_grad_norm": 0.23324190080165863, "ratio": 1.0005420446395874, "entropy": 0.97044517993927, "incre_win_rate": 0.34210526315789475, "step": 310}
{"time": 1767152632.625221, "phase": "train", "update": 311, "total_env_steps": 995200, "episode_reward": 0.18394969403743744, "value_loss": 0.03532131016254425, "policy_loss": -0.0009367490453342953, "dist_entropy": 0.9436208844184876, "actor_grad_norm": 0.09073187410831451, "critic_grad_norm": 0.2734449803829193, "ratio": 1.0003550052642822, "entropy": 0.9436208844184876, "incre_win_rate": 0.4358974358974359, "step": 311}
{"time": 1767152636.8237054, "phase": "train", "update": 312, "total_env_steps": 998400, "episode_reward": 0.15874534845352173, "value_loss": 0.037358982115983964, "policy_loss": -0.0011313627913001056, "dist_entropy": 0.9071175932884217, "actor_grad_norm": 0.0980045422911644, "critic_grad_norm": 0.3871743083000183, "ratio": 1.0002657175064087, "entropy": 0.9071175932884217, "incre_win_rate": 0.24242424242424243, "step": 312}
{"time": 1767152641.0820224, "phase": "train", "update": 313, "total_env_steps": 1001600, "episode_reward": 0.17545479536056519, "value_loss": 0.027170132845640182, "policy_loss": -0.0012403003140519786, "dist_entropy": 0.8992397308349609, "actor_grad_norm": 0.10201021283864975, "critic_grad_norm": 0.22999291121959686, "ratio": 0.9998847842216492, "entropy": 0.8992397308349609, "incre_win_rate": 0.3142857142857143, "step": 313}
{"time": 1767152645.3532417, "phase": "train", "update": 314, "total_env_steps": 1004800, "episode_reward": 0.1814238578081131, "value_loss": 0.03635160028934479, "policy_loss": -0.00104504896134614, "dist_entropy": 0.8983871340751648, "actor_grad_norm": 0.09282560646533966, "critic_grad_norm": 0.229709193110466, "ratio": 1.0001343488693237, "entropy": 0.8983871340751648, "incre_win_rate": 0.40540540540540543, "step": 314}
{"time": 1767152649.5312114, "phase": "train", "update": 315, "total_env_steps": 1008000, "episode_reward": 0.18597839772701263, "value_loss": 0.029377726837992668, "policy_loss": -0.0011762424960370054, "dist_entropy": 0.8690875887870788, "actor_grad_norm": 0.11793582886457443, "critic_grad_norm": 0.4898686110973358, "ratio": 1.0000189542770386, "entropy": 0.8690875887870788, "incre_win_rate": 0.6060606060606061, "step": 315}
{"time": 1767152653.7560573, "phase": "train", "update": 316, "total_env_steps": 1011200, "episode_reward": 0.17465904355049133, "value_loss": 0.03221837431192398, "policy_loss": -0.0009434280797592009, "dist_entropy": 0.8985034346580505, "actor_grad_norm": 0.1486188769340515, "critic_grad_norm": 0.3173717260360718, "ratio": 0.9997178912162781, "entropy": 0.8985034346580505, "incre_win_rate": 0.425, "step": 316}
{"time": 1767152657.9187658, "phase": "train", "update": 317, "total_env_steps": 1014400, "episode_reward": 0.16075901687145233, "value_loss": 0.030432240664958955, "policy_loss": -0.0012071021147718852, "dist_entropy": 0.8975780248641968, "actor_grad_norm": 0.1063447967171669, "critic_grad_norm": 0.2954142987728119, "ratio": 1.0000890493392944, "entropy": 0.8975780248641968, "incre_win_rate": 0.2571428571428571, "step": 317}
{"time": 1767152662.035904, "phase": "train", "update": 318, "total_env_steps": 1017600, "episode_reward": 0.16096389293670654, "value_loss": 0.030787718296051026, "policy_loss": -0.0009176845677931311, "dist_entropy": 0.8927319169044494, "actor_grad_norm": 0.09239736199378967, "critic_grad_norm": 0.387818306684494, "ratio": 1.0002003908157349, "entropy": 0.8927319169044494, "incre_win_rate": 0.2727272727272727, "step": 318}
{"time": 1767152666.2657008, "phase": "train", "update": 319, "total_env_steps": 1020800, "episode_reward": 0.18025559186935425, "value_loss": 0.0314470823854208, "policy_loss": -0.0008797626986346785, "dist_entropy": 0.8631134629249573, "actor_grad_norm": 0.08573894947767258, "critic_grad_norm": 0.30990466475486755, "ratio": 0.9999422430992126, "entropy": 0.8631134629249573, "incre_win_rate": 0.4444444444444444, "step": 319}
{"time": 1767152670.4823267, "phase": "train", "update": 320, "total_env_steps": 1024000, "episode_reward": 0.17118531465530396, "value_loss": 0.025054654479026793, "policy_loss": -0.0008155562888386925, "dist_entropy": 0.8591307401657104, "actor_grad_norm": 0.07594030350446701, "critic_grad_norm": 0.3164181113243103, "ratio": 0.9997879266738892, "entropy": 0.8591307401657104, "incre_win_rate": 0.3235294117647059, "step": 320}
{"time": 1767152674.6957927, "phase": "train", "update": 321, "total_env_steps": 1027200, "episode_reward": 0.1724596470594406, "value_loss": 0.030126689374446868, "policy_loss": -0.0010698778189901503, "dist_entropy": 0.8554676532745361, "actor_grad_norm": 0.08186635375022888, "critic_grad_norm": 0.20481935143470764, "ratio": 1.0001506805419922, "entropy": 0.8554676532745361, "incre_win_rate": 0.3783783783783784, "step": 321}
{"time": 1767152686.8462555, "phase": "eval", "update": 321, "total_env_steps": 1027200, "eval_win_rate": 0.53125, "eval_episode_reward": 17.122309602649008, "step": 321}
{"time": 1767152691.0868573, "phase": "train", "update": 322, "total_env_steps": 1030400, "episode_reward": 0.16534149646759033, "value_loss": 0.026996730640530587, "policy_loss": -0.0008512506997214508, "dist_entropy": 0.8674885869026184, "actor_grad_norm": 0.10021956264972687, "critic_grad_norm": 0.11377210915088654, "ratio": 0.9999051094055176, "entropy": 0.8674885869026184, "incre_win_rate": 0.2647058823529412, "step": 322}
{"time": 1767152695.3284483, "phase": "train", "update": 323, "total_env_steps": 1033600, "episode_reward": 0.16916650533676147, "value_loss": 0.02886655703186989, "policy_loss": -0.0010932679551011403, "dist_entropy": 0.8788680672645569, "actor_grad_norm": 0.07648016512393951, "critic_grad_norm": 0.14409056305885315, "ratio": 1.000154733657837, "entropy": 0.8788680672645569, "incre_win_rate": 0.2571428571428571, "step": 323}
{"time": 1767152699.7777765, "phase": "train", "update": 324, "total_env_steps": 1036800, "episode_reward": 0.16763244569301605, "value_loss": 0.0268673337996006, "policy_loss": -0.0009571355197834919, "dist_entropy": 0.8345639824867248, "actor_grad_norm": 0.13272710144519806, "critic_grad_norm": 0.23040592670440674, "ratio": 0.9999960064888, "entropy": 0.8345639824867248, "incre_win_rate": 0.2972972972972973, "step": 324}
{"time": 1767152703.9935772, "phase": "train", "update": 325, "total_env_steps": 1040000, "episode_reward": 0.16796615719795227, "value_loss": 0.02471773624420166, "policy_loss": -0.0008361213774506382, "dist_entropy": 0.8744959354400634, "actor_grad_norm": 0.09244602173566818, "critic_grad_norm": 0.18609558045864105, "ratio": 1.00003182888031, "entropy": 0.8744959354400634, "incre_win_rate": 0.24324324324324326, "step": 325}
{"time": 1767152708.230774, "phase": "train", "update": 326, "total_env_steps": 1043200, "episode_reward": 0.16852131485939026, "value_loss": 0.027467518299818038, "policy_loss": -0.0011354365069255578, "dist_entropy": 0.8528477907180786, "actor_grad_norm": 0.14612089097499847, "critic_grad_norm": 0.1270866096019745, "ratio": 1.0000444650650024, "entropy": 0.8528477907180786, "incre_win_rate": 0.2647058823529412, "step": 326}
{"time": 1767152737.0952175, "phase": "train", "update": 327, "total_env_steps": 1046400, "episode_reward": 0.16574865579605103, "value_loss": 0.06572736650705338, "policy_loss": -0.0009260250351311505, "dist_entropy": 0.8737371802330017, "actor_grad_norm": 0.07388363033533096, "critic_grad_norm": 0.29949304461479187, "ratio": 1.0000877380371094, "entropy": 0.8737371802330017, "incre_win_rate": 0.23529411764705882, "step": 327}
{"time": 1767152741.2906187, "phase": "train", "update": 328, "total_env_steps": 1049600, "episode_reward": 0.16186775267124176, "value_loss": 0.03205173648893833, "policy_loss": -0.001001211234302346, "dist_entropy": 0.8225948214530945, "actor_grad_norm": 0.07451387494802475, "critic_grad_norm": 0.23486338555812836, "ratio": 0.9998381733894348, "entropy": 0.8225948214530945, "incre_win_rate": 0.37142857142857144, "step": 328}
{"time": 1767152745.4674325, "phase": "train", "update": 329, "total_env_steps": 1052800, "episode_reward": 0.17746277153491974, "value_loss": 0.04610511958599091, "policy_loss": -0.0015671641815362847, "dist_entropy": 0.7943666934967041, "actor_grad_norm": 0.14331960678100586, "critic_grad_norm": 0.4777315557003021, "ratio": 0.9998327493667603, "entropy": 0.7943666934967041, "incre_win_rate": 0.3888888888888889, "step": 329}
{"time": 1767152749.6689374, "phase": "train", "update": 330, "total_env_steps": 1056000, "episode_reward": 0.1697055995464325, "value_loss": 0.026764948666095734, "policy_loss": -0.0014052049237491815, "dist_entropy": 0.7878410339355468, "actor_grad_norm": 0.1341378092765808, "critic_grad_norm": 0.3708427846431732, "ratio": 1.0001128911972046, "entropy": 0.7878410339355468, "incre_win_rate": 0.3055555555555556, "step": 330}
{"time": 1767152753.8803108, "phase": "train", "update": 331, "total_env_steps": 1059200, "episode_reward": 0.17010554671287537, "value_loss": 0.030993537977337837, "policy_loss": -0.001004981293691376, "dist_entropy": 0.8096677184104919, "actor_grad_norm": 0.11791155487298965, "critic_grad_norm": 0.19865190982818604, "ratio": 0.9996402859687805, "entropy": 0.8096677184104919, "incre_win_rate": 0.2857142857142857, "step": 331}
{"time": 1767152758.031505, "phase": "train", "update": 332, "total_env_steps": 1062400, "episode_reward": 0.18092870712280273, "value_loss": 0.03163804262876511, "policy_loss": -0.0010248972202653306, "dist_entropy": 0.8099505066871643, "actor_grad_norm": 0.09066829830408096, "critic_grad_norm": 0.14919817447662354, "ratio": 1.0000953674316406, "entropy": 0.8099505066871643, "incre_win_rate": 0.47368421052631576, "step": 332}
{"time": 1767152762.291296, "phase": "train", "update": 333, "total_env_steps": 1065600, "episode_reward": 0.1811661720275879, "value_loss": 0.03116965927183628, "policy_loss": -0.0012803271345831035, "dist_entropy": 0.8443838715553283, "actor_grad_norm": 0.13893209397792816, "critic_grad_norm": 0.31879571080207825, "ratio": 1.0000075101852417, "entropy": 0.8443838715553283, "incre_win_rate": 0.40540540540540543, "step": 333}
{"time": 1767152766.6148095, "phase": "train", "update": 334, "total_env_steps": 1068800, "episode_reward": 0.18815036118030548, "value_loss": 0.03319384381175041, "policy_loss": -0.0009913563719962325, "dist_entropy": 0.8705716133117676, "actor_grad_norm": 0.08910168707370758, "critic_grad_norm": 0.30012401938438416, "ratio": 1.000349760055542, "entropy": 0.8705716133117676, "incre_win_rate": 0.42105263157894735, "step": 334}
{"time": 1767152770.913772, "phase": "train", "update": 335, "total_env_steps": 1072000, "episode_reward": 0.18826884031295776, "value_loss": 0.028269951790571214, "policy_loss": -0.000909219401590633, "dist_entropy": 0.8662240862846374, "actor_grad_norm": 0.09743980318307877, "critic_grad_norm": 0.24947546422481537, "ratio": 1.0002985000610352, "entropy": 0.8662240862846374, "incre_win_rate": 0.4473684210526316, "step": 335}
{"time": 1767152775.136687, "phase": "train", "update": 336, "total_env_steps": 1075200, "episode_reward": 0.18308360874652863, "value_loss": 0.02874636948108673, "policy_loss": -0.0009045006943679823, "dist_entropy": 0.8812243938446045, "actor_grad_norm": 0.11067366600036621, "critic_grad_norm": 0.27215665578842163, "ratio": 0.9995007514953613, "entropy": 0.8812243938446045, "incre_win_rate": 0.4411764705882353, "step": 336}
{"time": 1767152779.4079492, "phase": "train", "update": 337, "total_env_steps": 1078400, "episode_reward": 0.19684083759784698, "value_loss": 0.030995113030076026, "policy_loss": -0.0012903592387480955, "dist_entropy": 0.8621575713157654, "actor_grad_norm": 0.13813087344169617, "critic_grad_norm": 0.18902018666267395, "ratio": 1.0000050067901611, "entropy": 0.8621575713157654, "incre_win_rate": 0.5, "step": 337}
{"time": 1767152783.5975206, "phase": "train", "update": 338, "total_env_steps": 1081600, "episode_reward": 0.18503208458423615, "value_loss": 0.02603127993643284, "policy_loss": -0.0011165038996956867, "dist_entropy": 0.864140248298645, "actor_grad_norm": 0.10502896457910538, "critic_grad_norm": 0.1110570952296257, "ratio": 1.0001100301742554, "entropy": 0.864140248298645, "incre_win_rate": 0.5428571428571428, "step": 338}
{"time": 1767152787.8087623, "phase": "train", "update": 339, "total_env_steps": 1084800, "episode_reward": 0.16385452449321747, "value_loss": 0.02647126540541649, "policy_loss": -0.0009926713052593073, "dist_entropy": 0.8781728506088257, "actor_grad_norm": 0.13898268342018127, "critic_grad_norm": 0.24818308651447296, "ratio": 0.9997901320457458, "entropy": 0.8781728506088257, "incre_win_rate": 0.30303030303030304, "step": 339}
{"time": 1767152792.0126429, "phase": "train", "update": 340, "total_env_steps": 1088000, "episode_reward": 0.15748551487922668, "value_loss": 0.021932217106223107, "policy_loss": -0.0011237826065801926, "dist_entropy": 0.8574763298034668, "actor_grad_norm": 0.15112507343292236, "critic_grad_norm": 0.15983514487743378, "ratio": 0.9998745322227478, "entropy": 0.8574763298034668, "incre_win_rate": 0.3235294117647059, "step": 340}
{"time": 1767152796.2784283, "phase": "train", "update": 341, "total_env_steps": 1091200, "episode_reward": 0.1900418996810913, "value_loss": 0.02670765034854412, "policy_loss": -0.0006174275141901831, "dist_entropy": 0.8560343742370605, "actor_grad_norm": 0.13303689658641815, "critic_grad_norm": 0.18214894831180573, "ratio": 0.9997543692588806, "entropy": 0.8560343742370605, "incre_win_rate": 0.5588235294117647, "step": 341}
{"time": 1767152810.44672, "phase": "eval", "update": 341, "total_env_steps": 1091200, "eval_win_rate": 0.4375, "eval_episode_reward": 16.117032284768207, "step": 341}
{"time": 1767152814.689727, "phase": "train", "update": 342, "total_env_steps": 1094400, "episode_reward": 0.18716834485530853, "value_loss": 0.02757157012820244, "policy_loss": -0.0011663453136684155, "dist_entropy": 0.8628666758537292, "actor_grad_norm": 0.09137820452451706, "critic_grad_norm": 0.1518363058567047, "ratio": 0.9996013641357422, "entropy": 0.8628666758537292, "incre_win_rate": 0.5555555555555556, "step": 342}
{"time": 1767152818.938997, "phase": "train", "update": 343, "total_env_steps": 1097600, "episode_reward": 0.20090749859809875, "value_loss": 0.026407067850232124, "policy_loss": -0.001358389579208108, "dist_entropy": 0.866923725605011, "actor_grad_norm": 0.11160465329885483, "critic_grad_norm": 0.26209557056427, "ratio": 0.9999880790710449, "entropy": 0.866923725605011, "incre_win_rate": 0.6111111111111112, "step": 343}
{"time": 1767152823.2004223, "phase": "train", "update": 344, "total_env_steps": 1100800, "episode_reward": 0.18085627257823944, "value_loss": 0.033237238973379137, "policy_loss": -0.0007774218887192319, "dist_entropy": 0.8555808663368225, "actor_grad_norm": 0.112352155148983, "critic_grad_norm": 0.5792266130447388, "ratio": 1.0000003576278687, "entropy": 0.8555808663368225, "incre_win_rate": 0.5, "step": 344}
{"time": 1767152827.460007, "phase": "train", "update": 345, "total_env_steps": 1104000, "episode_reward": 0.17556394636631012, "value_loss": 0.0387682780623436, "policy_loss": -0.0010814970272043922, "dist_entropy": 0.8803716182708741, "actor_grad_norm": 0.10670774430036545, "critic_grad_norm": 0.7421427369117737, "ratio": 0.9997553825378418, "entropy": 0.8803716182708741, "incre_win_rate": 0.39473684210526316, "step": 345}
{"time": 1767152831.6819458, "phase": "train", "update": 346, "total_env_steps": 1107200, "episode_reward": 0.1748427003622055, "value_loss": 0.028053975477814675, "policy_loss": -0.0011517597282454163, "dist_entropy": 0.8846261978149415, "actor_grad_norm": 0.10072648525238037, "critic_grad_norm": 0.32660984992980957, "ratio": 1.0000494718551636, "entropy": 0.8846261978149415, "incre_win_rate": 0.40540540540540543, "step": 346}
{"time": 1767152835.8986332, "phase": "train", "update": 347, "total_env_steps": 1110400, "episode_reward": 0.18208712339401245, "value_loss": 0.03054591789841652, "policy_loss": -0.0011904648599610824, "dist_entropy": 0.8893834352493286, "actor_grad_norm": 0.13587509095668793, "critic_grad_norm": 0.3005286157131195, "ratio": 0.9998549818992615, "entropy": 0.8893834352493286, "incre_win_rate": 0.4117647058823529, "step": 347}
{"time": 1767152840.1812868, "phase": "train", "update": 348, "total_env_steps": 1113600, "episode_reward": 0.18188999593257904, "value_loss": 0.0289273239672184, "policy_loss": -0.0010776801940380666, "dist_entropy": 0.8641306519508362, "actor_grad_norm": 0.07619088888168335, "critic_grad_norm": 0.3545590043067932, "ratio": 0.9999532103538513, "entropy": 0.8641306519508362, "incre_win_rate": 0.35135135135135137, "step": 348}
{"time": 1767152844.4321518, "phase": "train", "update": 349, "total_env_steps": 1116800, "episode_reward": 0.1775057017803192, "value_loss": 0.026361921802163124, "policy_loss": -0.0012338697768480955, "dist_entropy": 0.841490876674652, "actor_grad_norm": 0.12739670276641846, "critic_grad_norm": 0.1889999359846115, "ratio": 1.0001556873321533, "entropy": 0.841490876674652, "incre_win_rate": 0.4444444444444444, "step": 349}
{"time": 1767152848.6973577, "phase": "train", "update": 350, "total_env_steps": 1120000, "episode_reward": 0.17986547946929932, "value_loss": 0.031086453422904014, "policy_loss": -0.0012211678260129588, "dist_entropy": 0.8563625693321228, "actor_grad_norm": 0.10952593386173248, "critic_grad_norm": 0.3539615571498871, "ratio": 0.9997237324714661, "entropy": 0.8563625693321228, "incre_win_rate": 0.3783783783783784, "step": 350}
{"time": 1767152852.9690592, "phase": "train", "update": 351, "total_env_steps": 1123200, "episode_reward": 0.19773231446743011, "value_loss": 0.027726073563098908, "policy_loss": -0.0013127979397978607, "dist_entropy": 0.8656037092208863, "actor_grad_norm": 0.0932723805308342, "critic_grad_norm": 0.2734362781047821, "ratio": 1.000070571899414, "entropy": 0.8656037092208863, "incre_win_rate": 0.4864864864864865, "step": 351}
{"time": 1767152857.1501842, "phase": "train", "update": 352, "total_env_steps": 1126400, "episode_reward": 0.17596027255058289, "value_loss": 0.029121601209044456, "policy_loss": -0.001179400543320952, "dist_entropy": 0.8268816590309143, "actor_grad_norm": 0.12691155076026917, "critic_grad_norm": 0.14670443534851074, "ratio": 0.9998859763145447, "entropy": 0.8268816590309143, "incre_win_rate": 0.3611111111111111, "step": 352}
{"time": 1767152861.385523, "phase": "train", "update": 353, "total_env_steps": 1129600, "episode_reward": 0.1892285943031311, "value_loss": 0.02220606356859207, "policy_loss": -0.0009090400140394194, "dist_entropy": 0.8200697541236878, "actor_grad_norm": 0.11091303080320358, "critic_grad_norm": 0.1767847090959549, "ratio": 1.0000742673873901, "entropy": 0.8200697541236878, "incre_win_rate": 0.43243243243243246, "step": 353}
{"time": 1767152865.587432, "phase": "train", "update": 354, "total_env_steps": 1132800, "episode_reward": 0.18413959443569183, "value_loss": 0.02465906776487827, "policy_loss": -0.0010665471594609953, "dist_entropy": 0.8401912569999694, "actor_grad_norm": 0.10682668536901474, "critic_grad_norm": 0.16861723363399506, "ratio": 1.0002015829086304, "entropy": 0.8401912569999694, "incre_win_rate": 0.4444444444444444, "step": 354}
{"time": 1767152869.7929242, "phase": "train", "update": 355, "total_env_steps": 1136000, "episode_reward": 0.18598045408725739, "value_loss": 0.022533788159489632, "policy_loss": -0.0007994294186996597, "dist_entropy": 0.8152974128723145, "actor_grad_norm": 0.09032338857650757, "critic_grad_norm": 0.10490047186613083, "ratio": 0.9998347163200378, "entropy": 0.8152974128723145, "incre_win_rate": 0.4166666666666667, "step": 355}
{"time": 1767152874.0509813, "phase": "train", "update": 356, "total_env_steps": 1139200, "episode_reward": 0.18100063502788544, "value_loss": 0.026951091736555098, "policy_loss": -0.0013250972389913685, "dist_entropy": 0.8251907229423523, "actor_grad_norm": 0.09781438857316971, "critic_grad_norm": 0.2868705689907074, "ratio": 1.0000543594360352, "entropy": 0.8251907229423523, "incre_win_rate": 0.35135135135135137, "step": 356}
{"time": 1767152878.293467, "phase": "train", "update": 357, "total_env_steps": 1142400, "episode_reward": 0.18467043340206146, "value_loss": 0.025777485594153403, "policy_loss": -0.0008099158264703643, "dist_entropy": 0.8616696357727051, "actor_grad_norm": 0.09824103116989136, "critic_grad_norm": 0.21395082771778107, "ratio": 1.0000227689743042, "entropy": 0.8616696357727051, "incre_win_rate": 0.3684210526315789, "step": 357}
{"time": 1767152882.5678074, "phase": "train", "update": 358, "total_env_steps": 1145600, "episode_reward": 0.18827657401561737, "value_loss": 0.020312393829226495, "policy_loss": -0.0012623968617304303, "dist_entropy": 0.8324779272079468, "actor_grad_norm": 0.10142536461353302, "critic_grad_norm": 0.10720230638980865, "ratio": 1.0000720024108887, "entropy": 0.8324779272079468, "incre_win_rate": 0.4722222222222222, "step": 358}
{"time": 1767152886.789999, "phase": "train", "update": 359, "total_env_steps": 1148800, "episode_reward": 0.19588421285152435, "value_loss": 0.024676278606057166, "policy_loss": -0.0010606189044054305, "dist_entropy": 0.8581997990608216, "actor_grad_norm": 0.11480966955423355, "critic_grad_norm": 0.15651094913482666, "ratio": 0.9998456835746765, "entropy": 0.8581997990608216, "incre_win_rate": 0.5555555555555556, "step": 359}
{"time": 1767152891.0778084, "phase": "train", "update": 360, "total_env_steps": 1152000, "episode_reward": 0.192112997174263, "value_loss": 0.02696903795003891, "policy_loss": -0.0010554612487730709, "dist_entropy": 0.8321770310401917, "actor_grad_norm": 0.10083825886249542, "critic_grad_norm": 0.11507347971200943, "ratio": 1.000174880027771, "entropy": 0.8321770310401917, "incre_win_rate": 0.5641025641025641, "step": 360}
{"time": 1767152895.3018575, "phase": "train", "update": 361, "total_env_steps": 1155200, "episode_reward": 0.1748577058315277, "value_loss": 0.027662306278944015, "policy_loss": -0.0010371721982288308, "dist_entropy": 0.865692961215973, "actor_grad_norm": 0.11265619099140167, "critic_grad_norm": 0.23198500275611877, "ratio": 1.0000180006027222, "entropy": 0.865692961215973, "incre_win_rate": 0.42424242424242425, "step": 361}
{"time": 1767152910.4392445, "phase": "eval", "update": 361, "total_env_steps": 1155200, "eval_win_rate": 0.25, "eval_episode_reward": 13.91835678807946, "step": 361}
{"time": 1767152914.6815422, "phase": "train", "update": 362, "total_env_steps": 1158400, "episode_reward": 0.17412200570106506, "value_loss": 0.029103567823767662, "policy_loss": -0.0009503855610191181, "dist_entropy": 0.8453130602836609, "actor_grad_norm": 0.10763338953256607, "critic_grad_norm": 0.23854854702949524, "ratio": 1.0000859498977661, "entropy": 0.8453130602836609, "incre_win_rate": 0.4166666666666667, "step": 362}
{"time": 1767152918.9648218, "phase": "train", "update": 363, "total_env_steps": 1161600, "episode_reward": 0.18733909726142883, "value_loss": 0.02466171868145466, "policy_loss": -0.0013918613340500486, "dist_entropy": 0.8571691989898682, "actor_grad_norm": 0.10804276913404465, "critic_grad_norm": 0.1415344774723053, "ratio": 0.9999909400939941, "entropy": 0.8571691989898682, "incre_win_rate": 0.4857142857142857, "step": 363}
{"time": 1767152923.2280211, "phase": "train", "update": 364, "total_env_steps": 1164800, "episode_reward": 0.19295012950897217, "value_loss": 0.028860917314887047, "policy_loss": -0.001063094928446162, "dist_entropy": 0.8258216977119446, "actor_grad_norm": 0.09921334683895111, "critic_grad_norm": 0.12957601249217987, "ratio": 1.0002920627593994, "entropy": 0.8258216977119446, "incre_win_rate": 0.6111111111111112, "step": 364}
{"time": 1767152927.4269783, "phase": "train", "update": 365, "total_env_steps": 1168000, "episode_reward": 0.19043873250484467, "value_loss": 0.026238115131855012, "policy_loss": -0.0013355838427987266, "dist_entropy": 0.8300921201705933, "actor_grad_norm": 0.13904283940792084, "critic_grad_norm": 0.25224870443344116, "ratio": 0.9999470710754395, "entropy": 0.8300921201705933, "incre_win_rate": 0.5945945945945946, "step": 365}
{"time": 1767152931.6246543, "phase": "train", "update": 366, "total_env_steps": 1171200, "episode_reward": 0.19669288396835327, "value_loss": 0.020771804079413415, "policy_loss": -0.0009439487987435768, "dist_entropy": 0.8150216102600097, "actor_grad_norm": 0.11981852352619171, "critic_grad_norm": 0.3235158622264862, "ratio": 1.0000050067901611, "entropy": 0.8150216102600097, "incre_win_rate": 0.696969696969697, "step": 366}
{"time": 1767152935.795351, "phase": "train", "update": 367, "total_env_steps": 1174400, "episode_reward": 0.18310895562171936, "value_loss": 0.0251134917140007, "policy_loss": -0.0012966135522312072, "dist_entropy": 0.8208023309707642, "actor_grad_norm": 0.1284085363149643, "critic_grad_norm": 0.20059147477149963, "ratio": 0.9997388124465942, "entropy": 0.8208023309707642, "incre_win_rate": 0.5135135135135135, "step": 367}
{"time": 1767152940.0256443, "phase": "train", "update": 368, "total_env_steps": 1177600, "episode_reward": 0.18371377885341644, "value_loss": 0.02240106835961342, "policy_loss": -0.0011826304742683647, "dist_entropy": 0.8219002723693848, "actor_grad_norm": 0.08332175761461258, "critic_grad_norm": 0.1859062761068344, "ratio": 0.9998344779014587, "entropy": 0.8219002723693848, "incre_win_rate": 0.5, "step": 368}
{"time": 1767152944.2219071, "phase": "train", "update": 369, "total_env_steps": 1180800, "episode_reward": 0.17391300201416016, "value_loss": 0.02392611838877201, "policy_loss": -0.001224357385268604, "dist_entropy": 0.8241689443588257, "actor_grad_norm": 0.12449319660663605, "critic_grad_norm": 0.3551085591316223, "ratio": 1.000137209892273, "entropy": 0.8241689443588257, "incre_win_rate": 0.35135135135135137, "step": 369}
{"time": 1767152948.43001, "phase": "train", "update": 370, "total_env_steps": 1184000, "episode_reward": 0.19833248853683472, "value_loss": 0.0236283078789711, "policy_loss": -0.0009370813375333853, "dist_entropy": 0.8073287606239319, "actor_grad_norm": 0.0833696499466896, "critic_grad_norm": 0.29570889472961426, "ratio": 0.9998449683189392, "entropy": 0.8073287606239319, "incre_win_rate": 0.6363636363636364, "step": 370}
{"time": 1767152952.6674073, "phase": "train", "update": 371, "total_env_steps": 1187200, "episode_reward": 0.17006726562976837, "value_loss": 0.023778551444411277, "policy_loss": -0.00132878612293581, "dist_entropy": 0.8164704203605652, "actor_grad_norm": 0.08773063868284225, "critic_grad_norm": 0.2008739560842514, "ratio": 0.9999700784683228, "entropy": 0.8164704203605652, "incre_win_rate": 0.43243243243243246, "step": 371}
{"time": 1767152956.8965678, "phase": "train", "update": 372, "total_env_steps": 1190400, "episode_reward": 0.18129810690879822, "value_loss": 0.02233518026769161, "policy_loss": -0.0008825874227795794, "dist_entropy": 0.8067109227180481, "actor_grad_norm": 0.10214928537607193, "critic_grad_norm": 0.15957950055599213, "ratio": 1.0001484155654907, "entropy": 0.8067109227180481, "incre_win_rate": 0.5, "step": 372}
{"time": 1767152961.0879216, "phase": "train", "update": 373, "total_env_steps": 1193600, "episode_reward": 0.18191328644752502, "value_loss": 0.022168686240911485, "policy_loss": -0.0010249467422578818, "dist_entropy": 0.815530288219452, "actor_grad_norm": 0.09950234740972519, "critic_grad_norm": 0.15808741748332977, "ratio": 1.0001224279403687, "entropy": 0.815530288219452, "incre_win_rate": 0.4722222222222222, "step": 373}
{"time": 1767152965.3237991, "phase": "train", "update": 374, "total_env_steps": 1196800, "episode_reward": 0.19124948978424072, "value_loss": 0.02414800226688385, "policy_loss": -0.0012216276396526116, "dist_entropy": 0.8029626727104187, "actor_grad_norm": 0.09374088048934937, "critic_grad_norm": 0.2135227471590042, "ratio": 1.0002491474151611, "entropy": 0.8029626727104187, "incre_win_rate": 0.6363636363636364, "step": 374}
{"time": 1767152969.6045587, "phase": "train", "update": 375, "total_env_steps": 1200000, "episode_reward": 0.1839998960494995, "value_loss": 0.02372089996933937, "policy_loss": -0.0009946401345743538, "dist_entropy": 0.811095941066742, "actor_grad_norm": 0.11989472061395645, "critic_grad_norm": 0.23577053844928741, "ratio": 1.0001107454299927, "entropy": 0.811095941066742, "incre_win_rate": 0.4166666666666667, "step": 375}
{"time": 1767152973.7881072, "phase": "train", "update": 376, "total_env_steps": 1203200, "episode_reward": 0.18140988051891327, "value_loss": 0.02152767516672611, "policy_loss": -0.001087697919574282, "dist_entropy": 0.831938910484314, "actor_grad_norm": 0.09798163175582886, "critic_grad_norm": 0.12168685346841812, "ratio": 0.9998549818992615, "entropy": 0.831938910484314, "incre_win_rate": 0.5277777777777778, "step": 376}
{"time": 1767152977.9953997, "phase": "train", "update": 377, "total_env_steps": 1206400, "episode_reward": 0.17212902009487152, "value_loss": 0.024867762252688407, "policy_loss": -0.0009063428018109221, "dist_entropy": 0.8203270316123963, "actor_grad_norm": 0.10932188481092453, "critic_grad_norm": 0.10626151412725449, "ratio": 1.000073790550232, "entropy": 0.8203270316123963, "incre_win_rate": 0.47058823529411764, "step": 377}
{"time": 1767152982.2053766, "phase": "train", "update": 378, "total_env_steps": 1209600, "episode_reward": 0.19725631177425385, "value_loss": 0.020708782598376274, "policy_loss": -0.001332765846516626, "dist_entropy": 0.8265172600746155, "actor_grad_norm": 0.1485109031200409, "critic_grad_norm": 0.40733596682548523, "ratio": 1.0001941919326782, "entropy": 0.8265172600746155, "incre_win_rate": 0.696969696969697, "step": 378}
{"time": 1767152986.4057677, "phase": "train", "update": 379, "total_env_steps": 1212800, "episode_reward": 0.18518884479999542, "value_loss": 0.02235819920897484, "policy_loss": -0.0013045072800792923, "dist_entropy": 0.8567185163497925, "actor_grad_norm": 0.1539522409439087, "critic_grad_norm": 0.283369243144989, "ratio": 1.0000022649765015, "entropy": 0.8567185163497925, "incre_win_rate": 0.5, "step": 379}
{"time": 1767152990.6025279, "phase": "train", "update": 380, "total_env_steps": 1216000, "episode_reward": 0.18145126104354858, "value_loss": 0.022030271589756012, "policy_loss": -0.001090150539598911, "dist_entropy": 0.8605082631111145, "actor_grad_norm": 0.11942832916975021, "critic_grad_norm": 0.22359852492809296, "ratio": 1.000141978263855, "entropy": 0.8605082631111145, "incre_win_rate": 0.5277777777777778, "step": 380}
{"time": 1767152994.8115928, "phase": "train", "update": 381, "total_env_steps": 1219200, "episode_reward": 0.17958973348140717, "value_loss": 0.020666604116559028, "policy_loss": -0.0010310740451316748, "dist_entropy": 0.8514540314674377, "actor_grad_norm": 0.09213466197252274, "critic_grad_norm": 0.08814660459756851, "ratio": 1.0000804662704468, "entropy": 0.8514540314674377, "incre_win_rate": 0.4166666666666667, "step": 381}
{"time": 1767153008.2537315, "phase": "eval", "update": 381, "total_env_steps": 1219200, "eval_win_rate": 0.4375, "eval_episode_reward": 16.101200331125817, "step": 381}
{"time": 1767153012.4845605, "phase": "train", "update": 382, "total_env_steps": 1222400, "episode_reward": 0.19843491911888123, "value_loss": 0.02935918904840946, "policy_loss": -0.0010807009598735816, "dist_entropy": 0.8731279969215393, "actor_grad_norm": 0.12322793155908585, "critic_grad_norm": 0.11284255236387253, "ratio": 1.0002691745758057, "entropy": 0.8731279969215393, "incre_win_rate": 0.5897435897435898, "step": 382}
{"time": 1767153016.7108524, "phase": "train", "update": 383, "total_env_steps": 1225600, "episode_reward": 0.19965696334838867, "value_loss": 0.024664289504289626, "policy_loss": -0.0012063165183064939, "dist_entropy": 0.8710697531700134, "actor_grad_norm": 0.13980260491371155, "critic_grad_norm": 0.12993456423282623, "ratio": 0.9998113512992859, "entropy": 0.8710697531700134, "incre_win_rate": 0.5405405405405406, "step": 383}
{"time": 1767153020.923132, "phase": "train", "update": 384, "total_env_steps": 1228800, "episode_reward": 0.18879398703575134, "value_loss": 0.024626033380627632, "policy_loss": -0.0009746694230347685, "dist_entropy": 0.8466519713401794, "actor_grad_norm": 0.08855216950178146, "critic_grad_norm": 0.09776134788990021, "ratio": 0.9999546408653259, "entropy": 0.8466519713401794, "incre_win_rate": 0.6470588235294118, "step": 384}
{"time": 1767153025.1552563, "phase": "train", "update": 385, "total_env_steps": 1232000, "episode_reward": 0.18759053945541382, "value_loss": 0.018787271156907082, "policy_loss": -0.000804413810040927, "dist_entropy": 0.8829078316688538, "actor_grad_norm": 0.11562100797891617, "critic_grad_norm": 0.0696103572845459, "ratio": 0.9996895790100098, "entropy": 0.8829078316688538, "incre_win_rate": 0.4864864864864865, "step": 385}
{"time": 1767153029.4662392, "phase": "train", "update": 386, "total_env_steps": 1235200, "episode_reward": 0.2001158893108368, "value_loss": 0.023609410971403122, "policy_loss": -0.0010645430730210847, "dist_entropy": 0.8908604860305787, "actor_grad_norm": 0.0837990865111351, "critic_grad_norm": 0.1365966647863388, "ratio": 1.000514030456543, "entropy": 0.8908604860305787, "incre_win_rate": 0.6216216216216216, "step": 386}
{"time": 1767153033.7152193, "phase": "train", "update": 387, "total_env_steps": 1238400, "episode_reward": 0.19377171993255615, "value_loss": 0.02638515494763851, "policy_loss": -0.0011401600974810578, "dist_entropy": 0.8468941569328308, "actor_grad_norm": 0.08886873722076416, "critic_grad_norm": 0.16610819101333618, "ratio": 0.9999868273735046, "entropy": 0.8468941569328308, "incre_win_rate": 0.5833333333333334, "step": 387}
{"time": 1767153037.9963343, "phase": "train", "update": 388, "total_env_steps": 1241600, "episode_reward": 0.199735626578331, "value_loss": 0.02987433485686779, "policy_loss": -0.0011929483908745375, "dist_entropy": 0.8655611991882324, "actor_grad_norm": 0.0971471443772316, "critic_grad_norm": 0.11849837750196457, "ratio": 0.9997235536575317, "entropy": 0.8655611991882324, "incre_win_rate": 0.5789473684210527, "step": 388}
{"time": 1767153042.2713935, "phase": "train", "update": 389, "total_env_steps": 1244800, "episode_reward": 0.19391143321990967, "value_loss": 0.026808593049645425, "policy_loss": -0.0011704720822955038, "dist_entropy": 0.8732792377471924, "actor_grad_norm": 0.11129988729953766, "critic_grad_norm": 0.16727019846439362, "ratio": 1.0002518892288208, "entropy": 0.8732792377471924, "incre_win_rate": 0.4594594594594595, "step": 389}
{"time": 1767153046.5083976, "phase": "train", "update": 390, "total_env_steps": 1248000, "episode_reward": 0.1935761570930481, "value_loss": 0.030718427523970603, "policy_loss": -0.0011212518350196988, "dist_entropy": 0.8444751739501953, "actor_grad_norm": 0.11865372955799103, "critic_grad_norm": 0.199512779712677, "ratio": 1.0002301931381226, "entropy": 0.8444751739501953, "incre_win_rate": 0.6216216216216216, "step": 390}
{"time": 1767153050.751755, "phase": "train", "update": 391, "total_env_steps": 1251200, "episode_reward": 0.19225993752479553, "value_loss": 0.029251306504011153, "policy_loss": -0.0012901666881852236, "dist_entropy": 0.8404497981071473, "actor_grad_norm": 0.10628645867109299, "critic_grad_norm": 0.1462012529373169, "ratio": 0.9999948740005493, "entropy": 0.8404497981071473, "incre_win_rate": 0.6388888888888888, "step": 391}
{"time": 1767153055.0080407, "phase": "train", "update": 392, "total_env_steps": 1254400, "episode_reward": 0.200457364320755, "value_loss": 0.0217121921479702, "policy_loss": -0.0009584952495732324, "dist_entropy": 0.879512631893158, "actor_grad_norm": 0.09827196598052979, "critic_grad_norm": 0.2126402109861374, "ratio": 0.9999451041221619, "entropy": 0.879512631893158, "incre_win_rate": 0.5555555555555556, "step": 392}
{"time": 1767153059.2735598, "phase": "train", "update": 393, "total_env_steps": 1257600, "episode_reward": 0.20702660083770752, "value_loss": 0.020307226106524467, "policy_loss": -0.0013313779755474541, "dist_entropy": 0.8415482401847839, "actor_grad_norm": 0.1191902682185173, "critic_grad_norm": 0.2864685654640198, "ratio": 0.9996302723884583, "entropy": 0.8415482401847839, "incre_win_rate": 0.6578947368421053, "step": 393}
{"time": 1767153063.5296218, "phase": "train", "update": 394, "total_env_steps": 1260800, "episode_reward": 0.18604616820812225, "value_loss": 0.02414679117500782, "policy_loss": -0.0006917214702448326, "dist_entropy": 0.8422727823257447, "actor_grad_norm": 0.11152620613574982, "critic_grad_norm": 0.34810519218444824, "ratio": 1.0001453161239624, "entropy": 0.8422727823257447, "incre_win_rate": 0.45714285714285713, "step": 394}
{"time": 1767153067.8878818, "phase": "train", "update": 395, "total_env_steps": 1264000, "episode_reward": 0.19413234293460846, "value_loss": 0.022148456051945688, "policy_loss": -0.0011072494389296138, "dist_entropy": 0.8453074336051941, "actor_grad_norm": 0.10190786421298981, "critic_grad_norm": 0.30370795726776123, "ratio": 0.9996270537376404, "entropy": 0.8453074336051941, "incre_win_rate": 0.6111111111111112, "step": 395}
{"time": 1767153072.1216521, "phase": "train", "update": 396, "total_env_steps": 1267200, "episode_reward": 0.2115526646375656, "value_loss": 0.017480282858014107, "policy_loss": -0.000729268415225448, "dist_entropy": 0.8568840146064758, "actor_grad_norm": 0.1083432212471962, "critic_grad_norm": 0.12912923097610474, "ratio": 0.9995465278625488, "entropy": 0.8568840146064758, "incre_win_rate": 0.8055555555555556, "step": 396}
{"time": 1767153076.3562546, "phase": "train", "update": 397, "total_env_steps": 1270400, "episode_reward": 0.20371171832084656, "value_loss": 0.022164642065763473, "policy_loss": -0.001324225160054837, "dist_entropy": 0.8457767486572265, "actor_grad_norm": 0.10455945879220963, "critic_grad_norm": 0.16686448454856873, "ratio": 1.0002340078353882, "entropy": 0.8457767486572265, "incre_win_rate": 0.75, "step": 397}
{"time": 1767153080.6581612, "phase": "train", "update": 398, "total_env_steps": 1273600, "episode_reward": 0.2014150619506836, "value_loss": 0.01784367486834526, "policy_loss": -0.0010652769291539578, "dist_entropy": 0.8370123505592346, "actor_grad_norm": 0.15011842548847198, "critic_grad_norm": 0.1691950559616089, "ratio": 0.9997448325157166, "entropy": 0.8370123505592346, "incre_win_rate": 0.7714285714285715, "step": 398}
{"time": 1767153084.8935955, "phase": "train", "update": 399, "total_env_steps": 1276800, "episode_reward": 0.19846390187740326, "value_loss": 0.01941172108054161, "policy_loss": -0.0009844188972433442, "dist_entropy": 0.8668423891067505, "actor_grad_norm": 0.15833185613155365, "critic_grad_norm": 0.1608050912618637, "ratio": 0.9998369216918945, "entropy": 0.8668423891067505, "incre_win_rate": 0.7222222222222222, "step": 399}
{"time": 1767153089.157024, "phase": "train", "update": 400, "total_env_steps": 1280000, "episode_reward": 0.19954314827919006, "value_loss": 0.022068461775779723, "policy_loss": -0.0009130073160655173, "dist_entropy": 0.8913210868835449, "actor_grad_norm": 0.09360875934362411, "critic_grad_norm": 0.22246694564819336, "ratio": 1.0000916719436646, "entropy": 0.8913210868835449, "incre_win_rate": 0.6111111111111112, "step": 400}
{"time": 1767153093.4749691, "phase": "train", "update": 401, "total_env_steps": 1283200, "episode_reward": 0.20634570717811584, "value_loss": 0.015020673908293248, "policy_loss": -0.0016097254941804806, "dist_entropy": 0.9028196215629578, "actor_grad_norm": 0.12468457221984863, "critic_grad_norm": 0.13169097900390625, "ratio": 0.9998051524162292, "entropy": 0.9028196215629578, "incre_win_rate": 0.7058823529411765, "step": 401}
{"time": 1767153111.6988282, "phase": "eval", "update": 401, "total_env_steps": 1283200, "eval_win_rate": 0.71875, "eval_episode_reward": 17.701883278145694, "step": 401}
{"time": 1767153115.9965725, "phase": "train", "update": 402, "total_env_steps": 1286400, "episode_reward": 0.21549101173877716, "value_loss": 0.018519822135567666, "policy_loss": -0.0008135568734557452, "dist_entropy": 0.8714163422584533, "actor_grad_norm": 0.09234251081943512, "critic_grad_norm": 0.14097873866558075, "ratio": 0.999962329864502, "entropy": 0.8714163422584533, "incre_win_rate": 0.8108108108108109, "step": 402}
{"time": 1767153120.334162, "phase": "train", "update": 403, "total_env_steps": 1289600, "episode_reward": 0.1883660852909088, "value_loss": 0.0217600055038929, "policy_loss": -0.001238418648316042, "dist_entropy": 0.9001016616821289, "actor_grad_norm": 0.13170908391475677, "critic_grad_norm": 0.31848013401031494, "ratio": 0.9996099472045898, "entropy": 0.9001016616821289, "incre_win_rate": 0.48717948717948717, "step": 403}
{"time": 1767153124.7306635, "phase": "train", "update": 404, "total_env_steps": 1292800, "episode_reward": 0.1947506070137024, "value_loss": 0.02553860582411289, "policy_loss": -0.0014279920622179531, "dist_entropy": 0.9172263979911804, "actor_grad_norm": 0.12839160859584808, "critic_grad_norm": 0.3064650595188141, "ratio": 0.9994291663169861, "entropy": 0.9172263979911804, "incre_win_rate": 0.5833333333333334, "step": 404}
{"time": 1767153128.9643786, "phase": "train", "update": 405, "total_env_steps": 1296000, "episode_reward": 0.19551530480384827, "value_loss": 0.02055293135344982, "policy_loss": -0.0012954948471083582, "dist_entropy": 0.9045934081077576, "actor_grad_norm": 0.12911127507686615, "critic_grad_norm": 0.12739211320877075, "ratio": 0.9999977350234985, "entropy": 0.9045934081077576, "incre_win_rate": 0.6388888888888888, "step": 405}
{"time": 1767153133.2171626, "phase": "train", "update": 406, "total_env_steps": 1299200, "episode_reward": 0.18259000778198242, "value_loss": 0.01790296658873558, "policy_loss": -0.0013360739161726088, "dist_entropy": 0.9217718720436097, "actor_grad_norm": 0.11145805567502975, "critic_grad_norm": 0.12254097312688828, "ratio": 0.9999399185180664, "entropy": 0.9217718720436097, "incre_win_rate": 0.5151515151515151, "step": 406}
{"time": 1767153137.5213017, "phase": "train", "update": 407, "total_env_steps": 1302400, "episode_reward": 0.1922951191663742, "value_loss": 0.021250498294830323, "policy_loss": -0.001518001893221399, "dist_entropy": 0.9092159628868103, "actor_grad_norm": 0.10930963605642319, "critic_grad_norm": 0.24720549583435059, "ratio": 0.999913215637207, "entropy": 0.9092159628868103, "incre_win_rate": 0.6486486486486487, "step": 407}
{"time": 1767153141.799614, "phase": "train", "update": 408, "total_env_steps": 1305600, "episode_reward": 0.19116617739200592, "value_loss": 0.01982395686209202, "policy_loss": -0.00171897531551366, "dist_entropy": 0.8850890517234802, "actor_grad_norm": 0.10950159281492233, "critic_grad_norm": 0.1797575205564499, "ratio": 0.9999480247497559, "entropy": 0.8850890517234802, "incre_win_rate": 0.5588235294117647, "step": 408}
{"time": 1767153146.0903592, "phase": "train", "update": 409, "total_env_steps": 1308800, "episode_reward": 0.1914595365524292, "value_loss": 0.021647441014647485, "policy_loss": -0.0010698129083088759, "dist_entropy": 0.8955961465835571, "actor_grad_norm": 0.1271161437034607, "critic_grad_norm": 0.22373823821544647, "ratio": 0.9999513626098633, "entropy": 0.8955961465835571, "incre_win_rate": 0.5714285714285714, "step": 409}
{"time": 1767153150.3957784, "phase": "train", "update": 410, "total_env_steps": 1312000, "episode_reward": 0.1945757418870926, "value_loss": 0.023378483578562738, "policy_loss": -0.0012560606279393483, "dist_entropy": 0.8965624094009399, "actor_grad_norm": 0.10158250480890274, "critic_grad_norm": 0.15909186005592346, "ratio": 0.9998816847801208, "entropy": 0.8965624094009399, "incre_win_rate": 0.6388888888888888, "step": 410}
{"time": 1767153154.6493633, "phase": "train", "update": 411, "total_env_steps": 1315200, "episode_reward": 0.18142229318618774, "value_loss": 0.017462243512272834, "policy_loss": -0.001020936811138995, "dist_entropy": 0.8837534308433532, "actor_grad_norm": 0.09643688797950745, "critic_grad_norm": 0.09894489496946335, "ratio": 1.0001087188720703, "entropy": 0.8837534308433532, "incre_win_rate": 0.5, "step": 411}
{"time": 1767153158.9115682, "phase": "train", "update": 412, "total_env_steps": 1318400, "episode_reward": 0.19778507947921753, "value_loss": 0.02125917114317417, "policy_loss": -0.0013143233126612585, "dist_entropy": 0.899471664428711, "actor_grad_norm": 0.11263127624988556, "critic_grad_norm": 0.15220630168914795, "ratio": 0.9999834299087524, "entropy": 0.899471664428711, "incre_win_rate": 0.7714285714285715, "step": 412}
{"time": 1767153163.2063653, "phase": "train", "update": 413, "total_env_steps": 1321600, "episode_reward": 0.20342043042182922, "value_loss": 0.014924752525985241, "policy_loss": -0.001425556286968188, "dist_entropy": 0.8870618581771851, "actor_grad_norm": 0.10233545303344727, "critic_grad_norm": 0.2045334130525589, "ratio": 1.0000256299972534, "entropy": 0.8870618581771851, "incre_win_rate": 0.7428571428571429, "step": 413}
{"time": 1767153167.5368311, "phase": "train", "update": 414, "total_env_steps": 1324800, "episode_reward": 0.19959335029125214, "value_loss": 0.022482648491859436, "policy_loss": -0.0010700971477584531, "dist_entropy": 0.8903784990310669, "actor_grad_norm": 0.12915170192718506, "critic_grad_norm": 0.17392265796661377, "ratio": 0.9999228715896606, "entropy": 0.8903784990310669, "incre_win_rate": 0.6, "step": 414}
{"time": 1767153171.860576, "phase": "train", "update": 415, "total_env_steps": 1328000, "episode_reward": 0.19189104437828064, "value_loss": 0.01786799617111683, "policy_loss": -0.0010714807699820027, "dist_entropy": 0.8738673567771912, "actor_grad_norm": 0.11736252158880234, "critic_grad_norm": 0.15688687562942505, "ratio": 0.999853253364563, "entropy": 0.8738673567771912, "incre_win_rate": 0.5897435897435898, "step": 415}
{"time": 1767153176.1840067, "phase": "train", "update": 416, "total_env_steps": 1331200, "episode_reward": 0.19819587469100952, "value_loss": 0.021043360978364945, "policy_loss": -0.0010818003193630687, "dist_entropy": 0.8806138753890991, "actor_grad_norm": 0.09354057163000107, "critic_grad_norm": 0.20071208477020264, "ratio": 1.0001434087753296, "entropy": 0.8806138753890991, "incre_win_rate": 0.5675675675675675, "step": 416}
{"time": 1767153180.509638, "phase": "train", "update": 417, "total_env_steps": 1334400, "episode_reward": 0.1946098953485489, "value_loss": 0.02156735472381115, "policy_loss": -0.0012755824310948405, "dist_entropy": 0.8703225255012512, "actor_grad_norm": 0.1307501643896103, "critic_grad_norm": 0.12549464404582977, "ratio": 1.0001394748687744, "entropy": 0.8703225255012512, "incre_win_rate": 0.6176470588235294, "step": 417}
{"time": 1767153184.7569833, "phase": "train", "update": 418, "total_env_steps": 1337600, "episode_reward": 0.19616928696632385, "value_loss": 0.0167543962597847, "policy_loss": -0.001053167606918848, "dist_entropy": 0.8522072196006775, "actor_grad_norm": 0.10008475929498672, "critic_grad_norm": 0.17493119835853577, "ratio": 0.99970942735672, "entropy": 0.8522072196006775, "incre_win_rate": 0.6857142857142857, "step": 418}
{"time": 1767153189.0421138, "phase": "train", "update": 419, "total_env_steps": 1340800, "episode_reward": 0.200601726770401, "value_loss": 0.02120743431150913, "policy_loss": -0.0008607837698576759, "dist_entropy": 0.8364820361137391, "actor_grad_norm": 0.08256816118955612, "critic_grad_norm": 0.16827130317687988, "ratio": 0.9998403787612915, "entropy": 0.8364820361137391, "incre_win_rate": 0.6666666666666666, "step": 419}
{"time": 1767153193.352413, "phase": "train", "update": 420, "total_env_steps": 1344000, "episode_reward": 0.19798842072486877, "value_loss": 0.0187326155602932, "policy_loss": -0.0009125079322874541, "dist_entropy": 0.8433338880538941, "actor_grad_norm": 0.08584844321012497, "critic_grad_norm": 0.1396038979291916, "ratio": 1.000136137008667, "entropy": 0.8433338880538941, "incre_win_rate": 0.5526315789473685, "step": 420}
{"time": 1767153197.690402, "phase": "train", "update": 421, "total_env_steps": 1347200, "episode_reward": 0.2117466777563095, "value_loss": 0.0167565006762743, "policy_loss": -0.0008783501409991956, "dist_entropy": 0.8442307114601135, "actor_grad_norm": 0.0749131366610527, "critic_grad_norm": 0.1565791666507721, "ratio": 0.9998065829277039, "entropy": 0.8442307114601135, "incre_win_rate": 0.7142857142857143, "step": 421}
{"time": 1767153210.6443431, "phase": "eval", "update": 421, "total_env_steps": 1347200, "eval_win_rate": 0.65625, "eval_episode_reward": 18.554273592715234, "step": 421}
{"time": 1767153214.937828, "phase": "train", "update": 422, "total_env_steps": 1350400, "episode_reward": 0.20551633834838867, "value_loss": 0.018049684911966325, "policy_loss": -0.0008968239868572426, "dist_entropy": 0.835407018661499, "actor_grad_norm": 0.06515496224164963, "critic_grad_norm": 0.12555715441703796, "ratio": 0.9999778866767883, "entropy": 0.835407018661499, "incre_win_rate": 0.7, "step": 422}
{"time": 1767153219.199563, "phase": "train", "update": 423, "total_env_steps": 1353600, "episode_reward": 0.19597163796424866, "value_loss": 0.017910946533083914, "policy_loss": -0.0009004419071771963, "dist_entropy": 0.8542469382286072, "actor_grad_norm": 0.07622592896223068, "critic_grad_norm": 0.15062986314296722, "ratio": 1.0002630949020386, "entropy": 0.8542469382286072, "incre_win_rate": 0.59375, "step": 423}
{"time": 1767153223.4892316, "phase": "train", "update": 424, "total_env_steps": 1356800, "episode_reward": 0.1988312304019928, "value_loss": 0.01701359786093235, "policy_loss": -0.0017289634438185431, "dist_entropy": 0.8213226556777954, "actor_grad_norm": 0.11016585677862167, "critic_grad_norm": 0.10531031340360641, "ratio": 1.0003483295440674, "entropy": 0.8213226556777954, "incre_win_rate": 0.6944444444444444, "step": 424}
{"time": 1767153227.8069682, "phase": "train", "update": 425, "total_env_steps": 1360000, "episode_reward": 0.19920635223388672, "value_loss": 0.03600418567657471, "policy_loss": -0.0008799889702387987, "dist_entropy": 0.8011960029602051, "actor_grad_norm": 0.09184705466032028, "critic_grad_norm": 0.39633041620254517, "ratio": 0.999759316444397, "entropy": 0.8011960029602051, "incre_win_rate": 0.7941176470588235, "step": 425}
{"time": 1767153232.1035895, "phase": "train", "update": 426, "total_env_steps": 1363200, "episode_reward": 0.1971668004989624, "value_loss": 0.02340599149465561, "policy_loss": -0.000997516915758112, "dist_entropy": 0.7961552739143372, "actor_grad_norm": 0.10527712106704712, "critic_grad_norm": 0.31755825877189636, "ratio": 1.0001615285873413, "entropy": 0.7961552739143372, "incre_win_rate": 0.7297297297297297, "step": 426}
{"time": 1767153236.3256013, "phase": "train", "update": 427, "total_env_steps": 1366400, "episode_reward": 0.19754141569137573, "value_loss": 0.015960202552378178, "policy_loss": -0.0008569669238205791, "dist_entropy": 0.7719870924949646, "actor_grad_norm": 0.07869797945022583, "critic_grad_norm": 0.243655726313591, "ratio": 1.0001710653305054, "entropy": 0.7719870924949646, "incre_win_rate": 0.6857142857142857, "step": 427}
{"time": 1767153240.568512, "phase": "train", "update": 428, "total_env_steps": 1369600, "episode_reward": 0.19712746143341064, "value_loss": 0.035706888884305954, "policy_loss": -0.0014565788010063585, "dist_entropy": 0.7988212823867797, "actor_grad_norm": 0.11665266007184982, "critic_grad_norm": 0.4962962567806244, "ratio": 0.9999610781669617, "entropy": 0.7988212823867797, "incre_win_rate": 0.7272727272727273, "step": 428}
{"time": 1767153244.8193355, "phase": "train", "update": 429, "total_env_steps": 1372800, "episode_reward": 0.1966266632080078, "value_loss": 0.0228353276848793, "policy_loss": -0.0014082447156894772, "dist_entropy": 0.7948068618774414, "actor_grad_norm": 0.09427609294652939, "critic_grad_norm": 0.3441813886165619, "ratio": 1.0002167224884033, "entropy": 0.7948068618774414, "incre_win_rate": 0.6111111111111112, "step": 429}
{"time": 1767153249.084362, "phase": "train", "update": 430, "total_env_steps": 1376000, "episode_reward": 0.20289476215839386, "value_loss": 0.02727213241159916, "policy_loss": -0.001133539489532609, "dist_entropy": 0.817005717754364, "actor_grad_norm": 0.11134848743677139, "critic_grad_norm": 0.25748559832572937, "ratio": 0.9999796152114868, "entropy": 0.817005717754364, "incre_win_rate": 0.6486486486486487, "step": 430}
{"time": 1767153253.3067396, "phase": "train", "update": 431, "total_env_steps": 1379200, "episode_reward": 0.20129966735839844, "value_loss": 0.0199885006994009, "policy_loss": -0.0011705136785860049, "dist_entropy": 0.8168612957000733, "actor_grad_norm": 0.09579557925462723, "critic_grad_norm": 0.13069945573806763, "ratio": 1.000285267829895, "entropy": 0.8168612957000733, "incre_win_rate": 0.6578947368421053, "step": 431}
{"time": 1767153257.5501332, "phase": "train", "update": 432, "total_env_steps": 1382400, "episode_reward": 0.19225114583969116, "value_loss": 0.02000783048570156, "policy_loss": -0.0009650183303314463, "dist_entropy": 0.8020471930503845, "actor_grad_norm": 0.08617527782917023, "critic_grad_norm": 0.14411517977714539, "ratio": 1.0000855922698975, "entropy": 0.8020471930503845, "incre_win_rate": 0.6, "step": 432}
{"time": 1767153261.8694923, "phase": "train", "update": 433, "total_env_steps": 1385600, "episode_reward": 0.20018987357616425, "value_loss": 0.020439733192324637, "policy_loss": -0.0008869593283497678, "dist_entropy": 0.8188844680786133, "actor_grad_norm": 0.10423383861780167, "critic_grad_norm": 0.16595514118671417, "ratio": 0.9997057318687439, "entropy": 0.8188844680786133, "incre_win_rate": 0.7058823529411765, "step": 433}
{"time": 1767153266.1538754, "phase": "train", "update": 434, "total_env_steps": 1388800, "episode_reward": 0.2060394287109375, "value_loss": 0.019190923497080802, "policy_loss": -0.001269808866186839, "dist_entropy": 0.8470010757446289, "actor_grad_norm": 0.1169930249452591, "critic_grad_norm": 0.10841596126556396, "ratio": 1.0001267194747925, "entropy": 0.8470010757446289, "incre_win_rate": 0.6410256410256411, "step": 434}
{"time": 1767153270.4500937, "phase": "train", "update": 435, "total_env_steps": 1392000, "episode_reward": 0.20262055099010468, "value_loss": 0.02088400609791279, "policy_loss": -0.0014043510947232107, "dist_entropy": 0.8522623419761658, "actor_grad_norm": 0.0947841927409172, "critic_grad_norm": 0.14934101700782776, "ratio": 0.9999274611473083, "entropy": 0.8522623419761658, "incre_win_rate": 0.6756756756756757, "step": 435}
{"time": 1767153274.7492056, "phase": "train", "update": 436, "total_env_steps": 1395200, "episode_reward": 0.2029770463705063, "value_loss": 0.02394368648529053, "policy_loss": -0.0009586129613900595, "dist_entropy": 0.8759925723075866, "actor_grad_norm": 0.10098393261432648, "critic_grad_norm": 0.15274100005626678, "ratio": 1.0001486539840698, "entropy": 0.8759925723075866, "incre_win_rate": 0.5675675675675675, "step": 436}
{"time": 1767153279.0527642, "phase": "train", "update": 437, "total_env_steps": 1398400, "episode_reward": 0.20786011219024658, "value_loss": 0.02012057937681675, "policy_loss": -0.0009796425646136698, "dist_entropy": 0.8708855390548706, "actor_grad_norm": 0.10444249957799911, "critic_grad_norm": 0.09505316615104675, "ratio": 1.0002321004867554, "entropy": 0.8708855390548706, "incre_win_rate": 0.7027027027027027, "step": 437}
{"time": 1767153283.3390055, "phase": "train", "update": 438, "total_env_steps": 1401600, "episode_reward": 0.20531818270683289, "value_loss": 0.018261780962347984, "policy_loss": -0.0012147503567259577, "dist_entropy": 0.856497859954834, "actor_grad_norm": 0.11010046303272247, "critic_grad_norm": 0.10353521257638931, "ratio": 1.0004462003707886, "entropy": 0.856497859954834, "incre_win_rate": 0.6842105263157895, "step": 438}
{"time": 1767153287.694542, "phase": "train", "update": 439, "total_env_steps": 1404800, "episode_reward": 0.21265314519405365, "value_loss": 0.020972514897584914, "policy_loss": -0.001007539378628053, "dist_entropy": 0.8941326975822449, "actor_grad_norm": 0.10539612919092178, "critic_grad_norm": 0.11068575829267502, "ratio": 0.9993859529495239, "entropy": 0.8941326975822449, "incre_win_rate": 0.8, "step": 439}
{"time": 1767153291.952098, "phase": "train", "update": 440, "total_env_steps": 1408000, "episode_reward": 0.20024679601192474, "value_loss": 0.017777799069881438, "policy_loss": -0.0010655862923179883, "dist_entropy": 0.8787950992584228, "actor_grad_norm": 0.1190057322382927, "critic_grad_norm": 0.08243023604154587, "ratio": 0.9996135830879211, "entropy": 0.8787950992584228, "incre_win_rate": 0.7027027027027027, "step": 440}
{"time": 1767153296.2702422, "phase": "train", "update": 441, "total_env_steps": 1411200, "episode_reward": 0.20891298353672028, "value_loss": 0.018672082200646402, "policy_loss": -0.0008132426459506626, "dist_entropy": 0.8707180857658386, "actor_grad_norm": 0.09362827986478806, "critic_grad_norm": 0.21623478829860687, "ratio": 1.0003479719161987, "entropy": 0.8707180857658386, "incre_win_rate": 0.6388888888888888, "step": 441}
{"time": 1767153309.1020386, "phase": "eval", "update": 441, "total_env_steps": 1411200, "eval_win_rate": 0.65625, "eval_episode_reward": 18.089662665562916, "step": 441}
{"time": 1767153313.4061282, "phase": "train", "update": 442, "total_env_steps": 1414400, "episode_reward": 0.21077090501785278, "value_loss": 0.01825297698378563, "policy_loss": -0.0013174798033542602, "dist_entropy": 0.8948140382766724, "actor_grad_norm": 0.11757554858922958, "critic_grad_norm": 0.12307365238666534, "ratio": 0.9997642636299133, "entropy": 0.8948140382766724, "incre_win_rate": 0.8055555555555556, "step": 442}
{"time": 1767153317.6506145, "phase": "train", "update": 443, "total_env_steps": 1417600, "episode_reward": 0.18461556732654572, "value_loss": 0.018861818313598632, "policy_loss": -0.0012627966719152006, "dist_entropy": 0.8749872207641601, "actor_grad_norm": 0.12204239517450333, "critic_grad_norm": 0.291391521692276, "ratio": 0.9999133944511414, "entropy": 0.8749872207641601, "incre_win_rate": 0.6285714285714286, "step": 443}
{"time": 1767153321.9901617, "phase": "train", "update": 444, "total_env_steps": 1420800, "episode_reward": 0.19764278829097748, "value_loss": 0.020172880962491035, "policy_loss": -0.000812288619157897, "dist_entropy": 0.893395209312439, "actor_grad_norm": 0.09857045859098434, "critic_grad_norm": 0.27476271986961365, "ratio": 1.0001753568649292, "entropy": 0.893395209312439, "incre_win_rate": 0.6764705882352942, "step": 444}
{"time": 1767153326.271116, "phase": "train", "update": 445, "total_env_steps": 1424000, "episode_reward": 0.20345093309879303, "value_loss": 0.02031651921570301, "policy_loss": -0.000962493390377972, "dist_entropy": 0.8865713119506836, "actor_grad_norm": 0.0961272343993187, "critic_grad_norm": 0.22565674781799316, "ratio": 0.9999038577079773, "entropy": 0.8865713119506836, "incre_win_rate": 0.6666666666666666, "step": 445}
{"time": 1767153330.549026, "phase": "train", "update": 446, "total_env_steps": 1427200, "episode_reward": 0.2042115181684494, "value_loss": 0.01756301186978817, "policy_loss": -0.0016392714248766537, "dist_entropy": 0.8777346014976501, "actor_grad_norm": 0.11875414848327637, "critic_grad_norm": 0.2764342725276947, "ratio": 1.0000953674316406, "entropy": 0.8777346014976501, "incre_win_rate": 0.7058823529411765, "step": 446}
{"time": 1767153334.8038294, "phase": "train", "update": 447, "total_env_steps": 1430400, "episode_reward": 0.2062106728553772, "value_loss": 0.018493150174617768, "policy_loss": -0.0010256447529975788, "dist_entropy": 0.9061619281768799, "actor_grad_norm": 0.09384708106517792, "critic_grad_norm": 0.13276934623718262, "ratio": 1.0001822710037231, "entropy": 0.9061619281768799, "incre_win_rate": 0.6756756756756757, "step": 447}
{"time": 1767153339.1032197, "phase": "train", "update": 448, "total_env_steps": 1433600, "episode_reward": 0.20440243184566498, "value_loss": 0.018362775817513464, "policy_loss": -0.001110936149715336, "dist_entropy": 0.9361863017082215, "actor_grad_norm": 0.08306246250867844, "critic_grad_norm": 0.25011926889419556, "ratio": 0.9997884035110474, "entropy": 0.9361863017082215, "incre_win_rate": 0.6756756756756757, "step": 448}
{"time": 1767153343.4068878, "phase": "train", "update": 449, "total_env_steps": 1436800, "episode_reward": 0.19928443431854248, "value_loss": 0.02265482172369957, "policy_loss": -0.0010269474055853323, "dist_entropy": 0.9303506255149842, "actor_grad_norm": 0.08554136753082275, "critic_grad_norm": 0.20229163765907288, "ratio": 0.9999456405639648, "entropy": 0.9303506255149842, "incre_win_rate": 0.6486486486486487, "step": 449}
{"time": 1767153347.7983623, "phase": "train", "update": 450, "total_env_steps": 1440000, "episode_reward": 0.21903198957443237, "value_loss": 0.017338541522622108, "policy_loss": -0.0009589574821568192, "dist_entropy": 0.9397264242172241, "actor_grad_norm": 0.10771463066339493, "critic_grad_norm": 0.19561605155467987, "ratio": 1.0002084970474243, "entropy": 0.9397264242172241, "incre_win_rate": 0.7105263157894737, "step": 450}
{"time": 1767153352.0777192, "phase": "train", "update": 451, "total_env_steps": 1443200, "episode_reward": 0.19566741585731506, "value_loss": 0.02665989212691784, "policy_loss": -0.0013942325576515203, "dist_entropy": 0.9297679424285888, "actor_grad_norm": 0.11534933000802994, "critic_grad_norm": 0.353183776140213, "ratio": 0.99992436170578, "entropy": 0.9297679424285888, "incre_win_rate": 0.5945945945945946, "step": 451}
{"time": 1767153356.3322258, "phase": "train", "update": 452, "total_env_steps": 1446400, "episode_reward": 0.20524835586547852, "value_loss": 0.019317329674959183, "policy_loss": -0.0014279111142897704, "dist_entropy": 0.9290225982666016, "actor_grad_norm": 0.13625995814800262, "critic_grad_norm": 0.24028067290782928, "ratio": 1.0001866817474365, "entropy": 0.9290225982666016, "incre_win_rate": 0.6571428571428571, "step": 452}
{"time": 1767153360.6390793, "phase": "train", "update": 453, "total_env_steps": 1449600, "episode_reward": 0.21203020215034485, "value_loss": 0.019535128399729727, "policy_loss": -0.000769126491863581, "dist_entropy": 0.9149623990058899, "actor_grad_norm": 0.1354578286409378, "critic_grad_norm": 0.24277372658252716, "ratio": 0.9995237588882446, "entropy": 0.9149623990058899, "incre_win_rate": 0.725, "step": 453}
{"time": 1767153364.88798, "phase": "train", "update": 454, "total_env_steps": 1452800, "episode_reward": 0.20534612238407135, "value_loss": 0.017753323912620543, "policy_loss": -0.0012126343922915339, "dist_entropy": 0.9249451041221619, "actor_grad_norm": 0.16129140555858612, "critic_grad_norm": 0.1352686882019043, "ratio": 0.999841034412384, "entropy": 0.9249451041221619, "incre_win_rate": 0.7142857142857143, "step": 454}
{"time": 1767153369.1896574, "phase": "train", "update": 455, "total_env_steps": 1456000, "episode_reward": 0.21253621578216553, "value_loss": 0.019085677713155745, "policy_loss": -0.0008790363779051624, "dist_entropy": 0.9119046568870545, "actor_grad_norm": 0.10269653797149658, "critic_grad_norm": 0.13578975200653076, "ratio": 0.999951183795929, "entropy": 0.9119046568870545, "incre_win_rate": 0.7777777777777778, "step": 455}
{"time": 1767153373.5002327, "phase": "train", "update": 456, "total_env_steps": 1459200, "episode_reward": 0.2132476270198822, "value_loss": 0.016406121104955672, "policy_loss": -0.0015266540758887004, "dist_entropy": 0.8883549213409424, "actor_grad_norm": 0.10838935524225235, "critic_grad_norm": 0.15584306418895721, "ratio": 0.9999628067016602, "entropy": 0.8883549213409424, "incre_win_rate": 0.75, "step": 456}
{"time": 1767153377.7705128, "phase": "train", "update": 457, "total_env_steps": 1462400, "episode_reward": 0.20768627524375916, "value_loss": 0.018529314920306204, "policy_loss": -0.0009086006990257189, "dist_entropy": 0.8918364644050598, "actor_grad_norm": 0.11480613052845001, "critic_grad_norm": 0.19717924296855927, "ratio": 0.9996113777160645, "entropy": 0.8918364644050598, "incre_win_rate": 0.7368421052631579, "step": 457}
{"time": 1767153382.1058524, "phase": "train", "update": 458, "total_env_steps": 1465600, "episode_reward": 0.20377640426158905, "value_loss": 0.021550309285521506, "policy_loss": -0.0013855604879616124, "dist_entropy": 0.8961095929145813, "actor_grad_norm": 0.12140034884214401, "critic_grad_norm": 0.17925621569156647, "ratio": 0.999710202217102, "entropy": 0.8961095929145813, "incre_win_rate": 0.6571428571428571, "step": 458}
{"time": 1767153386.3895726, "phase": "train", "update": 459, "total_env_steps": 1468800, "episode_reward": 0.20788544416427612, "value_loss": 0.014517027884721756, "policy_loss": -0.0012685796027060547, "dist_entropy": 0.9086236000061035, "actor_grad_norm": 0.13580654561519623, "critic_grad_norm": 0.3221561014652252, "ratio": 1.0003252029418945, "entropy": 0.9086236000061035, "incre_win_rate": 0.75, "step": 459}
{"time": 1767153390.6917858, "phase": "train", "update": 460, "total_env_steps": 1472000, "episode_reward": 0.2078518271446228, "value_loss": 0.01784380152821541, "policy_loss": -0.001113472538425242, "dist_entropy": 0.9078128218650818, "actor_grad_norm": 0.12000516802072525, "critic_grad_norm": 0.20642434060573578, "ratio": 1.0002754926681519, "entropy": 0.9078128218650818, "incre_win_rate": 0.6578947368421053, "step": 460}
{"time": 1767153394.9985247, "phase": "train", "update": 461, "total_env_steps": 1475200, "episode_reward": 0.20608443021774292, "value_loss": 0.016745233535766603, "policy_loss": -0.0010356290573533045, "dist_entropy": 0.9180104494094848, "actor_grad_norm": 0.14346764981746674, "critic_grad_norm": 0.22351251542568207, "ratio": 1.0001355409622192, "entropy": 0.9180104494094848, "incre_win_rate": 0.7027027027027027, "step": 461}
{"time": 1767153407.3717651, "phase": "eval", "update": 461, "total_env_steps": 1475200, "eval_win_rate": 0.875, "eval_episode_reward": 19.531922599337747, "step": 461}
{"time": 1767153411.6562893, "phase": "train", "update": 462, "total_env_steps": 1478400, "episode_reward": 0.19788751006126404, "value_loss": 0.016832980141043664, "policy_loss": -0.0011927781998469556, "dist_entropy": 0.9076937317848206, "actor_grad_norm": 0.12022552639245987, "critic_grad_norm": 0.08132701367139816, "ratio": 0.9999752044677734, "entropy": 0.9076937317848206, "incre_win_rate": 0.6176470588235294, "step": 462}
{"time": 1767153415.9509914, "phase": "train", "update": 463, "total_env_steps": 1481600, "episode_reward": 0.20713111758232117, "value_loss": 0.020510079339146614, "policy_loss": -0.0012111355872853834, "dist_entropy": 0.8783015131950378, "actor_grad_norm": 0.1193384900689125, "critic_grad_norm": 0.12312157452106476, "ratio": 1.0001184940338135, "entropy": 0.8783015131950378, "incre_win_rate": 0.6923076923076923, "step": 463}
{"time": 1767153420.2909844, "phase": "train", "update": 464, "total_env_steps": 1484800, "episode_reward": 0.1982419192790985, "value_loss": 0.016737961024045945, "policy_loss": -0.001179340098033066, "dist_entropy": 0.8520789504051208, "actor_grad_norm": 0.09107573330402374, "critic_grad_norm": 0.08806248009204865, "ratio": 0.9998517036437988, "entropy": 0.8520789504051208, "incre_win_rate": 0.6666666666666666, "step": 464}
{"time": 1767153424.6016743, "phase": "train", "update": 465, "total_env_steps": 1488000, "episode_reward": 0.20577453076839447, "value_loss": 0.016475562751293183, "policy_loss": -0.0008525713042391913, "dist_entropy": 0.8628084182739257, "actor_grad_norm": 0.0858488380908966, "critic_grad_norm": 0.08817936480045319, "ratio": 1.0001195669174194, "entropy": 0.8628084182739257, "incre_win_rate": 0.7352941176470589, "step": 465}
{"time": 1767153428.8966832, "phase": "train", "update": 466, "total_env_steps": 1491200, "episode_reward": 0.2115030139684677, "value_loss": 0.01295869592577219, "policy_loss": -0.0009135966917950711, "dist_entropy": 0.8408604741096497, "actor_grad_norm": 0.07765727490186691, "critic_grad_norm": 0.07713247090578079, "ratio": 0.9997676014900208, "entropy": 0.8408604741096497, "incre_win_rate": 0.8157894736842105, "step": 466}
{"time": 1767153433.2016246, "phase": "train", "update": 467, "total_env_steps": 1494400, "episode_reward": 0.20923374593257904, "value_loss": 0.014719917438924313, "policy_loss": -0.0010309570742482066, "dist_entropy": 0.8620914220809937, "actor_grad_norm": 0.15913058817386627, "critic_grad_norm": 0.07265986502170563, "ratio": 0.9998185038566589, "entropy": 0.8620914220809937, "incre_win_rate": 0.6857142857142857, "step": 467}
{"time": 1767153437.508297, "phase": "train", "update": 468, "total_env_steps": 1497600, "episode_reward": 0.211150661110878, "value_loss": 0.014537442103028297, "policy_loss": -0.0010061551467515529, "dist_entropy": 0.8285328984260559, "actor_grad_norm": 0.10445477813482285, "critic_grad_norm": 0.12277045100927353, "ratio": 1.0000931024551392, "entropy": 0.8285328984260559, "incre_win_rate": 0.7777777777777778, "step": 468}
{"time": 1767153441.737849, "phase": "train", "update": 469, "total_env_steps": 1500800, "episode_reward": 0.21496792137622833, "value_loss": 0.01651292182505131, "policy_loss": -0.0008293860964926125, "dist_entropy": 0.8501261830329895, "actor_grad_norm": 0.09131952375173569, "critic_grad_norm": 0.08730527013540268, "ratio": 0.999811589717865, "entropy": 0.8501261830329895, "incre_win_rate": 0.7027027027027027, "step": 469}
{"time": 1767153446.035949, "phase": "train", "update": 470, "total_env_steps": 1504000, "episode_reward": 0.18730443716049194, "value_loss": 0.022104723006486894, "policy_loss": -0.0013485532273477929, "dist_entropy": 0.8638447761535645, "actor_grad_norm": 0.10839515924453735, "critic_grad_norm": 0.36587420105934143, "ratio": 0.9996433258056641, "entropy": 0.8638447761535645, "incre_win_rate": 0.5142857142857142, "step": 470}
{"time": 1767153450.3181074, "phase": "train", "update": 471, "total_env_steps": 1507200, "episode_reward": 0.20716112852096558, "value_loss": 0.019476893916726114, "policy_loss": -0.0014421868419006501, "dist_entropy": 0.846461832523346, "actor_grad_norm": 0.1525869369506836, "critic_grad_norm": 0.22588887810707092, "ratio": 0.9996887445449829, "entropy": 0.846461832523346, "incre_win_rate": 0.6923076923076923, "step": 471}
{"time": 1767153454.6004431, "phase": "train", "update": 472, "total_env_steps": 1510400, "episode_reward": 0.21932430565357208, "value_loss": 0.014205952547490597, "policy_loss": -0.0009593842031968336, "dist_entropy": 0.8367214202880859, "actor_grad_norm": 0.08595432341098785, "critic_grad_norm": 0.21233223378658295, "ratio": 1.000145673751831, "entropy": 0.8367214202880859, "incre_win_rate": 0.8055555555555556, "step": 472}
{"time": 1767153458.8697312, "phase": "train", "update": 473, "total_env_steps": 1513600, "episode_reward": 0.20775920152664185, "value_loss": 0.019819746911525726, "policy_loss": -0.00153831128881734, "dist_entropy": 0.821376621723175, "actor_grad_norm": 0.1281481236219406, "critic_grad_norm": 0.1686640828847885, "ratio": 0.9999191164970398, "entropy": 0.821376621723175, "incre_win_rate": 0.6756756756756757, "step": 473}
{"time": 1767153463.1513772, "phase": "train", "update": 474, "total_env_steps": 1516800, "episode_reward": 0.20900869369506836, "value_loss": 0.013555552624166013, "policy_loss": -0.001130982956481219, "dist_entropy": 0.8432164788246155, "actor_grad_norm": 0.09896933287382126, "critic_grad_norm": 0.09801249951124191, "ratio": 0.9999510049819946, "entropy": 0.8432164788246155, "incre_win_rate": 0.7631578947368421, "step": 474}
{"time": 1767153467.48051, "phase": "train", "update": 475, "total_env_steps": 1520000, "episode_reward": 0.2174586057662964, "value_loss": 0.016887763515114784, "policy_loss": -0.0011397245865765627, "dist_entropy": 0.8177491068840027, "actor_grad_norm": 0.08050176501274109, "critic_grad_norm": 0.10848092287778854, "ratio": 1.0001493692398071, "entropy": 0.8177491068840027, "incre_win_rate": 0.8055555555555556, "step": 475}
{"time": 1767153471.806808, "phase": "train", "update": 476, "total_env_steps": 1523200, "episode_reward": 0.20982927083969116, "value_loss": 0.02135237455368042, "policy_loss": -0.0012404661810641927, "dist_entropy": 0.8173296332359314, "actor_grad_norm": 0.10107757896184921, "critic_grad_norm": 0.11161654442548752, "ratio": 1.0001190900802612, "entropy": 0.8173296332359314, "incre_win_rate": 0.6842105263157895, "step": 476}
{"time": 1767153476.1189375, "phase": "train", "update": 477, "total_env_steps": 1526400, "episode_reward": 0.2140304148197174, "value_loss": 0.01762721426784992, "policy_loss": -0.0010786207611928945, "dist_entropy": 0.7831809878349304, "actor_grad_norm": 0.0956452414393425, "critic_grad_norm": 0.19764244556427002, "ratio": 1.000003695487976, "entropy": 0.7831809878349304, "incre_win_rate": 0.6842105263157895, "step": 477}
{"time": 1767153480.4007978, "phase": "train", "update": 478, "total_env_steps": 1529600, "episode_reward": 0.20673377811908722, "value_loss": 0.020899157598614694, "policy_loss": -0.0012011063142324473, "dist_entropy": 0.7909807920455932, "actor_grad_norm": 0.0955609679222107, "critic_grad_norm": 0.11505071073770523, "ratio": 0.9999876022338867, "entropy": 0.7909807920455932, "incre_win_rate": 0.7428571428571429, "step": 478}
{"time": 1767153484.651837, "phase": "train", "update": 479, "total_env_steps": 1532800, "episode_reward": 0.2066551148891449, "value_loss": 0.016620218008756637, "policy_loss": -0.0011262454872532856, "dist_entropy": 0.7743173360824585, "actor_grad_norm": 0.09830086678266525, "critic_grad_norm": 0.1138436570763588, "ratio": 0.9996756911277771, "entropy": 0.7743173360824585, "incre_win_rate": 0.7105263157894737, "step": 479}
{"time": 1767153488.8613143, "phase": "train", "update": 480, "total_env_steps": 1536000, "episode_reward": 0.2117999792098999, "value_loss": 0.01422029733657837, "policy_loss": -0.0009025281322237788, "dist_entropy": 0.7768723845481873, "actor_grad_norm": 0.12718534469604492, "critic_grad_norm": 0.1394214779138565, "ratio": 0.9999883770942688, "entropy": 0.7768723845481873, "incre_win_rate": 0.7941176470588235, "step": 480}
{"time": 1767153493.1051955, "phase": "train", "update": 481, "total_env_steps": 1539200, "episode_reward": 0.2061946541070938, "value_loss": 0.012488997541368008, "policy_loss": -0.0012380763708723208, "dist_entropy": 0.7885972619056701, "actor_grad_norm": 0.11903591454029083, "critic_grad_norm": 0.1449563354253769, "ratio": 0.9996606111526489, "entropy": 0.7885972619056701, "incre_win_rate": 0.7368421052631579, "step": 481}
{"time": 1767153506.1343434, "phase": "eval", "update": 481, "total_env_steps": 1539200, "eval_win_rate": 0.6875, "eval_episode_reward": 18.0116928807947, "step": 481}
{"time": 1767153510.4222853, "phase": "train", "update": 482, "total_env_steps": 1542400, "episode_reward": 0.2025429606437683, "value_loss": 0.017448735982179643, "policy_loss": -0.0009958927124412043, "dist_entropy": 0.7975260615348816, "actor_grad_norm": 0.09847810864448547, "critic_grad_norm": 0.11501667648553848, "ratio": 1.0000070333480835, "entropy": 0.7975260615348816, "incre_win_rate": 0.6486486486486487, "step": 482}
{"time": 1767153514.7149408, "phase": "train", "update": 483, "total_env_steps": 1545600, "episode_reward": 0.21186517179012299, "value_loss": 0.01779370829463005, "policy_loss": -0.000862817794869386, "dist_entropy": 0.8015965580940246, "actor_grad_norm": 0.10887116193771362, "critic_grad_norm": 0.1365334540605545, "ratio": 0.9999208450317383, "entropy": 0.8015965580940246, "incre_win_rate": 0.7222222222222222, "step": 483}
{"time": 1767153518.9948401, "phase": "train", "update": 484, "total_env_steps": 1548800, "episode_reward": 0.20691898465156555, "value_loss": 0.015719320997595786, "policy_loss": -0.0011343241617943534, "dist_entropy": 0.8209394335746765, "actor_grad_norm": 0.09937676042318344, "critic_grad_norm": 0.12769852578639984, "ratio": 1.0001850128173828, "entropy": 0.8209394335746765, "incre_win_rate": 0.6923076923076923, "step": 484}
{"time": 1767153523.2504106, "phase": "train", "update": 485, "total_env_steps": 1552000, "episode_reward": 0.21005691587924957, "value_loss": 0.012860832177102566, "policy_loss": -0.0010623238980670634, "dist_entropy": 0.8183686137199402, "actor_grad_norm": 0.07978629320859909, "critic_grad_norm": 0.10267674922943115, "ratio": 0.9999505281448364, "entropy": 0.8183686137199402, "incre_win_rate": 0.7575757575757576, "step": 485}
{"time": 1767153527.4713914, "phase": "train", "update": 486, "total_env_steps": 1555200, "episode_reward": 0.20089559257030487, "value_loss": 0.013256134651601314, "policy_loss": -0.0011765434707200818, "dist_entropy": 0.8245504856109619, "actor_grad_norm": 0.08490578085184097, "critic_grad_norm": 0.26197099685668945, "ratio": 0.9999493956565857, "entropy": 0.8245504856109619, "incre_win_rate": 0.6666666666666666, "step": 486}
{"time": 1767153531.6837552, "phase": "train", "update": 487, "total_env_steps": 1558400, "episode_reward": 0.1994432955980301, "value_loss": 0.015211190283298492, "policy_loss": -0.00131982752678681, "dist_entropy": 0.8097709894180298, "actor_grad_norm": 0.11598774045705795, "critic_grad_norm": 0.31824633479118347, "ratio": 0.9997022747993469, "entropy": 0.8097709894180298, "incre_win_rate": 0.6486486486486487, "step": 487}
{"time": 1767153535.9927595, "phase": "train", "update": 488, "total_env_steps": 1561600, "episode_reward": 0.20934344828128815, "value_loss": 0.015188534557819367, "policy_loss": -0.0008313538044809832, "dist_entropy": 0.7844956636428833, "actor_grad_norm": 0.08945786952972412, "critic_grad_norm": 0.2735592722892761, "ratio": 0.9999422430992126, "entropy": 0.7844956636428833, "incre_win_rate": 0.7428571428571429, "step": 488}
{"time": 1767153540.2945192, "phase": "train", "update": 489, "total_env_steps": 1564800, "episode_reward": 0.2152535319328308, "value_loss": 0.014801529608666897, "policy_loss": -0.0008896713561879821, "dist_entropy": 0.7941744208335877, "actor_grad_norm": 0.07949300855398178, "critic_grad_norm": 0.27212652564048767, "ratio": 0.9998235106468201, "entropy": 0.7941744208335877, "incre_win_rate": 0.8378378378378378, "step": 489}
{"time": 1767153544.5717068, "phase": "train", "update": 490, "total_env_steps": 1568000, "episode_reward": 0.20366410911083221, "value_loss": 0.015756529942154884, "policy_loss": -0.0012212817878141991, "dist_entropy": 0.8037082076072692, "actor_grad_norm": 0.15616758167743683, "critic_grad_norm": 0.13325278460979462, "ratio": 0.9999985694885254, "entropy": 0.8037082076072692, "incre_win_rate": 0.75, "step": 490}
{"time": 1767153578.084167, "phase": "train", "update": 491, "total_env_steps": 1571200, "episode_reward": 0.19998756051063538, "value_loss": 0.07728140503168106, "policy_loss": -0.0009778914716370934, "dist_entropy": 0.8084952235221863, "actor_grad_norm": 0.0794541984796524, "critic_grad_norm": 0.3930431306362152, "ratio": 1.0001933574676514, "entropy": 0.8084952235221863, "incre_win_rate": 0.5757575757575758, "step": 491}
{"time": 1767153582.3647263, "phase": "train", "update": 492, "total_env_steps": 1574400, "episode_reward": 0.21769195795059204, "value_loss": 0.016511987335979937, "policy_loss": -0.0009531546564079729, "dist_entropy": 0.8152231931686401, "actor_grad_norm": 0.08553143590688705, "critic_grad_norm": 0.21797028183937073, "ratio": 0.9999858140945435, "entropy": 0.8152231931686401, "incre_win_rate": 0.8108108108108109, "step": 492}
{"time": 1767153586.6776292, "phase": "train", "update": 493, "total_env_steps": 1577600, "episode_reward": 0.21649162471294403, "value_loss": 0.015112950280308724, "policy_loss": -0.0014778778601836962, "dist_entropy": 0.7913904428482056, "actor_grad_norm": 0.11176715046167374, "critic_grad_norm": 0.19014671444892883, "ratio": 1.0000784397125244, "entropy": 0.7913904428482056, "incre_win_rate": 0.7, "step": 493}
{"time": 1767153590.921018, "phase": "train", "update": 494, "total_env_steps": 1580800, "episode_reward": 0.22091525793075562, "value_loss": 0.01811596341431141, "policy_loss": -0.0009668343159893289, "dist_entropy": 0.8034819722175598, "actor_grad_norm": 0.08814527839422226, "critic_grad_norm": 0.24299946427345276, "ratio": 0.9999489784240723, "entropy": 0.8034819722175598, "incre_win_rate": 0.7777777777777778, "step": 494}
{"time": 1767153595.1566293, "phase": "train", "update": 495, "total_env_steps": 1584000, "episode_reward": 0.2102804332971573, "value_loss": 0.014995409734547138, "policy_loss": -0.001007936085082073, "dist_entropy": 0.8216514945030212, "actor_grad_norm": 0.10717630386352539, "critic_grad_norm": 0.17867134511470795, "ratio": 1.000009298324585, "entropy": 0.8216514945030212, "incre_win_rate": 0.7027027027027027, "step": 495}
{"time": 1767153599.4057596, "phase": "train", "update": 496, "total_env_steps": 1587200, "episode_reward": 0.21636848151683807, "value_loss": 0.018296397849917413, "policy_loss": -0.0008642250506207816, "dist_entropy": 0.7906542539596557, "actor_grad_norm": 0.08457239717245102, "critic_grad_norm": 0.12292405217885971, "ratio": 0.9998677372932434, "entropy": 0.7906542539596557, "incre_win_rate": 0.7631578947368421, "step": 496}
{"time": 1767153603.7001994, "phase": "train", "update": 497, "total_env_steps": 1590400, "episode_reward": 0.20561723411083221, "value_loss": 0.020542101189494132, "policy_loss": -0.001209602876798499, "dist_entropy": 0.8208377718925476, "actor_grad_norm": 0.11171741783618927, "critic_grad_norm": 0.17410774528980255, "ratio": 1.000008463859558, "entropy": 0.8208377718925476, "incre_win_rate": 0.5897435897435898, "step": 497}
{"time": 1767153607.9639795, "phase": "train", "update": 498, "total_env_steps": 1593600, "episode_reward": 0.21029438078403473, "value_loss": 0.018216442316770554, "policy_loss": -0.0015419969841573788, "dist_entropy": 0.8251395702362061, "actor_grad_norm": 0.12947702407836914, "critic_grad_norm": 0.21075628697872162, "ratio": 1.0001904964447021, "entropy": 0.8251395702362061, "incre_win_rate": 0.7297297297297297, "step": 498}
{"time": 1767153612.2775238, "phase": "train", "update": 499, "total_env_steps": 1596800, "episode_reward": 0.21720974147319794, "value_loss": 0.012727493606507777, "policy_loss": -0.0012153555150696605, "dist_entropy": 0.8379070281982421, "actor_grad_norm": 0.08398404717445374, "critic_grad_norm": 0.16045694053173065, "ratio": 1.0000104904174805, "entropy": 0.8379070281982421, "incre_win_rate": 0.7777777777777778, "step": 499}
{"time": 1767153616.5033782, "phase": "train", "update": 500, "total_env_steps": 1600000, "episode_reward": 0.201665461063385, "value_loss": 0.0169809702783823, "policy_loss": -0.0015118651390594096, "dist_entropy": 0.8307721972465515, "actor_grad_norm": 0.12957920134067535, "critic_grad_norm": 0.14956462383270264, "ratio": 0.9997919201850891, "entropy": 0.8307721972465515, "incre_win_rate": 0.7027027027027027, "step": 500}
{"time": 1767153620.7140298, "phase": "train", "update": 501, "total_env_steps": 1603200, "episode_reward": 0.1997656226158142, "value_loss": 0.03198211118578911, "policy_loss": -0.001145980209047792, "dist_entropy": 0.8191892504692078, "actor_grad_norm": 0.09400363266468048, "critic_grad_norm": 0.38787102699279785, "ratio": 0.9996461272239685, "entropy": 0.8191892504692078, "incre_win_rate": 0.7878787878787878, "step": 501}
{"time": 1767153634.312322, "phase": "eval", "update": 501, "total_env_steps": 1603200, "eval_win_rate": 0.65625, "eval_episode_reward": 17.912251655629134, "step": 501}
{"time": 1767153638.601343, "phase": "train", "update": 502, "total_env_steps": 1606400, "episode_reward": 0.2084105908870697, "value_loss": 0.03249436728656292, "policy_loss": -0.0013055793452963372, "dist_entropy": 0.8343462228775025, "actor_grad_norm": 0.13168679177761078, "critic_grad_norm": 0.22846274077892303, "ratio": 1.0001897811889648, "entropy": 0.8343462228775025, "incre_win_rate": 0.717948717948718, "step": 502}
{"time": 1767153642.883405, "phase": "train", "update": 503, "total_env_steps": 1609600, "episode_reward": 0.2036982774734497, "value_loss": 0.020620617270469665, "policy_loss": -0.000930203123331097, "dist_entropy": 0.836570143699646, "actor_grad_norm": 0.11508999019861221, "critic_grad_norm": 0.16057223081588745, "ratio": 0.9998010993003845, "entropy": 0.836570143699646, "incre_win_rate": 0.8387096774193549, "step": 503}
{"time": 1767153647.1703463, "phase": "train", "update": 504, "total_env_steps": 1612800, "episode_reward": 0.2093910574913025, "value_loss": 0.021148617193102837, "policy_loss": -0.001140423745750363, "dist_entropy": 0.8529930233955383, "actor_grad_norm": 0.08618203550577164, "critic_grad_norm": 0.15630227327346802, "ratio": 1.0002782344818115, "entropy": 0.8529930233955383, "incre_win_rate": 0.7692307692307693, "step": 504}
{"time": 1767153651.4398725, "phase": "train", "update": 505, "total_env_steps": 1616000, "episode_reward": 0.22007504105567932, "value_loss": 0.014607272483408451, "policy_loss": -0.0010304578277178455, "dist_entropy": 0.8305312037467957, "actor_grad_norm": 0.14248667657375336, "critic_grad_norm": 0.20443634688854218, "ratio": 1.0003327131271362, "entropy": 0.8305312037467957, "incre_win_rate": 0.8285714285714286, "step": 505}
{"time": 1767153655.7417936, "phase": "train", "update": 506, "total_env_steps": 1619200, "episode_reward": 0.21590232849121094, "value_loss": 0.02370254136621952, "policy_loss": -0.000990944216575329, "dist_entropy": 0.8379532098770142, "actor_grad_norm": 0.13610002398490906, "critic_grad_norm": 0.13797329366207123, "ratio": 1.0000652074813843, "entropy": 0.8379532098770142, "incre_win_rate": 0.7692307692307693, "step": 506}
{"time": 1767153660.0417938, "phase": "train", "update": 507, "total_env_steps": 1622400, "episode_reward": 0.22321657836437225, "value_loss": 0.016900097578763963, "policy_loss": -0.0010901015148945703, "dist_entropy": 0.8571221232414246, "actor_grad_norm": 0.09165703505277634, "critic_grad_norm": 0.18693241477012634, "ratio": 0.9997190833091736, "entropy": 0.8571221232414246, "incre_win_rate": 0.7894736842105263, "step": 507}
{"time": 1767153664.3108287, "phase": "train", "update": 508, "total_env_steps": 1625600, "episode_reward": 0.21998344361782074, "value_loss": 0.015275989472866059, "policy_loss": -0.0014398546830421744, "dist_entropy": 0.8337057590484619, "actor_grad_norm": 0.10390948504209518, "critic_grad_norm": 0.17320013046264648, "ratio": 1.0000141859054565, "entropy": 0.8337057590484619, "incre_win_rate": 0.7692307692307693, "step": 508}
{"time": 1767153668.584471, "phase": "train", "update": 509, "total_env_steps": 1628800, "episode_reward": 0.21328797936439514, "value_loss": 0.01853829249739647, "policy_loss": -0.0009110801590566098, "dist_entropy": 0.8493191719055175, "actor_grad_norm": 0.12410105764865875, "critic_grad_norm": 0.2045084685087204, "ratio": 1.0001707077026367, "entropy": 0.8493191719055175, "incre_win_rate": 0.6410256410256411, "step": 509}
{"time": 1767153672.9095771, "phase": "train", "update": 510, "total_env_steps": 1632000, "episode_reward": 0.2237474024295807, "value_loss": 0.013465722464025021, "policy_loss": -0.0009650401073159287, "dist_entropy": 0.8750643372535706, "actor_grad_norm": 0.10060577839612961, "critic_grad_norm": 0.11724995821714401, "ratio": 0.9999225735664368, "entropy": 0.8750643372535706, "incre_win_rate": 0.7631578947368421, "step": 510}
{"time": 1767153677.2170172, "phase": "train", "update": 511, "total_env_steps": 1635200, "episode_reward": 0.2255101352930069, "value_loss": 0.014286262914538383, "policy_loss": -0.0012624933987158472, "dist_entropy": 0.8724336624145508, "actor_grad_norm": 0.11839956045150757, "critic_grad_norm": 0.13395464420318604, "ratio": 1.0000566244125366, "entropy": 0.8724336624145508, "incre_win_rate": 0.8157894736842105, "step": 511}
{"time": 1767153681.4997497, "phase": "train", "update": 512, "total_env_steps": 1638400, "episode_reward": 0.21992963552474976, "value_loss": 0.01825430952012539, "policy_loss": -0.0014275728274462552, "dist_entropy": 0.8660079836845398, "actor_grad_norm": 0.09729225933551788, "critic_grad_norm": 0.10712957382202148, "ratio": 0.9995865225791931, "entropy": 0.8660079836845398, "incre_win_rate": 0.717948717948718, "step": 512}
{"time": 1767153685.8604898, "phase": "train", "update": 513, "total_env_steps": 1641600, "episode_reward": 0.21801479160785675, "value_loss": 0.01961119771003723, "policy_loss": -0.0011093091076697092, "dist_entropy": 0.8695874571800232, "actor_grad_norm": 0.14741720259189606, "critic_grad_norm": 0.07932841032743454, "ratio": 0.9998654723167419, "entropy": 0.8695874571800232, "incre_win_rate": 0.7297297297297297, "step": 513}
{"time": 1767153690.1371827, "phase": "train", "update": 514, "total_env_steps": 1644800, "episode_reward": 0.2238762229681015, "value_loss": 0.014383691549301147, "policy_loss": -0.0014045576702400807, "dist_entropy": 0.8353371620178223, "actor_grad_norm": 0.11326687783002853, "critic_grad_norm": 0.17533771693706512, "ratio": 0.9997852444648743, "entropy": 0.8353371620178223, "incre_win_rate": 0.8205128205128205, "step": 514}
{"time": 1767153694.4218354, "phase": "train", "update": 515, "total_env_steps": 1648000, "episode_reward": 0.22538337111473083, "value_loss": 0.010839634016156197, "policy_loss": -0.000702631409018295, "dist_entropy": 0.8329903602600097, "actor_grad_norm": 0.11910086125135422, "critic_grad_norm": 0.13052554428577423, "ratio": 1.0003618001937866, "entropy": 0.8329903602600097, "incre_win_rate": 0.8571428571428571, "step": 515}
{"time": 1767153698.6964254, "phase": "train", "update": 516, "total_env_steps": 1651200, "episode_reward": 0.21728631854057312, "value_loss": 0.015449653379619122, "policy_loss": -0.0011960196005794898, "dist_entropy": 0.807141923904419, "actor_grad_norm": 0.13292533159255981, "critic_grad_norm": 0.1366705745458603, "ratio": 0.999769389629364, "entropy": 0.807141923904419, "incre_win_rate": 0.8157894736842105, "step": 516}
{"time": 1767153702.979557, "phase": "train", "update": 517, "total_env_steps": 1654400, "episode_reward": 0.22077040374279022, "value_loss": 0.011468465253710747, "policy_loss": -0.0008086659511576499, "dist_entropy": 0.8297272205352784, "actor_grad_norm": 0.08932536095380783, "critic_grad_norm": 0.09913619607686996, "ratio": 1.0003411769866943, "entropy": 0.8297272205352784, "incre_win_rate": 0.8205128205128205, "step": 517}
{"time": 1767153707.3038988, "phase": "train", "update": 518, "total_env_steps": 1657600, "episode_reward": 0.22305823862552643, "value_loss": 0.012976902537047863, "policy_loss": -0.0013867599080537474, "dist_entropy": 0.8136726021766663, "actor_grad_norm": 0.09219498932361603, "critic_grad_norm": 0.07710881531238556, "ratio": 0.9997796416282654, "entropy": 0.8136726021766663, "incre_win_rate": 0.7692307692307693, "step": 518}
{"time": 1767153711.586881, "phase": "train", "update": 519, "total_env_steps": 1660800, "episode_reward": 0.21686983108520508, "value_loss": 0.013971294835209846, "policy_loss": -0.0009689245473559538, "dist_entropy": 0.8118946433067322, "actor_grad_norm": 0.10427991300821304, "critic_grad_norm": 0.17443014681339264, "ratio": 0.9997276663780212, "entropy": 0.8118946433067322, "incre_win_rate": 0.75, "step": 519}
{"time": 1767153715.8953037, "phase": "train", "update": 520, "total_env_steps": 1664000, "episode_reward": 0.22204676270484924, "value_loss": 0.01739269681274891, "policy_loss": -0.001123933595576343, "dist_entropy": 0.8068456172943115, "actor_grad_norm": 0.10227184742689133, "critic_grad_norm": 0.13278421759605408, "ratio": 1.000357985496521, "entropy": 0.8068456172943115, "incre_win_rate": 0.7567567567567568, "step": 520}
{"time": 1767153720.2017033, "phase": "train", "update": 521, "total_env_steps": 1667200, "episode_reward": 0.23182377219200134, "value_loss": 0.015724604576826097, "policy_loss": -0.0011463945109454698, "dist_entropy": 0.8095842599868774, "actor_grad_norm": 0.08445936441421509, "critic_grad_norm": 0.2932502329349518, "ratio": 1.0000728368759155, "entropy": 0.8095842599868774, "incre_win_rate": 0.775, "step": 521}
{"time": 1767153733.2709167, "phase": "eval", "update": 521, "total_env_steps": 1667200, "eval_win_rate": 0.71875, "eval_episode_reward": 18.542580711920525, "step": 521}
{"time": 1767153737.5724304, "phase": "train", "update": 522, "total_env_steps": 1670400, "episode_reward": 0.22493843734264374, "value_loss": 0.016022811830043792, "policy_loss": -0.001255729700955044, "dist_entropy": 0.8185485482215882, "actor_grad_norm": 0.0835302397608757, "critic_grad_norm": 0.2234734147787094, "ratio": 0.9997181296348572, "entropy": 0.8185485482215882, "incre_win_rate": 0.825, "step": 522}
{"time": 1767153741.834474, "phase": "train", "update": 523, "total_env_steps": 1673600, "episode_reward": 0.21642953157424927, "value_loss": 0.015584749914705754, "policy_loss": -0.0009919238039412192, "dist_entropy": 0.8073805093765258, "actor_grad_norm": 0.09863439947366714, "critic_grad_norm": 0.21623411774635315, "ratio": 0.9998990893363953, "entropy": 0.8073805093765258, "incre_win_rate": 0.7692307692307693, "step": 523}
{"time": 1767153746.1376834, "phase": "train", "update": 524, "total_env_steps": 1676800, "episode_reward": 0.22268471121788025, "value_loss": 0.014849558472633362, "policy_loss": -0.0014061416278849492, "dist_entropy": 0.822207760810852, "actor_grad_norm": 0.13812027871608734, "critic_grad_norm": 0.07822545617818832, "ratio": 0.9997888803482056, "entropy": 0.822207760810852, "incre_win_rate": 0.7837837837837838, "step": 524}
{"time": 1767153750.3981793, "phase": "train", "update": 525, "total_env_steps": 1680000, "episode_reward": 0.21288026869297028, "value_loss": 0.01683865338563919, "policy_loss": -0.0011258089930566762, "dist_entropy": 0.8445453643798828, "actor_grad_norm": 0.12197480350732803, "critic_grad_norm": 0.09146151691675186, "ratio": 0.999771237373352, "entropy": 0.8445453643798828, "incre_win_rate": 0.7714285714285715, "step": 525}
{"time": 1767153754.6976123, "phase": "train", "update": 526, "total_env_steps": 1683200, "episode_reward": 0.2301526516675949, "value_loss": 0.01130382064729929, "policy_loss": -0.001158916323547743, "dist_entropy": 0.8096821069717407, "actor_grad_norm": 0.1313590407371521, "critic_grad_norm": 0.22768285870552063, "ratio": 1.0001592636108398, "entropy": 0.8096821069717407, "incre_win_rate": 0.8461538461538461, "step": 526}
{"time": 1767153758.9506495, "phase": "train", "update": 527, "total_env_steps": 1686400, "episode_reward": 0.21668511629104614, "value_loss": 0.010644984245300294, "policy_loss": -0.001165802311527031, "dist_entropy": 0.8242474913597106, "actor_grad_norm": 0.115036241710186, "critic_grad_norm": 0.16101442277431488, "ratio": 0.9998515248298645, "entropy": 0.8242474913597106, "incre_win_rate": 0.8378378378378378, "step": 527}
{"time": 1767153763.265092, "phase": "train", "update": 528, "total_env_steps": 1689600, "episode_reward": 0.2078332006931305, "value_loss": 0.01623543296009302, "policy_loss": -0.0016062857330823022, "dist_entropy": 0.8437459945678711, "actor_grad_norm": 0.17235055565834045, "critic_grad_norm": 0.36005720496177673, "ratio": 0.9997931718826294, "entropy": 0.8437459945678711, "incre_win_rate": 0.631578947368421, "step": 528}
{"time": 1767153767.576836, "phase": "train", "update": 529, "total_env_steps": 1692800, "episode_reward": 0.22062914073467255, "value_loss": 0.012880830466747284, "policy_loss": -0.0012818730367513353, "dist_entropy": 0.8415311813354492, "actor_grad_norm": 0.10500723123550415, "critic_grad_norm": 0.24293985962867737, "ratio": 0.9995671510696411, "entropy": 0.8415311813354492, "incre_win_rate": 0.7837837837837838, "step": 529}
{"time": 1767153771.8990397, "phase": "train", "update": 530, "total_env_steps": 1696000, "episode_reward": 0.23821191489696503, "value_loss": 0.010815509036183358, "policy_loss": -0.0010458150894415929, "dist_entropy": 0.8222458720207214, "actor_grad_norm": 0.11777714639902115, "critic_grad_norm": 0.28278928995132446, "ratio": 1.0000571012496948, "entropy": 0.8222458720207214, "incre_win_rate": 0.9230769230769231, "step": 530}
{"time": 1767153776.237394, "phase": "train", "update": 531, "total_env_steps": 1699200, "episode_reward": 0.22123396396636963, "value_loss": 0.01625057365745306, "policy_loss": -0.001012164935381321, "dist_entropy": 0.8219390392303467, "actor_grad_norm": 0.09436764568090439, "critic_grad_norm": 0.16306890547275543, "ratio": 0.9999464154243469, "entropy": 0.8219390392303467, "incre_win_rate": 0.7692307692307693, "step": 531}
{"time": 1767153780.534819, "phase": "train", "update": 532, "total_env_steps": 1702400, "episode_reward": 0.21947847306728363, "value_loss": 0.01532195247709751, "policy_loss": -0.0011729760074530304, "dist_entropy": 0.8403736710548401, "actor_grad_norm": 0.093790203332901, "critic_grad_norm": 0.15794289112091064, "ratio": 1.0001906156539917, "entropy": 0.8403736710548401, "incre_win_rate": 0.7837837837837838, "step": 532}
{"time": 1767153784.822229, "phase": "train", "update": 533, "total_env_steps": 1705600, "episode_reward": 0.21977494657039642, "value_loss": 0.01074080653488636, "policy_loss": -0.0012253972144732118, "dist_entropy": 0.8302227258682251, "actor_grad_norm": 0.11397907882928848, "critic_grad_norm": 0.06016964465379715, "ratio": 1.000087857246399, "entropy": 0.8302227258682251, "incre_win_rate": 0.8378378378378378, "step": 533}
{"time": 1767153789.1072512, "phase": "train", "update": 534, "total_env_steps": 1708800, "episode_reward": 0.21703746914863586, "value_loss": 0.013020435720682145, "policy_loss": -0.0013085220001830323, "dist_entropy": 0.8414125204086303, "actor_grad_norm": 0.12593671679496765, "critic_grad_norm": 0.058084797114133835, "ratio": 0.9999656677246094, "entropy": 0.8414125204086303, "incre_win_rate": 0.7297297297297297, "step": 534}
{"time": 1767153793.3985944, "phase": "train", "update": 535, "total_env_steps": 1712000, "episode_reward": 0.22118791937828064, "value_loss": 0.010346716828644275, "policy_loss": -0.001312351453607974, "dist_entropy": 0.8297920465469361, "actor_grad_norm": 0.11892777681350708, "critic_grad_norm": 0.06715445965528488, "ratio": 1.0002093315124512, "entropy": 0.8297920465469361, "incre_win_rate": 0.8421052631578947, "step": 535}
{"time": 1767153797.7186942, "phase": "train", "update": 536, "total_env_steps": 1715200, "episode_reward": 0.21879811584949493, "value_loss": 0.02380983456969261, "policy_loss": -0.0009742299104525288, "dist_entropy": 0.8239621162414551, "actor_grad_norm": 0.10888671875, "critic_grad_norm": 0.21818366646766663, "ratio": 0.9999811053276062, "entropy": 0.8239621162414551, "incre_win_rate": 0.8378378378378378, "step": 536}
{"time": 1767153801.9975636, "phase": "train", "update": 537, "total_env_steps": 1718400, "episode_reward": 0.21164579689502716, "value_loss": 0.012757466547191143, "policy_loss": -0.0012568754223707401, "dist_entropy": 0.8483937382698059, "actor_grad_norm": 0.11880546063184738, "critic_grad_norm": 0.21184657514095306, "ratio": 0.9999035000801086, "entropy": 0.8483937382698059, "incre_win_rate": 0.6842105263157895, "step": 537}
{"time": 1767153806.294656, "phase": "train", "update": 538, "total_env_steps": 1721600, "episode_reward": 0.2116597592830658, "value_loss": 0.015536516904830933, "policy_loss": -0.0011897254791578328, "dist_entropy": 0.8659849047660828, "actor_grad_norm": 0.10845885425806046, "critic_grad_norm": 0.23091380298137665, "ratio": 0.9999741911888123, "entropy": 0.8659849047660828, "incre_win_rate": 0.7142857142857143, "step": 538}
{"time": 1767153810.601201, "phase": "train", "update": 539, "total_env_steps": 1724800, "episode_reward": 0.20094524323940277, "value_loss": 0.016993712261319162, "policy_loss": -0.0011119950301484494, "dist_entropy": 0.8608853101730347, "actor_grad_norm": 0.12819091975688934, "critic_grad_norm": 0.23870718479156494, "ratio": 1.0001747608184814, "entropy": 0.8608853101730347, "incre_win_rate": 0.6111111111111112, "step": 539}
{"time": 1767153814.8834405, "phase": "train", "update": 540, "total_env_steps": 1728000, "episode_reward": 0.22904902696609497, "value_loss": 0.011788195371627808, "policy_loss": -0.0013700772455322863, "dist_entropy": 0.8496264100074769, "actor_grad_norm": 0.10776706039905548, "critic_grad_norm": 0.2859567403793335, "ratio": 1.0001367330551147, "entropy": 0.8496264100074769, "incre_win_rate": 0.8461538461538461, "step": 540}
{"time": 1767153819.1372437, "phase": "train", "update": 541, "total_env_steps": 1731200, "episode_reward": 0.2142772078514099, "value_loss": 0.015115836448967458, "policy_loss": -0.0013781452146801598, "dist_entropy": 0.8361273527145385, "actor_grad_norm": 0.12470803409814835, "critic_grad_norm": 0.15931835770606995, "ratio": 1.0001542568206787, "entropy": 0.8361273527145385, "incre_win_rate": 0.7222222222222222, "step": 541}
{"time": 1767153831.9307547, "phase": "eval", "update": 541, "total_env_steps": 1731200, "eval_win_rate": 0.75, "eval_episode_reward": 18.852597268211916, "step": 541}
{"time": 1767153836.2174907, "phase": "train", "update": 542, "total_env_steps": 1734400, "episode_reward": 0.22530008852481842, "value_loss": 0.012195845693349838, "policy_loss": -0.0011407342473098935, "dist_entropy": 0.8209311127662658, "actor_grad_norm": 0.10655732452869415, "critic_grad_norm": 0.13901697099208832, "ratio": 0.9999851584434509, "entropy": 0.8209311127662658, "incre_win_rate": 0.8461538461538461, "step": 542}
{"time": 1767153840.5283842, "phase": "train", "update": 543, "total_env_steps": 1737600, "episode_reward": 0.20435896515846252, "value_loss": 0.01741708442568779, "policy_loss": -0.001488599256285994, "dist_entropy": 0.846151614189148, "actor_grad_norm": 0.11784883588552475, "critic_grad_norm": 0.33440274000167847, "ratio": 0.9998002052307129, "entropy": 0.846151614189148, "incre_win_rate": 0.6111111111111112, "step": 543}
{"time": 1767153844.8107755, "phase": "train", "update": 544, "total_env_steps": 1740800, "episode_reward": 0.1964786946773529, "value_loss": 0.01806616224348545, "policy_loss": -0.0011391519943813933, "dist_entropy": 0.8478063106536865, "actor_grad_norm": 0.14697317779064178, "critic_grad_norm": 0.24327273666858673, "ratio": 0.9995734095573425, "entropy": 0.8478063106536865, "incre_win_rate": 0.5526315789473685, "step": 544}
{"time": 1767153849.09942, "phase": "train", "update": 545, "total_env_steps": 1744000, "episode_reward": 0.22733858227729797, "value_loss": 0.01632507275789976, "policy_loss": -0.0014445252787361085, "dist_entropy": 0.8338658094406128, "actor_grad_norm": 0.11086423695087433, "critic_grad_norm": 0.42630472779273987, "ratio": 0.9999621510505676, "entropy": 0.8338658094406128, "incre_win_rate": 0.7837837837837838, "step": 545}
{"time": 1767153853.356128, "phase": "train", "update": 546, "total_env_steps": 1747200, "episode_reward": 0.204492449760437, "value_loss": 0.01368592567741871, "policy_loss": -0.0009502150805655418, "dist_entropy": 0.8233407258987426, "actor_grad_norm": 0.1205875426530838, "critic_grad_norm": 0.25546255707740784, "ratio": 0.9996891021728516, "entropy": 0.8233407258987426, "incre_win_rate": 0.6944444444444444, "step": 546}
{"time": 1767153857.6425328, "phase": "train", "update": 547, "total_env_steps": 1750400, "episode_reward": 0.2183775007724762, "value_loss": 0.015594537369906902, "policy_loss": -0.001416673913077915, "dist_entropy": 0.8241838455200196, "actor_grad_norm": 0.16356778144836426, "critic_grad_norm": 0.25130414962768555, "ratio": 0.9999271631240845, "entropy": 0.8241838455200196, "incre_win_rate": 0.7692307692307693, "step": 547}
{"time": 1767153861.918103, "phase": "train", "update": 548, "total_env_steps": 1753600, "episode_reward": 0.2077452540397644, "value_loss": 0.016052155382931234, "policy_loss": -0.0007897931580579609, "dist_entropy": 0.860344135761261, "actor_grad_norm": 0.08632545918226242, "critic_grad_norm": 0.31316909193992615, "ratio": 0.9999980926513672, "entropy": 0.860344135761261, "incre_win_rate": 0.631578947368421, "step": 548}
{"time": 1767153866.2388196, "phase": "train", "update": 549, "total_env_steps": 1756800, "episode_reward": 0.22733856737613678, "value_loss": 0.010256233252584934, "policy_loss": -0.0011789090082586994, "dist_entropy": 0.83652104139328, "actor_grad_norm": 0.09652490168809891, "critic_grad_norm": 0.2558954656124115, "ratio": 1.000220775604248, "entropy": 0.83652104139328, "incre_win_rate": 0.8108108108108109, "step": 549}
{"time": 1767153870.525804, "phase": "train", "update": 550, "total_env_steps": 1760000, "episode_reward": 0.21222060918807983, "value_loss": 0.011100629530847072, "policy_loss": -0.001332330041403651, "dist_entropy": 0.8347888469696045, "actor_grad_norm": 0.13323239982128143, "critic_grad_norm": 0.20432808995246887, "ratio": 0.9997320175170898, "entropy": 0.8347888469696045, "incre_win_rate": 0.7941176470588235, "step": 550}
{"time": 1767153874.830513, "phase": "train", "update": 551, "total_env_steps": 1763200, "episode_reward": 0.22467714548110962, "value_loss": 0.013509025797247887, "policy_loss": -0.0015480126688494523, "dist_entropy": 0.8296272039413453, "actor_grad_norm": 0.12062834948301315, "critic_grad_norm": 0.1441212296485901, "ratio": 1.0000723600387573, "entropy": 0.8296272039413453, "incre_win_rate": 0.8, "step": 551}
{"time": 1767153879.1355543, "phase": "train", "update": 552, "total_env_steps": 1766400, "episode_reward": 0.21470507979393005, "value_loss": 0.013522788509726524, "policy_loss": -0.0009682391993816708, "dist_entropy": 0.8274553060531616, "actor_grad_norm": 0.10474085807800293, "critic_grad_norm": 0.11331794410943985, "ratio": 1.0001442432403564, "entropy": 0.8274553060531616, "incre_win_rate": 0.6842105263157895, "step": 552}
{"time": 1767153883.41209, "phase": "train", "update": 553, "total_env_steps": 1769600, "episode_reward": 0.21645230054855347, "value_loss": 0.01596912890672684, "policy_loss": -0.0008020250558729459, "dist_entropy": 0.8308545589447022, "actor_grad_norm": 0.10254722088575363, "critic_grad_norm": 0.11410634964704514, "ratio": 0.9997955560684204, "entropy": 0.8308545589447022, "incre_win_rate": 0.7777777777777778, "step": 553}
{"time": 1767153887.7383404, "phase": "train", "update": 554, "total_env_steps": 1772800, "episode_reward": 0.22617188096046448, "value_loss": 0.013232131674885749, "policy_loss": -0.0006249887808881915, "dist_entropy": 0.8357069849967956, "actor_grad_norm": 0.1204819604754448, "critic_grad_norm": 0.11529208719730377, "ratio": 0.9998791813850403, "entropy": 0.8357069849967956, "incre_win_rate": 0.7692307692307693, "step": 554}
{"time": 1767153892.030214, "phase": "train", "update": 555, "total_env_steps": 1776000, "episode_reward": 0.2121952623128891, "value_loss": 0.01613757275044918, "policy_loss": -0.0007822456681173762, "dist_entropy": 0.827847421169281, "actor_grad_norm": 0.10202471166849136, "critic_grad_norm": 0.2280101329088211, "ratio": 1.0002198219299316, "entropy": 0.827847421169281, "incre_win_rate": 0.6944444444444444, "step": 555}
{"time": 1767153896.335299, "phase": "train", "update": 556, "total_env_steps": 1779200, "episode_reward": 0.21446605026721954, "value_loss": 0.014937653765082359, "policy_loss": -0.0011591496564812953, "dist_entropy": 0.8298441648483277, "actor_grad_norm": 0.10556753724813461, "critic_grad_norm": 0.18959419429302216, "ratio": 0.9998413920402527, "entropy": 0.8298441648483277, "incre_win_rate": 0.725, "step": 556}
{"time": 1767153900.6460876, "phase": "train", "update": 557, "total_env_steps": 1782400, "episode_reward": 0.2192135751247406, "value_loss": 0.01682541109621525, "policy_loss": -0.0009832735201573684, "dist_entropy": 0.8146258354187011, "actor_grad_norm": 0.08403544872999191, "critic_grad_norm": 0.12396197766065598, "ratio": 1.0000108480453491, "entropy": 0.8146258354187011, "incre_win_rate": 0.7692307692307693, "step": 557}
{"time": 1767153904.9028468, "phase": "train", "update": 558, "total_env_steps": 1785600, "episode_reward": 0.21967560052871704, "value_loss": 0.018135298043489456, "policy_loss": -0.0009896201327798337, "dist_entropy": 0.8477562308311463, "actor_grad_norm": 0.126413032412529, "critic_grad_norm": 0.18641413748264313, "ratio": 1.0001344680786133, "entropy": 0.8477562308311463, "incre_win_rate": 0.6666666666666666, "step": 558}
{"time": 1767153909.18474, "phase": "train", "update": 559, "total_env_steps": 1788800, "episode_reward": 0.21703796088695526, "value_loss": 0.012510411441326141, "policy_loss": -0.000978521322930348, "dist_entropy": 0.836767566204071, "actor_grad_norm": 0.1151178628206253, "critic_grad_norm": 0.12220777571201324, "ratio": 1.0001081228256226, "entropy": 0.836767566204071, "incre_win_rate": 0.7105263157894737, "step": 559}
{"time": 1767153913.7137713, "phase": "train", "update": 560, "total_env_steps": 1792000, "episode_reward": 0.22747984528541565, "value_loss": 0.015655767545104025, "policy_loss": -0.0007142755575799242, "dist_entropy": 0.8455445170402527, "actor_grad_norm": 0.09395071864128113, "critic_grad_norm": 0.10851504653692245, "ratio": 0.9998182654380798, "entropy": 0.8455445170402527, "incre_win_rate": 0.7560975609756098, "step": 560}
{"time": 1767153918.1065001, "phase": "train", "update": 561, "total_env_steps": 1795200, "episode_reward": 0.224593847990036, "value_loss": 0.013978144526481629, "policy_loss": -0.0011994413751221344, "dist_entropy": 0.8579776763916016, "actor_grad_norm": 0.13658306002616882, "critic_grad_norm": 0.13689211010932922, "ratio": 0.9997881054878235, "entropy": 0.8579776763916016, "incre_win_rate": 0.8378378378378378, "step": 561}
{"time": 1767153931.0192416, "phase": "eval", "update": 561, "total_env_steps": 1795200, "eval_win_rate": 0.8125, "eval_episode_reward": 18.439621274834437, "step": 561}
{"time": 1767153935.3154542, "phase": "train", "update": 562, "total_env_steps": 1798400, "episode_reward": 0.22294597327709198, "value_loss": 0.01787613295018673, "policy_loss": -0.0010574211716542158, "dist_entropy": 0.8739555954933167, "actor_grad_norm": 0.10268532484769821, "critic_grad_norm": 0.07748479396104813, "ratio": 1.0002659559249878, "entropy": 0.8739555954933167, "incre_win_rate": 0.7692307692307693, "step": 562}
{"time": 1767153939.5986114, "phase": "train", "update": 563, "total_env_steps": 1801600, "episode_reward": 0.21719785034656525, "value_loss": 0.015532347932457924, "policy_loss": -0.0011311129454945501, "dist_entropy": 0.8748397111892701, "actor_grad_norm": 0.13398011028766632, "critic_grad_norm": 0.1252887099981308, "ratio": 0.9999624490737915, "entropy": 0.8748397111892701, "incre_win_rate": 0.7297297297297297, "step": 563}
{"time": 1767153943.9162858, "phase": "train", "update": 564, "total_env_steps": 1804800, "episode_reward": 0.2262846827507019, "value_loss": 0.014177621714770794, "policy_loss": -0.00091567504539114, "dist_entropy": 0.8593337297439575, "actor_grad_norm": 0.14023230969905853, "critic_grad_norm": 0.13205648958683014, "ratio": 0.9996839761734009, "entropy": 0.8593337297439575, "incre_win_rate": 0.7619047619047619, "step": 564}
{"time": 1767153948.2485857, "phase": "train", "update": 565, "total_env_steps": 1808000, "episode_reward": 0.2265816479921341, "value_loss": 0.014054047502577304, "policy_loss": -0.0007263266685985315, "dist_entropy": 0.864164936542511, "actor_grad_norm": 0.15342915058135986, "critic_grad_norm": 0.14614520967006683, "ratio": 0.9999813437461853, "entropy": 0.864164936542511, "incre_win_rate": 0.8055555555555556, "step": 565}
{"time": 1767153952.5147724, "phase": "train", "update": 566, "total_env_steps": 1811200, "episode_reward": 0.20881415903568268, "value_loss": 0.02224554419517517, "policy_loss": -0.0012589449698680254, "dist_entropy": 0.8689275622367859, "actor_grad_norm": 0.09431512653827667, "critic_grad_norm": 0.3059178292751312, "ratio": 0.9995458722114563, "entropy": 0.8689275622367859, "incre_win_rate": 0.7105263157894737, "step": 566}
{"time": 1767153956.8021028, "phase": "train", "update": 567, "total_env_steps": 1814400, "episode_reward": 0.2089797407388687, "value_loss": 0.015503045730292797, "policy_loss": -0.001051841815936605, "dist_entropy": 0.8703957200050354, "actor_grad_norm": 0.11257670074701309, "critic_grad_norm": 0.18295295536518097, "ratio": 1.0000985860824585, "entropy": 0.8703957200050354, "incre_win_rate": 0.7222222222222222, "step": 567}
{"time": 1767153961.083645, "phase": "train", "update": 568, "total_env_steps": 1817600, "episode_reward": 0.22247308492660522, "value_loss": 0.015280819125473499, "policy_loss": -0.00121433137477851, "dist_entropy": 0.8794293999671936, "actor_grad_norm": 0.10692379623651505, "critic_grad_norm": 0.2031422108411789, "ratio": 0.9997796416282654, "entropy": 0.8794293999671936, "incre_win_rate": 0.7692307692307693, "step": 568}
{"time": 1767153965.3707392, "phase": "train", "update": 569, "total_env_steps": 1820800, "episode_reward": 0.22218956053256989, "value_loss": 0.018243389949202538, "policy_loss": -0.001032536890124902, "dist_entropy": 0.8794973969459534, "actor_grad_norm": 0.09605605900287628, "critic_grad_norm": 0.14981339871883392, "ratio": 0.9999504089355469, "entropy": 0.8794973969459534, "incre_win_rate": 0.7894736842105263, "step": 569}
{"time": 1767153969.6772683, "phase": "train", "update": 570, "total_env_steps": 1824000, "episode_reward": 0.22141505777835846, "value_loss": 0.014351174980401993, "policy_loss": -0.001156402681595381, "dist_entropy": 0.8813145756721497, "actor_grad_norm": 0.0833948478102684, "critic_grad_norm": 0.20919246971607208, "ratio": 0.999959409236908, "entropy": 0.8813145756721497, "incre_win_rate": 0.7297297297297297, "step": 570}
{"time": 1767153974.014362, "phase": "train", "update": 571, "total_env_steps": 1827200, "episode_reward": 0.22913388907909393, "value_loss": 0.013090114295482635, "policy_loss": -0.000666022373481212, "dist_entropy": 0.889599347114563, "actor_grad_norm": 0.12022695690393448, "critic_grad_norm": 0.19430528581142426, "ratio": 0.9997345209121704, "entropy": 0.889599347114563, "incre_win_rate": 0.8461538461538461, "step": 571}
{"time": 1767153978.3175929, "phase": "train", "update": 572, "total_env_steps": 1830400, "episode_reward": 0.22521264851093292, "value_loss": 0.018724781274795533, "policy_loss": -0.0010548873133934932, "dist_entropy": 0.88997563123703, "actor_grad_norm": 0.11893939971923828, "critic_grad_norm": 0.2635289430618286, "ratio": 0.9997637867927551, "entropy": 0.88997563123703, "incre_win_rate": 0.825, "step": 572}
{"time": 1767153982.6090794, "phase": "train", "update": 573, "total_env_steps": 1833600, "episode_reward": 0.21193762123584747, "value_loss": 0.014752921648323536, "policy_loss": -0.0009566699054637696, "dist_entropy": 0.9055708050727844, "actor_grad_norm": 0.10824467986822128, "critic_grad_norm": 0.20663629472255707, "ratio": 1.0000272989273071, "entropy": 0.9055708050727844, "incre_win_rate": 0.6756756756756757, "step": 573}
{"time": 1767153986.8796897, "phase": "train", "update": 574, "total_env_steps": 1836800, "episode_reward": 0.21989598870277405, "value_loss": 0.015513666346669197, "policy_loss": -0.0010912829818799708, "dist_entropy": 0.9046061396598816, "actor_grad_norm": 0.0812172219157219, "critic_grad_norm": 0.09125684201717377, "ratio": 0.9998846054077148, "entropy": 0.9046061396598816, "incre_win_rate": 0.7692307692307693, "step": 574}
{"time": 1767153991.14903, "phase": "train", "update": 575, "total_env_steps": 1840000, "episode_reward": 0.21796512603759766, "value_loss": 0.011397231370210648, "policy_loss": -0.0012568195629011568, "dist_entropy": 0.8932534337043763, "actor_grad_norm": 0.12137781828641891, "critic_grad_norm": 0.12533579766750336, "ratio": 1.0002574920654297, "entropy": 0.8932534337043763, "incre_win_rate": 0.8055555555555556, "step": 575}
{"time": 1767153995.4040105, "phase": "train", "update": 576, "total_env_steps": 1843200, "episode_reward": 0.20735979080200195, "value_loss": 0.013246877677738666, "policy_loss": -0.0011602790177192902, "dist_entropy": 0.8973927140235901, "actor_grad_norm": 0.09041040390729904, "critic_grad_norm": 0.0765150710940361, "ratio": 0.9999710321426392, "entropy": 0.8973927140235901, "incre_win_rate": 0.7777777777777778, "step": 576}
{"time": 1767153999.7670913, "phase": "train", "update": 577, "total_env_steps": 1846400, "episode_reward": 0.22292736172676086, "value_loss": 0.011686877533793449, "policy_loss": -0.000989564929250264, "dist_entropy": 0.9054113149642944, "actor_grad_norm": 0.10575707256793976, "critic_grad_norm": 0.11134641617536545, "ratio": 0.9996517300605774, "entropy": 0.9054113149642944, "incre_win_rate": 0.8421052631578947, "step": 577}
{"time": 1767154004.0794907, "phase": "train", "update": 578, "total_env_steps": 1849600, "episode_reward": 0.210899218916893, "value_loss": 0.015963476337492465, "policy_loss": -0.0012199367926655214, "dist_entropy": 0.9042517304420471, "actor_grad_norm": 0.10938357561826706, "critic_grad_norm": 0.09214811027050018, "ratio": 0.9999497532844543, "entropy": 0.9042517304420471, "incre_win_rate": 0.6486486486486487, "step": 578}
{"time": 1767154008.4063036, "phase": "train", "update": 579, "total_env_steps": 1852800, "episode_reward": 0.22311000525951385, "value_loss": 0.012894437834620475, "policy_loss": -0.0011242455917013672, "dist_entropy": 0.9010113954544068, "actor_grad_norm": 0.1093415766954422, "critic_grad_norm": 0.0764656811952591, "ratio": 0.9999287724494934, "entropy": 0.9010113954544068, "incre_win_rate": 0.8378378378378378, "step": 579}
{"time": 1767154012.647425, "phase": "train", "update": 580, "total_env_steps": 1856000, "episode_reward": 0.21071814000606537, "value_loss": 0.013987449556589126, "policy_loss": -0.001246106227101329, "dist_entropy": 0.8978244662284851, "actor_grad_norm": 0.09222672134637833, "critic_grad_norm": 0.10476453602313995, "ratio": 0.9995689392089844, "entropy": 0.8978244662284851, "incre_win_rate": 0.6756756756756757, "step": 580}
{"time": 1767154016.9130392, "phase": "train", "update": 581, "total_env_steps": 1859200, "episode_reward": 0.2139926552772522, "value_loss": 0.015190476737916469, "policy_loss": -0.001592264715467362, "dist_entropy": 0.8965898752212524, "actor_grad_norm": 0.11819756031036377, "critic_grad_norm": 0.14589841663837433, "ratio": 0.9997438788414001, "entropy": 0.8965898752212524, "incre_win_rate": 0.7368421052631579, "step": 581}
{"time": 1767154029.2520258, "phase": "eval", "update": 581, "total_env_steps": 1859200, "eval_win_rate": 0.8125, "eval_episode_reward": 18.961247930463575, "step": 581}
{"time": 1767154033.5855057, "phase": "train", "update": 582, "total_env_steps": 1862400, "episode_reward": 0.22394970059394836, "value_loss": 0.014463300071656703, "policy_loss": -0.0009820700599760812, "dist_entropy": 0.8594777464866639, "actor_grad_norm": 0.07723814994096756, "critic_grad_norm": 0.20917697250843048, "ratio": 1.0000176429748535, "entropy": 0.8594777464866639, "incre_win_rate": 0.7948717948717948, "step": 582}
{"time": 1767154037.8824635, "phase": "train", "update": 583, "total_env_steps": 1865600, "episode_reward": 0.20206281542778015, "value_loss": 0.01397569738328457, "policy_loss": -0.001016920506332042, "dist_entropy": 0.8776815295219421, "actor_grad_norm": 0.10058392584323883, "critic_grad_norm": 0.14733365178108215, "ratio": 1.0000742673873901, "entropy": 0.8776815295219421, "incre_win_rate": 0.7142857142857143, "step": 583}
{"time": 1767154042.1870744, "phase": "train", "update": 584, "total_env_steps": 1868800, "episode_reward": 0.2259804606437683, "value_loss": 0.009072467125952244, "policy_loss": -0.0012347515582156632, "dist_entropy": 0.8680633425712585, "actor_grad_norm": 0.08129433542490005, "critic_grad_norm": 0.14306440949440002, "ratio": 1.0001786947250366, "entropy": 0.8680633425712585, "incre_win_rate": 0.8974358974358975, "step": 584}
{"time": 1767154046.4914103, "phase": "train", "update": 585, "total_env_steps": 1872000, "episode_reward": 0.23059913516044617, "value_loss": 0.011776521988213062, "policy_loss": -0.00104421861283015, "dist_entropy": 0.8770359039306641, "actor_grad_norm": 0.132855623960495, "critic_grad_norm": 0.16084544360637665, "ratio": 0.9995071291923523, "entropy": 0.8770359039306641, "incre_win_rate": 0.9166666666666666, "step": 585}
{"time": 1767154050.7268174, "phase": "train", "update": 586, "total_env_steps": 1875200, "episode_reward": 0.21094629168510437, "value_loss": 0.01491749957203865, "policy_loss": -0.0010864410469849871, "dist_entropy": 0.8857147455215454, "actor_grad_norm": 0.08871058374643326, "critic_grad_norm": 0.15594586730003357, "ratio": 0.9998463988304138, "entropy": 0.8857147455215454, "incre_win_rate": 0.6923076923076923, "step": 586}
{"time": 1767154055.0144672, "phase": "train", "update": 587, "total_env_steps": 1878400, "episode_reward": 0.21399162709712982, "value_loss": 0.017936098203063012, "policy_loss": -0.0009912119974998745, "dist_entropy": 0.8953305363655091, "actor_grad_norm": 0.10766153782606125, "critic_grad_norm": 0.07745761424303055, "ratio": 1.0002092123031616, "entropy": 0.8953305363655091, "incre_win_rate": 0.6388888888888888, "step": 587}
{"time": 1767154059.286339, "phase": "train", "update": 588, "total_env_steps": 1881600, "episode_reward": 0.2042844593524933, "value_loss": 0.018941406160593033, "policy_loss": -0.0012452510164791875, "dist_entropy": 0.9055731177330018, "actor_grad_norm": 0.09448641538619995, "critic_grad_norm": 0.20508764684200287, "ratio": 1.0000935792922974, "entropy": 0.9055731177330018, "incre_win_rate": 0.7368421052631579, "step": 588}
{"time": 1767154063.6175878, "phase": "train", "update": 589, "total_env_steps": 1884800, "episode_reward": 0.21916598081588745, "value_loss": 0.015276438742876052, "policy_loss": -0.001223086234386983, "dist_entropy": 0.8911190509796143, "actor_grad_norm": 0.10832958668470383, "critic_grad_norm": 0.2331959456205368, "ratio": 0.9998188018798828, "entropy": 0.8911190509796143, "incre_win_rate": 0.7631578947368421, "step": 589}
{"time": 1767154067.8784702, "phase": "train", "update": 590, "total_env_steps": 1888000, "episode_reward": 0.20996174216270447, "value_loss": 0.012537900917232036, "policy_loss": -0.0018868015065251597, "dist_entropy": 0.8786739230155944, "actor_grad_norm": 0.13869912922382355, "critic_grad_norm": 0.2020891159772873, "ratio": 0.9993881583213806, "entropy": 0.8786739230155944, "incre_win_rate": 0.7058823529411765, "step": 590}
{"time": 1767154072.1561935, "phase": "train", "update": 591, "total_env_steps": 1891200, "episode_reward": 0.23144765198230743, "value_loss": 0.0094847759231925, "policy_loss": -0.0010105199638502428, "dist_entropy": 0.8304806470870971, "actor_grad_norm": 0.09946005791425705, "critic_grad_norm": 0.22929517924785614, "ratio": 0.9998130202293396, "entropy": 0.8304806470870971, "incre_win_rate": 0.8421052631578947, "step": 591}
{"time": 1767154076.427869, "phase": "train", "update": 592, "total_env_steps": 1894400, "episode_reward": 0.2309933602809906, "value_loss": 0.011885437369346618, "policy_loss": -0.0013621508884401833, "dist_entropy": 0.8312750697135926, "actor_grad_norm": 0.12543904781341553, "critic_grad_norm": 0.17956513166427612, "ratio": 0.9998762011528015, "entropy": 0.8312750697135926, "incre_win_rate": 0.875, "step": 592}
{"time": 1767154080.7050877, "phase": "train", "update": 593, "total_env_steps": 1897600, "episode_reward": 0.22984686493873596, "value_loss": 0.009670284762978553, "policy_loss": -0.0005894696602773309, "dist_entropy": 0.8101192235946655, "actor_grad_norm": 0.11343339830636978, "critic_grad_norm": 0.2699833810329437, "ratio": 1.0001087188720703, "entropy": 0.8101192235946655, "incre_win_rate": 0.8461538461538461, "step": 593}
{"time": 1767154085.0171316, "phase": "train", "update": 594, "total_env_steps": 1900800, "episode_reward": 0.23658527433872223, "value_loss": 0.009782572090625764, "policy_loss": -0.0012917404500889518, "dist_entropy": 0.8112517356872558, "actor_grad_norm": 0.0888417512178421, "critic_grad_norm": 0.19368021190166473, "ratio": 0.9998752474784851, "entropy": 0.8112517356872558, "incre_win_rate": 0.9230769230769231, "step": 594}
{"time": 1767154089.3287754, "phase": "train", "update": 595, "total_env_steps": 1904000, "episode_reward": 0.21934862434864044, "value_loss": 0.011845254898071289, "policy_loss": -0.0012671206182147897, "dist_entropy": 0.8095764994621277, "actor_grad_norm": 0.13460566103458405, "critic_grad_norm": 0.23248958587646484, "ratio": 0.9999579787254333, "entropy": 0.8095764994621277, "incre_win_rate": 0.7368421052631579, "step": 595}
{"time": 1767154093.6561506, "phase": "train", "update": 596, "total_env_steps": 1907200, "episode_reward": 0.22996275126934052, "value_loss": 0.01103769987821579, "policy_loss": -0.0010865601162469928, "dist_entropy": 0.8007293105125427, "actor_grad_norm": 0.12796495854854584, "critic_grad_norm": 0.09587515890598297, "ratio": 1.0000711679458618, "entropy": 0.8007293105125427, "incre_win_rate": 0.7948717948717948, "step": 596}
{"time": 1767154097.947011, "phase": "train", "update": 597, "total_env_steps": 1910400, "episode_reward": 0.22303137183189392, "value_loss": 0.011644865572452544, "policy_loss": -0.0011419567712035229, "dist_entropy": 0.8289871215820312, "actor_grad_norm": 0.08256585896015167, "critic_grad_norm": 0.15077729523181915, "ratio": 0.9998189806938171, "entropy": 0.8289871215820312, "incre_win_rate": 0.7631578947368421, "step": 597}
{"time": 1767154102.2704031, "phase": "train", "update": 598, "total_env_steps": 1913600, "episode_reward": 0.2292383909225464, "value_loss": 0.011687601730227471, "policy_loss": -0.0011299850878060624, "dist_entropy": 0.8257801413536072, "actor_grad_norm": 0.08610539883375168, "critic_grad_norm": 0.14178083837032318, "ratio": 1.0000637769699097, "entropy": 0.8257801413536072, "incre_win_rate": 0.8205128205128205, "step": 598}
{"time": 1767154106.6285815, "phase": "train", "update": 599, "total_env_steps": 1916800, "episode_reward": 0.22715233266353607, "value_loss": 0.010408224165439605, "policy_loss": -0.0011528610687065565, "dist_entropy": 0.8279057741165161, "actor_grad_norm": 0.08240807056427002, "critic_grad_norm": 0.10633105039596558, "ratio": 0.9999635815620422, "entropy": 0.8279057741165161, "incre_win_rate": 0.8205128205128205, "step": 599}
{"time": 1767154110.8713744, "phase": "train", "update": 600, "total_env_steps": 1920000, "episode_reward": 0.2177726775407791, "value_loss": 0.011485584639012813, "policy_loss": -0.0012494810984613025, "dist_entropy": 0.8494724273681641, "actor_grad_norm": 0.12220623344182968, "critic_grad_norm": 0.08601423352956772, "ratio": 0.9993433356285095, "entropy": 0.8494724273681641, "incre_win_rate": 0.7777777777777778, "step": 600}
{"time": 1767154115.1081223, "phase": "train", "update": 601, "total_env_steps": 1923200, "episode_reward": 0.2133272886276245, "value_loss": 0.01667715795338154, "policy_loss": -0.0008216689994245075, "dist_entropy": 0.8340986847877503, "actor_grad_norm": 0.12526635825634003, "critic_grad_norm": 0.2632030248641968, "ratio": 1.0000295639038086, "entropy": 0.8340986847877503, "incre_win_rate": 0.6410256410256411, "step": 601}
{"time": 1767154127.3450773, "phase": "eval", "update": 601, "total_env_steps": 1923200, "eval_win_rate": 0.84375, "eval_episode_reward": 19.13426117549669, "step": 601}
{"time": 1767154131.6028302, "phase": "train", "update": 602, "total_env_steps": 1926400, "episode_reward": 0.21482045948505402, "value_loss": 0.013911569118499756, "policy_loss": -0.0008601091696837315, "dist_entropy": 0.8412380933761596, "actor_grad_norm": 0.12239675968885422, "critic_grad_norm": 0.1831221729516983, "ratio": 1.0000858306884766, "entropy": 0.8412380933761596, "incre_win_rate": 0.725, "step": 602}
{"time": 1767154135.8073773, "phase": "train", "update": 603, "total_env_steps": 1929600, "episode_reward": 0.22633537650108337, "value_loss": 0.013506745547056198, "policy_loss": -0.0013740647438460485, "dist_entropy": 0.8381693243980408, "actor_grad_norm": 0.1360788643360138, "critic_grad_norm": 0.13363300263881683, "ratio": 0.999854564666748, "entropy": 0.8381693243980408, "incre_win_rate": 0.8285714285714286, "step": 603}
{"time": 1767154140.073256, "phase": "train", "update": 604, "total_env_steps": 1932800, "episode_reward": 0.22804997861385345, "value_loss": 0.010143900662660599, "policy_loss": -0.0008730317300287282, "dist_entropy": 0.8227362513542176, "actor_grad_norm": 0.08468370884656906, "critic_grad_norm": 0.15623536705970764, "ratio": 1.0001158714294434, "entropy": 0.8227362513542176, "incre_win_rate": 0.7948717948717948, "step": 604}
{"time": 1767154144.3232076, "phase": "train", "update": 605, "total_env_steps": 1936000, "episode_reward": 0.22075746953487396, "value_loss": 0.012174402363598347, "policy_loss": -0.0010976143945207184, "dist_entropy": 0.8414279103279114, "actor_grad_norm": 0.08116559684276581, "critic_grad_norm": 0.17964695394039154, "ratio": 0.9997736811637878, "entropy": 0.8414279103279114, "incre_win_rate": 0.7631578947368421, "step": 605}
{"time": 1767154148.5416112, "phase": "train", "update": 606, "total_env_steps": 1939200, "episode_reward": 0.21446502208709717, "value_loss": 0.013842123746871948, "policy_loss": -0.001704086801016602, "dist_entropy": 0.8044829130172729, "actor_grad_norm": 0.11893647909164429, "critic_grad_norm": 0.17373891174793243, "ratio": 1.000240683555603, "entropy": 0.8044829130172729, "incre_win_rate": 0.717948717948718, "step": 606}
{"time": 1767154152.7709498, "phase": "train", "update": 607, "total_env_steps": 1942400, "episode_reward": 0.22564467787742615, "value_loss": 0.013443996012210847, "policy_loss": -0.001295598216649374, "dist_entropy": 0.8111926913261414, "actor_grad_norm": 0.0865618884563446, "critic_grad_norm": 0.11827962845563889, "ratio": 1.0002139806747437, "entropy": 0.8111926913261414, "incre_win_rate": 0.7894736842105263, "step": 607}
{"time": 1767154157.027176, "phase": "train", "update": 608, "total_env_steps": 1945600, "episode_reward": 0.23371997475624084, "value_loss": 0.012147188186645508, "policy_loss": -0.0009164580548571167, "dist_entropy": 0.8177764177322387, "actor_grad_norm": 0.09675955772399902, "critic_grad_norm": 0.18436330556869507, "ratio": 1.0001496076583862, "entropy": 0.8177764177322387, "incre_win_rate": 0.8461538461538461, "step": 608}
{"time": 1767154161.2193277, "phase": "train", "update": 609, "total_env_steps": 1948800, "episode_reward": 0.21475423872470856, "value_loss": 0.012400813587009906, "policy_loss": -0.0010621810622978955, "dist_entropy": 0.847251045703888, "actor_grad_norm": 0.09743034094572067, "critic_grad_norm": 0.216469869017601, "ratio": 1.0000132322311401, "entropy": 0.847251045703888, "incre_win_rate": 0.6666666666666666, "step": 609}
{"time": 1767154165.4226882, "phase": "train", "update": 610, "total_env_steps": 1952000, "episode_reward": 0.23346130549907684, "value_loss": 0.012477533519268036, "policy_loss": -0.001464858832532201, "dist_entropy": 0.8280789852142334, "actor_grad_norm": 0.12936043739318848, "critic_grad_norm": 0.14925651252269745, "ratio": 0.9999355673789978, "entropy": 0.8280789852142334, "incre_win_rate": 0.8421052631578947, "step": 610}
{"time": 1767154169.750458, "phase": "train", "update": 611, "total_env_steps": 1955200, "episode_reward": 0.2201101928949356, "value_loss": 0.011592407524585725, "policy_loss": -0.0011278456205024768, "dist_entropy": 0.8344092249870301, "actor_grad_norm": 0.09101685136556625, "critic_grad_norm": 0.12958459556102753, "ratio": 0.9999372363090515, "entropy": 0.8344092249870301, "incre_win_rate": 0.7435897435897436, "step": 611}
{"time": 1767154174.0514548, "phase": "train", "update": 612, "total_env_steps": 1958400, "episode_reward": 0.23078644275665283, "value_loss": 0.009201155044138432, "policy_loss": -0.0015630965533517838, "dist_entropy": 0.8135771036148072, "actor_grad_norm": 0.10539750009775162, "critic_grad_norm": 0.10560531914234161, "ratio": 1.0002268552780151, "entropy": 0.8135771036148072, "incre_win_rate": 0.7948717948717948, "step": 612}
{"time": 1767154178.3102245, "phase": "train", "update": 613, "total_env_steps": 1961600, "episode_reward": 0.21880121529102325, "value_loss": 0.01348029226064682, "policy_loss": -0.0016353600217193787, "dist_entropy": 0.8082923889160156, "actor_grad_norm": 0.13524548709392548, "critic_grad_norm": 0.1335192173719406, "ratio": 1.0000790357589722, "entropy": 0.8082923889160156, "incre_win_rate": 0.6944444444444444, "step": 613}
{"time": 1767154182.613918, "phase": "train", "update": 614, "total_env_steps": 1964800, "episode_reward": 0.22234944999217987, "value_loss": 0.008671876788139344, "policy_loss": -0.001200262378556971, "dist_entropy": 0.8104246616363525, "actor_grad_norm": 0.11287721246480942, "critic_grad_norm": 0.09963358938694, "ratio": 1.0002163648605347, "entropy": 0.8104246616363525, "incre_win_rate": 0.8205128205128205, "step": 614}
{"time": 1767154186.884156, "phase": "train", "update": 615, "total_env_steps": 1968000, "episode_reward": 0.22711092233657837, "value_loss": 0.010786609351634979, "policy_loss": -0.0005521583079399761, "dist_entropy": 0.8042239069938659, "actor_grad_norm": 0.082758329808712, "critic_grad_norm": 0.10454660654067993, "ratio": 0.9997472763061523, "entropy": 0.8042239069938659, "incre_win_rate": 0.8648648648648649, "step": 615}
{"time": 1767154191.1446912, "phase": "train", "update": 616, "total_env_steps": 1971200, "episode_reward": 0.23038442432880402, "value_loss": 0.008380160480737687, "policy_loss": -0.0008289454548821573, "dist_entropy": 0.8095493197441102, "actor_grad_norm": 0.08146990090608597, "critic_grad_norm": 0.09316055476665497, "ratio": 0.9999546408653259, "entropy": 0.8095493197441102, "incre_win_rate": 0.918918918918919, "step": 616}
{"time": 1767154195.4094617, "phase": "train", "update": 617, "total_env_steps": 1974400, "episode_reward": 0.22137832641601562, "value_loss": 0.008586253970861435, "policy_loss": -0.0010908314353208937, "dist_entropy": 0.8113096475601196, "actor_grad_norm": 0.1033826619386673, "critic_grad_norm": 0.06337111443281174, "ratio": 0.999912440776825, "entropy": 0.8113096475601196, "incre_win_rate": 0.7631578947368421, "step": 617}
{"time": 1767154199.7098722, "phase": "train", "update": 618, "total_env_steps": 1977600, "episode_reward": 0.2322351038455963, "value_loss": 0.00709240110591054, "policy_loss": -0.0009785492220945712, "dist_entropy": 0.8086242794990539, "actor_grad_norm": 0.09692416340112686, "critic_grad_norm": 0.06280221045017242, "ratio": 1.000078558921814, "entropy": 0.8086242794990539, "incre_win_rate": 0.9459459459459459, "step": 618}
{"time": 1767154204.0213861, "phase": "train", "update": 619, "total_env_steps": 1980800, "episode_reward": 0.22855494916439056, "value_loss": 0.011599128507077694, "policy_loss": -0.001190409628571132, "dist_entropy": 0.8240282893180847, "actor_grad_norm": 0.12912380695343018, "critic_grad_norm": 0.20297901332378387, "ratio": 0.9996629953384399, "entropy": 0.8240282893180847, "incre_win_rate": 0.75, "step": 619}
{"time": 1767154208.4812226, "phase": "train", "update": 620, "total_env_steps": 1984000, "episode_reward": 0.231434166431427, "value_loss": 0.009394279308617115, "policy_loss": -0.0010906416310392686, "dist_entropy": 0.7906219244003296, "actor_grad_norm": 0.11692656576633453, "critic_grad_norm": 0.15424756705760956, "ratio": 0.9999335408210754, "entropy": 0.7906219244003296, "incre_win_rate": 0.8461538461538461, "step": 620}
{"time": 1767154212.7525213, "phase": "train", "update": 621, "total_env_steps": 1987200, "episode_reward": 0.23272348940372467, "value_loss": 0.009680367074906826, "policy_loss": -0.0010087438726902541, "dist_entropy": 0.7748958706855774, "actor_grad_norm": 0.08926036208868027, "critic_grad_norm": 0.16259276866912842, "ratio": 1.0000942945480347, "entropy": 0.7748958706855774, "incre_win_rate": 0.9210526315789473, "step": 621}
{"time": 1767154224.2808363, "phase": "eval", "update": 621, "total_env_steps": 1987200, "eval_win_rate": 0.8125, "eval_episode_reward": 19.25351821192053, "step": 621}
{"time": 1767154228.9075794, "phase": "train", "update": 622, "total_env_steps": 1990400, "episode_reward": 0.2363809198141098, "value_loss": 0.009764006547629833, "policy_loss": -0.0008859503197683694, "dist_entropy": 0.7549819469451904, "actor_grad_norm": 0.08372800797224045, "critic_grad_norm": 0.13250668346881866, "ratio": 1.000301480293274, "entropy": 0.7549819469451904, "incre_win_rate": 0.8292682926829268, "step": 622}
{"time": 1767154233.235395, "phase": "train", "update": 623, "total_env_steps": 1993600, "episode_reward": 0.23355960845947266, "value_loss": 0.00903480090200901, "policy_loss": -0.0008721677332705014, "dist_entropy": 0.753359067440033, "actor_grad_norm": 0.12125232070684433, "critic_grad_norm": 0.05755099281668663, "ratio": 0.9998507499694824, "entropy": 0.753359067440033, "incre_win_rate": 0.8648648648648649, "step": 623}
{"time": 1767154237.5595658, "phase": "train", "update": 624, "total_env_steps": 1996800, "episode_reward": 0.23113979399204254, "value_loss": 0.012393592298030854, "policy_loss": -0.0010106643256193593, "dist_entropy": 0.7584331154823303, "actor_grad_norm": 0.11345516890287399, "critic_grad_norm": 0.10902351140975952, "ratio": 0.9998794794082642, "entropy": 0.7584331154823303, "incre_win_rate": 0.85, "step": 624}
{"time": 1767154241.8272262, "phase": "train", "update": 625, "total_env_steps": 2000000, "episode_reward": 0.22159302234649658, "value_loss": 0.009384000860154628, "policy_loss": -0.000788091728410123, "dist_entropy": 0.762002968788147, "actor_grad_norm": 0.11669472604990005, "critic_grad_norm": 0.08327214419841766, "ratio": 0.9996696710586548, "entropy": 0.762002968788147, "incre_win_rate": 0.75, "step": 625}
{"time": 1767154246.1070828, "phase": "train", "update": 626, "total_env_steps": 2003200, "episode_reward": 0.23689207434654236, "value_loss": 0.006805328745394945, "policy_loss": -0.0008118692721794218, "dist_entropy": 0.7354207277297974, "actor_grad_norm": 0.11146930605173111, "critic_grad_norm": 0.08642824739217758, "ratio": 1.0000649690628052, "entropy": 0.7354207277297974, "incre_win_rate": 0.9, "step": 626}
{"time": 1767154250.3662257, "phase": "train", "update": 627, "total_env_steps": 2006400, "episode_reward": 0.22909769415855408, "value_loss": 0.0086355397477746, "policy_loss": -0.0007885867845310202, "dist_entropy": 0.7512288928031922, "actor_grad_norm": 0.10133866220712662, "critic_grad_norm": 0.12186133116483688, "ratio": 0.999649167060852, "entropy": 0.7512288928031922, "incre_win_rate": 0.7948717948717948, "step": 627}
{"time": 1767154254.6466641, "phase": "train", "update": 628, "total_env_steps": 2009600, "episode_reward": 0.23425497114658356, "value_loss": 0.010516984388232231, "policy_loss": -0.0012801478064277116, "dist_entropy": 0.7617316961288452, "actor_grad_norm": 0.13873085379600525, "critic_grad_norm": 0.17137952148914337, "ratio": 1.0000371932983398, "entropy": 0.7617316961288452, "incre_win_rate": 0.85, "step": 628}
{"time": 1767154258.9723725, "phase": "train", "update": 629, "total_env_steps": 2012800, "episode_reward": 0.23759935796260834, "value_loss": 0.010507794842123986, "policy_loss": -0.0012415768036181164, "dist_entropy": 0.769648015499115, "actor_grad_norm": 0.15420782566070557, "critic_grad_norm": 0.1835641860961914, "ratio": 0.9996917843818665, "entropy": 0.769648015499115, "incre_win_rate": 0.8947368421052632, "step": 629}
{"time": 1767154263.3260124, "phase": "train", "update": 630, "total_env_steps": 2016000, "episode_reward": 0.23382657766342163, "value_loss": 0.010780462808907033, "policy_loss": -0.0009748037653981356, "dist_entropy": 0.7733789563179017, "actor_grad_norm": 0.11691271513700485, "critic_grad_norm": 0.1280575692653656, "ratio": 0.9999120831489563, "entropy": 0.7733789563179017, "incre_win_rate": 0.8292682926829268, "step": 630}
{"time": 1767154267.621737, "phase": "train", "update": 631, "total_env_steps": 2019200, "episode_reward": 0.23193037509918213, "value_loss": 0.011491934023797511, "policy_loss": -0.001236133177521026, "dist_entropy": 0.7859750509262085, "actor_grad_norm": 0.10479018837213516, "critic_grad_norm": 0.08480866253376007, "ratio": 0.9998621940612793, "entropy": 0.7859750509262085, "incre_win_rate": 0.8648648648648649, "step": 631}
{"time": 1767154271.905453, "phase": "train", "update": 632, "total_env_steps": 2022400, "episode_reward": 0.233174666762352, "value_loss": 0.009775955416262149, "policy_loss": -0.0010465445255167793, "dist_entropy": 0.7670273065567017, "actor_grad_norm": 0.09418487548828125, "critic_grad_norm": 0.07846686989068985, "ratio": 1.0002763271331787, "entropy": 0.7670273065567017, "incre_win_rate": 0.8, "step": 632}
{"time": 1767154276.175412, "phase": "train", "update": 633, "total_env_steps": 2025600, "episode_reward": 0.22581230103969574, "value_loss": 0.015026072412729264, "policy_loss": -0.0009685270660860113, "dist_entropy": 0.7465798854827881, "actor_grad_norm": 0.08273769915103912, "critic_grad_norm": 0.1736152172088623, "ratio": 1.0001534223556519, "entropy": 0.7465798854827881, "incre_win_rate": 0.7073170731707317, "step": 633}
{"time": 1767154280.4666715, "phase": "train", "update": 634, "total_env_steps": 2028800, "episode_reward": 0.23471027612686157, "value_loss": 0.013181823119521142, "policy_loss": -0.0008543444001166023, "dist_entropy": 0.7492118716239929, "actor_grad_norm": 0.08530202507972717, "critic_grad_norm": 0.1625453233718872, "ratio": 1.0000724792480469, "entropy": 0.7492118716239929, "incre_win_rate": 0.8157894736842105, "step": 634}
{"time": 1767154284.7702448, "phase": "train", "update": 635, "total_env_steps": 2032000, "episode_reward": 0.22838421165943146, "value_loss": 0.011593832448124886, "policy_loss": -0.0011985998209629756, "dist_entropy": 0.7268114209175109, "actor_grad_norm": 0.12361901998519897, "critic_grad_norm": 0.218582421541214, "ratio": 1.0002483129501343, "entropy": 0.7268114209175109, "incre_win_rate": 0.8421052631578947, "step": 635}
{"time": 1767154289.0444531, "phase": "train", "update": 636, "total_env_steps": 2035200, "episode_reward": 0.2220979928970337, "value_loss": 0.01043667085468769, "policy_loss": -0.001041713029959368, "dist_entropy": 0.7253063797950745, "actor_grad_norm": 0.10205163061618805, "critic_grad_norm": 0.11824088543653488, "ratio": 1.0002045631408691, "entropy": 0.7253063797950745, "incre_win_rate": 0.7631578947368421, "step": 636}
{"time": 1767154293.307171, "phase": "train", "update": 637, "total_env_steps": 2038400, "episode_reward": 0.23444224894046783, "value_loss": 0.008908088505268096, "policy_loss": -0.0007854223796014637, "dist_entropy": 0.7128424167633056, "actor_grad_norm": 0.10207197815179825, "critic_grad_norm": 0.0777425616979599, "ratio": 0.9998630881309509, "entropy": 0.7128424167633056, "incre_win_rate": 0.8974358974358975, "step": 637}
{"time": 1767154297.576379, "phase": "train", "update": 638, "total_env_steps": 2041600, "episode_reward": 0.2232103794813156, "value_loss": 0.01095597967505455, "policy_loss": -0.000936387952869211, "dist_entropy": 0.7210703372955323, "actor_grad_norm": 0.09459138661623001, "critic_grad_norm": 0.22283349931240082, "ratio": 0.999913215637207, "entropy": 0.7210703372955323, "incre_win_rate": 0.7894736842105263, "step": 638}
{"time": 1767154301.788321, "phase": "train", "update": 639, "total_env_steps": 2044800, "episode_reward": 0.23076468706130981, "value_loss": 0.00871467925608158, "policy_loss": -0.0007369214826091763, "dist_entropy": 0.705526328086853, "actor_grad_norm": 0.09327936172485352, "critic_grad_norm": 0.13567222654819489, "ratio": 0.9998294115066528, "entropy": 0.705526328086853, "incre_win_rate": 0.8461538461538461, "step": 639}
{"time": 1767154306.078617, "phase": "train", "update": 640, "total_env_steps": 2048000, "episode_reward": 0.2370462417602539, "value_loss": 0.008124324027448893, "policy_loss": -0.000826141109059364, "dist_entropy": 0.7260069012641907, "actor_grad_norm": 0.11208204180002213, "critic_grad_norm": 0.1281791776418686, "ratio": 1.000146508216858, "entropy": 0.7260069012641907, "incre_win_rate": 0.8974358974358975, "step": 640}
{"time": 1767154310.3532956, "phase": "train", "update": 641, "total_env_steps": 2051200, "episode_reward": 0.2362292855978012, "value_loss": 0.0094026118516922, "policy_loss": -0.0008054842019014075, "dist_entropy": 0.7344397664070129, "actor_grad_norm": 0.09729720652103424, "critic_grad_norm": 0.0654221847653389, "ratio": 1.0000284910202026, "entropy": 0.7344397664070129, "incre_win_rate": 0.8461538461538461, "step": 641}
{"time": 1767154322.9859507, "phase": "eval", "update": 641, "total_env_steps": 2051200, "eval_win_rate": 0.75, "eval_episode_reward": 18.714973096026483, "step": 641}
{"time": 1767154327.2589052, "phase": "train", "update": 642, "total_env_steps": 2054400, "episode_reward": 0.23329058289527893, "value_loss": 0.010730382986366749, "policy_loss": -0.0011860322720693261, "dist_entropy": 0.7390576601028442, "actor_grad_norm": 0.09781556576490402, "critic_grad_norm": 0.07035194337368011, "ratio": 1.0002554655075073, "entropy": 0.7390576601028442, "incre_win_rate": 0.8974358974358975, "step": 642}
{"time": 1767154331.538768, "phase": "train", "update": 643, "total_env_steps": 2057600, "episode_reward": 0.239709734916687, "value_loss": 0.007532751187682152, "policy_loss": -0.0011995447837080063, "dist_entropy": 0.7465961098670959, "actor_grad_norm": 0.10380200296640396, "critic_grad_norm": 0.05763434246182442, "ratio": 1.0000981092453003, "entropy": 0.7465961098670959, "incre_win_rate": 0.9230769230769231, "step": 643}
{"time": 1767154335.7693307, "phase": "train", "update": 644, "total_env_steps": 2060800, "episode_reward": 0.22022971510887146, "value_loss": 0.00880899578332901, "policy_loss": -0.0010850219854091846, "dist_entropy": 0.7379263401031494, "actor_grad_norm": 0.11224763840436935, "critic_grad_norm": 0.06085869297385216, "ratio": 0.9998955130577087, "entropy": 0.7379263401031494, "incre_win_rate": 0.8333333333333334, "step": 644}
{"time": 1767154340.056437, "phase": "train", "update": 645, "total_env_steps": 2064000, "episode_reward": 0.2401200532913208, "value_loss": 0.007663725037127733, "policy_loss": -0.0010719962141500616, "dist_entropy": 0.7604488015174866, "actor_grad_norm": 0.12909331917762756, "critic_grad_norm": 0.07927575707435608, "ratio": 1.000062346458435, "entropy": 0.7604488015174866, "incre_win_rate": 0.8809523809523809, "step": 645}
{"time": 1767154344.3265781, "phase": "train", "update": 646, "total_env_steps": 2067200, "episode_reward": 0.22634883224964142, "value_loss": 0.009518195316195488, "policy_loss": -0.0009916802221915598, "dist_entropy": 0.7602528214454651, "actor_grad_norm": 0.11911795288324356, "critic_grad_norm": 0.10453253239393234, "ratio": 0.9998928308486938, "entropy": 0.7602528214454651, "incre_win_rate": 0.8333333333333334, "step": 646}
{"time": 1767154348.6061664, "phase": "train", "update": 647, "total_env_steps": 2070400, "episode_reward": 0.2391432225704193, "value_loss": 0.008096611686050892, "policy_loss": -0.0012865526062009636, "dist_entropy": 0.7634120225906372, "actor_grad_norm": 0.10220953077077866, "critic_grad_norm": 0.14995789527893066, "ratio": 0.9998422861099243, "entropy": 0.7634120225906372, "incre_win_rate": 0.8717948717948718, "step": 647}
{"time": 1767154352.9251022, "phase": "train", "update": 648, "total_env_steps": 2073600, "episode_reward": 0.2538638412952423, "value_loss": 0.00625560125336051, "policy_loss": -0.0009286261602841961, "dist_entropy": 0.7609788298606872, "actor_grad_norm": 0.10939295589923859, "critic_grad_norm": 0.13553543388843536, "ratio": 0.9997372627258301, "entropy": 0.7609788298606872, "incre_win_rate": 0.9761904761904762, "step": 648}
{"time": 1767154357.1516445, "phase": "train", "update": 649, "total_env_steps": 2076800, "episode_reward": 0.22458505630493164, "value_loss": 0.0103968670591712, "policy_loss": -0.0012034582775108048, "dist_entropy": 0.7638371586799622, "actor_grad_norm": 0.11480146646499634, "critic_grad_norm": 0.25003811717033386, "ratio": 1.0000096559524536, "entropy": 0.7638371586799622, "incre_win_rate": 0.8108108108108109, "step": 649}
{"time": 1767154361.405419, "phase": "train", "update": 650, "total_env_steps": 2080000, "episode_reward": 0.22931188344955444, "value_loss": 0.00720637971535325, "policy_loss": -0.0008479622321306834, "dist_entropy": 0.7645825862884521, "actor_grad_norm": 0.09859731793403625, "critic_grad_norm": 0.11955340206623077, "ratio": 1.0006216764450073, "entropy": 0.7645825862884521, "incre_win_rate": 0.8717948717948718, "step": 650}
{"time": 1767154365.8872597, "phase": "train", "update": 651, "total_env_steps": 2083200, "episode_reward": 0.22863824665546417, "value_loss": 0.009742071479558944, "policy_loss": -0.0007149794691635236, "dist_entropy": 0.7589091062545776, "actor_grad_norm": 0.09771404415369034, "critic_grad_norm": 0.0971432700753212, "ratio": 0.9997963905334473, "entropy": 0.7589091062545776, "incre_win_rate": 0.7948717948717948, "step": 651}
{"time": 1767154370.14048, "phase": "train", "update": 652, "total_env_steps": 2086400, "episode_reward": 0.21831953525543213, "value_loss": 0.012688988633453847, "policy_loss": -0.0007543204165131101, "dist_entropy": 0.7573755860328675, "actor_grad_norm": 0.08242659270763397, "critic_grad_norm": 0.1374085247516632, "ratio": 1.0001004934310913, "entropy": 0.7573755860328675, "incre_win_rate": 0.7567567567567568, "step": 652}
{"time": 1767154374.4215715, "phase": "train", "update": 653, "total_env_steps": 2089600, "episode_reward": 0.22895799577236176, "value_loss": 0.011150513216853142, "policy_loss": -0.0010589718826540917, "dist_entropy": 0.7636927962303162, "actor_grad_norm": 0.09581410884857178, "critic_grad_norm": 0.09986511617898941, "ratio": 0.999981701374054, "entropy": 0.7636927962303162, "incre_win_rate": 0.7692307692307693, "step": 653}
{"time": 1767154412.9211917, "phase": "train", "update": 654, "total_env_steps": 2092800, "episode_reward": 0.21849389374256134, "value_loss": 0.09045915603637696, "policy_loss": -0.0006773659629565997, "dist_entropy": 0.7501860141754151, "actor_grad_norm": 0.08196302503347397, "critic_grad_norm": 0.5788295269012451, "ratio": 1.0000641345977783, "entropy": 0.7501860141754151, "incre_win_rate": 0.8125, "step": 654}
{"time": 1767154417.4290605, "phase": "train", "update": 655, "total_env_steps": 2096000, "episode_reward": 0.21770334243774414, "value_loss": 0.012588562443852425, "policy_loss": -0.0011365438704203257, "dist_entropy": 0.7492567420005798, "actor_grad_norm": 0.09833139926195145, "critic_grad_norm": 0.3474346995353699, "ratio": 1.0000966787338257, "entropy": 0.7492567420005798, "incre_win_rate": 0.7567567567567568, "step": 655}
{"time": 1767154421.7573369, "phase": "train", "update": 656, "total_env_steps": 2099200, "episode_reward": 0.2300165593624115, "value_loss": 0.007523658871650696, "policy_loss": -0.0009702541538146647, "dist_entropy": 0.7358322143554688, "actor_grad_norm": 0.13010719418525696, "critic_grad_norm": 0.2728608250617981, "ratio": 1.0001306533813477, "entropy": 0.7358322143554688, "incre_win_rate": 0.8947368421052632, "step": 656}
{"time": 1767154426.0430148, "phase": "train", "update": 657, "total_env_steps": 2102400, "episode_reward": 0.23073416948318481, "value_loss": 0.007608071062713861, "policy_loss": -0.0009893146313132207, "dist_entropy": 0.735993754863739, "actor_grad_norm": 0.07509894669055939, "critic_grad_norm": 0.11414863914251328, "ratio": 1.0000238418579102, "entropy": 0.735993754863739, "incre_win_rate": 0.8, "step": 657}
{"time": 1767154430.3813431, "phase": "train", "update": 658, "total_env_steps": 2105600, "episode_reward": 0.25034770369529724, "value_loss": 0.005876208283007145, "policy_loss": -0.0009582732551585594, "dist_entropy": 0.7437936186790466, "actor_grad_norm": 0.08498512953519821, "critic_grad_norm": 0.08523613959550858, "ratio": 0.9997345209121704, "entropy": 0.7437936186790466, "incre_win_rate": 1.0, "step": 658}
{"time": 1767154434.6850624, "phase": "train", "update": 659, "total_env_steps": 2108800, "episode_reward": 0.23041339218616486, "value_loss": 0.012273242324590683, "policy_loss": -0.0012480876884815473, "dist_entropy": 0.7541145920753479, "actor_grad_norm": 0.11698140949010849, "critic_grad_norm": 0.1431705802679062, "ratio": 1.000099778175354, "entropy": 0.7541145920753479, "incre_win_rate": 0.8536585365853658, "step": 659}
{"time": 1767154438.9788465, "phase": "train", "update": 660, "total_env_steps": 2112000, "episode_reward": 0.24533110857009888, "value_loss": 0.006250925362110138, "policy_loss": -0.0009795903256388794, "dist_entropy": 0.7547033905982972, "actor_grad_norm": 0.09487681835889816, "critic_grad_norm": 0.09333600848913193, "ratio": 1.0002559423446655, "entropy": 0.7547033905982972, "incre_win_rate": 0.9210526315789473, "step": 660}
{"time": 1767154443.3002245, "phase": "train", "update": 661, "total_env_steps": 2115200, "episode_reward": 0.23389694094657898, "value_loss": 0.007508832961320877, "policy_loss": -0.0010370562937740857, "dist_entropy": 0.7894401311874389, "actor_grad_norm": 0.08308114856481552, "critic_grad_norm": 0.05330527946352959, "ratio": 1.000229835510254, "entropy": 0.7894401311874389, "incre_win_rate": 0.868421052631579, "step": 661}
{"time": 1767154455.4026043, "phase": "eval", "update": 661, "total_env_steps": 2115200, "eval_win_rate": 0.75, "eval_episode_reward": 18.80442880794702, "step": 661}
{"time": 1767154459.7005196, "phase": "train", "update": 662, "total_env_steps": 2118400, "episode_reward": 0.23265881836414337, "value_loss": 0.008849627152085305, "policy_loss": -0.0012078304344647962, "dist_entropy": 0.7816526770591736, "actor_grad_norm": 0.08238633722066879, "critic_grad_norm": 0.0670713409781456, "ratio": 1.0003007650375366, "entropy": 0.7816526770591736, "incre_win_rate": 0.7948717948717948, "step": 662}
{"time": 1767154464.025839, "phase": "train", "update": 663, "total_env_steps": 2121600, "episode_reward": 0.23554636538028717, "value_loss": 0.011775556392967701, "policy_loss": -0.0011829341716717678, "dist_entropy": 0.7680638432502747, "actor_grad_norm": 0.14067603647708893, "critic_grad_norm": 0.07120006531476974, "ratio": 1.0000871419906616, "entropy": 0.7680638432502747, "incre_win_rate": 0.825, "step": 663}
{"time": 1767154468.313532, "phase": "train", "update": 664, "total_env_steps": 2124800, "episode_reward": 0.24968956410884857, "value_loss": 0.006001963745802641, "policy_loss": -0.0010437125198762942, "dist_entropy": 0.7464825987815857, "actor_grad_norm": 0.08728732913732529, "critic_grad_norm": 0.11100754886865616, "ratio": 1.0001763105392456, "entropy": 0.7464825987815857, "incre_win_rate": 0.9285714285714286, "step": 664}
{"time": 1767154472.6716876, "phase": "train", "update": 665, "total_env_steps": 2128000, "episode_reward": 0.2362137734889984, "value_loss": 0.009335884265601635, "policy_loss": -0.0008630136718750236, "dist_entropy": 0.7351905465126037, "actor_grad_norm": 0.10275230556726456, "critic_grad_norm": 0.14477646350860596, "ratio": 0.999779224395752, "entropy": 0.7351905465126037, "incre_win_rate": 0.8461538461538461, "step": 665}
{"time": 1767154476.9470708, "phase": "train", "update": 666, "total_env_steps": 2131200, "episode_reward": 0.22685998678207397, "value_loss": 0.012953469157218933, "policy_loss": -0.0009898852963374338, "dist_entropy": 0.7593549966812134, "actor_grad_norm": 0.1040690690279007, "critic_grad_norm": 0.21219372749328613, "ratio": 0.9996903538703918, "entropy": 0.7593549966812134, "incre_win_rate": 0.7435897435897436, "step": 666}
{"time": 1767154481.273991, "phase": "train", "update": 667, "total_env_steps": 2134400, "episode_reward": 0.22653765976428986, "value_loss": 0.012822682969272137, "policy_loss": -0.0014469138944328108, "dist_entropy": 0.7448829412460327, "actor_grad_norm": 0.1483050137758255, "critic_grad_norm": 0.16699497401714325, "ratio": 0.9997097849845886, "entropy": 0.7448829412460327, "incre_win_rate": 0.7804878048780488, "step": 667}
{"time": 1767154485.5782294, "phase": "train", "update": 668, "total_env_steps": 2137600, "episode_reward": 0.23840542137622833, "value_loss": 0.009727592580020428, "policy_loss": -0.0010198327894357817, "dist_entropy": 0.7698808431625366, "actor_grad_norm": 0.10379469394683838, "critic_grad_norm": 0.2003306895494461, "ratio": 1.0002697706222534, "entropy": 0.7698808431625366, "incre_win_rate": 0.868421052631579, "step": 668}
{"time": 1767154489.9065642, "phase": "train", "update": 669, "total_env_steps": 2140800, "episode_reward": 0.2376355528831482, "value_loss": 0.011934185028076172, "policy_loss": -0.0013562506102815064, "dist_entropy": 0.7767488598823548, "actor_grad_norm": 0.08056627959012985, "critic_grad_norm": 0.08623283356428146, "ratio": 0.9999752044677734, "entropy": 0.7767488598823548, "incre_win_rate": 0.8048780487804879, "step": 669}
{"time": 1767154494.2248862, "phase": "train", "update": 670, "total_env_steps": 2144000, "episode_reward": 0.23639799654483795, "value_loss": 0.01161110308021307, "policy_loss": -0.0014002661176871101, "dist_entropy": 0.7807460427284241, "actor_grad_norm": 0.09915263950824738, "critic_grad_norm": 0.1306871622800827, "ratio": 1.0000556707382202, "entropy": 0.7807460427284241, "incre_win_rate": 0.8048780487804879, "step": 670}
{"time": 1767154498.5207348, "phase": "train", "update": 671, "total_env_steps": 2147200, "episode_reward": 0.23023180663585663, "value_loss": 0.018774372711777686, "policy_loss": -0.0013334536300128263, "dist_entropy": 0.7541442155838013, "actor_grad_norm": 0.09928862005472183, "critic_grad_norm": 0.1563163548707962, "ratio": 1.0003565549850464, "entropy": 0.7541442155838013, "incre_win_rate": 0.7948717948717948, "step": 671}
{"time": 1767154502.842728, "phase": "train", "update": 672, "total_env_steps": 2150400, "episode_reward": 0.22605544328689575, "value_loss": 0.01609201282262802, "policy_loss": -0.0012124017562896937, "dist_entropy": 0.7635991454124451, "actor_grad_norm": 0.09596865624189377, "critic_grad_norm": 0.22901837527751923, "ratio": 0.9998806118965149, "entropy": 0.7635991454124451, "incre_win_rate": 0.7435897435897436, "step": 672}
{"time": 1767154507.1557317, "phase": "train", "update": 673, "total_env_steps": 2153600, "episode_reward": 0.23385348916053772, "value_loss": 0.011619475111365319, "policy_loss": -0.0010828388092555485, "dist_entropy": 0.7730286836624145, "actor_grad_norm": 0.08505135774612427, "critic_grad_norm": 0.19404225051403046, "ratio": 0.999967098236084, "entropy": 0.7730286836624145, "incre_win_rate": 0.825, "step": 673}
{"time": 1767154511.4364839, "phase": "train", "update": 674, "total_env_steps": 2156800, "episode_reward": 0.23621897399425507, "value_loss": 0.00908030178397894, "policy_loss": -0.0011668870677951303, "dist_entropy": 0.7489826202392578, "actor_grad_norm": 0.12976941466331482, "critic_grad_norm": 0.1058802604675293, "ratio": 1.0002981424331665, "entropy": 0.7489826202392578, "incre_win_rate": 0.8717948717948718, "step": 674}
{"time": 1767154515.740608, "phase": "train", "update": 675, "total_env_steps": 2160000, "episode_reward": 0.2477349042892456, "value_loss": 0.00914964433759451, "policy_loss": -0.0009683270131954913, "dist_entropy": 0.7539418578147888, "actor_grad_norm": 0.10088939964771271, "critic_grad_norm": 0.09561686962842941, "ratio": 0.9998239874839783, "entropy": 0.7539418578147888, "incre_win_rate": 0.9024390243902439, "step": 675}
{"time": 1767154520.0495396, "phase": "train", "update": 676, "total_env_steps": 2163200, "episode_reward": 0.2517922520637512, "value_loss": 0.011073140613734721, "policy_loss": -0.0013279667622427382, "dist_entropy": 0.7602886438369751, "actor_grad_norm": 0.10927551984786987, "critic_grad_norm": 0.06195652484893799, "ratio": 0.9998809695243835, "entropy": 0.7602886438369751, "incre_win_rate": 0.9512195121951219, "step": 676}
{"time": 1767154524.3507297, "phase": "train", "update": 677, "total_env_steps": 2166400, "episode_reward": 0.23814208805561066, "value_loss": 0.01037953794002533, "policy_loss": -0.0011321644668527142, "dist_entropy": 0.7554664254188538, "actor_grad_norm": 0.13686016201972961, "critic_grad_norm": 0.09109999984502792, "ratio": 1.000062346458435, "entropy": 0.7554664254188538, "incre_win_rate": 0.7619047619047619, "step": 677}
{"time": 1767154529.1143134, "phase": "train", "update": 678, "total_env_steps": 2169600, "episode_reward": 0.2402421534061432, "value_loss": 0.009077475219964982, "policy_loss": -0.0011566194307576438, "dist_entropy": 0.7474915146827698, "actor_grad_norm": 0.08647691458463669, "critic_grad_norm": 0.0995115339756012, "ratio": 1.0002212524414062, "entropy": 0.7474915146827698, "incre_win_rate": 0.925, "step": 678}
{"time": 1767154533.4014895, "phase": "train", "update": 679, "total_env_steps": 2172800, "episode_reward": 0.2353745996952057, "value_loss": 0.009351939894258976, "policy_loss": -0.001289816563111401, "dist_entropy": 0.7469239115715027, "actor_grad_norm": 0.15999393165111542, "critic_grad_norm": 0.14231853187084198, "ratio": 0.9998018145561218, "entropy": 0.7469239115715027, "incre_win_rate": 0.825, "step": 679}
{"time": 1767154537.603227, "phase": "train", "update": 680, "total_env_steps": 2176000, "episode_reward": 0.23610100150108337, "value_loss": 0.010171223990619182, "policy_loss": -0.001275320245318312, "dist_entropy": 0.7499450445175171, "actor_grad_norm": 0.10170810669660568, "critic_grad_norm": 0.08879441767930984, "ratio": 0.9995476603507996, "entropy": 0.7499450445175171, "incre_win_rate": 0.8717948717948718, "step": 680}
{"time": 1767154541.8725162, "phase": "train", "update": 681, "total_env_steps": 2179200, "episode_reward": 0.24408526718616486, "value_loss": 0.010024764947593212, "policy_loss": -0.0013787800760816538, "dist_entropy": 0.7608364820480347, "actor_grad_norm": 0.09656520932912827, "critic_grad_norm": 0.08169932663440704, "ratio": 1.0000929832458496, "entropy": 0.7608364820480347, "incre_win_rate": 0.9210526315789473, "step": 681}
{"time": 1767154553.2453616, "phase": "eval", "update": 681, "total_env_steps": 2179200, "eval_win_rate": 0.875, "eval_episode_reward": 19.556032698675494, "step": 681}
{"time": 1767154557.484038, "phase": "train", "update": 682, "total_env_steps": 2182400, "episode_reward": 0.2411154806613922, "value_loss": 0.007970425207167864, "policy_loss": -0.001247901961597453, "dist_entropy": 0.7396655797958374, "actor_grad_norm": 0.08885816484689713, "critic_grad_norm": 0.2023104727268219, "ratio": 0.9997806549072266, "entropy": 0.7396655797958374, "incre_win_rate": 0.925, "step": 682}
{"time": 1767154561.7848158, "phase": "train", "update": 683, "total_env_steps": 2185600, "episode_reward": 0.24110408127307892, "value_loss": 0.010991022549569606, "policy_loss": -0.001282801472738271, "dist_entropy": 0.7583199620246888, "actor_grad_norm": 0.08201108872890472, "critic_grad_norm": 0.17471085488796234, "ratio": 0.9998683333396912, "entropy": 0.7583199620246888, "incre_win_rate": 0.8095238095238095, "step": 683}
{"time": 1767154566.0305917, "phase": "train", "update": 684, "total_env_steps": 2188800, "episode_reward": 0.2364802360534668, "value_loss": 0.010315559804439545, "policy_loss": -0.0011575757978121715, "dist_entropy": 0.7470003247261048, "actor_grad_norm": 0.1177830696105957, "critic_grad_norm": 0.1232224702835083, "ratio": 0.9993866086006165, "entropy": 0.7470003247261048, "incre_win_rate": 0.8108108108108109, "step": 684}
{"time": 1767154570.3051858, "phase": "train", "update": 685, "total_env_steps": 2192000, "episode_reward": 0.23119311034679413, "value_loss": 0.014758970774710178, "policy_loss": -0.0009109893808357583, "dist_entropy": 0.7641801357269287, "actor_grad_norm": 0.10304632037878036, "critic_grad_norm": 0.14370949566364288, "ratio": 0.9998371005058289, "entropy": 0.7641801357269287, "incre_win_rate": 0.775, "step": 685}
{"time": 1767154575.5375583, "phase": "train", "update": 686, "total_env_steps": 2195200, "episode_reward": 0.24518264830112457, "value_loss": 0.008378360606729984, "policy_loss": -0.001315950909641117, "dist_entropy": 0.7781954526901245, "actor_grad_norm": 0.08269859850406647, "critic_grad_norm": 0.11332204192876816, "ratio": 0.9998319745063782, "entropy": 0.7781954526901245, "incre_win_rate": 0.8809523809523809, "step": 686}
{"time": 1767154579.796202, "phase": "train", "update": 687, "total_env_steps": 2198400, "episode_reward": 0.23088420927524567, "value_loss": 0.009389864094555379, "policy_loss": -0.0014527706242162708, "dist_entropy": 0.7636564493179321, "actor_grad_norm": 0.09261547774076462, "critic_grad_norm": 0.10113246738910675, "ratio": 0.9998825192451477, "entropy": 0.7636564493179321, "incre_win_rate": 0.8108108108108109, "step": 687}
{"time": 1767154584.041454, "phase": "train", "update": 688, "total_env_steps": 2201600, "episode_reward": 0.23692932724952698, "value_loss": 0.009765684232115745, "policy_loss": -0.0016786131165730466, "dist_entropy": 0.7597527861595154, "actor_grad_norm": 0.1166142001748085, "critic_grad_norm": 0.087310291826725, "ratio": 0.9996606707572937, "entropy": 0.7597527861595154, "incre_win_rate": 0.8095238095238095, "step": 688}
{"time": 1767154588.248308, "phase": "train", "update": 689, "total_env_steps": 2204800, "episode_reward": 0.23052774369716644, "value_loss": 0.007899194210767745, "policy_loss": -0.001672070742584708, "dist_entropy": 0.757134985923767, "actor_grad_norm": 0.11863239109516144, "critic_grad_norm": 0.05440038442611694, "ratio": 0.9996512532234192, "entropy": 0.757134985923767, "incre_win_rate": 0.8108108108108109, "step": 689}
{"time": 1767154592.4727423, "phase": "train", "update": 690, "total_env_steps": 2208000, "episode_reward": 0.22309499979019165, "value_loss": 0.0104109738022089, "policy_loss": -0.0013278702118074137, "dist_entropy": 0.7493524432182312, "actor_grad_norm": 0.10551563650369644, "critic_grad_norm": 0.09155210107564926, "ratio": 1.0002789497375488, "entropy": 0.7493524432182312, "incre_win_rate": 0.7894736842105263, "step": 690}
{"time": 1767154596.7361703, "phase": "train", "update": 691, "total_env_steps": 2211200, "episode_reward": 0.2400476038455963, "value_loss": 0.0062539934180676935, "policy_loss": -0.0009532403972286829, "dist_entropy": 0.7535574316978455, "actor_grad_norm": 0.11018427461385727, "critic_grad_norm": 0.08132921904325485, "ratio": 1.0000115633010864, "entropy": 0.7535574316978455, "incre_win_rate": 0.9230769230769231, "step": 691}
{"time": 1767154601.067806, "phase": "train", "update": 692, "total_env_steps": 2214400, "episode_reward": 0.21772506833076477, "value_loss": 0.01099682431668043, "policy_loss": -0.0016769461176863842, "dist_entropy": 0.7603156328201294, "actor_grad_norm": 0.10654065757989883, "critic_grad_norm": 0.23568835854530334, "ratio": 0.9999417662620544, "entropy": 0.7603156328201294, "incre_win_rate": 0.7, "step": 692}
{"time": 1767154605.3990173, "phase": "train", "update": 693, "total_env_steps": 2217600, "episode_reward": 0.23770177364349365, "value_loss": 0.011269203759729863, "policy_loss": -0.0012137033704789247, "dist_entropy": 0.7475997924804687, "actor_grad_norm": 0.08689086884260178, "critic_grad_norm": 0.15632005035877228, "ratio": 0.9997469186782837, "entropy": 0.7475997924804687, "incre_win_rate": 0.9210526315789473, "step": 693}
{"time": 1767154609.625694, "phase": "train", "update": 694, "total_env_steps": 2220800, "episode_reward": 0.22484582662582397, "value_loss": 0.012083977274596692, "policy_loss": -0.0015689023786634947, "dist_entropy": 0.7483572721481323, "actor_grad_norm": 0.09931131452322006, "critic_grad_norm": 0.11594001203775406, "ratio": 0.9996699690818787, "entropy": 0.7483572721481323, "incre_win_rate": 0.7631578947368421, "step": 694}
{"time": 1767154613.8635297, "phase": "train", "update": 695, "total_env_steps": 2224000, "episode_reward": 0.2312023937702179, "value_loss": 0.009681077115237713, "policy_loss": -0.0015002914991086413, "dist_entropy": 0.7582393169403077, "actor_grad_norm": 0.10340575128793716, "critic_grad_norm": 0.2613617479801178, "ratio": 1.000107765197754, "entropy": 0.7582393169403077, "incre_win_rate": 0.7948717948717948, "step": 695}
{"time": 1767154618.0936072, "phase": "train", "update": 696, "total_env_steps": 2227200, "episode_reward": 0.23851770162582397, "value_loss": 0.006849299091845751, "policy_loss": -0.0016056219600784516, "dist_entropy": 0.7344220876693726, "actor_grad_norm": 0.09264367073774338, "critic_grad_norm": 0.14940932393074036, "ratio": 0.9999001622200012, "entropy": 0.7344220876693726, "incre_win_rate": 0.85, "step": 696}
{"time": 1767154622.3711188, "phase": "train", "update": 697, "total_env_steps": 2230400, "episode_reward": 0.2352752536535263, "value_loss": 0.008941207826137543, "policy_loss": -0.0012156838905374556, "dist_entropy": 0.739435863494873, "actor_grad_norm": 0.08201246708631516, "critic_grad_norm": 0.14026351273059845, "ratio": 0.9998772740364075, "entropy": 0.739435863494873, "incre_win_rate": 0.7948717948717948, "step": 697}
{"time": 1767154626.6184273, "phase": "train", "update": 698, "total_env_steps": 2233600, "episode_reward": 0.2324751615524292, "value_loss": 0.011557978205382824, "policy_loss": -0.0014775553968380706, "dist_entropy": 0.7051201701164246, "actor_grad_norm": 0.1343146413564682, "critic_grad_norm": 0.18392392992973328, "ratio": 0.9998670816421509, "entropy": 0.7051201701164246, "incre_win_rate": 0.8205128205128205, "step": 698}
{"time": 1767154630.846238, "phase": "train", "update": 699, "total_env_steps": 2236800, "episode_reward": 0.241472989320755, "value_loss": 0.010069363377988338, "policy_loss": -0.0009026232936570011, "dist_entropy": 0.706952691078186, "actor_grad_norm": 0.10550981014966965, "critic_grad_norm": 0.1343124359846115, "ratio": 0.9999298453330994, "entropy": 0.706952691078186, "incre_win_rate": 0.8780487804878049, "step": 699}
{"time": 1767154635.346635, "phase": "train", "update": 700, "total_env_steps": 2240000, "episode_reward": 0.23203331232070923, "value_loss": 0.012109924294054508, "policy_loss": -0.0011658711417354972, "dist_entropy": 0.7169366002082824, "actor_grad_norm": 0.1337711364030838, "critic_grad_norm": 0.12842105329036713, "ratio": 0.999977707862854, "entropy": 0.7169366002082824, "incre_win_rate": 0.75, "step": 700}
{"time": 1767154639.7250354, "phase": "train", "update": 701, "total_env_steps": 2243200, "episode_reward": 0.24689362943172455, "value_loss": 0.009750163555145264, "policy_loss": -0.0010576098829435665, "dist_entropy": 0.7078120946884155, "actor_grad_norm": 0.08754436671733856, "critic_grad_norm": 0.1550159603357315, "ratio": 0.9999265074729919, "entropy": 0.7078120946884155, "incre_win_rate": 0.85, "step": 701}
{"time": 1767154650.5988238, "phase": "eval", "update": 701, "total_env_steps": 2243200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.749068708609272, "step": 701}
{"time": 1767154654.8584225, "phase": "train", "update": 702, "total_env_steps": 2246400, "episode_reward": 0.24780888855457306, "value_loss": 0.007993466965854169, "policy_loss": -0.0011967154330633889, "dist_entropy": 0.7145689606666565, "actor_grad_norm": 0.11604126542806625, "critic_grad_norm": 0.11408209055662155, "ratio": 0.9995169043540955, "entropy": 0.7145689606666565, "incre_win_rate": 0.9285714285714286, "step": 702}
{"time": 1767154659.1084075, "phase": "train", "update": 703, "total_env_steps": 2249600, "episode_reward": 0.23865482211112976, "value_loss": 0.010789907164871692, "policy_loss": -0.001398849825502335, "dist_entropy": 0.7125100255012512, "actor_grad_norm": 0.12419559806585312, "critic_grad_norm": 0.23337841033935547, "ratio": 0.9995298385620117, "entropy": 0.7125100255012512, "incre_win_rate": 0.8292682926829268, "step": 703}
{"time": 1767154663.3940432, "phase": "train", "update": 704, "total_env_steps": 2252800, "episode_reward": 0.25146111845970154, "value_loss": 0.005716866627335548, "policy_loss": -0.0012628457099957302, "dist_entropy": 0.6928087830543518, "actor_grad_norm": 0.1260746270418167, "critic_grad_norm": 0.11540301144123077, "ratio": 0.9995922446250916, "entropy": 0.6928087830543518, "incre_win_rate": 0.95, "step": 704}
{"time": 1767154667.643591, "phase": "train", "update": 705, "total_env_steps": 2256000, "episode_reward": 0.22470250725746155, "value_loss": 0.011351170018315315, "policy_loss": -0.00121444481843902, "dist_entropy": 0.696384048461914, "actor_grad_norm": 0.12005641311407089, "critic_grad_norm": 0.14754219353199005, "ratio": 1.000306487083435, "entropy": 0.696384048461914, "incre_win_rate": 0.7435897435897436, "step": 705}
{"time": 1767154671.919735, "phase": "train", "update": 706, "total_env_steps": 2259200, "episode_reward": 0.2363203763961792, "value_loss": 0.01100363340228796, "policy_loss": -0.001226661412141139, "dist_entropy": 0.6781453847885132, "actor_grad_norm": 0.08482328802347183, "critic_grad_norm": 0.1687532514333725, "ratio": 1.0000838041305542, "entropy": 0.6781453847885132, "incre_win_rate": 0.8, "step": 706}
{"time": 1767154676.1719747, "phase": "train", "update": 707, "total_env_steps": 2262400, "episode_reward": 0.23718906939029694, "value_loss": 0.009426478669047356, "policy_loss": -0.0011159701930328226, "dist_entropy": 0.6935689687728882, "actor_grad_norm": 0.12657438218593597, "critic_grad_norm": 0.15507996082305908, "ratio": 1.0002930164337158, "entropy": 0.6935689687728882, "incre_win_rate": 0.8461538461538461, "step": 707}
{"time": 1767154680.4343586, "phase": "train", "update": 708, "total_env_steps": 2265600, "episode_reward": 0.25196608901023865, "value_loss": 0.006263505946844816, "policy_loss": -0.0008856971103313072, "dist_entropy": 0.6911054253578186, "actor_grad_norm": 0.0974591001868248, "critic_grad_norm": 0.06066051870584488, "ratio": 1.0000513792037964, "entropy": 0.6911054253578186, "incre_win_rate": 0.95, "step": 708}
{"time": 1767154684.6855638, "phase": "train", "update": 709, "total_env_steps": 2268800, "episode_reward": 0.23639486730098724, "value_loss": 0.00887594111263752, "policy_loss": -0.001475795302939531, "dist_entropy": 0.709805142879486, "actor_grad_norm": 0.10154572874307632, "critic_grad_norm": 0.19062171876430511, "ratio": 0.9994427561759949, "entropy": 0.709805142879486, "incre_win_rate": 0.8717948717948718, "step": 709}
{"time": 1767154689.0077283, "phase": "train", "update": 710, "total_env_steps": 2272000, "episode_reward": 0.23920217156410217, "value_loss": 0.015201174095273018, "policy_loss": -0.0011303301216283757, "dist_entropy": 0.7360432624816895, "actor_grad_norm": 0.09497655183076859, "critic_grad_norm": 0.2018275260925293, "ratio": 1.0002825260162354, "entropy": 0.7360432624816895, "incre_win_rate": 0.875, "step": 710}
{"time": 1767154693.2633495, "phase": "train", "update": 711, "total_env_steps": 2275200, "episode_reward": 0.23473821580410004, "value_loss": 0.008175318781286477, "policy_loss": -0.0009755770262053432, "dist_entropy": 0.7274051070213318, "actor_grad_norm": 0.12158600240945816, "critic_grad_norm": 0.2343694269657135, "ratio": 1.000200867652893, "entropy": 0.7274051070213318, "incre_win_rate": 0.875, "step": 711}
{"time": 1767154697.497782, "phase": "train", "update": 712, "total_env_steps": 2278400, "episode_reward": 0.239946186542511, "value_loss": 0.007600148301571607, "policy_loss": -0.001212247713932868, "dist_entropy": 0.7223255276679993, "actor_grad_norm": 0.0861947312951088, "critic_grad_norm": 0.19751159846782684, "ratio": 0.9999608993530273, "entropy": 0.7223255276679993, "incre_win_rate": 0.8947368421052632, "step": 712}
{"time": 1767154701.7421772, "phase": "train", "update": 713, "total_env_steps": 2281600, "episode_reward": 0.22526541352272034, "value_loss": 0.012954753078520297, "policy_loss": -0.0008059733375503697, "dist_entropy": 0.7487587332725525, "actor_grad_norm": 0.09941060841083527, "critic_grad_norm": 0.25707197189331055, "ratio": 1.0004010200500488, "entropy": 0.7487587332725525, "incre_win_rate": 0.7560975609756098, "step": 713}
{"time": 1767154706.0121677, "phase": "train", "update": 714, "total_env_steps": 2284800, "episode_reward": 0.2357320934534073, "value_loss": 0.010227993130683899, "policy_loss": -0.0012023431377375716, "dist_entropy": 0.7220600843429565, "actor_grad_norm": 0.10770156234502792, "critic_grad_norm": 0.14013147354125977, "ratio": 0.999743640422821, "entropy": 0.7220600843429565, "incre_win_rate": 0.7804878048780488, "step": 714}
{"time": 1767154710.2795053, "phase": "train", "update": 715, "total_env_steps": 2288000, "episode_reward": 0.24450746178627014, "value_loss": 0.009653388708829879, "policy_loss": -0.001101077115229998, "dist_entropy": 0.7413367986679077, "actor_grad_norm": 0.12790550291538239, "critic_grad_norm": 0.11244833469390869, "ratio": 0.9999575614929199, "entropy": 0.7413367986679077, "incre_win_rate": 0.9, "step": 715}
{"time": 1767154714.5425844, "phase": "train", "update": 716, "total_env_steps": 2291200, "episode_reward": 0.24393416941165924, "value_loss": 0.006963302008807659, "policy_loss": -0.0015603021090132784, "dist_entropy": 0.7380722641944886, "actor_grad_norm": 0.10607790946960449, "critic_grad_norm": 0.1692088097333908, "ratio": 0.9999151229858398, "entropy": 0.7380722641944886, "incre_win_rate": 0.9, "step": 716}
{"time": 1767154718.7999759, "phase": "train", "update": 717, "total_env_steps": 2294400, "episode_reward": 0.24135760962963104, "value_loss": 0.007114151399582625, "policy_loss": -0.0013797759959267354, "dist_entropy": 0.7476380228996277, "actor_grad_norm": 0.13659094274044037, "critic_grad_norm": 0.052594393491744995, "ratio": 0.9999338388442993, "entropy": 0.7476380228996277, "incre_win_rate": 0.9230769230769231, "step": 717}
{"time": 1767154723.1056535, "phase": "train", "update": 718, "total_env_steps": 2297600, "episode_reward": 0.237741619348526, "value_loss": 0.0066582666710019115, "policy_loss": -0.0013198279190433481, "dist_entropy": 0.7316577315330506, "actor_grad_norm": 0.11043905466794968, "critic_grad_norm": 0.048895686864852905, "ratio": 1.0001434087753296, "entropy": 0.7316577315330506, "incre_win_rate": 0.9230769230769231, "step": 718}
{"time": 1767154727.4226577, "phase": "train", "update": 719, "total_env_steps": 2300800, "episode_reward": 0.231175497174263, "value_loss": 0.00981459841132164, "policy_loss": -0.001038489107180851, "dist_entropy": 0.7749035716056824, "actor_grad_norm": 0.10387032479047775, "critic_grad_norm": 0.09870065748691559, "ratio": 1.0001063346862793, "entropy": 0.7749035716056824, "incre_win_rate": 0.8947368421052632, "step": 719}
{"time": 1767154731.7485714, "phase": "train", "update": 720, "total_env_steps": 2304000, "episode_reward": 0.23612117767333984, "value_loss": 0.00679181506857276, "policy_loss": -0.0016471550101861965, "dist_entropy": 0.7423870682716369, "actor_grad_norm": 0.11481191217899323, "critic_grad_norm": 0.09894566237926483, "ratio": 1.0004932880401611, "entropy": 0.7423870682716369, "incre_win_rate": 0.8717948717948718, "step": 720}
{"time": 1767154736.051033, "phase": "train", "update": 721, "total_env_steps": 2307200, "episode_reward": 0.23137003183364868, "value_loss": 0.008603036031126976, "policy_loss": -0.0006619336779380092, "dist_entropy": 0.7719372034072876, "actor_grad_norm": 0.12494557350873947, "critic_grad_norm": 0.11184986680746078, "ratio": 1.0003876686096191, "entropy": 0.7719372034072876, "incre_win_rate": 0.7894736842105263, "step": 721}
{"time": 1767154747.333581, "phase": "eval", "update": 721, "total_env_steps": 2307200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.67813534768212, "step": 721}
{"time": 1767154751.6277275, "phase": "train", "update": 722, "total_env_steps": 2310400, "episode_reward": 0.23655059933662415, "value_loss": 0.008445771783590317, "policy_loss": -0.001379335595808584, "dist_entropy": 0.7622618794441223, "actor_grad_norm": 0.1306856870651245, "critic_grad_norm": 0.09177418053150177, "ratio": 0.9997190833091736, "entropy": 0.7622618794441223, "incre_win_rate": 0.8536585365853658, "step": 722}
{"time": 1767154755.9200761, "phase": "train", "update": 723, "total_env_steps": 2313600, "episode_reward": 0.22569018602371216, "value_loss": 0.011105062998831272, "policy_loss": -0.0010451468691130116, "dist_entropy": 0.7501089215278626, "actor_grad_norm": 0.13019926846027374, "critic_grad_norm": 0.11366059631109238, "ratio": 1.0000721216201782, "entropy": 0.7501089215278626, "incre_win_rate": 0.6923076923076923, "step": 723}
{"time": 1767154760.1568413, "phase": "train", "update": 724, "total_env_steps": 2316800, "episode_reward": 0.2335239201784134, "value_loss": 0.01127635482698679, "policy_loss": -0.0013253524039328114, "dist_entropy": 0.7587587356567382, "actor_grad_norm": 0.09042814373970032, "critic_grad_norm": 0.11734286695718765, "ratio": 1.0001729726791382, "entropy": 0.7587587356567382, "incre_win_rate": 0.8048780487804879, "step": 724}
{"time": 1767154764.4436107, "phase": "train", "update": 725, "total_env_steps": 2320000, "episode_reward": 0.225164532661438, "value_loss": 0.013830072246491909, "policy_loss": -0.0013342134550754282, "dist_entropy": 0.7571127414703369, "actor_grad_norm": 0.09191664308309555, "critic_grad_norm": 0.09803368151187897, "ratio": 0.9999295473098755, "entropy": 0.7571127414703369, "incre_win_rate": 0.7435897435897436, "step": 725}
{"time": 1767154768.7344224, "phase": "train", "update": 726, "total_env_steps": 2323200, "episode_reward": 0.22955350577831268, "value_loss": 0.00969292651861906, "policy_loss": -0.0012608704486865463, "dist_entropy": 0.7595841884613037, "actor_grad_norm": 0.13915280997753143, "critic_grad_norm": 0.1673736721277237, "ratio": 0.9999627470970154, "entropy": 0.7595841884613037, "incre_win_rate": 0.8378378378378378, "step": 726}
{"time": 1767154773.0641994, "phase": "train", "update": 727, "total_env_steps": 2326400, "episode_reward": 0.2345995455980301, "value_loss": 0.010421458631753922, "policy_loss": -0.001674564779171206, "dist_entropy": 0.7365613341331482, "actor_grad_norm": 0.1401718407869339, "critic_grad_norm": 0.16258230805397034, "ratio": 0.9996107220649719, "entropy": 0.7365613341331482, "incre_win_rate": 0.8, "step": 727}
{"time": 1767154777.3447628, "phase": "train", "update": 728, "total_env_steps": 2329600, "episode_reward": 0.24690397083759308, "value_loss": 0.009106515720486642, "policy_loss": -0.0010229011466861948, "dist_entropy": 0.7306336998939514, "actor_grad_norm": 0.14121925830841064, "critic_grad_norm": 0.22137241065502167, "ratio": 1.0000755786895752, "entropy": 0.7306336998939514, "incre_win_rate": 0.925, "step": 728}
{"time": 1767154781.6370087, "phase": "train", "update": 729, "total_env_steps": 2332800, "episode_reward": 0.24334384500980377, "value_loss": 0.009029863588511943, "policy_loss": -0.0011143106340192332, "dist_entropy": 0.7145466804504395, "actor_grad_norm": 0.10540713369846344, "critic_grad_norm": 0.16252735257148743, "ratio": 0.9996303915977478, "entropy": 0.7145466804504395, "incre_win_rate": 0.8974358974358975, "step": 729}
{"time": 1767154785.9080498, "phase": "train", "update": 730, "total_env_steps": 2336000, "episode_reward": 0.22922807931900024, "value_loss": 0.010555626451969146, "policy_loss": -0.0012794738318258503, "dist_entropy": 0.7281410336494446, "actor_grad_norm": 0.123937226831913, "critic_grad_norm": 0.12288512289524078, "ratio": 1.00002121925354, "entropy": 0.7281410336494446, "incre_win_rate": 0.8717948717948718, "step": 730}
{"time": 1767154790.1821644, "phase": "train", "update": 731, "total_env_steps": 2339200, "episode_reward": 0.214934304356575, "value_loss": 0.012443562224507331, "policy_loss": -0.0014624107303729873, "dist_entropy": 0.7174066185951233, "actor_grad_norm": 0.09791430085897446, "critic_grad_norm": 0.17472313344478607, "ratio": 1.000191569328308, "entropy": 0.7174066185951233, "incre_win_rate": 0.7027027027027027, "step": 731}
{"time": 1767154794.4894478, "phase": "train", "update": 732, "total_env_steps": 2342400, "episode_reward": 0.21793822944164276, "value_loss": 0.01396477222442627, "policy_loss": -0.0013745841912552238, "dist_entropy": 0.7377776622772216, "actor_grad_norm": 0.10116428136825562, "critic_grad_norm": 0.13423703610897064, "ratio": 1.000109076499939, "entropy": 0.7377776622772216, "incre_win_rate": 0.7105263157894737, "step": 732}
{"time": 1767154798.8073285, "phase": "train", "update": 733, "total_env_steps": 2345600, "episode_reward": 0.24086402356624603, "value_loss": 0.009354631602764129, "policy_loss": -0.0010136442465922713, "dist_entropy": 0.7331613898277283, "actor_grad_norm": 0.11126971244812012, "critic_grad_norm": 0.08863160759210587, "ratio": 0.999882161617279, "entropy": 0.7331613898277283, "incre_win_rate": 0.8780487804878049, "step": 733}
{"time": 1767154803.134476, "phase": "train", "update": 734, "total_env_steps": 2348800, "episode_reward": 0.23265573382377625, "value_loss": 0.009664040990173817, "policy_loss": -0.001303187455984922, "dist_entropy": 0.7622530698776245, "actor_grad_norm": 0.11341949552297592, "critic_grad_norm": 0.04967372864484787, "ratio": 0.9996950030326843, "entropy": 0.7622530698776245, "incre_win_rate": 0.8205128205128205, "step": 734}
{"time": 1767154807.3922136, "phase": "train", "update": 735, "total_env_steps": 2352000, "episode_reward": 0.2336382269859314, "value_loss": 0.011459004692733287, "policy_loss": -0.0015058763462659109, "dist_entropy": 0.7726295471191407, "actor_grad_norm": 0.1084752306342125, "critic_grad_norm": 0.09904218465089798, "ratio": 1.0001667737960815, "entropy": 0.7726295471191407, "incre_win_rate": 0.8205128205128205, "step": 735}
{"time": 1767154811.6696942, "phase": "train", "update": 736, "total_env_steps": 2355200, "episode_reward": 0.2344324290752411, "value_loss": 0.010130430199205875, "policy_loss": -0.000913808611977629, "dist_entropy": 0.7799895763397217, "actor_grad_norm": 0.09988921135663986, "critic_grad_norm": 0.0976448506116867, "ratio": 1.0001213550567627, "entropy": 0.7799895763397217, "incre_win_rate": 0.8292682926829268, "step": 736}
{"time": 1767154815.9428785, "phase": "train", "update": 737, "total_env_steps": 2358400, "episode_reward": 0.21987996995449066, "value_loss": 0.011714601144194602, "policy_loss": -0.0010691168562139807, "dist_entropy": 0.7573521733283997, "actor_grad_norm": 0.10215183347463608, "critic_grad_norm": 0.2520517110824585, "ratio": 0.9998148083686829, "entropy": 0.7573521733283997, "incre_win_rate": 0.6756756756756757, "step": 737}
{"time": 1767154820.2729092, "phase": "train", "update": 738, "total_env_steps": 2361600, "episode_reward": 0.2309064418077469, "value_loss": 0.010022921487689018, "policy_loss": -0.0011369715510339163, "dist_entropy": 0.7630343675613404, "actor_grad_norm": 0.1059575080871582, "critic_grad_norm": 0.17273291945457458, "ratio": 0.9998135566711426, "entropy": 0.7630343675613404, "incre_win_rate": 0.775, "step": 738}
{"time": 1767154824.567934, "phase": "train", "update": 739, "total_env_steps": 2364800, "episode_reward": 0.2283216118812561, "value_loss": 0.013654238544404507, "policy_loss": -0.0013981417839872279, "dist_entropy": 0.745817506313324, "actor_grad_norm": 0.10623536258935928, "critic_grad_norm": 0.11556625366210938, "ratio": 0.9998708963394165, "entropy": 0.745817506313324, "incre_win_rate": 0.7692307692307693, "step": 739}
{"time": 1767154829.0853455, "phase": "train", "update": 740, "total_env_steps": 2368000, "episode_reward": 0.22719423472881317, "value_loss": 0.008828948810696602, "policy_loss": -0.0007378222505153076, "dist_entropy": 0.7555274128913879, "actor_grad_norm": 0.10917022079229355, "critic_grad_norm": 0.10102266073226929, "ratio": 0.9998353123664856, "entropy": 0.7555274128913879, "incre_win_rate": 0.7948717948717948, "step": 740}
{"time": 1767154833.408411, "phase": "train", "update": 741, "total_env_steps": 2371200, "episode_reward": 0.23051324486732483, "value_loss": 0.009596925415098666, "policy_loss": -0.001366331016253497, "dist_entropy": 0.7633853197097779, "actor_grad_norm": 0.13972815871238708, "critic_grad_norm": 0.08019066601991653, "ratio": 1.00016450881958, "entropy": 0.7633853197097779, "incre_win_rate": 0.775, "step": 741}
{"time": 1767154844.7283323, "phase": "eval", "update": 741, "total_env_steps": 2371200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.412458609271525, "step": 741}
{"time": 1767154849.0326622, "phase": "train", "update": 742, "total_env_steps": 2374400, "episode_reward": 0.22927358746528625, "value_loss": 0.01249690931290388, "policy_loss": -0.0013468587921551035, "dist_entropy": 0.778203284740448, "actor_grad_norm": 0.08675599843263626, "critic_grad_norm": 0.14364294707775116, "ratio": 0.9999054074287415, "entropy": 0.778203284740448, "incre_win_rate": 0.7837837837837838, "step": 742}
{"time": 1767154853.339999, "phase": "train", "update": 743, "total_env_steps": 2377600, "episode_reward": 0.23704677820205688, "value_loss": 0.00963293481618166, "policy_loss": -0.0016604490339393152, "dist_entropy": 0.7759466409683228, "actor_grad_norm": 0.12280582636594772, "critic_grad_norm": 0.1321268081665039, "ratio": 0.9999715089797974, "entropy": 0.7759466409683228, "incre_win_rate": 0.8974358974358975, "step": 743}
{"time": 1767154857.6262796, "phase": "train", "update": 744, "total_env_steps": 2380800, "episode_reward": 0.24710886180400848, "value_loss": 0.005231696274131536, "policy_loss": -0.0010285727986165227, "dist_entropy": 0.769886827468872, "actor_grad_norm": 0.0973081886768341, "critic_grad_norm": 0.1922122836112976, "ratio": 0.9999544024467468, "entropy": 0.769886827468872, "incre_win_rate": 0.975609756097561, "step": 744}
{"time": 1767154861.9160762, "phase": "train", "update": 745, "total_env_steps": 2384000, "episode_reward": 0.22521160542964935, "value_loss": 0.008704833686351776, "policy_loss": -0.0013773705624899435, "dist_entropy": 0.7579308390617371, "actor_grad_norm": 0.11205388605594635, "critic_grad_norm": 0.08455942571163177, "ratio": 0.9998247027397156, "entropy": 0.7579308390617371, "incre_win_rate": 0.8648648648648649, "step": 745}
{"time": 1767154866.2006884, "phase": "train", "update": 746, "total_env_steps": 2387200, "episode_reward": 0.23687759041786194, "value_loss": 0.00842980518937111, "policy_loss": -0.0013753856724385116, "dist_entropy": 0.7514654278755188, "actor_grad_norm": 0.09126889705657959, "critic_grad_norm": 0.06131448969244957, "ratio": 1.000090479850769, "entropy": 0.7514654278755188, "incre_win_rate": 0.8717948717948718, "step": 746}
{"time": 1767154870.4928653, "phase": "train", "update": 747, "total_env_steps": 2390400, "episode_reward": 0.24270282685756683, "value_loss": 0.008937130495905877, "policy_loss": -0.0015519088296780837, "dist_entropy": 0.7480732798576355, "actor_grad_norm": 0.0908614918589592, "critic_grad_norm": 0.06411203742027283, "ratio": 1.0001524686813354, "entropy": 0.7480732798576355, "incre_win_rate": 0.875, "step": 747}
{"time": 1767154874.8145254, "phase": "train", "update": 748, "total_env_steps": 2393600, "episode_reward": 0.23397505283355713, "value_loss": 0.008929671719670296, "policy_loss": -0.0013287192692608585, "dist_entropy": 0.7385259389877319, "actor_grad_norm": 0.09540022909641266, "critic_grad_norm": 0.14855651557445526, "ratio": 1.0001243352890015, "entropy": 0.7385259389877319, "incre_win_rate": 0.7948717948717948, "step": 748}
{"time": 1767154879.1332803, "phase": "train", "update": 749, "total_env_steps": 2396800, "episode_reward": 0.23788751661777496, "value_loss": 0.010004534572362899, "policy_loss": -0.0013294371070792011, "dist_entropy": 0.7277186751365662, "actor_grad_norm": 0.10903996229171753, "critic_grad_norm": 0.14374814927577972, "ratio": 0.999595582485199, "entropy": 0.7277186751365662, "incre_win_rate": 0.8292682926829268, "step": 749}
{"time": 1767154883.4703517, "phase": "train", "update": 750, "total_env_steps": 2400000, "episode_reward": 0.24737271666526794, "value_loss": 0.005932703334838152, "policy_loss": -0.001158804492111898, "dist_entropy": 0.7380531191825866, "actor_grad_norm": 0.10976433753967285, "critic_grad_norm": 0.11792361736297607, "ratio": 1.000052809715271, "entropy": 0.7380531191825866, "incre_win_rate": 0.95, "step": 750}
{"time": 1767154887.7867615, "phase": "train", "update": 751, "total_env_steps": 2403200, "episode_reward": 0.23647712171077728, "value_loss": 0.009639570489525795, "policy_loss": -0.0015493668841744634, "dist_entropy": 0.7321788430213928, "actor_grad_norm": 0.09778416901826859, "critic_grad_norm": 0.08507777750492096, "ratio": 0.9999303817749023, "entropy": 0.7321788430213928, "incre_win_rate": 0.85, "step": 751}
{"time": 1767154892.1089237, "phase": "train", "update": 752, "total_env_steps": 2406400, "episode_reward": 0.25010916590690613, "value_loss": 0.008239599969238042, "policy_loss": -0.001430995832807014, "dist_entropy": 0.7129217982292175, "actor_grad_norm": 0.12530744075775146, "critic_grad_norm": 0.1618977040052414, "ratio": 1.000287413597107, "entropy": 0.7129217982292175, "incre_win_rate": 0.8780487804878049, "step": 752}
{"time": 1767154896.3821225, "phase": "train", "update": 753, "total_env_steps": 2409600, "episode_reward": 0.24315035343170166, "value_loss": 0.007576388772577047, "policy_loss": -0.0012448146972580787, "dist_entropy": 0.7179579377174378, "actor_grad_norm": 0.07436883449554443, "critic_grad_norm": 0.12564317882061005, "ratio": 0.9999311566352844, "entropy": 0.7179579377174378, "incre_win_rate": 0.9, "step": 753}
{"time": 1767154900.6624687, "phase": "train", "update": 754, "total_env_steps": 2412800, "episode_reward": 0.23478271067142487, "value_loss": 0.006854301318526268, "policy_loss": -0.0014212931818339935, "dist_entropy": 0.7310766458511353, "actor_grad_norm": 0.10108474642038345, "critic_grad_norm": 0.09957979619503021, "ratio": 0.9995256662368774, "entropy": 0.7310766458511353, "incre_win_rate": 0.8461538461538461, "step": 754}
{"time": 1767154905.0218956, "phase": "train", "update": 755, "total_env_steps": 2416000, "episode_reward": 0.24918875098228455, "value_loss": 0.007246950920671224, "policy_loss": -0.0010225183217542622, "dist_entropy": 0.7309697866439819, "actor_grad_norm": 0.11942774057388306, "critic_grad_norm": 0.0635313019156456, "ratio": 0.9998882412910461, "entropy": 0.7309697866439819, "incre_win_rate": 0.9, "step": 755}
{"time": 1767154909.323701, "phase": "train", "update": 756, "total_env_steps": 2419200, "episode_reward": 0.2403218150138855, "value_loss": 0.008101726323366166, "policy_loss": -0.0012114692822507323, "dist_entropy": 0.7416401267051697, "actor_grad_norm": 0.12802660465240479, "critic_grad_norm": 0.06109393388032913, "ratio": 0.9999553561210632, "entropy": 0.7416401267051697, "incre_win_rate": 0.875, "step": 756}
{"time": 1767154913.621474, "phase": "train", "update": 757, "total_env_steps": 2422400, "episode_reward": 0.24483650922775269, "value_loss": 0.006237019412219524, "policy_loss": -0.0012743641563858431, "dist_entropy": 0.7171777844429016, "actor_grad_norm": 0.08526882529258728, "critic_grad_norm": 0.1350243240594864, "ratio": 0.9996859431266785, "entropy": 0.7171777844429016, "incre_win_rate": 0.875, "step": 757}
{"time": 1767154917.9120347, "phase": "train", "update": 758, "total_env_steps": 2425600, "episode_reward": 0.25293874740600586, "value_loss": 0.005236450303345919, "policy_loss": -0.001033526956148023, "dist_entropy": 0.7443384528160095, "actor_grad_norm": 0.10234446823596954, "critic_grad_norm": 0.11162390559911728, "ratio": 1.0001333951950073, "entropy": 0.7443384528160095, "incre_win_rate": 0.9512195121951219, "step": 758}
{"time": 1767154922.232696, "phase": "train", "update": 759, "total_env_steps": 2428800, "episode_reward": 0.24238722026348114, "value_loss": 0.006251118890941143, "policy_loss": -0.0013329351852206627, "dist_entropy": 0.7207268357276917, "actor_grad_norm": 0.10372567176818848, "critic_grad_norm": 0.12606045603752136, "ratio": 0.9999334216117859, "entropy": 0.7207268357276917, "incre_win_rate": 0.8536585365853658, "step": 759}
{"time": 1767154926.554597, "phase": "train", "update": 760, "total_env_steps": 2432000, "episode_reward": 0.24788236618041992, "value_loss": 0.007069510500878095, "policy_loss": -0.001076228186584416, "dist_entropy": 0.7463887929916382, "actor_grad_norm": 0.0926128700375557, "critic_grad_norm": 0.1501869410276413, "ratio": 0.9998383522033691, "entropy": 0.7463887929916382, "incre_win_rate": 0.8780487804878049, "step": 760}
{"time": 1767154930.8704586, "phase": "train", "update": 761, "total_env_steps": 2435200, "episode_reward": 0.2431870847940445, "value_loss": 0.009837999381124974, "policy_loss": -0.0009530887635364138, "dist_entropy": 0.7165932536125184, "actor_grad_norm": 0.08648736774921417, "critic_grad_norm": 0.11084449291229248, "ratio": 0.9996086359024048, "entropy": 0.7165932536125184, "incre_win_rate": 0.9024390243902439, "step": 761}
{"time": 1767154942.314319, "phase": "eval", "update": 761, "total_env_steps": 2435200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.65976821192053, "step": 761}
{"time": 1767154946.5917852, "phase": "train", "update": 762, "total_env_steps": 2438400, "episode_reward": 0.24122104048728943, "value_loss": 0.006622639112174511, "policy_loss": -0.0012676821638347492, "dist_entropy": 0.7361176371574402, "actor_grad_norm": 0.12314126640558243, "critic_grad_norm": 0.11860539764165878, "ratio": 1.000060796737671, "entropy": 0.7361176371574402, "incre_win_rate": 0.9, "step": 762}
{"time": 1767154950.9006507, "phase": "train", "update": 763, "total_env_steps": 2441600, "episode_reward": 0.249301016330719, "value_loss": 0.006202867068350315, "policy_loss": -0.0011337406443118424, "dist_entropy": 0.7396757125854492, "actor_grad_norm": 0.09232290089130402, "critic_grad_norm": 0.11839637905359268, "ratio": 0.999727189540863, "entropy": 0.7396757125854492, "incre_win_rate": 0.9, "step": 763}
{"time": 1767154955.1664507, "phase": "train", "update": 764, "total_env_steps": 2444800, "episode_reward": 0.24601823091506958, "value_loss": 0.008475873991847039, "policy_loss": -0.0012439960025439234, "dist_entropy": 0.7593734860420227, "actor_grad_norm": 0.1043274998664856, "critic_grad_norm": 0.08817002177238464, "ratio": 1.0001200437545776, "entropy": 0.7593734860420227, "incre_win_rate": 0.8974358974358975, "step": 764}
{"time": 1767154959.4730914, "phase": "train", "update": 765, "total_env_steps": 2448000, "episode_reward": 0.2403559535741806, "value_loss": 0.008923883736133575, "policy_loss": -0.0014073839272938926, "dist_entropy": 0.7426573276519776, "actor_grad_norm": 0.11104823648929596, "critic_grad_norm": 0.2541106343269348, "ratio": 0.9997299313545227, "entropy": 0.7426573276519776, "incre_win_rate": 0.8292682926829268, "step": 765}
{"time": 1767154963.7938037, "phase": "train", "update": 766, "total_env_steps": 2451200, "episode_reward": 0.2364688664674759, "value_loss": 0.013777653127908707, "policy_loss": -0.001046921935384404, "dist_entropy": 0.7225368976593017, "actor_grad_norm": 0.11885656416416168, "critic_grad_norm": 0.15672750771045685, "ratio": 0.9998370409011841, "entropy": 0.7225368976593017, "incre_win_rate": 0.7857142857142857, "step": 766}
{"time": 1767154968.0742676, "phase": "train", "update": 767, "total_env_steps": 2454400, "episode_reward": 0.2317529171705246, "value_loss": 0.010422204062342644, "policy_loss": -0.001128789265299801, "dist_entropy": 0.7203220248222351, "actor_grad_norm": 0.1170177087187767, "critic_grad_norm": 0.115951769053936, "ratio": 0.9998888969421387, "entropy": 0.7203220248222351, "incre_win_rate": 0.8205128205128205, "step": 767}
{"time": 1767154972.3606653, "phase": "train", "update": 768, "total_env_steps": 2457600, "episode_reward": 0.23686672747135162, "value_loss": 0.010573472082614898, "policy_loss": -0.0011602704059413328, "dist_entropy": 0.7438146591186523, "actor_grad_norm": 0.08586325496435165, "critic_grad_norm": 0.1353221982717514, "ratio": 1.0003442764282227, "entropy": 0.7438146591186523, "incre_win_rate": 0.8, "step": 768}
{"time": 1767154976.696891, "phase": "train", "update": 769, "total_env_steps": 2460800, "episode_reward": 0.2489776462316513, "value_loss": 0.007517935056239366, "policy_loss": -0.001078861610079862, "dist_entropy": 0.7343228578567504, "actor_grad_norm": 0.07702421396970749, "critic_grad_norm": 0.06030765920877457, "ratio": 1.000133752822876, "entropy": 0.7343228578567504, "incre_win_rate": 0.9, "step": 769}
{"time": 1767154980.9847126, "phase": "train", "update": 770, "total_env_steps": 2464000, "episode_reward": 0.24640364944934845, "value_loss": 0.005663986038416624, "policy_loss": -0.0015213330329331143, "dist_entropy": 0.7067865848541259, "actor_grad_norm": 0.10536497831344604, "critic_grad_norm": 0.07411809265613556, "ratio": 0.9995738863945007, "entropy": 0.7067865848541259, "incre_win_rate": 0.9230769230769231, "step": 770}
{"time": 1767154985.348727, "phase": "train", "update": 771, "total_env_steps": 2467200, "episode_reward": 0.24807533621788025, "value_loss": 0.007029562070965767, "policy_loss": -0.001078565844433399, "dist_entropy": 0.7109417796134949, "actor_grad_norm": 0.10352843254804611, "critic_grad_norm": 0.05125581845641136, "ratio": 0.9998709559440613, "entropy": 0.7109417796134949, "incre_win_rate": 0.8809523809523809, "step": 771}
{"time": 1767154989.6408792, "phase": "train", "update": 772, "total_env_steps": 2470400, "episode_reward": 0.2460099458694458, "value_loss": 0.007613432686775922, "policy_loss": -0.000779716393282115, "dist_entropy": 0.7087080121040344, "actor_grad_norm": 0.10024209320545197, "critic_grad_norm": 0.07838929444551468, "ratio": 0.9996458888053894, "entropy": 0.7087080121040344, "incre_win_rate": 0.8780487804878049, "step": 772}
{"time": 1767154993.9268377, "phase": "train", "update": 773, "total_env_steps": 2473600, "episode_reward": 0.2515004277229309, "value_loss": 0.008058621548116207, "policy_loss": -0.0012459562824268743, "dist_entropy": 0.7047266840934754, "actor_grad_norm": 0.10666310787200928, "critic_grad_norm": 0.06160982325673103, "ratio": 0.9999086260795593, "entropy": 0.7047266840934754, "incre_win_rate": 0.9, "step": 773}
{"time": 1767154998.232734, "phase": "train", "update": 774, "total_env_steps": 2476800, "episode_reward": 0.24801738560199738, "value_loss": 0.009304300509393215, "policy_loss": -0.0013316443953087288, "dist_entropy": 0.7069432377815247, "actor_grad_norm": 0.11642525345087051, "critic_grad_norm": 0.1119464635848999, "ratio": 0.9999982118606567, "entropy": 0.7069432377815247, "incre_win_rate": 0.9069767441860465, "step": 774}
{"time": 1767155002.5182202, "phase": "train", "update": 775, "total_env_steps": 2480000, "episode_reward": 0.2379164844751358, "value_loss": 0.011350735649466514, "policy_loss": -0.0013676378314553261, "dist_entropy": 0.7086296677589417, "actor_grad_norm": 0.0993124321103096, "critic_grad_norm": 0.09336008131504059, "ratio": 0.999722957611084, "entropy": 0.7086296677589417, "incre_win_rate": 0.85, "step": 775}
{"time": 1767155006.8283722, "phase": "train", "update": 776, "total_env_steps": 2483200, "episode_reward": 0.24179480969905853, "value_loss": 0.007301211357116699, "policy_loss": -0.001208586281993007, "dist_entropy": 0.7144231081008912, "actor_grad_norm": 0.0861341580748558, "critic_grad_norm": 0.13448594510555267, "ratio": 1.0000232458114624, "entropy": 0.7144231081008912, "incre_win_rate": 0.8974358974358975, "step": 776}
{"time": 1767155011.096564, "phase": "train", "update": 777, "total_env_steps": 2486400, "episode_reward": 0.23581847548484802, "value_loss": 0.010469076968729497, "policy_loss": -0.0011474554523566382, "dist_entropy": 0.7112962603569031, "actor_grad_norm": 0.11753188818693161, "critic_grad_norm": 0.14688831567764282, "ratio": 1.0001190900802612, "entropy": 0.7112962603569031, "incre_win_rate": 0.775, "step": 777}
{"time": 1767155015.404733, "phase": "train", "update": 778, "total_env_steps": 2489600, "episode_reward": 0.23978425562381744, "value_loss": 0.01029782835394144, "policy_loss": -0.001295087350835189, "dist_entropy": 0.7121492266654968, "actor_grad_norm": 0.10844554752111435, "critic_grad_norm": 0.20839571952819824, "ratio": 0.9997830390930176, "entropy": 0.7121492266654968, "incre_win_rate": 0.85, "step": 778}
{"time": 1767155020.3075995, "phase": "train", "update": 779, "total_env_steps": 2492800, "episode_reward": 0.24512208998203278, "value_loss": 0.008542427979409694, "policy_loss": -0.001060455929393811, "dist_entropy": 0.6981508016586304, "actor_grad_norm": 0.09062235802412033, "critic_grad_norm": 0.17066286504268646, "ratio": 0.999768853187561, "entropy": 0.6981508016586304, "incre_win_rate": 0.85, "step": 779}
{"time": 1767155024.8429973, "phase": "train", "update": 780, "total_env_steps": 2496000, "episode_reward": 0.2409680336713791, "value_loss": 0.009479391761124134, "policy_loss": -0.0010232073268895193, "dist_entropy": 0.6725805759429931, "actor_grad_norm": 0.08348410576581955, "critic_grad_norm": 0.12250639498233795, "ratio": 0.9998862147331238, "entropy": 0.6725805759429931, "incre_win_rate": 0.9024390243902439, "step": 780}
{"time": 1767155029.11656, "phase": "train", "update": 781, "total_env_steps": 2499200, "episode_reward": 0.22386279702186584, "value_loss": 0.012442611902952195, "policy_loss": -0.001553642887196105, "dist_entropy": 0.6782698631286621, "actor_grad_norm": 0.1234288215637207, "critic_grad_norm": 0.19381371140480042, "ratio": 0.9997071623802185, "entropy": 0.6782698631286621, "incre_win_rate": 0.7, "step": 781}
{"time": 1767155040.6907094, "phase": "eval", "update": 781, "total_env_steps": 2499200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.72407905629139, "step": 781}
{"time": 1767155045.0884128, "phase": "train", "update": 782, "total_env_steps": 2502400, "episode_reward": 0.25639280676841736, "value_loss": 0.006047350354492664, "policy_loss": -0.0010798291542784, "dist_entropy": 0.6809227347373963, "actor_grad_norm": 0.11075102537870407, "critic_grad_norm": 0.2661372125148773, "ratio": 0.9999091029167175, "entropy": 0.6809227347373963, "incre_win_rate": 0.95, "step": 782}
{"time": 1767155049.3796988, "phase": "train", "update": 783, "total_env_steps": 2505600, "episode_reward": 0.24844732880592346, "value_loss": 0.007815331965684891, "policy_loss": -0.0013290857898269337, "dist_entropy": 0.6724287986755371, "actor_grad_norm": 0.10676949471235275, "critic_grad_norm": 0.1891300529241562, "ratio": 1.0000818967819214, "entropy": 0.6724287986755371, "incre_win_rate": 0.9, "step": 783}
{"time": 1767155053.698636, "phase": "train", "update": 784, "total_env_steps": 2508800, "episode_reward": 0.24139951169490814, "value_loss": 0.005828770808875561, "policy_loss": -0.0014910396999715304, "dist_entropy": 0.6641084551811218, "actor_grad_norm": 0.0821974128484726, "critic_grad_norm": 0.12223950773477554, "ratio": 1.0003286600112915, "entropy": 0.6641084551811218, "incre_win_rate": 0.9024390243902439, "step": 784}
{"time": 1767155057.988744, "phase": "train", "update": 785, "total_env_steps": 2512000, "episode_reward": 0.24581332504749298, "value_loss": 0.006900034286081791, "policy_loss": -0.0009634532958337161, "dist_entropy": 0.6721800446510315, "actor_grad_norm": 0.08234753459692001, "critic_grad_norm": 0.15994349122047424, "ratio": 0.9996111989021301, "entropy": 0.6721800446510315, "incre_win_rate": 0.85, "step": 785}
{"time": 1767155062.3219528, "phase": "train", "update": 786, "total_env_steps": 2515200, "episode_reward": 0.24514847993850708, "value_loss": 0.011370138823986053, "policy_loss": -0.0011713629196371755, "dist_entropy": 0.673278295993805, "actor_grad_norm": 0.09901472181081772, "critic_grad_norm": 0.17319782078266144, "ratio": 1.0001976490020752, "entropy": 0.673278295993805, "incre_win_rate": 0.8571428571428571, "step": 786}
{"time": 1767155066.6421652, "phase": "train", "update": 787, "total_env_steps": 2518400, "episode_reward": 0.25145697593688965, "value_loss": 0.009126592613756656, "policy_loss": -0.0007715089217427362, "dist_entropy": 0.6750859141349792, "actor_grad_norm": 0.10311082750558853, "critic_grad_norm": 0.09661556780338287, "ratio": 1.0000263452529907, "entropy": 0.6750859141349792, "incre_win_rate": 0.8780487804878049, "step": 787}
{"time": 1767155070.967026, "phase": "train", "update": 788, "total_env_steps": 2521600, "episode_reward": 0.2502690553665161, "value_loss": 0.007525403704494238, "policy_loss": -0.0012594516102602427, "dist_entropy": 0.6937807440757752, "actor_grad_norm": 0.10769665241241455, "critic_grad_norm": 0.10366387665271759, "ratio": 1.000309944152832, "entropy": 0.6937807440757752, "incre_win_rate": 0.925, "step": 788}
{"time": 1767155075.3041234, "phase": "train", "update": 789, "total_env_steps": 2524800, "episode_reward": 0.2572009563446045, "value_loss": 0.005315326154232025, "policy_loss": -0.001235467989210548, "dist_entropy": 0.6953084707260132, "actor_grad_norm": 0.0998326763510704, "critic_grad_norm": 0.03924281895160675, "ratio": 0.9999794960021973, "entropy": 0.6953084707260132, "incre_win_rate": 0.9534883720930233, "step": 789}
{"time": 1767155079.6308708, "phase": "train", "update": 790, "total_env_steps": 2528000, "episode_reward": 0.24891506135463715, "value_loss": 0.007737234886735678, "policy_loss": -0.0009305595037176317, "dist_entropy": 0.7220428109169006, "actor_grad_norm": 0.10169859230518341, "critic_grad_norm": 0.05719456821680069, "ratio": 0.9999393820762634, "entropy": 0.7220428109169006, "incre_win_rate": 0.9512195121951219, "step": 790}
{"time": 1767155083.9535267, "phase": "train", "update": 791, "total_env_steps": 2531200, "episode_reward": 0.2457823008298874, "value_loss": 0.007921458315104246, "policy_loss": -0.0011979816493660421, "dist_entropy": 0.7360704779624939, "actor_grad_norm": 0.09604497998952866, "critic_grad_norm": 0.06501362472772598, "ratio": 0.9999588131904602, "entropy": 0.7360704779624939, "incre_win_rate": 0.8780487804878049, "step": 791}
{"time": 1767155088.3136086, "phase": "train", "update": 792, "total_env_steps": 2534400, "episode_reward": 0.25473201274871826, "value_loss": 0.004325382877141237, "policy_loss": -0.0010422331089586124, "dist_entropy": 0.7250993847846985, "actor_grad_norm": 0.12204194068908691, "critic_grad_norm": 0.13014470040798187, "ratio": 1.000165343284607, "entropy": 0.7250993847846985, "incre_win_rate": 0.9512195121951219, "step": 792}
{"time": 1767155092.582524, "phase": "train", "update": 793, "total_env_steps": 2537600, "episode_reward": 0.23935842514038086, "value_loss": 0.008832465671002866, "policy_loss": -0.0015906239058967487, "dist_entropy": 0.7232232809066772, "actor_grad_norm": 0.14406464993953705, "critic_grad_norm": 0.19346831738948822, "ratio": 0.9994959235191345, "entropy": 0.7232232809066772, "incre_win_rate": 0.8421052631578947, "step": 793}
{"time": 1767155096.8641686, "phase": "train", "update": 794, "total_env_steps": 2540800, "episode_reward": 0.2505505084991455, "value_loss": 0.008857344649732113, "policy_loss": -0.0009320463768318632, "dist_entropy": 0.724531602859497, "actor_grad_norm": 0.11060954630374908, "critic_grad_norm": 0.11562591791152954, "ratio": 1.0001853704452515, "entropy": 0.724531602859497, "incre_win_rate": 0.8863636363636364, "step": 794}
{"time": 1767155101.1748195, "phase": "train", "update": 795, "total_env_steps": 2544000, "episode_reward": 0.2397061139345169, "value_loss": 0.011062720976769923, "policy_loss": -0.0008003714152955866, "dist_entropy": 0.7094802379608154, "actor_grad_norm": 0.0903996080160141, "critic_grad_norm": 0.08425817638635635, "ratio": 0.9997891783714294, "entropy": 0.7094802379608154, "incre_win_rate": 0.7692307692307693, "step": 795}
{"time": 1767155105.5093215, "phase": "train", "update": 796, "total_env_steps": 2547200, "episode_reward": 0.24715232849121094, "value_loss": 0.009236640110611916, "policy_loss": -0.0014651334225021628, "dist_entropy": 0.7178518414497376, "actor_grad_norm": 0.11824282258749008, "critic_grad_norm": 0.11642970889806747, "ratio": 1.000357985496521, "entropy": 0.7178518414497376, "incre_win_rate": 0.8809523809523809, "step": 796}
{"time": 1767155109.8430471, "phase": "train", "update": 797, "total_env_steps": 2550400, "episode_reward": 0.2448018491268158, "value_loss": 0.013275732286274433, "policy_loss": -0.0012933575763952377, "dist_entropy": 0.7058418393135071, "actor_grad_norm": 0.12648726999759674, "critic_grad_norm": 0.11205915361642838, "ratio": 1.0001064538955688, "entropy": 0.7058418393135071, "incre_win_rate": 0.825, "step": 797}
{"time": 1767155114.1526768, "phase": "train", "update": 798, "total_env_steps": 2553600, "episode_reward": 0.25123345851898193, "value_loss": 0.008673147670924664, "policy_loss": -0.0011156471621349695, "dist_entropy": 0.6961801528930665, "actor_grad_norm": 0.09535317867994308, "critic_grad_norm": 0.13009881973266602, "ratio": 0.9999669194221497, "entropy": 0.6961801528930665, "incre_win_rate": 0.9069767441860465, "step": 798}
{"time": 1767155118.43332, "phase": "train", "update": 799, "total_env_steps": 2556800, "episode_reward": 0.24492447078227997, "value_loss": 0.009984108060598374, "policy_loss": -0.0011409586344711896, "dist_entropy": 0.69407958984375, "actor_grad_norm": 0.08810754865407944, "critic_grad_norm": 0.14059795439243317, "ratio": 0.999820351600647, "entropy": 0.69407958984375, "incre_win_rate": 0.926829268292683, "step": 799}
{"time": 1767155122.7018158, "phase": "train", "update": 800, "total_env_steps": 2560000, "episode_reward": 0.24510347843170166, "value_loss": 0.011753462068736554, "policy_loss": -0.0010990598839910604, "dist_entropy": 0.7033432722091675, "actor_grad_norm": 0.1549033224582672, "critic_grad_norm": 0.1438629925251007, "ratio": 0.9998605847358704, "entropy": 0.7033432722091675, "incre_win_rate": 0.8536585365853658, "step": 800}
{"time": 1767155126.9991589, "phase": "train", "update": 801, "total_env_steps": 2563200, "episode_reward": 0.24196140468120575, "value_loss": 0.006363926827907563, "policy_loss": -0.0011354821345172183, "dist_entropy": 0.7308420419692994, "actor_grad_norm": 0.07547727227210999, "critic_grad_norm": 0.12467443943023682, "ratio": 1.0001071691513062, "entropy": 0.7308420419692994, "incre_win_rate": 0.9210526315789473, "step": 801}
{"time": 1767155138.181606, "phase": "eval", "update": 801, "total_env_steps": 2563200, "eval_win_rate": 0.8125, "eval_episode_reward": 19.023903145695364, "step": 801}
{"time": 1767155142.4945083, "phase": "train", "update": 802, "total_env_steps": 2566400, "episode_reward": 0.2439693659543991, "value_loss": 0.006804022379219532, "policy_loss": -0.00112467892527377, "dist_entropy": 0.6970602512359619, "actor_grad_norm": 0.07549600303173065, "critic_grad_norm": 0.1201673150062561, "ratio": 0.9997731447219849, "entropy": 0.6970602512359619, "incre_win_rate": 0.925, "step": 802}
{"time": 1767155146.7741926, "phase": "train", "update": 803, "total_env_steps": 2569600, "episode_reward": 0.24862168729305267, "value_loss": 0.007108070701360702, "policy_loss": -0.0010281799402165781, "dist_entropy": 0.7242044448852539, "actor_grad_norm": 0.07358121126890182, "critic_grad_norm": 0.06356362998485565, "ratio": 1.0001780986785889, "entropy": 0.7242044448852539, "incre_win_rate": 0.875, "step": 803}
{"time": 1767155151.0481703, "phase": "train", "update": 804, "total_env_steps": 2572800, "episode_reward": 0.2330297976732254, "value_loss": 0.012164678424596786, "policy_loss": -0.0012990861487068629, "dist_entropy": 0.7146971583366394, "actor_grad_norm": 0.09016433358192444, "critic_grad_norm": 0.21653147041797638, "ratio": 1.0001213550567627, "entropy": 0.7146971583366394, "incre_win_rate": 0.7857142857142857, "step": 804}
{"time": 1767155155.353232, "phase": "train", "update": 805, "total_env_steps": 2576000, "episode_reward": 0.25928807258605957, "value_loss": 0.006488686800003052, "policy_loss": -0.0014778543288937128, "dist_entropy": 0.7274794578552246, "actor_grad_norm": 0.10700317472219467, "critic_grad_norm": 0.15193305909633636, "ratio": 1.0001591444015503, "entropy": 0.7274794578552246, "incre_win_rate": 0.9523809523809523, "step": 805}
{"time": 1767155159.6567452, "phase": "train", "update": 806, "total_env_steps": 2579200, "episode_reward": 0.24054068326950073, "value_loss": 0.007931222300976514, "policy_loss": -0.0010804306823878561, "dist_entropy": 0.746362841129303, "actor_grad_norm": 0.08589919656515121, "critic_grad_norm": 0.21557782590389252, "ratio": 0.9999200105667114, "entropy": 0.746362841129303, "incre_win_rate": 0.8292682926829268, "step": 806}
{"time": 1767155163.9785113, "phase": "train", "update": 807, "total_env_steps": 2582400, "episode_reward": 0.24653249979019165, "value_loss": 0.01094607301056385, "policy_loss": -0.000979488661520378, "dist_entropy": 0.7193267822265625, "actor_grad_norm": 0.10292825847864151, "critic_grad_norm": 0.16197824478149414, "ratio": 0.9998109936714172, "entropy": 0.7193267822265625, "incre_win_rate": 0.85, "step": 807}
{"time": 1767155168.301727, "phase": "train", "update": 808, "total_env_steps": 2585600, "episode_reward": 0.2492968887090683, "value_loss": 0.004907351359724999, "policy_loss": -0.0016402759471539242, "dist_entropy": 0.7108886003494262, "actor_grad_norm": 0.1030440554022789, "critic_grad_norm": 0.12132088094949722, "ratio": 1.0000793933868408, "entropy": 0.7108886003494262, "incre_win_rate": 0.95, "step": 808}
{"time": 1767155172.6249468, "phase": "train", "update": 809, "total_env_steps": 2588800, "episode_reward": 0.25087645649909973, "value_loss": 0.00659569138661027, "policy_loss": -0.0011299713742396022, "dist_entropy": 0.7071323990821838, "actor_grad_norm": 0.1000857874751091, "critic_grad_norm": 0.08635186403989792, "ratio": 0.9995824098587036, "entropy": 0.7071323990821838, "incre_win_rate": 0.9047619047619048, "step": 809}
{"time": 1767155176.9521291, "phase": "train", "update": 810, "total_env_steps": 2592000, "episode_reward": 0.24478475749492645, "value_loss": 0.0061614993959665295, "policy_loss": -0.0010020064255208184, "dist_entropy": 0.6965137124061584, "actor_grad_norm": 0.08267325162887573, "critic_grad_norm": 0.057192541658878326, "ratio": 0.9999319314956665, "entropy": 0.6965137124061584, "incre_win_rate": 0.8780487804878049, "step": 810}
{"time": 1767155181.2495353, "phase": "train", "update": 811, "total_env_steps": 2595200, "episode_reward": 0.2518129050731659, "value_loss": 0.006624411512166262, "policy_loss": -0.001670119650277968, "dist_entropy": 0.6985580682754516, "actor_grad_norm": 0.09321728348731995, "critic_grad_norm": 0.05854655057191849, "ratio": 0.9999071359634399, "entropy": 0.6985580682754516, "incre_win_rate": 0.9024390243902439, "step": 811}
{"time": 1767155185.5437303, "phase": "train", "update": 812, "total_env_steps": 2598400, "episode_reward": 0.24189309775829315, "value_loss": 0.009435070678591728, "policy_loss": -0.001144102355465293, "dist_entropy": 0.7008883833885193, "actor_grad_norm": 0.10314059257507324, "critic_grad_norm": 0.11558963358402252, "ratio": 1.0001320838928223, "entropy": 0.7008883833885193, "incre_win_rate": 0.9230769230769231, "step": 812}
{"time": 1767155189.8306453, "phase": "train", "update": 813, "total_env_steps": 2601600, "episode_reward": 0.24219369888305664, "value_loss": 0.0066840977407991884, "policy_loss": -0.001134982217783609, "dist_entropy": 0.7027640223503113, "actor_grad_norm": 0.09176981449127197, "critic_grad_norm": 0.06740161776542664, "ratio": 1.0004099607467651, "entropy": 0.7027640223503113, "incre_win_rate": 0.85, "step": 813}
{"time": 1767155194.1247306, "phase": "train", "update": 814, "total_env_steps": 2604800, "episode_reward": 0.24015522003173828, "value_loss": 0.008194561488926411, "policy_loss": -0.0011535091970358736, "dist_entropy": 0.6856722950935363, "actor_grad_norm": 0.08644215017557144, "critic_grad_norm": 0.05721783638000488, "ratio": 1.0000020265579224, "entropy": 0.6856722950935363, "incre_win_rate": 0.8974358974358975, "step": 814}
{"time": 1767155198.4349034, "phase": "train", "update": 815, "total_env_steps": 2608000, "episode_reward": 0.2370954155921936, "value_loss": 0.006456411350518465, "policy_loss": -0.0011399947902063444, "dist_entropy": 0.675884735584259, "actor_grad_norm": 0.11851807683706284, "critic_grad_norm": 0.04671430215239525, "ratio": 0.999905526638031, "entropy": 0.675884735584259, "incre_win_rate": 0.9, "step": 815}
{"time": 1767155202.7139707, "phase": "train", "update": 816, "total_env_steps": 2611200, "episode_reward": 0.23948104679584503, "value_loss": 0.01071852631866932, "policy_loss": -0.0007256436052415438, "dist_entropy": 0.6729387402534485, "actor_grad_norm": 0.10142387449741364, "critic_grad_norm": 0.0828198716044426, "ratio": 1.000117301940918, "entropy": 0.6729387402534485, "incre_win_rate": 0.8571428571428571, "step": 816}
{"time": 1767155231.5985851, "phase": "train", "update": 817, "total_env_steps": 2614400, "episode_reward": 0.23389902710914612, "value_loss": 0.05657049864530563, "policy_loss": -0.0010348053438193005, "dist_entropy": 0.7138394713401794, "actor_grad_norm": 0.09802350401878357, "critic_grad_norm": 0.3335168957710266, "ratio": 1.000390887260437, "entropy": 0.7138394713401794, "incre_win_rate": 0.8888888888888888, "step": 817}
{"time": 1767155235.9219587, "phase": "train", "update": 818, "total_env_steps": 2617600, "episode_reward": 0.23561155796051025, "value_loss": 0.012674872390925884, "policy_loss": -0.0010638566411770966, "dist_entropy": 0.7222070932388306, "actor_grad_norm": 0.1112227663397789, "critic_grad_norm": 0.21181125938892365, "ratio": 0.9999378323554993, "entropy": 0.7222070932388306, "incre_win_rate": 0.7368421052631579, "step": 818}
{"time": 1767155240.3495407, "phase": "train", "update": 819, "total_env_steps": 2620800, "episode_reward": 0.24550499022006989, "value_loss": 0.010589702054858208, "policy_loss": -0.0012976108532051001, "dist_entropy": 0.7146316409111023, "actor_grad_norm": 0.13713712990283966, "critic_grad_norm": 0.23107950389385223, "ratio": 0.9996728897094727, "entropy": 0.7146316409111023, "incre_win_rate": 0.8536585365853658, "step": 819}
{"time": 1767155244.692844, "phase": "train", "update": 820, "total_env_steps": 2624000, "episode_reward": 0.23273643851280212, "value_loss": 0.012007773853838444, "policy_loss": -0.0009170963402738153, "dist_entropy": 0.7278799891471863, "actor_grad_norm": 0.08642062544822693, "critic_grad_norm": 0.13431236147880554, "ratio": 1.0001006126403809, "entropy": 0.7278799891471863, "incre_win_rate": 0.7619047619047619, "step": 820}
{"time": 1767155248.9235678, "phase": "train", "update": 821, "total_env_steps": 2627200, "episode_reward": 0.23175911605358124, "value_loss": 0.010109314136207104, "policy_loss": -0.0013110805410461168, "dist_entropy": 0.7226230144500733, "actor_grad_norm": 0.10936713218688965, "critic_grad_norm": 0.1435370147228241, "ratio": 1.0002778768539429, "entropy": 0.7226230144500733, "incre_win_rate": 0.7837837837837838, "step": 821}
{"time": 1767155261.480879, "phase": "eval", "update": 821, "total_env_steps": 2627200, "eval_win_rate": 0.84375, "eval_episode_reward": 19.435689155629138, "step": 821}
{"time": 1767155265.78145, "phase": "train", "update": 822, "total_env_steps": 2630400, "episode_reward": 0.24140159785747528, "value_loss": 0.010006435960531235, "policy_loss": -0.0015066068126220245, "dist_entropy": 0.7189336657524109, "actor_grad_norm": 0.11563616245985031, "critic_grad_norm": 0.16666080057621002, "ratio": 0.9998747110366821, "entropy": 0.7189336657524109, "incre_win_rate": 0.8604651162790697, "step": 822}
{"time": 1767155270.0724006, "phase": "train", "update": 823, "total_env_steps": 2633600, "episode_reward": 0.23802980780601501, "value_loss": 0.00844030436128378, "policy_loss": -0.0013354383431689598, "dist_entropy": 0.7123770713806152, "actor_grad_norm": 0.10645463317632675, "critic_grad_norm": 0.06171827390789986, "ratio": 1.000179409980774, "entropy": 0.7123770713806152, "incre_win_rate": 0.8461538461538461, "step": 823}
{"time": 1767155274.3319535, "phase": "train", "update": 824, "total_env_steps": 2636800, "episode_reward": 0.23299255967140198, "value_loss": 0.008588245138525963, "policy_loss": -0.0010325622217813191, "dist_entropy": 0.6707889080047608, "actor_grad_norm": 0.08942633867263794, "critic_grad_norm": 0.05947798117995262, "ratio": 0.9998912811279297, "entropy": 0.6707889080047608, "incre_win_rate": 0.85, "step": 824}
{"time": 1767155278.5551796, "phase": "train", "update": 825, "total_env_steps": 2640000, "episode_reward": 0.24728992581367493, "value_loss": 0.007345548644661903, "policy_loss": -0.0008860758304578553, "dist_entropy": 0.6769128203392029, "actor_grad_norm": 0.10736610740423203, "critic_grad_norm": 0.10870075225830078, "ratio": 1.0002787113189697, "entropy": 0.6769128203392029, "incre_win_rate": 0.9512195121951219, "step": 825}
{"time": 1767155282.88945, "phase": "train", "update": 826, "total_env_steps": 2643200, "episode_reward": 0.22992081940174103, "value_loss": 0.010111388750374317, "policy_loss": -0.0015828637809624623, "dist_entropy": 0.6726189851760864, "actor_grad_norm": 0.10251553356647491, "critic_grad_norm": 0.19344083964824677, "ratio": 0.9998651742935181, "entropy": 0.6726189851760864, "incre_win_rate": 0.8421052631578947, "step": 826}
{"time": 1767155287.205396, "phase": "train", "update": 827, "total_env_steps": 2646400, "episode_reward": 0.24622930586338043, "value_loss": 0.017370620742440224, "policy_loss": -0.0006955878008177762, "dist_entropy": 0.6815820336341858, "actor_grad_norm": 0.1152501329779625, "critic_grad_norm": 0.133646160364151, "ratio": 0.9998556971549988, "entropy": 0.6815820336341858, "incre_win_rate": 0.8780487804878049, "step": 827}
{"time": 1767155291.5138605, "phase": "train", "update": 828, "total_env_steps": 2649600, "episode_reward": 0.245600163936615, "value_loss": 0.0077975763939321045, "policy_loss": -0.0013170798388998151, "dist_entropy": 0.6780288457870484, "actor_grad_norm": 0.10301516205072403, "critic_grad_norm": 0.15668781101703644, "ratio": 1.0004160404205322, "entropy": 0.6780288457870484, "incre_win_rate": 0.8974358974358975, "step": 828}
{"time": 1767155295.8264809, "phase": "train", "update": 829, "total_env_steps": 2652800, "episode_reward": 0.24797601997852325, "value_loss": 0.010194391943514347, "policy_loss": -0.0011676058278936806, "dist_entropy": 0.707689082622528, "actor_grad_norm": 0.09114970266819, "critic_grad_norm": 0.1332239955663681, "ratio": 1.0003511905670166, "entropy": 0.707689082622528, "incre_win_rate": 0.8536585365853658, "step": 829}
{"time": 1767155300.1310265, "phase": "train", "update": 830, "total_env_steps": 2656000, "episode_reward": 0.2380944788455963, "value_loss": 0.010020898655056953, "policy_loss": -0.0012166140010833714, "dist_entropy": 0.7112345814704895, "actor_grad_norm": 0.08033128082752228, "critic_grad_norm": 0.17969833314418793, "ratio": 0.9997444152832031, "entropy": 0.7112345814704895, "incre_win_rate": 0.825, "step": 830}
{"time": 1767155304.4354508, "phase": "train", "update": 831, "total_env_steps": 2659200, "episode_reward": 0.24777264893054962, "value_loss": 0.006889469362795353, "policy_loss": -0.001322501590473557, "dist_entropy": 0.7100576996803284, "actor_grad_norm": 0.09990641474723816, "critic_grad_norm": 0.0914631113409996, "ratio": 0.9998196959495544, "entropy": 0.7100576996803284, "incre_win_rate": 0.9024390243902439, "step": 831}
{"time": 1767155308.733185, "phase": "train", "update": 832, "total_env_steps": 2662400, "episode_reward": 0.23998554050922394, "value_loss": 0.010039321519434452, "policy_loss": -0.0014871098242863923, "dist_entropy": 0.734975004196167, "actor_grad_norm": 0.11030683666467667, "critic_grad_norm": 0.0680769830942154, "ratio": 0.9999208450317383, "entropy": 0.734975004196167, "incre_win_rate": 0.8461538461538461, "step": 832}
{"time": 1767155313.0307145, "phase": "train", "update": 833, "total_env_steps": 2665600, "episode_reward": 0.23758432269096375, "value_loss": 0.009110636450350285, "policy_loss": -0.0011333017259833155, "dist_entropy": 0.7380850434303283, "actor_grad_norm": 0.09048346430063248, "critic_grad_norm": 0.10960906744003296, "ratio": 1.0002228021621704, "entropy": 0.7380850434303283, "incre_win_rate": 0.7804878048780488, "step": 833}
{"time": 1767155317.3410478, "phase": "train", "update": 834, "total_env_steps": 2668800, "episode_reward": 0.2513860762119293, "value_loss": 0.006471190787851811, "policy_loss": -0.0009752441281918323, "dist_entropy": 0.7143716812133789, "actor_grad_norm": 0.07624059915542603, "critic_grad_norm": 0.10406520217657089, "ratio": 0.9999263882637024, "entropy": 0.7143716812133789, "incre_win_rate": 0.8636363636363636, "step": 834}
{"time": 1767155321.629975, "phase": "train", "update": 835, "total_env_steps": 2672000, "episode_reward": 0.24894869327545166, "value_loss": 0.007220517378300428, "policy_loss": -0.0010544852317323715, "dist_entropy": 0.7147745966911316, "actor_grad_norm": 0.09220033138990402, "critic_grad_norm": 0.13643066585063934, "ratio": 1.0004953145980835, "entropy": 0.7147745966911316, "incre_win_rate": 0.925, "step": 835}
{"time": 1767155325.9584634, "phase": "train", "update": 836, "total_env_steps": 2675200, "episode_reward": 0.2403746098279953, "value_loss": 0.011681109853088855, "policy_loss": -0.0013887210087801805, "dist_entropy": 0.7236057043075561, "actor_grad_norm": 0.12916560471057892, "critic_grad_norm": 0.22457356750965118, "ratio": 0.9994077682495117, "entropy": 0.7236057043075561, "incre_win_rate": 0.8974358974358975, "step": 836}
{"time": 1767155330.3246305, "phase": "train", "update": 837, "total_env_steps": 2678400, "episode_reward": 0.24230703711509705, "value_loss": 0.011960410512983799, "policy_loss": -0.0014353630025240704, "dist_entropy": 0.7213015556335449, "actor_grad_norm": 0.1053675189614296, "critic_grad_norm": 0.13169382512569427, "ratio": 1.000216007232666, "entropy": 0.7213015556335449, "incre_win_rate": 0.8421052631578947, "step": 837}
{"time": 1767155334.5871007, "phase": "train", "update": 838, "total_env_steps": 2681600, "episode_reward": 0.23028455674648285, "value_loss": 0.011705071479082108, "policy_loss": -0.0013690360935099122, "dist_entropy": 0.7317469596862793, "actor_grad_norm": 0.10671838372945786, "critic_grad_norm": 0.20331978797912598, "ratio": 0.9993416666984558, "entropy": 0.7317469596862793, "incre_win_rate": 0.8048780487804879, "step": 838}
{"time": 1767155338.9178898, "phase": "train", "update": 839, "total_env_steps": 2684800, "episode_reward": 0.24945363402366638, "value_loss": 0.011526233330368996, "policy_loss": -0.001275892461736916, "dist_entropy": 0.7521848797798156, "actor_grad_norm": 0.10906793922185898, "critic_grad_norm": 0.12421262264251709, "ratio": 1.0003613233566284, "entropy": 0.7521848797798156, "incre_win_rate": 0.8809523809523809, "step": 839}
{"time": 1767155343.2303793, "phase": "train", "update": 840, "total_env_steps": 2688000, "episode_reward": 0.23681601881980896, "value_loss": 0.011887861602008342, "policy_loss": -0.0010827052555756112, "dist_entropy": 0.7647142052650452, "actor_grad_norm": 0.1042785793542862, "critic_grad_norm": 0.17390476167201996, "ratio": 0.9998844265937805, "entropy": 0.7647142052650452, "incre_win_rate": 0.75, "step": 840}
{"time": 1767155347.5288703, "phase": "train", "update": 841, "total_env_steps": 2691200, "episode_reward": 0.24920687079429626, "value_loss": 0.008677546959370374, "policy_loss": -0.0016096806248550699, "dist_entropy": 0.7432418942451477, "actor_grad_norm": 0.1414867490530014, "critic_grad_norm": 0.16124267876148224, "ratio": 0.9998211860656738, "entropy": 0.7432418942451477, "incre_win_rate": 0.9047619047619048, "step": 841}
{"time": 1767155359.1080937, "phase": "eval", "update": 841, "total_env_steps": 2691200, "eval_win_rate": 0.8125, "eval_episode_reward": 18.96445571192053, "step": 841}
{"time": 1767155363.444423, "phase": "train", "update": 842, "total_env_steps": 2694400, "episode_reward": 0.23692001402378082, "value_loss": 0.011252595670521259, "policy_loss": -0.0012858129167973686, "dist_entropy": 0.7487391352653503, "actor_grad_norm": 0.11293255537748337, "critic_grad_norm": 0.17043666541576385, "ratio": 1.0000003576278687, "entropy": 0.7487391352653503, "incre_win_rate": 0.7804878048780488, "step": 842}
{"time": 1767155367.7684324, "phase": "train", "update": 843, "total_env_steps": 2697600, "episode_reward": 0.25026386976242065, "value_loss": 0.007852073293179274, "policy_loss": -0.0011880826827692203, "dist_entropy": 0.7410403966903687, "actor_grad_norm": 0.10013872385025024, "critic_grad_norm": 0.2449483424425125, "ratio": 1.0003125667572021, "entropy": 0.7410403966903687, "incre_win_rate": 0.9024390243902439, "step": 843}
{"time": 1767155372.026677, "phase": "train", "update": 844, "total_env_steps": 2700800, "episode_reward": 0.2295152097940445, "value_loss": 0.012975667603313923, "policy_loss": -0.0016137753798879829, "dist_entropy": 0.7226090431213379, "actor_grad_norm": 0.12175846099853516, "critic_grad_norm": 0.17315372824668884, "ratio": 0.9997388124465942, "entropy": 0.7226090431213379, "incre_win_rate": 0.8461538461538461, "step": 844}
{"time": 1767155376.3375294, "phase": "train", "update": 845, "total_env_steps": 2704000, "episode_reward": 0.24755845963954926, "value_loss": 0.009038811549544334, "policy_loss": -0.0010327671876760648, "dist_entropy": 0.6958202719688416, "actor_grad_norm": 0.11845596134662628, "critic_grad_norm": 0.22857654094696045, "ratio": 1.000372290611267, "entropy": 0.6958202719688416, "incre_win_rate": 0.8780487804878049, "step": 845}
{"time": 1767155380.6318293, "phase": "train", "update": 846, "total_env_steps": 2707200, "episode_reward": 0.24323880672454834, "value_loss": 0.011885581351816655, "policy_loss": -0.0012694370009171507, "dist_entropy": 0.7153178453445435, "actor_grad_norm": 0.10868114233016968, "critic_grad_norm": 0.2343561202287674, "ratio": 0.9998769164085388, "entropy": 0.7153178453445435, "incre_win_rate": 0.825, "step": 846}
{"time": 1767155384.9516075, "phase": "train", "update": 847, "total_env_steps": 2710400, "episode_reward": 0.245463564991951, "value_loss": 0.006755404826253653, "policy_loss": -0.0015488146362400812, "dist_entropy": 0.7017943620681762, "actor_grad_norm": 0.1213555857539177, "critic_grad_norm": 0.18064355850219727, "ratio": 0.9998915791511536, "entropy": 0.7017943620681762, "incre_win_rate": 0.8780487804878049, "step": 847}
{"time": 1767155389.2825477, "phase": "train", "update": 848, "total_env_steps": 2713600, "episode_reward": 0.24391144514083862, "value_loss": 0.008801568858325481, "policy_loss": -0.0014505360443610726, "dist_entropy": 0.6838513731956481, "actor_grad_norm": 0.1027437224984169, "critic_grad_norm": 0.10453762859106064, "ratio": 1.0000190734863281, "entropy": 0.6838513731956481, "incre_win_rate": 0.8536585365853658, "step": 848}
{"time": 1767155393.5700748, "phase": "train", "update": 849, "total_env_steps": 2716800, "episode_reward": 0.2323877364397049, "value_loss": 0.01275640819221735, "policy_loss": -0.001383063390883521, "dist_entropy": 0.6889318466186524, "actor_grad_norm": 0.08678273856639862, "critic_grad_norm": 0.08673682063817978, "ratio": 0.9997877478599548, "entropy": 0.6889318466186524, "incre_win_rate": 0.7435897435897436, "step": 849}
{"time": 1767155397.8571186, "phase": "train", "update": 850, "total_env_steps": 2720000, "episode_reward": 0.23564983904361725, "value_loss": 0.012730108946561814, "policy_loss": -0.0012242677591359553, "dist_entropy": 0.6967185020446778, "actor_grad_norm": 0.08431503176689148, "critic_grad_norm": 0.08704184740781784, "ratio": 0.9998802542686462, "entropy": 0.6967185020446778, "incre_win_rate": 0.7142857142857143, "step": 850}
{"time": 1767155402.157401, "phase": "train", "update": 851, "total_env_steps": 2723200, "episode_reward": 0.24769039452075958, "value_loss": 0.009574688971042633, "policy_loss": -0.0014476469051182051, "dist_entropy": 0.722846508026123, "actor_grad_norm": 0.11074274033308029, "critic_grad_norm": 0.1123223528265953, "ratio": 0.9999529719352722, "entropy": 0.722846508026123, "incre_win_rate": 0.8333333333333334, "step": 851}
{"time": 1767155406.447781, "phase": "train", "update": 852, "total_env_steps": 2726400, "episode_reward": 0.2515469789505005, "value_loss": 0.01001669093966484, "policy_loss": -0.0009832123695444396, "dist_entropy": 0.7526436448097229, "actor_grad_norm": 0.09827160090208054, "critic_grad_norm": 0.08487661182880402, "ratio": 0.9997988939285278, "entropy": 0.7526436448097229, "incre_win_rate": 0.8809523809523809, "step": 852}
{"time": 1767155410.700574, "phase": "train", "update": 853, "total_env_steps": 2729600, "episode_reward": 0.23432739078998566, "value_loss": 0.010418700985610485, "policy_loss": -0.001406379259424284, "dist_entropy": 0.7677329063415528, "actor_grad_norm": 0.08033300936222076, "critic_grad_norm": 0.13088923692703247, "ratio": 0.9996888041496277, "entropy": 0.7677329063415528, "incre_win_rate": 0.8378378378378378, "step": 853}
{"time": 1767155414.9644232, "phase": "train", "update": 854, "total_env_steps": 2732800, "episode_reward": 0.23784303665161133, "value_loss": 0.0088420107960701, "policy_loss": -0.0011575651701832613, "dist_entropy": 0.7446855902671814, "actor_grad_norm": 0.09876541048288345, "critic_grad_norm": 0.0735507532954216, "ratio": 0.9998368620872498, "entropy": 0.7446855902671814, "incre_win_rate": 0.8333333333333334, "step": 854}
{"time": 1767155419.2695246, "phase": "train", "update": 855, "total_env_steps": 2736000, "episode_reward": 0.24064260721206665, "value_loss": 0.008822309039533138, "policy_loss": -0.0012654371128796526, "dist_entropy": 0.7795109391212464, "actor_grad_norm": 0.09569721668958664, "critic_grad_norm": 0.1672031134366989, "ratio": 1.000224232673645, "entropy": 0.7795109391212464, "incre_win_rate": 0.8205128205128205, "step": 855}
{"time": 1767155423.5691364, "phase": "train", "update": 856, "total_env_steps": 2739200, "episode_reward": 0.23820053040981293, "value_loss": 0.00861467532813549, "policy_loss": -0.0013055384203127574, "dist_entropy": 0.7395425319671631, "actor_grad_norm": 0.09476470202207565, "critic_grad_norm": 0.09454327076673508, "ratio": 0.9998182654380798, "entropy": 0.7395425319671631, "incre_win_rate": 0.825, "step": 856}
{"time": 1767155427.9183238, "phase": "train", "update": 857, "total_env_steps": 2742400, "episode_reward": 0.24288907647132874, "value_loss": 0.010735544562339782, "policy_loss": -0.0016546727526637994, "dist_entropy": 0.7433175325393677, "actor_grad_norm": 0.11054322868585587, "critic_grad_norm": 0.0710742324590683, "ratio": 0.9998533129692078, "entropy": 0.7433175325393677, "incre_win_rate": 0.7804878048780488, "step": 857}
{"time": 1767155432.2576494, "phase": "train", "update": 858, "total_env_steps": 2745600, "episode_reward": 0.2439693808555603, "value_loss": 0.011040535010397434, "policy_loss": -0.0012198133998651884, "dist_entropy": 0.7249926447868347, "actor_grad_norm": 0.08691008388996124, "critic_grad_norm": 0.12219583243131638, "ratio": 1.0001007318496704, "entropy": 0.7249926447868347, "incre_win_rate": 0.8292682926829268, "step": 858}
{"time": 1767155436.5937657, "phase": "train", "update": 859, "total_env_steps": 2748800, "episode_reward": 0.24824243783950806, "value_loss": 0.010569592751562596, "policy_loss": -0.0011366506770329465, "dist_entropy": 0.7296088695526123, "actor_grad_norm": 0.08889170736074448, "critic_grad_norm": 0.1262405961751938, "ratio": 0.9996153712272644, "entropy": 0.7296088695526123, "incre_win_rate": 0.9285714285714286, "step": 859}
{"time": 1767155440.9304645, "phase": "train", "update": 860, "total_env_steps": 2752000, "episode_reward": 0.23296771943569183, "value_loss": 0.011057091690599919, "policy_loss": -0.0013721467153828826, "dist_entropy": 0.7202136397361756, "actor_grad_norm": 0.0938233956694603, "critic_grad_norm": 0.14133472740650177, "ratio": 1.0001684427261353, "entropy": 0.7202136397361756, "incre_win_rate": 0.7692307692307693, "step": 860}
{"time": 1767155445.2361908, "phase": "train", "update": 861, "total_env_steps": 2755200, "episode_reward": 0.23857925832271576, "value_loss": 0.008875559456646443, "policy_loss": -0.0015829718313686847, "dist_entropy": 0.7209229469299316, "actor_grad_norm": 0.11894848197698593, "critic_grad_norm": 0.1447313278913498, "ratio": 0.9999331831932068, "entropy": 0.7209229469299316, "incre_win_rate": 0.8780487804878049, "step": 861}
{"time": 1767155460.7245378, "phase": "eval", "update": 861, "total_env_steps": 2755200, "eval_win_rate": 0.875, "eval_episode_reward": 19.43775869205298, "step": 861}
{"time": 1767155465.0401485, "phase": "train", "update": 862, "total_env_steps": 2758400, "episode_reward": 0.24850165843963623, "value_loss": 0.009479745104908944, "policy_loss": -0.0014782937661493635, "dist_entropy": 0.7155867695808411, "actor_grad_norm": 0.12563259899616241, "critic_grad_norm": 0.11558729410171509, "ratio": 0.9996699690818787, "entropy": 0.7155867695808411, "incre_win_rate": 0.8780487804878049, "step": 862}
{"time": 1767155469.3596532, "phase": "train", "update": 863, "total_env_steps": 2761600, "episode_reward": 0.22004346549510956, "value_loss": 0.010213400050997735, "policy_loss": -0.001102479749203411, "dist_entropy": 0.7222680926322937, "actor_grad_norm": 0.09993257373571396, "critic_grad_norm": 0.14154639840126038, "ratio": 0.9997952580451965, "entropy": 0.7222680926322937, "incre_win_rate": 0.7027027027027027, "step": 863}
{"time": 1767155473.6473057, "phase": "train", "update": 864, "total_env_steps": 2764800, "episode_reward": 0.23444433510303497, "value_loss": 0.014661656133830548, "policy_loss": -0.0016772885963195704, "dist_entropy": 0.7145220875740051, "actor_grad_norm": 0.11754993349313736, "critic_grad_norm": 0.12501351535320282, "ratio": 0.9999939203262329, "entropy": 0.7145220875740051, "incre_win_rate": 0.85, "step": 864}
{"time": 1767155478.029062, "phase": "train", "update": 865, "total_env_steps": 2768000, "episode_reward": 0.25760138034820557, "value_loss": 0.010510674305260181, "policy_loss": -0.0019793488981084905, "dist_entropy": 0.7475455641746521, "actor_grad_norm": 0.18540002405643463, "critic_grad_norm": 0.1300722360610962, "ratio": 0.9997415542602539, "entropy": 0.7475455641746521, "incre_win_rate": 0.9, "step": 865}
{"time": 1767155482.3350382, "phase": "train", "update": 866, "total_env_steps": 2771200, "episode_reward": 0.24852752685546875, "value_loss": 0.007425650302320719, "policy_loss": -0.0010989637552914822, "dist_entropy": 0.7229109644889832, "actor_grad_norm": 0.10258238762617111, "critic_grad_norm": 0.06747601181268692, "ratio": 1.0000556707382202, "entropy": 0.7229109644889832, "incre_win_rate": 0.8222222222222222, "step": 866}
{"time": 1767155486.677437, "phase": "train", "update": 867, "total_env_steps": 2774400, "episode_reward": 0.24013037979602814, "value_loss": 0.01205704677850008, "policy_loss": -0.0012017594391991794, "dist_entropy": 0.7086693167686462, "actor_grad_norm": 0.09004195779561996, "critic_grad_norm": 0.1710488647222519, "ratio": 0.999542236328125, "entropy": 0.7086693167686462, "incre_win_rate": 0.8048780487804879, "step": 867}
{"time": 1767155490.958181, "phase": "train", "update": 868, "total_env_steps": 2777600, "episode_reward": 0.2531167268753052, "value_loss": 0.005136434268206358, "policy_loss": -0.0014298921229936924, "dist_entropy": 0.738781476020813, "actor_grad_norm": 0.1186428889632225, "critic_grad_norm": 0.15460650622844696, "ratio": 1.0001047849655151, "entropy": 0.738781476020813, "incre_win_rate": 0.9512195121951219, "step": 868}
{"time": 1767155495.3054159, "phase": "train", "update": 869, "total_env_steps": 2780800, "episode_reward": 0.2494494765996933, "value_loss": 0.005619506631046533, "policy_loss": -0.0012994706695444336, "dist_entropy": 0.7323375940322876, "actor_grad_norm": 0.11256541311740875, "critic_grad_norm": 0.1484561264514923, "ratio": 1.0004724264144897, "entropy": 0.7323375940322876, "incre_win_rate": 0.9230769230769231, "step": 869}
{"time": 1767155499.6386104, "phase": "train", "update": 870, "total_env_steps": 2784000, "episode_reward": 0.2464895397424698, "value_loss": 0.01155087687075138, "policy_loss": -0.0012889447991838664, "dist_entropy": 0.713208544254303, "actor_grad_norm": 0.10251747816801071, "critic_grad_norm": 0.12045565992593765, "ratio": 0.999218761920929, "entropy": 0.713208544254303, "incre_win_rate": 0.8372093023255814, "step": 870}
{"time": 1767155503.969551, "phase": "train", "update": 871, "total_env_steps": 2787200, "episode_reward": 0.23863567411899567, "value_loss": 0.010053841955959797, "policy_loss": -0.0013062124420866184, "dist_entropy": 0.7193312168121337, "actor_grad_norm": 0.11516492813825607, "critic_grad_norm": 0.12756967544555664, "ratio": 1.0001085996627808, "entropy": 0.7193312168121337, "incre_win_rate": 0.8205128205128205, "step": 871}
{"time": 1767155508.295998, "phase": "train", "update": 872, "total_env_steps": 2790400, "episode_reward": 0.2279496043920517, "value_loss": 0.012248053029179574, "policy_loss": -0.0010451419842716803, "dist_entropy": 0.6912608742713928, "actor_grad_norm": 0.10865415632724762, "critic_grad_norm": 0.22432811558246613, "ratio": 1.0000605583190918, "entropy": 0.6912608742713928, "incre_win_rate": 0.6829268292682927, "step": 872}
{"time": 1767155512.607202, "phase": "train", "update": 873, "total_env_steps": 2793600, "episode_reward": 0.23177307844161987, "value_loss": 0.017610712349414824, "policy_loss": -0.001478439191329528, "dist_entropy": 0.7025746464729309, "actor_grad_norm": 0.12874318659305573, "critic_grad_norm": 0.29632797837257385, "ratio": 0.9996880888938904, "entropy": 0.7025746464729309, "incre_win_rate": 0.717948717948718, "step": 873}
{"time": 1767155516.9611616, "phase": "train", "update": 874, "total_env_steps": 2796800, "episode_reward": 0.2516721785068512, "value_loss": 0.007390230149030686, "policy_loss": -0.0013648634969314344, "dist_entropy": 0.708660888671875, "actor_grad_norm": 0.13034875690937042, "critic_grad_norm": 0.18574155867099762, "ratio": 0.9999939203262329, "entropy": 0.708660888671875, "incre_win_rate": 0.8571428571428571, "step": 874}
{"time": 1767155521.448896, "phase": "train", "update": 875, "total_env_steps": 2800000, "episode_reward": 0.24570675194263458, "value_loss": 0.00826886873692274, "policy_loss": -0.0011158879444797877, "dist_entropy": 0.7068076848983764, "actor_grad_norm": 0.10948044061660767, "critic_grad_norm": 0.14380906522274017, "ratio": 0.9998685717582703, "entropy": 0.7068076848983764, "incre_win_rate": 0.8536585365853658, "step": 875}
{"time": 1767155525.9264636, "phase": "train", "update": 876, "total_env_steps": 2803200, "episode_reward": 0.25629550218582153, "value_loss": 0.00726984441280365, "policy_loss": -0.001566166892948928, "dist_entropy": 0.7254251360893249, "actor_grad_norm": 0.10320035368204117, "critic_grad_norm": 0.1309576779603958, "ratio": 0.9997013211250305, "entropy": 0.7254251360893249, "incre_win_rate": 0.9285714285714286, "step": 876}
{"time": 1767155530.2492805, "phase": "train", "update": 877, "total_env_steps": 2806400, "episode_reward": 0.25298842787742615, "value_loss": 0.005632118601351976, "policy_loss": -0.0015643783852912208, "dist_entropy": 0.7269063711166381, "actor_grad_norm": 0.10128145664930344, "critic_grad_norm": 0.08601295202970505, "ratio": 0.9997809529304504, "entropy": 0.7269063711166381, "incre_win_rate": 0.926829268292683, "step": 877}
{"time": 1767155534.5370202, "phase": "train", "update": 878, "total_env_steps": 2809600, "episode_reward": 0.24123190343379974, "value_loss": 0.005536061245948076, "policy_loss": -0.0010441622318570153, "dist_entropy": 0.7124114632606506, "actor_grad_norm": 0.10623830556869507, "critic_grad_norm": 0.076768659055233, "ratio": 0.9998903274536133, "entropy": 0.7124114632606506, "incre_win_rate": 0.9, "step": 878}
{"time": 1767155538.8521354, "phase": "train", "update": 879, "total_env_steps": 2812800, "episode_reward": 0.23477233946323395, "value_loss": 0.008855320513248444, "policy_loss": -0.0011279198826343872, "dist_entropy": 0.714401376247406, "actor_grad_norm": 0.10485091060400009, "critic_grad_norm": 0.09736974537372589, "ratio": 1.0003652572631836, "entropy": 0.714401376247406, "incre_win_rate": 0.7619047619047619, "step": 879}
{"time": 1767155543.1610038, "phase": "train", "update": 880, "total_env_steps": 2816000, "episode_reward": 0.24923528730869293, "value_loss": 0.006258998159319162, "policy_loss": -0.0009526127658311623, "dist_entropy": 0.7043007612228394, "actor_grad_norm": 0.1063375249505043, "critic_grad_norm": 0.06410092860460281, "ratio": 0.9997797012329102, "entropy": 0.7043007612228394, "incre_win_rate": 0.8780487804878049, "step": 880}
{"time": 1767155547.51947, "phase": "train", "update": 881, "total_env_steps": 2819200, "episode_reward": 0.23567622900009155, "value_loss": 0.007796165347099304, "policy_loss": -0.0011280465485263846, "dist_entropy": 0.7089341282844543, "actor_grad_norm": 0.11198887974023819, "critic_grad_norm": 0.09629049152135849, "ratio": 1.000048041343689, "entropy": 0.7089341282844543, "incre_win_rate": 0.8421052631578947, "step": 881}
{"time": 1767155558.4351757, "phase": "eval", "update": 881, "total_env_steps": 2819200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.639538493377483, "step": 881}
{"time": 1767155562.7636232, "phase": "train", "update": 882, "total_env_steps": 2822400, "episode_reward": 0.2492053061723709, "value_loss": 0.009456767328083515, "policy_loss": -0.0012814966156192043, "dist_entropy": 0.6839388728141784, "actor_grad_norm": 0.11582410335540771, "critic_grad_norm": 0.07563811540603638, "ratio": 0.9993758201599121, "entropy": 0.6839388728141784, "incre_win_rate": 0.8292682926829268, "step": 882}
{"time": 1767155567.1083038, "phase": "train", "update": 883, "total_env_steps": 2825600, "episode_reward": 0.2456115484237671, "value_loss": 0.00945850219577551, "policy_loss": -0.0015166288566711207, "dist_entropy": 0.7032559514045715, "actor_grad_norm": 0.14470209181308746, "critic_grad_norm": 0.0952698364853859, "ratio": 0.9992266893386841, "entropy": 0.7032559514045715, "incre_win_rate": 0.8, "step": 883}
{"time": 1767155571.4336386, "phase": "train", "update": 884, "total_env_steps": 2828800, "episode_reward": 0.236883282661438, "value_loss": 0.0110543267801404, "policy_loss": -0.0008171092607000219, "dist_entropy": 0.6896900773048401, "actor_grad_norm": 0.09400317072868347, "critic_grad_norm": 0.09021645039319992, "ratio": 0.9997586607933044, "entropy": 0.6896900773048401, "incre_win_rate": 0.7857142857142857, "step": 884}
{"time": 1767155575.7815776, "phase": "train", "update": 885, "total_env_steps": 2832000, "episode_reward": 0.24332214891910553, "value_loss": 0.008983564749360084, "policy_loss": -0.0010526287476373853, "dist_entropy": 0.6914520978927612, "actor_grad_norm": 0.12185242027044296, "critic_grad_norm": 0.07773038744926453, "ratio": 1.0000991821289062, "entropy": 0.6914520978927612, "incre_win_rate": 0.8292682926829268, "step": 885}
{"time": 1767155580.128978, "phase": "train", "update": 886, "total_env_steps": 2835200, "episode_reward": 0.24823415279388428, "value_loss": 0.010779565759003162, "policy_loss": -0.0014245763135164679, "dist_entropy": 0.6911980867385864, "actor_grad_norm": 0.11343289911746979, "critic_grad_norm": 0.11521732807159424, "ratio": 0.9999204874038696, "entropy": 0.6911980867385864, "incre_win_rate": 0.9069767441860465, "step": 886}
{"time": 1767155584.465092, "phase": "train", "update": 887, "total_env_steps": 2838400, "episode_reward": 0.2281849980354309, "value_loss": 0.008124284073710441, "policy_loss": -0.0012478679121123548, "dist_entropy": 0.7030758619308471, "actor_grad_norm": 0.11457313597202301, "critic_grad_norm": 0.13206882774829865, "ratio": 0.9993652701377869, "entropy": 0.7030758619308471, "incre_win_rate": 0.8378378378378378, "step": 887}
{"time": 1767155588.8157492, "phase": "train", "update": 888, "total_env_steps": 2841600, "episode_reward": 0.24812862277030945, "value_loss": 0.007892282772809267, "policy_loss": -0.0013666325078730778, "dist_entropy": 0.72427978515625, "actor_grad_norm": 0.09471571445465088, "critic_grad_norm": 0.13357388973236084, "ratio": 1.000109076499939, "entropy": 0.72427978515625, "incre_win_rate": 0.8974358974358975, "step": 888}
{"time": 1767155593.0739439, "phase": "train", "update": 889, "total_env_steps": 2844800, "episode_reward": 0.22010555863380432, "value_loss": 0.0093726834282279, "policy_loss": -0.0015226172363703937, "dist_entropy": 0.7200914144515991, "actor_grad_norm": 0.10238654911518097, "critic_grad_norm": 0.09364219754934311, "ratio": 1.0000264644622803, "entropy": 0.7200914144515991, "incre_win_rate": 0.7837837837837838, "step": 889}
{"time": 1767155597.3789587, "phase": "train", "update": 890, "total_env_steps": 2848000, "episode_reward": 0.24030371010303497, "value_loss": 0.0065791506320238115, "policy_loss": -0.0011400576131119777, "dist_entropy": 0.7152849912643433, "actor_grad_norm": 0.09360026568174362, "critic_grad_norm": 0.12376339733600616, "ratio": 0.9997067451477051, "entropy": 0.7152849912643433, "incre_win_rate": 0.8947368421052632, "step": 890}
{"time": 1767155601.6105912, "phase": "train", "update": 891, "total_env_steps": 2851200, "episode_reward": 0.2396755963563919, "value_loss": 0.006444404926151037, "policy_loss": -0.0009544517602870783, "dist_entropy": 0.7266721487045288, "actor_grad_norm": 0.10010891407728195, "critic_grad_norm": 0.09984805434942245, "ratio": 1.0001600980758667, "entropy": 0.7266721487045288, "incre_win_rate": 0.85, "step": 891}
{"time": 1767155605.9014463, "phase": "train", "update": 892, "total_env_steps": 2854400, "episode_reward": 0.253397673368454, "value_loss": 0.0051170608028769495, "policy_loss": -0.0011750148411096006, "dist_entropy": 0.7082270503044128, "actor_grad_norm": 0.12915824353694916, "critic_grad_norm": 0.10486220568418503, "ratio": 0.9998577237129211, "entropy": 0.7082270503044128, "incre_win_rate": 0.8604651162790697, "step": 892}
{"time": 1767155610.1746542, "phase": "train", "update": 893, "total_env_steps": 2857600, "episode_reward": 0.2553683817386627, "value_loss": 0.007583867479115725, "policy_loss": -0.0010943953979666078, "dist_entropy": 0.6978767871856689, "actor_grad_norm": 0.0805065706372261, "critic_grad_norm": 0.11162721365690231, "ratio": 0.9998924136161804, "entropy": 0.6978767871856689, "incre_win_rate": 0.9512195121951219, "step": 893}
{"time": 1767155614.529459, "phase": "train", "update": 894, "total_env_steps": 2860800, "episode_reward": 0.2472108006477356, "value_loss": 0.006880017928779125, "policy_loss": -0.001284336409514708, "dist_entropy": 0.686160433292389, "actor_grad_norm": 0.10165786743164062, "critic_grad_norm": 0.09207036346197128, "ratio": 0.9998237490653992, "entropy": 0.686160433292389, "incre_win_rate": 0.8372093023255814, "step": 894}
{"time": 1767155618.9067307, "phase": "train", "update": 895, "total_env_steps": 2864000, "episode_reward": 0.25715649127960205, "value_loss": 0.005644420254975557, "policy_loss": -0.0012547093890873384, "dist_entropy": 0.6996694922447204, "actor_grad_norm": 0.10284121334552765, "critic_grad_norm": 0.043869175016880035, "ratio": 1.0000648498535156, "entropy": 0.6996694922447204, "incre_win_rate": 0.8809523809523809, "step": 895}
{"time": 1767155623.2373524, "phase": "train", "update": 896, "total_env_steps": 2867200, "episode_reward": 0.24389798939228058, "value_loss": 0.010602791048586368, "policy_loss": -0.0011652460266912356, "dist_entropy": 0.6774845242500305, "actor_grad_norm": 0.11801335960626602, "critic_grad_norm": 0.08646192401647568, "ratio": 0.9995073676109314, "entropy": 0.6774845242500305, "incre_win_rate": 0.8717948717948718, "step": 896}
{"time": 1767155627.6141684, "phase": "train", "update": 897, "total_env_steps": 2870400, "episode_reward": 0.25902679562568665, "value_loss": 0.007946420460939407, "policy_loss": -0.0011153559307430783, "dist_entropy": 0.6740906596183777, "actor_grad_norm": 0.11283238232135773, "critic_grad_norm": 0.16519944369792938, "ratio": 1.0001134872436523, "entropy": 0.6740906596183777, "incre_win_rate": 0.9302325581395349, "step": 897}
{"time": 1767155631.9518073, "phase": "train", "update": 898, "total_env_steps": 2873600, "episode_reward": 0.24953022599220276, "value_loss": 0.004508426133543253, "policy_loss": -0.0009304625144430645, "dist_entropy": 0.6779677033424377, "actor_grad_norm": 0.09706082195043564, "critic_grad_norm": 0.0653529018163681, "ratio": 0.9998455047607422, "entropy": 0.6779677033424377, "incre_win_rate": 0.925, "step": 898}
{"time": 1767155636.2435045, "phase": "train", "update": 899, "total_env_steps": 2876800, "episode_reward": 0.24932481348514557, "value_loss": 0.005168885458260775, "policy_loss": -0.0011090658716966574, "dist_entropy": 0.6854774713516235, "actor_grad_norm": 0.08634766191244125, "critic_grad_norm": 0.059259068220853806, "ratio": 0.9998369216918945, "entropy": 0.6854774713516235, "incre_win_rate": 0.926829268292683, "step": 899}
{"time": 1767155640.5797074, "phase": "train", "update": 900, "total_env_steps": 2880000, "episode_reward": 0.26162251830101013, "value_loss": 0.004826165921986103, "policy_loss": -0.0014403285019961131, "dist_entropy": 0.6683837056159974, "actor_grad_norm": 0.10828155279159546, "critic_grad_norm": 0.03092571534216404, "ratio": 0.9995948076248169, "entropy": 0.6683837056159974, "incre_win_rate": 0.9302325581395349, "step": 900}
{"time": 1767155644.9355044, "phase": "train", "update": 901, "total_env_steps": 2883200, "episode_reward": 0.25275248289108276, "value_loss": 0.005794619955122471, "policy_loss": -0.0013484192860911293, "dist_entropy": 0.6885612607002258, "actor_grad_norm": 0.09129395335912704, "critic_grad_norm": 0.04447275027632713, "ratio": 0.9997950792312622, "entropy": 0.6885612607002258, "incre_win_rate": 0.9512195121951219, "step": 901}
{"time": 1767155655.412012, "phase": "eval", "update": 901, "total_env_steps": 2883200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.602390314569536, "step": 901}
{"time": 1767155659.7307248, "phase": "train", "update": 902, "total_env_steps": 2886400, "episode_reward": 0.24713265895843506, "value_loss": 0.007738498505204916, "policy_loss": -0.001454930809871513, "dist_entropy": 0.6785422563552856, "actor_grad_norm": 0.11271855980157852, "critic_grad_norm": 0.07783500105142593, "ratio": 0.9998262524604797, "entropy": 0.6785422563552856, "incre_win_rate": 0.8809523809523809, "step": 902}
{"time": 1767155664.0131316, "phase": "train", "update": 903, "total_env_steps": 2889600, "episode_reward": 0.25971439480781555, "value_loss": 0.005383437033742666, "policy_loss": -0.001280175180843912, "dist_entropy": 0.6862315654754638, "actor_grad_norm": 0.09417843073606491, "critic_grad_norm": 0.1220584437251091, "ratio": 0.999904453754425, "entropy": 0.6862315654754638, "incre_win_rate": 0.9487179487179487, "step": 903}
{"time": 1767155668.2864842, "phase": "train", "update": 904, "total_env_steps": 2892800, "episode_reward": 0.2508542239665985, "value_loss": 0.007411729451268912, "policy_loss": -0.0011999584426394705, "dist_entropy": 0.6701862573623657, "actor_grad_norm": 0.09423013031482697, "critic_grad_norm": 0.14430589973926544, "ratio": 1.0002613067626953, "entropy": 0.6701862573623657, "incre_win_rate": 0.8604651162790697, "step": 904}
{"time": 1767155672.531056, "phase": "train", "update": 905, "total_env_steps": 2896000, "episode_reward": 0.24898488819599152, "value_loss": 0.008693039417266846, "policy_loss": -0.0013532025068692555, "dist_entropy": 0.6680438756942749, "actor_grad_norm": 0.10441792011260986, "critic_grad_norm": 0.1734030544757843, "ratio": 0.9996992945671082, "entropy": 0.6680438756942749, "incre_win_rate": 0.9024390243902439, "step": 905}
{"time": 1767155676.8365211, "phase": "train", "update": 906, "total_env_steps": 2899200, "episode_reward": 0.2607574462890625, "value_loss": 0.007528215367347002, "policy_loss": -0.001128690492066653, "dist_entropy": 0.6632971167564392, "actor_grad_norm": 0.10919227451086044, "critic_grad_norm": 0.09661844372749329, "ratio": 1.000059723854065, "entropy": 0.6632971167564392, "incre_win_rate": 0.9069767441860465, "step": 906}
{"time": 1767155681.0613568, "phase": "train", "update": 907, "total_env_steps": 2902400, "episode_reward": 0.2375212162733078, "value_loss": 0.008091166988015175, "policy_loss": -0.0014643778404487052, "dist_entropy": 0.6485511660575867, "actor_grad_norm": 0.09729930013418198, "critic_grad_norm": 0.07696908712387085, "ratio": 1.000288724899292, "entropy": 0.6485511660575867, "incre_win_rate": 0.8205128205128205, "step": 907}
{"time": 1767155685.3394365, "phase": "train", "update": 908, "total_env_steps": 2905600, "episode_reward": 0.25467923283576965, "value_loss": 0.00713097658008337, "policy_loss": -0.0008984135278066851, "dist_entropy": 0.6459604144096375, "actor_grad_norm": 0.12189797312021255, "critic_grad_norm": 0.1334371268749237, "ratio": 0.999928891658783, "entropy": 0.6459604144096375, "incre_win_rate": 0.9285714285714286, "step": 908}
{"time": 1767155689.6129603, "phase": "train", "update": 909, "total_env_steps": 2908800, "episode_reward": 0.2505049705505371, "value_loss": 0.005907767917960882, "policy_loss": -0.000981235737742736, "dist_entropy": 0.635637629032135, "actor_grad_norm": 0.09824701398611069, "critic_grad_norm": 0.12271566689014435, "ratio": 1.0001604557037354, "entropy": 0.635637629032135, "incre_win_rate": 0.925, "step": 909}
{"time": 1767155693.882779, "phase": "train", "update": 910, "total_env_steps": 2912000, "episode_reward": 0.24809810519218445, "value_loss": 0.006092008389532566, "policy_loss": -0.0012144596062249491, "dist_entropy": 0.6533583164215088, "actor_grad_norm": 0.11189978569746017, "critic_grad_norm": 0.05596725270152092, "ratio": 0.999638557434082, "entropy": 0.6533583164215088, "incre_win_rate": 0.9285714285714286, "step": 910}
{"time": 1767155698.1375022, "phase": "train", "update": 911, "total_env_steps": 2915200, "episode_reward": 0.2514735162258148, "value_loss": 0.006079995166510343, "policy_loss": -0.0008807125802936077, "dist_entropy": 0.6543941974639893, "actor_grad_norm": 0.09603818506002426, "critic_grad_norm": 0.043892938643693924, "ratio": 1.0001486539840698, "entropy": 0.6543941974639893, "incre_win_rate": 0.9230769230769231, "step": 911}
{"time": 1767155702.438492, "phase": "train", "update": 912, "total_env_steps": 2918400, "episode_reward": 0.25288495421409607, "value_loss": 0.006230639014393091, "policy_loss": -0.0009352461718030725, "dist_entropy": 0.6605842113494873, "actor_grad_norm": 0.10509983450174332, "critic_grad_norm": 0.024771733209490776, "ratio": 0.999945342540741, "entropy": 0.6605842113494873, "incre_win_rate": 0.9069767441860465, "step": 912}
{"time": 1767155706.7510781, "phase": "train", "update": 913, "total_env_steps": 2921600, "episode_reward": 0.2517208158969879, "value_loss": 0.004166785161942244, "policy_loss": -0.0008867924783441339, "dist_entropy": 0.6557866930961609, "actor_grad_norm": 0.13128215074539185, "critic_grad_norm": 0.021849248558282852, "ratio": 0.9998018145561218, "entropy": 0.6557866930961609, "incre_win_rate": 0.9210526315789473, "step": 913}
{"time": 1767155711.036281, "phase": "train", "update": 914, "total_env_steps": 2924800, "episode_reward": 0.25872933864593506, "value_loss": 0.004519118648022413, "policy_loss": -0.0008493188431259568, "dist_entropy": 0.6781733870506287, "actor_grad_norm": 0.10698529332876205, "critic_grad_norm": 0.06360328942537308, "ratio": 1.0002034902572632, "entropy": 0.6781733870506287, "incre_win_rate": 0.9772727272727273, "step": 914}
{"time": 1767155715.3304076, "phase": "train", "update": 915, "total_env_steps": 2928000, "episode_reward": 0.25376656651496887, "value_loss": 0.005311142932623625, "policy_loss": -0.001042293812133721, "dist_entropy": 0.654545533657074, "actor_grad_norm": 0.09663122147321701, "critic_grad_norm": 0.043170224875211716, "ratio": 0.9997875094413757, "entropy": 0.654545533657074, "incre_win_rate": 0.9512195121951219, "step": 915}
{"time": 1767155719.645686, "phase": "train", "update": 916, "total_env_steps": 2931200, "episode_reward": 0.2548634111881256, "value_loss": 0.00435873307287693, "policy_loss": -0.0007038932587759561, "dist_entropy": 0.6615593910217286, "actor_grad_norm": 0.0884484201669693, "critic_grad_norm": 0.0240641999989748, "ratio": 0.999753475189209, "entropy": 0.6615593910217286, "incre_win_rate": 0.9534883720930233, "step": 916}
{"time": 1767155723.9356158, "phase": "train", "update": 917, "total_env_steps": 2934400, "episode_reward": 0.2506342828273773, "value_loss": 0.006364219915121793, "policy_loss": -0.001004003783895513, "dist_entropy": 0.6581634640693664, "actor_grad_norm": 0.08172383904457092, "critic_grad_norm": 0.06626246869564056, "ratio": 1.00043785572052, "entropy": 0.6581634640693664, "incre_win_rate": 0.875, "step": 917}
{"time": 1767155728.2665367, "phase": "train", "update": 918, "total_env_steps": 2937600, "episode_reward": 0.25634104013442993, "value_loss": 0.00707815308123827, "policy_loss": -0.0011468216829705114, "dist_entropy": 0.6762818098068237, "actor_grad_norm": 0.09270556271076202, "critic_grad_norm": 0.08603205531835556, "ratio": 0.9996844530105591, "entropy": 0.6762818098068237, "incre_win_rate": 0.9024390243902439, "step": 918}
{"time": 1767155732.618955, "phase": "train", "update": 919, "total_env_steps": 2940800, "episode_reward": 0.2543129026889801, "value_loss": 0.007425224687904119, "policy_loss": -0.0014068866086446973, "dist_entropy": 0.6787521600723266, "actor_grad_norm": 0.11417045444250107, "critic_grad_norm": 0.034297700971364975, "ratio": 0.999592125415802, "entropy": 0.6787521600723266, "incre_win_rate": 0.8888888888888888, "step": 919}
{"time": 1767155736.9389489, "phase": "train", "update": 920, "total_env_steps": 2944000, "episode_reward": 0.25966060161590576, "value_loss": 0.006147706042975187, "policy_loss": -0.0006366649406118086, "dist_entropy": 0.6835564851760865, "actor_grad_norm": 0.09680672734975815, "critic_grad_norm": 0.04654897004365921, "ratio": 0.9995975494384766, "entropy": 0.6835564851760865, "incre_win_rate": 0.9512195121951219, "step": 920}
{"time": 1767155741.2602277, "phase": "train", "update": 921, "total_env_steps": 2947200, "episode_reward": 0.25540977716445923, "value_loss": 0.00529256472364068, "policy_loss": -0.0009910457948622664, "dist_entropy": 0.6860238790512085, "actor_grad_norm": 0.09287412464618683, "critic_grad_norm": 0.09330450743436813, "ratio": 1.0001330375671387, "entropy": 0.6860238790512085, "incre_win_rate": 0.926829268292683, "step": 921}
{"time": 1767155751.62085, "phase": "eval", "update": 921, "total_env_steps": 2947200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.690811258278146, "step": 921}
{"time": 1767155755.9332278, "phase": "train", "update": 922, "total_env_steps": 2950400, "episode_reward": 0.263414204120636, "value_loss": 0.006706517282873392, "policy_loss": -0.0012938149177507796, "dist_entropy": 0.7002769708633423, "actor_grad_norm": 0.11260966211557388, "critic_grad_norm": 0.08663363754749298, "ratio": 0.9996904730796814, "entropy": 0.7002769708633423, "incre_win_rate": 0.9318181818181818, "step": 922}
{"time": 1767155760.3045337, "phase": "train", "update": 923, "total_env_steps": 2953600, "episode_reward": 0.25884106755256653, "value_loss": 0.006537053268402815, "policy_loss": -0.0008690252485635596, "dist_entropy": 0.6830200314521789, "actor_grad_norm": 0.08900302648544312, "critic_grad_norm": 0.08412139862775803, "ratio": 1.0001344680786133, "entropy": 0.6830200314521789, "incre_win_rate": 0.9047619047619048, "step": 923}
{"time": 1767155764.6611402, "phase": "train", "update": 924, "total_env_steps": 2956800, "episode_reward": 0.25398126244544983, "value_loss": 0.005818310845643282, "policy_loss": -0.0008081882395117645, "dist_entropy": 0.7083838105201721, "actor_grad_norm": 0.08420008420944214, "critic_grad_norm": 0.06796721369028091, "ratio": 0.99982750415802, "entropy": 0.7083838105201721, "incre_win_rate": 0.9047619047619048, "step": 924}
{"time": 1767155769.0323918, "phase": "train", "update": 925, "total_env_steps": 2960000, "episode_reward": 0.2671026587486267, "value_loss": 0.004120167717337609, "policy_loss": -0.0009058991302159924, "dist_entropy": 0.7181512951850891, "actor_grad_norm": 0.08519390970468521, "critic_grad_norm": 0.03662562742829323, "ratio": 0.9996504187583923, "entropy": 0.7181512951850891, "incre_win_rate": 0.9761904761904762, "step": 925}
{"time": 1767155773.3619149, "phase": "train", "update": 926, "total_env_steps": 2963200, "episode_reward": 0.2530505061149597, "value_loss": 0.008136746473610401, "policy_loss": -0.0011158400418540993, "dist_entropy": 0.7204220056533813, "actor_grad_norm": 0.09351950883865356, "critic_grad_norm": 0.05483651161193848, "ratio": 1.0000183582305908, "entropy": 0.7204220056533813, "incre_win_rate": 0.8333333333333334, "step": 926}
{"time": 1767155777.6692863, "phase": "train", "update": 927, "total_env_steps": 2966400, "episode_reward": 0.23993274569511414, "value_loss": 0.009083079919219018, "policy_loss": -0.0012135582459109173, "dist_entropy": 0.7319845795631409, "actor_grad_norm": 0.0981195941567421, "critic_grad_norm": 0.12439315766096115, "ratio": 0.9999627470970154, "entropy": 0.7319845795631409, "incre_win_rate": 0.7441860465116279, "step": 927}
{"time": 1767155781.9804661, "phase": "train", "update": 928, "total_env_steps": 2969600, "episode_reward": 0.24725216627120972, "value_loss": 0.00656001279130578, "policy_loss": -0.00124006284561915, "dist_entropy": 0.7327370524406434, "actor_grad_norm": 0.09742947667837143, "critic_grad_norm": 0.09865280985832214, "ratio": 0.999909520149231, "entropy": 0.7327370524406434, "incre_win_rate": 0.9, "step": 928}
{"time": 1767155786.3330126, "phase": "train", "update": 929, "total_env_steps": 2972800, "episode_reward": 0.25754502415657043, "value_loss": 0.006475664768368005, "policy_loss": -0.0008309265118191078, "dist_entropy": 0.725535261631012, "actor_grad_norm": 0.0785999670624733, "critic_grad_norm": 0.11125113070011139, "ratio": 0.9999343752861023, "entropy": 0.725535261631012, "incre_win_rate": 0.9285714285714286, "step": 929}
{"time": 1767155790.6639998, "phase": "train", "update": 930, "total_env_steps": 2976000, "episode_reward": 0.25161734223365784, "value_loss": 0.006441915594041348, "policy_loss": -0.001352512047824206, "dist_entropy": 0.7279249548912048, "actor_grad_norm": 0.08831609040498734, "critic_grad_norm": 0.07879790663719177, "ratio": 0.999707043170929, "entropy": 0.7279249548912048, "incre_win_rate": 0.875, "step": 930}
{"time": 1767155795.0386448, "phase": "train", "update": 931, "total_env_steps": 2979200, "episode_reward": 0.2519727945327759, "value_loss": 0.007889909483492375, "policy_loss": -0.0012614458080717483, "dist_entropy": 0.7479540944099426, "actor_grad_norm": 0.10226239264011383, "critic_grad_norm": 0.17380262911319733, "ratio": 1.0000661611557007, "entropy": 0.7479540944099426, "incre_win_rate": 0.8604651162790697, "step": 931}
{"time": 1767155799.387798, "phase": "train", "update": 932, "total_env_steps": 2982400, "episode_reward": 0.24402007460594177, "value_loss": 0.011157801747322083, "policy_loss": -0.0014187076324944313, "dist_entropy": 0.717775297164917, "actor_grad_norm": 0.12173676490783691, "critic_grad_norm": 0.15038429200649261, "ratio": 1.0003843307495117, "entropy": 0.717775297164917, "incre_win_rate": 0.9047619047619048, "step": 932}
{"time": 1767155803.7424757, "phase": "train", "update": 933, "total_env_steps": 2985600, "episode_reward": 0.2615320086479187, "value_loss": 0.005490302108228207, "policy_loss": -0.0011402338397346057, "dist_entropy": 0.7181644678115845, "actor_grad_norm": 0.0922740176320076, "critic_grad_norm": 0.21765148639678955, "ratio": 1.000234842300415, "entropy": 0.7181644678115845, "incre_win_rate": 0.95, "step": 933}
{"time": 1767155808.090414, "phase": "train", "update": 934, "total_env_steps": 2988800, "episode_reward": 0.2656813859939575, "value_loss": 0.003801451763138175, "policy_loss": -0.0012467223538788375, "dist_entropy": 0.7187509894371032, "actor_grad_norm": 0.08369063585996628, "critic_grad_norm": 0.1626419723033905, "ratio": 0.9996039271354675, "entropy": 0.7187509894371032, "incre_win_rate": 0.9761904761904762, "step": 934}
{"time": 1767155812.4038384, "phase": "train", "update": 935, "total_env_steps": 2992000, "episode_reward": 0.26126450300216675, "value_loss": 0.006005095038563013, "policy_loss": -0.0010982176736163752, "dist_entropy": 0.7138266563415527, "actor_grad_norm": 0.09435614198446274, "critic_grad_norm": 0.09144067764282227, "ratio": 1.0003128051757812, "entropy": 0.7138266563415527, "incre_win_rate": 0.9333333333333333, "step": 935}
{"time": 1767155816.7279193, "phase": "train", "update": 936, "total_env_steps": 2995200, "episode_reward": 0.25396111607551575, "value_loss": 0.007534774579107761, "policy_loss": -0.0011194906387169468, "dist_entropy": 0.7260445952415466, "actor_grad_norm": 0.11986298859119415, "critic_grad_norm": 0.30203792452812195, "ratio": 1.0001267194747925, "entropy": 0.7260445952415466, "incre_win_rate": 0.8780487804878049, "step": 936}
{"time": 1767155821.057195, "phase": "train", "update": 937, "total_env_steps": 2998400, "episode_reward": 0.24824556708335876, "value_loss": 0.007507954817265272, "policy_loss": -0.0014552069772048703, "dist_entropy": 0.7322994112968445, "actor_grad_norm": 0.12705521285533905, "critic_grad_norm": 0.19197049736976624, "ratio": 1.000210165977478, "entropy": 0.7322994112968445, "incre_win_rate": 0.926829268292683, "step": 937}
{"time": 1767155825.370014, "phase": "train", "update": 938, "total_env_steps": 3001600, "episode_reward": 0.2555209994316101, "value_loss": 0.005820913799107074, "policy_loss": -0.0016379388521080783, "dist_entropy": 0.7049808382987977, "actor_grad_norm": 0.14110492169857025, "critic_grad_norm": 0.12289724498987198, "ratio": 0.9994938969612122, "entropy": 0.7049808382987977, "incre_win_rate": 0.926829268292683, "step": 938}
{"time": 1767155829.7119548, "phase": "train", "update": 939, "total_env_steps": 3004800, "episode_reward": 0.26315808296203613, "value_loss": 0.007935449853539467, "policy_loss": -0.0013517613154620633, "dist_entropy": 0.7103105306625366, "actor_grad_norm": 0.13402985036373138, "critic_grad_norm": 0.14012563228607178, "ratio": 1.0001709461212158, "entropy": 0.7103105306625366, "incre_win_rate": 0.9302325581395349, "step": 939}
{"time": 1767155833.9984536, "phase": "train", "update": 940, "total_env_steps": 3008000, "episode_reward": 0.25548842549324036, "value_loss": 0.007718655280768871, "policy_loss": -0.0013410260301455422, "dist_entropy": 0.704421877861023, "actor_grad_norm": 0.09972339123487473, "critic_grad_norm": 0.05539816617965698, "ratio": 1.000299096107483, "entropy": 0.704421877861023, "incre_win_rate": 0.9069767441860465, "step": 940}
{"time": 1767155838.3440843, "phase": "train", "update": 941, "total_env_steps": 3011200, "episode_reward": 0.25451159477233887, "value_loss": 0.009731390327215195, "policy_loss": -0.0013925142514430889, "dist_entropy": 0.7105607271194458, "actor_grad_norm": 0.0962013378739357, "critic_grad_norm": 0.20037785172462463, "ratio": 0.999531090259552, "entropy": 0.7105607271194458, "incre_win_rate": 0.8571428571428571, "step": 941}
{"time": 1767155848.653177, "phase": "eval", "update": 941, "total_env_steps": 3011200, "eval_win_rate": 1.0, "eval_episode_reward": 20.0, "step": 941}
{"time": 1767155852.982152, "phase": "train", "update": 942, "total_env_steps": 3014400, "episode_reward": 0.25387004017829895, "value_loss": 0.0073862351477146145, "policy_loss": -0.0013595871716017172, "dist_entropy": 0.7080492615699768, "actor_grad_norm": 0.11517155170440674, "critic_grad_norm": 0.17211198806762695, "ratio": 0.9997939467430115, "entropy": 0.7080492615699768, "incre_win_rate": 0.925, "step": 942}
{"time": 1767155857.435061, "phase": "train", "update": 943, "total_env_steps": 3017600, "episode_reward": 0.24648283421993256, "value_loss": 0.008261691220104695, "policy_loss": -0.0007792741040236528, "dist_entropy": 0.7008022904396057, "actor_grad_norm": 0.09745786339044571, "critic_grad_norm": 0.125502809882164, "ratio": 0.999787449836731, "entropy": 0.7008022904396057, "incre_win_rate": 0.8863636363636364, "step": 943}
{"time": 1767155861.9372547, "phase": "train", "update": 944, "total_env_steps": 3020800, "episode_reward": 0.26052671670913696, "value_loss": 0.006626921705901623, "policy_loss": -0.0011740733874079368, "dist_entropy": 0.7018008232116699, "actor_grad_norm": 0.11947375535964966, "critic_grad_norm": 0.21041260659694672, "ratio": 1.000244379043579, "entropy": 0.7018008232116699, "incre_win_rate": 0.926829268292683, "step": 944}
{"time": 1767155867.0648048, "phase": "train", "update": 945, "total_env_steps": 3024000, "episode_reward": 0.2648561894893646, "value_loss": 0.005541578028351068, "policy_loss": -0.001187637549626297, "dist_entropy": 0.6862571835517883, "actor_grad_norm": 0.09596260637044907, "critic_grad_norm": 0.09543684124946594, "ratio": 0.9998025894165039, "entropy": 0.6862571835517883, "incre_win_rate": 0.9024390243902439, "step": 945}
{"time": 1767155871.9832933, "phase": "train", "update": 946, "total_env_steps": 3027200, "episode_reward": 0.26343855261802673, "value_loss": 0.005590684898197651, "policy_loss": -0.0013114322077441899, "dist_entropy": 0.6804583311080933, "actor_grad_norm": 0.10469533503055573, "critic_grad_norm": 0.1255876123905182, "ratio": 1.000059962272644, "entropy": 0.6804583311080933, "incre_win_rate": 0.9555555555555556, "step": 946}
{"time": 1767155876.2694619, "phase": "train", "update": 947, "total_env_steps": 3030400, "episode_reward": 0.24746377766132355, "value_loss": 0.008725815080106258, "policy_loss": -0.0013247514163936102, "dist_entropy": 0.6696585893630982, "actor_grad_norm": 0.10601913928985596, "critic_grad_norm": 0.08279278129339218, "ratio": 1.0002294778823853, "entropy": 0.6696585893630982, "incre_win_rate": 0.926829268292683, "step": 947}
{"time": 1767155880.5690987, "phase": "train", "update": 948, "total_env_steps": 3033600, "episode_reward": 0.2597273588180542, "value_loss": 0.00868700984865427, "policy_loss": -0.0013544277552234973, "dist_entropy": 0.6802924513816834, "actor_grad_norm": 0.1165933758020401, "critic_grad_norm": 0.11056780815124512, "ratio": 0.9996606111526489, "entropy": 0.6802924513816834, "incre_win_rate": 0.8809523809523809, "step": 948}
{"time": 1767155884.9054906, "phase": "train", "update": 949, "total_env_steps": 3036800, "episode_reward": 0.2551402151584625, "value_loss": 0.007266612630337477, "policy_loss": -0.00115423870174709, "dist_entropy": 0.6587016582489014, "actor_grad_norm": 0.10528905689716339, "critic_grad_norm": 0.18041911721229553, "ratio": 0.9999755024909973, "entropy": 0.6587016582489014, "incre_win_rate": 0.9285714285714286, "step": 949}
{"time": 1767155889.1990814, "phase": "train", "update": 950, "total_env_steps": 3040000, "episode_reward": 0.2607077658176422, "value_loss": 0.0045038660056889055, "policy_loss": -0.0013324446847789773, "dist_entropy": 0.6718445539474487, "actor_grad_norm": 0.08916786313056946, "critic_grad_norm": 0.15647713840007782, "ratio": 0.9998723864555359, "entropy": 0.6718445539474487, "incre_win_rate": 0.9545454545454546, "step": 950}
{"time": 1767155893.4648006, "phase": "train", "update": 951, "total_env_steps": 3043200, "episode_reward": 0.2619965970516205, "value_loss": 0.003486615465953946, "policy_loss": -0.0009789894070507898, "dist_entropy": 0.68953458070755, "actor_grad_norm": 0.10758526623249054, "critic_grad_norm": 0.08839791268110275, "ratio": 0.9999763369560242, "entropy": 0.68953458070755, "incre_win_rate": 0.975609756097561, "step": 951}
{"time": 1767155897.7499232, "phase": "train", "update": 952, "total_env_steps": 3046400, "episode_reward": 0.2461356669664383, "value_loss": 0.00959710255265236, "policy_loss": -0.0012564401698227812, "dist_entropy": 0.7021566748619079, "actor_grad_norm": 0.11509984731674194, "critic_grad_norm": 0.2662183940410614, "ratio": 1.0004425048828125, "entropy": 0.7021566748619079, "incre_win_rate": 0.825, "step": 952}
{"time": 1767155902.1071398, "phase": "train", "update": 953, "total_env_steps": 3049600, "episode_reward": 0.25703227519989014, "value_loss": 0.0071821450255811214, "policy_loss": -0.0010900229518672866, "dist_entropy": 0.6900749206542969, "actor_grad_norm": 0.11186492443084717, "critic_grad_norm": 0.177634134888649, "ratio": 0.9996728301048279, "entropy": 0.6900749206542969, "incre_win_rate": 0.9090909090909091, "step": 953}
{"time": 1767155906.4269128, "phase": "train", "update": 954, "total_env_steps": 3052800, "episode_reward": 0.26522353291511536, "value_loss": 0.004946465604007244, "policy_loss": -0.0012146093074317577, "dist_entropy": 0.6866594314575195, "actor_grad_norm": 0.12254752963781357, "critic_grad_norm": 0.1533215492963791, "ratio": 1.0000076293945312, "entropy": 0.6866594314575195, "incre_win_rate": 1.0, "step": 954}
{"time": 1767155910.7341585, "phase": "train", "update": 955, "total_env_steps": 3056000, "episode_reward": 0.25288495421409607, "value_loss": 0.008047504350543022, "policy_loss": -0.0011465747513781821, "dist_entropy": 0.6929811120033265, "actor_grad_norm": 0.08381997793912888, "critic_grad_norm": 0.09580754488706589, "ratio": 0.9999896883964539, "entropy": 0.6929811120033265, "incre_win_rate": 0.926829268292683, "step": 955}
{"time": 1767155915.0451186, "phase": "train", "update": 956, "total_env_steps": 3059200, "episode_reward": 0.2522791028022766, "value_loss": 0.008211449533700944, "policy_loss": -0.0009796342736338559, "dist_entropy": 0.6950547337532044, "actor_grad_norm": 0.08446081727743149, "critic_grad_norm": 0.15058164298534393, "ratio": 0.999810516834259, "entropy": 0.6950547337532044, "incre_win_rate": 0.8571428571428571, "step": 956}
{"time": 1767155919.4427445, "phase": "train", "update": 957, "total_env_steps": 3062400, "episode_reward": 0.2542979121208191, "value_loss": 0.009367375075817109, "policy_loss": -0.0013766364001444487, "dist_entropy": 0.7168443679809571, "actor_grad_norm": 0.10967706888914108, "critic_grad_norm": 0.13726887106895447, "ratio": 0.99984210729599, "entropy": 0.7168443679809571, "incre_win_rate": 0.926829268292683, "step": 957}
{"time": 1767155923.7880597, "phase": "train", "update": 958, "total_env_steps": 3065600, "episode_reward": 0.2548711895942688, "value_loss": 0.0066698607057333, "policy_loss": -0.0016165155995160774, "dist_entropy": 0.7143094658851623, "actor_grad_norm": 0.10884459316730499, "critic_grad_norm": 0.13788631558418274, "ratio": 1.0006250143051147, "entropy": 0.7143094658851623, "incre_win_rate": 0.975609756097561, "step": 958}
{"time": 1767155928.136128, "phase": "train", "update": 959, "total_env_steps": 3068800, "episode_reward": 0.2595488429069519, "value_loss": 0.005485045909881592, "policy_loss": -0.001393363333808395, "dist_entropy": 0.6795705437660218, "actor_grad_norm": 0.09776764363050461, "critic_grad_norm": 0.22919559478759766, "ratio": 0.9994360208511353, "entropy": 0.6795705437660218, "incre_win_rate": 0.9318181818181818, "step": 959}
{"time": 1767155932.4552848, "phase": "train", "update": 960, "total_env_steps": 3072000, "episode_reward": 0.26306912302970886, "value_loss": 0.005905199144035578, "policy_loss": -0.001148747441386888, "dist_entropy": 0.6913426995277405, "actor_grad_norm": 0.09444915503263474, "critic_grad_norm": 0.1016630157828331, "ratio": 1.0001214742660522, "entropy": 0.6913426995277405, "incre_win_rate": 0.9047619047619048, "step": 960}
{"time": 1767155936.7572699, "phase": "train", "update": 961, "total_env_steps": 3075200, "episode_reward": 0.2650579512119293, "value_loss": 0.004901919793337583, "policy_loss": -0.0011664185324669063, "dist_entropy": 0.6695926666259766, "actor_grad_norm": 0.10667242854833603, "critic_grad_norm": 0.10631692409515381, "ratio": 0.9995903968811035, "entropy": 0.6695926666259766, "incre_win_rate": 0.9534883720930233, "step": 961}
{"time": 1767155947.493918, "phase": "eval", "update": 961, "total_env_steps": 3075200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.924875827814567, "step": 961}
{"time": 1767155951.916835, "phase": "train", "update": 962, "total_env_steps": 3078400, "episode_reward": 0.2727110981941223, "value_loss": 0.004244669806212187, "policy_loss": -0.0007440111108209635, "dist_entropy": 0.682960057258606, "actor_grad_norm": 0.09201674908399582, "critic_grad_norm": 0.11457335203886032, "ratio": 0.9998307228088379, "entropy": 0.682960057258606, "incre_win_rate": 0.9772727272727273, "step": 962}
{"time": 1767155956.255259, "phase": "train", "update": 963, "total_env_steps": 3081600, "episode_reward": 0.2469376176595688, "value_loss": 0.011778682284057141, "policy_loss": -0.001075845433231848, "dist_entropy": 0.6887654185295105, "actor_grad_norm": 0.09842847287654877, "critic_grad_norm": 0.21842746436595917, "ratio": 0.9998597502708435, "entropy": 0.6887654185295105, "incre_win_rate": 0.8292682926829268, "step": 963}
{"time": 1767155960.6508417, "phase": "train", "update": 964, "total_env_steps": 3084800, "episode_reward": 0.25423842668533325, "value_loss": 0.007430349662899971, "policy_loss": -0.0008967590237119793, "dist_entropy": 0.6929454445838928, "actor_grad_norm": 0.09276145696640015, "critic_grad_norm": 0.24267326295375824, "ratio": 0.9998588562011719, "entropy": 0.6929454445838928, "incre_win_rate": 0.9512195121951219, "step": 964}
{"time": 1767155964.9842536, "phase": "train", "update": 965, "total_env_steps": 3088000, "episode_reward": 0.26804637908935547, "value_loss": 0.005388487130403519, "policy_loss": -0.001106945646188251, "dist_entropy": 0.6735495090484619, "actor_grad_norm": 0.0986107811331749, "critic_grad_norm": 0.23699116706848145, "ratio": 1.0001707077026367, "entropy": 0.6735495090484619, "incre_win_rate": 0.9555555555555556, "step": 965}
{"time": 1767155969.3299038, "phase": "train", "update": 966, "total_env_steps": 3091200, "episode_reward": 0.2667684257030487, "value_loss": 0.004372050520032644, "policy_loss": -0.0008419756366890851, "dist_entropy": 0.7158605933189393, "actor_grad_norm": 0.08757846802473068, "critic_grad_norm": 0.09028618782758713, "ratio": 0.9999508261680603, "entropy": 0.7158605933189393, "incre_win_rate": 0.9761904761904762, "step": 966}
{"time": 1767155973.6397665, "phase": "train", "update": 967, "total_env_steps": 3094400, "episode_reward": 0.2592601478099823, "value_loss": 0.005220285803079605, "policy_loss": -0.0009445970478232368, "dist_entropy": 0.7152018904685974, "actor_grad_norm": 0.09297537803649902, "critic_grad_norm": 0.22718863189220428, "ratio": 0.9998617172241211, "entropy": 0.7152018904685974, "incre_win_rate": 0.926829268292683, "step": 967}
{"time": 1767155977.918455, "phase": "train", "update": 968, "total_env_steps": 3097600, "episode_reward": 0.2579801082611084, "value_loss": 0.003841204848140478, "policy_loss": -0.0012072058880818303, "dist_entropy": 0.7350890398025512, "actor_grad_norm": 0.10649511963129044, "critic_grad_norm": 0.1553841233253479, "ratio": 1.0001325607299805, "entropy": 0.7350890398025512, "incre_win_rate": 1.0, "step": 968}
{"time": 1767155982.2506413, "phase": "train", "update": 969, "total_env_steps": 3100800, "episode_reward": 0.2480359971523285, "value_loss": 0.006464296579360962, "policy_loss": -0.0011595476751011802, "dist_entropy": 0.7242079496383667, "actor_grad_norm": 0.08811615407466888, "critic_grad_norm": 0.0691584050655365, "ratio": 0.9997893571853638, "entropy": 0.7242079496383667, "incre_win_rate": 0.8780487804878049, "step": 969}
{"time": 1767155986.5845814, "phase": "train", "update": 970, "total_env_steps": 3104000, "episode_reward": 0.25795218348503113, "value_loss": 0.005493005178868771, "policy_loss": -0.0007639317711239712, "dist_entropy": 0.7139567136764526, "actor_grad_norm": 0.09764235466718674, "critic_grad_norm": 0.1992887705564499, "ratio": 1.0001943111419678, "entropy": 0.7139567136764526, "incre_win_rate": 0.9285714285714286, "step": 970}
{"time": 1767155990.9523273, "phase": "train", "update": 971, "total_env_steps": 3107200, "episode_reward": 0.2545478045940399, "value_loss": 0.009500054828822612, "policy_loss": -0.0009642858697091583, "dist_entropy": 0.7102542042732238, "actor_grad_norm": 0.09329671412706375, "critic_grad_norm": 0.13123777508735657, "ratio": 1.0001616477966309, "entropy": 0.7102542042732238, "incre_win_rate": 0.8636363636363636, "step": 971}
{"time": 1767155995.322568, "phase": "train", "update": 972, "total_env_steps": 3110400, "episode_reward": 0.2558184862136841, "value_loss": 0.010261585190892219, "policy_loss": -0.001532998893622306, "dist_entropy": 0.7148122429847718, "actor_grad_norm": 0.07851542532444, "critic_grad_norm": 0.20391562581062317, "ratio": 0.999835193157196, "entropy": 0.7148122429847718, "incre_win_rate": 0.9024390243902439, "step": 972}
{"time": 1767155999.6689868, "phase": "train", "update": 973, "total_env_steps": 3113600, "episode_reward": 0.25748345255851746, "value_loss": 0.01210163701325655, "policy_loss": -0.0011593408818526996, "dist_entropy": 0.7327059268951416, "actor_grad_norm": 0.09209336340427399, "critic_grad_norm": 0.20129011571407318, "ratio": 0.9997366070747375, "entropy": 0.7327059268951416, "incre_win_rate": 0.8809523809523809, "step": 973}
{"time": 1767156003.954574, "phase": "train", "update": 974, "total_env_steps": 3116800, "episode_reward": 0.25224801898002625, "value_loss": 0.008320118300616741, "policy_loss": -0.0011688935782474986, "dist_entropy": 0.7252234578132629, "actor_grad_norm": 0.11602242290973663, "critic_grad_norm": 0.1211525946855545, "ratio": 0.9998241662979126, "entropy": 0.7252234578132629, "incre_win_rate": 0.9047619047619048, "step": 974}
{"time": 1767156008.2431324, "phase": "train", "update": 975, "total_env_steps": 3120000, "episode_reward": 0.24863773584365845, "value_loss": 0.009356076456606388, "policy_loss": -0.0012022774485753729, "dist_entropy": 0.7379971027374268, "actor_grad_norm": 0.11147052049636841, "critic_grad_norm": 0.11345060169696808, "ratio": 0.9998911023139954, "entropy": 0.7379971027374268, "incre_win_rate": 0.9024390243902439, "step": 975}
{"time": 1767156012.5298018, "phase": "train", "update": 976, "total_env_steps": 3123200, "episode_reward": 0.25314778089523315, "value_loss": 0.007132359780371189, "policy_loss": -0.0012877186187733257, "dist_entropy": 0.7150205969810486, "actor_grad_norm": 0.09319000691175461, "critic_grad_norm": 0.19801507890224457, "ratio": 1.0000145435333252, "entropy": 0.7150205969810486, "incre_win_rate": 0.8837209302325582, "step": 976}
{"time": 1767156016.9052143, "phase": "train", "update": 977, "total_env_steps": 3126400, "episode_reward": 0.25874173641204834, "value_loss": 0.007281019818037748, "policy_loss": -0.0014075603185560227, "dist_entropy": 0.7303911209106445, "actor_grad_norm": 0.12308035045862198, "critic_grad_norm": 0.14996977150440216, "ratio": 1.0000393390655518, "entropy": 0.7303911209106445, "incre_win_rate": 0.9523809523809523, "step": 977}
{"time": 1767156021.2593482, "phase": "train", "update": 978, "total_env_steps": 3129600, "episode_reward": 0.26134932041168213, "value_loss": 0.004701013863086701, "policy_loss": -0.0013790902938069394, "dist_entropy": 0.7007896184921265, "actor_grad_norm": 0.10741811245679855, "critic_grad_norm": 0.1103542372584343, "ratio": 1.0000255107879639, "entropy": 0.7007896184921265, "incre_win_rate": 0.926829268292683, "step": 978}
{"time": 1767156025.5523317, "phase": "train", "update": 979, "total_env_steps": 3132800, "episode_reward": 0.25586509704589844, "value_loss": 0.006803748290985822, "policy_loss": -0.0017077488707883503, "dist_entropy": 0.7049461603164673, "actor_grad_norm": 0.09677504748106003, "critic_grad_norm": 0.0716630145907402, "ratio": 1.0001124143600464, "entropy": 0.7049461603164673, "incre_win_rate": 0.9090909090909091, "step": 979}
{"time": 1767156029.8928607, "phase": "train", "update": 980, "total_env_steps": 3136000, "episode_reward": 0.25564828515052795, "value_loss": 0.008383942767977715, "policy_loss": -0.0010193634849230194, "dist_entropy": 0.6918499231338501, "actor_grad_norm": 0.09903603792190552, "critic_grad_norm": 0.08892963826656342, "ratio": 0.9999598860740662, "entropy": 0.6918499231338501, "incre_win_rate": 0.9024390243902439, "step": 980}
{"time": 1767156063.3680837, "phase": "train", "update": 981, "total_env_steps": 3139200, "episode_reward": 0.23737429082393646, "value_loss": 0.048178975284099576, "policy_loss": -0.0012938655769936247, "dist_entropy": 0.70629380941391, "actor_grad_norm": 0.10085319727659225, "critic_grad_norm": 0.29703816771507263, "ratio": 0.9998396039009094, "entropy": 0.70629380941391, "incre_win_rate": 0.8857142857142857, "step": 981}
{"time": 1767156073.9587948, "phase": "eval", "update": 981, "total_env_steps": 3139200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.793253311258276, "step": 981}
{"time": 1767156078.2510018, "phase": "train", "update": 982, "total_env_steps": 3142400, "episode_reward": 0.25647297501564026, "value_loss": 0.006545420736074448, "policy_loss": -0.00131891111797664, "dist_entropy": 0.7223704099655152, "actor_grad_norm": 0.10819516330957413, "critic_grad_norm": 0.26167985796928406, "ratio": 1.0000382661819458, "entropy": 0.7223704099655152, "incre_win_rate": 0.8809523809523809, "step": 982}
{"time": 1767156082.6588926, "phase": "train", "update": 983, "total_env_steps": 3145600, "episode_reward": 0.2562970817089081, "value_loss": 0.005452587455511093, "policy_loss": -0.001133686504447784, "dist_entropy": 0.7315945506095887, "actor_grad_norm": 0.10125740617513657, "critic_grad_norm": 0.20156188309192657, "ratio": 1.0003331899642944, "entropy": 0.7315945506095887, "incre_win_rate": 0.9302325581395349, "step": 983}
{"time": 1767156086.9619715, "phase": "train", "update": 984, "total_env_steps": 3148800, "episode_reward": 0.24178186058998108, "value_loss": 0.009728002361953259, "policy_loss": -0.0012048487309392897, "dist_entropy": 0.7221578240394593, "actor_grad_norm": 0.0856563076376915, "critic_grad_norm": 0.18899928033351898, "ratio": 0.9997791647911072, "entropy": 0.7221578240394593, "incre_win_rate": 0.7894736842105263, "step": 984}
{"time": 1767156091.2939641, "phase": "train", "update": 985, "total_env_steps": 3152000, "episode_reward": 0.2461429238319397, "value_loss": 0.00788912596181035, "policy_loss": -0.0017577184457849171, "dist_entropy": 0.7098830938339233, "actor_grad_norm": 0.1419348120689392, "critic_grad_norm": 0.12130502611398697, "ratio": 0.9996482729911804, "entropy": 0.7098830938339233, "incre_win_rate": 0.8333333333333334, "step": 985}
{"time": 1767156095.657672, "phase": "train", "update": 986, "total_env_steps": 3155200, "episode_reward": 0.25890469551086426, "value_loss": 0.007074933592230081, "policy_loss": -0.0012562735102044087, "dist_entropy": 0.7057197690010071, "actor_grad_norm": 0.10822750627994537, "critic_grad_norm": 0.09563343226909637, "ratio": 1.0000802278518677, "entropy": 0.7057197690010071, "incre_win_rate": 0.9545454545454546, "step": 986}
{"time": 1767156099.9774332, "phase": "train", "update": 987, "total_env_steps": 3158400, "episode_reward": 0.25073108077049255, "value_loss": 0.00800239872187376, "policy_loss": -0.0008606731436888281, "dist_entropy": 0.7136990904808045, "actor_grad_norm": 0.1073470264673233, "critic_grad_norm": 0.0907362774014473, "ratio": 0.9998710751533508, "entropy": 0.7136990904808045, "incre_win_rate": 0.8333333333333334, "step": 987}
{"time": 1767156104.3151748, "phase": "train", "update": 988, "total_env_steps": 3161600, "episode_reward": 0.2580251693725586, "value_loss": 0.009726984798908234, "policy_loss": -0.0009308108447172003, "dist_entropy": 0.7156005859375, "actor_grad_norm": 0.11418377608060837, "critic_grad_norm": 0.16832301020622253, "ratio": 0.9996376037597656, "entropy": 0.7156005859375, "incre_win_rate": 0.9024390243902439, "step": 988}
{"time": 1767156108.621312, "phase": "train", "update": 989, "total_env_steps": 3164800, "episode_reward": 0.25493377447128296, "value_loss": 0.006303457543253899, "policy_loss": -0.0007082643223698781, "dist_entropy": 0.7192677140235901, "actor_grad_norm": 0.1213623508810997, "critic_grad_norm": 0.1341649740934372, "ratio": 0.9998775720596313, "entropy": 0.7192677140235901, "incre_win_rate": 0.9523809523809523, "step": 989}
{"time": 1767156112.950792, "phase": "train", "update": 990, "total_env_steps": 3168000, "episode_reward": 0.24751190841197968, "value_loss": 0.00562500711530447, "policy_loss": -0.001162499286587604, "dist_entropy": 0.7360859870910644, "actor_grad_norm": 0.1096552386879921, "critic_grad_norm": 0.09990312904119492, "ratio": 1.000038981437683, "entropy": 0.7360859870910644, "incre_win_rate": 0.8780487804878049, "step": 990}
{"time": 1767156117.2887762, "phase": "train", "update": 991, "total_env_steps": 3171200, "episode_reward": 0.2617383897304535, "value_loss": 0.005432578455656767, "policy_loss": -0.0008393652958623932, "dist_entropy": 0.7072142243385315, "actor_grad_norm": 0.09268292039632797, "critic_grad_norm": 0.07466884702444077, "ratio": 0.9999205470085144, "entropy": 0.7072142243385315, "incre_win_rate": 0.9523809523809523, "step": 991}
{"time": 1767156121.6069992, "phase": "train", "update": 992, "total_env_steps": 3174400, "episode_reward": 0.24709075689315796, "value_loss": 0.009165734238922595, "policy_loss": -0.0006341182977154247, "dist_entropy": 0.7121753215789794, "actor_grad_norm": 0.11816387623548508, "critic_grad_norm": 0.08012073487043381, "ratio": 0.9999904036521912, "entropy": 0.7121753215789794, "incre_win_rate": 0.8333333333333334, "step": 992}
{"time": 1767156125.938498, "phase": "train", "update": 993, "total_env_steps": 3177600, "episode_reward": 0.2625362277030945, "value_loss": 0.006722223851829768, "policy_loss": -0.00123761090943737, "dist_entropy": 0.7172093749046325, "actor_grad_norm": 0.11890316009521484, "critic_grad_norm": 0.12267246097326279, "ratio": 1.0000054836273193, "entropy": 0.7172093749046325, "incre_win_rate": 0.9523809523809523, "step": 993}
{"time": 1767156130.2550244, "phase": "train", "update": 994, "total_env_steps": 3180800, "episode_reward": 0.24957263469696045, "value_loss": 0.00738234119489789, "policy_loss": -0.0005139351587004626, "dist_entropy": 0.7308012127876282, "actor_grad_norm": 0.12865470349788666, "critic_grad_norm": 0.09800641238689423, "ratio": 1.000367522239685, "entropy": 0.7308012127876282, "incre_win_rate": 0.8571428571428571, "step": 994}
{"time": 1767156134.5740767, "phase": "train", "update": 995, "total_env_steps": 3184000, "episode_reward": 0.26021522283554077, "value_loss": 0.005585108604282141, "policy_loss": -0.001209625670647796, "dist_entropy": 0.7102841019630433, "actor_grad_norm": 0.10407375544309616, "critic_grad_norm": 0.09411009401082993, "ratio": 0.9997051358222961, "entropy": 0.7102841019630433, "incre_win_rate": 0.9761904761904762, "step": 995}
{"time": 1767156138.8684132, "phase": "train", "update": 996, "total_env_steps": 3187200, "episode_reward": 0.24828176200389862, "value_loss": 0.005049430578947067, "policy_loss": -0.0013497595384251327, "dist_entropy": 0.7177503824234008, "actor_grad_norm": 0.10776791721582413, "critic_grad_norm": 0.11866790056228638, "ratio": 0.9997721910476685, "entropy": 0.7177503824234008, "incre_win_rate": 0.9024390243902439, "step": 996}
{"time": 1767156143.204418, "phase": "train", "update": 997, "total_env_steps": 3190400, "episode_reward": 0.2580054998397827, "value_loss": 0.005647536925971508, "policy_loss": -0.0011561118533222725, "dist_entropy": 0.6977483630180359, "actor_grad_norm": 0.09364640712738037, "critic_grad_norm": 0.08377828449010849, "ratio": 1.0000473260879517, "entropy": 0.6977483630180359, "incre_win_rate": 0.9047619047619048, "step": 997}
{"time": 1767156147.4995544, "phase": "train", "update": 998, "total_env_steps": 3193600, "episode_reward": 0.24373604357242584, "value_loss": 0.00856994092464447, "policy_loss": -0.0009750295356397487, "dist_entropy": 0.7007574439048767, "actor_grad_norm": 0.07736080139875412, "critic_grad_norm": 0.07047375291585922, "ratio": 0.9998171925544739, "entropy": 0.7007574439048767, "incre_win_rate": 0.8292682926829268, "step": 998}
{"time": 1767156151.7914543, "phase": "train", "update": 999, "total_env_steps": 3196800, "episode_reward": 0.2621901035308838, "value_loss": 0.009130184911191464, "policy_loss": -0.0012648886901576617, "dist_entropy": 0.6809073686599731, "actor_grad_norm": 0.11705859005451202, "critic_grad_norm": 0.13480065762996674, "ratio": 1.0001589059829712, "entropy": 0.6809073686599731, "incre_win_rate": 0.9024390243902439, "step": 999}
{"time": 1767156156.091025, "phase": "train", "update": 1000, "total_env_steps": 3200000, "episode_reward": 0.2552705705165863, "value_loss": 0.008600460179150105, "policy_loss": -0.0010568311742080283, "dist_entropy": 0.6868184566497803, "actor_grad_norm": 0.10979384183883667, "critic_grad_norm": 0.07690047472715378, "ratio": 0.9998480081558228, "entropy": 0.6868184566497803, "incre_win_rate": 0.9111111111111111, "step": 1000}
{"time": 1767156160.3663518, "phase": "train", "update": 1001, "total_env_steps": 3203200, "episode_reward": 0.24882037937641144, "value_loss": 0.0053657515905797485, "policy_loss": -0.0007149937309330667, "dist_entropy": 0.6916575789451599, "actor_grad_norm": 0.09991014003753662, "critic_grad_norm": 0.07310961931943893, "ratio": 1.0000380277633667, "entropy": 0.6916575789451599, "incre_win_rate": 0.925, "step": 1001}
{"time": 1767156171.2260888, "phase": "eval", "update": 1001, "total_env_steps": 3203200, "eval_win_rate": 0.78125, "eval_episode_reward": 19.10130380794702, "step": 1001}
{"time": 1767156175.5169375, "phase": "train", "update": 1002, "total_env_steps": 3206400, "episode_reward": 0.25812140107154846, "value_loss": 0.004652582667768001, "policy_loss": -0.0007222629374798118, "dist_entropy": 0.7030820965766906, "actor_grad_norm": 0.09793660789728165, "critic_grad_norm": 0.09389559179544449, "ratio": 1.00006103515625, "entropy": 0.7030820965766906, "incre_win_rate": 0.926829268292683, "step": 1002}
{"time": 1767156179.7976742, "phase": "train", "update": 1003, "total_env_steps": 3209600, "episode_reward": 0.2543025612831116, "value_loss": 0.007366260886192322, "policy_loss": -0.0010921251038013224, "dist_entropy": 0.7024073719978332, "actor_grad_norm": 0.10242664813995361, "critic_grad_norm": 0.11166588217020035, "ratio": 0.9997267127037048, "entropy": 0.7024073719978332, "incre_win_rate": 0.8604651162790697, "step": 1003}
{"time": 1767156184.0871978, "phase": "train", "update": 1004, "total_env_steps": 3212800, "episode_reward": 0.2540118098258972, "value_loss": 0.006389417685568333, "policy_loss": -0.0009528136380112073, "dist_entropy": 0.717832350730896, "actor_grad_norm": 0.0726364478468895, "critic_grad_norm": 0.10130200535058975, "ratio": 1.0001482963562012, "entropy": 0.717832350730896, "incre_win_rate": 0.8780487804878049, "step": 1004}
{"time": 1767156188.385868, "phase": "train", "update": 1005, "total_env_steps": 3216000, "episode_reward": 0.2466675341129303, "value_loss": 0.01163675393909216, "policy_loss": -0.0011333448342036867, "dist_entropy": 0.7188505053520202, "actor_grad_norm": 0.07831373065710068, "critic_grad_norm": 0.09475217759609222, "ratio": 1.0000369548797607, "entropy": 0.7188505053520202, "incre_win_rate": 0.8372093023255814, "step": 1005}
{"time": 1767156192.665235, "phase": "train", "update": 1006, "total_env_steps": 3219200, "episode_reward": 0.25528043508529663, "value_loss": 0.007057958282530308, "policy_loss": -0.0010252771058289589, "dist_entropy": 0.7061290383338928, "actor_grad_norm": 0.0879986360669136, "critic_grad_norm": 0.1496477574110031, "ratio": 1.0002554655075073, "entropy": 0.7061290383338928, "incre_win_rate": 0.875, "step": 1006}
{"time": 1767156196.951861, "phase": "train", "update": 1007, "total_env_steps": 3222400, "episode_reward": 0.251800000667572, "value_loss": 0.007181851658970118, "policy_loss": -0.0012571103386499693, "dist_entropy": 0.6965890169143677, "actor_grad_norm": 0.08103421330451965, "critic_grad_norm": 0.16085980832576752, "ratio": 0.9997771382331848, "entropy": 0.6965890169143677, "incre_win_rate": 0.975609756097561, "step": 1007}
{"time": 1767156201.2752497, "phase": "train", "update": 1008, "total_env_steps": 3225600, "episode_reward": 0.25675031542778015, "value_loss": 0.005657920520752669, "policy_loss": -0.0014546746386173482, "dist_entropy": 0.6967947363853455, "actor_grad_norm": 0.08302567899227142, "critic_grad_norm": 0.09262665361166, "ratio": 1.0000375509262085, "entropy": 0.6967947363853455, "incre_win_rate": 0.9285714285714286, "step": 1008}
{"time": 1767156205.584123, "phase": "train", "update": 1009, "total_env_steps": 3228800, "episode_reward": 0.26162251830101013, "value_loss": 0.005888236500322819, "policy_loss": -0.0010736157062936514, "dist_entropy": 0.6831055879592896, "actor_grad_norm": 0.08024749904870987, "critic_grad_norm": 0.09033264964818954, "ratio": 1.0002776384353638, "entropy": 0.6831055879592896, "incre_win_rate": 0.9090909090909091, "step": 1009}
{"time": 1767156209.91827, "phase": "train", "update": 1010, "total_env_steps": 3232000, "episode_reward": 0.2535730302333832, "value_loss": 0.010447565652430057, "policy_loss": -0.0011903433698314814, "dist_entropy": 0.6796175599098205, "actor_grad_norm": 0.08569194376468658, "critic_grad_norm": 0.12242989987134933, "ratio": 0.999984085559845, "entropy": 0.6796175599098205, "incre_win_rate": 0.8333333333333334, "step": 1010}
{"time": 1767156214.2133899, "phase": "train", "update": 1011, "total_env_steps": 3235200, "episode_reward": 0.24923738837242126, "value_loss": 0.01191795039921999, "policy_loss": -0.0012244536968914587, "dist_entropy": 0.7035723686218261, "actor_grad_norm": 0.09508609026670456, "critic_grad_norm": 0.15259984135627747, "ratio": 1.0001344680786133, "entropy": 0.7035723686218261, "incre_win_rate": 0.813953488372093, "step": 1011}
{"time": 1767156218.5008607, "phase": "train", "update": 1012, "total_env_steps": 3238400, "episode_reward": 0.25109580159187317, "value_loss": 0.01099604032933712, "policy_loss": -0.0010762941366934341, "dist_entropy": 0.700583565235138, "actor_grad_norm": 0.08667292445898056, "critic_grad_norm": 0.17169052362442017, "ratio": 1.0001953840255737, "entropy": 0.700583565235138, "incre_win_rate": 0.8536585365853658, "step": 1012}
{"time": 1767156222.8184006, "phase": "train", "update": 1013, "total_env_steps": 3241600, "episode_reward": 0.2548179030418396, "value_loss": 0.011316966637969017, "policy_loss": -0.001113953092989739, "dist_entropy": 0.7345640659332275, "actor_grad_norm": 0.07881530374288559, "critic_grad_norm": 0.17445474863052368, "ratio": 0.9998337030410767, "entropy": 0.7345640659332275, "incre_win_rate": 0.8181818181818182, "step": 1013}
{"time": 1767156227.0889916, "phase": "train", "update": 1014, "total_env_steps": 3244800, "episode_reward": 0.2420276254415512, "value_loss": 0.013285506516695023, "policy_loss": -0.0010098972551716655, "dist_entropy": 0.7253934383392334, "actor_grad_norm": 0.08806826174259186, "critic_grad_norm": 0.19807377457618713, "ratio": 1.0002259016036987, "entropy": 0.7253934383392334, "incre_win_rate": 0.7857142857142857, "step": 1014}
{"time": 1767156231.38314, "phase": "train", "update": 1015, "total_env_steps": 3248000, "episode_reward": 0.2524022161960602, "value_loss": 0.006445251405239105, "policy_loss": -0.0010279722946780368, "dist_entropy": 0.7035541772842407, "actor_grad_norm": 0.08892004936933517, "critic_grad_norm": 0.19829022884368896, "ratio": 1.000022530555725, "entropy": 0.7035541772842407, "incre_win_rate": 0.926829268292683, "step": 1015}
{"time": 1767156235.6730623, "phase": "train", "update": 1016, "total_env_steps": 3251200, "episode_reward": 0.2550418972969055, "value_loss": 0.008052821923047303, "policy_loss": -0.0010788869001634894, "dist_entropy": 0.6875829935073853, "actor_grad_norm": 0.08489104360342026, "critic_grad_norm": 0.17169171571731567, "ratio": 0.9995757937431335, "entropy": 0.6875829935073853, "incre_win_rate": 0.8809523809523809, "step": 1016}
{"time": 1767156239.9370463, "phase": "train", "update": 1017, "total_env_steps": 3254400, "episode_reward": 0.23909611999988556, "value_loss": 0.008892129547894001, "policy_loss": -0.0009806767361534518, "dist_entropy": 0.6843412637710571, "actor_grad_norm": 0.11976449936628342, "critic_grad_norm": 0.0962485745549202, "ratio": 1.0001888275146484, "entropy": 0.6843412637710571, "incre_win_rate": 0.8048780487804879, "step": 1017}
{"time": 1767156244.2530754, "phase": "train", "update": 1018, "total_env_steps": 3257600, "episode_reward": 0.2416483759880066, "value_loss": 0.008717428520321846, "policy_loss": -0.0010554720620859826, "dist_entropy": 0.7109554052352905, "actor_grad_norm": 0.09637486189603806, "critic_grad_norm": 0.12941069900989532, "ratio": 0.9999570846557617, "entropy": 0.7109554052352905, "incre_win_rate": 0.8205128205128205, "step": 1018}
{"time": 1767156248.5284915, "phase": "train", "update": 1019, "total_env_steps": 3260800, "episode_reward": 0.25462645292282104, "value_loss": 0.011454051733016968, "policy_loss": -0.0015719360493058332, "dist_entropy": 0.6847855925559998, "actor_grad_norm": 0.09355857223272324, "critic_grad_norm": 0.12575668096542358, "ratio": 1.000130534172058, "entropy": 0.6847855925559998, "incre_win_rate": 0.8604651162790697, "step": 1019}
{"time": 1767156252.8038762, "phase": "train", "update": 1020, "total_env_steps": 3264000, "episode_reward": 0.23747518658638, "value_loss": 0.011893383599817753, "policy_loss": -0.001326888544262772, "dist_entropy": 0.6776099681854248, "actor_grad_norm": 0.10495442152023315, "critic_grad_norm": 0.09561239182949066, "ratio": 0.9997659921646118, "entropy": 0.6776099681854248, "incre_win_rate": 0.7380952380952381, "step": 1020}
{"time": 1767156257.0877128, "phase": "train", "update": 1021, "total_env_steps": 3267200, "episode_reward": 0.2512499988079071, "value_loss": 0.01145906075835228, "policy_loss": -0.001024791008410375, "dist_entropy": 0.7098809242248535, "actor_grad_norm": 0.06716175377368927, "critic_grad_norm": 0.10396552085876465, "ratio": 1.0002516508102417, "entropy": 0.7098809242248535, "incre_win_rate": 0.875, "step": 1021}
{"time": 1767156267.2469735, "phase": "eval", "update": 1021, "total_env_steps": 3267200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.431601821192054, "step": 1021}
{"time": 1767156271.567602, "phase": "train", "update": 1022, "total_env_steps": 3270400, "episode_reward": 0.25437086820602417, "value_loss": 0.005464631225913763, "policy_loss": -0.000785655187647194, "dist_entropy": 0.7082318782806396, "actor_grad_norm": 0.08328147977590561, "critic_grad_norm": 0.14357848465442657, "ratio": 0.9996353387832642, "entropy": 0.7082318782806396, "incre_win_rate": 0.9285714285714286, "step": 1022}
{"time": 1767156275.8529942, "phase": "train", "update": 1023, "total_env_steps": 3273600, "episode_reward": 0.2556819021701813, "value_loss": 0.006555818021297455, "policy_loss": -0.0010287448437772185, "dist_entropy": 0.7049656391143799, "actor_grad_norm": 0.08524718880653381, "critic_grad_norm": 0.09034732729196548, "ratio": 1.0001552104949951, "entropy": 0.7049656391143799, "incre_win_rate": 0.8636363636363636, "step": 1023}
{"time": 1767156280.1295512, "phase": "train", "update": 1024, "total_env_steps": 3276800, "episode_reward": 0.25930464267730713, "value_loss": 0.0045284852385520935, "policy_loss": -0.0008325177237765047, "dist_entropy": 0.7025069475173951, "actor_grad_norm": 0.08738142251968384, "critic_grad_norm": 0.04738769680261612, "ratio": 0.9997401237487793, "entropy": 0.7025069475173951, "incre_win_rate": 0.9512195121951219, "step": 1024}
{"time": 1767156284.434428, "phase": "train", "update": 1025, "total_env_steps": 3280000, "episode_reward": 0.2516214847564697, "value_loss": 0.006272733863443136, "policy_loss": -0.001328068645089342, "dist_entropy": 0.7134477496147156, "actor_grad_norm": 0.09015554934740067, "critic_grad_norm": 0.036351580172777176, "ratio": 1.000147819519043, "entropy": 0.7134477496147156, "incre_win_rate": 0.875, "step": 1025}
{"time": 1767156288.6491225, "phase": "train", "update": 1026, "total_env_steps": 3283200, "episode_reward": 0.2484685480594635, "value_loss": 0.008782152645289898, "policy_loss": -0.0009646467744232722, "dist_entropy": 0.7125392556190491, "actor_grad_norm": 0.07754969596862793, "critic_grad_norm": 0.06586693972349167, "ratio": 0.9998189210891724, "entropy": 0.7125392556190491, "incre_win_rate": 0.8181818181818182, "step": 1026}
{"time": 1767156292.8512108, "phase": "train", "update": 1027, "total_env_steps": 3286400, "episode_reward": 0.2347702831029892, "value_loss": 0.00941797960549593, "policy_loss": -0.0012565148548556947, "dist_entropy": 0.7002816438674927, "actor_grad_norm": 0.10769148170948029, "critic_grad_norm": 0.2272379845380783, "ratio": 1.000264048576355, "entropy": 0.7002816438674927, "incre_win_rate": 0.7837837837837838, "step": 1027}
{"time": 1767156297.1498837, "phase": "train", "update": 1028, "total_env_steps": 3289600, "episode_reward": 0.24957263469696045, "value_loss": 0.008408153615891933, "policy_loss": -0.0011910904356234654, "dist_entropy": 0.6954132199287415, "actor_grad_norm": 0.09522628784179688, "critic_grad_norm": 0.12441527098417282, "ratio": 0.9997586607933044, "entropy": 0.6954132199287415, "incre_win_rate": 0.813953488372093, "step": 1028}
{"time": 1767156301.4588952, "phase": "train", "update": 1029, "total_env_steps": 3292800, "episode_reward": 0.24097940325737, "value_loss": 0.00918630976229906, "policy_loss": -0.001252110158003461, "dist_entropy": 0.6872409343719482, "actor_grad_norm": 0.09599285572767258, "critic_grad_norm": 0.09124793112277985, "ratio": 1.000104308128357, "entropy": 0.6872409343719482, "incre_win_rate": 0.825, "step": 1029}
{"time": 1767156305.7482927, "phase": "train", "update": 1030, "total_env_steps": 3296000, "episode_reward": 0.25663700699806213, "value_loss": 0.006872575450688601, "policy_loss": -0.0009379053490658152, "dist_entropy": 0.7043089389801025, "actor_grad_norm": 0.10611146688461304, "critic_grad_norm": 0.20230995118618011, "ratio": 0.999578595161438, "entropy": 0.7043089389801025, "incre_win_rate": 0.9047619047619048, "step": 1030}
{"time": 1767156310.0126224, "phase": "train", "update": 1031, "total_env_steps": 3299200, "episode_reward": 0.2641468346118927, "value_loss": 0.003907402930781245, "policy_loss": -0.0010612008745091827, "dist_entropy": 0.6667259812355042, "actor_grad_norm": 0.09227177500724792, "critic_grad_norm": 0.13868585228919983, "ratio": 1.000288724899292, "entropy": 0.6667259812355042, "incre_win_rate": 0.9761904761904762, "step": 1031}
{"time": 1767156314.331467, "phase": "train", "update": 1032, "total_env_steps": 3302400, "episode_reward": 0.2641432285308838, "value_loss": 0.0032072332687675953, "policy_loss": -0.00102505292102677, "dist_entropy": 0.6717275023460388, "actor_grad_norm": 0.08812644332647324, "critic_grad_norm": 0.05002063512802124, "ratio": 0.9999604225158691, "entropy": 0.6717275023460388, "incre_win_rate": 0.975609756097561, "step": 1032}
{"time": 1767156318.6493058, "phase": "train", "update": 1033, "total_env_steps": 3305600, "episode_reward": 0.25847840309143066, "value_loss": 0.004511269740760326, "policy_loss": -0.0009775020925459899, "dist_entropy": 0.6689572334289551, "actor_grad_norm": 0.07926414161920547, "critic_grad_norm": 0.11759133636951447, "ratio": 0.9996775984764099, "entropy": 0.6689572334289551, "incre_win_rate": 0.9111111111111111, "step": 1033}
{"time": 1767156322.9648154, "phase": "train", "update": 1034, "total_env_steps": 3308800, "episode_reward": 0.2630256712436676, "value_loss": 0.004658373165875673, "policy_loss": -0.0011828452399571532, "dist_entropy": 0.6576387524604798, "actor_grad_norm": 0.11407740414142609, "critic_grad_norm": 0.06993801146745682, "ratio": 0.9999997019767761, "entropy": 0.6576387524604798, "incre_win_rate": 0.9761904761904762, "step": 1034}
{"time": 1767156327.2612178, "phase": "train", "update": 1035, "total_env_steps": 3312000, "episode_reward": 0.26015833020210266, "value_loss": 0.004432254005223513, "policy_loss": -0.0010848377244954577, "dist_entropy": 0.6850149869918823, "actor_grad_norm": 0.09629231691360474, "critic_grad_norm": 0.07842972129583359, "ratio": 1.0003174543380737, "entropy": 0.6850149869918823, "incre_win_rate": 0.9523809523809523, "step": 1035}
{"time": 1767156331.5437307, "phase": "train", "update": 1036, "total_env_steps": 3315200, "episode_reward": 0.26406872272491455, "value_loss": 0.005442224070429802, "policy_loss": -0.0012443536113416088, "dist_entropy": 0.663824200630188, "actor_grad_norm": 0.12365692108869553, "critic_grad_norm": 0.07881874591112137, "ratio": 0.999916672706604, "entropy": 0.663824200630188, "incre_win_rate": 0.9318181818181818, "step": 1036}
{"time": 1767156335.84736, "phase": "train", "update": 1037, "total_env_steps": 3318400, "episode_reward": 0.25930774211883545, "value_loss": 0.007630374561995268, "policy_loss": -0.0011009843242248962, "dist_entropy": 0.664204216003418, "actor_grad_norm": 0.09506399929523468, "critic_grad_norm": 0.08631687611341476, "ratio": 0.9999012351036072, "entropy": 0.664204216003418, "incre_win_rate": 0.9024390243902439, "step": 1037}
{"time": 1767156340.101394, "phase": "train", "update": 1038, "total_env_steps": 3321600, "episode_reward": 0.2602369487285614, "value_loss": 0.005107039771974087, "policy_loss": -0.0009977362432458392, "dist_entropy": 0.656971526145935, "actor_grad_norm": 0.08853738009929657, "critic_grad_norm": 0.09571515768766403, "ratio": 1.0000598430633545, "entropy": 0.656971526145935, "incre_win_rate": 0.9302325581395349, "step": 1038}
{"time": 1767156344.3558173, "phase": "train", "update": 1039, "total_env_steps": 3324800, "episode_reward": 0.25922390818595886, "value_loss": 0.005995307862758636, "policy_loss": -0.0010813146955996444, "dist_entropy": 0.6895723223686219, "actor_grad_norm": 0.08344314247369766, "critic_grad_norm": 0.08511044830083847, "ratio": 1.0002180337905884, "entropy": 0.6895723223686219, "incre_win_rate": 0.8863636363636364, "step": 1039}
{"time": 1767156348.6044154, "phase": "train", "update": 1040, "total_env_steps": 3328000, "episode_reward": 0.25901490449905396, "value_loss": 0.005101506318897009, "policy_loss": -0.0010527081031455944, "dist_entropy": 0.6789748191833496, "actor_grad_norm": 0.08362555503845215, "critic_grad_norm": 0.05988016724586487, "ratio": 0.9998327493667603, "entropy": 0.6789748191833496, "incre_win_rate": 0.926829268292683, "step": 1040}
{"time": 1767156352.937186, "phase": "train", "update": 1041, "total_env_steps": 3331200, "episode_reward": 0.2594950497150421, "value_loss": 0.005957311298698187, "policy_loss": -0.0013700048167031298, "dist_entropy": 0.6756473779678345, "actor_grad_norm": 0.10409785807132721, "critic_grad_norm": 0.06674712151288986, "ratio": 0.9993553161621094, "entropy": 0.6756473779678345, "incre_win_rate": 0.9047619047619048, "step": 1041}
{"time": 1767156363.8591204, "phase": "eval", "update": 1041, "total_env_steps": 3331200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.79884105960265, "step": 1041}
{"time": 1767156368.0925112, "phase": "train", "update": 1042, "total_env_steps": 3334400, "episode_reward": 0.2532781660556793, "value_loss": 0.008793114684522152, "policy_loss": -0.0011259508531949792, "dist_entropy": 0.6537191271781921, "actor_grad_norm": 0.10928156226873398, "critic_grad_norm": 0.061056144535541534, "ratio": 0.9998745918273926, "entropy": 0.6537191271781921, "incre_win_rate": 0.8444444444444444, "step": 1042}
{"time": 1767156372.4052484, "phase": "train", "update": 1043, "total_env_steps": 3337600, "episode_reward": 0.2676779627799988, "value_loss": 0.0054783675819635395, "policy_loss": -0.0011058056816885653, "dist_entropy": 0.6764463782310486, "actor_grad_norm": 0.10118072479963303, "critic_grad_norm": 0.08673163503408432, "ratio": 1.0000309944152832, "entropy": 0.6764463782310486, "incre_win_rate": 0.95, "step": 1043}
{"time": 1767156376.642696, "phase": "train", "update": 1044, "total_env_steps": 3340800, "episode_reward": 0.2598308324813843, "value_loss": 0.006254094373434782, "policy_loss": -0.0015295776668423854, "dist_entropy": 0.6570847153663635, "actor_grad_norm": 0.09238363802433014, "critic_grad_norm": 0.07789372652769089, "ratio": 0.9996127486228943, "entropy": 0.6570847153663635, "incre_win_rate": 0.9130434782608695, "step": 1044}
{"time": 1767156380.8686824, "phase": "train", "update": 1045, "total_env_steps": 3344000, "episode_reward": 0.2753331959247589, "value_loss": 0.002910354547202587, "policy_loss": -0.001057703226179285, "dist_entropy": 0.6673909664154053, "actor_grad_norm": 0.1041591688990593, "critic_grad_norm": 0.108241967856884, "ratio": 0.9998976588249207, "entropy": 0.6673909664154053, "incre_win_rate": 1.0, "step": 1045}
{"time": 1767156385.1223197, "phase": "train", "update": 1046, "total_env_steps": 3347200, "episode_reward": 0.2557864487171173, "value_loss": 0.005266765132546425, "policy_loss": -0.0007735888004681612, "dist_entropy": 0.6698316931724548, "actor_grad_norm": 0.08293277770280838, "critic_grad_norm": 0.10727184265851974, "ratio": 0.9998736381530762, "entropy": 0.6698316931724548, "incre_win_rate": 0.9302325581395349, "step": 1046}
{"time": 1767156389.4015408, "phase": "train", "update": 1047, "total_env_steps": 3350400, "episode_reward": 0.25813379883766174, "value_loss": 0.005004932545125485, "policy_loss": -0.0009193875237327731, "dist_entropy": 0.712788188457489, "actor_grad_norm": 0.10184367001056671, "critic_grad_norm": 0.10308434814214706, "ratio": 1.0003503561019897, "entropy": 0.712788188457489, "incre_win_rate": 0.926829268292683, "step": 1047}
{"time": 1767156393.6931345, "phase": "train", "update": 1048, "total_env_steps": 3353600, "episode_reward": 0.25182583928108215, "value_loss": 0.0057783108204603195, "policy_loss": -0.0010953995815925267, "dist_entropy": 0.681160569190979, "actor_grad_norm": 0.10544543713331223, "critic_grad_norm": 0.0748467892408371, "ratio": 1.0000985860824585, "entropy": 0.681160569190979, "incre_win_rate": 0.9090909090909091, "step": 1048}
{"time": 1767156397.9865625, "phase": "train", "update": 1049, "total_env_steps": 3356800, "episode_reward": 0.24984271824359894, "value_loss": 0.007727724500000477, "policy_loss": -0.0014715603308665948, "dist_entropy": 0.6869202852249146, "actor_grad_norm": 0.12682659924030304, "critic_grad_norm": 0.08162594586610794, "ratio": 0.9998963475227356, "entropy": 0.6869202852249146, "incre_win_rate": 0.8536585365853658, "step": 1049}
{"time": 1767156402.2648454, "phase": "train", "update": 1050, "total_env_steps": 3360000, "episode_reward": 0.26137471199035645, "value_loss": 0.007970867957919837, "policy_loss": -0.001402460425279628, "dist_entropy": 0.6828467726707459, "actor_grad_norm": 0.1018633022904396, "critic_grad_norm": 0.036216314882040024, "ratio": 0.999478816986084, "entropy": 0.6828467726707459, "incre_win_rate": 0.9069767441860465, "step": 1050}
{"time": 1767156406.5315177, "phase": "train", "update": 1051, "total_env_steps": 3363200, "episode_reward": 0.26597270369529724, "value_loss": 0.007091769017279148, "policy_loss": -0.0010025076628252805, "dist_entropy": 0.6867656826972961, "actor_grad_norm": 0.08704008907079697, "critic_grad_norm": 0.08593036234378815, "ratio": 0.9998591542243958, "entropy": 0.6867656826972961, "incre_win_rate": 0.9285714285714286, "step": 1051}
{"time": 1767156410.81137, "phase": "train", "update": 1052, "total_env_steps": 3366400, "episode_reward": 0.25966888666152954, "value_loss": 0.006236518081277609, "policy_loss": -0.0011854294277938494, "dist_entropy": 0.7041076421737671, "actor_grad_norm": 0.08748432248830795, "critic_grad_norm": 0.04539211094379425, "ratio": 0.999912679195404, "entropy": 0.7041076421737671, "incre_win_rate": 0.9285714285714286, "step": 1052}
{"time": 1767156415.118565, "phase": "train", "update": 1053, "total_env_steps": 3369600, "episode_reward": 0.26398852467536926, "value_loss": 0.005066587682813406, "policy_loss": -0.001124533454321819, "dist_entropy": 0.6843836903572083, "actor_grad_norm": 0.09260734915733337, "critic_grad_norm": 0.10176863521337509, "ratio": 1.0000638961791992, "entropy": 0.6843836903572083, "incre_win_rate": 0.9333333333333333, "step": 1053}
{"time": 1767156419.342204, "phase": "train", "update": 1054, "total_env_steps": 3372800, "episode_reward": 0.26652732491493225, "value_loss": 0.0022083998192101717, "policy_loss": -0.000827612174404635, "dist_entropy": 0.6806813836097717, "actor_grad_norm": 0.1128905788064003, "critic_grad_norm": 0.060073673725128174, "ratio": 1.0003414154052734, "entropy": 0.6806813836097717, "incre_win_rate": 1.0, "step": 1054}
{"time": 1767156423.6553981, "phase": "train", "update": 1055, "total_env_steps": 3376000, "episode_reward": 0.265579491853714, "value_loss": 0.004855282139033079, "policy_loss": -0.0016234410518620734, "dist_entropy": 0.7046721816062927, "actor_grad_norm": 0.09825774282217026, "critic_grad_norm": 0.11341338604688644, "ratio": 1.000124216079712, "entropy": 0.7046721816062927, "incre_win_rate": 0.9130434782608695, "step": 1055}
{"time": 1767156427.9096615, "phase": "train", "update": 1056, "total_env_steps": 3379200, "episode_reward": 0.2626531720161438, "value_loss": 0.004408098384737968, "policy_loss": -0.0010796112819122072, "dist_entropy": 0.7166309118270874, "actor_grad_norm": 0.08388733863830566, "critic_grad_norm": 0.05578136444091797, "ratio": 1.000527262687683, "entropy": 0.7166309118270874, "incre_win_rate": 0.975609756097561, "step": 1056}
{"time": 1767156432.1427748, "phase": "train", "update": 1057, "total_env_steps": 3382400, "episode_reward": 0.2572164833545685, "value_loss": 0.005389150232076645, "policy_loss": -0.0012887142175209477, "dist_entropy": 0.7275134801864624, "actor_grad_norm": 0.10285919159650803, "critic_grad_norm": 0.048338618129491806, "ratio": 0.999984860420227, "entropy": 0.7275134801864624, "incre_win_rate": 0.8809523809523809, "step": 1057}
{"time": 1767156436.3534985, "phase": "train", "update": 1058, "total_env_steps": 3385600, "episode_reward": 0.24002638459205627, "value_loss": 0.008891072310507297, "policy_loss": -0.0009733976642131381, "dist_entropy": 0.6946294426918029, "actor_grad_norm": 0.10239525139331818, "critic_grad_norm": 0.07398809492588043, "ratio": 1.000132441520691, "entropy": 0.6946294426918029, "incre_win_rate": 0.825, "step": 1058}
{"time": 1767156440.5593457, "phase": "train", "update": 1059, "total_env_steps": 3388800, "episode_reward": 0.25651440024375916, "value_loss": 0.00959074143320322, "policy_loss": -0.0011501765761963156, "dist_entropy": 0.6967156887054443, "actor_grad_norm": 0.10137468576431274, "critic_grad_norm": 0.0636511817574501, "ratio": 0.9999141693115234, "entropy": 0.6967156887054443, "incre_win_rate": 0.8444444444444444, "step": 1059}
{"time": 1767156444.777246, "phase": "train", "update": 1060, "total_env_steps": 3392000, "episode_reward": 0.25415512919425964, "value_loss": 0.008893867395818234, "policy_loss": -0.0012092515865433917, "dist_entropy": 0.6904338359832763, "actor_grad_norm": 0.09871750324964523, "critic_grad_norm": 0.06622206419706345, "ratio": 1.0001922845840454, "entropy": 0.6904338359832763, "incre_win_rate": 0.9024390243902439, "step": 1060}
{"time": 1767156448.9855895, "phase": "train", "update": 1061, "total_env_steps": 3395200, "episode_reward": 0.2506829500198364, "value_loss": 0.007333327550441027, "policy_loss": -0.0009484781923291052, "dist_entropy": 0.695998740196228, "actor_grad_norm": 0.09125663340091705, "critic_grad_norm": 0.06394460052251816, "ratio": 1.0000126361846924, "entropy": 0.695998740196228, "incre_win_rate": 0.8809523809523809, "step": 1061}
{"time": 1767156459.454108, "phase": "eval", "update": 1061, "total_env_steps": 3395200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.928187086092713, "step": 1061}
{"time": 1767156463.655397, "phase": "train", "update": 1062, "total_env_steps": 3398400, "episode_reward": 0.2590811252593994, "value_loss": 0.006063700933009386, "policy_loss": -0.0014091949620024025, "dist_entropy": 0.6776492953300476, "actor_grad_norm": 0.10073738545179367, "critic_grad_norm": 0.1105266809463501, "ratio": 0.9997240304946899, "entropy": 0.6776492953300476, "incre_win_rate": 0.926829268292683, "step": 1062}
{"time": 1767156467.814435, "phase": "train", "update": 1063, "total_env_steps": 3401600, "episode_reward": 0.24905061721801758, "value_loss": 0.0039548097178339955, "policy_loss": -0.001281488622603888, "dist_entropy": 0.6689276933670044, "actor_grad_norm": 0.09464017301797867, "critic_grad_norm": 0.0748346820473671, "ratio": 0.9995658993721008, "entropy": 0.6689276933670044, "incre_win_rate": 0.9487179487179487, "step": 1063}
{"time": 1767156472.055591, "phase": "train", "update": 1064, "total_env_steps": 3404800, "episode_reward": 0.24937863647937775, "value_loss": 0.005854738410562277, "policy_loss": -0.0008126773329827586, "dist_entropy": 0.6863311648368835, "actor_grad_norm": 0.07854018360376358, "critic_grad_norm": 0.07846532016992569, "ratio": 1.0005168914794922, "entropy": 0.6863311648368835, "incre_win_rate": 0.8604651162790697, "step": 1064}
{"time": 1767156476.3042161, "phase": "train", "update": 1065, "total_env_steps": 3408000, "episode_reward": 0.25948935747146606, "value_loss": 0.006461501028388739, "policy_loss": -0.0012901777317900099, "dist_entropy": 0.6776358723640442, "actor_grad_norm": 0.0912298709154129, "critic_grad_norm": 0.11426514387130737, "ratio": 0.9997454881668091, "entropy": 0.6776358723640442, "incre_win_rate": 0.926829268292683, "step": 1065}
{"time": 1767156480.4743605, "phase": "train", "update": 1066, "total_env_steps": 3411200, "episode_reward": 0.2551365792751312, "value_loss": 0.007275279890745878, "policy_loss": -0.001251919695061332, "dist_entropy": 0.6936161279678345, "actor_grad_norm": 0.1091788038611412, "critic_grad_norm": 0.09435989707708359, "ratio": 1.0001108646392822, "entropy": 0.6936161279678345, "incre_win_rate": 0.9069767441860465, "step": 1066}
{"time": 1767156484.6816149, "phase": "train", "update": 1067, "total_env_steps": 3414400, "episode_reward": 0.2583329975605011, "value_loss": 0.006741373892873525, "policy_loss": -0.0012766168918886933, "dist_entropy": 0.6822452664375305, "actor_grad_norm": 0.11571943014860153, "critic_grad_norm": 0.11701061576604843, "ratio": 1.0000766515731812, "entropy": 0.6822452664375305, "incre_win_rate": 0.8809523809523809, "step": 1067}
{"time": 1767156488.8799648, "phase": "train", "update": 1068, "total_env_steps": 3417600, "episode_reward": 0.25462231040000916, "value_loss": 0.007986552082002163, "policy_loss": -0.0008663423628782141, "dist_entropy": 0.6736953020095825, "actor_grad_norm": 0.08896777033805847, "critic_grad_norm": 0.08656851202249527, "ratio": 0.9999958872795105, "entropy": 0.6736953020095825, "incre_win_rate": 0.8837209302325582, "step": 1068}
{"time": 1767156493.0704827, "phase": "train", "update": 1069, "total_env_steps": 3420800, "episode_reward": 0.25010091066360474, "value_loss": 0.006524742487818003, "policy_loss": -0.0013456084355055963, "dist_entropy": 0.6848167300224304, "actor_grad_norm": 0.09175784885883331, "critic_grad_norm": 0.10041500627994537, "ratio": 1.000341534614563, "entropy": 0.6848167300224304, "incre_win_rate": 0.925, "step": 1069}
{"time": 1767156497.3581092, "phase": "train", "update": 1070, "total_env_steps": 3424000, "episode_reward": 0.26504969596862793, "value_loss": 0.005179738067090512, "policy_loss": -0.0012056335502084181, "dist_entropy": 0.6887575626373291, "actor_grad_norm": 0.09079726040363312, "critic_grad_norm": 0.09599493443965912, "ratio": 0.9999004602432251, "entropy": 0.6887575626373291, "incre_win_rate": 0.9761904761904762, "step": 1070}
{"time": 1767156501.6062405, "phase": "train", "update": 1071, "total_env_steps": 3427200, "episode_reward": 0.2505768835544586, "value_loss": 0.00906271506100893, "policy_loss": -0.0013583076397850392, "dist_entropy": 0.6943028450012207, "actor_grad_norm": 0.09153639525175095, "critic_grad_norm": 0.08964283019304276, "ratio": 0.9998882412910461, "entropy": 0.6943028450012207, "incre_win_rate": 0.8604651162790697, "step": 1071}
{"time": 1767156505.9458838, "phase": "train", "update": 1072, "total_env_steps": 3430400, "episode_reward": 0.2614114284515381, "value_loss": 0.005887196306139231, "policy_loss": -0.0012061779038614162, "dist_entropy": 0.7177839756011963, "actor_grad_norm": 0.1288585215806961, "critic_grad_norm": 0.08966568112373352, "ratio": 1.0004419088363647, "entropy": 0.7177839756011963, "incre_win_rate": 0.9302325581395349, "step": 1072}
{"time": 1767156510.246715, "phase": "train", "update": 1073, "total_env_steps": 3433600, "episode_reward": 0.25542113184928894, "value_loss": 0.006664537638425827, "policy_loss": -0.0012196901309131647, "dist_entropy": 0.7346970915794373, "actor_grad_norm": 0.09612628072500229, "critic_grad_norm": 0.09247160702943802, "ratio": 1.0004768371582031, "entropy": 0.7346970915794373, "incre_win_rate": 0.8809523809523809, "step": 1073}
{"time": 1767156514.5442257, "phase": "train", "update": 1074, "total_env_steps": 3436800, "episode_reward": 0.2618046700954437, "value_loss": 0.00444612642750144, "policy_loss": -0.0013630375283341322, "dist_entropy": 0.7354040384292603, "actor_grad_norm": 0.08910851925611496, "critic_grad_norm": 0.05701335892081261, "ratio": 0.9997746348381042, "entropy": 0.7354040384292603, "incre_win_rate": 0.9318181818181818, "step": 1074}
{"time": 1767156518.8533726, "phase": "train", "update": 1075, "total_env_steps": 3440000, "episode_reward": 0.2633454203605652, "value_loss": 0.007495147828012705, "policy_loss": -0.0011145466630670508, "dist_entropy": 0.7444475889205933, "actor_grad_norm": 0.08909922093153, "critic_grad_norm": 0.2009265273809433, "ratio": 0.9998689889907837, "entropy": 0.7444475889205933, "incre_win_rate": 0.8780487804878049, "step": 1075}
{"time": 1767156523.1315165, "phase": "train", "update": 1076, "total_env_steps": 3443200, "episode_reward": 0.2483816295862198, "value_loss": 0.007365561369806528, "policy_loss": -0.0014264058722019968, "dist_entropy": 0.7297807574272156, "actor_grad_norm": 0.1125306636095047, "critic_grad_norm": 0.15445218980312347, "ratio": 0.9999963045120239, "entropy": 0.7297807574272156, "incre_win_rate": 0.8409090909090909, "step": 1076}
{"time": 1767156527.437316, "phase": "train", "update": 1077, "total_env_steps": 3446400, "episode_reward": 0.26025351881980896, "value_loss": 0.005510814022272825, "policy_loss": -0.0014855178608829788, "dist_entropy": 0.7276097297668457, "actor_grad_norm": 0.10622747242450714, "critic_grad_norm": 0.09526745975017548, "ratio": 0.9996916651725769, "entropy": 0.7276097297668457, "incre_win_rate": 0.8780487804878049, "step": 1077}
{"time": 1767156531.7409596, "phase": "train", "update": 1078, "total_env_steps": 3449600, "episode_reward": 0.2565852701663971, "value_loss": 0.007151618599891663, "policy_loss": -0.0014061494537862985, "dist_entropy": 0.7195538401603698, "actor_grad_norm": 0.10720080137252808, "critic_grad_norm": 0.06467552483081818, "ratio": 0.9998125433921814, "entropy": 0.7195538401603698, "incre_win_rate": 0.8372093023255814, "step": 1078}
{"time": 1767156536.0608199, "phase": "train", "update": 1079, "total_env_steps": 3452800, "episode_reward": 0.2674782872200012, "value_loss": 0.006459592562168837, "policy_loss": -0.001075817313812699, "dist_entropy": 0.7095842123031616, "actor_grad_norm": 0.11456475406885147, "critic_grad_norm": 0.11644883453845978, "ratio": 0.9998281598091125, "entropy": 0.7095842123031616, "incre_win_rate": 0.9545454545454546, "step": 1079}
{"time": 1767156540.3358917, "phase": "train", "update": 1080, "total_env_steps": 3456000, "episode_reward": 0.2521047294139862, "value_loss": 0.0057608962059021, "policy_loss": -0.0009297683562870418, "dist_entropy": 0.7093066692352294, "actor_grad_norm": 0.08592378348112106, "critic_grad_norm": 0.07911493629217148, "ratio": 1.0001192092895508, "entropy": 0.7093066692352294, "incre_win_rate": 0.8536585365853658, "step": 1080}
{"time": 1767156544.5750556, "phase": "train", "update": 1081, "total_env_steps": 3459200, "episode_reward": 0.2591390609741211, "value_loss": 0.005391811486333609, "policy_loss": -0.0008369148228076995, "dist_entropy": 0.7105333685874939, "actor_grad_norm": 0.07239089161157608, "critic_grad_norm": 0.11587680876255035, "ratio": 0.9999739527702332, "entropy": 0.7105333685874939, "incre_win_rate": 0.9069767441860465, "step": 1081}
{"time": 1767156554.641001, "phase": "eval", "update": 1081, "total_env_steps": 3459200, "eval_win_rate": 1.0, "eval_episode_reward": 20.0, "step": 1081}
{"time": 1767156558.900407, "phase": "train", "update": 1082, "total_env_steps": 3462400, "episode_reward": 0.25812289118766785, "value_loss": 0.00529579222202301, "policy_loss": -0.0009555899610074192, "dist_entropy": 0.7135541200637817, "actor_grad_norm": 0.0888223648071289, "critic_grad_norm": 0.1001342311501503, "ratio": 0.9999554753303528, "entropy": 0.7135541200637817, "incre_win_rate": 0.9047619047619048, "step": 1082}
{"time": 1767156563.1864517, "phase": "train", "update": 1083, "total_env_steps": 3465600, "episode_reward": 0.24375933408737183, "value_loss": 0.008951916731894017, "policy_loss": -0.0015343610021756326, "dist_entropy": 0.6947417259216309, "actor_grad_norm": 0.1196824237704277, "critic_grad_norm": 0.15995405614376068, "ratio": 0.9999213218688965, "entropy": 0.6947417259216309, "incre_win_rate": 0.7857142857142857, "step": 1083}
{"time": 1767156567.4881613, "phase": "train", "update": 1084, "total_env_steps": 3468800, "episode_reward": 0.24796460568904877, "value_loss": 0.011218268796801567, "policy_loss": -0.0009709240863500668, "dist_entropy": 0.7163189291954041, "actor_grad_norm": 0.10224359482526779, "critic_grad_norm": 0.13368648290634155, "ratio": 1.0000746250152588, "entropy": 0.7163189291954041, "incre_win_rate": 0.7857142857142857, "step": 1084}
{"time": 1767156571.831073, "phase": "train", "update": 1085, "total_env_steps": 3472000, "episode_reward": 0.24665407836437225, "value_loss": 0.00977309662848711, "policy_loss": -0.0017459212140394698, "dist_entropy": 0.7165978074073791, "actor_grad_norm": 0.14626076817512512, "critic_grad_norm": 0.05408253148198128, "ratio": 0.9995723962783813, "entropy": 0.7165978074073791, "incre_win_rate": 0.8536585365853658, "step": 1085}
{"time": 1767156576.141697, "phase": "train", "update": 1086, "total_env_steps": 3475200, "episode_reward": 0.25863099098205566, "value_loss": 0.005916129611432552, "policy_loss": -0.001116895098442683, "dist_entropy": 0.7391515731811523, "actor_grad_norm": 0.11135681718587875, "critic_grad_norm": 0.13680526614189148, "ratio": 0.9992384314537048, "entropy": 0.7391515731811523, "incre_win_rate": 0.9069767441860465, "step": 1086}
{"time": 1767156580.4541106, "phase": "train", "update": 1087, "total_env_steps": 3478400, "episode_reward": 0.25190967321395874, "value_loss": 0.009951396100223064, "policy_loss": -0.0011227124596153715, "dist_entropy": 0.7192865371704101, "actor_grad_norm": 0.08051507920026779, "critic_grad_norm": 0.15746872127056122, "ratio": 0.9999861717224121, "entropy": 0.7192865371704101, "incre_win_rate": 0.7674418604651163, "step": 1087}
{"time": 1767156584.7388134, "phase": "train", "update": 1088, "total_env_steps": 3481600, "episode_reward": 0.2577359080314636, "value_loss": 0.004645234160125256, "policy_loss": -0.0009796976222740561, "dist_entropy": 0.7527135848999024, "actor_grad_norm": 0.13093629479408264, "critic_grad_norm": 0.16557376086711884, "ratio": 1.0001293420791626, "entropy": 0.7527135848999024, "incre_win_rate": 0.9761904761904762, "step": 1088}
{"time": 1767156589.0932474, "phase": "train", "update": 1089, "total_env_steps": 3484800, "episode_reward": 0.2509116232395172, "value_loss": 0.008159564528614282, "policy_loss": -0.0014300382630636932, "dist_entropy": 0.7300809979438782, "actor_grad_norm": 0.11032433807849884, "critic_grad_norm": 0.19431596994400024, "ratio": 0.9996735453605652, "entropy": 0.7300809979438782, "incre_win_rate": 0.8571428571428571, "step": 1089}
{"time": 1767156593.403527, "phase": "train", "update": 1090, "total_env_steps": 3488000, "episode_reward": 0.26131364703178406, "value_loss": 0.00679397601634264, "policy_loss": -0.0012978906957211932, "dist_entropy": 0.7223034620285034, "actor_grad_norm": 0.11617717891931534, "critic_grad_norm": 0.15267987549304962, "ratio": 0.9998413920402527, "entropy": 0.7223034620285034, "incre_win_rate": 0.926829268292683, "step": 1090}
{"time": 1767156597.704758, "phase": "train", "update": 1091, "total_env_steps": 3491200, "episode_reward": 0.2601531445980072, "value_loss": 0.008142992202192546, "policy_loss": -0.0012587313015153256, "dist_entropy": 0.7165091633796692, "actor_grad_norm": 0.1267717480659485, "critic_grad_norm": 0.1315508633852005, "ratio": 0.9997884035110474, "entropy": 0.7165091633796692, "incre_win_rate": 0.9318181818181818, "step": 1091}
{"time": 1767156602.0249026, "phase": "train", "update": 1092, "total_env_steps": 3494400, "episode_reward": 0.2577783465385437, "value_loss": 0.006135781016200781, "policy_loss": -0.0009389697030677269, "dist_entropy": 0.6889935612678528, "actor_grad_norm": 0.08677413314580917, "critic_grad_norm": 0.06932856887578964, "ratio": 0.9999279379844666, "entropy": 0.6889935612678528, "incre_win_rate": 0.9302325581395349, "step": 1092}
{"time": 1767156606.3512847, "phase": "train", "update": 1093, "total_env_steps": 3497600, "episode_reward": 0.25794288516044617, "value_loss": 0.006653446145355702, "policy_loss": -0.001455545436604666, "dist_entropy": 0.6930845022201538, "actor_grad_norm": 0.12031342834234238, "critic_grad_norm": 0.07323286682367325, "ratio": 1.0000793933868408, "entropy": 0.6930845022201538, "incre_win_rate": 0.8571428571428571, "step": 1093}
{"time": 1767156610.6753428, "phase": "train", "update": 1094, "total_env_steps": 3500800, "episode_reward": 0.2561372220516205, "value_loss": 0.0067926525138318535, "policy_loss": -0.0009428567320833636, "dist_entropy": 0.7257043719291687, "actor_grad_norm": 0.0812922939658165, "critic_grad_norm": 0.10288248211145401, "ratio": 0.9998369216918945, "entropy": 0.7257043719291687, "incre_win_rate": 0.9047619047619048, "step": 1094}
{"time": 1767156615.0205586, "phase": "train", "update": 1095, "total_env_steps": 3504000, "episode_reward": 0.25981011986732483, "value_loss": 0.008311891555786132, "policy_loss": -0.0011592140960161145, "dist_entropy": 0.7073283910751342, "actor_grad_norm": 0.0888294130563736, "critic_grad_norm": 0.09594138711690903, "ratio": 1.000147819519043, "entropy": 0.7073283910751342, "incre_win_rate": 0.8571428571428571, "step": 1095}
{"time": 1767156619.2935817, "phase": "train", "update": 1096, "total_env_steps": 3507200, "episode_reward": 0.25142383575439453, "value_loss": 0.011734182201325893, "policy_loss": -0.0011945903002153813, "dist_entropy": 0.7221231102943421, "actor_grad_norm": 0.09107860177755356, "critic_grad_norm": 0.12252571433782578, "ratio": 0.9999899864196777, "entropy": 0.7221231102943421, "incre_win_rate": 0.7954545454545454, "step": 1096}
{"time": 1767156623.6143203, "phase": "train", "update": 1097, "total_env_steps": 3510400, "episode_reward": 0.2596818208694458, "value_loss": 0.009553860314190388, "policy_loss": -0.0012173344351499083, "dist_entropy": 0.730742347240448, "actor_grad_norm": 0.1271187961101532, "critic_grad_norm": 0.16991885006427765, "ratio": 1.0000442266464233, "entropy": 0.730742347240448, "incre_win_rate": 0.8837209302325582, "step": 1097}
{"time": 1767156627.9464774, "phase": "train", "update": 1098, "total_env_steps": 3513600, "episode_reward": 0.2585430443286896, "value_loss": 0.006372396647930145, "policy_loss": -0.0011228920768473927, "dist_entropy": 0.7538034439086914, "actor_grad_norm": 0.09645495563745499, "critic_grad_norm": 0.13874797523021698, "ratio": 1.000206470489502, "entropy": 0.7538034439086914, "incre_win_rate": 0.9047619047619048, "step": 1098}
{"time": 1767156632.2737348, "phase": "train", "update": 1099, "total_env_steps": 3516800, "episode_reward": 0.2450336515903473, "value_loss": 0.00840557310730219, "policy_loss": -0.0014657927400430816, "dist_entropy": 0.7694542646408081, "actor_grad_norm": 0.09175308048725128, "critic_grad_norm": 0.15837673842906952, "ratio": 0.9996291995048523, "entropy": 0.7694542646408081, "incre_win_rate": 0.8292682926829268, "step": 1099}
{"time": 1767156636.559474, "phase": "train", "update": 1100, "total_env_steps": 3520000, "episode_reward": 0.23755018413066864, "value_loss": 0.010584555380046368, "policy_loss": -0.0013526124561206387, "dist_entropy": 0.7418966293334961, "actor_grad_norm": 0.1266038864850998, "critic_grad_norm": 0.16516146063804626, "ratio": 0.9999691843986511, "entropy": 0.7418966293334961, "incre_win_rate": 0.6904761904761905, "step": 1100}
{"time": 1767156640.9248104, "phase": "train", "update": 1101, "total_env_steps": 3523200, "episode_reward": 0.2626603841781616, "value_loss": 0.008468396775424481, "policy_loss": -0.0015058386226981745, "dist_entropy": 0.752474045753479, "actor_grad_norm": 0.10053431987762451, "critic_grad_norm": 0.16895230114459991, "ratio": 0.9999625086784363, "entropy": 0.752474045753479, "incre_win_rate": 0.8636363636363636, "step": 1101}
{"time": 1767156651.389524, "phase": "eval", "update": 1101, "total_env_steps": 3523200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.572175082781456, "step": 1101}
{"time": 1767156655.699021, "phase": "train", "update": 1102, "total_env_steps": 3526400, "episode_reward": 0.25765419006347656, "value_loss": 0.009478347934782505, "policy_loss": -0.001330459052866928, "dist_entropy": 0.7300252318382263, "actor_grad_norm": 0.08487247675657272, "critic_grad_norm": 0.16860051453113556, "ratio": 1.0001057386398315, "entropy": 0.7300252318382263, "incre_win_rate": 0.8372093023255814, "step": 1102}
{"time": 1767156660.020664, "phase": "train", "update": 1103, "total_env_steps": 3529600, "episode_reward": 0.25916802883148193, "value_loss": 0.007694550324231386, "policy_loss": -0.001338162246443808, "dist_entropy": 0.7350180149078369, "actor_grad_norm": 0.12130805104970932, "critic_grad_norm": 0.05304943397641182, "ratio": 1.0001345872879028, "entropy": 0.7350180149078369, "incre_win_rate": 0.9302325581395349, "step": 1103}
{"time": 1767156664.3797913, "phase": "train", "update": 1104, "total_env_steps": 3532800, "episode_reward": 0.2597889006137848, "value_loss": 0.009924975410103797, "policy_loss": -0.001305824776786102, "dist_entropy": 0.7109669089317322, "actor_grad_norm": 0.11234676092863083, "critic_grad_norm": 0.10774637758731842, "ratio": 0.999926745891571, "entropy": 0.7109669089317322, "incre_win_rate": 0.8372093023255814, "step": 1104}
{"time": 1767156668.6825378, "phase": "train", "update": 1105, "total_env_steps": 3536000, "episode_reward": 0.25859686732292175, "value_loss": 0.010800154507160186, "policy_loss": -0.0012922713591080992, "dist_entropy": 0.7020864844322204, "actor_grad_norm": 0.10659521818161011, "critic_grad_norm": 0.12604399025440216, "ratio": 1.0001686811447144, "entropy": 0.7020864844322204, "incre_win_rate": 0.8809523809523809, "step": 1105}
{"time": 1767156672.9852269, "phase": "train", "update": 1106, "total_env_steps": 3539200, "episode_reward": 0.25508278608322144, "value_loss": 0.008844512701034545, "policy_loss": -0.0010194528106893586, "dist_entropy": 0.6901580929756165, "actor_grad_norm": 0.12830953299999237, "critic_grad_norm": 0.07695551961660385, "ratio": 1.0004568099975586, "entropy": 0.6901580929756165, "incre_win_rate": 0.8409090909090909, "step": 1106}
{"time": 1767156677.2919762, "phase": "train", "update": 1107, "total_env_steps": 3542400, "episode_reward": 0.25881361961364746, "value_loss": 0.011052832007408142, "policy_loss": -0.0010582342595185424, "dist_entropy": 0.690283727645874, "actor_grad_norm": 0.1320119947195053, "critic_grad_norm": 0.09492950886487961, "ratio": 0.9992082715034485, "entropy": 0.690283727645874, "incre_win_rate": 0.7906976744186046, "step": 1107}
{"time": 1767156681.590691, "phase": "train", "update": 1108, "total_env_steps": 3545600, "episode_reward": 0.2557072639465332, "value_loss": 0.010744629427790642, "policy_loss": -0.0008871331580493802, "dist_entropy": 0.7133743762969971, "actor_grad_norm": 0.14246125519275665, "critic_grad_norm": 0.10511951893568039, "ratio": 0.999875009059906, "entropy": 0.7133743762969971, "incre_win_rate": 0.8636363636363636, "step": 1108}
{"time": 1767156685.935987, "phase": "train", "update": 1109, "total_env_steps": 3548800, "episode_reward": 0.25660598278045654, "value_loss": 0.00982456337660551, "policy_loss": -0.0010100970429895995, "dist_entropy": 0.6875093102455139, "actor_grad_norm": 0.10556218773126602, "critic_grad_norm": 0.057509880512952805, "ratio": 0.9998745918273926, "entropy": 0.6875093102455139, "incre_win_rate": 0.8372093023255814, "step": 1109}
{"time": 1767156690.2010148, "phase": "train", "update": 1110, "total_env_steps": 3552000, "episode_reward": 0.2589859068393707, "value_loss": 0.00764387110248208, "policy_loss": -0.0011805776399150148, "dist_entropy": 0.6748242378234863, "actor_grad_norm": 0.10265254974365234, "critic_grad_norm": 0.03894886001944542, "ratio": 0.999786376953125, "entropy": 0.6748242378234863, "incre_win_rate": 0.813953488372093, "step": 1110}
{"time": 1767156694.5743985, "phase": "train", "update": 1111, "total_env_steps": 3555200, "episode_reward": 0.2710135877132416, "value_loss": 0.005825830716639757, "policy_loss": -0.0015367341825295532, "dist_entropy": 0.6792323350906372, "actor_grad_norm": 0.0953681468963623, "critic_grad_norm": 0.04363268241286278, "ratio": 0.9996694922447205, "entropy": 0.6792323350906372, "incre_win_rate": 0.9545454545454546, "step": 1111}
{"time": 1767156698.9172647, "phase": "train", "update": 1112, "total_env_steps": 3558400, "episode_reward": 0.255791574716568, "value_loss": 0.008537155389785767, "policy_loss": -0.001458107930157837, "dist_entropy": 0.6859132289886475, "actor_grad_norm": 0.14365050196647644, "critic_grad_norm": 0.13559077680110931, "ratio": 1.0001461505889893, "entropy": 0.6859132289886475, "incre_win_rate": 0.8604651162790697, "step": 1112}
{"time": 1767156703.2287872, "phase": "train", "update": 1113, "total_env_steps": 3561600, "episode_reward": 0.24887779355049133, "value_loss": 0.010206729173660278, "policy_loss": -0.00108924198293181, "dist_entropy": 0.6915349960327148, "actor_grad_norm": 0.13209550082683563, "critic_grad_norm": 0.14346401393413544, "ratio": 1.0000673532485962, "entropy": 0.6915349960327148, "incre_win_rate": 0.7380952380952381, "step": 1113}
{"time": 1767156707.5523736, "phase": "train", "update": 1114, "total_env_steps": 3564800, "episode_reward": 0.2613731324672699, "value_loss": 0.010061532631516457, "policy_loss": -0.0012753132299081927, "dist_entropy": 0.6839692950248718, "actor_grad_norm": 0.09103131294250488, "critic_grad_norm": 0.14799045026302338, "ratio": 1.0002621412277222, "entropy": 0.6839692950248718, "incre_win_rate": 0.9285714285714286, "step": 1114}
{"time": 1767156711.8656893, "phase": "train", "update": 1115, "total_env_steps": 3568000, "episode_reward": 0.26190242171287537, "value_loss": 0.007381038274616003, "policy_loss": -0.0011038590250763037, "dist_entropy": 0.7042773723602295, "actor_grad_norm": 0.10775461047887802, "critic_grad_norm": 0.11149608343839645, "ratio": 0.9997746348381042, "entropy": 0.7042773723602295, "incre_win_rate": 0.9090909090909091, "step": 1115}
{"time": 1767156716.1911492, "phase": "train", "update": 1116, "total_env_steps": 3571200, "episode_reward": 0.26309654116630554, "value_loss": 0.004397288244217634, "policy_loss": -0.0012740206323764269, "dist_entropy": 0.7130980610847473, "actor_grad_norm": 0.09790041297674179, "critic_grad_norm": 0.04662583768367767, "ratio": 0.9999434351921082, "entropy": 0.7130980610847473, "incre_win_rate": 0.9523809523809523, "step": 1116}
{"time": 1767156720.496386, "phase": "train", "update": 1117, "total_env_steps": 3574400, "episode_reward": 0.25151076912879944, "value_loss": 0.00795003417879343, "policy_loss": -0.0012770860331333012, "dist_entropy": 0.6927372813224792, "actor_grad_norm": 0.08546455204486847, "critic_grad_norm": 0.0771983191370964, "ratio": 0.9996181726455688, "entropy": 0.6927372813224792, "incre_win_rate": 0.8636363636363636, "step": 1117}
{"time": 1767156724.8678684, "phase": "train", "update": 1118, "total_env_steps": 3577600, "episode_reward": 0.2634586989879608, "value_loss": 0.006597846839576959, "policy_loss": -0.0010102431992979888, "dist_entropy": 0.7283002018928528, "actor_grad_norm": 0.1111101433634758, "critic_grad_norm": 0.11453395336866379, "ratio": 0.9997197389602661, "entropy": 0.7283002018928528, "incre_win_rate": 0.8809523809523809, "step": 1118}
{"time": 1767156729.2005947, "phase": "train", "update": 1119, "total_env_steps": 3580800, "episode_reward": 0.26333558559417725, "value_loss": 0.006326868571341038, "policy_loss": -0.0013662724498656686, "dist_entropy": 0.7006634831428528, "actor_grad_norm": 0.09307242929935455, "critic_grad_norm": 0.0974450409412384, "ratio": 1.000152587890625, "entropy": 0.7006634831428528, "incre_win_rate": 0.9318181818181818, "step": 1119}
{"time": 1767156733.529858, "phase": "train", "update": 1120, "total_env_steps": 3584000, "episode_reward": 0.25373756885528564, "value_loss": 0.007773236744105816, "policy_loss": -0.0013252636188374467, "dist_entropy": 0.7179498910903931, "actor_grad_norm": 0.10834238678216934, "critic_grad_norm": 0.16684286296367645, "ratio": 0.9999045729637146, "entropy": 0.7179498910903931, "incre_win_rate": 0.85, "step": 1120}
{"time": 1767156737.8027823, "phase": "train", "update": 1121, "total_env_steps": 3587200, "episode_reward": 0.25793877243995667, "value_loss": 0.007186498027294874, "policy_loss": -0.001160198746438823, "dist_entropy": 0.7213353037834167, "actor_grad_norm": 0.08087091147899628, "critic_grad_norm": 0.1116587296128273, "ratio": 1.0003256797790527, "entropy": 0.7213353037834167, "incre_win_rate": 0.9318181818181818, "step": 1121}
{"time": 1767156747.7587998, "phase": "eval", "update": 1121, "total_env_steps": 3587200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.874379139072847, "step": 1121}
{"time": 1767156752.0519822, "phase": "train", "update": 1122, "total_env_steps": 3590400, "episode_reward": 0.2591991126537323, "value_loss": 0.00702528040856123, "policy_loss": -0.001423884017756194, "dist_entropy": 0.6763484239578247, "actor_grad_norm": 0.13559186458587646, "critic_grad_norm": 0.11929609626531601, "ratio": 1.0005639791488647, "entropy": 0.6763484239578247, "incre_win_rate": 0.8636363636363636, "step": 1122}
{"time": 1767156756.3881705, "phase": "train", "update": 1123, "total_env_steps": 3593600, "episode_reward": 0.2619546949863434, "value_loss": 0.0066776138730347155, "policy_loss": -0.0014393569189159905, "dist_entropy": 0.687737226486206, "actor_grad_norm": 0.09301994740962982, "critic_grad_norm": 0.08128836750984192, "ratio": 0.9997208714485168, "entropy": 0.687737226486206, "incre_win_rate": 0.8837209302325582, "step": 1123}
{"time": 1767156760.683488, "phase": "train", "update": 1124, "total_env_steps": 3596800, "episode_reward": 0.25124791264533997, "value_loss": 0.008202513121068478, "policy_loss": -0.0010958766993468317, "dist_entropy": 0.6883963108062744, "actor_grad_norm": 0.1011999249458313, "critic_grad_norm": 0.09377254545688629, "ratio": 0.9999973177909851, "entropy": 0.6883963108062744, "incre_win_rate": 0.8536585365853658, "step": 1124}
{"time": 1767156765.0659335, "phase": "train", "update": 1125, "total_env_steps": 3600000, "episode_reward": 0.2678021490573883, "value_loss": 0.004207569919526577, "policy_loss": -0.0010078463748122602, "dist_entropy": 0.6882784724235534, "actor_grad_norm": 0.10083098709583282, "critic_grad_norm": 0.09201905876398087, "ratio": 1.0001535415649414, "entropy": 0.6882784724235534, "incre_win_rate": 0.9555555555555556, "step": 1125}
{"time": 1767156769.3604822, "phase": "train", "update": 1126, "total_env_steps": 3603200, "episode_reward": 0.2462686151266098, "value_loss": 0.010572200827300548, "policy_loss": -0.0011791392858000905, "dist_entropy": 0.6626408457756042, "actor_grad_norm": 0.09027241915464401, "critic_grad_norm": 0.23565836250782013, "ratio": 0.9994401931762695, "entropy": 0.6626408457756042, "incre_win_rate": 0.8048780487804879, "step": 1126}
{"time": 1767156773.7001193, "phase": "train", "update": 1127, "total_env_steps": 3606400, "episode_reward": 0.2648546099662781, "value_loss": 0.005448641534894705, "policy_loss": -0.0008950309984774307, "dist_entropy": 0.6661124110221863, "actor_grad_norm": 0.08631060272455215, "critic_grad_norm": 0.1391821652650833, "ratio": 1.000125527381897, "entropy": 0.6661124110221863, "incre_win_rate": 0.9090909090909091, "step": 1127}
{"time": 1767156778.0369363, "phase": "train", "update": 1128, "total_env_steps": 3609600, "episode_reward": 0.266597718000412, "value_loss": 0.007213903591036797, "policy_loss": -0.0012692738342813925, "dist_entropy": 0.6342109560966491, "actor_grad_norm": 0.0951998233795166, "critic_grad_norm": 0.0892297551035881, "ratio": 0.9999510645866394, "entropy": 0.6342109560966491, "incre_win_rate": 0.9069767441860465, "step": 1128}
{"time": 1767156782.3337553, "phase": "train", "update": 1129, "total_env_steps": 3612800, "episode_reward": 0.25071918964385986, "value_loss": 0.009793091006577015, "policy_loss": -0.0012974765854014692, "dist_entropy": 0.6342228770256042, "actor_grad_norm": 0.10173103958368301, "critic_grad_norm": 0.10265208780765533, "ratio": 0.9996623396873474, "entropy": 0.6342228770256042, "incre_win_rate": 0.8048780487804879, "step": 1129}
{"time": 1767156786.587906, "phase": "train", "update": 1130, "total_env_steps": 3616000, "episode_reward": 0.25540459156036377, "value_loss": 0.01072826273739338, "policy_loss": -0.0013596096853536466, "dist_entropy": 0.6373944759368897, "actor_grad_norm": 0.10738255828619003, "critic_grad_norm": 0.09155615419149399, "ratio": 0.9998647570610046, "entropy": 0.6373944759368897, "incre_win_rate": 0.8409090909090909, "step": 1130}
{"time": 1767156790.8184936, "phase": "train", "update": 1131, "total_env_steps": 3619200, "episode_reward": 0.2614755928516388, "value_loss": 0.00914541557431221, "policy_loss": -0.0010887214223252784, "dist_entropy": 0.6313500881195069, "actor_grad_norm": 0.11565583944320679, "critic_grad_norm": 0.08342396467924118, "ratio": 0.9999708533287048, "entropy": 0.6313500881195069, "incre_win_rate": 0.8604651162790697, "step": 1131}
{"time": 1767156795.0417576, "phase": "train", "update": 1132, "total_env_steps": 3622400, "episode_reward": 0.2562479078769684, "value_loss": 0.007051939517259598, "policy_loss": -0.0009391287966170836, "dist_entropy": 0.6259616613388062, "actor_grad_norm": 0.09930212050676346, "critic_grad_norm": 0.08721698820590973, "ratio": 1.0000163316726685, "entropy": 0.6259616613388062, "incre_win_rate": 0.8604651162790697, "step": 1132}
{"time": 1767156799.279694, "phase": "train", "update": 1133, "total_env_steps": 3625600, "episode_reward": 0.26754966378211975, "value_loss": 0.006210998632013798, "policy_loss": -0.0009284205021714342, "dist_entropy": 0.6472344160079956, "actor_grad_norm": 0.0857011079788208, "critic_grad_norm": 0.06224947050213814, "ratio": 0.9998764991760254, "entropy": 0.6472344160079956, "incre_win_rate": 0.9090909090909091, "step": 1133}
{"time": 1767156803.490373, "phase": "train", "update": 1134, "total_env_steps": 3628800, "episode_reward": 0.26091471314430237, "value_loss": 0.00668148472905159, "policy_loss": -0.0006341413494624249, "dist_entropy": 0.65084388256073, "actor_grad_norm": 0.08983089029788971, "critic_grad_norm": 0.04059339687228203, "ratio": 1.0002158880233765, "entropy": 0.65084388256073, "incre_win_rate": 0.9318181818181818, "step": 1134}
{"time": 1767156807.8214054, "phase": "train", "update": 1135, "total_env_steps": 3632000, "episode_reward": 0.25438690185546875, "value_loss": 0.009643954038619996, "policy_loss": -0.0010022368014716676, "dist_entropy": 0.6360581636428833, "actor_grad_norm": 0.09032103419303894, "critic_grad_norm": 0.07878584414720535, "ratio": 0.9999562501907349, "entropy": 0.6360581636428833, "incre_win_rate": 0.8333333333333334, "step": 1135}
{"time": 1767156812.156824, "phase": "train", "update": 1136, "total_env_steps": 3635200, "episode_reward": 0.2662293016910553, "value_loss": 0.007606487534940243, "policy_loss": -0.0012176983968871014, "dist_entropy": 0.6464999675750732, "actor_grad_norm": 0.103639617562294, "critic_grad_norm": 0.11913274973630905, "ratio": 0.9994060397148132, "entropy": 0.6464999675750732, "incre_win_rate": 0.9090909090909091, "step": 1136}
{"time": 1767156816.4681144, "phase": "train", "update": 1137, "total_env_steps": 3638400, "episode_reward": 0.25660231709480286, "value_loss": 0.0063101440668106076, "policy_loss": -0.0009814249040363877, "dist_entropy": 0.6625963687896729, "actor_grad_norm": 0.07893303781747818, "critic_grad_norm": 0.10921178013086319, "ratio": 1.0000724792480469, "entropy": 0.6625963687896729, "incre_win_rate": 0.9, "step": 1137}
{"time": 1767156820.831662, "phase": "train", "update": 1138, "total_env_steps": 3641600, "episode_reward": 0.26087382435798645, "value_loss": 0.006790892127901316, "policy_loss": -0.0010233203522673762, "dist_entropy": 0.6674250364303589, "actor_grad_norm": 0.09351187199354172, "critic_grad_norm": 0.088527612388134, "ratio": 0.9995434880256653, "entropy": 0.6674250364303589, "incre_win_rate": 0.9090909090909091, "step": 1138}
{"time": 1767156825.1988504, "phase": "train", "update": 1139, "total_env_steps": 3644800, "episode_reward": 0.26824504137039185, "value_loss": 0.0036377568263560533, "policy_loss": -0.001079627643171399, "dist_entropy": 0.6812347888946533, "actor_grad_norm": 0.08368353545665741, "critic_grad_norm": 0.027201836928725243, "ratio": 0.9999207854270935, "entropy": 0.6812347888946533, "incre_win_rate": 0.9302325581395349, "step": 1139}
{"time": 1767156829.4984348, "phase": "train", "update": 1140, "total_env_steps": 3648000, "episode_reward": 0.2509726583957672, "value_loss": 0.00876691546291113, "policy_loss": -0.0015002690209108493, "dist_entropy": 0.6687740445137024, "actor_grad_norm": 0.13112516701221466, "critic_grad_norm": 0.12216847389936447, "ratio": 0.9999306797981262, "entropy": 0.6687740445137024, "incre_win_rate": 0.8636363636363636, "step": 1140}
{"time": 1767156833.8289459, "phase": "train", "update": 1141, "total_env_steps": 3651200, "episode_reward": 0.2616432011127472, "value_loss": 0.00873538013547659, "policy_loss": -0.0012309596196544703, "dist_entropy": 0.6752095341682434, "actor_grad_norm": 0.08349321037530899, "critic_grad_norm": 0.16698122024536133, "ratio": 0.9995469450950623, "entropy": 0.6752095341682434, "incre_win_rate": 0.8604651162790697, "step": 1141}
{"time": 1767156844.7690063, "phase": "eval", "update": 1141, "total_env_steps": 3651200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.556963990066222, "step": 1141}
{"time": 1767156849.1050694, "phase": "train", "update": 1142, "total_env_steps": 3654400, "episode_reward": 0.2658728361129761, "value_loss": 0.005214353650808334, "policy_loss": -0.0012710123365565096, "dist_entropy": 0.6733181715011597, "actor_grad_norm": 0.08704595267772675, "critic_grad_norm": 0.16612298786640167, "ratio": 1.0000828504562378, "entropy": 0.6733181715011597, "incre_win_rate": 0.926829268292683, "step": 1142}
{"time": 1767156853.468421, "phase": "train", "update": 1143, "total_env_steps": 3657600, "episode_reward": 0.2594541609287262, "value_loss": 0.010044832527637482, "policy_loss": -0.0014334686652112793, "dist_entropy": 0.6679050207138062, "actor_grad_norm": 0.10097723454236984, "critic_grad_norm": 0.2121991217136383, "ratio": 0.9993160367012024, "entropy": 0.6679050207138062, "incre_win_rate": 0.8444444444444444, "step": 1143}
{"time": 1767156882.2929482, "phase": "train", "update": 1144, "total_env_steps": 3660800, "episode_reward": 0.25090646743774414, "value_loss": 0.04751828834414482, "policy_loss": -0.0015379201960485033, "dist_entropy": 0.6728952527046204, "actor_grad_norm": 0.09871824830770493, "critic_grad_norm": 0.4408109784126282, "ratio": 0.9997236132621765, "entropy": 0.6728952527046204, "incre_win_rate": 0.918918918918919, "step": 1144}
{"time": 1767156886.6653945, "phase": "train", "update": 1145, "total_env_steps": 3664000, "episode_reward": 0.2682077884674072, "value_loss": 0.008151833154261112, "policy_loss": -0.0012175676609587072, "dist_entropy": 0.6619452834129333, "actor_grad_norm": 0.1286001056432724, "critic_grad_norm": 0.31124791502952576, "ratio": 1.0001622438430786, "entropy": 0.6619452834129333, "incre_win_rate": 0.9333333333333333, "step": 1145}
{"time": 1767156890.9932563, "phase": "train", "update": 1146, "total_env_steps": 3667200, "episode_reward": 0.2689161002635956, "value_loss": 0.008622475899755955, "policy_loss": -0.0010804632759956689, "dist_entropy": 0.6727245688438416, "actor_grad_norm": 0.08832509070634842, "critic_grad_norm": 0.2553825080394745, "ratio": 0.9999354481697083, "entropy": 0.6727245688438416, "incre_win_rate": 0.9090909090909091, "step": 1146}
{"time": 1767156895.3587992, "phase": "train", "update": 1147, "total_env_steps": 3670400, "episode_reward": 0.26473355293273926, "value_loss": 0.004768722783774137, "policy_loss": -0.0010913614968089292, "dist_entropy": 0.6764538288116455, "actor_grad_norm": 0.08592302352190018, "critic_grad_norm": 0.10297868400812149, "ratio": 0.9997154474258423, "entropy": 0.6764538288116455, "incre_win_rate": 0.9302325581395349, "step": 1147}
{"time": 1767156899.6797707, "phase": "train", "update": 1148, "total_env_steps": 3673600, "episode_reward": 0.2647019922733307, "value_loss": 0.008165882993489504, "policy_loss": -0.0007627447058744963, "dist_entropy": 0.6655371427536011, "actor_grad_norm": 0.07565943151712418, "critic_grad_norm": 0.23160064220428467, "ratio": 0.9996577501296997, "entropy": 0.6655371427536011, "incre_win_rate": 0.926829268292683, "step": 1148}
{"time": 1767156903.9595633, "phase": "train", "update": 1149, "total_env_steps": 3676800, "episode_reward": 0.24367496371269226, "value_loss": 0.009393727593123912, "policy_loss": -0.001486263766565621, "dist_entropy": 0.6539774060249328, "actor_grad_norm": 0.08010577410459518, "critic_grad_norm": 0.16703800857067108, "ratio": 0.9996938705444336, "entropy": 0.6539774060249328, "incre_win_rate": 0.8571428571428571, "step": 1149}
{"time": 1767156908.2744632, "phase": "train", "update": 1150, "total_env_steps": 3680000, "episode_reward": 0.2777814567089081, "value_loss": 0.004996989015489816, "policy_loss": -0.0012064549810403946, "dist_entropy": 0.6550138235092163, "actor_grad_norm": 0.10332081466913223, "critic_grad_norm": 0.20390580594539642, "ratio": 1.000348687171936, "entropy": 0.6550138235092163, "incre_win_rate": 0.9782608695652174, "step": 1150}
{"time": 1767156912.4931474, "phase": "train", "update": 1151, "total_env_steps": 3683200, "episode_reward": 0.2506307065486908, "value_loss": 0.009454448521137238, "policy_loss": -0.0014244854974688082, "dist_entropy": 0.6621658205986023, "actor_grad_norm": 0.12082000076770782, "critic_grad_norm": 0.12252949923276901, "ratio": 1.000367283821106, "entropy": 0.6621658205986023, "incre_win_rate": 0.8461538461538461, "step": 1151}
{"time": 1767156916.7999809, "phase": "train", "update": 1152, "total_env_steps": 3686400, "episode_reward": 0.25610101222991943, "value_loss": 0.00930432640016079, "policy_loss": -0.00146129559585777, "dist_entropy": 0.6724650502204895, "actor_grad_norm": 0.09558043628931046, "critic_grad_norm": 0.19074001908302307, "ratio": 1.000010371208191, "entropy": 0.6724650502204895, "incre_win_rate": 0.8863636363636364, "step": 1152}
{"time": 1767156921.0754533, "phase": "train", "update": 1153, "total_env_steps": 3689600, "episode_reward": 0.2542021870613098, "value_loss": 0.01627599149942398, "policy_loss": -0.0011612373895228956, "dist_entropy": 0.6754339337348938, "actor_grad_norm": 0.10795092582702637, "critic_grad_norm": 0.2922409772872925, "ratio": 0.9995130896568298, "entropy": 0.6754339337348938, "incre_win_rate": 0.8536585365853658, "step": 1153}
{"time": 1767156925.3797622, "phase": "train", "update": 1154, "total_env_steps": 3692800, "episode_reward": 0.26222267746925354, "value_loss": 0.005945255421102047, "policy_loss": -0.0013267341783290477, "dist_entropy": 0.7047280311584473, "actor_grad_norm": 0.10575824230909348, "critic_grad_norm": 0.17704717814922333, "ratio": 0.999686062335968, "entropy": 0.7047280311584473, "incre_win_rate": 0.9130434782608695, "step": 1154}
{"time": 1767156929.6253874, "phase": "train", "update": 1155, "total_env_steps": 3696000, "episode_reward": 0.2584768235683441, "value_loss": 0.006665609683841467, "policy_loss": -0.0014651381805794728, "dist_entropy": 0.7313078999519348, "actor_grad_norm": 0.0919739156961441, "critic_grad_norm": 0.13289731740951538, "ratio": 0.9999217391014099, "entropy": 0.7313078999519348, "incre_win_rate": 0.926829268292683, "step": 1155}
{"time": 1767156933.929127, "phase": "train", "update": 1156, "total_env_steps": 3699200, "episode_reward": 0.25623294711112976, "value_loss": 0.008477414399385453, "policy_loss": -0.0011419577315304962, "dist_entropy": 0.7079834103584289, "actor_grad_norm": 0.13791249692440033, "critic_grad_norm": 0.10643982887268066, "ratio": 0.9997585415840149, "entropy": 0.7079834103584289, "incre_win_rate": 0.8604651162790697, "step": 1156}
{"time": 1767156938.288317, "phase": "train", "update": 1157, "total_env_steps": 3702400, "episode_reward": 0.2539662718772888, "value_loss": 0.0103337399661541, "policy_loss": -0.0011957171046830695, "dist_entropy": 0.7142723202705383, "actor_grad_norm": 0.1046147346496582, "critic_grad_norm": 0.13655193150043488, "ratio": 0.9998742938041687, "entropy": 0.7142723202705383, "incre_win_rate": 0.8095238095238095, "step": 1157}
{"time": 1767156942.6695523, "phase": "train", "update": 1158, "total_env_steps": 3705600, "episode_reward": 0.2683148980140686, "value_loss": 0.005587807763367892, "policy_loss": -0.0008305847916068032, "dist_entropy": 0.6986709475517273, "actor_grad_norm": 0.1293044090270996, "critic_grad_norm": 0.10643558949232101, "ratio": 0.9999486804008484, "entropy": 0.6986709475517273, "incre_win_rate": 0.9111111111111111, "step": 1158}
{"time": 1767156947.0162745, "phase": "train", "update": 1159, "total_env_steps": 3708800, "episode_reward": 0.2619779706001282, "value_loss": 0.00625656321644783, "policy_loss": -0.0012781586900640462, "dist_entropy": 0.6852441310882569, "actor_grad_norm": 0.09310469776391983, "critic_grad_norm": 0.13806907832622528, "ratio": 0.9999475479125977, "entropy": 0.6852441310882569, "incre_win_rate": 0.9047619047619048, "step": 1159}
{"time": 1767156951.3521037, "phase": "train", "update": 1160, "total_env_steps": 3712000, "episode_reward": 0.263123482465744, "value_loss": 0.006128369271755219, "policy_loss": -0.0012452637586179093, "dist_entropy": 0.6710901379585266, "actor_grad_norm": 0.11262533813714981, "critic_grad_norm": 0.11063631623983383, "ratio": 1.0001739263534546, "entropy": 0.6710901379585266, "incre_win_rate": 0.9111111111111111, "step": 1160}
{"time": 1767156955.7007363, "phase": "train", "update": 1161, "total_env_steps": 3715200, "episode_reward": 0.2526816129684448, "value_loss": 0.007210148591548204, "policy_loss": -0.0009249628623926754, "dist_entropy": 0.6865243792533875, "actor_grad_norm": 0.11163178831338882, "critic_grad_norm": 0.06945457309484482, "ratio": 1.0003280639648438, "entropy": 0.6865243792533875, "incre_win_rate": 0.8333333333333334, "step": 1161}
{"time": 1767156966.2914376, "phase": "eval", "update": 1161, "total_env_steps": 3715200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.659975165562912, "step": 1161}
{"time": 1767156970.5399113, "phase": "train", "update": 1162, "total_env_steps": 3718400, "episode_reward": 0.2658029794692993, "value_loss": 0.006460946146398782, "policy_loss": -0.00074110892034156, "dist_entropy": 0.7054078936576843, "actor_grad_norm": 0.09547699242830276, "critic_grad_norm": 0.05809732899069786, "ratio": 0.9999122023582458, "entropy": 0.7054078936576843, "incre_win_rate": 0.9534883720930233, "step": 1162}
{"time": 1767156974.8747025, "phase": "train", "update": 1163, "total_env_steps": 3721600, "episode_reward": 0.2710927128791809, "value_loss": 0.004059271886944771, "policy_loss": -0.0012425100273034673, "dist_entropy": 0.6952614784240723, "actor_grad_norm": 0.10988916456699371, "critic_grad_norm": 0.0679256021976471, "ratio": 0.9997777342796326, "entropy": 0.6952614784240723, "incre_win_rate": 0.9534883720930233, "step": 1163}
{"time": 1767156979.2009819, "phase": "train", "update": 1164, "total_env_steps": 3724800, "episode_reward": 0.25817984342575073, "value_loss": 0.008354492112994194, "policy_loss": -0.001286440245873166, "dist_entropy": 0.6695329666137695, "actor_grad_norm": 0.10693290084600449, "critic_grad_norm": 0.10218998044729233, "ratio": 1.000125765800476, "entropy": 0.6695329666137695, "incre_win_rate": 0.8222222222222222, "step": 1164}
{"time": 1767156983.5096776, "phase": "train", "update": 1165, "total_env_steps": 3728000, "episode_reward": 0.2665185332298279, "value_loss": 0.008802301064133645, "policy_loss": -0.0010836197878234088, "dist_entropy": 0.6716724038124084, "actor_grad_norm": 0.12884363532066345, "critic_grad_norm": 0.06023029237985611, "ratio": 0.999620258808136, "entropy": 0.6716724038124084, "incre_win_rate": 0.8809523809523809, "step": 1165}
{"time": 1767156987.8064885, "phase": "train", "update": 1166, "total_env_steps": 3731200, "episode_reward": 0.25397610664367676, "value_loss": 0.005443734861910343, "policy_loss": -0.0015206402545939301, "dist_entropy": 0.6757121324539185, "actor_grad_norm": 0.10520855337381363, "critic_grad_norm": 0.0499417781829834, "ratio": 0.9996070861816406, "entropy": 0.6757121324539185, "incre_win_rate": 0.9534883720930233, "step": 1166}
{"time": 1767156992.1668036, "phase": "train", "update": 1167, "total_env_steps": 3734400, "episode_reward": 0.2665407657623291, "value_loss": 0.005889981240034104, "policy_loss": -0.0012719609955752277, "dist_entropy": 0.6711542248725891, "actor_grad_norm": 0.09380339831113815, "critic_grad_norm": 0.0871666893362999, "ratio": 0.9999071955680847, "entropy": 0.6711542248725891, "incre_win_rate": 0.9047619047619048, "step": 1167}
{"time": 1767156996.5036862, "phase": "train", "update": 1168, "total_env_steps": 3737600, "episode_reward": 0.2629221975803375, "value_loss": 0.006506532803177834, "policy_loss": -0.0017435571928672289, "dist_entropy": 0.6644615411758423, "actor_grad_norm": 0.09818173944950104, "critic_grad_norm": 0.05985340103507042, "ratio": 0.9998194575309753, "entropy": 0.6644615411758423, "incre_win_rate": 0.9090909090909091, "step": 1168}
{"time": 1767157000.8691998, "phase": "train", "update": 1169, "total_env_steps": 3740800, "episode_reward": 0.2629221975803375, "value_loss": 0.005012741219252348, "policy_loss": -0.0014270015140031233, "dist_entropy": 0.6417698502540589, "actor_grad_norm": 0.07818322628736496, "critic_grad_norm": 0.04992252215743065, "ratio": 1.0001620054244995, "entropy": 0.6417698502540589, "incre_win_rate": 0.9523809523809523, "step": 1169}
{"time": 1767157005.2013288, "phase": "train", "update": 1170, "total_env_steps": 3744000, "episode_reward": 0.2697640657424927, "value_loss": 0.004490750841796398, "policy_loss": -0.0008667090940974731, "dist_entropy": 0.6419882655143738, "actor_grad_norm": 0.08224578946828842, "critic_grad_norm": 0.06314129382371902, "ratio": 0.9999515414237976, "entropy": 0.6419882655143738, "incre_win_rate": 0.9555555555555556, "step": 1170}
{"time": 1767157009.534533, "phase": "train", "update": 1171, "total_env_steps": 3747200, "episode_reward": 0.27330711483955383, "value_loss": 0.004853771440684796, "policy_loss": -0.001256038863127884, "dist_entropy": 0.6406689643859863, "actor_grad_norm": 0.08974054455757141, "critic_grad_norm": 0.06597387045621872, "ratio": 1.0004554986953735, "entropy": 0.6406689643859863, "incre_win_rate": 0.9545454545454546, "step": 1171}
{"time": 1767157013.808199, "phase": "train", "update": 1172, "total_env_steps": 3750400, "episode_reward": 0.26393985748291016, "value_loss": 0.005820082407444716, "policy_loss": -0.0010922524431805415, "dist_entropy": 0.6564074516296386, "actor_grad_norm": 0.10062152147293091, "critic_grad_norm": 0.0913403108716011, "ratio": 1.0000208616256714, "entropy": 0.6564074516296386, "incre_win_rate": 0.8837209302325582, "step": 1172}
{"time": 1767157018.1532292, "phase": "train", "update": 1173, "total_env_steps": 3753600, "episode_reward": 0.27778559923171997, "value_loss": 0.003553264448419213, "policy_loss": -0.001375111074877111, "dist_entropy": 0.6412081241607666, "actor_grad_norm": 0.11559326946735382, "critic_grad_norm": 0.06468906253576279, "ratio": 0.9995020031929016, "entropy": 0.6412081241607666, "incre_win_rate": 1.0, "step": 1173}
{"time": 1767157022.497149, "phase": "train", "update": 1174, "total_env_steps": 3756800, "episode_reward": 0.2625330984592438, "value_loss": 0.009068811126053334, "policy_loss": -0.0010838428398464827, "dist_entropy": 0.6763599634170532, "actor_grad_norm": 0.10527924448251724, "critic_grad_norm": 0.12282319366931915, "ratio": 0.9999937415122986, "entropy": 0.6763599634170532, "incre_win_rate": 0.9523809523809523, "step": 1174}
{"time": 1767157026.8589873, "phase": "train", "update": 1175, "total_env_steps": 3760000, "episode_reward": 0.26661425828933716, "value_loss": 0.007071501947939396, "policy_loss": -0.0012333784485779376, "dist_entropy": 0.6579380631446838, "actor_grad_norm": 0.09930898249149323, "critic_grad_norm": 0.14652669429779053, "ratio": 0.9998863339424133, "entropy": 0.6579380631446838, "incre_win_rate": 0.8863636363636364, "step": 1175}
{"time": 1767157031.16498, "phase": "train", "update": 1176, "total_env_steps": 3763200, "episode_reward": 0.25395283102989197, "value_loss": 0.007874054554849862, "policy_loss": -0.001498526226716912, "dist_entropy": 0.651883316040039, "actor_grad_norm": 0.08692123740911484, "critic_grad_norm": 0.1107020154595375, "ratio": 0.9999210238456726, "entropy": 0.651883316040039, "incre_win_rate": 0.8292682926829268, "step": 1176}
{"time": 1767157035.5068953, "phase": "train", "update": 1177, "total_env_steps": 3766400, "episode_reward": 0.2739444971084595, "value_loss": 0.005146508943289519, "policy_loss": -0.0011210957705614533, "dist_entropy": 0.6682087540626526, "actor_grad_norm": 0.08990318328142166, "critic_grad_norm": 0.06998469680547714, "ratio": 1.000288486480713, "entropy": 0.6682087540626526, "incre_win_rate": 0.9565217391304348, "step": 1177}
{"time": 1767157039.8671541, "phase": "train", "update": 1178, "total_env_steps": 3769600, "episode_reward": 0.2603538930416107, "value_loss": 0.009732820838689805, "policy_loss": -0.0010764221394410356, "dist_entropy": 0.6805213451385498, "actor_grad_norm": 0.1035362109541893, "critic_grad_norm": 0.25196573138237, "ratio": 0.9995471239089966, "entropy": 0.6805213451385498, "incre_win_rate": 0.8863636363636364, "step": 1178}
{"time": 1767157044.2012703, "phase": "train", "update": 1179, "total_env_steps": 3772800, "episode_reward": 0.2552514672279358, "value_loss": 0.010124404914677143, "policy_loss": -0.0011477117405007675, "dist_entropy": 0.690620756149292, "actor_grad_norm": 0.08174432814121246, "critic_grad_norm": 0.22512058913707733, "ratio": 0.9999625086784363, "entropy": 0.690620756149292, "incre_win_rate": 0.8095238095238095, "step": 1179}
{"time": 1767157048.5954816, "phase": "train", "update": 1180, "total_env_steps": 3776000, "episode_reward": 0.26480650901794434, "value_loss": 0.0068154772743582726, "policy_loss": -0.00103424867941726, "dist_entropy": 0.6973498702049256, "actor_grad_norm": 0.10341384261846542, "critic_grad_norm": 0.14952899515628815, "ratio": 0.9999517798423767, "entropy": 0.6973498702049256, "incre_win_rate": 0.9302325581395349, "step": 1180}
{"time": 1767157052.9003265, "phase": "train", "update": 1181, "total_env_steps": 3779200, "episode_reward": 0.26079678535461426, "value_loss": 0.008053046092391014, "policy_loss": -0.001126052302009839, "dist_entropy": 0.6878334760665894, "actor_grad_norm": 0.08996874839067459, "critic_grad_norm": 0.14077675342559814, "ratio": 1.0000555515289307, "entropy": 0.6878334760665894, "incre_win_rate": 0.8809523809523809, "step": 1181}
{"time": 1767157063.592103, "phase": "eval", "update": 1181, "total_env_steps": 3779200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.904232201986755, "step": 1181}
{"time": 1767157067.93047, "phase": "train", "update": 1182, "total_env_steps": 3782400, "episode_reward": 0.2561584413051605, "value_loss": 0.008083700202405453, "policy_loss": -0.0012429538725612587, "dist_entropy": 0.6959299325942994, "actor_grad_norm": 0.10323301702737808, "critic_grad_norm": 0.07757491618394852, "ratio": 1.0000677108764648, "entropy": 0.6959299325942994, "incre_win_rate": 0.9302325581395349, "step": 1182}
{"time": 1767157072.2812443, "phase": "train", "update": 1183, "total_env_steps": 3785600, "episode_reward": 0.26165616512298584, "value_loss": 0.00624890411272645, "policy_loss": -0.0013154218594884526, "dist_entropy": 0.6967166066169739, "actor_grad_norm": 0.0937829241156578, "critic_grad_norm": 0.11087053269147873, "ratio": 0.9998947381973267, "entropy": 0.6967166066169739, "incre_win_rate": 0.8863636363636364, "step": 1183}
{"time": 1767157076.635625, "phase": "train", "update": 1184, "total_env_steps": 3788800, "episode_reward": 0.26133331656455994, "value_loss": 0.006599058862775564, "policy_loss": -0.001307627415479118, "dist_entropy": 0.7108170032501221, "actor_grad_norm": 0.09205533564090729, "critic_grad_norm": 0.09859563410282135, "ratio": 0.9999116063117981, "entropy": 0.7108170032501221, "incre_win_rate": 0.8780487804878049, "step": 1184}
{"time": 1767157080.9783828, "phase": "train", "update": 1185, "total_env_steps": 3792000, "episode_reward": 0.26424410939216614, "value_loss": 0.007103864010423422, "policy_loss": -0.0013244046244196284, "dist_entropy": 0.6881298065185547, "actor_grad_norm": 0.1087082177400589, "critic_grad_norm": 0.04305601865053177, "ratio": 1.0004161596298218, "entropy": 0.6881298065185547, "incre_win_rate": 0.9111111111111111, "step": 1185}
{"time": 1767157085.3497767, "phase": "train", "update": 1186, "total_env_steps": 3795200, "episode_reward": 0.26885607838630676, "value_loss": 0.005681566894054413, "policy_loss": -0.0009402894238455417, "dist_entropy": 0.6873862981796265, "actor_grad_norm": 0.08704610913991928, "critic_grad_norm": 0.11621864140033722, "ratio": 0.999821662902832, "entropy": 0.6873862981796265, "incre_win_rate": 0.9069767441860465, "step": 1186}
{"time": 1767157089.6959724, "phase": "train", "update": 1187, "total_env_steps": 3798400, "episode_reward": 0.26352599263191223, "value_loss": 0.0057932966388762, "policy_loss": -0.0012878469165713113, "dist_entropy": 0.6826289892196655, "actor_grad_norm": 0.10298537462949753, "critic_grad_norm": 0.06329362839460373, "ratio": 0.9999513626098633, "entropy": 0.6826289892196655, "incre_win_rate": 0.9090909090909091, "step": 1187}
{"time": 1767157094.0601964, "phase": "train", "update": 1188, "total_env_steps": 3801600, "episode_reward": 0.27157285809516907, "value_loss": 0.004766528308391571, "policy_loss": -0.0009839317699707807, "dist_entropy": 0.681930685043335, "actor_grad_norm": 0.10082676261663437, "critic_grad_norm": 0.07115546613931656, "ratio": 1.0000704526901245, "entropy": 0.681930685043335, "incre_win_rate": 0.9534883720930233, "step": 1188}
{"time": 1767157098.387859, "phase": "train", "update": 1189, "total_env_steps": 3804800, "episode_reward": 0.2713824510574341, "value_loss": 0.005100068170577288, "policy_loss": -0.0011028796528940177, "dist_entropy": 0.6702658653259277, "actor_grad_norm": 0.10006894916296005, "critic_grad_norm": 0.06511848419904709, "ratio": 1.0001325607299805, "entropy": 0.6702658653259277, "incre_win_rate": 0.9555555555555556, "step": 1189}
{"time": 1767157102.7573893, "phase": "train", "update": 1190, "total_env_steps": 3808000, "episode_reward": 0.27059605717658997, "value_loss": 0.004688695166260004, "policy_loss": -0.001170508696695749, "dist_entropy": 0.6910033226013184, "actor_grad_norm": 0.10583200305700302, "critic_grad_norm": 0.04800619184970856, "ratio": 0.9999763369560242, "entropy": 0.6910033226013184, "incre_win_rate": 0.9767441860465116, "step": 1190}
{"time": 1767157107.1768343, "phase": "train", "update": 1191, "total_env_steps": 3811200, "episode_reward": 0.2690402567386627, "value_loss": 0.00637078182771802, "policy_loss": -0.0014122100792357984, "dist_entropy": 0.6735297679901123, "actor_grad_norm": 0.09492010623216629, "critic_grad_norm": 0.05747046694159508, "ratio": 0.999573826789856, "entropy": 0.6735297679901123, "incre_win_rate": 0.9069767441860465, "step": 1191}
{"time": 1767157111.5314462, "phase": "train", "update": 1192, "total_env_steps": 3814400, "episode_reward": 0.26161783933639526, "value_loss": 0.005851861741393805, "policy_loss": -0.0012174842307624445, "dist_entropy": 0.675472617149353, "actor_grad_norm": 0.09828010946512222, "critic_grad_norm": 0.05197528749704361, "ratio": 0.9997178316116333, "entropy": 0.675472617149353, "incre_win_rate": 0.9069767441860465, "step": 1192}
{"time": 1767157115.8874028, "phase": "train", "update": 1193, "total_env_steps": 3817600, "episode_reward": 0.2525719404220581, "value_loss": 0.0070961276069283485, "policy_loss": -0.0010596898141990608, "dist_entropy": 0.6700048804283142, "actor_grad_norm": 0.09787406772375107, "critic_grad_norm": 0.1295880526304245, "ratio": 1.0001707077026367, "entropy": 0.6700048804283142, "incre_win_rate": 0.8809523809523809, "step": 1193}
{"time": 1767157120.2626975, "phase": "train", "update": 1194, "total_env_steps": 3820800, "episode_reward": 0.2735554575920105, "value_loss": 0.003258513892069459, "policy_loss": -0.001504333296435334, "dist_entropy": 0.6762753009796143, "actor_grad_norm": 0.11946717649698257, "critic_grad_norm": 0.13325853645801544, "ratio": 0.9997981190681458, "entropy": 0.6762753009796143, "incre_win_rate": 0.9565217391304348, "step": 1194}
{"time": 1767157124.593463, "phase": "train", "update": 1195, "total_env_steps": 3824000, "episode_reward": 0.2713162302970886, "value_loss": 0.003451450727880001, "policy_loss": -0.0010746096307613583, "dist_entropy": 0.6623517155647278, "actor_grad_norm": 0.09202144294977188, "critic_grad_norm": 0.10588639229536057, "ratio": 0.9996790885925293, "entropy": 0.6623517155647278, "incre_win_rate": 0.975609756097561, "step": 1195}
{"time": 1767157128.9605865, "phase": "train", "update": 1196, "total_env_steps": 3827200, "episode_reward": 0.26758331060409546, "value_loss": 0.003984631923958659, "policy_loss": -0.0008851808063698785, "dist_entropy": 0.6358376026153565, "actor_grad_norm": 0.09893275797367096, "critic_grad_norm": 0.07679677754640579, "ratio": 1.00021493434906, "entropy": 0.6358376026153565, "incre_win_rate": 0.9347826086956522, "step": 1196}
{"time": 1767157133.3145385, "phase": "train", "update": 1197, "total_env_steps": 3830400, "episode_reward": 0.27006208896636963, "value_loss": 0.003038215544074774, "policy_loss": -0.0011899797589279616, "dist_entropy": 0.6594939947128295, "actor_grad_norm": 0.08556696772575378, "critic_grad_norm": 0.06389253586530685, "ratio": 0.9995611310005188, "entropy": 0.6594939947128295, "incre_win_rate": 0.9523809523809523, "step": 1197}
{"time": 1767157137.6642041, "phase": "train", "update": 1198, "total_env_steps": 3833600, "episode_reward": 0.2679304778575897, "value_loss": 0.004480317700654268, "policy_loss": -0.0010108059868231046, "dist_entropy": 0.6583543419837952, "actor_grad_norm": 0.12132743746042252, "critic_grad_norm": 0.08005762100219727, "ratio": 0.9999529123306274, "entropy": 0.6583543419837952, "incre_win_rate": 0.9555555555555556, "step": 1198}
{"time": 1767157142.0063143, "phase": "train", "update": 1199, "total_env_steps": 3836800, "episode_reward": 0.26615944504737854, "value_loss": 0.005511302128434181, "policy_loss": -0.0015708312260713341, "dist_entropy": 0.6712770342826844, "actor_grad_norm": 0.13177768886089325, "critic_grad_norm": 0.053843867033720016, "ratio": 1.000070571899414, "entropy": 0.6712770342826844, "incre_win_rate": 0.9047619047619048, "step": 1199}
{"time": 1767157146.3488195, "phase": "train", "update": 1200, "total_env_steps": 3840000, "episode_reward": 0.26847267150878906, "value_loss": 0.004315687064081431, "policy_loss": -0.0009501006564043735, "dist_entropy": 0.6706051111221314, "actor_grad_norm": 0.09913971275091171, "critic_grad_norm": 0.0530158169567585, "ratio": 1.0006073713302612, "entropy": 0.6706051111221314, "incre_win_rate": 0.9545454545454546, "step": 1200}
{"time": 1767157150.6817796, "phase": "train", "update": 1201, "total_env_steps": 3843200, "episode_reward": 0.2646854519844055, "value_loss": 0.004029326606541872, "policy_loss": -0.0010164232503178995, "dist_entropy": 0.6476551413536071, "actor_grad_norm": 0.11118916422128677, "critic_grad_norm": 0.05275171622633934, "ratio": 0.9996234774589539, "entropy": 0.6476551413536071, "incre_win_rate": 0.9545454545454546, "step": 1201}
{"time": 1767157161.0144398, "phase": "eval", "update": 1201, "total_env_steps": 3843200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.892591059602648, "step": 1201}
{"time": 1767157165.3112092, "phase": "train", "update": 1202, "total_env_steps": 3846400, "episode_reward": 0.26375827193260193, "value_loss": 0.00499251764267683, "policy_loss": -0.0013913067779661504, "dist_entropy": 0.6571771502494812, "actor_grad_norm": 0.09325927495956421, "critic_grad_norm": 0.07395140081644058, "ratio": 0.9997655749320984, "entropy": 0.6571771502494812, "incre_win_rate": 0.9285714285714286, "step": 1202}
{"time": 1767157169.6176538, "phase": "train", "update": 1203, "total_env_steps": 3849600, "episode_reward": 0.2563762366771698, "value_loss": 0.00477708587422967, "policy_loss": -0.0013451574070757033, "dist_entropy": 0.635588812828064, "actor_grad_norm": 0.09988986700773239, "critic_grad_norm": 0.08158698678016663, "ratio": 1.0001505613327026, "entropy": 0.635588812828064, "incre_win_rate": 0.9523809523809523, "step": 1203}
{"time": 1767157173.9483588, "phase": "train", "update": 1204, "total_env_steps": 3852800, "episode_reward": 0.2625734508037567, "value_loss": 0.00465158075094223, "policy_loss": -0.0009410947730252416, "dist_entropy": 0.6235634922981262, "actor_grad_norm": 0.09883489459753036, "critic_grad_norm": 0.04997323080897331, "ratio": 0.9993848204612732, "entropy": 0.6235634922981262, "incre_win_rate": 0.9047619047619048, "step": 1204}
{"time": 1767157178.2873664, "phase": "train", "update": 1205, "total_env_steps": 3856000, "episode_reward": 0.26824504137039185, "value_loss": 0.006289930082857609, "policy_loss": -0.0009624251716102705, "dist_entropy": 0.6248914241790772, "actor_grad_norm": 0.11756166070699692, "critic_grad_norm": 0.14981716871261597, "ratio": 0.9999040961265564, "entropy": 0.6248914241790772, "incre_win_rate": 0.9555555555555556, "step": 1205}
{"time": 1767157182.5551069, "phase": "train", "update": 1206, "total_env_steps": 3859200, "episode_reward": 0.26562240719795227, "value_loss": 0.007198207918554545, "policy_loss": -0.0011895071570378946, "dist_entropy": 0.635199785232544, "actor_grad_norm": 0.10898605734109879, "critic_grad_norm": 0.09745878726243973, "ratio": 0.9999997019767761, "entropy": 0.635199785232544, "incre_win_rate": 0.8809523809523809, "step": 1206}
{"time": 1767157186.8333488, "phase": "train", "update": 1207, "total_env_steps": 3862400, "episode_reward": 0.27261021733283997, "value_loss": 0.004758194461464882, "policy_loss": -0.0011091082217269844, "dist_entropy": 0.6278805255889892, "actor_grad_norm": 0.09057144075632095, "critic_grad_norm": 0.06254933029413223, "ratio": 0.9999042749404907, "entropy": 0.6278805255889892, "incre_win_rate": 0.9565217391304348, "step": 1207}
{"time": 1767157191.1512365, "phase": "train", "update": 1208, "total_env_steps": 3865600, "episode_reward": 0.26431238651275635, "value_loss": 0.005985910724848509, "policy_loss": -0.00120898590971521, "dist_entropy": 0.6361520528793335, "actor_grad_norm": 0.10682594031095505, "critic_grad_norm": 0.15279348194599152, "ratio": 0.999960720539093, "entropy": 0.6361520528793335, "incre_win_rate": 0.926829268292683, "step": 1208}
{"time": 1767157195.4641366, "phase": "train", "update": 1209, "total_env_steps": 3868800, "episode_reward": 0.27060845494270325, "value_loss": 0.0048927745781838896, "policy_loss": -0.001000660281489285, "dist_entropy": 0.6518201231956482, "actor_grad_norm": 0.10022479295730591, "critic_grad_norm": 0.09821123629808426, "ratio": 0.9998351335525513, "entropy": 0.6518201231956482, "incre_win_rate": 0.9782608695652174, "step": 1209}
{"time": 1767157199.7916083, "phase": "train", "update": 1210, "total_env_steps": 3872000, "episode_reward": 0.26634109020233154, "value_loss": 0.004065396543592214, "policy_loss": -0.0010195610153878932, "dist_entropy": 0.6785419821739197, "actor_grad_norm": 0.08630985766649246, "critic_grad_norm": 0.10482801496982574, "ratio": 0.999885082244873, "entropy": 0.6785419821739197, "incre_win_rate": 0.975609756097561, "step": 1210}
{"time": 1767157204.1544123, "phase": "train", "update": 1211, "total_env_steps": 3875200, "episode_reward": 0.26091423630714417, "value_loss": 0.004772888962179422, "policy_loss": -0.0013745793916772441, "dist_entropy": 0.6809484720230102, "actor_grad_norm": 0.09829661250114441, "critic_grad_norm": 0.10425088554620743, "ratio": 1.0000437498092651, "entropy": 0.6809484720230102, "incre_win_rate": 0.9302325581395349, "step": 1211}
{"time": 1767157208.4998586, "phase": "train", "update": 1212, "total_env_steps": 3878400, "episode_reward": 0.2609768211841583, "value_loss": 0.005819410271942616, "policy_loss": -0.0010673770157907825, "dist_entropy": 0.6805608034133911, "actor_grad_norm": 0.11230559647083282, "critic_grad_norm": 0.05975036695599556, "ratio": 0.9998442530632019, "entropy": 0.6805608034133911, "incre_win_rate": 0.926829268292683, "step": 1212}
{"time": 1767157212.8150873, "phase": "train", "update": 1213, "total_env_steps": 3881600, "episode_reward": 0.2596518099308014, "value_loss": 0.0074891911819577215, "policy_loss": -0.001428545387065583, "dist_entropy": 0.6958867073059082, "actor_grad_norm": 0.10507287085056305, "critic_grad_norm": 0.1431671380996704, "ratio": 0.9998999834060669, "entropy": 0.6958867073059082, "incre_win_rate": 0.8695652173913043, "step": 1213}
{"time": 1767157217.1207983, "phase": "train", "update": 1214, "total_env_steps": 3884800, "episode_reward": 0.26775404810905457, "value_loss": 0.004570907168090344, "policy_loss": -0.0013709174207690467, "dist_entropy": 0.6966831684112549, "actor_grad_norm": 0.09183483570814133, "critic_grad_norm": 0.0944252535700798, "ratio": 0.9997190833091736, "entropy": 0.6966831684112549, "incre_win_rate": 0.9523809523809523, "step": 1214}
{"time": 1767157221.427118, "phase": "train", "update": 1215, "total_env_steps": 3888000, "episode_reward": 0.26631051301956177, "value_loss": 0.004392093513160944, "policy_loss": -0.0018642089794895012, "dist_entropy": 0.6717766880989074, "actor_grad_norm": 0.11564227193593979, "critic_grad_norm": 0.05317620187997818, "ratio": 1.0001134872436523, "entropy": 0.6717766880989074, "incre_win_rate": 0.9318181818181818, "step": 1215}
{"time": 1767157225.7709827, "phase": "train", "update": 1216, "total_env_steps": 3891200, "episode_reward": 0.2617673873901367, "value_loss": 0.008263938128948212, "policy_loss": -0.0010236903655240325, "dist_entropy": 0.6679512858390808, "actor_grad_norm": 0.10603654384613037, "critic_grad_norm": 0.08085615932941437, "ratio": 1.0004777908325195, "entropy": 0.6679512858390808, "incre_win_rate": 0.9090909090909091, "step": 1216}
{"time": 1767157230.1254451, "phase": "train", "update": 1217, "total_env_steps": 3894400, "episode_reward": 0.2609354257583618, "value_loss": 0.00905644204467535, "policy_loss": -0.0008631668954080851, "dist_entropy": 0.6646578073501587, "actor_grad_norm": 0.0998142883181572, "critic_grad_norm": 0.05140118673443794, "ratio": 0.9998815655708313, "entropy": 0.6646578073501587, "incre_win_rate": 0.8780487804878049, "step": 1217}
{"time": 1767157234.4630299, "phase": "train", "update": 1218, "total_env_steps": 3897600, "episode_reward": 0.2707160711288452, "value_loss": 0.00607081763446331, "policy_loss": -0.0011434689061600167, "dist_entropy": 0.6631475448608398, "actor_grad_norm": 0.10207247734069824, "critic_grad_norm": 0.17228008806705475, "ratio": 1.0002601146697998, "entropy": 0.6631475448608398, "incre_win_rate": 0.9772727272727273, "step": 1218}
{"time": 1767157238.7846515, "phase": "train", "update": 1219, "total_env_steps": 3900800, "episode_reward": 0.25822898745536804, "value_loss": 0.006566819176077843, "policy_loss": -0.001090231450902479, "dist_entropy": 0.6887957453727722, "actor_grad_norm": 0.08521553874015808, "critic_grad_norm": 0.1481775939464569, "ratio": 0.9997376799583435, "entropy": 0.6887957453727722, "incre_win_rate": 0.8636363636363636, "step": 1219}
{"time": 1767157243.1454442, "phase": "train", "update": 1220, "total_env_steps": 3904000, "episode_reward": 0.25860100984573364, "value_loss": 0.010225363820791245, "policy_loss": -0.0013434016570144536, "dist_entropy": 0.7062859058380127, "actor_grad_norm": 0.0874708890914917, "critic_grad_norm": 0.12771177291870117, "ratio": 0.9998732805252075, "entropy": 0.7062859058380127, "incre_win_rate": 0.8636363636363636, "step": 1220}
{"time": 1767157247.4759297, "phase": "train", "update": 1221, "total_env_steps": 3907200, "episode_reward": 0.266119122505188, "value_loss": 0.0060280970297753814, "policy_loss": -0.0012177004757518261, "dist_entropy": 0.7211989521980285, "actor_grad_norm": 0.1004694476723671, "critic_grad_norm": 0.06849592179059982, "ratio": 0.9999822974205017, "entropy": 0.7211989521980285, "incre_win_rate": 0.926829268292683, "step": 1221}
{"time": 1767157257.9895678, "phase": "eval", "update": 1221, "total_env_steps": 3907200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.863203642384104, "step": 1221}
{"time": 1767157262.3065786, "phase": "train", "update": 1222, "total_env_steps": 3910400, "episode_reward": 0.26139071583747864, "value_loss": 0.007389631401747465, "policy_loss": -0.001572061684758097, "dist_entropy": 0.705654752254486, "actor_grad_norm": 0.10455725342035294, "critic_grad_norm": 0.03473299741744995, "ratio": 1.0001273155212402, "entropy": 0.705654752254486, "incre_win_rate": 0.9111111111111111, "step": 1222}
{"time": 1767157266.6166275, "phase": "train", "update": 1223, "total_env_steps": 3913600, "episode_reward": 0.2499161958694458, "value_loss": 0.012807813473045826, "policy_loss": -0.0012803515101907693, "dist_entropy": 0.6979178667068482, "actor_grad_norm": 0.11979683488607407, "critic_grad_norm": 0.1790780872106552, "ratio": 0.9996245503425598, "entropy": 0.6979178667068482, "incre_win_rate": 0.7560975609756098, "step": 1223}
{"time": 1767157270.9588795, "phase": "train", "update": 1224, "total_env_steps": 3916800, "episode_reward": 0.26624172925949097, "value_loss": 0.0046159857884049416, "policy_loss": -0.0013239703610488096, "dist_entropy": 0.7422686576843261, "actor_grad_norm": 0.1156075969338417, "critic_grad_norm": 0.12420132011175156, "ratio": 0.9999406933784485, "entropy": 0.7422686576843261, "incre_win_rate": 0.9130434782608695, "step": 1224}
{"time": 1767157275.2941697, "phase": "train", "update": 1225, "total_env_steps": 3920000, "episode_reward": 0.26783835887908936, "value_loss": 0.005733778048306703, "policy_loss": -0.0010110817575039732, "dist_entropy": 0.7494263529777527, "actor_grad_norm": 0.08161287009716034, "critic_grad_norm": 0.08922356367111206, "ratio": 1.0000925064086914, "entropy": 0.7494263529777527, "incre_win_rate": 0.9545454545454546, "step": 1225}
{"time": 1767157279.6011505, "phase": "train", "update": 1226, "total_env_steps": 3923200, "episode_reward": 0.2492130696773529, "value_loss": 0.008410241268575192, "policy_loss": -0.0009725173983852642, "dist_entropy": 0.7569847226142883, "actor_grad_norm": 0.08104390650987625, "critic_grad_norm": 0.14275406301021576, "ratio": 1.0000090599060059, "entropy": 0.7569847226142883, "incre_win_rate": 0.8333333333333334, "step": 1226}
{"time": 1767157283.9360974, "phase": "train", "update": 1227, "total_env_steps": 3926400, "episode_reward": 0.24836091697216034, "value_loss": 0.006369690783321858, "policy_loss": -0.0012907212408984846, "dist_entropy": 0.73953777551651, "actor_grad_norm": 0.09084060788154602, "critic_grad_norm": 0.0986337661743164, "ratio": 0.9995611310005188, "entropy": 0.73953777551651, "incre_win_rate": 0.8717948717948718, "step": 1227}
{"time": 1767157288.2757456, "phase": "train", "update": 1228, "total_env_steps": 3929600, "episode_reward": 0.2556741237640381, "value_loss": 0.01104391012340784, "policy_loss": -0.001574721767183007, "dist_entropy": 0.7287084579467773, "actor_grad_norm": 0.1200786605477333, "critic_grad_norm": 0.05621124431490898, "ratio": 1.0001401901245117, "entropy": 0.7287084579467773, "incre_win_rate": 0.8604651162790697, "step": 1228}
{"time": 1767157292.5803242, "phase": "train", "update": 1229, "total_env_steps": 3932800, "episode_reward": 0.2537210285663605, "value_loss": 0.010858066007494926, "policy_loss": -0.0011380562125019368, "dist_entropy": 0.7079954981803894, "actor_grad_norm": 0.11624538898468018, "critic_grad_norm": 0.07079984992742538, "ratio": 1.0000275373458862, "entropy": 0.7079954981803894, "incre_win_rate": 0.8, "step": 1229}
{"time": 1767157296.8904119, "phase": "train", "update": 1230, "total_env_steps": 3936000, "episode_reward": 0.2634369730949402, "value_loss": 0.008974256552755832, "policy_loss": -0.0007311946516004753, "dist_entropy": 0.7090046167373657, "actor_grad_norm": 0.09802746027708054, "critic_grad_norm": 0.10395479202270508, "ratio": 1.0003232955932617, "entropy": 0.7090046167373657, "incre_win_rate": 0.9285714285714286, "step": 1230}
{"time": 1767157301.219692, "phase": "train", "update": 1231, "total_env_steps": 3939200, "episode_reward": 0.2500610649585724, "value_loss": 0.009959758631885052, "policy_loss": -0.0010700135322622372, "dist_entropy": 0.6985023498535157, "actor_grad_norm": 0.11863380670547485, "critic_grad_norm": 0.10189087688922882, "ratio": 0.9995679259300232, "entropy": 0.6985023498535157, "incre_win_rate": 0.8333333333333334, "step": 1231}
{"time": 1767157305.5396237, "phase": "train", "update": 1232, "total_env_steps": 3942400, "episode_reward": 0.2613658905029297, "value_loss": 0.004114476870745421, "policy_loss": -0.0013464349615798898, "dist_entropy": 0.7090831875801087, "actor_grad_norm": 0.11588549613952637, "critic_grad_norm": 0.10175633430480957, "ratio": 1.0000211000442505, "entropy": 0.7090831875801087, "incre_win_rate": 0.9512195121951219, "step": 1232}
{"time": 1767157309.8742828, "phase": "train", "update": 1233, "total_env_steps": 3945600, "episode_reward": 0.25161993503570557, "value_loss": 0.007902325317263603, "policy_loss": -0.000997155726957999, "dist_entropy": 0.6693784117698669, "actor_grad_norm": 0.11930064111948013, "critic_grad_norm": 0.07433267682790756, "ratio": 0.9999526143074036, "entropy": 0.6693784117698669, "incre_win_rate": 0.8666666666666667, "step": 1233}
{"time": 1767157314.195037, "phase": "train", "update": 1234, "total_env_steps": 3948800, "episode_reward": 0.26319122314453125, "value_loss": 0.005919346027076245, "policy_loss": -0.0010234713033000276, "dist_entropy": 0.6901022553443908, "actor_grad_norm": 0.12468794733285904, "critic_grad_norm": 0.15603473782539368, "ratio": 0.9998618364334106, "entropy": 0.6901022553443908, "incre_win_rate": 0.9047619047619048, "step": 1234}
{"time": 1767157318.5107772, "phase": "train", "update": 1235, "total_env_steps": 3952000, "episode_reward": 0.2555670440196991, "value_loss": 0.0060272512026131155, "policy_loss": -0.0010512303540302526, "dist_entropy": 0.6794842123985291, "actor_grad_norm": 0.10009949654340744, "critic_grad_norm": 0.11385171860456467, "ratio": 0.9998193979263306, "entropy": 0.6794842123985291, "incre_win_rate": 0.9230769230769231, "step": 1235}
{"time": 1767157322.7974534, "phase": "train", "update": 1236, "total_env_steps": 3955200, "episode_reward": 0.25192001461982727, "value_loss": 0.007492277305573225, "policy_loss": -0.001092322010626745, "dist_entropy": 0.6936409592628479, "actor_grad_norm": 0.10305758565664291, "critic_grad_norm": 0.14342056214809418, "ratio": 0.9998664855957031, "entropy": 0.6936409592628479, "incre_win_rate": 0.8409090909090909, "step": 1236}
{"time": 1767157327.1064456, "phase": "train", "update": 1237, "total_env_steps": 3958400, "episode_reward": 0.2528989017009735, "value_loss": 0.006640923861414194, "policy_loss": -0.0008285516746695976, "dist_entropy": 0.6845310688018799, "actor_grad_norm": 0.0920572578907013, "critic_grad_norm": 0.06209038570523262, "ratio": 0.9997628331184387, "entropy": 0.6845310688018799, "incre_win_rate": 0.8837209302325582, "step": 1237}
{"time": 1767157331.4721773, "phase": "train", "update": 1238, "total_env_steps": 3961600, "episode_reward": 0.26253417134284973, "value_loss": 0.006697770953178406, "policy_loss": -0.001003509852255746, "dist_entropy": 0.6875282287597656, "actor_grad_norm": 0.09384193271398544, "critic_grad_norm": 0.0440179668366909, "ratio": 1.0000675916671753, "entropy": 0.6875282287597656, "incre_win_rate": 0.8809523809523809, "step": 1238}
{"time": 1767157335.7767863, "phase": "train", "update": 1239, "total_env_steps": 3964800, "episode_reward": 0.25437602400779724, "value_loss": 0.009902232885360717, "policy_loss": -0.0012672352035018263, "dist_entropy": 0.6848504066467285, "actor_grad_norm": 0.09820225089788437, "critic_grad_norm": 0.06934094429016113, "ratio": 0.999950110912323, "entropy": 0.6848504066467285, "incre_win_rate": 0.8604651162790697, "step": 1239}
{"time": 1767157340.078439, "phase": "train", "update": 1240, "total_env_steps": 3968000, "episode_reward": 0.2601800560951233, "value_loss": 0.0055885427631437775, "policy_loss": -0.0008879889027809895, "dist_entropy": 0.6895759344100952, "actor_grad_norm": 0.09080805629491806, "critic_grad_norm": 0.05080472305417061, "ratio": 1.0000333786010742, "entropy": 0.6895759344100952, "incre_win_rate": 0.9047619047619048, "step": 1240}
{"time": 1767157344.376928, "phase": "train", "update": 1241, "total_env_steps": 3971200, "episode_reward": 0.2637169063091278, "value_loss": 0.006852720305323601, "policy_loss": -0.0011598803624252696, "dist_entropy": 0.6681286811828613, "actor_grad_norm": 0.08518469333648682, "critic_grad_norm": 0.0644736960530281, "ratio": 0.9998134970664978, "entropy": 0.6681286811828613, "incre_win_rate": 0.9534883720930233, "step": 1241}
{"time": 1767157354.710233, "phase": "eval", "update": 1241, "total_env_steps": 3971200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.890780215231786, "step": 1241}
{"time": 1767157359.0373888, "phase": "train", "update": 1242, "total_env_steps": 3974400, "episode_reward": 0.2581586241722107, "value_loss": 0.009028354473412038, "policy_loss": -0.0012955971180247162, "dist_entropy": 0.6707016587257385, "actor_grad_norm": 0.1372550129890442, "critic_grad_norm": 0.0687100887298584, "ratio": 0.9999790191650391, "entropy": 0.6707016587257385, "incre_win_rate": 0.8863636363636364, "step": 1242}
{"time": 1767157363.3601258, "phase": "train", "update": 1243, "total_env_steps": 3977600, "episode_reward": 0.25781145691871643, "value_loss": 0.007331241574138403, "policy_loss": -0.001466403763099322, "dist_entropy": 0.6467323422431945, "actor_grad_norm": 0.12451878935098648, "critic_grad_norm": 0.11449455469846725, "ratio": 0.9999937415122986, "entropy": 0.6467323422431945, "incre_win_rate": 0.9047619047619048, "step": 1243}
{"time": 1767157367.673455, "phase": "train", "update": 1244, "total_env_steps": 3980800, "episode_reward": 0.26563793420791626, "value_loss": 0.007396722119301558, "policy_loss": -0.0012273905961976083, "dist_entropy": 0.6624209523200989, "actor_grad_norm": 0.10950040817260742, "critic_grad_norm": 0.1031753420829773, "ratio": 1.0001991987228394, "entropy": 0.6624209523200989, "incre_win_rate": 0.9318181818181818, "step": 1244}
{"time": 1767157372.0060196, "phase": "train", "update": 1245, "total_env_steps": 3984000, "episode_reward": 0.26152315735816956, "value_loss": 0.006805047765374184, "policy_loss": -0.0009001992140007075, "dist_entropy": 0.6776730060577393, "actor_grad_norm": 0.08115363866090775, "critic_grad_norm": 0.12321757525205612, "ratio": 1.0000141859054565, "entropy": 0.6776730060577393, "incre_win_rate": 0.9285714285714286, "step": 1245}
{"time": 1767157376.3368034, "phase": "train", "update": 1246, "total_env_steps": 3987200, "episode_reward": 0.25327351689338684, "value_loss": 0.00692328829318285, "policy_loss": -0.0014803357242556103, "dist_entropy": 0.6857386827468872, "actor_grad_norm": 0.08372974395751953, "critic_grad_norm": 0.13446709513664246, "ratio": 0.9997846484184265, "entropy": 0.6857386827468872, "incre_win_rate": 0.8333333333333334, "step": 1246}
{"time": 1767157380.6692986, "phase": "train", "update": 1247, "total_env_steps": 3990400, "episode_reward": 0.26028868556022644, "value_loss": 0.007031388580799103, "policy_loss": -0.0009892654152658053, "dist_entropy": 0.6882081270217896, "actor_grad_norm": 0.10150929540395737, "critic_grad_norm": 0.10864400863647461, "ratio": 0.9998024106025696, "entropy": 0.6882081270217896, "incre_win_rate": 0.9047619047619048, "step": 1247}
{"time": 1767157385.0249135, "phase": "train", "update": 1248, "total_env_steps": 3993600, "episode_reward": 0.2577488422393799, "value_loss": 0.008936868235468864, "policy_loss": -0.0010757957424472498, "dist_entropy": 0.6980876326560974, "actor_grad_norm": 0.07182993739843369, "critic_grad_norm": 0.14214259386062622, "ratio": 1.0000540018081665, "entropy": 0.6980876326560974, "incre_win_rate": 0.8636363636363636, "step": 1248}
{"time": 1767157389.3619773, "phase": "train", "update": 1249, "total_env_steps": 3996800, "episode_reward": 0.26321089267730713, "value_loss": 0.004903469420969486, "policy_loss": -0.0013926540696068911, "dist_entropy": 0.7179056525230407, "actor_grad_norm": 0.10167868435382843, "critic_grad_norm": 0.06947212666273117, "ratio": 1.0001581907272339, "entropy": 0.7179056525230407, "incre_win_rate": 0.9302325581395349, "step": 1249}
{"time": 1767157393.7027502, "phase": "train", "update": 1250, "total_env_steps": 4000000, "episode_reward": 0.26072070002555847, "value_loss": 0.007722732238471508, "policy_loss": -0.0011005616859140587, "dist_entropy": 0.7196467995643616, "actor_grad_norm": 0.11767752468585968, "critic_grad_norm": 0.1505742073059082, "ratio": 0.9997102618217468, "entropy": 0.7196467995643616, "incre_win_rate": 0.926829268292683, "step": 1250}
{"time": 1767157397.9487164, "phase": "train", "update": 1251, "total_env_steps": 4003200, "episode_reward": 0.263543039560318, "value_loss": 0.004080748278647661, "policy_loss": -0.0012928647391653668, "dist_entropy": 0.7212034583091735, "actor_grad_norm": 0.11659983545541763, "critic_grad_norm": 0.08273789286613464, "ratio": 0.9995525479316711, "entropy": 0.7212034583091735, "incre_win_rate": 0.9777777777777777, "step": 1251}
{"time": 1767157402.260281, "phase": "train", "update": 1252, "total_env_steps": 4006400, "episode_reward": 0.26564571261405945, "value_loss": 0.004028129717335105, "policy_loss": -0.0009108442426210672, "dist_entropy": 0.7436765432357788, "actor_grad_norm": 0.08354555815458298, "critic_grad_norm": 0.10162856429815292, "ratio": 0.9997420310974121, "entropy": 0.7436765432357788, "incre_win_rate": 0.9512195121951219, "step": 1252}
{"time": 1767157406.6166298, "phase": "train", "update": 1253, "total_env_steps": 4009600, "episode_reward": 0.25811567902565, "value_loss": 0.009940980188548564, "policy_loss": -0.0011692204354073255, "dist_entropy": 0.7228074789047241, "actor_grad_norm": 0.09847681224346161, "critic_grad_norm": 0.09711746871471405, "ratio": 0.9996537566184998, "entropy": 0.7228074789047241, "incre_win_rate": 0.8636363636363636, "step": 1253}
{"time": 1767157410.94674, "phase": "train", "update": 1254, "total_env_steps": 4012800, "episode_reward": 0.25637057423591614, "value_loss": 0.007046824414283037, "policy_loss": -0.0015602328860936155, "dist_entropy": 0.7302748560905457, "actor_grad_norm": 0.10163573175668716, "critic_grad_norm": 0.07547694444656372, "ratio": 0.9999887347221375, "entropy": 0.7302748560905457, "incre_win_rate": 0.8780487804878049, "step": 1254}
{"time": 1767157415.291693, "phase": "train", "update": 1255, "total_env_steps": 4016000, "episode_reward": 0.26115843653678894, "value_loss": 0.00678246021270752, "policy_loss": -0.0014016217798982211, "dist_entropy": 0.7117109537124634, "actor_grad_norm": 0.10567318648099899, "critic_grad_norm": 0.08548235148191452, "ratio": 0.9999340176582336, "entropy": 0.7117109537124634, "incre_win_rate": 0.8695652173913043, "step": 1255}
{"time": 1767157419.64237, "phase": "train", "update": 1256, "total_env_steps": 4019200, "episode_reward": 0.26713162660598755, "value_loss": 0.005415954627096653, "policy_loss": -0.0010146562259492954, "dist_entropy": 0.6812102913856506, "actor_grad_norm": 0.08715670555830002, "critic_grad_norm": 0.04616894945502281, "ratio": 1.0000196695327759, "entropy": 0.6812102913856506, "incre_win_rate": 0.975609756097561, "step": 1256}
{"time": 1767157423.9580312, "phase": "train", "update": 1257, "total_env_steps": 4022400, "episode_reward": 0.2562169134616852, "value_loss": 0.0064514103345572945, "policy_loss": -0.001294727721574418, "dist_entropy": 0.706034517288208, "actor_grad_norm": 0.08692201226949692, "critic_grad_norm": 0.08045937865972519, "ratio": 1.0004278421401978, "entropy": 0.706034517288208, "incre_win_rate": 0.8636363636363636, "step": 1257}
{"time": 1767157428.2475626, "phase": "train", "update": 1258, "total_env_steps": 4025600, "episode_reward": 0.26030632853507996, "value_loss": 0.008698663674294949, "policy_loss": -0.0018174171120849182, "dist_entropy": 0.6769577145576477, "actor_grad_norm": 0.1363505870103836, "critic_grad_norm": 0.08354343473911285, "ratio": 1.0001670122146606, "entropy": 0.6769577145576477, "incre_win_rate": 0.8604651162790697, "step": 1258}
{"time": 1767157432.5172396, "phase": "train", "update": 1259, "total_env_steps": 4028800, "episode_reward": 0.26105961203575134, "value_loss": 0.008148831315338612, "policy_loss": -0.0011560167062654614, "dist_entropy": 0.6622511148452759, "actor_grad_norm": 0.12110137194395065, "critic_grad_norm": 0.07437530159950256, "ratio": 1.0004220008850098, "entropy": 0.6622511148452759, "incre_win_rate": 0.8409090909090909, "step": 1259}
{"time": 1767157436.746866, "phase": "train", "update": 1260, "total_env_steps": 4032000, "episode_reward": 0.25887107849121094, "value_loss": 0.009293440915644168, "policy_loss": -0.000694519234374269, "dist_entropy": 0.6583221197128296, "actor_grad_norm": 0.10971949249505997, "critic_grad_norm": 0.07872947305440903, "ratio": 0.9998835921287537, "entropy": 0.6583221197128296, "incre_win_rate": 0.8571428571428571, "step": 1260}
{"time": 1767157441.0045724, "phase": "train", "update": 1261, "total_env_steps": 4035200, "episode_reward": 0.27216577529907227, "value_loss": 0.004295699158683419, "policy_loss": -0.0008559504738682832, "dist_entropy": 0.6691397070884705, "actor_grad_norm": 0.08414017409086227, "critic_grad_norm": 0.057242006063461304, "ratio": 0.9998278617858887, "entropy": 0.6691397070884705, "incre_win_rate": 0.9767441860465116, "step": 1261}
{"time": 1767157451.4319541, "phase": "eval", "update": 1261, "total_env_steps": 4035200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.83774834437086, "step": 1261}
{"time": 1767157455.6330383, "phase": "train", "update": 1262, "total_env_steps": 4038400, "episode_reward": 0.2623608112335205, "value_loss": 0.006621009204536676, "policy_loss": -0.0013584106444596955, "dist_entropy": 0.6618370175361633, "actor_grad_norm": 0.10296870768070221, "critic_grad_norm": 0.08612719923257828, "ratio": 0.9994418025016785, "entropy": 0.6618370175361633, "incre_win_rate": 0.8863636363636364, "step": 1262}
{"time": 1767157459.9107826, "phase": "train", "update": 1263, "total_env_steps": 4041600, "episode_reward": 0.2688550353050232, "value_loss": 0.005970800574868917, "policy_loss": -0.0009335040977946462, "dist_entropy": 0.6532286882400513, "actor_grad_norm": 0.1019383892416954, "critic_grad_norm": 0.09990384429693222, "ratio": 0.9999634027481079, "entropy": 0.6532286882400513, "incre_win_rate": 0.9545454545454546, "step": 1263}
{"time": 1767157464.2193213, "phase": "train", "update": 1264, "total_env_steps": 4044800, "episode_reward": 0.2661832571029663, "value_loss": 0.006452556885778904, "policy_loss": -0.0010582236539292468, "dist_entropy": 0.6518848657608032, "actor_grad_norm": 0.13678573071956635, "critic_grad_norm": 0.08434558659791946, "ratio": 0.9999703764915466, "entropy": 0.6518848657608032, "incre_win_rate": 0.8837209302325582, "step": 1264}
{"time": 1767157468.5543613, "phase": "train", "update": 1265, "total_env_steps": 4048000, "episode_reward": 0.26876240968704224, "value_loss": 0.006061063706874847, "policy_loss": -0.0009660754444084319, "dist_entropy": 0.6391965627670289, "actor_grad_norm": 0.0889870747923851, "critic_grad_norm": 0.10578743368387222, "ratio": 1.0001230239868164, "entropy": 0.6391965627670289, "incre_win_rate": 0.9130434782608695, "step": 1265}
{"time": 1767157472.8754363, "phase": "train", "update": 1266, "total_env_steps": 4051200, "episode_reward": 0.27737995982170105, "value_loss": 0.005378292314708233, "policy_loss": -0.0010193758265842235, "dist_entropy": 0.6325733304023743, "actor_grad_norm": 0.08469273149967194, "critic_grad_norm": 0.12313324213027954, "ratio": 1.0000065565109253, "entropy": 0.6325733304023743, "incre_win_rate": 1.0, "step": 1266}
{"time": 1767157477.162592, "phase": "train", "update": 1267, "total_env_steps": 4054400, "episode_reward": 0.26342713832855225, "value_loss": 0.004944661818444729, "policy_loss": -0.0010107329920131746, "dist_entropy": 0.6246927857398987, "actor_grad_norm": 0.10821285098791122, "critic_grad_norm": 0.08286623656749725, "ratio": 1.0000046491622925, "entropy": 0.6246927857398987, "incre_win_rate": 0.9777777777777777, "step": 1267}
{"time": 1767157481.4704707, "phase": "train", "update": 1268, "total_env_steps": 4057600, "episode_reward": 0.26541340351104736, "value_loss": 0.004648251179605723, "policy_loss": -0.0007400422747885216, "dist_entropy": 0.6138265371322632, "actor_grad_norm": 0.10411560535430908, "critic_grad_norm": 0.19979380071163177, "ratio": 1.0001051425933838, "entropy": 0.6138265371322632, "incre_win_rate": 0.9512195121951219, "step": 1268}
{"time": 1767157485.8144035, "phase": "train", "update": 1269, "total_env_steps": 4060800, "episode_reward": 0.2655836343765259, "value_loss": 0.006903268489986658, "policy_loss": -0.0008958376227752752, "dist_entropy": 0.6194186210632324, "actor_grad_norm": 0.09783760458230972, "critic_grad_norm": 0.12260643392801285, "ratio": 1.0001283884048462, "entropy": 0.6194186210632324, "incre_win_rate": 0.8888888888888888, "step": 1269}
{"time": 1767157490.0958304, "phase": "train", "update": 1270, "total_env_steps": 4064000, "episode_reward": 0.2611599862575531, "value_loss": 0.006816105265170336, "policy_loss": -0.0011828721440217294, "dist_entropy": 0.6286337494850158, "actor_grad_norm": 0.09006541222333908, "critic_grad_norm": 0.15538379549980164, "ratio": 1.000261664390564, "entropy": 0.6286337494850158, "incre_win_rate": 0.8837209302325582, "step": 1270}
{"time": 1767157494.4010816, "phase": "train", "update": 1271, "total_env_steps": 4067200, "episode_reward": 0.2582921087741852, "value_loss": 0.012166387028992176, "policy_loss": -0.0011227538414964044, "dist_entropy": 0.647409987449646, "actor_grad_norm": 0.12035924196243286, "critic_grad_norm": 0.33152061700820923, "ratio": 1.000011920928955, "entropy": 0.647409987449646, "incre_win_rate": 0.8536585365853658, "step": 1271}
{"time": 1767157498.7210212, "phase": "train", "update": 1272, "total_env_steps": 4070400, "episode_reward": 0.2556074261665344, "value_loss": 0.011146663315594196, "policy_loss": -0.0009016484392958546, "dist_entropy": 0.6396833896636963, "actor_grad_norm": 0.10244698822498322, "critic_grad_norm": 0.22196154296398163, "ratio": 0.9999470710754395, "entropy": 0.6396833896636963, "incre_win_rate": 0.8636363636363636, "step": 1272}
{"time": 1767157503.0247827, "phase": "train", "update": 1273, "total_env_steps": 4073600, "episode_reward": 0.25040873885154724, "value_loss": 0.008078643679618835, "policy_loss": -0.0007697808227675295, "dist_entropy": 0.6174707055091858, "actor_grad_norm": 0.09049709141254425, "critic_grad_norm": 0.10370676964521408, "ratio": 1.0003775358200073, "entropy": 0.6174707055091858, "incre_win_rate": 0.8095238095238095, "step": 1273}
{"time": 1767157507.3090217, "phase": "train", "update": 1274, "total_env_steps": 4076800, "episode_reward": 0.26800963282585144, "value_loss": 0.007438899669796229, "policy_loss": -0.0007709710221703858, "dist_entropy": 0.6218737363815308, "actor_grad_norm": 0.07589554041624069, "critic_grad_norm": 0.23553059995174408, "ratio": 1.0001499652862549, "entropy": 0.6218737363815308, "incre_win_rate": 0.9523809523809523, "step": 1274}
{"time": 1767157511.607656, "phase": "train", "update": 1275, "total_env_steps": 4080000, "episode_reward": 0.2615935802459717, "value_loss": 0.006189541984349489, "policy_loss": -0.0008854116331978191, "dist_entropy": 0.6248014688491821, "actor_grad_norm": 0.08021657913923264, "critic_grad_norm": 0.14268915355205536, "ratio": 1.0005048513412476, "entropy": 0.6248014688491821, "incre_win_rate": 0.8888888888888888, "step": 1275}
{"time": 1767157515.887404, "phase": "train", "update": 1276, "total_env_steps": 4083200, "episode_reward": 0.2672019898891449, "value_loss": 0.005781487189233303, "policy_loss": -0.0006017259260204355, "dist_entropy": 0.6278623938560486, "actor_grad_norm": 0.09187860786914825, "critic_grad_norm": 0.18400870263576508, "ratio": 0.9993404746055603, "entropy": 0.6278623938560486, "incre_win_rate": 0.9761904761904762, "step": 1276}
{"time": 1767157520.2227714, "phase": "train", "update": 1277, "total_env_steps": 4086400, "episode_reward": 0.26903611421585083, "value_loss": 0.0053897912614047526, "policy_loss": -0.001002404368483667, "dist_entropy": 0.6342464327812195, "actor_grad_norm": 0.07910227030515671, "critic_grad_norm": 0.11097413301467896, "ratio": 0.9998211860656738, "entropy": 0.6342464327812195, "incre_win_rate": 0.9318181818181818, "step": 1277}
{"time": 1767157524.6644092, "phase": "train", "update": 1278, "total_env_steps": 4089600, "episode_reward": 0.265542209148407, "value_loss": 0.004947365913540125, "policy_loss": -0.001000444245057075, "dist_entropy": 0.6134836077690125, "actor_grad_norm": 0.08734703809022903, "critic_grad_norm": 0.09012086689472198, "ratio": 0.999738872051239, "entropy": 0.6134836077690125, "incre_win_rate": 0.9534883720930233, "step": 1278}
{"time": 1767157529.0206277, "phase": "train", "update": 1279, "total_env_steps": 4092800, "episode_reward": 0.2610342502593994, "value_loss": 0.007386036403477192, "policy_loss": -0.0011461445352779266, "dist_entropy": 0.6365916013717652, "actor_grad_norm": 0.07982552796602249, "critic_grad_norm": 0.15265314280986786, "ratio": 0.9999909400939941, "entropy": 0.6365916013717652, "incre_win_rate": 0.9069767441860465, "step": 1279}
{"time": 1767157533.3406994, "phase": "train", "update": 1280, "total_env_steps": 4096000, "episode_reward": 0.26871582865715027, "value_loss": 0.005354353971779346, "policy_loss": -0.0008599578937431573, "dist_entropy": 0.6334504842758178, "actor_grad_norm": 0.08988019078969955, "critic_grad_norm": 0.11850245296955109, "ratio": 1.0001697540283203, "entropy": 0.6334504842758178, "incre_win_rate": 0.9534883720930233, "step": 1280}
{"time": 1767157537.6823406, "phase": "train", "update": 1281, "total_env_steps": 4099200, "episode_reward": 0.266376256942749, "value_loss": 0.00593296904116869, "policy_loss": -0.0008711716131145408, "dist_entropy": 0.653440260887146, "actor_grad_norm": 0.08670320361852646, "critic_grad_norm": 0.13040600717067719, "ratio": 0.9998722076416016, "entropy": 0.653440260887146, "incre_win_rate": 0.9130434782608695, "step": 1281}
{"time": 1767157548.2231522, "phase": "eval", "update": 1281, "total_env_steps": 4099200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.59778559602649, "step": 1281}
{"time": 1767157552.5557961, "phase": "train", "update": 1282, "total_env_steps": 4102400, "episode_reward": 0.24187034368515015, "value_loss": 0.013523934036493301, "policy_loss": -0.001046111521404569, "dist_entropy": 0.6591564893722535, "actor_grad_norm": 0.09955346584320068, "critic_grad_norm": 0.3441857397556305, "ratio": 0.99941486120224, "entropy": 0.6591564893722535, "incre_win_rate": 0.75, "step": 1282}
{"time": 1767157556.8505516, "phase": "train", "update": 1283, "total_env_steps": 4105600, "episode_reward": 0.2637820839881897, "value_loss": 0.011568841896951199, "policy_loss": -0.0012008474404659353, "dist_entropy": 0.675789749622345, "actor_grad_norm": 0.09699689596891403, "critic_grad_norm": 0.2016839236021042, "ratio": 1.0001274347305298, "entropy": 0.675789749622345, "incre_win_rate": 0.8837209302325582, "step": 1283}
{"time": 1767157561.1638312, "phase": "train", "update": 1284, "total_env_steps": 4108800, "episode_reward": 0.25108858942985535, "value_loss": 0.0074175848625600335, "policy_loss": -0.001059741693457994, "dist_entropy": 0.6803603291511535, "actor_grad_norm": 0.09880941361188889, "critic_grad_norm": 0.1803886890411377, "ratio": 0.9999228715896606, "entropy": 0.6803603291511535, "incre_win_rate": 0.8809523809523809, "step": 1284}
{"time": 1767157565.4741192, "phase": "train", "update": 1285, "total_env_steps": 4112000, "episode_reward": 0.26011744141578674, "value_loss": 0.007047204487025738, "policy_loss": -0.0011579481688322347, "dist_entropy": 0.6731081247329712, "actor_grad_norm": 0.09953581541776657, "critic_grad_norm": 0.09996798634529114, "ratio": 1.0001367330551147, "entropy": 0.6731081247329712, "incre_win_rate": 0.8536585365853658, "step": 1285}
{"time": 1767157569.7539115, "phase": "train", "update": 1286, "total_env_steps": 4115200, "episode_reward": 0.26537254452705383, "value_loss": 0.0039858585223555565, "policy_loss": -0.001185761007129571, "dist_entropy": 0.6687074184417725, "actor_grad_norm": 0.11857203394174576, "critic_grad_norm": 0.057979829609394073, "ratio": 1.0002615451812744, "entropy": 0.6687074184417725, "incre_win_rate": 0.9347826086956522, "step": 1286}
{"time": 1767157574.0533068, "phase": "train", "update": 1287, "total_env_steps": 4118400, "episode_reward": 0.26963162422180176, "value_loss": 0.004542122408747673, "policy_loss": -0.001379088049393573, "dist_entropy": 0.680556845664978, "actor_grad_norm": 0.10399148613214493, "critic_grad_norm": 0.10867669433355331, "ratio": 1.0000393390655518, "entropy": 0.680556845664978, "incre_win_rate": 0.926829268292683, "step": 1287}
{"time": 1767157578.36305, "phase": "train", "update": 1288, "total_env_steps": 4121600, "episode_reward": 0.26928240060806274, "value_loss": 0.0051790130324661735, "policy_loss": -0.0007668653142452797, "dist_entropy": 0.6846886992454528, "actor_grad_norm": 0.07546567171812057, "critic_grad_norm": 0.07680761814117432, "ratio": 0.9998382925987244, "entropy": 0.6846886992454528, "incre_win_rate": 0.9347826086956522, "step": 1288}
{"time": 1767157582.6866355, "phase": "train", "update": 1289, "total_env_steps": 4124800, "episode_reward": 0.2570949196815491, "value_loss": 0.007233030628412962, "policy_loss": -0.0014912433328561291, "dist_entropy": 0.6391497850418091, "actor_grad_norm": 0.09293759614229202, "critic_grad_norm": 0.045658715069293976, "ratio": 0.9998475909233093, "entropy": 0.6391497850418091, "incre_win_rate": 0.8536585365853658, "step": 1289}
{"time": 1767157586.9764102, "phase": "train", "update": 1290, "total_env_steps": 4128000, "episode_reward": 0.2454061359167099, "value_loss": 0.010993316955864429, "policy_loss": -0.0010574331089998168, "dist_entropy": 0.6620693922042846, "actor_grad_norm": 0.11321254074573517, "critic_grad_norm": 0.07793285697698593, "ratio": 0.9996959567070007, "entropy": 0.6620693922042846, "incre_win_rate": 0.8, "step": 1290}
{"time": 1767157591.2832007, "phase": "train", "update": 1291, "total_env_steps": 4131200, "episode_reward": 0.2611217200756073, "value_loss": 0.00807560160756111, "policy_loss": -0.0010369977825987586, "dist_entropy": 0.6324978947639466, "actor_grad_norm": 0.13508926331996918, "critic_grad_norm": 0.14534331858158112, "ratio": 1.0001344680786133, "entropy": 0.6324978947639466, "incre_win_rate": 0.9111111111111111, "step": 1291}
{"time": 1767157595.567888, "phase": "train", "update": 1292, "total_env_steps": 4134400, "episode_reward": 0.2514176666736603, "value_loss": 0.006065433751791716, "policy_loss": -0.001156697796652395, "dist_entropy": 0.6358298420906067, "actor_grad_norm": 0.10723497718572617, "critic_grad_norm": 0.11319001764059067, "ratio": 1.0000951290130615, "entropy": 0.6358298420906067, "incre_win_rate": 0.9047619047619048, "step": 1292}
{"time": 1767157599.946608, "phase": "train", "update": 1293, "total_env_steps": 4137600, "episode_reward": 0.26014384627342224, "value_loss": 0.00519799292087555, "policy_loss": -0.0008220779805025557, "dist_entropy": 0.6217106938362121, "actor_grad_norm": 0.1058429405093193, "critic_grad_norm": 0.09109926223754883, "ratio": 1.000212550163269, "entropy": 0.6217106938362121, "incre_win_rate": 0.8809523809523809, "step": 1293}
{"time": 1767157604.2557745, "phase": "train", "update": 1294, "total_env_steps": 4140800, "episode_reward": 0.2633102238178253, "value_loss": 0.007101334445178509, "policy_loss": -0.0011115611568371265, "dist_entropy": 0.6328668713569641, "actor_grad_norm": 0.10408421605825424, "critic_grad_norm": 0.1059131845831871, "ratio": 0.9996166229248047, "entropy": 0.6328668713569641, "incre_win_rate": 0.8837209302325582, "step": 1294}
{"time": 1767157608.5738547, "phase": "train", "update": 1295, "total_env_steps": 4144000, "episode_reward": 0.26449501514434814, "value_loss": 0.006726240739226341, "policy_loss": -0.0008649954788699787, "dist_entropy": 0.6311692357063293, "actor_grad_norm": 0.08938971906900406, "critic_grad_norm": 0.17873071134090424, "ratio": 1.00029718875885, "entropy": 0.6311692357063293, "incre_win_rate": 0.9545454545454546, "step": 1295}
{"time": 1767157612.9453185, "phase": "train", "update": 1296, "total_env_steps": 4147200, "episode_reward": 0.2693062126636505, "value_loss": 0.007147339079529047, "policy_loss": -0.0005890475025452701, "dist_entropy": 0.6224921941757202, "actor_grad_norm": 0.07013314217329025, "critic_grad_norm": 0.19920048117637634, "ratio": 0.9998325705528259, "entropy": 0.6224921941757202, "incre_win_rate": 0.9069767441860465, "step": 1296}
{"time": 1767157617.279531, "phase": "train", "update": 1297, "total_env_steps": 4150400, "episode_reward": 0.26496535539627075, "value_loss": 0.006438266579061746, "policy_loss": -0.001111028603671116, "dist_entropy": 0.6051946640014648, "actor_grad_norm": 0.10594164580106735, "critic_grad_norm": 0.08976779878139496, "ratio": 1.000184416770935, "entropy": 0.6051946640014648, "incre_win_rate": 0.9318181818181818, "step": 1297}
{"time": 1767157621.6128798, "phase": "train", "update": 1298, "total_env_steps": 4153600, "episode_reward": 0.2722904682159424, "value_loss": 0.006667202711105347, "policy_loss": -0.0009728439535706457, "dist_entropy": 0.5955930352210999, "actor_grad_norm": 0.08604227006435394, "critic_grad_norm": 0.15991602838039398, "ratio": 0.9999409914016724, "entropy": 0.5955930352210999, "incre_win_rate": 0.9534883720930233, "step": 1298}
{"time": 1767157625.9178026, "phase": "train", "update": 1299, "total_env_steps": 4156800, "episode_reward": 0.2694055140018463, "value_loss": 0.00624695448204875, "policy_loss": -0.0009010323966293754, "dist_entropy": 0.6036136150360107, "actor_grad_norm": 0.08786457031965256, "critic_grad_norm": 0.11424481123685837, "ratio": 0.9997085928916931, "entropy": 0.6036136150360107, "incre_win_rate": 0.9555555555555556, "step": 1299}
{"time": 1767157630.2839074, "phase": "train", "update": 1300, "total_env_steps": 4160000, "episode_reward": 0.27379554510116577, "value_loss": 0.0033268374390900135, "policy_loss": -0.0011689073108485104, "dist_entropy": 0.6072595953941345, "actor_grad_norm": 0.08067668229341507, "critic_grad_norm": 0.06169014796614647, "ratio": 0.9997758269309998, "entropy": 0.6072595953941345, "incre_win_rate": 1.0, "step": 1300}
{"time": 1767157634.6544905, "phase": "train", "update": 1301, "total_env_steps": 4163200, "episode_reward": 0.27003777027130127, "value_loss": 0.006001429632306099, "policy_loss": -0.0010793687706119215, "dist_entropy": 0.6068752527236938, "actor_grad_norm": 0.10447235405445099, "critic_grad_norm": 0.13271038234233856, "ratio": 1.0001428127288818, "entropy": 0.6068752527236938, "incre_win_rate": 0.9333333333333333, "step": 1301}
{"time": 1767157644.7715535, "phase": "eval", "update": 1301, "total_env_steps": 4163200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.85078642384106, "step": 1301}
{"time": 1767157649.1188974, "phase": "train", "update": 1302, "total_env_steps": 4166400, "episode_reward": 0.2605665624141693, "value_loss": 0.005408135149627924, "policy_loss": -0.00134934855495068, "dist_entropy": 0.633202850818634, "actor_grad_norm": 0.1039755716919899, "critic_grad_norm": 0.08065015822649002, "ratio": 0.9997906684875488, "entropy": 0.633202850818634, "incre_win_rate": 0.9090909090909091, "step": 1302}
{"time": 1767157653.47455, "phase": "train", "update": 1303, "total_env_steps": 4169600, "episode_reward": 0.26118791103363037, "value_loss": 0.006548678688704968, "policy_loss": -0.0007453482601572859, "dist_entropy": 0.5941611766815186, "actor_grad_norm": 0.08593853563070297, "critic_grad_norm": 0.12319564074277878, "ratio": 1.00002920627594, "entropy": 0.5941611766815186, "incre_win_rate": 0.8536585365853658, "step": 1303}
{"time": 1767157657.8012984, "phase": "train", "update": 1304, "total_env_steps": 4172800, "episode_reward": 0.27072378993034363, "value_loss": 0.007562344707548618, "policy_loss": -0.00112310889529752, "dist_entropy": 0.6121697664260864, "actor_grad_norm": 0.08299272507429123, "critic_grad_norm": 0.11788424104452133, "ratio": 1.000048041343689, "entropy": 0.6121697664260864, "incre_win_rate": 0.9555555555555556, "step": 1304}
{"time": 1767157662.1634593, "phase": "train", "update": 1305, "total_env_steps": 4176000, "episode_reward": 0.262052983045578, "value_loss": 0.006986391823738813, "policy_loss": -0.0012928762188153086, "dist_entropy": 0.6098796606063843, "actor_grad_norm": 0.08676592260599136, "critic_grad_norm": 0.07137132436037064, "ratio": 0.9997787475585938, "entropy": 0.6098796606063843, "incre_win_rate": 0.9302325581395349, "step": 1305}
{"time": 1767157666.4850209, "phase": "train", "update": 1306, "total_env_steps": 4179200, "episode_reward": 0.2738901972770691, "value_loss": 0.005993831064552068, "policy_loss": -0.0008182070929475316, "dist_entropy": 0.6095395445823669, "actor_grad_norm": 0.07156582176685333, "critic_grad_norm": 0.1295766979455948, "ratio": 0.999940037727356, "entropy": 0.6095395445823669, "incre_win_rate": 0.9302325581395349, "step": 1306}
{"time": 1767157700.0900178, "phase": "train", "update": 1307, "total_env_steps": 4182400, "episode_reward": 0.25836920738220215, "value_loss": 0.04321874007582664, "policy_loss": -0.0011012885875981483, "dist_entropy": 0.6188045501708984, "actor_grad_norm": 0.07591324299573898, "critic_grad_norm": 0.2446601390838623, "ratio": 1.000411868095398, "entropy": 0.6188045501708984, "incre_win_rate": 0.8947368421052632, "step": 1307}
{"time": 1767157704.4068727, "phase": "train", "update": 1308, "total_env_steps": 4185600, "episode_reward": 0.26056134700775146, "value_loss": 0.006644088495522738, "policy_loss": -0.000980886701834649, "dist_entropy": 0.631463348865509, "actor_grad_norm": 0.09354553371667862, "critic_grad_norm": 0.2122785598039627, "ratio": 1.00006902217865, "entropy": 0.631463348865509, "incre_win_rate": 0.9069767441860465, "step": 1308}
{"time": 1767157708.6827514, "phase": "train", "update": 1309, "total_env_steps": 4188800, "episode_reward": 0.26597216725349426, "value_loss": 0.006512492522597313, "policy_loss": -0.0011977628086853541, "dist_entropy": 0.6232907056808472, "actor_grad_norm": 0.11691068857908249, "critic_grad_norm": 0.17221161723136902, "ratio": 0.999603271484375, "entropy": 0.6232907056808472, "incre_win_rate": 0.9130434782608695, "step": 1309}
{"time": 1767157712.9667192, "phase": "train", "update": 1310, "total_env_steps": 4192000, "episode_reward": 0.2659105956554413, "value_loss": 0.006543325260281563, "policy_loss": -0.0008849598072885101, "dist_entropy": 0.6430724740028382, "actor_grad_norm": 0.10897541046142578, "critic_grad_norm": 0.08247684687376022, "ratio": 1.0001553297042847, "entropy": 0.6430724740028382, "incre_win_rate": 0.925, "step": 1310}
{"time": 1767157717.2382784, "phase": "train", "update": 1311, "total_env_steps": 4195200, "episode_reward": 0.23494671285152435, "value_loss": 0.009976799227297306, "policy_loss": -0.0013588404562995926, "dist_entropy": 0.6251115560531616, "actor_grad_norm": 0.0955904945731163, "critic_grad_norm": 0.20558424293994904, "ratio": 0.9999822974205017, "entropy": 0.6251115560531616, "incre_win_rate": 0.825, "step": 1311}
{"time": 1767157721.7665858, "phase": "train", "update": 1312, "total_env_steps": 4198400, "episode_reward": 0.2573561668395996, "value_loss": 0.006950224004685879, "policy_loss": -0.0009436567459189859, "dist_entropy": 0.6236841440200805, "actor_grad_norm": 0.09162568300962448, "critic_grad_norm": 0.15638695657253265, "ratio": 0.9996472597122192, "entropy": 0.6236841440200805, "incre_win_rate": 0.8444444444444444, "step": 1312}
{"time": 1767157726.4386072, "phase": "train", "update": 1313, "total_env_steps": 4201600, "episode_reward": 0.2623799741268158, "value_loss": 0.0045418933965265754, "policy_loss": -0.0011822296646384345, "dist_entropy": 0.6153897881507874, "actor_grad_norm": 0.07628967612981796, "critic_grad_norm": 0.13353469967842102, "ratio": 1.000001311302185, "entropy": 0.6153897881507874, "incre_win_rate": 0.9512195121951219, "step": 1313}
{"time": 1767157730.7813346, "phase": "train", "update": 1314, "total_env_steps": 4204800, "episode_reward": 0.2664078176021576, "value_loss": 0.00531055573374033, "policy_loss": -0.0011575253897085247, "dist_entropy": 0.6010826826095581, "actor_grad_norm": 0.08236692100763321, "critic_grad_norm": 0.0809873640537262, "ratio": 1.0004653930664062, "entropy": 0.6010826826095581, "incre_win_rate": 0.9090909090909091, "step": 1314}
{"time": 1767157735.033776, "phase": "train", "update": 1315, "total_env_steps": 4208000, "episode_reward": 0.26333245635032654, "value_loss": 0.005197517573833466, "policy_loss": -0.0008635990115514857, "dist_entropy": 0.6257012486457825, "actor_grad_norm": 0.08000211417675018, "critic_grad_norm": 0.09214874356985092, "ratio": 1.0002347230911255, "entropy": 0.6257012486457825, "incre_win_rate": 0.8837209302325582, "step": 1315}
{"time": 1767157739.313333, "phase": "train", "update": 1316, "total_env_steps": 4211200, "episode_reward": 0.2641960084438324, "value_loss": 0.006924891658127308, "policy_loss": -0.0012117187587236344, "dist_entropy": 0.6145718336105347, "actor_grad_norm": 0.1218961700797081, "critic_grad_norm": 0.07344173640012741, "ratio": 0.9996526837348938, "entropy": 0.6145718336105347, "incre_win_rate": 0.8888888888888888, "step": 1316}
{"time": 1767157743.6440706, "phase": "train", "update": 1317, "total_env_steps": 4214400, "episode_reward": 0.26156872510910034, "value_loss": 0.008684387616813182, "policy_loss": -0.000980698426670834, "dist_entropy": 0.6232245087623596, "actor_grad_norm": 0.0793733224272728, "critic_grad_norm": 0.0683768168091774, "ratio": 1.0000271797180176, "entropy": 0.6232245087623596, "incre_win_rate": 0.8837209302325582, "step": 1317}
{"time": 1767157747.9496443, "phase": "train", "update": 1318, "total_env_steps": 4217600, "episode_reward": 0.2712453603744507, "value_loss": 0.006144287064671516, "policy_loss": -0.001051504923616875, "dist_entropy": 0.6284659743309021, "actor_grad_norm": 0.1069912314414978, "critic_grad_norm": 0.0892532542347908, "ratio": 1.000045657157898, "entropy": 0.6284659743309021, "incre_win_rate": 0.9090909090909091, "step": 1318}
{"time": 1767157752.2238894, "phase": "train", "update": 1319, "total_env_steps": 4220800, "episode_reward": 0.27114394307136536, "value_loss": 0.003751091379672289, "policy_loss": -0.0015265069509272423, "dist_entropy": 0.629208755493164, "actor_grad_norm": 0.0869152769446373, "critic_grad_norm": 0.0972895473241806, "ratio": 1.0000871419906616, "entropy": 0.629208755493164, "incre_win_rate": 0.9333333333333333, "step": 1319}
{"time": 1767157756.4804108, "phase": "train", "update": 1320, "total_env_steps": 4224000, "episode_reward": 0.2719665765762329, "value_loss": 0.004100960865616799, "policy_loss": -0.000921204861921865, "dist_entropy": 0.6329867482185364, "actor_grad_norm": 0.0977177768945694, "critic_grad_norm": 0.10641036182641983, "ratio": 1.000277042388916, "entropy": 0.6329867482185364, "incre_win_rate": 0.9285714285714286, "step": 1320}
{"time": 1767157760.7675855, "phase": "train", "update": 1321, "total_env_steps": 4227200, "episode_reward": 0.27185019850730896, "value_loss": 0.005901566985994577, "policy_loss": -0.0012215423312206043, "dist_entropy": 0.6474279284477233, "actor_grad_norm": 0.10026862472295761, "critic_grad_norm": 0.10127508640289307, "ratio": 0.9996716380119324, "entropy": 0.6474279284477233, "incre_win_rate": 0.9333333333333333, "step": 1321}
{"time": 1767157771.5211117, "phase": "eval", "update": 1321, "total_env_steps": 4227200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.689466059602648, "step": 1321}
{"time": 1767157775.7493727, "phase": "train", "update": 1322, "total_env_steps": 4230400, "episode_reward": 0.25095871090888977, "value_loss": 0.007497925031930208, "policy_loss": -0.001260680005881909, "dist_entropy": 0.6519843339920044, "actor_grad_norm": 0.08865632116794586, "critic_grad_norm": 0.07193555682897568, "ratio": 0.9999600648880005, "entropy": 0.6519843339920044, "incre_win_rate": 0.7727272727272727, "step": 1322}
{"time": 1767157779.9785323, "phase": "train", "update": 1323, "total_env_steps": 4233600, "episode_reward": 0.2628513276576996, "value_loss": 0.009351103007793427, "policy_loss": -0.001058554226916897, "dist_entropy": 0.6388753652572632, "actor_grad_norm": 0.08809832483530045, "critic_grad_norm": 0.12342917174100876, "ratio": 1.0000628232955933, "entropy": 0.6388753652572632, "incre_win_rate": 0.9047619047619048, "step": 1323}
{"time": 1767157784.2569983, "phase": "train", "update": 1324, "total_env_steps": 4236800, "episode_reward": 0.2756379544734955, "value_loss": 0.0046543430536985396, "policy_loss": -0.0011801805500979868, "dist_entropy": 0.6418232917785645, "actor_grad_norm": 0.08699339628219604, "critic_grad_norm": 0.16010458767414093, "ratio": 1.000017523765564, "entropy": 0.6418232917785645, "incre_win_rate": 0.9555555555555556, "step": 1324}
{"time": 1767157788.4831455, "phase": "train", "update": 1325, "total_env_steps": 4240000, "episode_reward": 0.2795281410217285, "value_loss": 0.0038482312578707934, "policy_loss": -0.0011071666902097376, "dist_entropy": 0.6400530576705933, "actor_grad_norm": 0.0761597529053688, "critic_grad_norm": 0.06460770219564438, "ratio": 1.0001477003097534, "entropy": 0.6400530576705933, "incre_win_rate": 0.9777777777777777, "step": 1325}
{"time": 1767157792.7007856, "phase": "train", "update": 1326, "total_env_steps": 4243200, "episode_reward": 0.2619422674179077, "value_loss": 0.006409227568656206, "policy_loss": -0.0011024363196366239, "dist_entropy": 0.6449226260185241, "actor_grad_norm": 0.07803861051797867, "critic_grad_norm": 0.17747126519680023, "ratio": 0.9999805688858032, "entropy": 0.6449226260185241, "incre_win_rate": 0.8604651162790697, "step": 1326}
{"time": 1767157796.9511666, "phase": "train", "update": 1327, "total_env_steps": 4246400, "episode_reward": 0.27200278639793396, "value_loss": 0.004488338343799114, "policy_loss": -0.0012345472790777023, "dist_entropy": 0.629914116859436, "actor_grad_norm": 0.07731210440397263, "critic_grad_norm": 0.10815663635730743, "ratio": 0.9997669458389282, "entropy": 0.629914116859436, "incre_win_rate": 0.9545454545454546, "step": 1327}
{"time": 1767157801.1699076, "phase": "train", "update": 1328, "total_env_steps": 4249600, "episode_reward": 0.2565231919288635, "value_loss": 0.008469227328896522, "policy_loss": -0.001115099667258157, "dist_entropy": 0.6285910487174988, "actor_grad_norm": 0.09446471929550171, "critic_grad_norm": 0.08892130106687546, "ratio": 1.0001221895217896, "entropy": 0.6285910487174988, "incre_win_rate": 0.8604651162790697, "step": 1328}
{"time": 1767157805.6047316, "phase": "train", "update": 1329, "total_env_steps": 4252800, "episode_reward": 0.2600398361682892, "value_loss": 0.008041166327893734, "policy_loss": -0.001455782228854652, "dist_entropy": 0.6254854559898376, "actor_grad_norm": 0.10381972789764404, "critic_grad_norm": 0.07621270418167114, "ratio": 0.9997884631156921, "entropy": 0.6254854559898376, "incre_win_rate": 0.8636363636363636, "step": 1329}
{"time": 1767157809.877575, "phase": "train", "update": 1330, "total_env_steps": 4256000, "episode_reward": 0.26409098505973816, "value_loss": 0.006841810047626495, "policy_loss": -0.001401759902425681, "dist_entropy": 0.6040482521057129, "actor_grad_norm": 0.11518845707178116, "critic_grad_norm": 0.060620784759521484, "ratio": 1.0000332593917847, "entropy": 0.6040482521057129, "incre_win_rate": 0.8863636363636364, "step": 1330}
{"time": 1767157814.1310391, "phase": "train", "update": 1331, "total_env_steps": 4259200, "episode_reward": 0.2668755054473877, "value_loss": 0.006755548436194659, "policy_loss": -0.0013293778844683858, "dist_entropy": 0.6255879640579224, "actor_grad_norm": 0.10302086919546127, "critic_grad_norm": 0.09432267397642136, "ratio": 0.9994825720787048, "entropy": 0.6255879640579224, "incre_win_rate": 0.9285714285714286, "step": 1331}
{"time": 1767157818.3786123, "phase": "train", "update": 1332, "total_env_steps": 4262400, "episode_reward": 0.26501137018203735, "value_loss": 0.00707915686070919, "policy_loss": -0.0010545317999621773, "dist_entropy": 0.6141521453857421, "actor_grad_norm": 0.0913347601890564, "critic_grad_norm": 0.06800384819507599, "ratio": 0.9999944567680359, "entropy": 0.6141521453857421, "incre_win_rate": 0.8863636363636364, "step": 1332}
{"time": 1767157822.6290774, "phase": "train", "update": 1333, "total_env_steps": 4265600, "episode_reward": 0.26533007621765137, "value_loss": 0.005931268539279699, "policy_loss": -0.0010572759212596594, "dist_entropy": 0.6104567885398865, "actor_grad_norm": 0.08686258643865585, "critic_grad_norm": 0.10821738094091415, "ratio": 1.000102162361145, "entropy": 0.6104567885398865, "incre_win_rate": 0.8837209302325582, "step": 1333}
{"time": 1767157826.8843052, "phase": "train", "update": 1334, "total_env_steps": 4268800, "episode_reward": 0.2576034665107727, "value_loss": 0.006481158267706633, "policy_loss": -0.0014822404131820122, "dist_entropy": 0.6036724328994751, "actor_grad_norm": 0.09060156345367432, "critic_grad_norm": 0.0880870372056961, "ratio": 1.0000203847885132, "entropy": 0.6036724328994751, "incre_win_rate": 0.9090909090909091, "step": 1334}
{"time": 1767157831.1778438, "phase": "train", "update": 1335, "total_env_steps": 4272000, "episode_reward": 0.26017332077026367, "value_loss": 0.00684048580005765, "policy_loss": -0.0010044275845034311, "dist_entropy": 0.5940212607383728, "actor_grad_norm": 0.07817424833774567, "critic_grad_norm": 0.05952490493655205, "ratio": 1.0003259181976318, "entropy": 0.5940212607383728, "incre_win_rate": 0.9, "step": 1335}
{"time": 1767157835.4742508, "phase": "train", "update": 1336, "total_env_steps": 4275200, "episode_reward": 0.2707346975803375, "value_loss": 0.005651784967631102, "policy_loss": -0.0012592047285757246, "dist_entropy": 0.6086361885070801, "actor_grad_norm": 0.10694463551044464, "critic_grad_norm": 0.08200962841510773, "ratio": 0.9998459219932556, "entropy": 0.6086361885070801, "incre_win_rate": 0.9782608695652174, "step": 1336}
{"time": 1767157839.7210317, "phase": "train", "update": 1337, "total_env_steps": 4278400, "episode_reward": 0.26648178696632385, "value_loss": 0.006444977410137653, "policy_loss": -0.0009562243819573269, "dist_entropy": 0.6284539580345154, "actor_grad_norm": 0.09939905256032944, "critic_grad_norm": 0.09582583606243134, "ratio": 0.9995832443237305, "entropy": 0.6284539580345154, "incre_win_rate": 0.9512195121951219, "step": 1337}
{"time": 1767157843.9686863, "phase": "train", "update": 1338, "total_env_steps": 4281600, "episode_reward": 0.2540997564792633, "value_loss": 0.00688986461609602, "policy_loss": -0.0010496741534611331, "dist_entropy": 0.6319432258605957, "actor_grad_norm": 0.10346122831106186, "critic_grad_norm": 0.10221773386001587, "ratio": 0.9999950528144836, "entropy": 0.6319432258605957, "incre_win_rate": 0.8372093023255814, "step": 1338}
{"time": 1767157848.2155623, "phase": "train", "update": 1339, "total_env_steps": 4284800, "episode_reward": 0.2628626823425293, "value_loss": 0.008209256175905465, "policy_loss": -0.001256703245640267, "dist_entropy": 0.6368889093399048, "actor_grad_norm": 0.08547323942184448, "critic_grad_norm": 0.08163084089756012, "ratio": 1.0000828504562378, "entropy": 0.6368889093399048, "incre_win_rate": 0.8409090909090909, "step": 1339}
{"time": 1767157852.4685383, "phase": "train", "update": 1340, "total_env_steps": 4288000, "episode_reward": 0.2634313106536865, "value_loss": 0.005150334443897009, "policy_loss": -0.0008283440412682807, "dist_entropy": 0.6277203679084777, "actor_grad_norm": 0.0945139080286026, "critic_grad_norm": 0.053184378892183304, "ratio": 0.9995186924934387, "entropy": 0.6277203679084777, "incre_win_rate": 0.9111111111111111, "step": 1340}
{"time": 1767157856.7400517, "phase": "train", "update": 1341, "total_env_steps": 4291200, "episode_reward": 0.26953279972076416, "value_loss": 0.005743845924735069, "policy_loss": -0.0012212026839350187, "dist_entropy": 0.6282602548599243, "actor_grad_norm": 0.09663873165845871, "critic_grad_norm": 0.03696231171488762, "ratio": 1.0002470016479492, "entropy": 0.6282602548599243, "incre_win_rate": 0.9090909090909091, "step": 1341}
{"time": 1767157867.0333166, "phase": "eval", "update": 1341, "total_env_steps": 4291200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.810637417218544, "step": 1341}
{"time": 1767157871.3091724, "phase": "train", "update": 1342, "total_env_steps": 4294400, "episode_reward": 0.26040977239608765, "value_loss": 0.00806014183908701, "policy_loss": -0.0011630684333155728, "dist_entropy": 0.637915313243866, "actor_grad_norm": 0.10344431549310684, "critic_grad_norm": 0.08573801815509796, "ratio": 1.0002926588058472, "entropy": 0.637915313243866, "incre_win_rate": 0.875, "step": 1342}
{"time": 1767157875.5676079, "phase": "train", "update": 1343, "total_env_steps": 4297600, "episode_reward": 0.26200640201568604, "value_loss": 0.008172685094177724, "policy_loss": -0.0015275312633093562, "dist_entropy": 0.6414108872413635, "actor_grad_norm": 0.09202617406845093, "critic_grad_norm": 0.09267638623714447, "ratio": 1.000339388847351, "entropy": 0.6414108872413635, "incre_win_rate": 0.8863636363636364, "step": 1343}
{"time": 1767157879.7679496, "phase": "train", "update": 1344, "total_env_steps": 4300800, "episode_reward": 0.2646947503089905, "value_loss": 0.006543956138193608, "policy_loss": -0.001382062814753038, "dist_entropy": 0.638833487033844, "actor_grad_norm": 0.08891768753528595, "critic_grad_norm": 0.07746952772140503, "ratio": 1.0003271102905273, "entropy": 0.638833487033844, "incre_win_rate": 0.8888888888888888, "step": 1344}
{"time": 1767157884.0737839, "phase": "train", "update": 1345, "total_env_steps": 4304000, "episode_reward": 0.27346545457839966, "value_loss": 0.005966234393417836, "policy_loss": -0.0016430816606774813, "dist_entropy": 0.6407307624816895, "actor_grad_norm": 0.0985914096236229, "critic_grad_norm": 0.07435699552297592, "ratio": 0.999711811542511, "entropy": 0.6407307624816895, "incre_win_rate": 0.9545454545454546, "step": 1345}
{"time": 1767157888.3087296, "phase": "train", "update": 1346, "total_env_steps": 4307200, "episode_reward": 0.2660627067089081, "value_loss": 0.00444223852828145, "policy_loss": -0.0014892804011902073, "dist_entropy": 0.6568307161331177, "actor_grad_norm": 0.10689906030893326, "critic_grad_norm": 0.047863855957984924, "ratio": 1.0002264976501465, "entropy": 0.6568307161331177, "incre_win_rate": 0.9047619047619048, "step": 1346}
{"time": 1767157892.5812168, "phase": "train", "update": 1347, "total_env_steps": 4310400, "episode_reward": 0.2599829435348511, "value_loss": 0.007211108319461345, "policy_loss": -0.0012665778185906972, "dist_entropy": 0.6959292173385621, "actor_grad_norm": 0.09389615058898926, "critic_grad_norm": 0.16516920924186707, "ratio": 1.000379204750061, "entropy": 0.6959292173385621, "incre_win_rate": 0.8636363636363636, "step": 1347}
{"time": 1767157896.8724394, "phase": "train", "update": 1348, "total_env_steps": 4313600, "episode_reward": 0.26663804054260254, "value_loss": 0.005310388747602701, "policy_loss": -0.0013701564806012812, "dist_entropy": 0.7054362416267395, "actor_grad_norm": 0.08738894760608673, "critic_grad_norm": 0.08114355057477951, "ratio": 1.0000357627868652, "entropy": 0.7054362416267395, "incre_win_rate": 0.8863636363636364, "step": 1348}
{"time": 1767157901.1874485, "phase": "train", "update": 1349, "total_env_steps": 4316800, "episode_reward": 0.2654304802417755, "value_loss": 0.007182449940592051, "policy_loss": -0.001718762638490645, "dist_entropy": 0.701416528224945, "actor_grad_norm": 0.08886220306158066, "critic_grad_norm": 0.08249572664499283, "ratio": 0.9994441270828247, "entropy": 0.701416528224945, "incre_win_rate": 0.8837209302325582, "step": 1349}
{"time": 1767157905.4524283, "phase": "train", "update": 1350, "total_env_steps": 4320000, "episode_reward": 0.26355546712875366, "value_loss": 0.006119563709944487, "policy_loss": -0.0012994973118480857, "dist_entropy": 0.6815390944480896, "actor_grad_norm": 0.08005852997303009, "critic_grad_norm": 0.1347782015800476, "ratio": 0.9999969601631165, "entropy": 0.6815390944480896, "incre_win_rate": 0.8666666666666667, "step": 1350}
{"time": 1767157910.0179405, "phase": "train", "update": 1351, "total_env_steps": 4323200, "episode_reward": 0.26273542642593384, "value_loss": 0.007180451788008213, "policy_loss": -0.0010612033568058621, "dist_entropy": 0.6755899786949158, "actor_grad_norm": 0.1019899845123291, "critic_grad_norm": 0.07139585167169571, "ratio": 0.9999761581420898, "entropy": 0.6755899786949158, "incre_win_rate": 0.8863636363636364, "step": 1351}
{"time": 1767157914.612818, "phase": "train", "update": 1352, "total_env_steps": 4326400, "episode_reward": 0.2592865228652954, "value_loss": 0.008600777946412563, "policy_loss": -0.0010005438862851434, "dist_entropy": 0.656528639793396, "actor_grad_norm": 0.0915762260556221, "critic_grad_norm": 0.1964905709028244, "ratio": 0.9998010993003845, "entropy": 0.656528639793396, "incre_win_rate": 0.8780487804878049, "step": 1352}
{"time": 1767157918.8922617, "phase": "train", "update": 1353, "total_env_steps": 4329600, "episode_reward": 0.2714610993862152, "value_loss": 0.005236725881695747, "policy_loss": -0.001023456549154389, "dist_entropy": 0.6696908831596374, "actor_grad_norm": 0.08636821806430817, "critic_grad_norm": 0.11383199691772461, "ratio": 1.000051736831665, "entropy": 0.6696908831596374, "incre_win_rate": 0.9555555555555556, "step": 1353}
{"time": 1767157923.182629, "phase": "train", "update": 1354, "total_env_steps": 4332800, "episode_reward": 0.2610839307308197, "value_loss": 0.0063091938383877276, "policy_loss": -0.0014566312679313853, "dist_entropy": 0.660940432548523, "actor_grad_norm": 0.09579461812973022, "critic_grad_norm": 0.10570565611124039, "ratio": 0.9999642372131348, "entropy": 0.660940432548523, "incre_win_rate": 0.9069767441860465, "step": 1354}
{"time": 1767157927.43221, "phase": "train", "update": 1355, "total_env_steps": 4336000, "episode_reward": 0.2518206834793091, "value_loss": 0.006737100146710873, "policy_loss": -0.0012454521891985594, "dist_entropy": 0.6730141282081604, "actor_grad_norm": 0.11298447102308273, "critic_grad_norm": 0.171842560172081, "ratio": 1.0002353191375732, "entropy": 0.6730141282081604, "incre_win_rate": 0.8571428571428571, "step": 1355}
{"time": 1767157931.6993315, "phase": "train", "update": 1356, "total_env_steps": 4339200, "episode_reward": 0.2628554403781891, "value_loss": 0.00647840304300189, "policy_loss": -0.0009802553200906061, "dist_entropy": 0.6645123958587646, "actor_grad_norm": 0.07606958597898483, "critic_grad_norm": 0.11428564786911011, "ratio": 1.0000728368759155, "entropy": 0.6645123958587646, "incre_win_rate": 0.926829268292683, "step": 1356}
{"time": 1767157935.9148462, "phase": "train", "update": 1357, "total_env_steps": 4342400, "episode_reward": 0.2540614902973175, "value_loss": 0.00617861058562994, "policy_loss": -0.001367118293870817, "dist_entropy": 0.7012941718101502, "actor_grad_norm": 0.0985632911324501, "critic_grad_norm": 0.08805830776691437, "ratio": 0.9996110200881958, "entropy": 0.7012941718101502, "incre_win_rate": 0.8863636363636364, "step": 1357}
{"time": 1767157940.1699538, "phase": "train", "update": 1358, "total_env_steps": 4345600, "episode_reward": 0.2585617005825043, "value_loss": 0.006121506262570619, "policy_loss": -0.0013872002853474897, "dist_entropy": 0.6906798481941223, "actor_grad_norm": 0.0888468399643898, "critic_grad_norm": 0.13149544596672058, "ratio": 1.0001051425933838, "entropy": 0.6906798481941223, "incre_win_rate": 0.8536585365853658, "step": 1358}
{"time": 1767157944.4899902, "phase": "train", "update": 1359, "total_env_steps": 4348800, "episode_reward": 0.26427361369132996, "value_loss": 0.009134224057197571, "policy_loss": -0.0014569863464629408, "dist_entropy": 0.7086915016174317, "actor_grad_norm": 0.09004559367895126, "critic_grad_norm": 0.1264413446187973, "ratio": 0.9995460510253906, "entropy": 0.7086915016174317, "incre_win_rate": 0.9285714285714286, "step": 1359}
{"time": 1767157948.778749, "phase": "train", "update": 1360, "total_env_steps": 4352000, "episode_reward": 0.25197020173072815, "value_loss": 0.010096150822937489, "policy_loss": -0.0012610155638320465, "dist_entropy": 0.6771738529205322, "actor_grad_norm": 0.11360056698322296, "critic_grad_norm": 0.1297285556793213, "ratio": 1.0001224279403687, "entropy": 0.6771738529205322, "incre_win_rate": 0.8043478260869565, "step": 1360}
{"time": 1767157953.0782485, "phase": "train", "update": 1361, "total_env_steps": 4355200, "episode_reward": 0.2579366862773895, "value_loss": 0.006998890545219183, "policy_loss": -0.0017265316509714524, "dist_entropy": 0.6760205507278443, "actor_grad_norm": 0.1411871761083603, "critic_grad_norm": 0.15381968021392822, "ratio": 0.9997912645339966, "entropy": 0.6760205507278443, "incre_win_rate": 0.9024390243902439, "step": 1361}
{"time": 1767157963.4775286, "phase": "eval", "update": 1361, "total_env_steps": 4355200, "eval_win_rate": 0.875, "eval_episode_reward": 19.23882450331126, "step": 1361}
{"time": 1767157967.7110648, "phase": "train", "update": 1362, "total_env_steps": 4358400, "episode_reward": 0.23892642557621002, "value_loss": 0.0112879429012537, "policy_loss": -0.0012940130599732313, "dist_entropy": 0.6536799073219299, "actor_grad_norm": 0.10542122274637222, "critic_grad_norm": 0.19212928414344788, "ratio": 0.9997555017471313, "entropy": 0.6536799073219299, "incre_win_rate": 0.75, "step": 1362}
{"time": 1767157971.9732287, "phase": "train", "update": 1363, "total_env_steps": 4361600, "episode_reward": 0.2560714781284332, "value_loss": 0.008341073896735907, "policy_loss": -0.001576737619305746, "dist_entropy": 0.6627150654792786, "actor_grad_norm": 0.11322367191314697, "critic_grad_norm": 0.17182345688343048, "ratio": 0.9998455047607422, "entropy": 0.6627150654792786, "incre_win_rate": 0.9047619047619048, "step": 1363}
{"time": 1767157976.215052, "phase": "train", "update": 1364, "total_env_steps": 4364800, "episode_reward": 0.25935688614845276, "value_loss": 0.00839947871863842, "policy_loss": -0.0013268103872498215, "dist_entropy": 0.655012845993042, "actor_grad_norm": 0.1070336103439331, "critic_grad_norm": 0.11126556247472763, "ratio": 1.000186800956726, "entropy": 0.655012845993042, "incre_win_rate": 0.9047619047619048, "step": 1364}
{"time": 1767157980.4972897, "phase": "train", "update": 1365, "total_env_steps": 4368000, "episode_reward": 0.2638244926929474, "value_loss": 0.00655180225148797, "policy_loss": -0.0013416249224576405, "dist_entropy": 0.6483810186386109, "actor_grad_norm": 0.0942627489566803, "critic_grad_norm": 0.18072107434272766, "ratio": 0.9999567270278931, "entropy": 0.6483810186386109, "incre_win_rate": 0.8444444444444444, "step": 1365}
{"time": 1767157984.7264783, "phase": "train", "update": 1366, "total_env_steps": 4371200, "episode_reward": 0.25132450461387634, "value_loss": 0.008673102781176566, "policy_loss": -0.0011847761328283469, "dist_entropy": 0.6342309474945068, "actor_grad_norm": 0.1185443326830864, "critic_grad_norm": 0.0727008655667305, "ratio": 1.0000797510147095, "entropy": 0.6342309474945068, "incre_win_rate": 0.8292682926829268, "step": 1366}
{"time": 1767157988.957952, "phase": "train", "update": 1367, "total_env_steps": 4374400, "episode_reward": 0.25323522090911865, "value_loss": 0.008198876865208149, "policy_loss": -0.0015490310942134044, "dist_entropy": 0.6385418772697449, "actor_grad_norm": 0.10891075432300568, "critic_grad_norm": 0.12336760014295578, "ratio": 1.000143051147461, "entropy": 0.6385418772697449, "incre_win_rate": 0.813953488372093, "step": 1367}
{"time": 1767157993.2306924, "phase": "train", "update": 1368, "total_env_steps": 4377600, "episode_reward": 0.266072541475296, "value_loss": 0.006841779220849276, "policy_loss": -0.0011236331255072506, "dist_entropy": 0.6368606805801391, "actor_grad_norm": 0.1142197772860527, "critic_grad_norm": 0.08702924102544785, "ratio": 0.9998083114624023, "entropy": 0.6368606805801391, "incre_win_rate": 0.8863636363636364, "step": 1368}
{"time": 1767157997.5209188, "phase": "train", "update": 1369, "total_env_steps": 4380800, "episode_reward": 0.2568129301071167, "value_loss": 0.009627623297274113, "policy_loss": -0.0011118769141548856, "dist_entropy": 0.6345876932144165, "actor_grad_norm": 0.10205268114805222, "critic_grad_norm": 0.14194980263710022, "ratio": 0.9998895525932312, "entropy": 0.6345876932144165, "incre_win_rate": 0.8809523809523809, "step": 1369}
{"time": 1767158001.8856158, "phase": "train", "update": 1370, "total_env_steps": 4384000, "episode_reward": 0.2534049153327942, "value_loss": 0.00813471209257841, "policy_loss": -0.0014528905418714545, "dist_entropy": 0.6624415636062622, "actor_grad_norm": 0.10128132253885269, "critic_grad_norm": 0.1423368901014328, "ratio": 1.0002442598342896, "entropy": 0.6624415636062622, "incre_win_rate": 0.9047619047619048, "step": 1370}
{"time": 1767158006.1592195, "phase": "train", "update": 1371, "total_env_steps": 4387200, "episode_reward": 0.25120601058006287, "value_loss": 0.005967255029827356, "policy_loss": -0.0009279056332630375, "dist_entropy": 0.643560528755188, "actor_grad_norm": 0.07405054569244385, "critic_grad_norm": 0.15690100193023682, "ratio": 0.9997860789299011, "entropy": 0.643560528755188, "incre_win_rate": 0.8780487804878049, "step": 1371}
{"time": 1767158010.4282496, "phase": "train", "update": 1372, "total_env_steps": 4390400, "episode_reward": 0.26869258284568787, "value_loss": 0.004218288231641054, "policy_loss": -0.0011274520333058647, "dist_entropy": 0.6608907103538513, "actor_grad_norm": 0.08746721595525742, "critic_grad_norm": 0.12422309070825577, "ratio": 1.000209093093872, "entropy": 0.6608907103538513, "incre_win_rate": 0.9090909090909091, "step": 1372}
{"time": 1767158014.7233303, "phase": "train", "update": 1373, "total_env_steps": 4393600, "episode_reward": 0.2716887593269348, "value_loss": 0.004081968497484922, "policy_loss": -0.0010070960157211317, "dist_entropy": 0.6483890771865845, "actor_grad_norm": 0.07539565861225128, "critic_grad_norm": 0.07223842293024063, "ratio": 1.0002373456954956, "entropy": 0.6483890771865845, "incre_win_rate": 0.9777777777777777, "step": 1373}
{"time": 1767158018.9989953, "phase": "train", "update": 1374, "total_env_steps": 4396800, "episode_reward": 0.26430463790893555, "value_loss": 0.004869886953383684, "policy_loss": -0.0013322534248835893, "dist_entropy": 0.6668239831924438, "actor_grad_norm": 0.08707888424396515, "critic_grad_norm": 0.16761526465415955, "ratio": 1.0002844333648682, "entropy": 0.6668239831924438, "incre_win_rate": 0.9512195121951219, "step": 1374}
{"time": 1767158023.2581902, "phase": "train", "update": 1375, "total_env_steps": 4400000, "episode_reward": 0.26004448533058167, "value_loss": 0.0067824854515492914, "policy_loss": -0.0014712984332518886, "dist_entropy": 0.6622404098510742, "actor_grad_norm": 0.09762831032276154, "critic_grad_norm": 0.0812513530254364, "ratio": 0.9999771118164062, "entropy": 0.6622404098510742, "incre_win_rate": 0.8444444444444444, "step": 1375}
{"time": 1767158027.5373473, "phase": "train", "update": 1376, "total_env_steps": 4403200, "episode_reward": 0.2695198953151703, "value_loss": 0.006476658303290606, "policy_loss": -0.0011184481435193127, "dist_entropy": 0.6590231776237487, "actor_grad_norm": 0.09763824194669724, "critic_grad_norm": 0.09445451200008392, "ratio": 0.9994007349014282, "entropy": 0.6590231776237487, "incre_win_rate": 0.9318181818181818, "step": 1376}
{"time": 1767158031.7970126, "phase": "train", "update": 1377, "total_env_steps": 4406400, "episode_reward": 0.25673842430114746, "value_loss": 0.00712732570245862, "policy_loss": -0.0009963528287244116, "dist_entropy": 0.6622054576873779, "actor_grad_norm": 0.1021232008934021, "critic_grad_norm": 0.08533710241317749, "ratio": 1.0000743865966797, "entropy": 0.6622054576873779, "incre_win_rate": 0.8333333333333334, "step": 1377}
{"time": 1767158036.10185, "phase": "train", "update": 1378, "total_env_steps": 4409600, "episode_reward": 0.27182531356811523, "value_loss": 0.004593917820602656, "policy_loss": -0.0012147115766238058, "dist_entropy": 0.6562841773033142, "actor_grad_norm": 0.11078319698572159, "critic_grad_norm": 0.06950151175260544, "ratio": 1.0003585815429688, "entropy": 0.6562841773033142, "incre_win_rate": 0.9555555555555556, "step": 1378}
{"time": 1767158040.3725336, "phase": "train", "update": 1379, "total_env_steps": 4412800, "episode_reward": 0.2595990300178528, "value_loss": 0.00931634847074747, "policy_loss": -0.0012887435170156891, "dist_entropy": 0.6362825155258178, "actor_grad_norm": 0.09649132192134857, "critic_grad_norm": 0.20110046863555908, "ratio": 0.9998106360435486, "entropy": 0.6362825155258178, "incre_win_rate": 0.8571428571428571, "step": 1379}
{"time": 1767158044.695337, "phase": "train", "update": 1380, "total_env_steps": 4416000, "episode_reward": 0.25858649611473083, "value_loss": 0.011979997344315051, "policy_loss": -0.0010986968844548528, "dist_entropy": 0.645504105091095, "actor_grad_norm": 0.09687473624944687, "critic_grad_norm": 0.19829067587852478, "ratio": 1.0002254247665405, "entropy": 0.645504105091095, "incre_win_rate": 0.7727272727272727, "step": 1380}
{"time": 1767158048.9793165, "phase": "train", "update": 1381, "total_env_steps": 4419200, "episode_reward": 0.2598158121109009, "value_loss": 0.008254870399832725, "policy_loss": -0.0014464546292238367, "dist_entropy": 0.6672958135604858, "actor_grad_norm": 0.11210336536169052, "critic_grad_norm": 0.10510139912366867, "ratio": 1.0001477003097534, "entropy": 0.6672958135604858, "incre_win_rate": 0.8372093023255814, "step": 1381}
{"time": 1767158059.125418, "phase": "eval", "update": 1381, "total_env_steps": 4419200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.478683774834437, "step": 1381}
{"time": 1767158063.393286, "phase": "train", "update": 1382, "total_env_steps": 4422400, "episode_reward": 0.2585529088973999, "value_loss": 0.007384710572659969, "policy_loss": -0.0014616222833382154, "dist_entropy": 0.667386257648468, "actor_grad_norm": 0.1042412519454956, "critic_grad_norm": 0.07677377760410309, "ratio": 0.99965900182724, "entropy": 0.667386257648468, "incre_win_rate": 0.8222222222222222, "step": 1382}
{"time": 1767158067.6819308, "phase": "train", "update": 1383, "total_env_steps": 4425600, "episode_reward": 0.27266815304756165, "value_loss": 0.00866104643791914, "policy_loss": -0.0013143890961348603, "dist_entropy": 0.6632998585700989, "actor_grad_norm": 0.08681652694940567, "critic_grad_norm": 0.06408677995204926, "ratio": 0.9997661709785461, "entropy": 0.6632998585700989, "incre_win_rate": 0.8888888888888888, "step": 1383}
{"time": 1767158071.9613376, "phase": "train", "update": 1384, "total_env_steps": 4428800, "episode_reward": 0.25195106863975525, "value_loss": 0.010228336602449418, "policy_loss": -0.0010798231051296625, "dist_entropy": 0.6322307109832763, "actor_grad_norm": 0.07763825356960297, "critic_grad_norm": 0.07892907410860062, "ratio": 0.9997744560241699, "entropy": 0.6322307109832763, "incre_win_rate": 0.8095238095238095, "step": 1384}
{"time": 1767158076.2814937, "phase": "train", "update": 1385, "total_env_steps": 4432000, "episode_reward": 0.278438538312912, "value_loss": 0.00733333257958293, "policy_loss": -0.0014468600248832785, "dist_entropy": 0.6497748851776123, "actor_grad_norm": 0.09371179342269897, "critic_grad_norm": 0.17669038474559784, "ratio": 0.9998601078987122, "entropy": 0.6497748851776123, "incre_win_rate": 0.9534883720930233, "step": 1385}
{"time": 1767158080.5505893, "phase": "train", "update": 1386, "total_env_steps": 4435200, "episode_reward": 0.2592487633228302, "value_loss": 0.00970868393778801, "policy_loss": -0.0011846849584109976, "dist_entropy": 0.6267052292823792, "actor_grad_norm": 0.09739583730697632, "critic_grad_norm": 0.1303027719259262, "ratio": 1.00018310546875, "entropy": 0.6267052292823792, "incre_win_rate": 0.8222222222222222, "step": 1386}
{"time": 1767158084.8294177, "phase": "train", "update": 1387, "total_env_steps": 4438400, "episode_reward": 0.26020383834838867, "value_loss": 0.008429311402142047, "policy_loss": -0.001459189297361263, "dist_entropy": 0.6108011841773987, "actor_grad_norm": 0.10310590267181396, "critic_grad_norm": 0.16078978776931763, "ratio": 1.0002864599227905, "entropy": 0.6108011841773987, "incre_win_rate": 0.8444444444444444, "step": 1387}
{"time": 1767158089.1089473, "phase": "train", "update": 1388, "total_env_steps": 4441600, "episode_reward": 0.2730044424533844, "value_loss": 0.008579609915614128, "policy_loss": -0.0011402886786367362, "dist_entropy": 0.6132774829864502, "actor_grad_norm": 0.07786834239959717, "critic_grad_norm": 0.10117337852716446, "ratio": 0.9997361302375793, "entropy": 0.6132774829864502, "incre_win_rate": 0.9069767441860465, "step": 1388}
{"time": 1767158093.4120748, "phase": "train", "update": 1389, "total_env_steps": 4444800, "episode_reward": 0.27567416429519653, "value_loss": 0.0049883871339261535, "policy_loss": -0.0010799618398749545, "dist_entropy": 0.5848538637161255, "actor_grad_norm": 0.09287421405315399, "critic_grad_norm": 0.0864093229174614, "ratio": 0.9999370574951172, "entropy": 0.5848538637161255, "incre_win_rate": 0.9333333333333333, "step": 1389}
{"time": 1767158097.6907718, "phase": "train", "update": 1390, "total_env_steps": 4448000, "episode_reward": 0.26816225051879883, "value_loss": 0.0071882431395351885, "policy_loss": -0.0013004975057132385, "dist_entropy": 0.5890498518943786, "actor_grad_norm": 0.08892907202243805, "critic_grad_norm": 0.10861324518918991, "ratio": 0.9998562932014465, "entropy": 0.5890498518943786, "incre_win_rate": 0.8666666666666667, "step": 1390}
{"time": 1767158101.9971902, "phase": "train", "update": 1391, "total_env_steps": 4451200, "episode_reward": 0.2700206935405731, "value_loss": 0.007467201445251703, "policy_loss": -0.0007891576820213686, "dist_entropy": 0.5723309755325318, "actor_grad_norm": 0.07909823954105377, "critic_grad_norm": 0.1393185704946518, "ratio": 0.9999915957450867, "entropy": 0.5723309755325318, "incre_win_rate": 0.9090909090909091, "step": 1391}
{"time": 1767158106.2997987, "phase": "train", "update": 1392, "total_env_steps": 4454400, "episode_reward": 0.2729428708553314, "value_loss": 0.008835973218083382, "policy_loss": -0.0009589200347701165, "dist_entropy": 0.5674222111701965, "actor_grad_norm": 0.08266320079565048, "critic_grad_norm": 0.12742705643177032, "ratio": 0.999799370765686, "entropy": 0.5674222111701965, "incre_win_rate": 0.8888888888888888, "step": 1392}
{"time": 1767158110.5788565, "phase": "train", "update": 1393, "total_env_steps": 4457600, "episode_reward": 0.2733692228794098, "value_loss": 0.008418811298906804, "policy_loss": -0.001300305531658097, "dist_entropy": 0.5911945343017578, "actor_grad_norm": 0.1107185035943985, "critic_grad_norm": 0.05123294144868851, "ratio": 0.9994704127311707, "entropy": 0.5911945343017578, "incre_win_rate": 0.9111111111111111, "step": 1393}
{"time": 1767158114.8955786, "phase": "train", "update": 1394, "total_env_steps": 4460800, "episode_reward": 0.28169962763786316, "value_loss": 0.006806570943444968, "policy_loss": -0.0012210729312329249, "dist_entropy": 0.6002371430397033, "actor_grad_norm": 0.12106024473905563, "critic_grad_norm": 0.045396316796541214, "ratio": 1.0000076293945312, "entropy": 0.6002371430397033, "incre_win_rate": 0.9361702127659575, "step": 1394}
{"time": 1767158119.2022815, "phase": "train", "update": 1395, "total_env_steps": 4464000, "episode_reward": 0.2773789167404175, "value_loss": 0.006218555662781, "policy_loss": -0.0008647121539439695, "dist_entropy": 0.6003435134887696, "actor_grad_norm": 0.09540998190641403, "critic_grad_norm": 0.03561486676335335, "ratio": 1.0002771615982056, "entropy": 0.6003435134887696, "incre_win_rate": 0.9534883720930233, "step": 1395}
{"time": 1767158123.488159, "phase": "train", "update": 1396, "total_env_steps": 4467200, "episode_reward": 0.2585528790950775, "value_loss": 0.00606838557869196, "policy_loss": -0.0013212802079792141, "dist_entropy": 0.6130085825920105, "actor_grad_norm": 0.0918140560388565, "critic_grad_norm": 0.07739116251468658, "ratio": 1.000292181968689, "entropy": 0.6130085825920105, "incre_win_rate": 0.8888888888888888, "step": 1396}
{"time": 1767158127.7601085, "phase": "train", "update": 1397, "total_env_steps": 4470400, "episode_reward": 0.27646729350090027, "value_loss": 0.005214122124016285, "policy_loss": -0.001356632028393534, "dist_entropy": 0.6046883940696717, "actor_grad_norm": 0.10947078466415405, "critic_grad_norm": 0.0842929258942604, "ratio": 1.0003583431243896, "entropy": 0.6046883940696717, "incre_win_rate": 0.9545454545454546, "step": 1397}
{"time": 1767158132.005813, "phase": "train", "update": 1398, "total_env_steps": 4473600, "episode_reward": 0.26644042134284973, "value_loss": 0.004712306335568428, "policy_loss": -0.0010780547151635345, "dist_entropy": 0.590216088294983, "actor_grad_norm": 0.09856795519590378, "critic_grad_norm": 0.07173760235309601, "ratio": 1.0001287460327148, "entropy": 0.590216088294983, "incre_win_rate": 0.9069767441860465, "step": 1398}
{"time": 1767158136.3147674, "phase": "train", "update": 1399, "total_env_steps": 4476800, "episode_reward": 0.26972994208335876, "value_loss": 0.0035514811985194682, "policy_loss": -0.0007013147291630162, "dist_entropy": 0.6138446450233459, "actor_grad_norm": 0.08552340418100357, "critic_grad_norm": 0.0447215735912323, "ratio": 1.000386357307434, "entropy": 0.6138446450233459, "incre_win_rate": 0.9555555555555556, "step": 1399}
{"time": 1767158140.5673978, "phase": "train", "update": 1400, "total_env_steps": 4480000, "episode_reward": 0.2821709215641022, "value_loss": 0.002820189483463764, "policy_loss": -0.0010412458125735214, "dist_entropy": 0.5933406710624695, "actor_grad_norm": 0.08647753298282623, "critic_grad_norm": 0.042443107813596725, "ratio": 1.000114917755127, "entropy": 0.5933406710624695, "incre_win_rate": 0.9772727272727273, "step": 1400}
{"time": 1767158144.8854702, "phase": "train", "update": 1401, "total_env_steps": 4483200, "episode_reward": 0.2709478735923767, "value_loss": 0.004351497069001198, "policy_loss": -0.0010496944918827467, "dist_entropy": 0.5935281038284301, "actor_grad_norm": 0.08108551055192947, "critic_grad_norm": 0.06025117635726929, "ratio": 0.9998877644538879, "entropy": 0.5935281038284301, "incre_win_rate": 0.9130434782608695, "step": 1401}
{"time": 1767158159.9077222, "phase": "eval", "update": 1401, "total_env_steps": 4483200, "eval_win_rate": 0.875, "eval_episode_reward": 19.073623758278146, "step": 1401}
{"time": 1767158164.251071, "phase": "train", "update": 1402, "total_env_steps": 4486400, "episode_reward": 0.2677913010120392, "value_loss": 0.0062307649292051796, "policy_loss": -0.0012962758946059693, "dist_entropy": 0.5787011027336121, "actor_grad_norm": 0.09545888751745224, "critic_grad_norm": 0.08775448054075241, "ratio": 0.9997550845146179, "entropy": 0.5787011027336121, "incre_win_rate": 0.8636363636363636, "step": 1402}
{"time": 1767158168.5078804, "phase": "train", "update": 1403, "total_env_steps": 4489600, "episode_reward": 0.27671462297439575, "value_loss": 0.007503269053995609, "policy_loss": -0.0009384934930306343, "dist_entropy": 0.5927527785301209, "actor_grad_norm": 0.06907601654529572, "critic_grad_norm": 0.11255469173192978, "ratio": 0.9999003410339355, "entropy": 0.5927527785301209, "incre_win_rate": 0.9534883720930233, "step": 1403}
{"time": 1767158172.8205192, "phase": "train", "update": 1404, "total_env_steps": 4492800, "episode_reward": 0.26851770281791687, "value_loss": 0.006293854583054781, "policy_loss": -0.0009968987927337024, "dist_entropy": 0.6097495436668396, "actor_grad_norm": 0.08411121368408203, "critic_grad_norm": 0.07802969217300415, "ratio": 0.9999292492866516, "entropy": 0.6097495436668396, "incre_win_rate": 0.8863636363636364, "step": 1404}
{"time": 1767158177.1278968, "phase": "train", "update": 1405, "total_env_steps": 4496000, "episode_reward": 0.2641380727291107, "value_loss": 0.006483971793204546, "policy_loss": -0.0010275680306311764, "dist_entropy": 0.6040599465370178, "actor_grad_norm": 0.08840669691562653, "critic_grad_norm": 0.07004579156637192, "ratio": 0.9999173283576965, "entropy": 0.6040599465370178, "incre_win_rate": 0.9069767441860465, "step": 1405}
{"time": 1767158181.4232078, "phase": "train", "update": 1406, "total_env_steps": 4499200, "episode_reward": 0.27611443400382996, "value_loss": 0.004350819904357195, "policy_loss": -0.0011062197729695856, "dist_entropy": 0.6080583572387696, "actor_grad_norm": 0.10766541957855225, "critic_grad_norm": 0.06711728125810623, "ratio": 0.9998575448989868, "entropy": 0.6080583572387696, "incre_win_rate": 0.9565217391304348, "step": 1406}
{"time": 1767158185.7914221, "phase": "train", "update": 1407, "total_env_steps": 4502400, "episode_reward": 0.2760471999645233, "value_loss": 0.0038617309648543595, "policy_loss": -0.001121586287522547, "dist_entropy": 0.6248229026794434, "actor_grad_norm": 0.12845532596111298, "critic_grad_norm": 0.05076484754681587, "ratio": 1.0004152059555054, "entropy": 0.6248229026794434, "incre_win_rate": 0.9555555555555556, "step": 1407}
{"time": 1767158190.1011, "phase": "train", "update": 1408, "total_env_steps": 4505600, "episode_reward": 0.28048014640808105, "value_loss": 0.004246327374130487, "policy_loss": -0.0012588982713459985, "dist_entropy": 0.5959208726882934, "actor_grad_norm": 0.08701517432928085, "critic_grad_norm": 0.07891863584518433, "ratio": 0.9999393820762634, "entropy": 0.5959208726882934, "incre_win_rate": 0.9777777777777777, "step": 1408}
{"time": 1767158194.3693185, "phase": "train", "update": 1409, "total_env_steps": 4508800, "episode_reward": 0.2735099494457245, "value_loss": 0.004635414388030767, "policy_loss": -0.0009788154142441386, "dist_entropy": 0.5985660195350647, "actor_grad_norm": 0.08277659118175507, "critic_grad_norm": 0.07818417996168137, "ratio": 0.9998408555984497, "entropy": 0.5985660195350647, "incre_win_rate": 0.9545454545454546, "step": 1409}
{"time": 1767158198.7071104, "phase": "train", "update": 1410, "total_env_steps": 4512000, "episode_reward": 0.2650398313999176, "value_loss": 0.00581519789993763, "policy_loss": -0.001425683560605684, "dist_entropy": 0.6048109531402588, "actor_grad_norm": 0.09033500403165817, "critic_grad_norm": 0.10637235641479492, "ratio": 0.9996799826622009, "entropy": 0.6048109531402588, "incre_win_rate": 0.8863636363636364, "step": 1410}
{"time": 1767158202.9512827, "phase": "train", "update": 1411, "total_env_steps": 4515200, "episode_reward": 0.26406508684158325, "value_loss": 0.005570279061794281, "policy_loss": -0.0009735761084296524, "dist_entropy": 0.5947056412696838, "actor_grad_norm": 0.075006864964962, "critic_grad_norm": 0.08910788595676422, "ratio": 0.9999002814292908, "entropy": 0.5947056412696838, "incre_win_rate": 0.9069767441860465, "step": 1411}
{"time": 1767158207.1783557, "phase": "train", "update": 1412, "total_env_steps": 4518400, "episode_reward": 0.2746999263763428, "value_loss": 0.006237264536321163, "policy_loss": -0.0010076833626023074, "dist_entropy": 0.5991036772727967, "actor_grad_norm": 0.07570115476846695, "critic_grad_norm": 0.12667587399482727, "ratio": 0.9998068809509277, "entropy": 0.5991036772727967, "incre_win_rate": 0.9302325581395349, "step": 1412}
{"time": 1767158211.4987743, "phase": "train", "update": 1413, "total_env_steps": 4521600, "episode_reward": 0.26676738262176514, "value_loss": 0.0059198373928666115, "policy_loss": -0.0012544013244786712, "dist_entropy": 0.601336944103241, "actor_grad_norm": 0.07928009331226349, "critic_grad_norm": 0.08676134049892426, "ratio": 0.9996822476387024, "entropy": 0.601336944103241, "incre_win_rate": 0.9333333333333333, "step": 1413}
{"time": 1767158215.813683, "phase": "train", "update": 1414, "total_env_steps": 4524800, "episode_reward": 0.2626800537109375, "value_loss": 0.00858459696173668, "policy_loss": -0.0012400225182744862, "dist_entropy": 0.6088859915733338, "actor_grad_norm": 0.06897275894880295, "critic_grad_norm": 0.10104306787252426, "ratio": 0.9997876286506653, "entropy": 0.6088859915733338, "incre_win_rate": 0.8636363636363636, "step": 1414}
{"time": 1767158220.0824602, "phase": "train", "update": 1415, "total_env_steps": 4528000, "episode_reward": 0.2574865221977234, "value_loss": 0.00784588111564517, "policy_loss": -0.0012254735895758984, "dist_entropy": 0.6078145861625671, "actor_grad_norm": 0.09381575882434845, "critic_grad_norm": 0.15078411996364594, "ratio": 1.000038981437683, "entropy": 0.6078145861625671, "incre_win_rate": 0.8809523809523809, "step": 1415}
{"time": 1767158224.378519, "phase": "train", "update": 1416, "total_env_steps": 4531200, "episode_reward": 0.2601034939289093, "value_loss": 0.008387881703674794, "policy_loss": -0.0012598449623212105, "dist_entropy": 0.6098984122276306, "actor_grad_norm": 0.11246871203184128, "critic_grad_norm": 0.1776958554983139, "ratio": 0.9998014569282532, "entropy": 0.6098984122276306, "incre_win_rate": 0.8181818181818182, "step": 1416}
{"time": 1767158228.6642628, "phase": "train", "update": 1417, "total_env_steps": 4534400, "episode_reward": 0.2665562927722931, "value_loss": 0.006169606652110815, "policy_loss": -0.0012761617294799522, "dist_entropy": 0.6027555584907531, "actor_grad_norm": 0.09920673817396164, "critic_grad_norm": 0.14970794320106506, "ratio": 1.0001105070114136, "entropy": 0.6027555584907531, "incre_win_rate": 0.8636363636363636, "step": 1417}
{"time": 1767158232.93369, "phase": "train", "update": 1418, "total_env_steps": 4537600, "episode_reward": 0.2685927152633667, "value_loss": 0.0073548429645597935, "policy_loss": -0.0012337962934026337, "dist_entropy": 0.6025637507438659, "actor_grad_norm": 0.0799977108836174, "critic_grad_norm": 0.12686984241008759, "ratio": 0.9999627470970154, "entropy": 0.6025637507438659, "incre_win_rate": 0.9090909090909091, "step": 1418}
{"time": 1767158237.2939682, "phase": "train", "update": 1419, "total_env_steps": 4540800, "episode_reward": 0.26577040553092957, "value_loss": 0.007666827086359263, "policy_loss": -0.0007778981209316527, "dist_entropy": 0.6059813499450684, "actor_grad_norm": 0.07095405459403992, "critic_grad_norm": 0.09045975655317307, "ratio": 0.9997215270996094, "entropy": 0.6059813499450684, "incre_win_rate": 0.8888888888888888, "step": 1419}
{"time": 1767158241.5764196, "phase": "train", "update": 1420, "total_env_steps": 4544000, "episode_reward": 0.26510658860206604, "value_loss": 0.008146569225937128, "policy_loss": -0.0009433538155889209, "dist_entropy": 0.6242994904518128, "actor_grad_norm": 0.08767446130514145, "critic_grad_norm": 0.1716548204421997, "ratio": 1.000217080116272, "entropy": 0.6242994904518128, "incre_win_rate": 0.9285714285714286, "step": 1420}
{"time": 1767158245.880686, "phase": "train", "update": 1421, "total_env_steps": 4547200, "episode_reward": 0.2582615911960602, "value_loss": 0.006457517668604851, "policy_loss": -0.0009207716017037182, "dist_entropy": 0.6371074795722962, "actor_grad_norm": 0.0704081580042839, "critic_grad_norm": 0.12640808522701263, "ratio": 0.9998623132705688, "entropy": 0.6371074795722962, "incre_win_rate": 0.8604651162790697, "step": 1421}
{"time": 1767158256.1311114, "phase": "eval", "update": 1421, "total_env_steps": 4547200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.674254966887418, "step": 1421}
{"time": 1767158260.4205613, "phase": "train", "update": 1422, "total_env_steps": 4550400, "episode_reward": 0.2560596168041229, "value_loss": 0.011970570124685765, "policy_loss": -0.0013115396967144477, "dist_entropy": 0.6201827645301818, "actor_grad_norm": 0.0818515494465828, "critic_grad_norm": 0.17632268369197845, "ratio": 0.9999008178710938, "entropy": 0.6201827645301818, "incre_win_rate": 0.8, "step": 1422}
{"time": 1767158264.7008717, "phase": "train", "update": 1423, "total_env_steps": 4553600, "episode_reward": 0.2632243037223816, "value_loss": 0.006931373197585344, "policy_loss": -0.0016688005100689907, "dist_entropy": 0.6199451088905334, "actor_grad_norm": 0.09894493222236633, "critic_grad_norm": 0.08190051466226578, "ratio": 0.9997462630271912, "entropy": 0.6199451088905334, "incre_win_rate": 0.8571428571428571, "step": 1423}
{"time": 1767158269.0155385, "phase": "train", "update": 1424, "total_env_steps": 4556800, "episode_reward": 0.2702690362930298, "value_loss": 0.005967515613883733, "policy_loss": -0.0015163554946497015, "dist_entropy": 0.6103951573371887, "actor_grad_norm": 0.09414216130971909, "critic_grad_norm": 0.0856962576508522, "ratio": 1.0000152587890625, "entropy": 0.6103951573371887, "incre_win_rate": 0.9130434782608695, "step": 1424}
{"time": 1767158273.2391608, "phase": "train", "update": 1425, "total_env_steps": 4560000, "episode_reward": 0.26711711287498474, "value_loss": 0.008859319239854812, "policy_loss": -0.0013613697671672753, "dist_entropy": 0.6275761008262635, "actor_grad_norm": 0.0882888063788414, "critic_grad_norm": 0.028470996767282486, "ratio": 0.9999047517776489, "entropy": 0.6275761008262635, "incre_win_rate": 0.8837209302325582, "step": 1425}
{"time": 1767158277.5643497, "phase": "train", "update": 1426, "total_env_steps": 4563200, "episode_reward": 0.27482616901397705, "value_loss": 0.0064308569766581055, "policy_loss": -0.0018267102822687065, "dist_entropy": 0.6274438619613647, "actor_grad_norm": 0.09828756004571915, "critic_grad_norm": 0.0672716423869133, "ratio": 0.9996883273124695, "entropy": 0.6274438619613647, "incre_win_rate": 0.9318181818181818, "step": 1426}
{"time": 1767158281.8718147, "phase": "train", "update": 1427, "total_env_steps": 4566400, "episode_reward": 0.27582472562789917, "value_loss": 0.005094967968761921, "policy_loss": -0.0015655217149557644, "dist_entropy": 0.6308401703834534, "actor_grad_norm": 0.10040543228387833, "critic_grad_norm": 0.07157275080680847, "ratio": 0.9992973208427429, "entropy": 0.6308401703834534, "incre_win_rate": 0.9772727272727273, "step": 1427}
{"time": 1767158286.1296763, "phase": "train", "update": 1428, "total_env_steps": 4569600, "episode_reward": 0.2617730498313904, "value_loss": 0.007533144764602184, "policy_loss": -0.0009220425638361007, "dist_entropy": 0.6075626611709595, "actor_grad_norm": 0.0849650427699089, "critic_grad_norm": 0.11906281858682632, "ratio": 1.0001493692398071, "entropy": 0.6075626611709595, "incre_win_rate": 0.8444444444444444, "step": 1428}
{"time": 1767158290.3743002, "phase": "train", "update": 1429, "total_env_steps": 4572800, "episode_reward": 0.2560596168041229, "value_loss": 0.008027079980820417, "policy_loss": -0.0010627516719139863, "dist_entropy": 0.6087657451629639, "actor_grad_norm": 0.07562140375375748, "critic_grad_norm": 0.11215545982122421, "ratio": 1.0000126361846924, "entropy": 0.6087657451629639, "incre_win_rate": 0.8222222222222222, "step": 1429}
{"time": 1767158294.7134974, "phase": "train", "update": 1430, "total_env_steps": 4576000, "episode_reward": 0.26852649450302124, "value_loss": 0.009020552411675454, "policy_loss": -0.001374771464065816, "dist_entropy": 0.6262985348701477, "actor_grad_norm": 0.11207839101552963, "critic_grad_norm": 0.12029752880334854, "ratio": 1.0000873804092407, "entropy": 0.6262985348701477, "incre_win_rate": 0.8837209302325582, "step": 1430}
{"time": 1767158299.0151696, "phase": "train", "update": 1431, "total_env_steps": 4579200, "episode_reward": 0.2676779627799988, "value_loss": 0.006406896095722914, "policy_loss": -0.0011467714873433011, "dist_entropy": 0.6154578566551209, "actor_grad_norm": 0.08682074397802353, "critic_grad_norm": 0.15793918073177338, "ratio": 0.9999814033508301, "entropy": 0.6154578566551209, "incre_win_rate": 0.9302325581395349, "step": 1431}
{"time": 1767158303.3507009, "phase": "train", "update": 1432, "total_env_steps": 4582400, "episode_reward": 0.277092307806015, "value_loss": 0.005122415069490671, "policy_loss": -0.0010577832270449506, "dist_entropy": 0.6247472405433655, "actor_grad_norm": 0.06415893137454987, "critic_grad_norm": 0.06458545476198196, "ratio": 0.9996496438980103, "entropy": 0.6247472405433655, "incre_win_rate": 0.9574468085106383, "step": 1432}
{"time": 1767158307.6931047, "phase": "train", "update": 1433, "total_env_steps": 4585600, "episode_reward": 0.27385348081588745, "value_loss": 0.004924111347645521, "policy_loss": -0.0011209941346848496, "dist_entropy": 0.6414945602416993, "actor_grad_norm": 0.0834260955452919, "critic_grad_norm": 0.035138946026563644, "ratio": 0.9997707605361938, "entropy": 0.6414945602416993, "incre_win_rate": 0.9523809523809523, "step": 1433}
{"time": 1767158311.964964, "phase": "train", "update": 1434, "total_env_steps": 4588800, "episode_reward": 0.2682574391365051, "value_loss": 0.006580715347081423, "policy_loss": -0.0007739850013278371, "dist_entropy": 0.6391187906265259, "actor_grad_norm": 0.07367114722728729, "critic_grad_norm": 0.08552564680576324, "ratio": 1.0000909566879272, "entropy": 0.6391187906265259, "incre_win_rate": 0.9347826086956522, "step": 1434}
{"time": 1767158316.1957238, "phase": "train", "update": 1435, "total_env_steps": 4592000, "episode_reward": 0.2679283916950226, "value_loss": 0.006230961717665196, "policy_loss": -0.0008810511804721699, "dist_entropy": 0.6365340948104858, "actor_grad_norm": 0.08637453615665436, "critic_grad_norm": 0.12146370857954025, "ratio": 0.9998819231987, "entropy": 0.6365340948104858, "incre_win_rate": 0.926829268292683, "step": 1435}
{"time": 1767158320.4485734, "phase": "train", "update": 1436, "total_env_steps": 4595200, "episode_reward": 0.2681405246257782, "value_loss": 0.004382325615733862, "policy_loss": -0.0013484275869330986, "dist_entropy": 0.6446498155593872, "actor_grad_norm": 0.08674923330545425, "critic_grad_norm": 0.10458152741193771, "ratio": 1.0001226663589478, "entropy": 0.6446498155593872, "incre_win_rate": 0.9333333333333333, "step": 1436}
{"time": 1767158324.7577083, "phase": "train", "update": 1437, "total_env_steps": 4598400, "episode_reward": 0.27014076709747314, "value_loss": 0.006034363154321909, "policy_loss": -0.000977952916559488, "dist_entropy": 0.6623396873474121, "actor_grad_norm": 0.08013360947370529, "critic_grad_norm": 0.07956687361001968, "ratio": 1.0001842975616455, "entropy": 0.6623396873474121, "incre_win_rate": 0.9318181818181818, "step": 1437}
{"time": 1767158329.0977743, "phase": "train", "update": 1438, "total_env_steps": 4601600, "episode_reward": 0.27079522609710693, "value_loss": 0.0062498502433300015, "policy_loss": -0.0011733277898969164, "dist_entropy": 0.663307499885559, "actor_grad_norm": 0.09939216822385788, "critic_grad_norm": 0.09328531473875046, "ratio": 0.9998159408569336, "entropy": 0.663307499885559, "incre_win_rate": 0.9333333333333333, "step": 1438}
{"time": 1767158333.394248, "phase": "train", "update": 1439, "total_env_steps": 4604800, "episode_reward": 0.27207159996032715, "value_loss": 0.008345982246100902, "policy_loss": -0.0008838488431308633, "dist_entropy": 0.6983619928359985, "actor_grad_norm": 0.08657468110322952, "critic_grad_norm": 0.08578457683324814, "ratio": 0.999237060546875, "entropy": 0.6983619928359985, "incre_win_rate": 0.8863636363636364, "step": 1439}
{"time": 1767158337.6976, "phase": "train", "update": 1440, "total_env_steps": 4608000, "episode_reward": 0.2604842483997345, "value_loss": 0.008239813148975372, "policy_loss": -0.0012328094756234975, "dist_entropy": 0.7012816429138183, "actor_grad_norm": 0.0894559696316719, "critic_grad_norm": 0.05252263695001602, "ratio": 0.9999117851257324, "entropy": 0.7012816429138183, "incre_win_rate": 0.8409090909090909, "step": 1440}
{"time": 1767158342.0019655, "phase": "train", "update": 1441, "total_env_steps": 4611200, "episode_reward": 0.2565500736236572, "value_loss": 0.012504168786108494, "policy_loss": -0.001241416021352393, "dist_entropy": 0.6978458285331726, "actor_grad_norm": 0.08922918140888214, "critic_grad_norm": 0.05974048376083374, "ratio": 1.0000313520431519, "entropy": 0.6978458285331726, "incre_win_rate": 0.7954545454545454, "step": 1441}
{"time": 1767158351.9438848, "phase": "eval", "update": 1441, "total_env_steps": 4611200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.862479304635762, "step": 1441}
{"time": 1767158356.2104325, "phase": "train", "update": 1442, "total_env_steps": 4614400, "episode_reward": 0.2504325211048126, "value_loss": 0.012159573845565319, "policy_loss": -0.0013282306710443947, "dist_entropy": 0.6976636290550232, "actor_grad_norm": 0.09799624979496002, "critic_grad_norm": 0.06163664534687996, "ratio": 0.9997960925102234, "entropy": 0.6976636290550232, "incre_win_rate": 0.7857142857142857, "step": 1442}
{"time": 1767158360.505343, "phase": "train", "update": 1443, "total_env_steps": 4617600, "episode_reward": 0.2590666711330414, "value_loss": 0.010106229409575462, "policy_loss": -0.0013179059458412468, "dist_entropy": 0.7076771855354309, "actor_grad_norm": 0.10599692910909653, "critic_grad_norm": 0.06897424906492233, "ratio": 1.0004692077636719, "entropy": 0.7076771855354309, "incre_win_rate": 0.8666666666666667, "step": 1443}
{"time": 1767158364.7703118, "phase": "train", "update": 1444, "total_env_steps": 4620800, "episode_reward": 0.264294296503067, "value_loss": 0.010548989847302436, "policy_loss": -0.0010160401779231165, "dist_entropy": 0.7062163591384888, "actor_grad_norm": 0.11597322672605515, "critic_grad_norm": 0.07470396906137466, "ratio": 0.9998793005943298, "entropy": 0.7062163591384888, "incre_win_rate": 0.8571428571428571, "step": 1444}
{"time": 1767158368.9575055, "phase": "train", "update": 1445, "total_env_steps": 4624000, "episode_reward": 0.2532445192337036, "value_loss": 0.007896708976477384, "policy_loss": -0.0015017473231608847, "dist_entropy": 0.7169600248336792, "actor_grad_norm": 0.11707185953855515, "critic_grad_norm": 0.05109638720750809, "ratio": 1.0000298023223877, "entropy": 0.7169600248336792, "incre_win_rate": 0.9, "step": 1445}
{"time": 1767158373.3824956, "phase": "train", "update": 1446, "total_env_steps": 4627200, "episode_reward": 0.25836506485939026, "value_loss": 0.00637456364929676, "policy_loss": -0.0014240898918398415, "dist_entropy": 0.7163010835647583, "actor_grad_norm": 0.11264368146657944, "critic_grad_norm": 0.06739053875207901, "ratio": 1.0001822710037231, "entropy": 0.7163010835647583, "incre_win_rate": 0.8695652173913043, "step": 1446}
{"time": 1767158377.6198082, "phase": "train", "update": 1447, "total_env_steps": 4630400, "episode_reward": 0.24794287979602814, "value_loss": 0.008797351084649564, "policy_loss": -0.0008439861243868307, "dist_entropy": 0.7025272965431213, "actor_grad_norm": 0.10126149654388428, "critic_grad_norm": 0.10430289804935455, "ratio": 1.0001757144927979, "entropy": 0.7025272965431213, "incre_win_rate": 0.8205128205128205, "step": 1447}
{"time": 1767158381.8905437, "phase": "train", "update": 1448, "total_env_steps": 4633600, "episode_reward": 0.2403637319803238, "value_loss": 0.006939950585365296, "policy_loss": -0.0010750951085185534, "dist_entropy": 0.718460202217102, "actor_grad_norm": 0.10818058252334595, "critic_grad_norm": 0.1140550896525383, "ratio": 0.9999937415122986, "entropy": 0.718460202217102, "incre_win_rate": 0.7857142857142857, "step": 1448}
{"time": 1767158386.160221, "phase": "train", "update": 1449, "total_env_steps": 4636800, "episode_reward": 0.25430360436439514, "value_loss": 0.009692281298339368, "policy_loss": -0.0015993108589356098, "dist_entropy": 0.6899154901504516, "actor_grad_norm": 0.11540794372558594, "critic_grad_norm": 0.21072308719158173, "ratio": 1.00010347366333, "entropy": 0.6899154901504516, "incre_win_rate": 0.8292682926829268, "step": 1449}
{"time": 1767158390.4313726, "phase": "train", "update": 1450, "total_env_steps": 4640000, "episode_reward": 0.26083090901374817, "value_loss": 0.010152088105678558, "policy_loss": -0.0014762889032866155, "dist_entropy": 0.691082215309143, "actor_grad_norm": 0.07873495668172836, "critic_grad_norm": 0.11904680728912354, "ratio": 1.0003231763839722, "entropy": 0.691082215309143, "incre_win_rate": 0.8863636363636364, "step": 1450}
{"time": 1767158394.6711545, "phase": "train", "update": 1451, "total_env_steps": 4643200, "episode_reward": 0.24626758694648743, "value_loss": 0.010004731640219689, "policy_loss": -0.0015826419234478805, "dist_entropy": 0.6543755054473877, "actor_grad_norm": 0.10058333724737167, "critic_grad_norm": 0.08559544384479523, "ratio": 1.0004756450653076, "entropy": 0.6543755054473877, "incre_win_rate": 0.7857142857142857, "step": 1451}
{"time": 1767158398.9314947, "phase": "train", "update": 1452, "total_env_steps": 4646400, "episode_reward": 0.2650124430656433, "value_loss": 0.0093791626393795, "policy_loss": -0.0010835885300082282, "dist_entropy": 0.6479789733886718, "actor_grad_norm": 0.09537892788648605, "critic_grad_norm": 0.16157160699367523, "ratio": 0.9999113082885742, "entropy": 0.6479789733886718, "incre_win_rate": 0.9090909090909091, "step": 1452}
{"time": 1767158403.1637743, "phase": "train", "update": 1453, "total_env_steps": 4649600, "episode_reward": 0.26569125056266785, "value_loss": 0.006292888149619103, "policy_loss": -0.001049649921789353, "dist_entropy": 0.661646842956543, "actor_grad_norm": 0.08958058059215546, "critic_grad_norm": 0.13517415523529053, "ratio": 1.0001791715621948, "entropy": 0.661646842956543, "incre_win_rate": 0.9090909090909091, "step": 1453}
{"time": 1767158407.3915129, "phase": "train", "update": 1454, "total_env_steps": 4652800, "episode_reward": 0.25783011317253113, "value_loss": 0.00801182072609663, "policy_loss": -0.0012545989006753188, "dist_entropy": 0.642870032787323, "actor_grad_norm": 0.07433482259511948, "critic_grad_norm": 0.13170267641544342, "ratio": 0.9997731447219849, "entropy": 0.642870032787323, "incre_win_rate": 0.8780487804878049, "step": 1454}
{"time": 1767158411.6759176, "phase": "train", "update": 1455, "total_env_steps": 4656000, "episode_reward": 0.26513659954071045, "value_loss": 0.005500965472310782, "policy_loss": -0.0011266461655977, "dist_entropy": 0.6358536124229431, "actor_grad_norm": 0.08185674250125885, "critic_grad_norm": 0.0836147740483284, "ratio": 0.999934196472168, "entropy": 0.6358536124229431, "incre_win_rate": 0.9111111111111111, "step": 1455}
{"time": 1767158415.978944, "phase": "train", "update": 1456, "total_env_steps": 4659200, "episode_reward": 0.2745778262615204, "value_loss": 0.0035421492997556926, "policy_loss": -0.0011168226888486287, "dist_entropy": 0.643912959098816, "actor_grad_norm": 0.08682836592197418, "critic_grad_norm": 0.12000932544469833, "ratio": 0.9996556639671326, "entropy": 0.643912959098816, "incre_win_rate": 0.9767441860465116, "step": 1456}
{"time": 1767158420.2335982, "phase": "train", "update": 1457, "total_env_steps": 4662400, "episode_reward": 0.2644246816635132, "value_loss": 0.005006259959191084, "policy_loss": -0.001148939339478261, "dist_entropy": 0.6486333250999451, "actor_grad_norm": 0.08431577682495117, "critic_grad_norm": 0.09645938128232956, "ratio": 1.000046968460083, "entropy": 0.6486333250999451, "incre_win_rate": 0.8604651162790697, "step": 1457}
{"time": 1767158424.4845004, "phase": "train", "update": 1458, "total_env_steps": 4665600, "episode_reward": 0.2724917232990265, "value_loss": 0.0039337723515927795, "policy_loss": -0.0012228915369461024, "dist_entropy": 0.6391228914260865, "actor_grad_norm": 0.09104537218809128, "critic_grad_norm": 0.06547673791646957, "ratio": 1.0005133152008057, "entropy": 0.6391228914260865, "incre_win_rate": 0.9333333333333333, "step": 1458}
{"time": 1767158428.7147539, "phase": "train", "update": 1459, "total_env_steps": 4668800, "episode_reward": 0.2754708230495453, "value_loss": 0.005134924780577421, "policy_loss": -0.0008878971008783765, "dist_entropy": 0.631128978729248, "actor_grad_norm": 0.07896646112203598, "critic_grad_norm": 0.12803040444850922, "ratio": 1.0000255107879639, "entropy": 0.631128978729248, "incre_win_rate": 0.9555555555555556, "step": 1459}
{"time": 1767158432.9806664, "phase": "train", "update": 1460, "total_env_steps": 4672000, "episode_reward": 0.27264073491096497, "value_loss": 0.006252088584005833, "policy_loss": -0.0011980945900148753, "dist_entropy": 0.6161247849464416, "actor_grad_norm": 0.08557678014039993, "critic_grad_norm": 0.1715126782655716, "ratio": 0.9997051358222961, "entropy": 0.6161247849464416, "incre_win_rate": 0.9545454545454546, "step": 1460}
{"time": 1767158437.1984313, "phase": "train", "update": 1461, "total_env_steps": 4675200, "episode_reward": 0.2658650875091553, "value_loss": 0.004181846417486668, "policy_loss": -0.001293549435166952, "dist_entropy": 0.6189317107200623, "actor_grad_norm": 0.09091188758611679, "critic_grad_norm": 0.08865245431661606, "ratio": 1.0000417232513428, "entropy": 0.6189317107200623, "incre_win_rate": 0.9534883720930233, "step": 1461}
{"time": 1767158447.089125, "phase": "eval", "update": 1461, "total_env_steps": 4675200, "eval_win_rate": 1.0, "eval_episode_reward": 20.0, "step": 1461}
{"time": 1767158451.3430796, "phase": "train", "update": 1462, "total_env_steps": 4678400, "episode_reward": 0.2746678590774536, "value_loss": 0.005973267182707786, "policy_loss": -0.001214897183305652, "dist_entropy": 0.6026330947875976, "actor_grad_norm": 0.10414232313632965, "critic_grad_norm": 0.08681198209524155, "ratio": 0.9999397397041321, "entropy": 0.6026330947875976, "incre_win_rate": 0.9545454545454546, "step": 1462}
{"time": 1767158455.6325924, "phase": "train", "update": 1463, "total_env_steps": 4681600, "episode_reward": 0.26843544840812683, "value_loss": 0.003948038350790739, "policy_loss": -0.0009885164519133128, "dist_entropy": 0.5843325138092041, "actor_grad_norm": 0.110076405107975, "critic_grad_norm": 0.085109643638134, "ratio": 1.000847339630127, "entropy": 0.5843325138092041, "incre_win_rate": 0.9069767441860465, "step": 1463}
{"time": 1767158459.9085722, "phase": "train", "update": 1464, "total_env_steps": 4684800, "episode_reward": 0.26750412583351135, "value_loss": 0.005535091459751129, "policy_loss": -0.0009314159561167656, "dist_entropy": 0.5860501885414123, "actor_grad_norm": 0.08426292985677719, "critic_grad_norm": 0.11535384505987167, "ratio": 1.0000890493392944, "entropy": 0.5860501885414123, "incre_win_rate": 0.9555555555555556, "step": 1464}
{"time": 1767158464.2259486, "phase": "train", "update": 1465, "total_env_steps": 4688000, "episode_reward": 0.2748427093029022, "value_loss": 0.0051109764724969866, "policy_loss": -0.0009674522229126126, "dist_entropy": 0.5971551537513733, "actor_grad_norm": 0.096476249396801, "critic_grad_norm": 0.10475865751504898, "ratio": 0.9998343586921692, "entropy": 0.5971551537513733, "incre_win_rate": 0.9318181818181818, "step": 1465}
{"time": 1767158468.5077283, "phase": "train", "update": 1466, "total_env_steps": 4691200, "episode_reward": 0.26156455278396606, "value_loss": 0.007239401713013649, "policy_loss": -0.0014412088022240255, "dist_entropy": 0.5996765255928039, "actor_grad_norm": 0.09423702955245972, "critic_grad_norm": 0.0747494176030159, "ratio": 0.9998348355293274, "entropy": 0.5996765255928039, "incre_win_rate": 0.8409090909090909, "step": 1466}
{"time": 1767158472.778848, "phase": "train", "update": 1467, "total_env_steps": 4694400, "episode_reward": 0.2711222171783447, "value_loss": 0.006092494353652, "policy_loss": -0.0009050386605446992, "dist_entropy": 0.6185960054397583, "actor_grad_norm": 0.08108943700790405, "critic_grad_norm": 0.07518361508846283, "ratio": 1.000113844871521, "entropy": 0.6185960054397583, "incre_win_rate": 0.9111111111111111, "step": 1467}
{"time": 1767158477.0603728, "phase": "train", "update": 1468, "total_env_steps": 4697600, "episode_reward": 0.2710968255996704, "value_loss": 0.005474334768950939, "policy_loss": -0.0012524424004816126, "dist_entropy": 0.6081098556518555, "actor_grad_norm": 0.09763572365045547, "critic_grad_norm": 0.10511454194784164, "ratio": 1.0000224113464355, "entropy": 0.6081098556518555, "incre_win_rate": 0.9545454545454546, "step": 1468}
{"time": 1767158481.3630831, "phase": "train", "update": 1469, "total_env_steps": 4700800, "episode_reward": 0.27516970038414, "value_loss": 0.005422327667474747, "policy_loss": -0.0015241774979259048, "dist_entropy": 0.6308166027069092, "actor_grad_norm": 0.12095139175653458, "critic_grad_norm": 0.08303874731063843, "ratio": 1.0000977516174316, "entropy": 0.6308166027069092, "incre_win_rate": 0.9772727272727273, "step": 1469}
{"time": 1767158514.9879808, "phase": "train", "update": 1470, "total_env_steps": 4704000, "episode_reward": 0.26060429215431213, "value_loss": 0.06597682684659958, "policy_loss": -0.001089230001488417, "dist_entropy": 0.6535651206970214, "actor_grad_norm": 0.07364507019519806, "critic_grad_norm": 0.3994590938091278, "ratio": 0.9996663928031921, "entropy": 0.6535651206970214, "incre_win_rate": 0.9090909090909091, "step": 1470}
{"time": 1767158519.235848, "phase": "train", "update": 1471, "total_env_steps": 4707200, "episode_reward": 0.26056551933288574, "value_loss": 0.009339634701609612, "policy_loss": -0.0013082919418777373, "dist_entropy": 0.6647723913192749, "actor_grad_norm": 0.0916764885187149, "critic_grad_norm": 0.2450258582830429, "ratio": 0.9998979568481445, "entropy": 0.6647723913192749, "incre_win_rate": 0.8, "step": 1471}
{"time": 1767158523.4671454, "phase": "train", "update": 1472, "total_env_steps": 4710400, "episode_reward": 0.26797598600387573, "value_loss": 0.0069433671422302725, "policy_loss": -0.001136011194926212, "dist_entropy": 0.6532864570617676, "actor_grad_norm": 0.07905985414981842, "critic_grad_norm": 0.1606684923171997, "ratio": 0.9999489188194275, "entropy": 0.6532864570617676, "incre_win_rate": 0.9767441860465116, "step": 1472}
{"time": 1767158527.7123969, "phase": "train", "update": 1473, "total_env_steps": 4713600, "episode_reward": 0.27597683668136597, "value_loss": 0.003563127899542451, "policy_loss": -0.0008476704078844932, "dist_entropy": 0.6574759721755982, "actor_grad_norm": 0.08441381901502609, "critic_grad_norm": 0.14551272988319397, "ratio": 1.0002120733261108, "entropy": 0.6574759721755982, "incre_win_rate": 0.9787234042553191, "step": 1473}
{"time": 1767158531.915122, "phase": "train", "update": 1474, "total_env_steps": 4716800, "episode_reward": 0.27584022283554077, "value_loss": 0.004252472892403603, "policy_loss": -0.0010378344502981918, "dist_entropy": 0.6704458355903625, "actor_grad_norm": 0.08076389878988266, "critic_grad_norm": 0.11917056888341904, "ratio": 1.000058889389038, "entropy": 0.6704458355903625, "incre_win_rate": 0.9523809523809523, "step": 1474}
{"time": 1767158536.1706777, "phase": "train", "update": 1475, "total_env_steps": 4720000, "episode_reward": 0.27148643136024475, "value_loss": 0.0052997486665844916, "policy_loss": -0.001236412320346858, "dist_entropy": 0.6491018295288086, "actor_grad_norm": 0.10414429008960724, "critic_grad_norm": 0.07062765210866928, "ratio": 0.9999839663505554, "entropy": 0.6491018295288086, "incre_win_rate": 0.9347826086956522, "step": 1475}
{"time": 1767158540.4078658, "phase": "train", "update": 1476, "total_env_steps": 4723200, "episode_reward": 0.26808205246925354, "value_loss": 0.006296722404658795, "policy_loss": -0.001600471314362295, "dist_entropy": 0.6700286746025086, "actor_grad_norm": 0.12825517356395721, "critic_grad_norm": 0.17783255875110626, "ratio": 0.9997953772544861, "entropy": 0.6700286746025086, "incre_win_rate": 0.9302325581395349, "step": 1476}
{"time": 1767158544.663193, "phase": "train", "update": 1477, "total_env_steps": 4726400, "episode_reward": 0.25148284435272217, "value_loss": 0.007112702261656523, "policy_loss": -0.001328215640418584, "dist_entropy": 0.6761398792266846, "actor_grad_norm": 0.09685813635587692, "critic_grad_norm": 0.12736831605434418, "ratio": 0.9997863173484802, "entropy": 0.6761398792266846, "incre_win_rate": 0.9, "step": 1477}
{"time": 1767158548.9084036, "phase": "train", "update": 1478, "total_env_steps": 4729600, "episode_reward": 0.2528342306613922, "value_loss": 0.004194653872400522, "policy_loss": -0.0013637956828674192, "dist_entropy": 0.6525553941726685, "actor_grad_norm": 0.09469524770975113, "critic_grad_norm": 0.06675498932600021, "ratio": 1.000044822692871, "entropy": 0.6525553941726685, "incre_win_rate": 0.8837209302325582, "step": 1478}
{"time": 1767158553.2070668, "phase": "train", "update": 1479, "total_env_steps": 4732800, "episode_reward": 0.2676241397857666, "value_loss": 0.0054064934141933915, "policy_loss": -0.0010272353508561593, "dist_entropy": 0.6457359075546265, "actor_grad_norm": 0.09018176048994064, "critic_grad_norm": 0.08257610350847244, "ratio": 0.9997413754463196, "entropy": 0.6457359075546265, "incre_win_rate": 0.9302325581395349, "step": 1479}
{"time": 1767158557.4915786, "phase": "train", "update": 1480, "total_env_steps": 4736000, "episode_reward": 0.264987587928772, "value_loss": 0.007343212049454451, "policy_loss": -0.001300327698439041, "dist_entropy": 0.6577236413955688, "actor_grad_norm": 0.12993447482585907, "critic_grad_norm": 0.06030469015240669, "ratio": 1.0002354383468628, "entropy": 0.6577236413955688, "incre_win_rate": 0.8863636363636364, "step": 1480}
{"time": 1767158561.7964127, "phase": "train", "update": 1481, "total_env_steps": 4739200, "episode_reward": 0.27673014998435974, "value_loss": 0.003764372132718563, "policy_loss": -0.0008684969307395818, "dist_entropy": 0.660369598865509, "actor_grad_norm": 0.11178809404373169, "critic_grad_norm": 0.08738984167575836, "ratio": 1.0000401735305786, "entropy": 0.660369598865509, "incre_win_rate": 0.9565217391304348, "step": 1481}
{"time": 1767158571.7247336, "phase": "eval", "update": 1481, "total_env_steps": 4739200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.91199296357616, "step": 1481}
{"time": 1767158575.996078, "phase": "train", "update": 1482, "total_env_steps": 4742400, "episode_reward": 0.2701283395290375, "value_loss": 0.0036168898921459915, "policy_loss": -0.000996852994541797, "dist_entropy": 0.6543956279754639, "actor_grad_norm": 0.11393771320581436, "critic_grad_norm": 0.09359347075223923, "ratio": 0.9998025894165039, "entropy": 0.6543956279754639, "incre_win_rate": 0.9761904761904762, "step": 1482}
{"time": 1767158580.2992399, "phase": "train", "update": 1483, "total_env_steps": 4745600, "episode_reward": 0.2698582410812378, "value_loss": 0.004664896335452795, "policy_loss": -0.0010860523359326635, "dist_entropy": 0.6513052463531495, "actor_grad_norm": 0.09759341925382614, "critic_grad_norm": 0.08258906751871109, "ratio": 0.9997943043708801, "entropy": 0.6513052463531495, "incre_win_rate": 0.9333333333333333, "step": 1483}
{"time": 1767158584.6172931, "phase": "train", "update": 1484, "total_env_steps": 4748800, "episode_reward": 0.2686713635921478, "value_loss": 0.005548219010233879, "policy_loss": -0.0010385820130260014, "dist_entropy": 0.6422398924827576, "actor_grad_norm": 0.10026172548532486, "critic_grad_norm": 0.08136102557182312, "ratio": 0.9999986886978149, "entropy": 0.6422398924827576, "incre_win_rate": 0.9534883720930233, "step": 1484}
{"time": 1767158589.1799643, "phase": "train", "update": 1485, "total_env_steps": 4752000, "episode_reward": 0.2695271074771881, "value_loss": 0.006697229389101267, "policy_loss": -0.0013569411401700648, "dist_entropy": 0.6209343075752258, "actor_grad_norm": 0.08356036245822906, "critic_grad_norm": 0.05512068793177605, "ratio": 1.0001705884933472, "entropy": 0.6209343075752258, "incre_win_rate": 0.8444444444444444, "step": 1485}
{"time": 1767158593.8927083, "phase": "train", "update": 1486, "total_env_steps": 4755200, "episode_reward": 0.2680562138557434, "value_loss": 0.004639823734760284, "policy_loss": -0.0009961748351910772, "dist_entropy": 0.62461256980896, "actor_grad_norm": 0.10080599784851074, "critic_grad_norm": 0.07940687984228134, "ratio": 0.9997860789299011, "entropy": 0.62461256980896, "incre_win_rate": 0.9318181818181818, "step": 1486}
{"time": 1767158598.193511, "phase": "train", "update": 1487, "total_env_steps": 4758400, "episode_reward": 0.26759934425354004, "value_loss": 0.004626787733286619, "policy_loss": -0.001513843009218796, "dist_entropy": 0.6299533843994141, "actor_grad_norm": 0.09320535510778427, "critic_grad_norm": 0.0706927552819252, "ratio": 0.9996663928031921, "entropy": 0.6299533843994141, "incre_win_rate": 0.9069767441860465, "step": 1487}
{"time": 1767158602.4791918, "phase": "train", "update": 1488, "total_env_steps": 4761600, "episode_reward": 0.26986753940582275, "value_loss": 0.00616707019507885, "policy_loss": -0.0012059896571848584, "dist_entropy": 0.6128897905349732, "actor_grad_norm": 0.08954359591007233, "critic_grad_norm": 0.05241852626204491, "ratio": 1.000017762184143, "entropy": 0.6128897905349732, "incre_win_rate": 0.9333333333333333, "step": 1488}
{"time": 1767158606.8143601, "phase": "train", "update": 1489, "total_env_steps": 4764800, "episode_reward": 0.28566643595695496, "value_loss": 0.0035920207854360344, "policy_loss": -0.0013522671600696868, "dist_entropy": 0.6092337369918823, "actor_grad_norm": 0.09764888137578964, "critic_grad_norm": 0.11241426318883896, "ratio": 1.000238060951233, "entropy": 0.6092337369918823, "incre_win_rate": 0.9787234042553191, "step": 1489}
{"time": 1767158611.1394284, "phase": "train", "update": 1490, "total_env_steps": 4768000, "episode_reward": 0.27803343534469604, "value_loss": 0.0038921684958040715, "policy_loss": -0.001065708176040303, "dist_entropy": 0.5961427927017212, "actor_grad_norm": 0.08225952833890915, "critic_grad_norm": 0.0586497001349926, "ratio": 1.0000351667404175, "entropy": 0.5961427927017212, "incre_win_rate": 0.9534883720930233, "step": 1490}
{"time": 1767158615.4290295, "phase": "train", "update": 1491, "total_env_steps": 4771200, "episode_reward": 0.26554274559020996, "value_loss": 0.00622426513582468, "policy_loss": -0.0009621704938943765, "dist_entropy": 0.5934551000595093, "actor_grad_norm": 0.07171998172998428, "critic_grad_norm": 0.10407859086990356, "ratio": 0.9996899962425232, "entropy": 0.5934551000595093, "incre_win_rate": 0.8863636363636364, "step": 1491}
{"time": 1767158619.7627313, "phase": "train", "update": 1492, "total_env_steps": 4774400, "episode_reward": 0.27527421712875366, "value_loss": 0.006231422536075115, "policy_loss": -0.0011143146125153435, "dist_entropy": 0.5941662907600402, "actor_grad_norm": 0.08124389499425888, "critic_grad_norm": 0.09472496062517166, "ratio": 1.000152826309204, "entropy": 0.5941662907600402, "incre_win_rate": 0.9111111111111111, "step": 1492}
{"time": 1767158624.0149634, "phase": "train", "update": 1493, "total_env_steps": 4777600, "episode_reward": 0.26856374740600586, "value_loss": 0.004668683465570212, "policy_loss": -0.0011372771205460097, "dist_entropy": 0.5915523052215577, "actor_grad_norm": 0.09307482838630676, "critic_grad_norm": 0.051424574106931686, "ratio": 0.9997901320457458, "entropy": 0.5915523052215577, "incre_win_rate": 0.9333333333333333, "step": 1493}
{"time": 1767158628.306001, "phase": "train", "update": 1494, "total_env_steps": 4780800, "episode_reward": 0.2791028618812561, "value_loss": 0.0047640235163271425, "policy_loss": -0.0008961203230796854, "dist_entropy": 0.5896760106086731, "actor_grad_norm": 0.07565482705831528, "critic_grad_norm": 0.07268540561199188, "ratio": 0.9998272061347961, "entropy": 0.5896760106086731, "incre_win_rate": 0.9761904761904762, "step": 1494}
{"time": 1767158632.5457406, "phase": "train", "update": 1495, "total_env_steps": 4784000, "episode_reward": 0.2743760347366333, "value_loss": 0.004492354579269886, "policy_loss": -0.0008708909221301298, "dist_entropy": 0.5839908838272094, "actor_grad_norm": 0.06193040683865547, "critic_grad_norm": 0.06020451337099075, "ratio": 1.0000957250595093, "entropy": 0.5839908838272094, "incre_win_rate": 0.9375, "step": 1495}
{"time": 1767158636.7867062, "phase": "train", "update": 1496, "total_env_steps": 4787200, "episode_reward": 0.2860182225704193, "value_loss": 0.003229857003316283, "policy_loss": -0.001105826364373641, "dist_entropy": 0.5855659127235413, "actor_grad_norm": 0.08439502865076065, "critic_grad_norm": 0.04036964848637581, "ratio": 1.000136375427246, "entropy": 0.5855659127235413, "incre_win_rate": 0.9555555555555556, "step": 1496}
{"time": 1767158641.0625226, "phase": "train", "update": 1497, "total_env_steps": 4790400, "episode_reward": 0.27343541383743286, "value_loss": 0.007129254098981619, "policy_loss": -0.0011407361145156613, "dist_entropy": 0.5646237969398499, "actor_grad_norm": 0.08082825690507889, "critic_grad_norm": 0.10017848014831543, "ratio": 1.0001261234283447, "entropy": 0.5646237969398499, "incre_win_rate": 0.9318181818181818, "step": 1497}
{"time": 1767158645.3789837, "phase": "train", "update": 1498, "total_env_steps": 4793600, "episode_reward": 0.2723841369152069, "value_loss": 0.006238137651234865, "policy_loss": -0.0014784143256058257, "dist_entropy": 0.5713781237602233, "actor_grad_norm": 0.08945606648921967, "critic_grad_norm": 0.07542747259140015, "ratio": 0.9997656941413879, "entropy": 0.5713781237602233, "incre_win_rate": 0.9347826086956522, "step": 1498}
{"time": 1767158649.710456, "phase": "train", "update": 1499, "total_env_steps": 4796800, "episode_reward": 0.2806415855884552, "value_loss": 0.0041908117476850745, "policy_loss": -0.0011343982597175283, "dist_entropy": 0.6038498520851135, "actor_grad_norm": 0.12102837860584259, "critic_grad_norm": 0.15707258880138397, "ratio": 1.0000066757202148, "entropy": 0.6038498520851135, "incre_win_rate": 1.0, "step": 1499}
{"time": 1767158654.0489485, "phase": "train", "update": 1500, "total_env_steps": 4800000, "episode_reward": 0.27526387572288513, "value_loss": 0.0051217925734817985, "policy_loss": -0.0012092065911740945, "dist_entropy": 0.5902689218521118, "actor_grad_norm": 0.09109354019165039, "critic_grad_norm": 0.11593767255544662, "ratio": 0.9999352693557739, "entropy": 0.5902689218521118, "incre_win_rate": 0.9130434782608695, "step": 1500}
{"time": 1767158658.3675294, "phase": "train", "update": 1501, "total_env_steps": 4803200, "episode_reward": 0.2732486426830292, "value_loss": 0.004838107153773308, "policy_loss": -0.0009895671526746197, "dist_entropy": 0.6102015614509583, "actor_grad_norm": 0.06646962463855743, "critic_grad_norm": 0.049320004880428314, "ratio": 0.9999079704284668, "entropy": 0.6102015614509583, "incre_win_rate": 0.9333333333333333, "step": 1501}
{"time": 1767158668.1437964, "phase": "eval", "update": 1501, "total_env_steps": 4803200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.757864238410598, "step": 1501}
{"time": 1767158672.43681, "phase": "train", "update": 1502, "total_env_steps": 4806400, "episode_reward": 0.288158118724823, "value_loss": 0.0030167382676154373, "policy_loss": -0.0008921410001253349, "dist_entropy": 0.6134731054306031, "actor_grad_norm": 0.06614168733358383, "critic_grad_norm": 0.06362110376358032, "ratio": 0.9999743700027466, "entropy": 0.6134731054306031, "incre_win_rate": 0.9782608695652174, "step": 1502}
{"time": 1767158676.7268255, "phase": "train", "update": 1503, "total_env_steps": 4809600, "episode_reward": 0.28275248408317566, "value_loss": 0.0034057716839015484, "policy_loss": -0.001268107180612077, "dist_entropy": 0.620988404750824, "actor_grad_norm": 0.07400482147932053, "critic_grad_norm": 0.1188821941614151, "ratio": 1.000183343887329, "entropy": 0.620988404750824, "incre_win_rate": 0.9782608695652174, "step": 1503}
{"time": 1767158680.9839957, "phase": "train", "update": 1504, "total_env_steps": 4812800, "episode_reward": 0.2713658809661865, "value_loss": 0.004797578416764736, "policy_loss": -0.0010070906479558773, "dist_entropy": 0.6256984233856201, "actor_grad_norm": 0.0727912113070488, "critic_grad_norm": 0.06874778866767883, "ratio": 0.9998399615287781, "entropy": 0.6256984233856201, "incre_win_rate": 0.9069767441860465, "step": 1504}
{"time": 1767158685.516886, "phase": "train", "update": 1505, "total_env_steps": 4816000, "episode_reward": 0.2770695388317108, "value_loss": 0.0048632933758199215, "policy_loss": -0.0007880165618399104, "dist_entropy": 0.643645191192627, "actor_grad_norm": 0.06734897941350937, "critic_grad_norm": 0.07639054208993912, "ratio": 0.9997965097427368, "entropy": 0.643645191192627, "incre_win_rate": 0.9347826086956522, "step": 1505}
{"time": 1767158689.8495998, "phase": "train", "update": 1506, "total_env_steps": 4819200, "episode_reward": 0.2773178815841675, "value_loss": 0.00490920701995492, "policy_loss": -0.0016967013789326302, "dist_entropy": 0.6337089776992798, "actor_grad_norm": 0.10677596181631088, "critic_grad_norm": 0.0724065750837326, "ratio": 1.000020980834961, "entropy": 0.6337089776992798, "incre_win_rate": 0.9534883720930233, "step": 1506}
{"time": 1767158694.1678503, "phase": "train", "update": 1507, "total_env_steps": 4822400, "episode_reward": 0.26648178696632385, "value_loss": 0.005090435594320297, "policy_loss": -0.0015536652896813053, "dist_entropy": 0.6458066821098327, "actor_grad_norm": 0.1011878028512001, "critic_grad_norm": 0.11720738559961319, "ratio": 0.9999752044677734, "entropy": 0.6458066821098327, "incre_win_rate": 0.8723404255319149, "step": 1507}
{"time": 1767158698.4078681, "phase": "train", "update": 1508, "total_env_steps": 4825600, "episode_reward": 0.2725165784358978, "value_loss": 0.006489271670579911, "policy_loss": -0.0011926433825035331, "dist_entropy": 0.6452236175537109, "actor_grad_norm": 0.11333005875349045, "critic_grad_norm": 0.09193972498178482, "ratio": 0.9997255206108093, "entropy": 0.6452236175537109, "incre_win_rate": 0.9090909090909091, "step": 1508}
{"time": 1767158702.6872523, "phase": "train", "update": 1509, "total_env_steps": 4828800, "episode_reward": 0.2687825858592987, "value_loss": 0.006520104128867388, "policy_loss": -0.001167843649818323, "dist_entropy": 0.6353468894958496, "actor_grad_norm": 0.08315491676330566, "critic_grad_norm": 0.06900659948587418, "ratio": 0.9997367858886719, "entropy": 0.6353468894958496, "incre_win_rate": 0.9090909090909091, "step": 1509}
{"time": 1767158706.9740305, "phase": "train", "update": 1510, "total_env_steps": 4832000, "episode_reward": 0.2709933817386627, "value_loss": 0.004588843137025833, "policy_loss": -0.0010236935973964023, "dist_entropy": 0.6561066627502441, "actor_grad_norm": 0.07972580939531326, "critic_grad_norm": 0.09891717880964279, "ratio": 0.9998974204063416, "entropy": 0.6561066627502441, "incre_win_rate": 0.9534883720930233, "step": 1510}
{"time": 1767158711.26774, "phase": "train", "update": 1511, "total_env_steps": 4835200, "episode_reward": 0.2773773670196533, "value_loss": 0.005485822446644306, "policy_loss": -0.0011722793476550918, "dist_entropy": 0.652371621131897, "actor_grad_norm": 0.08017851412296295, "critic_grad_norm": 0.10364659875631332, "ratio": 0.9999369978904724, "entropy": 0.652371621131897, "incre_win_rate": 0.9782608695652174, "step": 1511}
{"time": 1767158715.5303864, "phase": "train", "update": 1512, "total_env_steps": 4838400, "episode_reward": 0.27147766947746277, "value_loss": 0.005538973305374384, "policy_loss": -0.0013612484192481844, "dist_entropy": 0.642943799495697, "actor_grad_norm": 0.09467604011297226, "critic_grad_norm": 0.0669778510928154, "ratio": 1.0000091791152954, "entropy": 0.642943799495697, "incre_win_rate": 0.9090909090909091, "step": 1512}
{"time": 1767158719.8606727, "phase": "train", "update": 1513, "total_env_steps": 4841600, "episode_reward": 0.2810637354850769, "value_loss": 0.004076748341321945, "policy_loss": -0.0011941211031590627, "dist_entropy": 0.6433621764183044, "actor_grad_norm": 0.0963137298822403, "critic_grad_norm": 0.07488542795181274, "ratio": 0.9998052716255188, "entropy": 0.6433621764183044, "incre_win_rate": 0.9777777777777777, "step": 1513}
{"time": 1767158724.1357388, "phase": "train", "update": 1514, "total_env_steps": 4844800, "episode_reward": 0.2750709056854248, "value_loss": 0.005271965079009533, "policy_loss": -0.0012992811050331454, "dist_entropy": 0.6447265267372131, "actor_grad_norm": 0.08196693658828735, "critic_grad_norm": 0.09708025306463242, "ratio": 1.000174641609192, "entropy": 0.6447265267372131, "incre_win_rate": 0.9090909090909091, "step": 1514}
{"time": 1767158728.426452, "phase": "train", "update": 1515, "total_env_steps": 4848000, "episode_reward": 0.27293047308921814, "value_loss": 0.004292304255068302, "policy_loss": -0.0010507890302967836, "dist_entropy": 0.6846009492874146, "actor_grad_norm": 0.08248281478881836, "critic_grad_norm": 0.08053053170442581, "ratio": 1.0000180006027222, "entropy": 0.6846009492874146, "incre_win_rate": 0.9333333333333333, "step": 1515}
{"time": 1767158732.691828, "phase": "train", "update": 1516, "total_env_steps": 4851200, "episode_reward": 0.2727768123149872, "value_loss": 0.0074446267448365685, "policy_loss": -0.0010564358810555064, "dist_entropy": 0.6787389397621155, "actor_grad_norm": 0.08563025295734406, "critic_grad_norm": 0.07853495329618454, "ratio": 1.000178575515747, "entropy": 0.6787389397621155, "incre_win_rate": 0.8913043478260869, "step": 1516}
{"time": 1767158737.0142891, "phase": "train", "update": 1517, "total_env_steps": 4854400, "episode_reward": 0.2686103284358978, "value_loss": 0.008966713026165963, "policy_loss": -0.0011573119481724347, "dist_entropy": 0.6734995722770691, "actor_grad_norm": 0.10223797708749771, "critic_grad_norm": 0.06852355599403381, "ratio": 1.0002411603927612, "entropy": 0.6734995722770691, "incre_win_rate": 0.7954545454545454, "step": 1517}
{"time": 1767158741.3325338, "phase": "train", "update": 1518, "total_env_steps": 4857600, "episode_reward": 0.28109684586524963, "value_loss": 0.006061722431331873, "policy_loss": -0.0012313686931037181, "dist_entropy": 0.6543979167938232, "actor_grad_norm": 0.08936715126037598, "critic_grad_norm": 0.1282028704881668, "ratio": 1.0001373291015625, "entropy": 0.6543979167938232, "incre_win_rate": 0.9565217391304348, "step": 1518}
{"time": 1767158745.5801764, "phase": "train", "update": 1519, "total_env_steps": 4860800, "episode_reward": 0.2662908732891083, "value_loss": 0.008959386870265007, "policy_loss": -0.001267954987515818, "dist_entropy": 0.654162871837616, "actor_grad_norm": 0.10437335073947906, "critic_grad_norm": 0.16461589932441711, "ratio": 0.9996687173843384, "entropy": 0.654162871837616, "incre_win_rate": 0.8695652173913043, "step": 1519}
{"time": 1767158749.8633287, "phase": "train", "update": 1520, "total_env_steps": 4864000, "episode_reward": 0.27138659358024597, "value_loss": 0.005620605871081352, "policy_loss": -0.0009291550985921048, "dist_entropy": 0.6595890879631042, "actor_grad_norm": 0.08860941976308823, "critic_grad_norm": 0.0788322314620018, "ratio": 0.9998814463615417, "entropy": 0.6595890879631042, "incre_win_rate": 0.9090909090909091, "step": 1520}
{"time": 1767158754.111022, "phase": "train", "update": 1521, "total_env_steps": 4867200, "episode_reward": 0.2679666578769684, "value_loss": 0.006190415937453508, "policy_loss": -0.001282878196859727, "dist_entropy": 0.6387658953666687, "actor_grad_norm": 0.08691569417715073, "critic_grad_norm": 0.11979460716247559, "ratio": 1.0000604391098022, "entropy": 0.6387658953666687, "incre_win_rate": 0.9047619047619048, "step": 1521}
{"time": 1767158764.023028, "phase": "eval", "update": 1521, "total_env_steps": 4867200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.793615480132452, "step": 1521}
{"time": 1767158768.3130174, "phase": "train", "update": 1522, "total_env_steps": 4870400, "episode_reward": 0.27692466974258423, "value_loss": 0.005597037076950073, "policy_loss": -0.001230739571578532, "dist_entropy": 0.6465170741081238, "actor_grad_norm": 0.11737243086099625, "critic_grad_norm": 0.11420657485723495, "ratio": 0.9999322295188904, "entropy": 0.6465170741081238, "incre_win_rate": 0.9361702127659575, "step": 1522}
{"time": 1767158772.6196895, "phase": "train", "update": 1523, "total_env_steps": 4873600, "episode_reward": 0.2809106111526489, "value_loss": 0.00470868507400155, "policy_loss": -0.001160689241616808, "dist_entropy": 0.6489139199256897, "actor_grad_norm": 0.09311045706272125, "critic_grad_norm": 0.06482052803039551, "ratio": 1.000108003616333, "entropy": 0.6489139199256897, "incre_win_rate": 0.9534883720930233, "step": 1523}
{"time": 1767158776.907486, "phase": "train", "update": 1524, "total_env_steps": 4876800, "episode_reward": 0.2695778012275696, "value_loss": 0.005521272867918014, "policy_loss": -0.0008911523263002152, "dist_entropy": 0.6240825414657593, "actor_grad_norm": 0.09140119701623917, "critic_grad_norm": 0.13350287079811096, "ratio": 1.0001429319381714, "entropy": 0.6240825414657593, "incre_win_rate": 0.9111111111111111, "step": 1524}
{"time": 1767158781.2072039, "phase": "train", "update": 1525, "total_env_steps": 4880000, "episode_reward": 0.2744205594062805, "value_loss": 0.004292760603129863, "policy_loss": -0.0013431322309934268, "dist_entropy": 0.6488006830215454, "actor_grad_norm": 0.10210344940423965, "critic_grad_norm": 0.07113472372293472, "ratio": 1.0003215074539185, "entropy": 0.6488006830215454, "incre_win_rate": 0.9545454545454546, "step": 1525}
{"time": 1767158785.4903228, "phase": "train", "update": 1526, "total_env_steps": 4883200, "episode_reward": 0.27269917726516724, "value_loss": 0.004135484993457794, "policy_loss": -0.0009959641075113269, "dist_entropy": 0.6368197441101074, "actor_grad_norm": 0.0906166061758995, "critic_grad_norm": 0.021026596426963806, "ratio": 0.9996604323387146, "entropy": 0.6368197441101074, "incre_win_rate": 0.9565217391304348, "step": 1526}
{"time": 1767158789.8036513, "phase": "train", "update": 1527, "total_env_steps": 4886400, "episode_reward": 0.27821195125579834, "value_loss": 0.005488235130906105, "policy_loss": -0.0009862824814485193, "dist_entropy": 0.651416826248169, "actor_grad_norm": 0.09454554319381714, "critic_grad_norm": 0.09724735468626022, "ratio": 1.0001554489135742, "entropy": 0.651416826248169, "incre_win_rate": 0.9534883720930233, "step": 1527}
{"time": 1767158794.1103609, "phase": "train", "update": 1528, "total_env_steps": 4889600, "episode_reward": 0.26237067580223083, "value_loss": 0.008633697591722011, "policy_loss": -0.0012776662630878733, "dist_entropy": 0.6647264838218689, "actor_grad_norm": 0.09164420515298843, "critic_grad_norm": 0.13509534299373627, "ratio": 0.9998018145561218, "entropy": 0.6647264838218689, "incre_win_rate": 0.8666666666666667, "step": 1528}
{"time": 1767158798.4587924, "phase": "train", "update": 1529, "total_env_steps": 4892800, "episode_reward": 0.2630225718021393, "value_loss": 0.009535347856581212, "policy_loss": -0.001363985585356531, "dist_entropy": 0.6522457480430603, "actor_grad_norm": 0.12287979573011398, "critic_grad_norm": 0.10719132423400879, "ratio": 1.000110149383545, "entropy": 0.6522457480430603, "incre_win_rate": 0.8837209302325582, "step": 1529}
{"time": 1767158802.7379315, "phase": "train", "update": 1530, "total_env_steps": 4896000, "episode_reward": 0.25727441906929016, "value_loss": 0.010033641196787357, "policy_loss": -0.00120755696620094, "dist_entropy": 0.6724220037460327, "actor_grad_norm": 0.10597143322229385, "critic_grad_norm": 0.1209924966096878, "ratio": 0.9997539520263672, "entropy": 0.6724220037460327, "incre_win_rate": 0.7954545454545454, "step": 1530}
{"time": 1767158807.087982, "phase": "train", "update": 1531, "total_env_steps": 4899200, "episode_reward": 0.2681431174278259, "value_loss": 0.008423616364598274, "policy_loss": -0.001177029015099862, "dist_entropy": 0.6788655161857605, "actor_grad_norm": 0.09853335469961166, "critic_grad_norm": 0.0722745954990387, "ratio": 1.0003612041473389, "entropy": 0.6788655161857605, "incre_win_rate": 0.8444444444444444, "step": 1531}
{"time": 1767158811.3976026, "phase": "train", "update": 1532, "total_env_steps": 4902400, "episode_reward": 0.2718004882335663, "value_loss": 0.0063215427100658415, "policy_loss": -0.0016237547774494488, "dist_entropy": 0.6951796293258667, "actor_grad_norm": 0.11467161029577255, "critic_grad_norm": 0.08329739421606064, "ratio": 1.000160574913025, "entropy": 0.6951796293258667, "incre_win_rate": 0.9111111111111111, "step": 1532}
{"time": 1767158815.7042284, "phase": "train", "update": 1533, "total_env_steps": 4905600, "episode_reward": 0.27398645877838135, "value_loss": 0.007149617187678814, "policy_loss": -0.0011238919864148046, "dist_entropy": 0.6576766848564148, "actor_grad_norm": 0.08689592778682709, "critic_grad_norm": 0.08619695156812668, "ratio": 1.000193476676941, "entropy": 0.6576766848564148, "incre_win_rate": 0.9069767441860465, "step": 1533}
{"time": 1767158819.9904616, "phase": "train", "update": 1534, "total_env_steps": 4908800, "episode_reward": 0.2621114253997803, "value_loss": 0.005143326614052058, "policy_loss": -0.0009343833338487428, "dist_entropy": 0.6340469479560852, "actor_grad_norm": 0.09577172994613647, "critic_grad_norm": 0.03590582311153412, "ratio": 0.9996711611747742, "entropy": 0.6340469479560852, "incre_win_rate": 0.8636363636363636, "step": 1534}
{"time": 1767158824.3380878, "phase": "train", "update": 1535, "total_env_steps": 4912000, "episode_reward": 0.2683154046535492, "value_loss": 0.006313471123576164, "policy_loss": -0.0009399955125768856, "dist_entropy": 0.6389213562011719, "actor_grad_norm": 0.07846622914075851, "critic_grad_norm": 0.03955715522170067, "ratio": 1.0000224113464355, "entropy": 0.6389213562011719, "incre_win_rate": 0.8888888888888888, "step": 1535}
{"time": 1767158828.6810646, "phase": "train", "update": 1536, "total_env_steps": 4915200, "episode_reward": 0.2660280466079712, "value_loss": 0.006290565710514784, "policy_loss": -0.0012423868170088781, "dist_entropy": 0.6495885610580444, "actor_grad_norm": 0.08504360169172287, "critic_grad_norm": 0.053063273429870605, "ratio": 1.0005308389663696, "entropy": 0.6495885610580444, "incre_win_rate": 0.9069767441860465, "step": 1536}
{"time": 1767158832.992645, "phase": "train", "update": 1537, "total_env_steps": 4918400, "episode_reward": 0.26748448610305786, "value_loss": 0.005762095004320145, "policy_loss": -0.0008459660653571177, "dist_entropy": 0.6458095788955689, "actor_grad_norm": 0.08424736559391022, "critic_grad_norm": 0.07324323803186417, "ratio": 0.9997424483299255, "entropy": 0.6458095788955689, "incre_win_rate": 0.9111111111111111, "step": 1537}
{"time": 1767158837.3091066, "phase": "train", "update": 1538, "total_env_steps": 4921600, "episode_reward": 0.27372774481773376, "value_loss": 0.006475953850895166, "policy_loss": -0.0011327948674725973, "dist_entropy": 0.6712458848953247, "actor_grad_norm": 0.08813255280256271, "critic_grad_norm": 0.04498610645532608, "ratio": 1.0003867149353027, "entropy": 0.6712458848953247, "incre_win_rate": 0.9090909090909091, "step": 1538}
{"time": 1767158841.603711, "phase": "train", "update": 1539, "total_env_steps": 4924800, "episode_reward": 0.2530168890953064, "value_loss": 0.008995255082845688, "policy_loss": -0.0011362720003688764, "dist_entropy": 0.679698932170868, "actor_grad_norm": 0.09792914986610413, "critic_grad_norm": 0.12013771384954453, "ratio": 1.000045657157898, "entropy": 0.679698932170868, "incre_win_rate": 0.8048780487804879, "step": 1539}
{"time": 1767158845.9255085, "phase": "train", "update": 1540, "total_env_steps": 4928000, "episode_reward": 0.27595198154449463, "value_loss": 0.005285308789461851, "policy_loss": -0.0012349933022612447, "dist_entropy": 0.6940423727035523, "actor_grad_norm": 0.11136428266763687, "critic_grad_norm": 0.15938933193683624, "ratio": 1.0005487203598022, "entropy": 0.6940423727035523, "incre_win_rate": 0.9574468085106383, "step": 1540}
{"time": 1767158850.2411513, "phase": "train", "update": 1541, "total_env_steps": 4931200, "episode_reward": 0.2674487829208374, "value_loss": 0.006385921034961939, "policy_loss": -0.0008200668060238669, "dist_entropy": 0.7136938214302063, "actor_grad_norm": 0.07341954112052917, "critic_grad_norm": 0.11997615545988083, "ratio": 1.000273585319519, "entropy": 0.7136938214302063, "incre_win_rate": 0.8571428571428571, "step": 1541}
{"time": 1767158860.3127165, "phase": "eval", "update": 1541, "total_env_steps": 4931200, "eval_win_rate": 1.0, "eval_episode_reward": 20.00010347682119, "step": 1541}
{"time": 1767158864.5899477, "phase": "train", "update": 1542, "total_env_steps": 4934400, "episode_reward": 0.2686465382575989, "value_loss": 0.006546677649021148, "policy_loss": -0.001648740068585397, "dist_entropy": 0.7182274699211121, "actor_grad_norm": 0.08990653604269028, "critic_grad_norm": 0.09371166676282883, "ratio": 0.9996423125267029, "entropy": 0.7182274699211121, "incre_win_rate": 0.8913043478260869, "step": 1542}
{"time": 1767158868.9281268, "phase": "train", "update": 1543, "total_env_steps": 4937600, "episode_reward": 0.26022040843963623, "value_loss": 0.008790204487740993, "policy_loss": -0.0010103201794962047, "dist_entropy": 0.6970199346542358, "actor_grad_norm": 0.09262165427207947, "critic_grad_norm": 0.2388794720172882, "ratio": 1.000223994255066, "entropy": 0.6970199346542358, "incre_win_rate": 0.8372093023255814, "step": 1543}
{"time": 1767158873.229327, "phase": "train", "update": 1544, "total_env_steps": 4940800, "episode_reward": 0.2695695161819458, "value_loss": 0.006442086957395077, "policy_loss": -0.001037335634498504, "dist_entropy": 0.6918715596199035, "actor_grad_norm": 0.08530258387327194, "critic_grad_norm": 0.20001991093158722, "ratio": 1.000266671180725, "entropy": 0.6918715596199035, "incre_win_rate": 0.9555555555555556, "step": 1544}
{"time": 1767158877.519771, "phase": "train", "update": 1545, "total_env_steps": 4944000, "episode_reward": 0.27194949984550476, "value_loss": 0.006659573782235384, "policy_loss": -0.0017317149496889784, "dist_entropy": 0.6887346982955933, "actor_grad_norm": 0.09097029268741608, "critic_grad_norm": 0.17539016902446747, "ratio": 1.00009286403656, "entropy": 0.6887346982955933, "incre_win_rate": 0.9047619047619048, "step": 1545}
{"time": 1767158881.8039038, "phase": "train", "update": 1546, "total_env_steps": 4947200, "episode_reward": 0.27074193954467773, "value_loss": 0.007420346047729254, "policy_loss": -0.0013746820955949702, "dist_entropy": 0.6464194774627685, "actor_grad_norm": 0.11525197327136993, "critic_grad_norm": 0.1734592318534851, "ratio": 1.0001505613327026, "entropy": 0.6464194774627685, "incre_win_rate": 0.9130434782608695, "step": 1546}
{"time": 1767158886.1243544, "phase": "train", "update": 1547, "total_env_steps": 4950400, "episode_reward": 0.2758583426475525, "value_loss": 0.004138015676289797, "policy_loss": -0.0013638080448799884, "dist_entropy": 0.6499354124069214, "actor_grad_norm": 0.1140768900513649, "critic_grad_norm": 0.12413861602544785, "ratio": 0.9998316764831543, "entropy": 0.6499354124069214, "incre_win_rate": 0.9555555555555556, "step": 1547}
{"time": 1767158890.425742, "phase": "train", "update": 1548, "total_env_steps": 4953600, "episode_reward": 0.26968127489089966, "value_loss": 0.004967195633798838, "policy_loss": -0.0014249717402954332, "dist_entropy": 0.6593312740325927, "actor_grad_norm": 0.0973350778222084, "critic_grad_norm": 0.10021360218524933, "ratio": 1.0001330375671387, "entropy": 0.6593312740325927, "incre_win_rate": 0.9302325581395349, "step": 1548}
{"time": 1767158894.7273912, "phase": "train", "update": 1549, "total_env_steps": 4956800, "episode_reward": 0.27631211280822754, "value_loss": 0.0041934606619179245, "policy_loss": -0.0010329251465408973, "dist_entropy": 0.653003740310669, "actor_grad_norm": 0.06812675297260284, "critic_grad_norm": 0.0326191745698452, "ratio": 0.9998664855957031, "entropy": 0.653003740310669, "incre_win_rate": 0.9555555555555556, "step": 1549}
{"time": 1767158899.0514197, "phase": "train", "update": 1550, "total_env_steps": 4960000, "episode_reward": 0.28247103095054626, "value_loss": 0.0033078369218856097, "policy_loss": -0.0012514690944802175, "dist_entropy": 0.6465643644332886, "actor_grad_norm": 0.07548828423023224, "critic_grad_norm": 0.030986744910478592, "ratio": 0.9995496869087219, "entropy": 0.6465643644332886, "incre_win_rate": 1.0, "step": 1550}
{"time": 1767158903.3612845, "phase": "train", "update": 1551, "total_env_steps": 4963200, "episode_reward": 0.27186256647109985, "value_loss": 0.004326093196868897, "policy_loss": -0.0010305230040444258, "dist_entropy": 0.6509523034095764, "actor_grad_norm": 0.0677192285656929, "critic_grad_norm": 0.05266202613711357, "ratio": 1.0000194311141968, "entropy": 0.6509523034095764, "incre_win_rate": 0.9318181818181818, "step": 1551}
{"time": 1767158907.6444488, "phase": "train", "update": 1552, "total_env_steps": 4966400, "episode_reward": 0.2736842930316925, "value_loss": 0.004976526461541652, "policy_loss": -0.0010027358443295497, "dist_entropy": 0.6514694690704346, "actor_grad_norm": 0.09319040924310684, "critic_grad_norm": 0.07557033747434616, "ratio": 1.0001838207244873, "entropy": 0.6514694690704346, "incre_win_rate": 0.9302325581395349, "step": 1552}
{"time": 1767158911.9503438, "phase": "train", "update": 1553, "total_env_steps": 4969600, "episode_reward": 0.2712453603744507, "value_loss": 0.0072179223410785195, "policy_loss": -0.0012235905232742539, "dist_entropy": 0.6561652898788453, "actor_grad_norm": 0.1019367128610611, "critic_grad_norm": 0.07969363778829575, "ratio": 0.9998055696487427, "entropy": 0.6561652898788453, "incre_win_rate": 0.8888888888888888, "step": 1553}
{"time": 1767158916.1912494, "phase": "train", "update": 1554, "total_env_steps": 4972800, "episode_reward": 0.27236029505729675, "value_loss": 0.0065165145322680475, "policy_loss": -0.0014736230344873035, "dist_entropy": 0.6597925543785095, "actor_grad_norm": 0.10841444879770279, "critic_grad_norm": 0.0660308375954628, "ratio": 0.9998649954795837, "entropy": 0.6597925543785095, "incre_win_rate": 0.9361702127659575, "step": 1554}
{"time": 1767158920.4268217, "phase": "train", "update": 1555, "total_env_steps": 4976000, "episode_reward": 0.2683495581150055, "value_loss": 0.008254423923790454, "policy_loss": -0.0011567482641925864, "dist_entropy": 0.65204256772995, "actor_grad_norm": 0.0891190692782402, "critic_grad_norm": 0.07852951437234879, "ratio": 0.9998292922973633, "entropy": 0.65204256772995, "incre_win_rate": 0.8604651162790697, "step": 1555}
{"time": 1767158924.706464, "phase": "train", "update": 1556, "total_env_steps": 4979200, "episode_reward": 0.2772682309150696, "value_loss": 0.005014751758426428, "policy_loss": -0.0010823359525332422, "dist_entropy": 0.6266567587852478, "actor_grad_norm": 0.10399102419614792, "critic_grad_norm": 0.14551600813865662, "ratio": 1.0004863739013672, "entropy": 0.6266567587852478, "incre_win_rate": 0.9318181818181818, "step": 1556}
{"time": 1767158929.1562152, "phase": "train", "update": 1557, "total_env_steps": 4982400, "episode_reward": 0.2659064531326294, "value_loss": 0.007956874649971723, "policy_loss": -0.0012383591353838596, "dist_entropy": 0.6146438956260681, "actor_grad_norm": 0.09088759124279022, "critic_grad_norm": 0.11192794144153595, "ratio": 0.9996109008789062, "entropy": 0.6146438956260681, "incre_win_rate": 0.9069767441860465, "step": 1557}
{"time": 1767158933.3944442, "phase": "train", "update": 1558, "total_env_steps": 4985600, "episode_reward": 0.27494412660598755, "value_loss": 0.004539569001644849, "policy_loss": -0.0015029223224345856, "dist_entropy": 0.6083321332931518, "actor_grad_norm": 0.10072311013936996, "critic_grad_norm": 0.12025739997625351, "ratio": 0.9998144507408142, "entropy": 0.6083321332931518, "incre_win_rate": 0.9130434782608695, "step": 1558}
{"time": 1767158937.631554, "phase": "train", "update": 1559, "total_env_steps": 4988800, "episode_reward": 0.2655753791332245, "value_loss": 0.004019031999632716, "policy_loss": -0.0012683304477093317, "dist_entropy": 0.6197465896606446, "actor_grad_norm": 0.09448323398828506, "critic_grad_norm": 0.10303574800491333, "ratio": 0.9997627139091492, "entropy": 0.6197465896606446, "incre_win_rate": 0.9523809523809523, "step": 1559}
{"time": 1767158941.8948426, "phase": "train", "update": 1560, "total_env_steps": 4992000, "episode_reward": 0.27307119965553284, "value_loss": 0.002909877058118582, "policy_loss": -0.001231237504970295, "dist_entropy": 0.6252375721931458, "actor_grad_norm": 0.08696740865707397, "critic_grad_norm": 0.06770174950361252, "ratio": 0.9998542666435242, "entropy": 0.6252375721931458, "incre_win_rate": 0.9782608695652174, "step": 1560}
{"time": 1767158946.1410575, "phase": "train", "update": 1561, "total_env_steps": 4995200, "episode_reward": 0.2724917531013489, "value_loss": 0.0033074314240366222, "policy_loss": -0.0012833673954129488, "dist_entropy": 0.5981200814247132, "actor_grad_norm": 0.08555956929922104, "critic_grad_norm": 0.06319298595190048, "ratio": 0.999867856502533, "entropy": 0.5981200814247132, "incre_win_rate": 0.9302325581395349, "step": 1561}
{"time": 1767158956.40212, "phase": "eval", "update": 1561, "total_env_steps": 4995200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.67591059602649, "step": 1561}
{"time": 1767158960.651184, "phase": "train", "update": 1562, "total_env_steps": 4998400, "episode_reward": 0.2736154794692993, "value_loss": 0.00525613846257329, "policy_loss": -0.001168661197880283, "dist_entropy": 0.5918203473091126, "actor_grad_norm": 0.06805180758237839, "critic_grad_norm": 0.05151176452636719, "ratio": 1.0002084970474243, "entropy": 0.5918203473091126, "incre_win_rate": 1.0, "step": 1562}
{"time": 1767158964.927819, "phase": "train", "update": 1563, "total_env_steps": 5001600, "episode_reward": 0.26295530796051025, "value_loss": 0.004817645438015461, "policy_loss": -0.0014462427096788133, "dist_entropy": 0.5908543825149536, "actor_grad_norm": 0.09157773852348328, "critic_grad_norm": 0.051758892834186554, "ratio": 0.9999029040336609, "entropy": 0.5908543825149536, "incre_win_rate": 0.9318181818181818, "step": 1563}
{"time": 1767158969.2473185, "phase": "train", "update": 1564, "total_env_steps": 5004800, "episode_reward": 0.28012004494667053, "value_loss": 0.004430163651704788, "policy_loss": -0.0013790402032057615, "dist_entropy": 0.6045715689659119, "actor_grad_norm": 0.10240782797336578, "critic_grad_norm": 0.08321177959442139, "ratio": 1.0001952648162842, "entropy": 0.6045715689659119, "incre_win_rate": 0.9772727272727273, "step": 1564}
{"time": 1767158973.4937954, "phase": "train", "update": 1565, "total_env_steps": 5008000, "episode_reward": 0.27165767550468445, "value_loss": 0.0042937595397233965, "policy_loss": -0.0010307413798845034, "dist_entropy": 0.607404351234436, "actor_grad_norm": 0.07936574518680573, "critic_grad_norm": 0.06481680274009705, "ratio": 1.0000776052474976, "entropy": 0.607404351234436, "incre_win_rate": 0.9555555555555556, "step": 1565}
{"time": 1767158977.7562568, "phase": "train", "update": 1566, "total_env_steps": 5011200, "episode_reward": 0.27184292674064636, "value_loss": 0.0030071900691837072, "policy_loss": -0.0012276511674656377, "dist_entropy": 0.6207122921943664, "actor_grad_norm": 0.08227652311325073, "critic_grad_norm": 0.044518157839775085, "ratio": 0.9997255206108093, "entropy": 0.6207122921943664, "incre_win_rate": 0.9534883720930233, "step": 1566}
{"time": 1767158982.014015, "phase": "train", "update": 1567, "total_env_steps": 5014400, "episode_reward": 0.27579471468925476, "value_loss": 0.0033683946821838617, "policy_loss": -0.0009715730372832354, "dist_entropy": 0.5994866132736206, "actor_grad_norm": 0.08341297507286072, "critic_grad_norm": 0.04646919667720795, "ratio": 1.000006914138794, "entropy": 0.5994866132736206, "incre_win_rate": 0.9777777777777777, "step": 1567}
{"time": 1767158986.293448, "phase": "train", "update": 1568, "total_env_steps": 5017600, "episode_reward": 0.2743915617465973, "value_loss": 0.004833056777715683, "policy_loss": -0.0008965617581122131, "dist_entropy": 0.607341980934143, "actor_grad_norm": 0.07719817012548447, "critic_grad_norm": 0.03381785377860069, "ratio": 1.0004147291183472, "entropy": 0.607341980934143, "incre_win_rate": 0.9772727272727273, "step": 1568}
{"time": 1767158990.4889257, "phase": "train", "update": 1569, "total_env_steps": 5020800, "episode_reward": 0.2528342306613922, "value_loss": 0.005743238888680935, "policy_loss": -0.0009861113374171281, "dist_entropy": 0.6107889890670777, "actor_grad_norm": 0.09318045526742935, "critic_grad_norm": 0.07965319603681564, "ratio": 1.0003056526184082, "entropy": 0.6107889890670777, "incre_win_rate": 0.8809523809523809, "step": 1569}
{"time": 1767158994.7398965, "phase": "train", "update": 1570, "total_env_steps": 5024000, "episode_reward": 0.24863827228546143, "value_loss": 0.005936119332909584, "policy_loss": -0.0013466260572911892, "dist_entropy": 0.6142019748687744, "actor_grad_norm": 0.0858919620513916, "critic_grad_norm": 0.09700274467468262, "ratio": 1.0001695156097412, "entropy": 0.6142019748687744, "incre_win_rate": 0.8048780487804879, "step": 1570}
{"time": 1767158999.0145307, "phase": "train", "update": 1571, "total_env_steps": 5027200, "episode_reward": 0.2585642337799072, "value_loss": 0.005090984236449003, "policy_loss": -0.0014363909314884181, "dist_entropy": 0.6200366973876953, "actor_grad_norm": 0.09543909132480621, "critic_grad_norm": 0.05735458806157112, "ratio": 0.9997617602348328, "entropy": 0.6200366973876953, "incre_win_rate": 0.9090909090909091, "step": 1571}
{"time": 1767159003.2924654, "phase": "train", "update": 1572, "total_env_steps": 5030400, "episode_reward": 0.26889124512672424, "value_loss": 0.004244038090109825, "policy_loss": -0.0011981909294270566, "dist_entropy": 0.6252164125442505, "actor_grad_norm": 0.08322662115097046, "critic_grad_norm": 0.04150373861193657, "ratio": 1.0000985860824585, "entropy": 0.6252164125442505, "incre_win_rate": 0.9302325581395349, "step": 1572}
{"time": 1767159007.561463, "phase": "train", "update": 1573, "total_env_steps": 5033600, "episode_reward": 0.26050499081611633, "value_loss": 0.006005624402314424, "policy_loss": -0.0013346407906722035, "dist_entropy": 0.6333176374435425, "actor_grad_norm": 0.08007654547691345, "critic_grad_norm": 0.03675315901637077, "ratio": 0.9996242523193359, "entropy": 0.6333176374435425, "incre_win_rate": 0.9285714285714286, "step": 1573}
{"time": 1767159011.8523962, "phase": "train", "update": 1574, "total_env_steps": 5036800, "episode_reward": 0.2595529854297638, "value_loss": 0.006537844892591238, "policy_loss": -0.0012177723891539927, "dist_entropy": 0.6318410754203796, "actor_grad_norm": 0.1009833812713623, "critic_grad_norm": 0.06417956948280334, "ratio": 1.0003845691680908, "entropy": 0.6318410754203796, "incre_win_rate": 0.8636363636363636, "step": 1574}
{"time": 1767159016.139168, "phase": "train", "update": 1575, "total_env_steps": 5040000, "episode_reward": 0.2684561312198639, "value_loss": 0.005722532793879509, "policy_loss": -0.0012761525473450775, "dist_entropy": 0.6753609299659729, "actor_grad_norm": 0.10143119096755981, "critic_grad_norm": 0.053395211696624756, "ratio": 1.000169038772583, "entropy": 0.6753609299659729, "incre_win_rate": 0.9285714285714286, "step": 1575}
{"time": 1767159020.4193532, "phase": "train", "update": 1576, "total_env_steps": 5043200, "episode_reward": 0.2643905282020569, "value_loss": 0.005481579527258873, "policy_loss": -0.0012324892440844337, "dist_entropy": 0.6771608352661133, "actor_grad_norm": 0.10607115179300308, "critic_grad_norm": 0.06942503899335861, "ratio": 0.9996520280838013, "entropy": 0.6771608352661133, "incre_win_rate": 0.8444444444444444, "step": 1576}
{"time": 1767159024.713527, "phase": "train", "update": 1577, "total_env_steps": 5046400, "episode_reward": 0.26240530610084534, "value_loss": 0.007718560099601745, "policy_loss": -0.0011017231635838342, "dist_entropy": 0.6763177037239074, "actor_grad_norm": 0.08175620436668396, "critic_grad_norm": 0.11026884615421295, "ratio": 0.9996420741081238, "entropy": 0.6763177037239074, "incre_win_rate": 0.9090909090909091, "step": 1577}
{"time": 1767159028.9913661, "phase": "train", "update": 1578, "total_env_steps": 5049600, "episode_reward": 0.26645901799201965, "value_loss": 0.007718069292604923, "policy_loss": -0.00128012781568696, "dist_entropy": 0.6939507246017456, "actor_grad_norm": 0.10254047065973282, "critic_grad_norm": 0.05289701372385025, "ratio": 0.9998480081558228, "entropy": 0.6939507246017456, "incre_win_rate": 0.9534883720930233, "step": 1578}
{"time": 1767159033.241243, "phase": "train", "update": 1579, "total_env_steps": 5052800, "episode_reward": 0.25746893882751465, "value_loss": 0.007861129846423865, "policy_loss": -0.0009478845696293092, "dist_entropy": 0.6829973459243774, "actor_grad_norm": 0.09003359824419022, "critic_grad_norm": 0.07846935838460922, "ratio": 1.000085711479187, "entropy": 0.6829973459243774, "incre_win_rate": 0.9047619047619048, "step": 1579}
{"time": 1767159037.5248692, "phase": "train", "update": 1580, "total_env_steps": 5056000, "episode_reward": 0.27141663432121277, "value_loss": 0.004665881767868996, "policy_loss": -0.0013150479475541488, "dist_entropy": 0.6949034929275513, "actor_grad_norm": 0.12118881195783615, "critic_grad_norm": 0.1924842894077301, "ratio": 1.00029718875885, "entropy": 0.6949034929275513, "incre_win_rate": 0.9545454545454546, "step": 1580}
{"time": 1767159041.82335, "phase": "train", "update": 1581, "total_env_steps": 5059200, "episode_reward": 0.2682201862335205, "value_loss": 0.004492967762053013, "policy_loss": -0.0010258512244661234, "dist_entropy": 0.696069598197937, "actor_grad_norm": 0.08731155842542648, "critic_grad_norm": 0.12000107765197754, "ratio": 1.000170350074768, "entropy": 0.696069598197937, "incre_win_rate": 0.9318181818181818, "step": 1581}
{"time": 1767159051.8139648, "phase": "eval", "update": 1581, "total_env_steps": 5059200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.825434602649008, "step": 1581}
{"time": 1767159056.1093016, "phase": "train", "update": 1582, "total_env_steps": 5062400, "episode_reward": 0.2600238025188446, "value_loss": 0.004559279419481754, "policy_loss": -0.0011416876770041994, "dist_entropy": 0.6656052589416503, "actor_grad_norm": 0.09495481103658676, "critic_grad_norm": 0.14261536300182343, "ratio": 0.999835193157196, "entropy": 0.6656052589416503, "incre_win_rate": 0.8837209302325582, "step": 1582}
{"time": 1767159060.3962553, "phase": "train", "update": 1583, "total_env_steps": 5065600, "episode_reward": 0.261513352394104, "value_loss": 0.00850190594792366, "policy_loss": -0.0013662006825789774, "dist_entropy": 0.653271746635437, "actor_grad_norm": 0.10775909572839737, "critic_grad_norm": 0.13623975217342377, "ratio": 0.9997665286064148, "entropy": 0.653271746635437, "incre_win_rate": 0.8604651162790697, "step": 1583}
{"time": 1767159064.693202, "phase": "train", "update": 1584, "total_env_steps": 5068800, "episode_reward": 0.26790356636047363, "value_loss": 0.005799643788486719, "policy_loss": -0.0012409222808646091, "dist_entropy": 0.6458948731422425, "actor_grad_norm": 0.08494282513856888, "critic_grad_norm": 0.140130877494812, "ratio": 1.0001085996627808, "entropy": 0.6458948731422425, "incre_win_rate": 0.9069767441860465, "step": 1584}
{"time": 1767159068.9310029, "phase": "train", "update": 1585, "total_env_steps": 5072000, "episode_reward": 0.26789167523384094, "value_loss": 0.005854418780654669, "policy_loss": -0.001294680517715463, "dist_entropy": 0.6397926688194275, "actor_grad_norm": 0.08945297449827194, "critic_grad_norm": 0.09276508539915085, "ratio": 1.0003037452697754, "entropy": 0.6397926688194275, "incre_win_rate": 0.8913043478260869, "step": 1585}
{"time": 1767159073.1985955, "phase": "train", "update": 1586, "total_env_steps": 5075200, "episode_reward": 0.27152836322784424, "value_loss": 0.006111823953688145, "policy_loss": -0.0008886348993129012, "dist_entropy": 0.6348832607269287, "actor_grad_norm": 0.08000551909208298, "critic_grad_norm": 0.10988550633192062, "ratio": 0.999828040599823, "entropy": 0.6348832607269287, "incre_win_rate": 0.8809523809523809, "step": 1586}
{"time": 1767159077.4318311, "phase": "train", "update": 1587, "total_env_steps": 5078400, "episode_reward": 0.2589569687843323, "value_loss": 0.010854307562112808, "policy_loss": -0.001493378758030417, "dist_entropy": 0.6283218264579773, "actor_grad_norm": 0.1130504161119461, "critic_grad_norm": 0.1561996191740036, "ratio": 0.9996574521064758, "entropy": 0.6283218264579773, "incre_win_rate": 0.8888888888888888, "step": 1587}
{"time": 1767159081.7488291, "phase": "train", "update": 1588, "total_env_steps": 5081600, "episode_reward": 0.2679925560951233, "value_loss": 0.004781819973140955, "policy_loss": -0.0009634758649127662, "dist_entropy": 0.6081167340278626, "actor_grad_norm": 0.10311572998762131, "critic_grad_norm": 0.10811376571655273, "ratio": 0.9997738003730774, "entropy": 0.6081167340278626, "incre_win_rate": 0.9285714285714286, "step": 1588}
{"time": 1767159086.0291681, "phase": "train", "update": 1589, "total_env_steps": 5084800, "episode_reward": 0.2704128921031952, "value_loss": 0.005508751235902309, "policy_loss": -0.00119550790820675, "dist_entropy": 0.6135326743125915, "actor_grad_norm": 0.1094258576631546, "critic_grad_norm": 0.10417119413614273, "ratio": 0.9998113512992859, "entropy": 0.6135326743125915, "incre_win_rate": 0.9347826086956522, "step": 1589}
{"time": 1767159090.2786207, "phase": "train", "update": 1590, "total_env_steps": 5088000, "episode_reward": 0.26939156651496887, "value_loss": 0.004986442346125841, "policy_loss": -0.0008601009770469404, "dist_entropy": 0.6202308416366578, "actor_grad_norm": 0.09369479864835739, "critic_grad_norm": 0.07081823796033859, "ratio": 1.0002236366271973, "entropy": 0.6202308416366578, "incre_win_rate": 0.9069767441860465, "step": 1590}
{"time": 1767159094.5710847, "phase": "train", "update": 1591, "total_env_steps": 5091200, "episode_reward": 0.27941641211509705, "value_loss": 0.002936812490224838, "policy_loss": -0.0011700371702687562, "dist_entropy": 0.6290555357933044, "actor_grad_norm": 0.08801107853651047, "critic_grad_norm": 0.05869970843195915, "ratio": 0.9999364018440247, "entropy": 0.6290555357933044, "incre_win_rate": 1.0, "step": 1591}
{"time": 1767159098.8481445, "phase": "train", "update": 1592, "total_env_steps": 5094400, "episode_reward": 0.27029696106910706, "value_loss": 0.004910762142390013, "policy_loss": -0.0010096670017617272, "dist_entropy": 0.6488443613052368, "actor_grad_norm": 0.08745836466550827, "critic_grad_norm": 0.11594309657812119, "ratio": 0.9995394945144653, "entropy": 0.6488443613052368, "incre_win_rate": 0.9090909090909091, "step": 1592}
{"time": 1767159103.182846, "phase": "train", "update": 1593, "total_env_steps": 5097600, "episode_reward": 0.2769909203052521, "value_loss": 0.0028295357711613177, "policy_loss": -0.0011152956531759628, "dist_entropy": 0.6522293567657471, "actor_grad_norm": 0.09006907045841217, "critic_grad_norm": 0.069351427257061, "ratio": 1.0000189542770386, "entropy": 0.6522293567657471, "incre_win_rate": 0.9777777777777777, "step": 1593}
{"time": 1767159107.4958692, "phase": "train", "update": 1594, "total_env_steps": 5100800, "episode_reward": 0.2769106924533844, "value_loss": 0.005522687267512083, "policy_loss": -0.0014708997581792005, "dist_entropy": 0.6603661179542542, "actor_grad_norm": 0.09997078031301498, "critic_grad_norm": 0.060195207595825195, "ratio": 0.9996407628059387, "entropy": 0.6603661179542542, "incre_win_rate": 0.9347826086956522, "step": 1594}
{"time": 1767159111.7958329, "phase": "train", "update": 1595, "total_env_steps": 5104000, "episode_reward": 0.2808246910572052, "value_loss": 0.004824166186153889, "policy_loss": -0.0010800676215275474, "dist_entropy": 0.6553538560867309, "actor_grad_norm": 0.09548512101173401, "critic_grad_norm": 0.07055559009313583, "ratio": 0.9999222159385681, "entropy": 0.6553538560867309, "incre_win_rate": 1.0, "step": 1595}
{"time": 1767159116.0800676, "phase": "train", "update": 1596, "total_env_steps": 5107200, "episode_reward": 0.27064570784568787, "value_loss": 0.006253521982580423, "policy_loss": -0.0013020920489903887, "dist_entropy": 0.6500045657157898, "actor_grad_norm": 0.09036243706941605, "critic_grad_norm": 0.10212556272745132, "ratio": 0.9999724626541138, "entropy": 0.6500045657157898, "incre_win_rate": 0.9130434782608695, "step": 1596}
{"time": 1767159120.3864539, "phase": "train", "update": 1597, "total_env_steps": 5110400, "episode_reward": 0.2749544680118561, "value_loss": 0.0047180760651826855, "policy_loss": -0.0016536557581677159, "dist_entropy": 0.631549084186554, "actor_grad_norm": 0.09161213040351868, "critic_grad_norm": 0.07779199630022049, "ratio": 0.9996438026428223, "entropy": 0.631549084186554, "incre_win_rate": 0.9545454545454546, "step": 1597}
{"time": 1767159124.6755815, "phase": "train", "update": 1598, "total_env_steps": 5113600, "episode_reward": 0.26219579577445984, "value_loss": 0.007445352990180254, "policy_loss": -0.0011963660621205463, "dist_entropy": 0.6250186800956726, "actor_grad_norm": 0.07429265975952148, "critic_grad_norm": 0.06835126131772995, "ratio": 0.9997599720954895, "entropy": 0.6250186800956726, "incre_win_rate": 0.8809523809523809, "step": 1598}
{"time": 1767159128.9422758, "phase": "train", "update": 1599, "total_env_steps": 5116800, "episode_reward": 0.26960524916648865, "value_loss": 0.005716319102793932, "policy_loss": -0.0009644998208180767, "dist_entropy": 0.6055397033691406, "actor_grad_norm": 0.07914470881223679, "critic_grad_norm": 0.0971112921833992, "ratio": 1.0002018213272095, "entropy": 0.6055397033691406, "incre_win_rate": 0.9534883720930233, "step": 1599}
{"time": 1767159133.2463577, "phase": "train", "update": 1600, "total_env_steps": 5120000, "episode_reward": 0.2649374008178711, "value_loss": 0.005216387286782265, "policy_loss": -0.0013776893278702573, "dist_entropy": 0.6198534965515137, "actor_grad_norm": 0.09179814159870148, "critic_grad_norm": 0.13289864361286163, "ratio": 1.000217318534851, "entropy": 0.6198534965515137, "incre_win_rate": 0.8913043478260869, "step": 1600}
{"time": 1767159137.517249, "phase": "train", "update": 1601, "total_env_steps": 5123200, "episode_reward": 0.2801666259765625, "value_loss": 0.0035197495482861994, "policy_loss": -0.0011365431743371346, "dist_entropy": 0.6264161229133606, "actor_grad_norm": 0.1034824475646019, "critic_grad_norm": 0.05442872270941734, "ratio": 1.000432014465332, "entropy": 0.6264161229133606, "incre_win_rate": 0.9767441860465116, "step": 1601}
{"time": 1767159147.1963115, "phase": "eval", "update": 1601, "total_env_steps": 5123200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.88700331125828, "step": 1601}
{"time": 1767159151.4523597, "phase": "train", "update": 1602, "total_env_steps": 5126400, "episode_reward": 0.2672320008277893, "value_loss": 0.004977901466190815, "policy_loss": -0.0009788026664391935, "dist_entropy": 0.5977995157241821, "actor_grad_norm": 0.09382354468107224, "critic_grad_norm": 0.11652789264917374, "ratio": 1.0002295970916748, "entropy": 0.5977995157241821, "incre_win_rate": 0.9318181818181818, "step": 1602}
{"time": 1767159155.7078726, "phase": "train", "update": 1603, "total_env_steps": 5129600, "episode_reward": 0.2679728865623474, "value_loss": 0.006859759520739317, "policy_loss": -0.0013707622401739172, "dist_entropy": 0.611618185043335, "actor_grad_norm": 0.10572239011526108, "critic_grad_norm": 0.09362538903951645, "ratio": 0.9999069571495056, "entropy": 0.611618185043335, "incre_win_rate": 0.9333333333333333, "step": 1603}
{"time": 1767159159.9873707, "phase": "train", "update": 1604, "total_env_steps": 5132800, "episode_reward": 0.2783537209033966, "value_loss": 0.004072549752891064, "policy_loss": -0.0012216795371960743, "dist_entropy": 0.6274143576622009, "actor_grad_norm": 0.08571445196866989, "critic_grad_norm": 0.04656694829463959, "ratio": 1.0001634359359741, "entropy": 0.6274143576622009, "incre_win_rate": 0.9555555555555556, "step": 1604}
{"time": 1767159164.303795, "phase": "train", "update": 1605, "total_env_steps": 5136000, "episode_reward": 0.28224751353263855, "value_loss": 0.002016269322484732, "policy_loss": -0.001390878029385334, "dist_entropy": 0.6398364305496216, "actor_grad_norm": 0.08463791012763977, "critic_grad_norm": 0.07396679371595383, "ratio": 0.9999222159385681, "entropy": 0.6398364305496216, "incre_win_rate": 1.0, "step": 1605}
{"time": 1767159168.5389125, "phase": "train", "update": 1606, "total_env_steps": 5139200, "episode_reward": 0.2667430639266968, "value_loss": 0.006769031938165426, "policy_loss": -0.0009453299906081014, "dist_entropy": 0.6243930935859681, "actor_grad_norm": 0.09057758003473282, "critic_grad_norm": 0.10704394429922104, "ratio": 1.0001287460327148, "entropy": 0.6243930935859681, "incre_win_rate": 0.9069767441860465, "step": 1606}
{"time": 1767159172.8466375, "phase": "train", "update": 1607, "total_env_steps": 5142400, "episode_reward": 0.259878933429718, "value_loss": 0.012343224324285983, "policy_loss": -0.0016095883278040902, "dist_entropy": 0.6368633270263672, "actor_grad_norm": 0.11047130078077316, "critic_grad_norm": 0.24420276284217834, "ratio": 1.0004205703735352, "entropy": 0.6368633270263672, "incre_win_rate": 0.8444444444444444, "step": 1607}
{"time": 1767159177.1198046, "phase": "train", "update": 1608, "total_env_steps": 5145600, "episode_reward": 0.26585111021995544, "value_loss": 0.0074711725115776065, "policy_loss": -0.0014242191056297315, "dist_entropy": 0.6280715942382813, "actor_grad_norm": 0.09580109268426895, "critic_grad_norm": 0.16236862540245056, "ratio": 0.9997879266738892, "entropy": 0.6280715942382813, "incre_win_rate": 0.8409090909090909, "step": 1608}
{"time": 1767159181.430002, "phase": "train", "update": 1609, "total_env_steps": 5148800, "episode_reward": 0.2759188413619995, "value_loss": 0.004022345133125782, "policy_loss": -0.0009450985003091716, "dist_entropy": 0.6156840801239014, "actor_grad_norm": 0.07010158151388168, "critic_grad_norm": 0.12169165909290314, "ratio": 1.0000194311141968, "entropy": 0.6156840801239014, "incre_win_rate": 0.9772727272727273, "step": 1609}
{"time": 1767159185.6779532, "phase": "train", "update": 1610, "total_env_steps": 5152000, "episode_reward": 0.27114546298980713, "value_loss": 0.005532686691731214, "policy_loss": -0.0015816795246966996, "dist_entropy": 0.5965964913368225, "actor_grad_norm": 0.07770054787397385, "critic_grad_norm": 0.031061604619026184, "ratio": 0.9997168779373169, "entropy": 0.5965964913368225, "incre_win_rate": 0.9347826086956522, "step": 1610}
{"time": 1767159189.9272246, "phase": "train", "update": 1611, "total_env_steps": 5155200, "episode_reward": 0.26745450496673584, "value_loss": 0.008016307558864354, "policy_loss": -0.001275341321531087, "dist_entropy": 0.5970130443572998, "actor_grad_norm": 0.07874029874801636, "critic_grad_norm": 0.052894946187734604, "ratio": 0.9998087286949158, "entropy": 0.5970130443572998, "incre_win_rate": 0.8780487804878049, "step": 1611}
{"time": 1767159194.1946635, "phase": "train", "update": 1612, "total_env_steps": 5158400, "episode_reward": 0.2790355980396271, "value_loss": 0.004449525475502014, "policy_loss": -0.0013156256316888993, "dist_entropy": 0.5884296536445618, "actor_grad_norm": 0.11331187933683395, "critic_grad_norm": 0.10422573238611221, "ratio": 0.9999300837516785, "entropy": 0.5884296536445618, "incre_win_rate": 0.9574468085106383, "step": 1612}
{"time": 1767159198.465377, "phase": "train", "update": 1613, "total_env_steps": 5161600, "episode_reward": 0.2658940553665161, "value_loss": 0.006920378468930721, "policy_loss": -0.001184797705961671, "dist_entropy": 0.5966112494468689, "actor_grad_norm": 0.08145926892757416, "critic_grad_norm": 0.11419886350631714, "ratio": 0.9996042251586914, "entropy": 0.5966112494468689, "incre_win_rate": 0.8372093023255814, "step": 1613}
{"time": 1767159202.727651, "phase": "train", "update": 1614, "total_env_steps": 5164800, "episode_reward": 0.26268884539604187, "value_loss": 0.006977993994951248, "policy_loss": -0.0014204911755029137, "dist_entropy": 0.5811354756355286, "actor_grad_norm": 0.09509348124265671, "critic_grad_norm": 0.097981296479702, "ratio": 0.9997755289077759, "entropy": 0.5811354756355286, "incre_win_rate": 0.9111111111111111, "step": 1614}
{"time": 1767159207.012988, "phase": "train", "update": 1615, "total_env_steps": 5168000, "episode_reward": 0.27299928665161133, "value_loss": 0.005587284918874502, "policy_loss": -0.001403397371250037, "dist_entropy": 0.5813584566116333, "actor_grad_norm": 0.08474086970090866, "critic_grad_norm": 0.05846128612756729, "ratio": 1.0000050067901611, "entropy": 0.5813584566116333, "incre_win_rate": 0.9302325581395349, "step": 1615}
{"time": 1767159211.2635794, "phase": "train", "update": 1616, "total_env_steps": 5171200, "episode_reward": 0.27738720178604126, "value_loss": 0.004468891583383083, "policy_loss": -0.0009549812417501968, "dist_entropy": 0.5886356472969055, "actor_grad_norm": 0.0715121179819107, "critic_grad_norm": 0.11930704116821289, "ratio": 0.9997749328613281, "entropy": 0.5886356472969055, "incre_win_rate": 0.9574468085106383, "step": 1616}
{"time": 1767159215.5367079, "phase": "train", "update": 1617, "total_env_steps": 5174400, "episode_reward": 0.27000001072883606, "value_loss": 0.007046743202954531, "policy_loss": -0.0012561556387780115, "dist_entropy": 0.5952895879745483, "actor_grad_norm": 0.0896255299448967, "critic_grad_norm": 0.1338415890932083, "ratio": 0.9998001456260681, "entropy": 0.5952895879745483, "incre_win_rate": 0.8837209302325582, "step": 1617}
{"time": 1767159219.823871, "phase": "train", "update": 1618, "total_env_steps": 5177600, "episode_reward": 0.27561259269714355, "value_loss": 0.006378743145614862, "policy_loss": -0.0012669038403259948, "dist_entropy": 0.6033883094787598, "actor_grad_norm": 0.08833906799554825, "critic_grad_norm": 0.1097988411784172, "ratio": 0.9999157786369324, "entropy": 0.6033883094787598, "incre_win_rate": 0.9555555555555556, "step": 1618}
{"time": 1767159224.1185362, "phase": "train", "update": 1619, "total_env_steps": 5180800, "episode_reward": 0.26761433482170105, "value_loss": 0.007588470913469791, "policy_loss": -0.0012740584927975363, "dist_entropy": 0.6236815929412842, "actor_grad_norm": 0.09600590169429779, "critic_grad_norm": 0.07655864953994751, "ratio": 0.9995676875114441, "entropy": 0.6236815929412842, "incre_win_rate": 0.9318181818181818, "step": 1619}
{"time": 1767159228.3819056, "phase": "train", "update": 1620, "total_env_steps": 5184000, "episode_reward": 0.26666441559791565, "value_loss": 0.00868214201182127, "policy_loss": -0.0010008252710719035, "dist_entropy": 0.6322163581848145, "actor_grad_norm": 0.06588158011436462, "critic_grad_norm": 0.11994455009698868, "ratio": 1.0001200437545776, "entropy": 0.6322163581848145, "incre_win_rate": 0.8444444444444444, "step": 1620}
{"time": 1767159232.6530647, "phase": "train", "update": 1621, "total_env_steps": 5187200, "episode_reward": 0.27140316367149353, "value_loss": 0.005897889845073223, "policy_loss": -0.0011435533601762415, "dist_entropy": 0.6421273946762085, "actor_grad_norm": 0.08931805193424225, "critic_grad_norm": 0.11744754761457443, "ratio": 1.0003281831741333, "entropy": 0.6421273946762085, "incre_win_rate": 0.9285714285714286, "step": 1621}
{"time": 1767159242.0508614, "phase": "eval", "update": 1621, "total_env_steps": 5187200, "eval_win_rate": 1.0, "eval_episode_reward": 20.001862582781456, "step": 1621}
{"time": 1767159246.3455894, "phase": "train", "update": 1622, "total_env_steps": 5190400, "episode_reward": 0.270913690328598, "value_loss": 0.006912683509290219, "policy_loss": -0.001164295085162337, "dist_entropy": 0.6528956413269043, "actor_grad_norm": 0.08488289266824722, "critic_grad_norm": 0.09587683528661728, "ratio": 0.9999683499336243, "entropy": 0.6528956413269043, "incre_win_rate": 0.9130434782608695, "step": 1622}
{"time": 1767159250.628569, "phase": "train", "update": 1623, "total_env_steps": 5193600, "episode_reward": 0.2670115828514099, "value_loss": 0.007143330387771129, "policy_loss": -0.0009624917872727678, "dist_entropy": 0.6737440705299378, "actor_grad_norm": 0.1051768809556961, "critic_grad_norm": 0.12997739017009735, "ratio": 1.0001506805419922, "entropy": 0.6737440705299378, "incre_win_rate": 0.8863636363636364, "step": 1623}
{"time": 1767159254.8964388, "phase": "train", "update": 1624, "total_env_steps": 5196800, "episode_reward": 0.26355186104774475, "value_loss": 0.006086792610585689, "policy_loss": -0.001499272925709505, "dist_entropy": 0.6499690413475037, "actor_grad_norm": 0.10811393707990646, "critic_grad_norm": 0.1127472072839737, "ratio": 0.9994561076164246, "entropy": 0.6499690413475037, "incre_win_rate": 0.8837209302325582, "step": 1624}
{"time": 1767159259.1563733, "phase": "train", "update": 1625, "total_env_steps": 5200000, "episode_reward": 0.26803600788116455, "value_loss": 0.0059850051999092106, "policy_loss": -0.001239584076050093, "dist_entropy": 0.6369723558425904, "actor_grad_norm": 0.10976306349039078, "critic_grad_norm": 0.13608600199222565, "ratio": 0.9995684623718262, "entropy": 0.6369723558425904, "incre_win_rate": 0.9069767441860465, "step": 1625}
{"time": 1767159263.4161932, "phase": "train", "update": 1626, "total_env_steps": 5203200, "episode_reward": 0.2590164244174957, "value_loss": 0.010400490462779998, "policy_loss": -0.0012576190028816825, "dist_entropy": 0.6292423844337464, "actor_grad_norm": 0.09970392286777496, "critic_grad_norm": 0.10192086547613144, "ratio": 0.9995760917663574, "entropy": 0.6292423844337464, "incre_win_rate": 0.8222222222222222, "step": 1626}
{"time": 1767159267.7034101, "phase": "train", "update": 1627, "total_env_steps": 5206400, "episode_reward": 0.26146572828292847, "value_loss": 0.011399788223206997, "policy_loss": -0.0011736503568563704, "dist_entropy": 0.61013822555542, "actor_grad_norm": 0.10030283033847809, "critic_grad_norm": 0.12041082233190536, "ratio": 0.9999008178710938, "entropy": 0.61013822555542, "incre_win_rate": 0.8571428571428571, "step": 1627}
{"time": 1767159272.0199509, "phase": "train", "update": 1628, "total_env_steps": 5209600, "episode_reward": 0.28053390979766846, "value_loss": 0.004361197911202907, "policy_loss": -0.0010937791250768213, "dist_entropy": 0.6066504120826721, "actor_grad_norm": 0.09011844545602798, "critic_grad_norm": 0.12145854532718658, "ratio": 0.999898374080658, "entropy": 0.6066504120826721, "incre_win_rate": 0.9574468085106383, "step": 1628}
{"time": 1767159276.3178535, "phase": "train", "update": 1629, "total_env_steps": 5212800, "episode_reward": 0.2730835974216461, "value_loss": 0.006161077413707972, "policy_loss": -0.001393586772337141, "dist_entropy": 0.5891613721847534, "actor_grad_norm": 0.09837018698453903, "critic_grad_norm": 0.10709504038095474, "ratio": 1.0001227855682373, "entropy": 0.5891613721847534, "incre_win_rate": 0.9069767441860465, "step": 1629}
{"time": 1767159280.5882506, "phase": "train", "update": 1630, "total_env_steps": 5216000, "episode_reward": 0.2711346447467804, "value_loss": 0.006116288807243108, "policy_loss": -0.000760398130362816, "dist_entropy": 0.5942009687423706, "actor_grad_norm": 0.09505921602249146, "critic_grad_norm": 0.08181260526180267, "ratio": 1.0001047849655151, "entropy": 0.5942009687423706, "incre_win_rate": 0.9347826086956522, "step": 1630}
{"time": 1767159284.8601422, "phase": "train", "update": 1631, "total_env_steps": 5219200, "episode_reward": 0.26842302083969116, "value_loss": 0.007539298571646214, "policy_loss": -0.0012432031904396012, "dist_entropy": 0.6025724411010742, "actor_grad_norm": 0.07489467412233353, "critic_grad_norm": 0.11593153327703476, "ratio": 0.999973714351654, "entropy": 0.6025724411010742, "incre_win_rate": 0.9069767441860465, "step": 1631}
{"time": 1767159289.1087594, "phase": "train", "update": 1632, "total_env_steps": 5222400, "episode_reward": 0.27750828862190247, "value_loss": 0.006486170273274183, "policy_loss": -0.001119810507326946, "dist_entropy": 0.6013661384582519, "actor_grad_norm": 0.08778135478496552, "critic_grad_norm": 0.16536040604114532, "ratio": 1.000009298324585, "entropy": 0.6013661384582519, "incre_win_rate": 0.9347826086956522, "step": 1632}
{"time": 1767159293.3880775, "phase": "train", "update": 1633, "total_env_steps": 5225600, "episode_reward": 0.2766597867012024, "value_loss": 0.005237772781401873, "policy_loss": -0.0010960887200482717, "dist_entropy": 0.5838642954826355, "actor_grad_norm": 0.08783560246229172, "critic_grad_norm": 0.0731315165758133, "ratio": 0.9999557733535767, "entropy": 0.5838642954826355, "incre_win_rate": 0.9545454545454546, "step": 1633}
{"time": 1767159326.9614215, "phase": "train", "update": 1634, "total_env_steps": 5228800, "episode_reward": 0.2653321921825409, "value_loss": 0.054541073739528656, "policy_loss": -0.0007738426488003824, "dist_entropy": 0.5797112345695495, "actor_grad_norm": 0.08902736753225327, "critic_grad_norm": 0.5065426826477051, "ratio": 0.9997357726097107, "entropy": 0.5797112345695495, "incre_win_rate": 0.926829268292683, "step": 1634}
{"time": 1767159331.1909027, "phase": "train", "update": 1635, "total_env_steps": 5232000, "episode_reward": 0.2557077705860138, "value_loss": 0.0073621106334030625, "policy_loss": -0.0012907183658096954, "dist_entropy": 0.611026155948639, "actor_grad_norm": 0.0928829088807106, "critic_grad_norm": 0.2696228623390198, "ratio": 0.9998369216918945, "entropy": 0.611026155948639, "incre_win_rate": 0.875, "step": 1635}
{"time": 1767159335.5570872, "phase": "train", "update": 1636, "total_env_steps": 5235200, "episode_reward": 0.2816261351108551, "value_loss": 0.005178718920797109, "policy_loss": -0.0010149297597083161, "dist_entropy": 0.6233000874519348, "actor_grad_norm": 0.09187725931406021, "critic_grad_norm": 0.2571738660335541, "ratio": 0.9999818205833435, "entropy": 0.6233000874519348, "incre_win_rate": 0.9361702127659575, "step": 1636}
{"time": 1767159339.8697863, "phase": "train", "update": 1637, "total_env_steps": 5238400, "episode_reward": 0.27035701274871826, "value_loss": 0.0077619821764528755, "policy_loss": -0.0008721988208407084, "dist_entropy": 0.6411418080329895, "actor_grad_norm": 0.08413556963205338, "critic_grad_norm": 0.17277030646800995, "ratio": 1.0003278255462646, "entropy": 0.6411418080329895, "incre_win_rate": 0.9090909090909091, "step": 1637}
{"time": 1767159344.1698468, "phase": "train", "update": 1638, "total_env_steps": 5241600, "episode_reward": 0.2708412706851959, "value_loss": 0.004411054588854313, "policy_loss": -0.001277606703220613, "dist_entropy": 0.627933931350708, "actor_grad_norm": 0.09026797860860825, "critic_grad_norm": 0.11103279888629913, "ratio": 1.0001285076141357, "entropy": 0.627933931350708, "incre_win_rate": 0.9534883720930233, "step": 1638}
{"time": 1767159348.430254, "phase": "train", "update": 1639, "total_env_steps": 5244800, "episode_reward": 0.2637287974357605, "value_loss": 0.00678455401211977, "policy_loss": -0.0013984956857257202, "dist_entropy": 0.6310140132904053, "actor_grad_norm": 0.08560808002948761, "critic_grad_norm": 0.16217122972011566, "ratio": 0.9997653961181641, "entropy": 0.6310140132904053, "incre_win_rate": 0.8863636363636364, "step": 1639}
{"time": 1767159352.7743256, "phase": "train", "update": 1640, "total_env_steps": 5248000, "episode_reward": 0.2695472836494446, "value_loss": 0.006367915868759155, "policy_loss": -0.0010205722253900263, "dist_entropy": 0.6077487826347351, "actor_grad_norm": 0.08779700845479965, "critic_grad_norm": 0.18002350628376007, "ratio": 1.0000245571136475, "entropy": 0.6077487826347351, "incre_win_rate": 0.8863636363636364, "step": 1640}
{"time": 1767159357.1232193, "phase": "train", "update": 1641, "total_env_steps": 5251200, "episode_reward": 0.27500829100608826, "value_loss": 0.00815015695989132, "policy_loss": -0.0014371223555528444, "dist_entropy": 0.6332144498825073, "actor_grad_norm": 0.0919836089015007, "critic_grad_norm": 0.12257026880979538, "ratio": 0.999775230884552, "entropy": 0.6332144498825073, "incre_win_rate": 0.9148936170212766, "step": 1641}
{"time": 1767159367.333633, "phase": "eval", "update": 1641, "total_env_steps": 5251200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.5338886589404, "step": 1641}
{"time": 1767159371.601555, "phase": "train", "update": 1642, "total_env_steps": 5254400, "episode_reward": 0.25706642866134644, "value_loss": 0.0076011762954294685, "policy_loss": -0.001266232648063159, "dist_entropy": 0.6161714196205139, "actor_grad_norm": 0.09979541599750519, "critic_grad_norm": 0.09232272207736969, "ratio": 0.9999099969863892, "entropy": 0.6161714196205139, "incre_win_rate": 0.8536585365853658, "step": 1642}
{"time": 1767159375.9075248, "phase": "train", "update": 1643, "total_env_steps": 5257600, "episode_reward": 0.27404284477233887, "value_loss": 0.005796828772872686, "policy_loss": -0.001373115689806781, "dist_entropy": 0.6211184024810791, "actor_grad_norm": 0.10676604509353638, "critic_grad_norm": 0.16465818881988525, "ratio": 1.0004713535308838, "entropy": 0.6211184024810791, "incre_win_rate": 0.9333333333333333, "step": 1643}
{"time": 1767159380.210623, "phase": "train", "update": 1644, "total_env_steps": 5260800, "episode_reward": 0.2680691182613373, "value_loss": 0.005666249338537455, "policy_loss": -0.0010924503106714667, "dist_entropy": 0.6104442954063416, "actor_grad_norm": 0.11890864372253418, "critic_grad_norm": 0.12884178757667542, "ratio": 0.9998660087585449, "entropy": 0.6104442954063416, "incre_win_rate": 0.9069767441860465, "step": 1644}
{"time": 1767159384.5121665, "phase": "train", "update": 1645, "total_env_steps": 5264000, "episode_reward": 0.27537667751312256, "value_loss": 0.0030820267740637062, "policy_loss": -0.0010220543315952568, "dist_entropy": 0.6078547358512878, "actor_grad_norm": 0.10352474451065063, "critic_grad_norm": 0.08568046987056732, "ratio": 0.9999610781669617, "entropy": 0.6078547358512878, "incre_win_rate": 0.9565217391304348, "step": 1645}
{"time": 1767159388.8013463, "phase": "train", "update": 1646, "total_env_steps": 5267200, "episode_reward": 0.2651185095310211, "value_loss": 0.006828052178025246, "policy_loss": -0.0015006661615210247, "dist_entropy": 0.6095270156860352, "actor_grad_norm": 0.0997043028473854, "critic_grad_norm": 0.11304428428411484, "ratio": 0.9998838305473328, "entropy": 0.6095270156860352, "incre_win_rate": 0.9069767441860465, "step": 1646}
{"time": 1767159393.119231, "phase": "train", "update": 1647, "total_env_steps": 5270400, "episode_reward": 0.2682957351207733, "value_loss": 0.005117377545684576, "policy_loss": -0.0009246531361277732, "dist_entropy": 0.6049518585205078, "actor_grad_norm": 0.09251033514738083, "critic_grad_norm": 0.10853791236877441, "ratio": 0.9997596144676208, "entropy": 0.6049518585205078, "incre_win_rate": 0.9090909090909091, "step": 1647}
{"time": 1767159397.4433494, "phase": "train", "update": 1648, "total_env_steps": 5273600, "episode_reward": 0.27028149366378784, "value_loss": 0.0051457202062010765, "policy_loss": -0.0013637004640095541, "dist_entropy": 0.6095483541488648, "actor_grad_norm": 0.08609273284673691, "critic_grad_norm": 0.07364713400602341, "ratio": 0.9998143315315247, "entropy": 0.6095483541488648, "incre_win_rate": 0.9302325581395349, "step": 1648}
{"time": 1767159401.7355301, "phase": "train", "update": 1649, "total_env_steps": 5276800, "episode_reward": 0.2704967260360718, "value_loss": 0.005035749450325966, "policy_loss": -0.0010061915146636125, "dist_entropy": 0.6109998822212219, "actor_grad_norm": 0.08126372843980789, "critic_grad_norm": 0.050317224115133286, "ratio": 0.9998567700386047, "entropy": 0.6109998822212219, "incre_win_rate": 0.9111111111111111, "step": 1649}
{"time": 1767159405.9639993, "phase": "train", "update": 1650, "total_env_steps": 5280000, "episode_reward": 0.2651117742061615, "value_loss": 0.008791054785251617, "policy_loss": -0.0007651698867409351, "dist_entropy": 0.5900118470191955, "actor_grad_norm": 0.08218490332365036, "critic_grad_norm": 0.1519765853881836, "ratio": 0.9999622702598572, "entropy": 0.5900118470191955, "incre_win_rate": 0.8888888888888888, "step": 1650}
{"time": 1767159410.2129767, "phase": "train", "update": 1651, "total_env_steps": 5283200, "episode_reward": 0.2740071415901184, "value_loss": 0.003907685447484255, "policy_loss": -0.0011205678755999316, "dist_entropy": 0.6541817307472229, "actor_grad_norm": 0.08298009634017944, "critic_grad_norm": 0.07535511255264282, "ratio": 0.9998990297317505, "entropy": 0.6541817307472229, "incre_win_rate": 0.9767441860465116, "step": 1651}
{"time": 1767159414.4525921, "phase": "train", "update": 1652, "total_env_steps": 5286400, "episode_reward": 0.2725662291049957, "value_loss": 0.005621131137013435, "policy_loss": -0.0016218465791325797, "dist_entropy": 0.6395310282707214, "actor_grad_norm": 0.1069771870970726, "critic_grad_norm": 0.07318180799484253, "ratio": 0.9997122883796692, "entropy": 0.6395310282707214, "incre_win_rate": 0.8888888888888888, "step": 1652}
{"time": 1767159418.6826158, "phase": "train", "update": 1653, "total_env_steps": 5289600, "episode_reward": 0.2758733630180359, "value_loss": 0.005461869668215514, "policy_loss": -0.001824687458030283, "dist_entropy": 0.6628365635871887, "actor_grad_norm": 0.10973908752202988, "critic_grad_norm": 0.06036214902997017, "ratio": 0.9999073147773743, "entropy": 0.6628365635871887, "incre_win_rate": 0.9534883720930233, "step": 1653}
{"time": 1767159422.992084, "phase": "train", "update": 1654, "total_env_steps": 5292800, "episode_reward": 0.25583869218826294, "value_loss": 0.008471290208399295, "policy_loss": -0.0014287005652757756, "dist_entropy": 0.6444086790084839, "actor_grad_norm": 0.07429414242506027, "critic_grad_norm": 0.1362674981355667, "ratio": 0.9999200105667114, "entropy": 0.6444086790084839, "incre_win_rate": 0.7727272727272727, "step": 1654}
{"time": 1767159427.3250966, "phase": "train", "update": 1655, "total_env_steps": 5296000, "episode_reward": 0.2812267243862152, "value_loss": 0.004954907204955816, "policy_loss": -0.0009994852608677719, "dist_entropy": 0.6653640389442443, "actor_grad_norm": 0.06923399120569229, "critic_grad_norm": 0.09565230458974838, "ratio": 1.0001580715179443, "entropy": 0.6653640389442443, "incre_win_rate": 0.9565217391304348, "step": 1655}
{"time": 1767159431.6146924, "phase": "train", "update": 1656, "total_env_steps": 5299200, "episode_reward": 0.2777591943740845, "value_loss": 0.0066901474259793755, "policy_loss": -0.0015113319376581559, "dist_entropy": 0.6698086738586426, "actor_grad_norm": 0.09415391832590103, "critic_grad_norm": 0.08943020552396774, "ratio": 0.9997217059135437, "entropy": 0.6698086738586426, "incre_win_rate": 0.9347826086956522, "step": 1656}
{"time": 1767159435.9091935, "phase": "train", "update": 1657, "total_env_steps": 5302400, "episode_reward": 0.259652316570282, "value_loss": 0.00646502673625946, "policy_loss": -0.00132263958610892, "dist_entropy": 0.6580084085464477, "actor_grad_norm": 0.08115803450345993, "critic_grad_norm": 0.06436296552419662, "ratio": 0.9999639391899109, "entropy": 0.6580084085464477, "incre_win_rate": 0.9069767441860465, "step": 1657}
{"time": 1767159440.2543392, "phase": "train", "update": 1658, "total_env_steps": 5305600, "episode_reward": 0.27777212858200073, "value_loss": 0.004883434809744358, "policy_loss": -0.0010907999114849077, "dist_entropy": 0.6645818471908569, "actor_grad_norm": 0.08188717812299728, "critic_grad_norm": 0.10241594165563583, "ratio": 1.000064492225647, "entropy": 0.6645818471908569, "incre_win_rate": 0.9285714285714286, "step": 1658}
{"time": 1767159444.6028953, "phase": "train", "update": 1659, "total_env_steps": 5308800, "episode_reward": 0.26563483476638794, "value_loss": 0.005497549753636121, "policy_loss": -0.0012548575193974897, "dist_entropy": 0.6583808898925781, "actor_grad_norm": 0.09669815003871918, "critic_grad_norm": 0.051772069185972214, "ratio": 0.999573826789856, "entropy": 0.6583808898925781, "incre_win_rate": 0.9090909090909091, "step": 1659}
{"time": 1767159448.8805475, "phase": "train", "update": 1660, "total_env_steps": 5312000, "episode_reward": 0.2748427093029022, "value_loss": 0.004173448774963617, "policy_loss": -0.0012599145593519268, "dist_entropy": 0.6688610315322876, "actor_grad_norm": 0.10347255319356918, "critic_grad_norm": 0.06515069305896759, "ratio": 1.000483512878418, "entropy": 0.6688610315322876, "incre_win_rate": 0.9361702127659575, "step": 1660}
{"time": 1767159453.1476371, "phase": "train", "update": 1661, "total_env_steps": 5315200, "episode_reward": 0.2744821012020111, "value_loss": 0.005829099658876657, "policy_loss": -0.000964250675394851, "dist_entropy": 0.6828494191169738, "actor_grad_norm": 0.08806820213794708, "critic_grad_norm": 0.1137847825884819, "ratio": 1.0000896453857422, "entropy": 0.6828494191169738, "incre_win_rate": 0.9111111111111111, "step": 1661}
{"time": 1767159463.6019576, "phase": "eval", "update": 1661, "total_env_steps": 5315200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.672185430463575, "step": 1661}
{"time": 1767159467.8591921, "phase": "train", "update": 1662, "total_env_steps": 5318400, "episode_reward": 0.2685844302177429, "value_loss": 0.00556467343121767, "policy_loss": -0.001481069833573745, "dist_entropy": 0.666377866268158, "actor_grad_norm": 0.10222367197275162, "critic_grad_norm": 0.09220755845308304, "ratio": 1.0000312328338623, "entropy": 0.666377866268158, "incre_win_rate": 0.9534883720930233, "step": 1662}
{"time": 1767159472.1560917, "phase": "train", "update": 1663, "total_env_steps": 5321600, "episode_reward": 0.2567322254180908, "value_loss": 0.009665533155202865, "policy_loss": -0.0012036970301096516, "dist_entropy": 0.6625153183937073, "actor_grad_norm": 0.09620498865842819, "critic_grad_norm": 0.059973884373903275, "ratio": 0.9998517036437988, "entropy": 0.6625153183937073, "incre_win_rate": 0.8095238095238095, "step": 1663}
{"time": 1767159476.4735544, "phase": "train", "update": 1664, "total_env_steps": 5324800, "episode_reward": 0.2686299681663513, "value_loss": 0.009051436185836792, "policy_loss": -0.0014833053969912414, "dist_entropy": 0.6436546564102172, "actor_grad_norm": 0.13646776974201202, "critic_grad_norm": 0.13076677918434143, "ratio": 0.9998556971549988, "entropy": 0.6436546564102172, "incre_win_rate": 0.8723404255319149, "step": 1664}
{"time": 1767159480.8062284, "phase": "train", "update": 1665, "total_env_steps": 5328000, "episode_reward": 0.2807481288909912, "value_loss": 0.006531363725662232, "policy_loss": -0.0013861063048238975, "dist_entropy": 0.6346398830413819, "actor_grad_norm": 0.09588667005300522, "critic_grad_norm": 0.1459573656320572, "ratio": 0.9999298453330994, "entropy": 0.6346398830413819, "incre_win_rate": 0.9111111111111111, "step": 1665}
{"time": 1767159485.1373127, "phase": "train", "update": 1666, "total_env_steps": 5331200, "episode_reward": 0.2726821303367615, "value_loss": 0.008287728950381278, "policy_loss": -0.0012444718495380868, "dist_entropy": 0.6689348101615906, "actor_grad_norm": 0.09090312570333481, "critic_grad_norm": 0.22813263535499573, "ratio": 1.0000895261764526, "entropy": 0.6689348101615906, "incre_win_rate": 0.8863636363636364, "step": 1666}
{"time": 1767159489.4680836, "phase": "train", "update": 1667, "total_env_steps": 5334400, "episode_reward": 0.26666340231895447, "value_loss": 0.007473535742610693, "policy_loss": -0.0010848459385674274, "dist_entropy": 0.6454789400100708, "actor_grad_norm": 0.08964400738477707, "critic_grad_norm": 0.16027428209781647, "ratio": 0.9995316863059998, "entropy": 0.6454789400100708, "incre_win_rate": 0.8837209302325582, "step": 1667}
{"time": 1767159493.7612603, "phase": "train", "update": 1668, "total_env_steps": 5337600, "episode_reward": 0.26159611344337463, "value_loss": 0.005875573772937059, "policy_loss": -0.0011113766515981282, "dist_entropy": 0.6755015611648559, "actor_grad_norm": 0.0846523717045784, "critic_grad_norm": 0.045414917171001434, "ratio": 0.9999793171882629, "entropy": 0.6755015611648559, "incre_win_rate": 0.8888888888888888, "step": 1668}
{"time": 1767159498.0638487, "phase": "train", "update": 1669, "total_env_steps": 5340800, "episode_reward": 0.27666595578193665, "value_loss": 0.00494319312274456, "policy_loss": -0.0011774167824299298, "dist_entropy": 0.6676877498626709, "actor_grad_norm": 0.08813516050577164, "critic_grad_norm": 0.154195174574852, "ratio": 0.9997774362564087, "entropy": 0.6676877498626709, "incre_win_rate": 0.9302325581395349, "step": 1669}
{"time": 1767159502.3508651, "phase": "train", "update": 1670, "total_env_steps": 5344000, "episode_reward": 0.27527886629104614, "value_loss": 0.008575980737805366, "policy_loss": -0.0012129414494594926, "dist_entropy": 0.6686070322990417, "actor_grad_norm": 0.09527475386857986, "critic_grad_norm": 0.0957556888461113, "ratio": 1.000180959701538, "entropy": 0.6686070322990417, "incre_win_rate": 0.8936170212765957, "step": 1670}
{"time": 1767159506.5716286, "phase": "train", "update": 1671, "total_env_steps": 5347200, "episode_reward": 0.26791080832481384, "value_loss": 0.00725651178508997, "policy_loss": -0.001200840555812066, "dist_entropy": 0.6858126044273376, "actor_grad_norm": 0.09593375027179718, "critic_grad_norm": 0.1003313809633255, "ratio": 0.9997798204421997, "entropy": 0.6858126044273376, "incre_win_rate": 0.9285714285714286, "step": 1671}
{"time": 1767159510.8725462, "phase": "train", "update": 1672, "total_env_steps": 5350400, "episode_reward": 0.2683309018611908, "value_loss": 0.008218801021575928, "policy_loss": -0.0014177113381684593, "dist_entropy": 0.657677161693573, "actor_grad_norm": 0.09079799056053162, "critic_grad_norm": 0.14788810908794403, "ratio": 0.9999914169311523, "entropy": 0.657677161693573, "incre_win_rate": 0.9090909090909091, "step": 1672}
{"time": 1767159515.2530909, "phase": "train", "update": 1673, "total_env_steps": 5353600, "episode_reward": 0.26185429096221924, "value_loss": 0.0066064814105629924, "policy_loss": -0.0016339333170254378, "dist_entropy": 0.6470851540565491, "actor_grad_norm": 0.09978362917900085, "critic_grad_norm": 0.13695190846920013, "ratio": 0.9998899698257446, "entropy": 0.6470851540565491, "incre_win_rate": 0.9069767441860465, "step": 1673}
{"time": 1767159519.691338, "phase": "train", "update": 1674, "total_env_steps": 5356800, "episode_reward": 0.27552929520606995, "value_loss": 0.005133340414613485, "policy_loss": -0.00126108939957561, "dist_entropy": 0.6300347566604614, "actor_grad_norm": 0.0949835404753685, "critic_grad_norm": 0.16336311399936676, "ratio": 0.9999549984931946, "entropy": 0.6300347566604614, "incre_win_rate": 0.9555555555555556, "step": 1674}
{"time": 1767159524.0345223, "phase": "train", "update": 1675, "total_env_steps": 5360000, "episode_reward": 0.2811201512813568, "value_loss": 0.004051036713644862, "policy_loss": -0.0008870642350076174, "dist_entropy": 0.6421488642692565, "actor_grad_norm": 0.0813983827829361, "critic_grad_norm": 0.09637243300676346, "ratio": 0.999769389629364, "entropy": 0.6421488642692565, "incre_win_rate": 0.9565217391304348, "step": 1675}
{"time": 1767159528.373415, "phase": "train", "update": 1676, "total_env_steps": 5363200, "episode_reward": 0.2718874216079712, "value_loss": 0.005103821214288473, "policy_loss": -0.001252508597286095, "dist_entropy": 0.6149846911430359, "actor_grad_norm": 0.09379074722528458, "critic_grad_norm": 0.11067553609609604, "ratio": 0.9998379945755005, "entropy": 0.6149846911430359, "incre_win_rate": 0.8913043478260869, "step": 1676}
{"time": 1767159532.6566725, "phase": "train", "update": 1677, "total_env_steps": 5366400, "episode_reward": 0.2724834680557251, "value_loss": 0.006640005391091108, "policy_loss": -0.0010234984789018852, "dist_entropy": 0.6079382061958313, "actor_grad_norm": 0.09734141081571579, "critic_grad_norm": 0.12406071275472641, "ratio": 0.9999213218688965, "entropy": 0.6079382061958313, "incre_win_rate": 0.9523809523809523, "step": 1677}
{"time": 1767159536.9205787, "phase": "train", "update": 1678, "total_env_steps": 5369600, "episode_reward": 0.27652886509895325, "value_loss": 0.004057450219988823, "policy_loss": -0.0013221954807395519, "dist_entropy": 0.5944416522979736, "actor_grad_norm": 0.10608535259962082, "critic_grad_norm": 0.05246724560856819, "ratio": 0.9997087717056274, "entropy": 0.5944416522979736, "incre_win_rate": 0.9565217391304348, "step": 1678}
{"time": 1767159541.2393727, "phase": "train", "update": 1679, "total_env_steps": 5372800, "episode_reward": 0.27423426508903503, "value_loss": 0.00397314028814435, "policy_loss": -0.001126605323287322, "dist_entropy": 0.5961969375610352, "actor_grad_norm": 0.08437999337911606, "critic_grad_norm": 0.1238221749663353, "ratio": 0.9996727108955383, "entropy": 0.5961969375610352, "incre_win_rate": 0.9318181818181818, "step": 1679}
{"time": 1767159545.6149008, "phase": "train", "update": 1680, "total_env_steps": 5376000, "episode_reward": 0.269592821598053, "value_loss": 0.005149240978062153, "policy_loss": -0.0007822355718090535, "dist_entropy": 0.6145475029945373, "actor_grad_norm": 0.09741535037755966, "critic_grad_norm": 0.04905547574162483, "ratio": 1.0003979206085205, "entropy": 0.6145475029945373, "incre_win_rate": 0.9333333333333333, "step": 1680}
{"time": 1767159549.9973795, "phase": "train", "update": 1681, "total_env_steps": 5379200, "episode_reward": 0.26658526062965393, "value_loss": 0.005366137716919184, "policy_loss": -0.0011376766564936247, "dist_entropy": 0.6220643877983093, "actor_grad_norm": 0.08286426216363907, "critic_grad_norm": 0.15058760344982147, "ratio": 1.000022530555725, "entropy": 0.6220643877983093, "incre_win_rate": 0.9285714285714286, "step": 1681}
{"time": 1767159559.746531, "phase": "eval", "update": 1681, "total_env_steps": 5379200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.757864238410598, "step": 1681}
{"time": 1767159564.0278141, "phase": "train", "update": 1682, "total_env_steps": 5382400, "episode_reward": 0.271674782037735, "value_loss": 0.006045217718929052, "policy_loss": -0.0010021799076525896, "dist_entropy": 0.6104860067367553, "actor_grad_norm": 0.0811767727136612, "critic_grad_norm": 0.09089072048664093, "ratio": 1.0000076293945312, "entropy": 0.6104860067367553, "incre_win_rate": 0.9111111111111111, "step": 1682}
{"time": 1767159568.3152788, "phase": "train", "update": 1683, "total_env_steps": 5385600, "episode_reward": 0.2739693820476532, "value_loss": 0.005026848521083593, "policy_loss": -0.000916070291854254, "dist_entropy": 0.6185935497283935, "actor_grad_norm": 0.06332309544086456, "critic_grad_norm": 0.04961131885647774, "ratio": 0.9999865889549255, "entropy": 0.6185935497283935, "incre_win_rate": 0.9069767441860465, "step": 1683}
{"time": 1767159572.5968506, "phase": "train", "update": 1684, "total_env_steps": 5388800, "episode_reward": 0.2789445221424103, "value_loss": 0.004562309850007296, "policy_loss": -0.001160683990877942, "dist_entropy": 0.6288900017738343, "actor_grad_norm": 0.09017651528120041, "critic_grad_norm": 0.11412041634321213, "ratio": 0.999808132648468, "entropy": 0.6288900017738343, "incre_win_rate": 0.9777777777777777, "step": 1684}
{"time": 1767159576.897635, "phase": "train", "update": 1685, "total_env_steps": 5392000, "episode_reward": 0.273642361164093, "value_loss": 0.0039950737729668616, "policy_loss": -0.0011113254114476945, "dist_entropy": 0.6181122303009033, "actor_grad_norm": 0.09883499145507812, "critic_grad_norm": 0.08776714652776718, "ratio": 0.9998551607131958, "entropy": 0.6181122303009033, "incre_win_rate": 0.9565217391304348, "step": 1685}
{"time": 1767159581.1493711, "phase": "train", "update": 1686, "total_env_steps": 5395200, "episode_reward": 0.2638203501701355, "value_loss": 0.005413825903087854, "policy_loss": -0.0013651109023596676, "dist_entropy": 0.602137565612793, "actor_grad_norm": 0.11370070278644562, "critic_grad_norm": 0.05259707197546959, "ratio": 1.000201940536499, "entropy": 0.602137565612793, "incre_win_rate": 0.8536585365853658, "step": 1686}
{"time": 1767159585.5061245, "phase": "train", "update": 1687, "total_env_steps": 5398400, "episode_reward": 0.2800491750240326, "value_loss": 0.00676443362608552, "policy_loss": -0.0016005181682302804, "dist_entropy": 0.6207498908042908, "actor_grad_norm": 0.11001951992511749, "critic_grad_norm": 0.09912140667438507, "ratio": 0.9999804496765137, "entropy": 0.6207498908042908, "incre_win_rate": 0.9166666666666666, "step": 1687}
{"time": 1767159589.7693071, "phase": "train", "update": 1688, "total_env_steps": 5401600, "episode_reward": 0.27085575461387634, "value_loss": 0.007058265898376703, "policy_loss": -0.001309010294423807, "dist_entropy": 0.6255540728569031, "actor_grad_norm": 0.09150949120521545, "critic_grad_norm": 0.1292441338300705, "ratio": 1.0000618696212769, "entropy": 0.6255540728569031, "incre_win_rate": 0.9130434782608695, "step": 1688}
{"time": 1767159594.0575137, "phase": "train", "update": 1689, "total_env_steps": 5404800, "episode_reward": 0.2766892910003662, "value_loss": 0.004605311341583729, "policy_loss": -0.000755558104742704, "dist_entropy": 0.6366535544395446, "actor_grad_norm": 0.08985244482755661, "critic_grad_norm": 0.052355408668518066, "ratio": 0.9997184872627258, "entropy": 0.6366535544395446, "incre_win_rate": 0.9767441860465116, "step": 1689}
{"time": 1767159598.3372848, "phase": "train", "update": 1690, "total_env_steps": 5408000, "episode_reward": 0.27199503779411316, "value_loss": 0.00783219775184989, "policy_loss": -0.001458865855334679, "dist_entropy": 0.6115979671478271, "actor_grad_norm": 0.0957302376627922, "critic_grad_norm": 0.07581805437803268, "ratio": 1.0001038312911987, "entropy": 0.6115979671478271, "incre_win_rate": 0.9318181818181818, "step": 1690}
{"time": 1767159602.612864, "phase": "train", "update": 1691, "total_env_steps": 5411200, "episode_reward": 0.26382142305374146, "value_loss": 0.006684590037912131, "policy_loss": -0.001588898849629139, "dist_entropy": 0.6314225196838379, "actor_grad_norm": 0.11342088133096695, "critic_grad_norm": 0.1291108876466751, "ratio": 1.0001935958862305, "entropy": 0.6314225196838379, "incre_win_rate": 0.9069767441860465, "step": 1691}
{"time": 1767159606.930593, "phase": "train", "update": 1692, "total_env_steps": 5414400, "episode_reward": 0.2751655876636505, "value_loss": 0.004261089721694589, "policy_loss": -0.001110550449476122, "dist_entropy": 0.6333911657333374, "actor_grad_norm": 0.09762568026781082, "critic_grad_norm": 0.1341465413570404, "ratio": 1.0003492832183838, "entropy": 0.6333911657333374, "incre_win_rate": 0.9130434782608695, "step": 1692}
{"time": 1767159611.2402756, "phase": "train", "update": 1693, "total_env_steps": 5417600, "episode_reward": 0.28025662899017334, "value_loss": 0.0030027290806174277, "policy_loss": -0.001085176365945273, "dist_entropy": 0.6493859410285949, "actor_grad_norm": 0.10992884635925293, "critic_grad_norm": 0.05112419277429581, "ratio": 1.0003831386566162, "entropy": 0.6493859410285949, "incre_win_rate": 0.9777777777777777, "step": 1693}
{"time": 1767159615.565139, "phase": "train", "update": 1694, "total_env_steps": 5420800, "episode_reward": 0.2775537967681885, "value_loss": 0.004886259138584137, "policy_loss": -0.0014946947298767554, "dist_entropy": 0.6440463542938233, "actor_grad_norm": 0.11425842344760895, "critic_grad_norm": 0.14897894859313965, "ratio": 1.0001872777938843, "entropy": 0.6440463542938233, "incre_win_rate": 0.9347826086956522, "step": 1694}
{"time": 1767159619.8568883, "phase": "train", "update": 1695, "total_env_steps": 5424000, "episode_reward": 0.27213162183761597, "value_loss": 0.005166639387607574, "policy_loss": -0.0014132899792244301, "dist_entropy": 0.6489707350730896, "actor_grad_norm": 0.09661955386400223, "critic_grad_norm": 0.12858465313911438, "ratio": 0.9998103380203247, "entropy": 0.6489707350730896, "incre_win_rate": 0.8837209302325582, "step": 1695}
{"time": 1767159624.1951733, "phase": "train", "update": 1696, "total_env_steps": 5427200, "episode_reward": 0.2795167863368988, "value_loss": 0.0036453962791711094, "policy_loss": -0.0011358672840430018, "dist_entropy": 0.6415276885032654, "actor_grad_norm": 0.09172528237104416, "critic_grad_norm": 0.07388672977685928, "ratio": 0.9998528361320496, "entropy": 0.6415276885032654, "incre_win_rate": 0.9782608695652174, "step": 1696}
{"time": 1767159628.5196865, "phase": "train", "update": 1697, "total_env_steps": 5430400, "episode_reward": 0.27334439754486084, "value_loss": 0.0038488378282636403, "policy_loss": -0.0010776948402977382, "dist_entropy": 0.6514328956604004, "actor_grad_norm": 0.08928828686475754, "critic_grad_norm": 0.06223144009709358, "ratio": 1.0002843141555786, "entropy": 0.6514328956604004, "incre_win_rate": 0.9545454545454546, "step": 1697}
{"time": 1767159632.838758, "phase": "train", "update": 1698, "total_env_steps": 5433600, "episode_reward": 0.2641732394695282, "value_loss": 0.007003379706293345, "policy_loss": -0.0017545455123823216, "dist_entropy": 0.658660626411438, "actor_grad_norm": 0.1012534648180008, "critic_grad_norm": 0.05486416444182396, "ratio": 0.999921441078186, "entropy": 0.658660626411438, "incre_win_rate": 0.8409090909090909, "step": 1698}
{"time": 1767159637.2042222, "phase": "train", "update": 1699, "total_env_steps": 5436800, "episode_reward": 0.2699223756790161, "value_loss": 0.006384899560362101, "policy_loss": -0.00097283030321762, "dist_entropy": 0.6733756542205811, "actor_grad_norm": 0.08417681604623795, "critic_grad_norm": 0.05352267622947693, "ratio": 0.9999279379844666, "entropy": 0.6733756542205811, "incre_win_rate": 0.8863636363636364, "step": 1699}
{"time": 1767159641.4819732, "phase": "train", "update": 1700, "total_env_steps": 5440000, "episode_reward": 0.26935845613479614, "value_loss": 0.007569683156907559, "policy_loss": -0.0015055442537928343, "dist_entropy": 0.6666429877281189, "actor_grad_norm": 0.10403314977884293, "critic_grad_norm": 0.042510371655225754, "ratio": 1.000133752822876, "entropy": 0.6666429877281189, "incre_win_rate": 0.8888888888888888, "step": 1700}
{"time": 1767159645.7971282, "phase": "train", "update": 1701, "total_env_steps": 5443200, "episode_reward": 0.2620255649089813, "value_loss": 0.007293621916323901, "policy_loss": -0.0014977803953186708, "dist_entropy": 0.6529104471206665, "actor_grad_norm": 0.12987731397151947, "critic_grad_norm": 0.02887849509716034, "ratio": 0.9997270703315735, "entropy": 0.6529104471206665, "incre_win_rate": 0.8604651162790697, "step": 1701}
{"time": 1767159655.3804054, "phase": "eval", "update": 1701, "total_env_steps": 5443200, "eval_win_rate": 1.0, "eval_episode_reward": 20.0, "step": 1701}
{"time": 1767159659.6814802, "phase": "train", "update": 1702, "total_env_steps": 5446400, "episode_reward": 0.26816225051879883, "value_loss": 0.005353496503084898, "policy_loss": -0.0010952883413011705, "dist_entropy": 0.677395474910736, "actor_grad_norm": 0.10314009338617325, "critic_grad_norm": 0.04669002443552017, "ratio": 0.9998126029968262, "entropy": 0.677395474910736, "incre_win_rate": 0.9090909090909091, "step": 1702}
{"time": 1767159663.9793935, "phase": "train", "update": 1703, "total_env_steps": 5449600, "episode_reward": 0.2740563154220581, "value_loss": 0.005578679777681827, "policy_loss": -0.0013249673460443035, "dist_entropy": 0.6649238467216492, "actor_grad_norm": 0.129582017660141, "critic_grad_norm": 0.07620163261890411, "ratio": 1.0001786947250366, "entropy": 0.6649238467216492, "incre_win_rate": 0.9555555555555556, "step": 1703}
{"time": 1767159668.2967467, "phase": "train", "update": 1704, "total_env_steps": 5452800, "episode_reward": 0.2718501687049866, "value_loss": 0.006574823055416346, "policy_loss": -0.0013345089110970321, "dist_entropy": 0.6626892566680909, "actor_grad_norm": 0.11771493405103683, "critic_grad_norm": 0.045283399522304535, "ratio": 1.0000221729278564, "entropy": 0.6626892566680909, "incre_win_rate": 0.9069767441860465, "step": 1704}
{"time": 1767159672.5934978, "phase": "train", "update": 1705, "total_env_steps": 5456000, "episode_reward": 0.27876242995262146, "value_loss": 0.003255425253883004, "policy_loss": -0.0010309613725640431, "dist_entropy": 0.6438652515411377, "actor_grad_norm": 0.1429368108510971, "critic_grad_norm": 0.062070079147815704, "ratio": 1.0001424551010132, "entropy": 0.6438652515411377, "incre_win_rate": 1.0, "step": 1705}
{"time": 1767159676.8742363, "phase": "train", "update": 1706, "total_env_steps": 5459200, "episode_reward": 0.2651045322418213, "value_loss": 0.007417806703597307, "policy_loss": -0.0012404000358301915, "dist_entropy": 0.6474770069122314, "actor_grad_norm": 0.08740442991256714, "critic_grad_norm": 0.13264060020446777, "ratio": 1.0001024007797241, "entropy": 0.6474770069122314, "incre_win_rate": 0.8333333333333334, "step": 1706}
{"time": 1767159681.1995919, "phase": "train", "update": 1707, "total_env_steps": 5462400, "episode_reward": 0.2753140330314636, "value_loss": 0.005534753389656544, "policy_loss": -0.001304616452578955, "dist_entropy": 0.6661511898040772, "actor_grad_norm": 0.09941653162240982, "critic_grad_norm": 0.07399781793355942, "ratio": 0.9999362826347351, "entropy": 0.6661511898040772, "incre_win_rate": 0.9148936170212766, "step": 1707}
{"time": 1767159685.5405836, "phase": "train", "update": 1708, "total_env_steps": 5465600, "episode_reward": 0.27060431241989136, "value_loss": 0.007850381731986999, "policy_loss": -0.0011189774941414044, "dist_entropy": 0.6423625111579895, "actor_grad_norm": 0.11393417418003082, "critic_grad_norm": 0.07883905619382858, "ratio": 1.0000072717666626, "entropy": 0.6423625111579895, "incre_win_rate": 0.8604651162790697, "step": 1708}
{"time": 1767159689.816539, "phase": "train", "update": 1709, "total_env_steps": 5468800, "episode_reward": 0.2689072787761688, "value_loss": 0.0063171092420816425, "policy_loss": -0.001290619576584362, "dist_entropy": 0.655742061138153, "actor_grad_norm": 0.08397753536701202, "critic_grad_norm": 0.06303855031728745, "ratio": 0.9999285936355591, "entropy": 0.655742061138153, "incre_win_rate": 0.8913043478260869, "step": 1709}
{"time": 1767159694.1728106, "phase": "train", "update": 1710, "total_env_steps": 5472000, "episode_reward": 0.277086079120636, "value_loss": 0.006797638162970543, "policy_loss": -0.0014813445699331852, "dist_entropy": 0.665760850906372, "actor_grad_norm": 0.08502013236284256, "critic_grad_norm": 0.10685553401708603, "ratio": 1.0000168085098267, "entropy": 0.665760850906372, "incre_win_rate": 0.9545454545454546, "step": 1710}
{"time": 1767159698.488426, "phase": "train", "update": 1711, "total_env_steps": 5475200, "episode_reward": 0.267486035823822, "value_loss": 0.005470827873796225, "policy_loss": -0.001670833621291834, "dist_entropy": 0.6646309852600097, "actor_grad_norm": 0.10274696350097656, "critic_grad_norm": 0.07976850122213364, "ratio": 1.0001380443572998, "entropy": 0.6646309852600097, "incre_win_rate": 0.9111111111111111, "step": 1711}
{"time": 1767159702.8074572, "phase": "train", "update": 1712, "total_env_steps": 5478400, "episode_reward": 0.2651810944080353, "value_loss": 0.005158160906285047, "policy_loss": -0.0011291250582692314, "dist_entropy": 0.641046154499054, "actor_grad_norm": 0.08752240985631943, "critic_grad_norm": 0.03354514390230179, "ratio": 0.9999929666519165, "entropy": 0.641046154499054, "incre_win_rate": 0.9285714285714286, "step": 1712}
{"time": 1767159707.1207764, "phase": "train", "update": 1713, "total_env_steps": 5481600, "episode_reward": 0.2718682587146759, "value_loss": 0.004208859521895647, "policy_loss": -0.0015675506654304172, "dist_entropy": 0.6548221588134766, "actor_grad_norm": 0.10434683412313461, "critic_grad_norm": 0.04407915472984314, "ratio": 1.0001637935638428, "entropy": 0.6548221588134766, "incre_win_rate": 0.9555555555555556, "step": 1713}
{"time": 1767159711.407332, "phase": "train", "update": 1714, "total_env_steps": 5484800, "episode_reward": 0.2641163170337677, "value_loss": 0.0070263870060443875, "policy_loss": -0.001225477079399262, "dist_entropy": 0.6528830170631409, "actor_grad_norm": 0.11572381108999252, "critic_grad_norm": 0.05257640406489372, "ratio": 0.9999939799308777, "entropy": 0.6528830170631409, "incre_win_rate": 0.8604651162790697, "step": 1714}
{"time": 1767159715.741056, "phase": "train", "update": 1715, "total_env_steps": 5488000, "episode_reward": 0.2693744897842407, "value_loss": 0.007351870369166136, "policy_loss": -0.00126104898991386, "dist_entropy": 0.652925705909729, "actor_grad_norm": 0.1202937588095665, "critic_grad_norm": 0.037912704050540924, "ratio": 0.9998965263366699, "entropy": 0.652925705909729, "incre_win_rate": 0.8913043478260869, "step": 1715}
{"time": 1767159720.0339193, "phase": "train", "update": 1716, "total_env_steps": 5491200, "episode_reward": 0.27622929215431213, "value_loss": 0.004817670490592718, "policy_loss": -0.0011301785226434547, "dist_entropy": 0.661851966381073, "actor_grad_norm": 0.07859792560338974, "critic_grad_norm": 0.10846976190805435, "ratio": 1.000020146369934, "entropy": 0.661851966381073, "incre_win_rate": 0.9534883720930233, "step": 1716}
{"time": 1767159724.3882809, "phase": "train", "update": 1717, "total_env_steps": 5494400, "episode_reward": 0.269197016954422, "value_loss": 0.006386744510382414, "policy_loss": -0.0009415002682906959, "dist_entropy": 0.6425817608833313, "actor_grad_norm": 0.072532519698143, "critic_grad_norm": 0.08988402038812637, "ratio": 1.0000241994857788, "entropy": 0.6425817608833313, "incre_win_rate": 0.9111111111111111, "step": 1717}
{"time": 1767159728.6998909, "phase": "train", "update": 1718, "total_env_steps": 5497600, "episode_reward": 0.280612587928772, "value_loss": 0.0034080162644386292, "policy_loss": -0.0009710437063237265, "dist_entropy": 0.6464648008346557, "actor_grad_norm": 0.09683344513177872, "critic_grad_norm": 0.05883199721574783, "ratio": 0.9999476671218872, "entropy": 0.6464648008346557, "incre_win_rate": 0.9772727272727273, "step": 1718}
{"time": 1767159733.0000496, "phase": "train", "update": 1719, "total_env_steps": 5500800, "episode_reward": 0.2697143852710724, "value_loss": 0.006638803239911795, "policy_loss": -0.0012531975193178723, "dist_entropy": 0.6459291577339172, "actor_grad_norm": 0.09733206033706665, "critic_grad_norm": 0.06250392645597458, "ratio": 0.9998364448547363, "entropy": 0.6459291577339172, "incre_win_rate": 0.9347826086956522, "step": 1719}
{"time": 1767159737.3183098, "phase": "train", "update": 1720, "total_env_steps": 5504000, "episode_reward": 0.27112582325935364, "value_loss": 0.004710617661476135, "policy_loss": -0.001242629155804309, "dist_entropy": 0.6700677990913391, "actor_grad_norm": 0.08540499955415726, "critic_grad_norm": 0.06865876913070679, "ratio": 1.0002204179763794, "entropy": 0.6700677990913391, "incre_win_rate": 0.925, "step": 1720}
{"time": 1767159741.6214898, "phase": "train", "update": 1721, "total_env_steps": 5507200, "episode_reward": 0.2667466998100281, "value_loss": 0.008087871689349413, "policy_loss": -0.0021189420614097453, "dist_entropy": 0.6679294824600219, "actor_grad_norm": 0.10298047214746475, "critic_grad_norm": 0.0599273256957531, "ratio": 1.0000369548797607, "entropy": 0.6679294824600219, "incre_win_rate": 0.8913043478260869, "step": 1721}
{"time": 1767159751.4460175, "phase": "eval", "update": 1721, "total_env_steps": 5507200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.47733857615894, "step": 1721}
{"time": 1767159755.7530832, "phase": "train", "update": 1722, "total_env_steps": 5510400, "episode_reward": 0.25991153717041016, "value_loss": 0.015106921270489692, "policy_loss": -0.0009051478935884205, "dist_entropy": 0.6709976077079773, "actor_grad_norm": 0.08716777712106705, "critic_grad_norm": 0.1690211296081543, "ratio": 0.9996032118797302, "entropy": 0.6709976077079773, "incre_win_rate": 0.8837209302325582, "step": 1722}
{"time": 1767159760.0843058, "phase": "train", "update": 1723, "total_env_steps": 5513600, "episode_reward": 0.26480236649513245, "value_loss": 0.005750451236963272, "policy_loss": -0.001615102971786264, "dist_entropy": 0.6552593469619751, "actor_grad_norm": 0.14787285029888153, "critic_grad_norm": 0.11062473058700562, "ratio": 0.9995563626289368, "entropy": 0.6552593469619751, "incre_win_rate": 0.9318181818181818, "step": 1723}
{"time": 1767159764.415306, "phase": "train", "update": 1724, "total_env_steps": 5516800, "episode_reward": 0.2650972604751587, "value_loss": 0.007468432653695345, "policy_loss": -0.0012680152404129785, "dist_entropy": 0.6613574266433716, "actor_grad_norm": 0.11611150950193405, "critic_grad_norm": 0.105853371322155, "ratio": 0.9998044967651367, "entropy": 0.6613574266433716, "incre_win_rate": 0.8444444444444444, "step": 1724}
{"time": 1767159768.7353237, "phase": "train", "update": 1725, "total_env_steps": 5520000, "episode_reward": 0.27209436893463135, "value_loss": 0.0062055356800556185, "policy_loss": -0.0016006995374318934, "dist_entropy": 0.6495858192443847, "actor_grad_norm": 0.10062704235315323, "critic_grad_norm": 0.14564266800880432, "ratio": 0.9990585446357727, "entropy": 0.6495858192443847, "incre_win_rate": 0.9523809523809523, "step": 1725}
{"time": 1767159772.985059, "phase": "train", "update": 1726, "total_env_steps": 5523200, "episode_reward": 0.2597433924674988, "value_loss": 0.009946919046342373, "policy_loss": -0.0014926308935823585, "dist_entropy": 0.6431345701217651, "actor_grad_norm": 0.09953834116458893, "critic_grad_norm": 0.10481882095336914, "ratio": 1.0001469850540161, "entropy": 0.6431345701217651, "incre_win_rate": 0.8409090909090909, "step": 1726}
{"time": 1767159777.2666345, "phase": "train", "update": 1727, "total_env_steps": 5526400, "episode_reward": 0.26957419514656067, "value_loss": 0.007106131501495838, "policy_loss": -0.001056581615820562, "dist_entropy": 0.6329236268997193, "actor_grad_norm": 0.10323584079742432, "critic_grad_norm": 0.20052149891853333, "ratio": 1.0002762079238892, "entropy": 0.6329236268997193, "incre_win_rate": 0.9333333333333333, "step": 1727}
{"time": 1767159781.550145, "phase": "train", "update": 1728, "total_env_steps": 5529600, "episode_reward": 0.25650662183761597, "value_loss": 0.007740498520433903, "policy_loss": -0.0012567182644196428, "dist_entropy": 0.6416370034217834, "actor_grad_norm": 0.07622339576482773, "critic_grad_norm": 0.17202529311180115, "ratio": 0.9998950362205505, "entropy": 0.6416370034217834, "incre_win_rate": 0.8372093023255814, "step": 1728}
{"time": 1767159785.8433282, "phase": "train", "update": 1729, "total_env_steps": 5532800, "episode_reward": 0.26150453090667725, "value_loss": 0.007466987892985344, "policy_loss": -0.0008668992456939862, "dist_entropy": 0.647623074054718, "actor_grad_norm": 0.08073072880506516, "critic_grad_norm": 0.17685839533805847, "ratio": 0.9999130368232727, "entropy": 0.647623074054718, "incre_win_rate": 0.9523809523809523, "step": 1729}
{"time": 1767159790.1772723, "phase": "train", "update": 1730, "total_env_steps": 5536000, "episode_reward": 0.26889798045158386, "value_loss": 0.006720309890806675, "policy_loss": -0.0014482919030214703, "dist_entropy": 0.6400104403495789, "actor_grad_norm": 0.08696485310792923, "critic_grad_norm": 0.12934769690036774, "ratio": 0.9998660087585449, "entropy": 0.6400104403495789, "incre_win_rate": 0.9285714285714286, "step": 1730}
{"time": 1767159794.4694839, "phase": "train", "update": 1731, "total_env_steps": 5539200, "episode_reward": 0.2567984163761139, "value_loss": 0.009419956803321838, "policy_loss": -0.0012601326133975022, "dist_entropy": 0.6369161009788513, "actor_grad_norm": 0.10607681423425674, "critic_grad_norm": 0.127060204744339, "ratio": 0.9992610812187195, "entropy": 0.6369161009788513, "incre_win_rate": 0.8043478260869565, "step": 1731}
{"time": 1767159798.7919352, "phase": "train", "update": 1732, "total_env_steps": 5542400, "episode_reward": 0.2777690589427948, "value_loss": 0.005092845764011145, "policy_loss": -0.0009670204759373747, "dist_entropy": 0.6563163161277771, "actor_grad_norm": 0.10732873529195786, "critic_grad_norm": 0.1841568499803543, "ratio": 1.0002336502075195, "entropy": 0.6563163161277771, "incre_win_rate": 0.9772727272727273, "step": 1732}
{"time": 1767159803.050643, "phase": "train", "update": 1733, "total_env_steps": 5545600, "episode_reward": 0.26213058829307556, "value_loss": 0.005781307350844145, "policy_loss": -0.001266183375187735, "dist_entropy": 0.6313583493232727, "actor_grad_norm": 0.08876007050275803, "critic_grad_norm": 0.11368304491043091, "ratio": 1.0001827478408813, "entropy": 0.6313583493232727, "incre_win_rate": 0.8837209302325582, "step": 1733}
{"time": 1767159807.3508468, "phase": "train", "update": 1734, "total_env_steps": 5548800, "episode_reward": 0.27180880308151245, "value_loss": 0.006899928208440542, "policy_loss": -0.0013414370423351584, "dist_entropy": 0.6426656007766723, "actor_grad_norm": 0.08840453624725342, "critic_grad_norm": 0.16234688460826874, "ratio": 1.000069499015808, "entropy": 0.6426656007766723, "incre_win_rate": 0.9767441860465116, "step": 1734}
{"time": 1767159811.6352236, "phase": "train", "update": 1735, "total_env_steps": 5552000, "episode_reward": 0.26057949662208557, "value_loss": 0.009156544134020806, "policy_loss": -0.0008726613355634072, "dist_entropy": 0.6314221978187561, "actor_grad_norm": 0.07964242994785309, "critic_grad_norm": 0.2070419043302536, "ratio": 0.9996647834777832, "entropy": 0.6314221978187561, "incre_win_rate": 0.8409090909090909, "step": 1735}
{"time": 1767159815.887175, "phase": "train", "update": 1736, "total_env_steps": 5555200, "episode_reward": 0.2757781445980072, "value_loss": 0.005248673260211945, "policy_loss": -0.0014595223948870029, "dist_entropy": 0.6306046605110168, "actor_grad_norm": 0.08414637297391891, "critic_grad_norm": 0.1866297572851181, "ratio": 1.0002045631408691, "entropy": 0.6306046605110168, "incre_win_rate": 0.9767441860465116, "step": 1736}
{"time": 1767159820.194348, "phase": "train", "update": 1737, "total_env_steps": 5558400, "episode_reward": 0.27295994758605957, "value_loss": 0.0060663977637887, "policy_loss": -0.001006387168240508, "dist_entropy": 0.6199830770492554, "actor_grad_norm": 0.09051812440156937, "critic_grad_norm": 0.1753907948732376, "ratio": 0.9996618628501892, "entropy": 0.6199830770492554, "incre_win_rate": 0.9333333333333333, "step": 1737}
{"time": 1767159824.4933133, "phase": "train", "update": 1738, "total_env_steps": 5561600, "episode_reward": 0.2625330984592438, "value_loss": 0.00585296330973506, "policy_loss": -0.0014247685580050628, "dist_entropy": 0.6424324870109558, "actor_grad_norm": 0.1103806123137474, "critic_grad_norm": 0.07971535623073578, "ratio": 0.9997092485427856, "entropy": 0.6424324870109558, "incre_win_rate": 0.9111111111111111, "step": 1738}
{"time": 1767159828.7941308, "phase": "train", "update": 1739, "total_env_steps": 5564800, "episode_reward": 0.26374587416648865, "value_loss": 0.00675506005063653, "policy_loss": -0.001360546520604089, "dist_entropy": 0.6606589794158936, "actor_grad_norm": 0.09100700914859772, "critic_grad_norm": 0.17181751132011414, "ratio": 0.9997850656509399, "entropy": 0.6606589794158936, "incre_win_rate": 0.9047619047619048, "step": 1739}
{"time": 1767159833.033763, "phase": "train", "update": 1740, "total_env_steps": 5568000, "episode_reward": 0.2720835208892822, "value_loss": 0.004889835929498076, "policy_loss": -0.001073512054537673, "dist_entropy": 0.6878066420555115, "actor_grad_norm": 0.09052815288305283, "critic_grad_norm": 0.11958777904510498, "ratio": 1.0001521110534668, "entropy": 0.6878066420555115, "incre_win_rate": 0.9555555555555556, "step": 1740}
{"time": 1767159837.3497293, "phase": "train", "update": 1741, "total_env_steps": 5571200, "episode_reward": 0.26649010181427, "value_loss": 0.005259079951792955, "policy_loss": -0.0013418630583451828, "dist_entropy": 0.6735801339149475, "actor_grad_norm": 0.08820454031229019, "critic_grad_norm": 0.08294396847486496, "ratio": 0.9995426535606384, "entropy": 0.6735801339149475, "incre_win_rate": 0.9302325581395349, "step": 1741}
{"time": 1767159847.1841486, "phase": "eval", "update": 1741, "total_env_steps": 5571200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.53895902317881, "step": 1741}
{"time": 1767159851.4432316, "phase": "train", "update": 1742, "total_env_steps": 5574400, "episode_reward": 0.2690024673938751, "value_loss": 0.005753922089934349, "policy_loss": -0.0010522755221991531, "dist_entropy": 0.6818475127220154, "actor_grad_norm": 0.08789744228124619, "critic_grad_norm": 0.13285252451896667, "ratio": 1.0002893209457397, "entropy": 0.6818475127220154, "incre_win_rate": 0.9302325581395349, "step": 1742}
{"time": 1767159855.8013852, "phase": "train", "update": 1743, "total_env_steps": 5577600, "episode_reward": 0.26411837339401245, "value_loss": 0.007090820837765932, "policy_loss": -0.0012102182339759793, "dist_entropy": 0.6870600700378418, "actor_grad_norm": 0.10051450878381729, "critic_grad_norm": 0.1297379434108734, "ratio": 0.9999691247940063, "entropy": 0.6870600700378418, "incre_win_rate": 0.9090909090909091, "step": 1743}
{"time": 1767159860.1209054, "phase": "train", "update": 1744, "total_env_steps": 5580800, "episode_reward": 0.26920944452285767, "value_loss": 0.004743799287825823, "policy_loss": -0.0012008465397556733, "dist_entropy": 0.6857349753379822, "actor_grad_norm": 0.09590763598680496, "critic_grad_norm": 0.057961076498031616, "ratio": 0.9998558163642883, "entropy": 0.6857349753379822, "incre_win_rate": 0.9545454545454546, "step": 1744}
{"time": 1767159864.413921, "phase": "train", "update": 1745, "total_env_steps": 5584000, "episode_reward": 0.26955708861351013, "value_loss": 0.006323935277760029, "policy_loss": -0.0011058504117862356, "dist_entropy": 0.6984023451805115, "actor_grad_norm": 0.10181727260351181, "critic_grad_norm": 0.10940110683441162, "ratio": 0.9999160170555115, "entropy": 0.6984023451805115, "incre_win_rate": 0.9302325581395349, "step": 1745}
{"time": 1767159868.7192667, "phase": "train", "update": 1746, "total_env_steps": 5587200, "episode_reward": 0.27066224813461304, "value_loss": 0.004824193846434355, "policy_loss": -0.0009883555758420925, "dist_entropy": 0.6936344385147095, "actor_grad_norm": 0.0849350318312645, "critic_grad_norm": 0.10103654116392136, "ratio": 0.9998364448547363, "entropy": 0.6936344385147095, "incre_win_rate": 0.9318181818181818, "step": 1746}
{"time": 1767159872.9894114, "phase": "train", "update": 1747, "total_env_steps": 5590400, "episode_reward": 0.26510554552078247, "value_loss": 0.006134458817541599, "policy_loss": -0.0012796449350560124, "dist_entropy": 0.6966819882392883, "actor_grad_norm": 0.09174412488937378, "critic_grad_norm": 0.07848907262086868, "ratio": 0.9995164275169373, "entropy": 0.6966819882392883, "incre_win_rate": 0.8863636363636364, "step": 1747}
{"time": 1767159877.290403, "phase": "train", "update": 1748, "total_env_steps": 5593600, "episode_reward": 0.2620447278022766, "value_loss": 0.006485798303037882, "policy_loss": -0.0011730301222925732, "dist_entropy": 0.7074240446090698, "actor_grad_norm": 0.09756623208522797, "critic_grad_norm": 0.0733921080827713, "ratio": 1.0000134706497192, "entropy": 0.7074240446090698, "incre_win_rate": 0.9069767441860465, "step": 1748}
{"time": 1767159881.5581164, "phase": "train", "update": 1749, "total_env_steps": 5596800, "episode_reward": 0.258603572845459, "value_loss": 0.00832119882106781, "policy_loss": -0.001040842350658977, "dist_entropy": 0.6999110460281373, "actor_grad_norm": 0.08592678606510162, "critic_grad_norm": 0.06513997912406921, "ratio": 1.0000327825546265, "entropy": 0.6999110460281373, "incre_win_rate": 0.8571428571428571, "step": 1749}
{"time": 1767159885.9148598, "phase": "train", "update": 1750, "total_env_steps": 5600000, "episode_reward": 0.266642689704895, "value_loss": 0.00761884655803442, "policy_loss": -0.0012701548329992819, "dist_entropy": 0.684230387210846, "actor_grad_norm": 0.10362780094146729, "critic_grad_norm": 0.22372999787330627, "ratio": 1.0002844333648682, "entropy": 0.684230387210846, "incre_win_rate": 0.9090909090909091, "step": 1750}
{"time": 1767159890.2156827, "phase": "train", "update": 1751, "total_env_steps": 5603200, "episode_reward": 0.25778353214263916, "value_loss": 0.005704624205827713, "policy_loss": -0.001268163996642002, "dist_entropy": 0.7105219244956971, "actor_grad_norm": 0.09223011136054993, "critic_grad_norm": 0.14664167165756226, "ratio": 1.0000900030136108, "entropy": 0.7105219244956971, "incre_win_rate": 0.8571428571428571, "step": 1751}
{"time": 1767159894.48014, "phase": "train", "update": 1752, "total_env_steps": 5606400, "episode_reward": 0.25908011198043823, "value_loss": 0.006931256130337715, "policy_loss": -0.001433563005709715, "dist_entropy": 0.7105558753013611, "actor_grad_norm": 0.09877452999353409, "critic_grad_norm": 0.14405383169651031, "ratio": 0.9998624920845032, "entropy": 0.7105558753013611, "incre_win_rate": 0.8837209302325582, "step": 1752}
{"time": 1767159898.7553399, "phase": "train", "update": 1753, "total_env_steps": 5609600, "episode_reward": 0.26737067103385925, "value_loss": 0.0035976515617221596, "policy_loss": -0.001356055487736363, "dist_entropy": 0.7279246330261231, "actor_grad_norm": 0.07660689949989319, "critic_grad_norm": 0.10091765224933624, "ratio": 0.9998452067375183, "entropy": 0.7279246330261231, "incre_win_rate": 1.0, "step": 1753}
{"time": 1767159903.0203018, "phase": "train", "update": 1754, "total_env_steps": 5612800, "episode_reward": 0.2661346197128296, "value_loss": 0.005241576582193375, "policy_loss": -0.0010240007033561094, "dist_entropy": 0.7217948079109192, "actor_grad_norm": 0.0797162875533104, "critic_grad_norm": 0.07709354907274246, "ratio": 1.0000300407409668, "entropy": 0.7217948079109192, "incre_win_rate": 0.9302325581395349, "step": 1754}
{"time": 1767159907.3170505, "phase": "train", "update": 1755, "total_env_steps": 5616000, "episode_reward": 0.2607465982437134, "value_loss": 0.005555916950106621, "policy_loss": -0.0014763516156730105, "dist_entropy": 0.6944643378257751, "actor_grad_norm": 0.09850739687681198, "critic_grad_norm": 0.054471757262945175, "ratio": 0.9999832510948181, "entropy": 0.6944643378257751, "incre_win_rate": 0.8888888888888888, "step": 1755}
{"time": 1767159911.615997, "phase": "train", "update": 1756, "total_env_steps": 5619200, "episode_reward": 0.26471495628356934, "value_loss": 0.006384870223701, "policy_loss": -0.0009471638806976656, "dist_entropy": 0.7362758636474609, "actor_grad_norm": 0.06775020062923431, "critic_grad_norm": 0.05255963280797005, "ratio": 0.9997354745864868, "entropy": 0.7362758636474609, "incre_win_rate": 0.8809523809523809, "step": 1756}
{"time": 1767159915.8853436, "phase": "train", "update": 1757, "total_env_steps": 5622400, "episode_reward": 0.2626050114631653, "value_loss": 0.007746035512536764, "policy_loss": -0.001836504612516876, "dist_entropy": 0.729016375541687, "actor_grad_norm": 0.11086679995059967, "critic_grad_norm": 0.11643131077289581, "ratio": 1.0002226829528809, "entropy": 0.729016375541687, "incre_win_rate": 0.9285714285714286, "step": 1757}
{"time": 1767159920.1280744, "phase": "train", "update": 1758, "total_env_steps": 5625600, "episode_reward": 0.25802409648895264, "value_loss": 0.009756916947662831, "policy_loss": -0.0014765922660593845, "dist_entropy": 0.7049336075782776, "actor_grad_norm": 0.11449126154184341, "critic_grad_norm": 0.14485645294189453, "ratio": 1.0002866983413696, "entropy": 0.7049336075782776, "incre_win_rate": 0.8666666666666667, "step": 1758}
{"time": 1767159924.369447, "phase": "train", "update": 1759, "total_env_steps": 5628800, "episode_reward": 0.24857357144355774, "value_loss": 0.010543136298656464, "policy_loss": -0.0019063977814447242, "dist_entropy": 0.7017805099487304, "actor_grad_norm": 0.12656258046627045, "critic_grad_norm": 0.1722974181175232, "ratio": 0.9998796582221985, "entropy": 0.7017805099487304, "incre_win_rate": 0.7619047619047619, "step": 1759}
{"time": 1767159928.639417, "phase": "train", "update": 1760, "total_env_steps": 5632000, "episode_reward": 0.24771730601787567, "value_loss": 0.006807477306574583, "policy_loss": -0.0016440939744597927, "dist_entropy": 0.695986557006836, "actor_grad_norm": 0.11692831665277481, "critic_grad_norm": 0.07838183641433716, "ratio": 0.9999050498008728, "entropy": 0.695986557006836, "incre_win_rate": 0.8780487804878049, "step": 1760}
{"time": 1767159932.9167047, "phase": "train", "update": 1761, "total_env_steps": 5635200, "episode_reward": 0.24734117090702057, "value_loss": 0.007425634190440178, "policy_loss": -0.001473569562286592, "dist_entropy": 0.6997085690498352, "actor_grad_norm": 0.10332854837179184, "critic_grad_norm": 0.07841909676790237, "ratio": 0.9998485445976257, "entropy": 0.6997085690498352, "incre_win_rate": 0.926829268292683, "step": 1761}
{"time": 1767159944.511113, "phase": "eval", "update": 1761, "total_env_steps": 5635200, "eval_win_rate": 0.75, "eval_episode_reward": 19.071761175496682, "step": 1761}
{"time": 1767159948.812744, "phase": "train", "update": 1762, "total_env_steps": 5638400, "episode_reward": 0.2553952932357788, "value_loss": 0.007123866491019726, "policy_loss": -0.0010510782498766246, "dist_entropy": 0.6774824976921081, "actor_grad_norm": 0.09452270716428757, "critic_grad_norm": 0.06525453180074692, "ratio": 1.0000431537628174, "entropy": 0.6774824976921081, "incre_win_rate": 0.8571428571428571, "step": 1762}
{"time": 1767159953.1191752, "phase": "train", "update": 1763, "total_env_steps": 5641600, "episode_reward": 0.26389744877815247, "value_loss": 0.005205219238996505, "policy_loss": -0.001518236589066646, "dist_entropy": 0.6800494313240051, "actor_grad_norm": 0.09705334901809692, "critic_grad_norm": 0.07177034020423889, "ratio": 1.0002861022949219, "entropy": 0.6800494313240051, "incre_win_rate": 0.9302325581395349, "step": 1763}
{"time": 1767159957.4286542, "phase": "train", "update": 1764, "total_env_steps": 5644800, "episode_reward": 0.2686082422733307, "value_loss": 0.003473830549046397, "policy_loss": -0.0011985857831206203, "dist_entropy": 0.6837490320205688, "actor_grad_norm": 0.1120138168334961, "critic_grad_norm": 0.08501383662223816, "ratio": 1.0002230405807495, "entropy": 0.6837490320205688, "incre_win_rate": 0.9545454545454546, "step": 1764}
{"time": 1767159961.743431, "phase": "train", "update": 1765, "total_env_steps": 5648000, "episode_reward": 0.269022136926651, "value_loss": 0.004021858982741833, "policy_loss": -0.0012816021171687454, "dist_entropy": 0.6600328087806702, "actor_grad_norm": 0.0875759944319725, "critic_grad_norm": 0.03560556843876839, "ratio": 0.9998014569282532, "entropy": 0.6600328087806702, "incre_win_rate": 0.9318181818181818, "step": 1765}
{"time": 1767159966.0907855, "phase": "train", "update": 1766, "total_env_steps": 5651200, "episode_reward": 0.2811925709247589, "value_loss": 0.0036456702277064324, "policy_loss": -0.001307975470847822, "dist_entropy": 0.6616520643234253, "actor_grad_norm": 0.07039307802915573, "critic_grad_norm": 0.04585002735257149, "ratio": 0.9999708533287048, "entropy": 0.6616520643234253, "incre_win_rate": 0.9545454545454546, "step": 1766}
{"time": 1767159970.386856, "phase": "train", "update": 1767, "total_env_steps": 5654400, "episode_reward": 0.26361706852912903, "value_loss": 0.006679721642285585, "policy_loss": -0.001096659440170633, "dist_entropy": 0.6696415185928345, "actor_grad_norm": 0.0844050794839859, "critic_grad_norm": 0.17102642357349396, "ratio": 0.999984085559845, "entropy": 0.6696415185928345, "incre_win_rate": 0.8666666666666667, "step": 1767}
{"time": 1767159974.7406654, "phase": "train", "update": 1768, "total_env_steps": 5657600, "episode_reward": 0.27384519577026367, "value_loss": 0.005263049993664027, "policy_loss": -0.0010202198149904973, "dist_entropy": 0.6601684927940369, "actor_grad_norm": 0.09594377130270004, "critic_grad_norm": 0.09401758760213852, "ratio": 1.0001851320266724, "entropy": 0.6601684927940369, "incre_win_rate": 0.9534883720930233, "step": 1768}
{"time": 1767159979.0568936, "phase": "train", "update": 1769, "total_env_steps": 5660800, "episode_reward": 0.2702679932117462, "value_loss": 0.00739433141425252, "policy_loss": -0.0013663193609943392, "dist_entropy": 0.6717320203781127, "actor_grad_norm": 0.09365686774253845, "critic_grad_norm": 0.07773242890834808, "ratio": 1.0002217292785645, "entropy": 0.6717320203781127, "incre_win_rate": 0.9148936170212766, "step": 1769}
{"time": 1767159983.3358052, "phase": "train", "update": 1770, "total_env_steps": 5664000, "episode_reward": 0.2635264992713928, "value_loss": 0.004581103473901749, "policy_loss": -0.0011734852475012048, "dist_entropy": 0.657522714138031, "actor_grad_norm": 0.11648014932870865, "critic_grad_norm": 0.11709360033273697, "ratio": 1.0002506971359253, "entropy": 0.657522714138031, "incre_win_rate": 0.975, "step": 1770}
{"time": 1767159987.6469302, "phase": "train", "update": 1771, "total_env_steps": 5667200, "episode_reward": 0.27199089527130127, "value_loss": 0.003691274719312787, "policy_loss": -0.0013981213862720664, "dist_entropy": 0.6956210494041443, "actor_grad_norm": 0.11556918919086456, "critic_grad_norm": 0.08430755138397217, "ratio": 1.0003470182418823, "entropy": 0.6956210494041443, "incre_win_rate": 0.9565217391304348, "step": 1771}
{"time": 1767159992.0069869, "phase": "train", "update": 1772, "total_env_steps": 5670400, "episode_reward": 0.2737292945384979, "value_loss": 0.0019376310054212808, "policy_loss": -0.001271975053403196, "dist_entropy": 0.6996881604194641, "actor_grad_norm": 0.10056610405445099, "critic_grad_norm": 0.04969928786158562, "ratio": 1.0002316236495972, "entropy": 0.6996881604194641, "incre_win_rate": 1.0, "step": 1772}
{"time": 1767159996.3581948, "phase": "train", "update": 1773, "total_env_steps": 5673600, "episode_reward": 0.2693750262260437, "value_loss": 0.0030780309811234475, "policy_loss": -0.0009712744329195111, "dist_entropy": 0.7055634617805481, "actor_grad_norm": 0.09925858676433563, "critic_grad_norm": 0.05593738704919815, "ratio": 0.9998084902763367, "entropy": 0.7055634617805481, "incre_win_rate": 0.9545454545454546, "step": 1773}
{"time": 1767160000.7495856, "phase": "train", "update": 1774, "total_env_steps": 5676800, "episode_reward": 0.25768935680389404, "value_loss": 0.006198199279606342, "policy_loss": -0.000965986925901241, "dist_entropy": 0.696943747997284, "actor_grad_norm": 0.09043750911951065, "critic_grad_norm": 0.11194910109043121, "ratio": 1.000145435333252, "entropy": 0.696943747997284, "incre_win_rate": 0.8780487804878049, "step": 1774}
{"time": 1767160005.076115, "phase": "train", "update": 1775, "total_env_steps": 5680000, "episode_reward": 0.26643624901771545, "value_loss": 0.002787026530131698, "policy_loss": -0.001121330219886829, "dist_entropy": 0.6993839144706726, "actor_grad_norm": 0.09643051773309708, "critic_grad_norm": 0.04850267618894577, "ratio": 1.0000430345535278, "entropy": 0.6993839144706726, "incre_win_rate": 0.9333333333333333, "step": 1775}
{"time": 1767160009.3855574, "phase": "train", "update": 1776, "total_env_steps": 5683200, "episode_reward": 0.2650848627090454, "value_loss": 0.0058567700907588005, "policy_loss": -0.0008764887117493458, "dist_entropy": 0.720515501499176, "actor_grad_norm": 0.09789308160543442, "critic_grad_norm": 0.07423494756221771, "ratio": 1.0002570152282715, "entropy": 0.720515501499176, "incre_win_rate": 0.8809523809523809, "step": 1776}
{"time": 1767160013.7257047, "phase": "train", "update": 1777, "total_env_steps": 5686400, "episode_reward": 0.27395695447921753, "value_loss": 0.00291800107806921, "policy_loss": -0.0014571643004879676, "dist_entropy": 0.7401702761650085, "actor_grad_norm": 0.09287454187870026, "critic_grad_norm": 0.06673635542392731, "ratio": 1.0003465414047241, "entropy": 0.7401702761650085, "incre_win_rate": 0.9565217391304348, "step": 1777}
{"time": 1767160018.0642958, "phase": "train", "update": 1778, "total_env_steps": 5689600, "episode_reward": 0.2657109200954437, "value_loss": 0.008576170727610587, "policy_loss": -0.0014106171797785838, "dist_entropy": 0.7493580460548401, "actor_grad_norm": 0.1113734245300293, "critic_grad_norm": 0.15054532885551453, "ratio": 0.9999960064888, "entropy": 0.7493580460548401, "incre_win_rate": 0.8333333333333334, "step": 1778}
{"time": 1767160022.4371262, "phase": "train", "update": 1779, "total_env_steps": 5692800, "episode_reward": 0.2620033025741577, "value_loss": 0.011385917291045189, "policy_loss": -0.0017206115177344828, "dist_entropy": 0.7139329552650452, "actor_grad_norm": 0.14598308503627777, "critic_grad_norm": 0.13263380527496338, "ratio": 0.9998365640640259, "entropy": 0.7139329552650452, "incre_win_rate": 0.851063829787234, "step": 1779}
{"time": 1767160026.7740126, "phase": "train", "update": 1780, "total_env_steps": 5696000, "episode_reward": 0.2640562951564789, "value_loss": 0.009018799476325511, "policy_loss": -0.0013296300789100712, "dist_entropy": 0.7131265759468078, "actor_grad_norm": 0.09166194498538971, "critic_grad_norm": 0.09270165115594864, "ratio": 0.9999036192893982, "entropy": 0.7131265759468078, "incre_win_rate": 0.8837209302325582, "step": 1780}
{"time": 1767160031.0913823, "phase": "train", "update": 1781, "total_env_steps": 5699200, "episode_reward": 0.2716333866119385, "value_loss": 0.005786938406527042, "policy_loss": -0.0012194463826168621, "dist_entropy": 0.7111850023269654, "actor_grad_norm": 0.09047295898199081, "critic_grad_norm": 0.15692701935768127, "ratio": 0.9997294545173645, "entropy": 0.7111850023269654, "incre_win_rate": 0.9069767441860465, "step": 1781}
{"time": 1767160041.0582037, "phase": "eval", "update": 1781, "total_env_steps": 5699200, "eval_win_rate": 1.0, "eval_episode_reward": 20.00248344370861, "step": 1781}
{"time": 1767160045.363656, "phase": "train", "update": 1782, "total_env_steps": 5702400, "episode_reward": 0.2729056179523468, "value_loss": 0.004062567278742791, "policy_loss": -0.001313727808881282, "dist_entropy": 0.6932150244712829, "actor_grad_norm": 0.11495434492826462, "critic_grad_norm": 0.06823684275150299, "ratio": 1.000067949295044, "entropy": 0.6932150244712829, "incre_win_rate": 0.9555555555555556, "step": 1782}
{"time": 1767160049.7133107, "phase": "train", "update": 1783, "total_env_steps": 5705600, "episode_reward": 0.277015745639801, "value_loss": 0.003442012285813689, "policy_loss": -0.0011383762000509278, "dist_entropy": 0.6972867727279664, "actor_grad_norm": 0.101340651512146, "critic_grad_norm": 0.0654817670583725, "ratio": 0.9998738169670105, "entropy": 0.6972867727279664, "incre_win_rate": 0.9555555555555556, "step": 1783}
{"time": 1767160053.9844701, "phase": "train", "update": 1784, "total_env_steps": 5708800, "episode_reward": 0.2641550898551941, "value_loss": 0.004732446372509002, "policy_loss": -0.001090113324750952, "dist_entropy": 0.6902832984924316, "actor_grad_norm": 0.07736726850271225, "critic_grad_norm": 0.08385159075260162, "ratio": 1.000016450881958, "entropy": 0.6902832984924316, "incre_win_rate": 0.9302325581395349, "step": 1784}
{"time": 1767160058.322558, "phase": "train", "update": 1785, "total_env_steps": 5712000, "episode_reward": 0.27109116315841675, "value_loss": 0.0062873647548258305, "policy_loss": -0.0010710785731369299, "dist_entropy": 0.6808087468147278, "actor_grad_norm": 0.07930292934179306, "critic_grad_norm": 0.07112370431423187, "ratio": 1.0002402067184448, "entropy": 0.6808087468147278, "incre_win_rate": 0.9545454545454546, "step": 1785}
{"time": 1767160062.6008837, "phase": "train", "update": 1786, "total_env_steps": 5715200, "episode_reward": 0.2671854496002197, "value_loss": 0.0036961639299988745, "policy_loss": -0.0013101180044884585, "dist_entropy": 0.6889983296394349, "actor_grad_norm": 0.08723451942205429, "critic_grad_norm": 0.047667406499385834, "ratio": 1.0002110004425049, "entropy": 0.6889983296394349, "incre_win_rate": 0.9285714285714286, "step": 1786}
{"time": 1767160066.9211357, "phase": "train", "update": 1787, "total_env_steps": 5718400, "episode_reward": 0.27204468846321106, "value_loss": 0.00575290722772479, "policy_loss": -0.0011490017992139556, "dist_entropy": 0.6824315190315247, "actor_grad_norm": 0.0923960730433464, "critic_grad_norm": 0.06976013630628586, "ratio": 1.0002092123031616, "entropy": 0.6824315190315247, "incre_win_rate": 0.9130434782608695, "step": 1787}
{"time": 1767160071.2283719, "phase": "train", "update": 1788, "total_env_steps": 5721600, "episode_reward": 0.2675926089286804, "value_loss": 0.0039425106719136235, "policy_loss": -0.0010815056692006664, "dist_entropy": 0.6764037132263183, "actor_grad_norm": 0.08288977295160294, "critic_grad_norm": 0.05147063732147217, "ratio": 0.9999915361404419, "entropy": 0.6764037132263183, "incre_win_rate": 0.9302325581395349, "step": 1788}
{"time": 1767160075.5423765, "phase": "train", "update": 1789, "total_env_steps": 5724800, "episode_reward": 0.2633904218673706, "value_loss": 0.00564304543659091, "policy_loss": -0.0011929182424665896, "dist_entropy": 0.6645710825920105, "actor_grad_norm": 0.0730535089969635, "critic_grad_norm": 0.09256438165903091, "ratio": 0.9999476671218872, "entropy": 0.6645710825920105, "incre_win_rate": 0.9047619047619048, "step": 1789}
{"time": 1767160079.8697057, "phase": "train", "update": 1790, "total_env_steps": 5728000, "episode_reward": 0.2665061056613922, "value_loss": 0.004990816302597523, "policy_loss": -0.0011081970512407224, "dist_entropy": 0.6560078144073487, "actor_grad_norm": 0.07751449197530746, "critic_grad_norm": 0.059822894632816315, "ratio": 1.0000629425048828, "entropy": 0.6560078144073487, "incre_win_rate": 0.9534883720930233, "step": 1790}
{"time": 1767160084.1508393, "phase": "train", "update": 1791, "total_env_steps": 5731200, "episode_reward": 0.26535236835479736, "value_loss": 0.005341165047138929, "policy_loss": -0.0009296085601931736, "dist_entropy": 0.6780241847038269, "actor_grad_norm": 0.08846361935138702, "critic_grad_norm": 0.0896497592329979, "ratio": 0.9998896718025208, "entropy": 0.6780241847038269, "incre_win_rate": 0.9545454545454546, "step": 1791}
{"time": 1767160088.4729605, "phase": "train", "update": 1792, "total_env_steps": 5734400, "episode_reward": 0.2694019079208374, "value_loss": 0.004428914468735457, "policy_loss": -0.0014830906606123407, "dist_entropy": 0.6901852250099182, "actor_grad_norm": 0.1055772453546524, "critic_grad_norm": 0.15698997676372528, "ratio": 0.9996638298034668, "entropy": 0.6901852250099182, "incre_win_rate": 0.9318181818181818, "step": 1792}
{"time": 1767160092.753458, "phase": "train", "update": 1793, "total_env_steps": 5737600, "episode_reward": 0.26933053135871887, "value_loss": 0.004127941094338894, "policy_loss": -0.001174480032060643, "dist_entropy": 0.6928742170333863, "actor_grad_norm": 0.10467538982629776, "critic_grad_norm": 0.07840816676616669, "ratio": 0.9998350143432617, "entropy": 0.6928742170333863, "incre_win_rate": 1.0, "step": 1793}
{"time": 1767160097.0674763, "phase": "train", "update": 1794, "total_env_steps": 5740800, "episode_reward": 0.2639082968235016, "value_loss": 0.007091159094125032, "policy_loss": -0.0010648271552378575, "dist_entropy": 0.691251802444458, "actor_grad_norm": 0.08366098254919052, "critic_grad_norm": 0.203995943069458, "ratio": 1.0001081228256226, "entropy": 0.691251802444458, "incre_win_rate": 0.8863636363636364, "step": 1794}
{"time": 1767160101.3845272, "phase": "train", "update": 1795, "total_env_steps": 5744000, "episode_reward": 0.2649756669998169, "value_loss": 0.005986793059855699, "policy_loss": -0.0009740774347861247, "dist_entropy": 0.6949795365333558, "actor_grad_norm": 0.07051938027143478, "critic_grad_norm": 0.13913893699645996, "ratio": 1.0001471042633057, "entropy": 0.6949795365333558, "incre_win_rate": 0.8837209302325582, "step": 1795}
{"time": 1767160105.623861, "phase": "train", "update": 1796, "total_env_steps": 5747200, "episode_reward": 0.2630918622016907, "value_loss": 0.005039147473871708, "policy_loss": -0.0012054491383345577, "dist_entropy": 0.7037113666534424, "actor_grad_norm": 0.09446131438016891, "critic_grad_norm": 0.05738852173089981, "ratio": 1.0000958442687988, "entropy": 0.7037113666534424, "incre_win_rate": 0.9069767441860465, "step": 1796}
{"time": 1767160144.0136344, "phase": "train", "update": 1797, "total_env_steps": 5750400, "episode_reward": 0.25439155101776123, "value_loss": 0.0791033074259758, "policy_loss": -0.0011065527777503804, "dist_entropy": 0.674146580696106, "actor_grad_norm": 0.08059554547071457, "critic_grad_norm": 0.5148174166679382, "ratio": 0.9998936653137207, "entropy": 0.674146580696106, "incre_win_rate": 0.9230769230769231, "step": 1797}
{"time": 1767160148.401483, "phase": "train", "update": 1798, "total_env_steps": 5753600, "episode_reward": 0.26462802290916443, "value_loss": 0.00963155310600996, "policy_loss": -0.0009887342695577672, "dist_entropy": 0.6933769822120667, "actor_grad_norm": 0.10878937691450119, "critic_grad_norm": 0.41470909118652344, "ratio": 1.000292420387268, "entropy": 0.6933769822120667, "incre_win_rate": 0.9111111111111111, "step": 1798}
{"time": 1767160152.7559803, "phase": "train", "update": 1799, "total_env_steps": 5756800, "episode_reward": 0.2623339295387268, "value_loss": 0.00832531088963151, "policy_loss": -0.0009080356943615087, "dist_entropy": 0.6882566809654236, "actor_grad_norm": 0.11308743804693222, "critic_grad_norm": 0.2978494167327881, "ratio": 1.0002291202545166, "entropy": 0.6882566809654236, "incre_win_rate": 0.8372093023255814, "step": 1799}
{"time": 1767160157.1412542, "phase": "train", "update": 1800, "total_env_steps": 5760000, "episode_reward": 0.27373552322387695, "value_loss": 0.005657137092202902, "policy_loss": -0.001209030460583449, "dist_entropy": 0.6941559791564942, "actor_grad_norm": 0.09456675499677658, "critic_grad_norm": 0.1986444741487503, "ratio": 1.0004116296768188, "entropy": 0.6941559791564942, "incre_win_rate": 0.9545454545454546, "step": 1800}
{"time": 1767160161.460071, "phase": "train", "update": 1801, "total_env_steps": 5763200, "episode_reward": 0.2692880630493164, "value_loss": 0.005087684467434883, "policy_loss": -0.0015028750979567463, "dist_entropy": 0.6877841114997864, "actor_grad_norm": 0.10373828560113907, "critic_grad_norm": 0.2722778022289276, "ratio": 0.9998268485069275, "entropy": 0.6877841114997864, "incre_win_rate": 1.0, "step": 1801}
{"time": 1767160171.414847, "phase": "eval", "update": 1801, "total_env_steps": 5763200, "eval_win_rate": 1.0, "eval_episode_reward": 20.007657284768214, "step": 1801}
{"time": 1767160175.7190208, "phase": "train", "update": 1802, "total_env_steps": 5766400, "episode_reward": 0.2684478461742401, "value_loss": 0.003249184740707278, "policy_loss": -0.001363375359561303, "dist_entropy": 0.6899818420410156, "actor_grad_norm": 0.113109290599823, "critic_grad_norm": 0.22185519337654114, "ratio": 0.9999373555183411, "entropy": 0.6899818420410156, "incre_win_rate": 1.0, "step": 1802}
{"time": 1767160180.0334647, "phase": "train", "update": 1803, "total_env_steps": 5769600, "episode_reward": 0.2617073953151703, "value_loss": 0.008376787602901458, "policy_loss": -0.0009323003502334614, "dist_entropy": 0.6753289937973023, "actor_grad_norm": 0.09143924713134766, "critic_grad_norm": 0.11067255586385727, "ratio": 1.0001055002212524, "entropy": 0.6753289937973023, "incre_win_rate": 0.9302325581395349, "step": 1803}
{"time": 1767160184.401944, "phase": "train", "update": 1804, "total_env_steps": 5772800, "episode_reward": 0.27102336287498474, "value_loss": 0.004884367901831865, "policy_loss": -0.0009663973346775379, "dist_entropy": 0.6691441774368286, "actor_grad_norm": 0.08952847868204117, "critic_grad_norm": 0.2385370284318924, "ratio": 1.0003697872161865, "entropy": 0.6691441774368286, "incre_win_rate": 0.9761904761904762, "step": 1804}
{"time": 1767160188.7879982, "phase": "train", "update": 1805, "total_env_steps": 5776000, "episode_reward": 0.26468491554260254, "value_loss": 0.006655519735068083, "policy_loss": -0.0013719956681597979, "dist_entropy": 0.6708736658096314, "actor_grad_norm": 0.09866789728403091, "critic_grad_norm": 0.11532306671142578, "ratio": 0.9999661445617676, "entropy": 0.6708736658096314, "incre_win_rate": 0.9333333333333333, "step": 1805}
{"time": 1767160193.1204114, "phase": "train", "update": 1806, "total_env_steps": 5779200, "episode_reward": 0.2669277787208557, "value_loss": 0.0066833427175879475, "policy_loss": -0.0011106747565527541, "dist_entropy": 0.6880609154701233, "actor_grad_norm": 0.10915843397378922, "critic_grad_norm": 0.173319011926651, "ratio": 0.9999513626098633, "entropy": 0.6880609154701233, "incre_win_rate": 0.9047619047619048, "step": 1806}
{"time": 1767160197.4083972, "phase": "train", "update": 1807, "total_env_steps": 5782400, "episode_reward": 0.26050806045532227, "value_loss": 0.008302161749452353, "policy_loss": -0.0013905417835708533, "dist_entropy": 0.675435197353363, "actor_grad_norm": 0.08562343567609787, "critic_grad_norm": 0.25245314836502075, "ratio": 1.000026822090149, "entropy": 0.675435197353363, "incre_win_rate": 0.9318181818181818, "step": 1807}
{"time": 1767160201.7340016, "phase": "train", "update": 1808, "total_env_steps": 5785600, "episode_reward": 0.2551039755344391, "value_loss": 0.009511747211217881, "policy_loss": -0.0014110630932925971, "dist_entropy": 0.6812971353530883, "actor_grad_norm": 0.09920281916856766, "critic_grad_norm": 0.14849571883678436, "ratio": 0.999629020690918, "entropy": 0.6812971353530883, "incre_win_rate": 0.813953488372093, "step": 1808}
{"time": 1767160206.0785348, "phase": "train", "update": 1809, "total_env_steps": 5788800, "episode_reward": 0.26151904463768005, "value_loss": 0.006572326831519604, "policy_loss": -0.0008163213920141743, "dist_entropy": 0.6743271589279175, "actor_grad_norm": 0.09127800911664963, "critic_grad_norm": 0.14432036876678467, "ratio": 0.9998565912246704, "entropy": 0.6743271589279175, "incre_win_rate": 0.9512195121951219, "step": 1809}
{"time": 1767160210.4354346, "phase": "train", "update": 1810, "total_env_steps": 5792000, "episode_reward": 0.26718026399612427, "value_loss": 0.007431519031524658, "policy_loss": -0.0011013410523062817, "dist_entropy": 0.6848570823669433, "actor_grad_norm": 0.07787759602069855, "critic_grad_norm": 0.23075388371944427, "ratio": 1.0000736713409424, "entropy": 0.6848570823669433, "incre_win_rate": 0.9090909090909091, "step": 1810}
{"time": 1767160214.7988179, "phase": "train", "update": 1811, "total_env_steps": 5795200, "episode_reward": 0.2582041621208191, "value_loss": 0.008582026697695255, "policy_loss": -0.0010996247717233842, "dist_entropy": 0.7065390110015869, "actor_grad_norm": 0.09620826691389084, "critic_grad_norm": 0.10752660036087036, "ratio": 1.000057578086853, "entropy": 0.7065390110015869, "incre_win_rate": 0.9090909090909091, "step": 1811}
{"time": 1767160219.127225, "phase": "train", "update": 1812, "total_env_steps": 5798400, "episode_reward": 0.25578951835632324, "value_loss": 0.007366536185145378, "policy_loss": -0.0013861742877502082, "dist_entropy": 0.6961305975914002, "actor_grad_norm": 0.09599099308252335, "critic_grad_norm": 0.12570160627365112, "ratio": 0.9999173283576965, "entropy": 0.6961305975914002, "incre_win_rate": 0.8809523809523809, "step": 1812}
{"time": 1767160223.42598, "phase": "train", "update": 1813, "total_env_steps": 5801600, "episode_reward": 0.25181758403778076, "value_loss": 0.008652671799063682, "policy_loss": -0.0011076399756063892, "dist_entropy": 0.7060575366020203, "actor_grad_norm": 0.0736636370420456, "critic_grad_norm": 0.21093855798244476, "ratio": 0.9998146891593933, "entropy": 0.7060575366020203, "incre_win_rate": 0.875, "step": 1813}
{"time": 1767160227.7532578, "phase": "train", "update": 1814, "total_env_steps": 5804800, "episode_reward": 0.25053393840789795, "value_loss": 0.00874972827732563, "policy_loss": -0.002465993200163652, "dist_entropy": 0.7229104161262512, "actor_grad_norm": 0.11396422237157822, "critic_grad_norm": 0.1068994402885437, "ratio": 0.9995306134223938, "entropy": 0.7229104161262512, "incre_win_rate": 0.8809523809523809, "step": 1814}
{"time": 1767160232.008291, "phase": "train", "update": 1815, "total_env_steps": 5808000, "episode_reward": 0.25545579195022583, "value_loss": 0.008260911889374256, "policy_loss": -0.001176498515246749, "dist_entropy": 0.7184352040290832, "actor_grad_norm": 0.0981956198811531, "critic_grad_norm": 0.11772334575653076, "ratio": 0.9998857378959656, "entropy": 0.7184352040290832, "incre_win_rate": 0.8571428571428571, "step": 1815}
{"time": 1767160236.2917402, "phase": "train", "update": 1816, "total_env_steps": 5811200, "episode_reward": 0.264515221118927, "value_loss": 0.007070210669189692, "policy_loss": -0.0012314888543876635, "dist_entropy": 0.7272701263427734, "actor_grad_norm": 0.0794040858745575, "critic_grad_norm": 0.20592539012432098, "ratio": 0.9999074935913086, "entropy": 0.7272701263427734, "incre_win_rate": 0.9555555555555556, "step": 1816}
{"time": 1767160240.6617544, "phase": "train", "update": 1817, "total_env_steps": 5814400, "episode_reward": 0.26435691118240356, "value_loss": 0.006598495692014694, "policy_loss": -0.0015680894657315037, "dist_entropy": 0.6931975841522217, "actor_grad_norm": 0.09963672608137131, "critic_grad_norm": 0.13306231796741486, "ratio": 0.9998970031738281, "entropy": 0.6931975841522217, "incre_win_rate": 0.9069767441860465, "step": 1817}
{"time": 1767160245.0011303, "phase": "train", "update": 1818, "total_env_steps": 5817600, "episode_reward": 0.2561837434768677, "value_loss": 0.007668505143374205, "policy_loss": -0.0016566807118788772, "dist_entropy": 0.7031481862068176, "actor_grad_norm": 0.12591277062892914, "critic_grad_norm": 0.13778464496135712, "ratio": 0.9996134042739868, "entropy": 0.7031481862068176, "incre_win_rate": 0.8536585365853658, "step": 1818}
{"time": 1767160249.330968, "phase": "train", "update": 1819, "total_env_steps": 5820800, "episode_reward": 0.2698836028575897, "value_loss": 0.006276908423751592, "policy_loss": -0.0013137838819410775, "dist_entropy": 0.7082360029220581, "actor_grad_norm": 0.0887509286403656, "critic_grad_norm": 0.14052216708660126, "ratio": 0.9997920393943787, "entropy": 0.7082360029220581, "incre_win_rate": 0.9111111111111111, "step": 1819}
{"time": 1767160253.6568317, "phase": "train", "update": 1820, "total_env_steps": 5824000, "episode_reward": 0.2617368698120117, "value_loss": 0.00972247738391161, "policy_loss": -0.0010882153988603705, "dist_entropy": 0.6990392684936524, "actor_grad_norm": 0.09580820053815842, "critic_grad_norm": 0.14081703126430511, "ratio": 0.99932861328125, "entropy": 0.6990392684936524, "incre_win_rate": 0.8809523809523809, "step": 1820}
{"time": 1767160257.9522128, "phase": "train", "update": 1821, "total_env_steps": 5827200, "episode_reward": 0.26571863889694214, "value_loss": 0.005518647097051144, "policy_loss": -0.0014047414560053539, "dist_entropy": 0.6957872152328491, "actor_grad_norm": 0.08578398823738098, "critic_grad_norm": 0.15337643027305603, "ratio": 1.0000008344650269, "entropy": 0.6957872152328491, "incre_win_rate": 0.9318181818181818, "step": 1821}
{"time": 1767160268.321798, "phase": "eval", "update": 1821, "total_env_steps": 5827200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.408526490066226, "step": 1821}
{"time": 1767160272.6176863, "phase": "train", "update": 1822, "total_env_steps": 5830400, "episode_reward": 0.25900766253471375, "value_loss": 0.0078001442365348336, "policy_loss": -0.001315832502638159, "dist_entropy": 0.7163346409797668, "actor_grad_norm": 0.08298324048519135, "critic_grad_norm": 0.16812488436698914, "ratio": 0.9997712969779968, "entropy": 0.7163346409797668, "incre_win_rate": 0.8837209302325582, "step": 1822}
{"time": 1767160276.947707, "phase": "train", "update": 1823, "total_env_steps": 5833600, "episode_reward": 0.2588565945625305, "value_loss": 0.0070689859800040725, "policy_loss": -0.0012019272537566294, "dist_entropy": 0.7024129986763, "actor_grad_norm": 0.09677733480930328, "critic_grad_norm": 0.08720036596059799, "ratio": 0.999894917011261, "entropy": 0.7024129986763, "incre_win_rate": 0.8809523809523809, "step": 1823}
{"time": 1767160281.281077, "phase": "train", "update": 1824, "total_env_steps": 5836800, "episode_reward": 0.26180413365364075, "value_loss": 0.009662598930299282, "policy_loss": -0.0011882132522643475, "dist_entropy": 0.7072410106658935, "actor_grad_norm": 0.08351681381464005, "critic_grad_norm": 0.19274644553661346, "ratio": 0.9998371005058289, "entropy": 0.7072410106658935, "incre_win_rate": 0.8809523809523809, "step": 1824}
{"time": 1767160285.61279, "phase": "train", "update": 1825, "total_env_steps": 5840000, "episode_reward": 0.26461923122406006, "value_loss": 0.007658764813095331, "policy_loss": -0.001075673627238416, "dist_entropy": 0.698813533782959, "actor_grad_norm": 0.074490025639534, "critic_grad_norm": 0.11343596130609512, "ratio": 0.9997491240501404, "entropy": 0.698813533782959, "incre_win_rate": 0.9333333333333333, "step": 1825}
{"time": 1767160289.8953345, "phase": "train", "update": 1826, "total_env_steps": 5843200, "episode_reward": 0.2712422311306, "value_loss": 0.007622292544692755, "policy_loss": -0.0013136257775258286, "dist_entropy": 0.718760859966278, "actor_grad_norm": 0.10084207355976105, "critic_grad_norm": 0.13956229388713837, "ratio": 0.9998510479927063, "entropy": 0.718760859966278, "incre_win_rate": 1.0, "step": 1826}
{"time": 1767160294.2317164, "phase": "train", "update": 1827, "total_env_steps": 5846400, "episode_reward": 0.26504915952682495, "value_loss": 0.008975042775273324, "policy_loss": -0.0014744626073995627, "dist_entropy": 0.6804940819740295, "actor_grad_norm": 0.09486191719770432, "critic_grad_norm": 0.11311667412519455, "ratio": 0.9997662901878357, "entropy": 0.6804940819740295, "incre_win_rate": 0.8695652173913043, "step": 1827}
{"time": 1767160298.5549734, "phase": "train", "update": 1828, "total_env_steps": 5849600, "episode_reward": 0.26161012053489685, "value_loss": 0.009535093791782856, "policy_loss": -0.0013299759614696428, "dist_entropy": 0.67446848154068, "actor_grad_norm": 0.11037137359380722, "critic_grad_norm": 0.08622881025075912, "ratio": 1.0002422332763672, "entropy": 0.67446848154068, "incre_win_rate": 0.9069767441860465, "step": 1828}
{"time": 1767160302.8732946, "phase": "train", "update": 1829, "total_env_steps": 5852800, "episode_reward": 0.26809394359588623, "value_loss": 0.00401938334107399, "policy_loss": -0.0013620277630213451, "dist_entropy": 0.6841706156730651, "actor_grad_norm": 0.10349434614181519, "critic_grad_norm": 0.10255493223667145, "ratio": 0.9996593594551086, "entropy": 0.6841706156730651, "incre_win_rate": 0.926829268292683, "step": 1829}
{"time": 1767160307.1684866, "phase": "train", "update": 1830, "total_env_steps": 5856000, "episode_reward": 0.2497071623802185, "value_loss": 0.018729394301772118, "policy_loss": -0.0012976059023920073, "dist_entropy": 0.6497235774993897, "actor_grad_norm": 0.09588860720396042, "critic_grad_norm": 0.3461502194404602, "ratio": 0.999690055847168, "entropy": 0.6497235774993897, "incre_win_rate": 0.8636363636363636, "step": 1830}
{"time": 1767160311.5373127, "phase": "train", "update": 1831, "total_env_steps": 5859200, "episode_reward": 0.26850271224975586, "value_loss": 0.008341325633227824, "policy_loss": -0.0012019641481032296, "dist_entropy": 0.6561048746109008, "actor_grad_norm": 0.08972927927970886, "critic_grad_norm": 0.18391136825084686, "ratio": 1.0001674890518188, "entropy": 0.6561048746109008, "incre_win_rate": 0.9318181818181818, "step": 1831}
{"time": 1767160315.864839, "phase": "train", "update": 1832, "total_env_steps": 5862400, "episode_reward": 0.27143314480781555, "value_loss": 0.007289947010576725, "policy_loss": -0.0009489884371788549, "dist_entropy": 0.6579157114028931, "actor_grad_norm": 0.0895729660987854, "critic_grad_norm": 0.1499280482530594, "ratio": 1.0001003742218018, "entropy": 0.6579157114028931, "incre_win_rate": 0.9545454545454546, "step": 1832}
{"time": 1767160320.2190468, "phase": "train", "update": 1833, "total_env_steps": 5865600, "episode_reward": 0.2749808430671692, "value_loss": 0.0038334787357598545, "policy_loss": -0.0009994150998636543, "dist_entropy": 0.6534118056297302, "actor_grad_norm": 0.07390596717596054, "critic_grad_norm": 0.05703594908118248, "ratio": 1.000200629234314, "entropy": 0.6534118056297302, "incre_win_rate": 0.9767441860465116, "step": 1833}
{"time": 1767160324.5399346, "phase": "train", "update": 1834, "total_env_steps": 5868800, "episode_reward": 0.2721026539802551, "value_loss": 0.003577452339231968, "policy_loss": -0.0010088412794152291, "dist_entropy": 0.6575161457061768, "actor_grad_norm": 0.08648962527513504, "critic_grad_norm": 0.0713471844792366, "ratio": 1.0000213384628296, "entropy": 0.6575161457061768, "incre_win_rate": 0.9565217391304348, "step": 1834}
{"time": 1767160328.8278744, "phase": "train", "update": 1835, "total_env_steps": 5872000, "episode_reward": 0.27277785539627075, "value_loss": 0.0027256872039288283, "policy_loss": -0.001057359167545613, "dist_entropy": 0.6710012316703796, "actor_grad_norm": 0.08571233600378036, "critic_grad_norm": 0.02564328722655773, "ratio": 0.9998400807380676, "entropy": 0.6710012316703796, "incre_win_rate": 0.9767441860465116, "step": 1835}
{"time": 1767160333.1017158, "phase": "train", "update": 1836, "total_env_steps": 5875200, "episode_reward": 0.27504244446754456, "value_loss": 0.0038341427687555553, "policy_loss": -0.0012247569913420796, "dist_entropy": 0.6758989691734314, "actor_grad_norm": 0.08755308389663696, "critic_grad_norm": 0.02748333476483822, "ratio": 0.9999412894248962, "entropy": 0.6758989691734314, "incre_win_rate": 0.9534883720930233, "step": 1836}
{"time": 1767160337.3670483, "phase": "train", "update": 1837, "total_env_steps": 5878400, "episode_reward": 0.26667529344558716, "value_loss": 0.006463376060128212, "policy_loss": -0.0013737950220857442, "dist_entropy": 0.6872206926345825, "actor_grad_norm": 0.08582577854394913, "critic_grad_norm": 0.09029700607061386, "ratio": 0.9998621344566345, "entropy": 0.6872206926345825, "incre_win_rate": 0.8695652173913043, "step": 1837}
{"time": 1767160341.6635106, "phase": "train", "update": 1838, "total_env_steps": 5881600, "episode_reward": 0.2585720419883728, "value_loss": 0.0068278716877102855, "policy_loss": -0.0011990364359380835, "dist_entropy": 0.6855174899101257, "actor_grad_norm": 0.07858506590127945, "critic_grad_norm": 0.1326567530632019, "ratio": 1.0003684759140015, "entropy": 0.6855174899101257, "incre_win_rate": 0.9069767441860465, "step": 1838}
{"time": 1767160345.931797, "phase": "train", "update": 1839, "total_env_steps": 5884800, "episode_reward": 0.2734183669090271, "value_loss": 0.004816598072648048, "policy_loss": -0.0010443557161281091, "dist_entropy": 0.6936773180961608, "actor_grad_norm": 0.09522245824337006, "critic_grad_norm": 0.04305046796798706, "ratio": 0.9998329281806946, "entropy": 0.6936773180961608, "incre_win_rate": 0.9534883720930233, "step": 1839}
{"time": 1767160350.2016208, "phase": "train", "update": 1840, "total_env_steps": 5888000, "episode_reward": 0.25022971630096436, "value_loss": 0.00536083048209548, "policy_loss": -0.0013798979899728892, "dist_entropy": 0.6806951642036438, "actor_grad_norm": 0.11383116245269775, "critic_grad_norm": 0.04296727105975151, "ratio": 0.9998458027839661, "entropy": 0.6806951642036438, "incre_win_rate": 0.8571428571428571, "step": 1840}
{"time": 1767160354.451229, "phase": "train", "update": 1841, "total_env_steps": 5891200, "episode_reward": 0.2679470181465149, "value_loss": 0.004763858672231436, "policy_loss": -0.0010607723067636242, "dist_entropy": 0.7080734252929688, "actor_grad_norm": 0.09765606373548508, "critic_grad_norm": 0.10708526521921158, "ratio": 1.0000662803649902, "entropy": 0.7080734252929688, "incre_win_rate": 0.9523809523809523, "step": 1841}
{"time": 1767160364.210593, "phase": "eval", "update": 1841, "total_env_steps": 5891200, "eval_win_rate": 1.0, "eval_episode_reward": 20.0, "step": 1841}
{"time": 1767160368.522162, "phase": "train", "update": 1842, "total_env_steps": 5894400, "episode_reward": 0.2778269648551941, "value_loss": 0.002471436932682991, "policy_loss": -0.001039005309998231, "dist_entropy": 0.6923441529273987, "actor_grad_norm": 0.09887470304965973, "critic_grad_norm": 0.09930726140737534, "ratio": 1.00017249584198, "entropy": 0.6923441529273987, "incre_win_rate": 1.0, "step": 1842}
{"time": 1767160372.7497149, "phase": "train", "update": 1843, "total_env_steps": 5897600, "episode_reward": 0.2557952105998993, "value_loss": 0.020277445390820503, "policy_loss": -0.001188468724814129, "dist_entropy": 0.6980605840682983, "actor_grad_norm": 0.14209088683128357, "critic_grad_norm": 0.31058958172798157, "ratio": 0.9999808669090271, "entropy": 0.6980605840682983, "incre_win_rate": 0.9, "step": 1843}
{"time": 1767160377.0810218, "phase": "train", "update": 1844, "total_env_steps": 5900800, "episode_reward": 0.27589869499206543, "value_loss": 0.00479739373549819, "policy_loss": -0.001247948767814222, "dist_entropy": 0.689602255821228, "actor_grad_norm": 0.09475522488355637, "critic_grad_norm": 0.24749933183193207, "ratio": 0.9997760653495789, "entropy": 0.689602255821228, "incre_win_rate": 0.9574468085106383, "step": 1844}
{"time": 1767160381.448336, "phase": "train", "update": 1845, "total_env_steps": 5904000, "episode_reward": 0.2638229429721832, "value_loss": 0.007836824003607034, "policy_loss": -0.0011830827351012375, "dist_entropy": 0.6859976410865783, "actor_grad_norm": 0.09852957725524902, "critic_grad_norm": 0.27741530537605286, "ratio": 1.0000874996185303, "entropy": 0.6859976410865783, "incre_win_rate": 0.8444444444444444, "step": 1845}
{"time": 1767160385.7957177, "phase": "train", "update": 1846, "total_env_steps": 5907200, "episode_reward": 0.273103266954422, "value_loss": 0.0044862429145723585, "policy_loss": -0.0012682507628326788, "dist_entropy": 0.7053749203681946, "actor_grad_norm": 0.09167446941137314, "critic_grad_norm": 0.1963772177696228, "ratio": 0.9996364712715149, "entropy": 0.7053749203681946, "incre_win_rate": 0.975609756097561, "step": 1846}
{"time": 1767160390.1259904, "phase": "train", "update": 1847, "total_env_steps": 5910400, "episode_reward": 0.2684105932712555, "value_loss": 0.006474591698497534, "policy_loss": -0.0010972143397417256, "dist_entropy": 0.690936541557312, "actor_grad_norm": 0.11352671682834625, "critic_grad_norm": 0.16363799571990967, "ratio": 0.9999238848686218, "entropy": 0.690936541557312, "incre_win_rate": 0.9333333333333333, "step": 1847}
{"time": 1767160394.44101, "phase": "train", "update": 1848, "total_env_steps": 5913600, "episode_reward": 0.26754137873649597, "value_loss": 0.0054608494974672794, "policy_loss": -0.0014400553420159667, "dist_entropy": 0.6843335628509521, "actor_grad_norm": 0.10578824579715729, "critic_grad_norm": 0.1718246191740036, "ratio": 0.9999130368232727, "entropy": 0.6843335628509521, "incre_win_rate": 0.9534883720930233, "step": 1848}
{"time": 1767160398.7929316, "phase": "train", "update": 1849, "total_env_steps": 5916800, "episode_reward": 0.2758278250694275, "value_loss": 0.003768744086846709, "policy_loss": -0.0010460878890725667, "dist_entropy": 0.6689781546592712, "actor_grad_norm": 0.10277552902698517, "critic_grad_norm": 0.1426522582769394, "ratio": 0.9995040893554688, "entropy": 0.6689781546592712, "incre_win_rate": 1.0, "step": 1849}
{"time": 1767160403.1315415, "phase": "train", "update": 1850, "total_env_steps": 5920000, "episode_reward": 0.26795947551727295, "value_loss": 0.007685690745711326, "policy_loss": -0.0013715417979810241, "dist_entropy": 0.6627185106277466, "actor_grad_norm": 0.1036757156252861, "critic_grad_norm": 0.12731556594371796, "ratio": 1.0002254247665405, "entropy": 0.6627185106277466, "incre_win_rate": 0.9069767441860465, "step": 1850}
{"time": 1767160407.4476147, "phase": "train", "update": 1851, "total_env_steps": 5923200, "episode_reward": 0.27469372749328613, "value_loss": 0.005208954866975546, "policy_loss": -0.001047297626548982, "dist_entropy": 0.6555783987045288, "actor_grad_norm": 0.08085521310567856, "critic_grad_norm": 0.07355502992868423, "ratio": 0.9998825192451477, "entropy": 0.6555783987045288, "incre_win_rate": 0.9318181818181818, "step": 1851}
{"time": 1767160411.7896552, "phase": "train", "update": 1852, "total_env_steps": 5926400, "episode_reward": 0.2632036507129669, "value_loss": 0.007019210420548916, "policy_loss": -0.001353519757617505, "dist_entropy": 0.6843809604644775, "actor_grad_norm": 0.09176267683506012, "critic_grad_norm": 0.13717423379421234, "ratio": 0.9996410608291626, "entropy": 0.6843809604644775, "incre_win_rate": 0.9534883720930233, "step": 1852}
{"time": 1767160416.1391766, "phase": "train", "update": 1853, "total_env_steps": 5929600, "episode_reward": 0.2702385187149048, "value_loss": 0.006729467771947384, "policy_loss": -0.001051361542543461, "dist_entropy": 0.6714847445487976, "actor_grad_norm": 0.08801203966140747, "critic_grad_norm": 0.0550336129963398, "ratio": 0.9998952746391296, "entropy": 0.6714847445487976, "incre_win_rate": 0.8723404255319149, "step": 1853}
{"time": 1767160420.549957, "phase": "train", "update": 1854, "total_env_steps": 5932800, "episode_reward": 0.2742922306060791, "value_loss": 0.0056877356953918936, "policy_loss": -0.0007589933474470457, "dist_entropy": 0.67633056640625, "actor_grad_norm": 0.08262898772954941, "critic_grad_norm": 0.07565093040466309, "ratio": 1.0000414848327637, "entropy": 0.67633056640625, "incre_win_rate": 0.9069767441860465, "step": 1854}
{"time": 1767160424.8759506, "phase": "train", "update": 1855, "total_env_steps": 5936000, "episode_reward": 0.2679801285266876, "value_loss": 0.005694809090346098, "policy_loss": -0.0016053353216264553, "dist_entropy": 0.6510772347450257, "actor_grad_norm": 0.12356646358966827, "critic_grad_norm": 0.03427143394947052, "ratio": 0.999774158000946, "entropy": 0.6510772347450257, "incre_win_rate": 0.9069767441860465, "step": 1855}
{"time": 1767160429.197611, "phase": "train", "update": 1856, "total_env_steps": 5939200, "episode_reward": 0.2731870710849762, "value_loss": 0.00754598081111908, "policy_loss": -0.00099759410512803, "dist_entropy": 0.6512121558189392, "actor_grad_norm": 0.09500332176685333, "critic_grad_norm": 0.05029015615582466, "ratio": 1.0000025033950806, "entropy": 0.6512121558189392, "incre_win_rate": 0.9574468085106383, "step": 1856}
{"time": 1767160433.4967792, "phase": "train", "update": 1857, "total_env_steps": 5942400, "episode_reward": 0.270024836063385, "value_loss": 0.004196850955486298, "policy_loss": -0.0009091883818662438, "dist_entropy": 0.6550082206726074, "actor_grad_norm": 0.09196344763040543, "critic_grad_norm": 0.04156702384352684, "ratio": 0.999921441078186, "entropy": 0.6550082206726074, "incre_win_rate": 0.9534883720930233, "step": 1857}
{"time": 1767160437.8291945, "phase": "train", "update": 1858, "total_env_steps": 5945600, "episode_reward": 0.2748654782772064, "value_loss": 0.0032499847933650018, "policy_loss": -0.0010549301631144203, "dist_entropy": 0.6704078078269958, "actor_grad_norm": 0.08242382854223251, "critic_grad_norm": 0.03640997037291527, "ratio": 0.9998761415481567, "entropy": 0.6704078078269958, "incre_win_rate": 0.9767441860465116, "step": 1858}
{"time": 1767160442.1436987, "phase": "train", "update": 1859, "total_env_steps": 5948800, "episode_reward": 0.2825124263763428, "value_loss": 0.0023918839171528814, "policy_loss": -0.0011322955207781148, "dist_entropy": 0.6842693090438843, "actor_grad_norm": 0.09077050536870956, "critic_grad_norm": 0.035462912172079086, "ratio": 0.999954879283905, "entropy": 0.6842693090438843, "incre_win_rate": 0.9782608695652174, "step": 1859}
{"time": 1767160446.5320823, "phase": "train", "update": 1860, "total_env_steps": 5952000, "episode_reward": 0.27371224761009216, "value_loss": 0.005215737596154213, "policy_loss": -0.0015485689594640917, "dist_entropy": 0.6519371032714844, "actor_grad_norm": 0.09838800877332687, "critic_grad_norm": 0.0450516901910305, "ratio": 0.9998142123222351, "entropy": 0.6519371032714844, "incre_win_rate": 0.9333333333333333, "step": 1860}
{"time": 1767160450.8739843, "phase": "train", "update": 1861, "total_env_steps": 5955200, "episode_reward": 0.27061620354652405, "value_loss": 0.005999100767076016, "policy_loss": -0.0014508815837901423, "dist_entropy": 0.6488065838813781, "actor_grad_norm": 0.09493663161993027, "critic_grad_norm": 0.08694985508918762, "ratio": 0.9994186758995056, "entropy": 0.6488065838813781, "incre_win_rate": 0.9090909090909091, "step": 1861}
{"time": 1767160460.8935158, "phase": "eval", "update": 1861, "total_env_steps": 5955200, "eval_win_rate": 1.0, "eval_episode_reward": 20.0, "step": 1861}
{"time": 1767160465.2256246, "phase": "train", "update": 1862, "total_env_steps": 5958400, "episode_reward": 0.2752690613269806, "value_loss": 0.004379171784967184, "policy_loss": -0.0010330106656198268, "dist_entropy": 0.648406708240509, "actor_grad_norm": 0.06788092106580734, "critic_grad_norm": 0.08425084501504898, "ratio": 0.999674916267395, "entropy": 0.648406708240509, "incre_win_rate": 0.9545454545454546, "step": 1862}
{"time": 1767160469.556739, "phase": "train", "update": 1863, "total_env_steps": 5961600, "episode_reward": 0.27366310358047485, "value_loss": 0.003826532745733857, "policy_loss": -0.0010584177622568803, "dist_entropy": 0.6347605347633362, "actor_grad_norm": 0.10166027396917343, "critic_grad_norm": 0.059176236391067505, "ratio": 1.0003108978271484, "entropy": 0.6347605347633362, "incre_win_rate": 0.9777777777777777, "step": 1863}
{"time": 1767160473.9176474, "phase": "train", "update": 1864, "total_env_steps": 5964800, "episode_reward": 0.2773064970970154, "value_loss": 0.0027636494487524033, "policy_loss": -0.001475815729597585, "dist_entropy": 0.6411471605300904, "actor_grad_norm": 0.08802720159292221, "critic_grad_norm": 0.04977339878678322, "ratio": 0.9999394416809082, "entropy": 0.6411471605300904, "incre_win_rate": 0.9777777777777777, "step": 1864}
{"time": 1767160478.2962728, "phase": "train", "update": 1865, "total_env_steps": 5968000, "episode_reward": 0.2739279866218567, "value_loss": 0.0034483308903872968, "policy_loss": -0.00180099672758125, "dist_entropy": 0.622457230091095, "actor_grad_norm": 0.10495346039533615, "critic_grad_norm": 0.05139060690999031, "ratio": 0.9999095797538757, "entropy": 0.622457230091095, "incre_win_rate": 0.9318181818181818, "step": 1865}
{"time": 1767160482.5855124, "phase": "train", "update": 1866, "total_env_steps": 5971200, "episode_reward": 0.27719369530677795, "value_loss": 0.004609726555645466, "policy_loss": -0.0008635463166086765, "dist_entropy": 0.5968293309211731, "actor_grad_norm": 0.11451270431280136, "critic_grad_norm": 0.06453128904104233, "ratio": 0.9993677139282227, "entropy": 0.5968293309211731, "incre_win_rate": 0.9534883720930233, "step": 1866}
{"time": 1767160486.9207911, "phase": "train", "update": 1867, "total_env_steps": 5974400, "episode_reward": 0.27117136120796204, "value_loss": 0.005605505872517824, "policy_loss": -0.0008906310122100081, "dist_entropy": 0.5943752765655518, "actor_grad_norm": 0.09321755170822144, "critic_grad_norm": 0.05299953371286392, "ratio": 0.9996665120124817, "entropy": 0.5943752765655518, "incre_win_rate": 0.9333333333333333, "step": 1867}
{"time": 1767160491.2836025, "phase": "train", "update": 1868, "total_env_steps": 5977600, "episode_reward": 0.28235721588134766, "value_loss": 0.00410683061927557, "policy_loss": -0.0010284881107509136, "dist_entropy": 0.6209394335746765, "actor_grad_norm": 0.0741860419511795, "critic_grad_norm": 0.11107379198074341, "ratio": 0.9999285936355591, "entropy": 0.6209394335746765, "incre_win_rate": 0.9787234042553191, "step": 1868}
{"time": 1767160495.6488981, "phase": "train", "update": 1869, "total_env_steps": 5980800, "episode_reward": 0.2789776623249054, "value_loss": 0.003254260867834091, "policy_loss": -0.0010938062216157896, "dist_entropy": 0.6155223488807678, "actor_grad_norm": 0.07759033888578415, "critic_grad_norm": 0.06315742433071136, "ratio": 1.000020980834961, "entropy": 0.6155223488807678, "incre_win_rate": 0.9555555555555556, "step": 1869}
{"time": 1767160500.0356908, "phase": "train", "update": 1870, "total_env_steps": 5984000, "episode_reward": 0.28466057777404785, "value_loss": 0.0029987921938300134, "policy_loss": -0.0009191319537062981, "dist_entropy": 0.6140841484069824, "actor_grad_norm": 0.08727652579545975, "critic_grad_norm": 0.06292533129453659, "ratio": 0.9998205304145813, "entropy": 0.6140841484069824, "incre_win_rate": 0.9574468085106383, "step": 1870}
{"time": 1767160504.4007065, "phase": "train", "update": 1871, "total_env_steps": 5987200, "episode_reward": 0.27207574248313904, "value_loss": 0.004423026647418738, "policy_loss": -0.0010738627307464554, "dist_entropy": 0.6244885563850403, "actor_grad_norm": 0.08216141164302826, "critic_grad_norm": 0.12946166098117828, "ratio": 0.9999181628227234, "entropy": 0.6244885563850403, "incre_win_rate": 0.9285714285714286, "step": 1871}
{"time": 1767160508.7613826, "phase": "train", "update": 1872, "total_env_steps": 5990400, "episode_reward": 0.28419286012649536, "value_loss": 0.0032501186244189737, "policy_loss": -0.0014109794097478812, "dist_entropy": 0.6206835031509399, "actor_grad_norm": 0.09805592149496078, "critic_grad_norm": 0.0753440111875534, "ratio": 1.0001459121704102, "entropy": 0.6206835031509399, "incre_win_rate": 1.0, "step": 1872}
{"time": 1767160513.0678267, "phase": "train", "update": 1873, "total_env_steps": 5993600, "episode_reward": 0.26976820826530457, "value_loss": 0.003436926379799843, "policy_loss": -0.0013217448489740492, "dist_entropy": 0.6071008324623108, "actor_grad_norm": 0.08949824422597885, "critic_grad_norm": 0.09064265340566635, "ratio": 0.9998483657836914, "entropy": 0.6071008324623108, "incre_win_rate": 0.9767441860465116, "step": 1873}
{"time": 1767160517.4200106, "phase": "train", "update": 1874, "total_env_steps": 5996800, "episode_reward": 0.2769950330257416, "value_loss": 0.0046218869276344774, "policy_loss": -0.0011058866770817133, "dist_entropy": 0.6118276357650757, "actor_grad_norm": 0.08985032886266708, "critic_grad_norm": 0.09994102269411087, "ratio": 0.9999709129333496, "entropy": 0.6118276357650757, "incre_win_rate": 0.9565217391304348, "step": 1874}
{"time": 1767160521.787106, "phase": "train", "update": 1875, "total_env_steps": 6000000, "episode_reward": 0.2764818072319031, "value_loss": 0.0034617881290614607, "policy_loss": -0.0007942250730792466, "dist_entropy": 0.6083035349845887, "actor_grad_norm": 0.09012426435947418, "critic_grad_norm": 0.04965014010667801, "ratio": 1.0001524686813354, "entropy": 0.6083035349845887, "incre_win_rate": 0.9555555555555556, "step": 1875}
{"time": 1767160526.0982351, "phase": "train", "update": 1876, "total_env_steps": 6003200, "episode_reward": 0.27829211950302124, "value_loss": 0.0047031654044985775, "policy_loss": -0.0011136375665742547, "dist_entropy": 0.6025885820388794, "actor_grad_norm": 0.09045785665512085, "critic_grad_norm": 0.08041795343160629, "ratio": 0.9995222091674805, "entropy": 0.6025885820388794, "incre_win_rate": 0.9333333333333333, "step": 1876}
{"time": 1767160530.3873584, "phase": "train", "update": 1877, "total_env_steps": 6006400, "episode_reward": 0.26899421215057373, "value_loss": 0.0052468210458755495, "policy_loss": -0.0010710334649466802, "dist_entropy": 0.6231531262397766, "actor_grad_norm": 0.08318109065294266, "critic_grad_norm": 0.15070782601833344, "ratio": 0.9996500015258789, "entropy": 0.6231531262397766, "incre_win_rate": 0.9285714285714286, "step": 1877}
{"time": 1767160534.6893647, "phase": "train", "update": 1878, "total_env_steps": 6009600, "episode_reward": 0.283203661441803, "value_loss": 0.003479656111449003, "policy_loss": -0.0012567239278496345, "dist_entropy": 0.6189388871192932, "actor_grad_norm": 0.09583931416273117, "critic_grad_norm": 0.07326024770736694, "ratio": 0.999969482421875, "entropy": 0.6189388871192932, "incre_win_rate": 0.9787234042553191, "step": 1878}
{"time": 1767160539.0478077, "phase": "train", "update": 1879, "total_env_steps": 6012800, "episode_reward": 0.27779024839401245, "value_loss": 0.0053192063234746454, "policy_loss": -0.0011072252359211276, "dist_entropy": 0.6204119324684143, "actor_grad_norm": 0.07770184427499771, "critic_grad_norm": 0.06617219001054764, "ratio": 0.9998356699943542, "entropy": 0.6204119324684143, "incre_win_rate": 0.9111111111111111, "step": 1879}
{"time": 1767160543.4046361, "phase": "train", "update": 1880, "total_env_steps": 6016000, "episode_reward": 0.2784644067287445, "value_loss": 0.0030345349106937645, "policy_loss": -0.00106228698387838, "dist_entropy": 0.6186586260795593, "actor_grad_norm": 0.07626262307167053, "critic_grad_norm": 0.10079311579465866, "ratio": 0.9999653100967407, "entropy": 0.6186586260795593, "incre_win_rate": 0.9772727272727273, "step": 1880}
{"time": 1767160547.7910972, "phase": "train", "update": 1881, "total_env_steps": 6019200, "episode_reward": 0.28219372034072876, "value_loss": 0.002559245377779007, "policy_loss": -0.0011786630895663564, "dist_entropy": 0.6017815589904785, "actor_grad_norm": 0.08911576122045517, "critic_grad_norm": 0.07751458138227463, "ratio": 1.0001853704452515, "entropy": 0.6017815589904785, "incre_win_rate": 0.9787234042553191, "step": 1881}
{"time": 1767160557.4108045, "phase": "eval", "update": 1881, "total_env_steps": 6019200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.857201986754966, "step": 1881}
{"time": 1767160561.7794933, "phase": "train", "update": 1882, "total_env_steps": 6022400, "episode_reward": 0.28509053587913513, "value_loss": 0.00238059745170176, "policy_loss": -0.001306806986395692, "dist_entropy": 0.6397937536239624, "actor_grad_norm": 0.09028617292642593, "critic_grad_norm": 0.07690930366516113, "ratio": 1.0000073909759521, "entropy": 0.6397937536239624, "incre_win_rate": 0.9782608695652174, "step": 1882}
{"time": 1767160566.0775282, "phase": "train", "update": 1883, "total_env_steps": 6025600, "episode_reward": 0.27687087655067444, "value_loss": 0.004380757175385952, "policy_loss": -0.001230368217157718, "dist_entropy": 0.6190475583076477, "actor_grad_norm": 0.097327321767807, "critic_grad_norm": 0.08732756227254868, "ratio": 1.0000008344650269, "entropy": 0.6190475583076477, "incre_win_rate": 0.9772727272727273, "step": 1883}
{"time": 1767160570.4100308, "phase": "train", "update": 1884, "total_env_steps": 6028800, "episode_reward": 0.2785854637622833, "value_loss": 0.0047540836036205295, "policy_loss": -0.0009893487008270085, "dist_entropy": 0.634795892238617, "actor_grad_norm": 0.08525033295154572, "critic_grad_norm": 0.0577935054898262, "ratio": 0.999975323677063, "entropy": 0.634795892238617, "incre_win_rate": 0.9111111111111111, "step": 1884}
{"time": 1767160574.7353885, "phase": "train", "update": 1885, "total_env_steps": 6032000, "episode_reward": 0.27774059772491455, "value_loss": 0.002694965433329344, "policy_loss": -0.0012973468972631963, "dist_entropy": 0.6643253087997436, "actor_grad_norm": 0.0983709916472435, "critic_grad_norm": 0.06443276256322861, "ratio": 0.9998509287834167, "entropy": 0.6643253087997436, "incre_win_rate": 0.9545454545454546, "step": 1885}
{"time": 1767160579.081574, "phase": "train", "update": 1886, "total_env_steps": 6035200, "episode_reward": 0.268154501914978, "value_loss": 0.00603769039735198, "policy_loss": -0.0011098555077373006, "dist_entropy": 0.6729155659675599, "actor_grad_norm": 0.07960905879735947, "critic_grad_norm": 0.05092860385775566, "ratio": 0.9998666048049927, "entropy": 0.6729155659675599, "incre_win_rate": 0.8913043478260869, "step": 1886}
{"time": 1767160583.42349, "phase": "train", "update": 1887, "total_env_steps": 6038400, "episode_reward": 0.2807947099208832, "value_loss": 0.0065435154363512995, "policy_loss": -0.0008535430916978726, "dist_entropy": 0.6616871595382691, "actor_grad_norm": 0.07852480560541153, "critic_grad_norm": 0.07543624937534332, "ratio": 0.9999911189079285, "entropy": 0.6616871595382691, "incre_win_rate": 0.9767441860465116, "step": 1887}
{"time": 1767160587.7630317, "phase": "train", "update": 1888, "total_env_steps": 6041600, "episode_reward": 0.2742466628551483, "value_loss": 0.0040106880478560925, "policy_loss": -0.001389058891627215, "dist_entropy": 0.6374323248863221, "actor_grad_norm": 0.09868498146533966, "critic_grad_norm": 0.05843029543757439, "ratio": 0.9996787905693054, "entropy": 0.6374323248863221, "incre_win_rate": 0.9361702127659575, "step": 1888}
{"time": 1767160592.1000962, "phase": "train", "update": 1889, "total_env_steps": 6044800, "episode_reward": 0.28362274169921875, "value_loss": 0.003183127427473664, "policy_loss": -0.0013576959414216105, "dist_entropy": 0.6508502244949341, "actor_grad_norm": 0.08932890743017197, "critic_grad_norm": 0.02674282155930996, "ratio": 1.0000733137130737, "entropy": 0.6508502244949341, "incre_win_rate": 0.9782608695652174, "step": 1889}
{"time": 1767160596.4589207, "phase": "train", "update": 1890, "total_env_steps": 6048000, "episode_reward": 0.2812210023403168, "value_loss": 0.003841617237776518, "policy_loss": -0.0012083162760859524, "dist_entropy": 0.612217378616333, "actor_grad_norm": 0.07850667089223862, "critic_grad_norm": 0.03350687399506569, "ratio": 0.9997345209121704, "entropy": 0.612217378616333, "incre_win_rate": 0.9555555555555556, "step": 1890}
{"time": 1767160600.8198526, "phase": "train", "update": 1891, "total_env_steps": 6051200, "episode_reward": 0.28543874621391296, "value_loss": 0.0017712886445224285, "policy_loss": -0.0009687667918107934, "dist_entropy": 0.6211268901824951, "actor_grad_norm": 0.0766165480017662, "critic_grad_norm": 0.04531140252947807, "ratio": 1.000121831893921, "entropy": 0.6211268901824951, "incre_win_rate": 1.0, "step": 1891}
{"time": 1767160605.137821, "phase": "train", "update": 1892, "total_env_steps": 6054400, "episode_reward": 0.28604722023010254, "value_loss": 0.002356503903865814, "policy_loss": -0.001134810588939672, "dist_entropy": 0.6160545825958252, "actor_grad_norm": 0.09016958624124527, "critic_grad_norm": 0.05092139169573784, "ratio": 1.0001204013824463, "entropy": 0.6160545825958252, "incre_win_rate": 0.9787234042553191, "step": 1892}
{"time": 1767160609.411398, "phase": "train", "update": 1893, "total_env_steps": 6057600, "episode_reward": 0.2869122624397278, "value_loss": 0.0033673130441457034, "policy_loss": -0.0012170406650096055, "dist_entropy": 0.6046428561210633, "actor_grad_norm": 0.08138733357191086, "critic_grad_norm": 0.03922559693455696, "ratio": 0.9998180270195007, "entropy": 0.6046428561210633, "incre_win_rate": 0.9545454545454546, "step": 1893}
{"time": 1767160613.7244499, "phase": "train", "update": 1894, "total_env_steps": 6060800, "episode_reward": 0.2834550738334656, "value_loss": 0.0022228341549634933, "policy_loss": -0.0009107663935807864, "dist_entropy": 0.6239771246910095, "actor_grad_norm": 0.10071023553609848, "critic_grad_norm": 0.03487370163202286, "ratio": 1.0000431537628174, "entropy": 0.6239771246910095, "incre_win_rate": 0.9782608695652174, "step": 1894}
{"time": 1767160618.0160973, "phase": "train", "update": 1895, "total_env_steps": 6064000, "episode_reward": 0.26883846521377563, "value_loss": 0.006798404641449452, "policy_loss": -0.0010335350350942462, "dist_entropy": 0.6256698846817017, "actor_grad_norm": 0.08330413699150085, "critic_grad_norm": 0.17683438956737518, "ratio": 0.9999052882194519, "entropy": 0.6256698846817017, "incre_win_rate": 0.9111111111111111, "step": 1895}
{"time": 1767160622.4070625, "phase": "train", "update": 1896, "total_env_steps": 6067200, "episode_reward": 0.27802929282188416, "value_loss": 0.00467948354780674, "policy_loss": -0.0009492752273004612, "dist_entropy": 0.6108404755592346, "actor_grad_norm": 0.08194144070148468, "critic_grad_norm": 0.07395381480455399, "ratio": 1.0001106262207031, "entropy": 0.6108404755592346, "incre_win_rate": 0.9318181818181818, "step": 1896}
{"time": 1767160626.7732716, "phase": "train", "update": 1897, "total_env_steps": 6070400, "episode_reward": 0.2785264849662781, "value_loss": 0.005488157458603382, "policy_loss": -0.0011893057387553085, "dist_entropy": 0.6158848881721497, "actor_grad_norm": 0.08633989095687866, "critic_grad_norm": 0.0581510029733181, "ratio": 1.0000650882720947, "entropy": 0.6158848881721497, "incre_win_rate": 0.9111111111111111, "step": 1897}
{"time": 1767160631.1335664, "phase": "train", "update": 1898, "total_env_steps": 6073600, "episode_reward": 0.27562087774276733, "value_loss": 0.003623939724639058, "policy_loss": -0.0009839212123774032, "dist_entropy": 0.6038785457611084, "actor_grad_norm": 0.07637884467840195, "critic_grad_norm": 0.049290549010038376, "ratio": 0.9999753832817078, "entropy": 0.6038785457611084, "incre_win_rate": 0.9361702127659575, "step": 1898}
{"time": 1767160635.4162505, "phase": "train", "update": 1899, "total_env_steps": 6076800, "episode_reward": 0.28846853971481323, "value_loss": 0.0023573951330035925, "policy_loss": -0.0010973537589842764, "dist_entropy": 0.603708028793335, "actor_grad_norm": 0.08106661587953568, "critic_grad_norm": 0.06150984764099121, "ratio": 0.999928891658783, "entropy": 0.603708028793335, "incre_win_rate": 0.9777777777777777, "step": 1899}
{"time": 1767160639.7239, "phase": "train", "update": 1900, "total_env_steps": 6080000, "episode_reward": 0.2751355469226837, "value_loss": 0.005840752553194761, "policy_loss": -0.0010840912759834786, "dist_entropy": 0.5764864802360534, "actor_grad_norm": 0.07462947815656662, "critic_grad_norm": 0.041224103420972824, "ratio": 0.9997547268867493, "entropy": 0.5764864802360534, "incre_win_rate": 0.9555555555555556, "step": 1900}
{"time": 1767160644.032127, "phase": "train", "update": 1901, "total_env_steps": 6083200, "episode_reward": 0.2866598069667816, "value_loss": 0.003632610896602273, "policy_loss": -0.0009229073448594249, "dist_entropy": 0.5876838445663453, "actor_grad_norm": 0.10017251968383789, "critic_grad_norm": 0.052807360887527466, "ratio": 0.9998568892478943, "entropy": 0.5876838445663453, "incre_win_rate": 0.9361702127659575, "step": 1901}
{"time": 1767160653.8070228, "phase": "eval", "update": 1901, "total_env_steps": 6083200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.721750827814567, "step": 1901}
{"time": 1767160658.0909789, "phase": "train", "update": 1902, "total_env_steps": 6086400, "episode_reward": 0.2819494903087616, "value_loss": 0.0021711083129048346, "policy_loss": -0.001155506880056123, "dist_entropy": 0.5874362587928772, "actor_grad_norm": 0.08471594750881195, "critic_grad_norm": 0.037239402532577515, "ratio": 0.9997832179069519, "entropy": 0.5874362587928772, "incre_win_rate": 1.0, "step": 1902}
{"time": 1767160662.401302, "phase": "train", "update": 1903, "total_env_steps": 6089600, "episode_reward": 0.28011590242385864, "value_loss": 0.004034762922674418, "policy_loss": -0.0012957144646769335, "dist_entropy": 0.5902033686637879, "actor_grad_norm": 0.09118862450122833, "critic_grad_norm": 0.03192289173603058, "ratio": 0.9998787045478821, "entropy": 0.5902033686637879, "incre_win_rate": 0.9333333333333333, "step": 1903}
{"time": 1767160666.7296696, "phase": "train", "update": 1904, "total_env_steps": 6092800, "episode_reward": 0.2776665985584259, "value_loss": 0.005045156367123127, "policy_loss": -0.0012948358605342492, "dist_entropy": 0.5873597145080567, "actor_grad_norm": 0.085064597427845, "critic_grad_norm": 0.043933700770139694, "ratio": 0.9999047517776489, "entropy": 0.5873597145080567, "incre_win_rate": 0.9767441860465116, "step": 1904}
{"time": 1767160671.0510206, "phase": "train", "update": 1905, "total_env_steps": 6096000, "episode_reward": 0.2718791365623474, "value_loss": 0.004995868541300297, "policy_loss": -0.0010518054144107226, "dist_entropy": 0.5639019727706909, "actor_grad_norm": 0.0954955667257309, "critic_grad_norm": 0.0677463710308075, "ratio": 0.9997512698173523, "entropy": 0.5639019727706909, "incre_win_rate": 0.9111111111111111, "step": 1905}
{"time": 1767160675.3875353, "phase": "train", "update": 1906, "total_env_steps": 6099200, "episode_reward": 0.2820488214492798, "value_loss": 0.003565760049968958, "policy_loss": -0.001342373524496132, "dist_entropy": 0.59724440574646, "actor_grad_norm": 0.0958988144993782, "critic_grad_norm": 0.043819837272167206, "ratio": 1.0001710653305054, "entropy": 0.59724440574646, "incre_win_rate": 0.9565217391304348, "step": 1906}
{"time": 1767160679.7251863, "phase": "train", "update": 1907, "total_env_steps": 6102400, "episode_reward": 0.2805463373661041, "value_loss": 0.003261444112285972, "policy_loss": -0.0009481828105037948, "dist_entropy": 0.5906232476234436, "actor_grad_norm": 0.08245387673377991, "critic_grad_norm": 0.0408383347094059, "ratio": 1.0001142024993896, "entropy": 0.5906232476234436, "incre_win_rate": 0.9782608695652174, "step": 1907}
{"time": 1767160684.104125, "phase": "train", "update": 1908, "total_env_steps": 6105600, "episode_reward": 0.2767958343029022, "value_loss": 0.004935305938124657, "policy_loss": -0.0013259093853584148, "dist_entropy": 0.5901548743247986, "actor_grad_norm": 0.08460214734077454, "critic_grad_norm": 0.04374205693602562, "ratio": 1.0000982284545898, "entropy": 0.5901548743247986, "incre_win_rate": 0.9318181818181818, "step": 1908}
{"time": 1767160688.470672, "phase": "train", "update": 1909, "total_env_steps": 6108800, "episode_reward": 0.28469786047935486, "value_loss": 0.005631731171160936, "policy_loss": -0.0011303771120022787, "dist_entropy": 0.5964343667030334, "actor_grad_norm": 0.08313290029764175, "critic_grad_norm": 0.03675011917948723, "ratio": 1.0001636743545532, "entropy": 0.5964343667030334, "incre_win_rate": 0.9361702127659575, "step": 1909}
{"time": 1767160692.8319163, "phase": "train", "update": 1910, "total_env_steps": 6112000, "episode_reward": 0.27169546484947205, "value_loss": 0.007675251364707947, "policy_loss": -0.0010492374640790557, "dist_entropy": 0.5931927680969238, "actor_grad_norm": 0.08125831931829453, "critic_grad_norm": 0.1229112520813942, "ratio": 0.9998394250869751, "entropy": 0.5931927680969238, "incre_win_rate": 0.8222222222222222, "step": 1910}
{"time": 1767160697.1686034, "phase": "train", "update": 1911, "total_env_steps": 6115200, "episode_reward": 0.27904391288757324, "value_loss": 0.008008457254618406, "policy_loss": -0.0011048027206598476, "dist_entropy": 0.5875298500061035, "actor_grad_norm": 0.08365900814533234, "critic_grad_norm": 0.09971003979444504, "ratio": 1.0002025365829468, "entropy": 0.5875298500061035, "incre_win_rate": 0.9545454545454546, "step": 1911}
{"time": 1767160701.5251782, "phase": "train", "update": 1912, "total_env_steps": 6118400, "episode_reward": 0.27709436416625977, "value_loss": 0.004431118350476026, "policy_loss": -0.0010049504593141023, "dist_entropy": 0.602668559551239, "actor_grad_norm": 0.07219891995191574, "critic_grad_norm": 0.09458338469266891, "ratio": 0.9996517300605774, "entropy": 0.602668559551239, "incre_win_rate": 0.9347826086956522, "step": 1912}
{"time": 1767160705.8825977, "phase": "train", "update": 1913, "total_env_steps": 6121600, "episode_reward": 0.28470921516418457, "value_loss": 0.0034438876900821924, "policy_loss": -0.001499264591890892, "dist_entropy": 0.6196734309196472, "actor_grad_norm": 0.10057615488767624, "critic_grad_norm": 0.1065838560461998, "ratio": 1.000455379486084, "entropy": 0.6196734309196472, "incre_win_rate": 0.9787234042553191, "step": 1913}
{"time": 1767160710.2063284, "phase": "train", "update": 1914, "total_env_steps": 6124800, "episode_reward": 0.2740945816040039, "value_loss": 0.005574570037424564, "policy_loss": -0.001038904929901463, "dist_entropy": 0.6012304782867431, "actor_grad_norm": 0.08235859125852585, "critic_grad_norm": 0.07745849341154099, "ratio": 0.999655544757843, "entropy": 0.6012304782867431, "incre_win_rate": 0.9111111111111111, "step": 1914}
{"time": 1767160714.480042, "phase": "train", "update": 1915, "total_env_steps": 6128000, "episode_reward": 0.27728062868118286, "value_loss": 0.006051057018339634, "policy_loss": -0.0011025672867564396, "dist_entropy": 0.5921350121498108, "actor_grad_norm": 0.0753127783536911, "critic_grad_norm": 0.0603162907063961, "ratio": 0.9998774528503418, "entropy": 0.5921350121498108, "incre_win_rate": 0.9111111111111111, "step": 1915}
{"time": 1767160718.7937608, "phase": "train", "update": 1916, "total_env_steps": 6131200, "episode_reward": 0.27145126461982727, "value_loss": 0.008060546405613423, "policy_loss": -0.0012357632875819036, "dist_entropy": 0.6056505084037781, "actor_grad_norm": 0.07801070064306259, "critic_grad_norm": 0.03507597744464874, "ratio": 1.000003457069397, "entropy": 0.6056505084037781, "incre_win_rate": 0.8888888888888888, "step": 1916}
{"time": 1767160723.1266258, "phase": "train", "update": 1917, "total_env_steps": 6134400, "episode_reward": 0.26844266057014465, "value_loss": 0.005698786396533251, "policy_loss": -0.001238335194258866, "dist_entropy": 0.597791588306427, "actor_grad_norm": 0.0673908218741417, "critic_grad_norm": 0.05151456221938133, "ratio": 0.9999859929084778, "entropy": 0.597791588306427, "incre_win_rate": 0.8863636363636364, "step": 1917}
{"time": 1767160727.4639466, "phase": "train", "update": 1918, "total_env_steps": 6137600, "episode_reward": 0.2664569616317749, "value_loss": 0.006339791975915432, "policy_loss": -0.0011118060425496345, "dist_entropy": 0.6222543358802796, "actor_grad_norm": 0.08170222491025925, "critic_grad_norm": 0.06267206370830536, "ratio": 1.0000230073928833, "entropy": 0.6222543358802796, "incre_win_rate": 0.8863636363636364, "step": 1918}
{"time": 1767160731.8295872, "phase": "train", "update": 1919, "total_env_steps": 6140800, "episode_reward": 0.2769148349761963, "value_loss": 0.006109138112515211, "policy_loss": -0.0011074525570684557, "dist_entropy": 0.6332104206085205, "actor_grad_norm": 0.07727999240159988, "critic_grad_norm": 0.047884177416563034, "ratio": 1.000091314315796, "entropy": 0.6332104206085205, "incre_win_rate": 0.8863636363636364, "step": 1919}
{"time": 1767160736.2062986, "phase": "train", "update": 1920, "total_env_steps": 6144000, "episode_reward": 0.28197434544563293, "value_loss": 0.005462842993438244, "policy_loss": -0.0012032360770341199, "dist_entropy": 0.6450487375259399, "actor_grad_norm": 0.0948108434677124, "critic_grad_norm": 0.07400761544704437, "ratio": 0.9997499585151672, "entropy": 0.6450487375259399, "incre_win_rate": 0.9361702127659575, "step": 1920}
{"time": 1767160740.5580401, "phase": "train", "update": 1921, "total_env_steps": 6147200, "episode_reward": 0.2722682058811188, "value_loss": 0.005963043216615916, "policy_loss": -0.00142870925483507, "dist_entropy": 0.6306350827217102, "actor_grad_norm": 0.1131696105003357, "critic_grad_norm": 0.044524896889925, "ratio": 0.9999605417251587, "entropy": 0.6306350827217102, "incre_win_rate": 0.8863636363636364, "step": 1921}
{"time": 1767160750.2272975, "phase": "eval", "update": 1921, "total_env_steps": 6147200, "eval_win_rate": 1.0, "eval_episode_reward": 20.005380794701985, "step": 1921}
{"time": 1767160754.526719, "phase": "train", "update": 1922, "total_env_steps": 6150400, "episode_reward": 0.26700127124786377, "value_loss": 0.00905767884105444, "policy_loss": -0.001327728071329659, "dist_entropy": 0.611498486995697, "actor_grad_norm": 0.08436421304941177, "critic_grad_norm": 0.15966473519802094, "ratio": 0.999951958656311, "entropy": 0.611498486995697, "incre_win_rate": 0.851063829787234, "step": 1922}
{"time": 1767160758.8723958, "phase": "train", "update": 1923, "total_env_steps": 6153600, "episode_reward": 0.2781912088394165, "value_loss": 0.0065789553336799145, "policy_loss": -0.0015578545528626363, "dist_entropy": 0.640520966053009, "actor_grad_norm": 0.10438533127307892, "critic_grad_norm": 0.13092544674873352, "ratio": 0.9998539090156555, "entropy": 0.640520966053009, "incre_win_rate": 0.8863636363636364, "step": 1923}
{"time": 1767160763.2133775, "phase": "train", "update": 1924, "total_env_steps": 6156800, "episode_reward": 0.26218855381011963, "value_loss": 0.007926896587014199, "policy_loss": -0.0011740543883234978, "dist_entropy": 0.6250065803527832, "actor_grad_norm": 0.08715694397687912, "critic_grad_norm": 0.14924536645412445, "ratio": 0.9999530911445618, "entropy": 0.6250065803527832, "incre_win_rate": 0.8837209302325582, "step": 1924}
{"time": 1767160767.5344648, "phase": "train", "update": 1925, "total_env_steps": 6160000, "episode_reward": 0.2681679427623749, "value_loss": 0.009421762637794017, "policy_loss": -0.0012988359065090548, "dist_entropy": 0.633575689792633, "actor_grad_norm": 0.08871565014123917, "critic_grad_norm": 0.13254402577877045, "ratio": 0.9998536109924316, "entropy": 0.633575689792633, "incre_win_rate": 0.8695652173913043, "step": 1925}
{"time": 1767160771.84228, "phase": "train", "update": 1926, "total_env_steps": 6163200, "episode_reward": 0.2736620604991913, "value_loss": 0.006513230130076408, "policy_loss": -0.0011600139011775923, "dist_entropy": 0.6542832136154175, "actor_grad_norm": 0.09263424575328827, "critic_grad_norm": 0.09614186733961105, "ratio": 1.0002132654190063, "entropy": 0.6542832136154175, "incre_win_rate": 0.9111111111111111, "step": 1926}
{"time": 1767160776.1511545, "phase": "train", "update": 1927, "total_env_steps": 6166400, "episode_reward": 0.2860182225704193, "value_loss": 0.004092683782801032, "policy_loss": -0.0010093713601147414, "dist_entropy": 0.6440041184425354, "actor_grad_norm": 0.08876567333936691, "critic_grad_norm": 0.16258504986763, "ratio": 0.9998816847801208, "entropy": 0.6440041184425354, "incre_win_rate": 0.9767441860465116, "step": 1927}
{"time": 1767160780.4361145, "phase": "train", "update": 1928, "total_env_steps": 6169600, "episode_reward": 0.26877278089523315, "value_loss": 0.005992603302001953, "policy_loss": -0.0012611166393440953, "dist_entropy": 0.6699812054634094, "actor_grad_norm": 0.09240392595529556, "critic_grad_norm": 0.1022758036851883, "ratio": 0.9999831318855286, "entropy": 0.6699812054634094, "incre_win_rate": 0.8723404255319149, "step": 1928}
{"time": 1767160784.7910569, "phase": "train", "update": 1929, "total_env_steps": 6172800, "episode_reward": 0.2706788182258606, "value_loss": 0.007031931076198816, "policy_loss": -0.0012364905599778098, "dist_entropy": 0.6612793684005738, "actor_grad_norm": 0.08610749244689941, "critic_grad_norm": 0.13169187307357788, "ratio": 0.9999047517776489, "entropy": 0.6612793684005738, "incre_win_rate": 0.8888888888888888, "step": 1929}
{"time": 1767160789.1374931, "phase": "train", "update": 1930, "total_env_steps": 6176000, "episode_reward": 0.2795902192592621, "value_loss": 0.006568454671651125, "policy_loss": -0.0016009482861036872, "dist_entropy": 0.6309293746948242, "actor_grad_norm": 0.08626177906990051, "critic_grad_norm": 0.11731643974781036, "ratio": 0.999553382396698, "entropy": 0.6309293746948242, "incre_win_rate": 0.9772727272727273, "step": 1930}
{"time": 1767160793.4493375, "phase": "train", "update": 1931, "total_env_steps": 6179200, "episode_reward": 0.26406872272491455, "value_loss": 0.008266283944249154, "policy_loss": -0.0011733764384899814, "dist_entropy": 0.6271353483200073, "actor_grad_norm": 0.07838817685842514, "critic_grad_norm": 0.0791114941239357, "ratio": 0.9996841549873352, "entropy": 0.6271353483200073, "incre_win_rate": 0.9534883720930233, "step": 1931}
{"time": 1767160797.799826, "phase": "train", "update": 1932, "total_env_steps": 6182400, "episode_reward": 0.2764895558357239, "value_loss": 0.006759133189916611, "policy_loss": -0.0011769497076613788, "dist_entropy": 0.6414136767387391, "actor_grad_norm": 0.07596981525421143, "critic_grad_norm": 0.22661752998828888, "ratio": 1.000251293182373, "entropy": 0.6414136767387391, "incre_win_rate": 0.9130434782608695, "step": 1932}
{"time": 1767160802.113696, "phase": "train", "update": 1933, "total_env_steps": 6185600, "episode_reward": 0.2785373628139496, "value_loss": 0.006663815956562758, "policy_loss": -0.00162348050547223, "dist_entropy": 0.6260852813720703, "actor_grad_norm": 0.09406381845474243, "critic_grad_norm": 0.12131452560424805, "ratio": 1.0002087354660034, "entropy": 0.6260852813720703, "incre_win_rate": 0.9318181818181818, "step": 1933}
{"time": 1767160806.3939893, "phase": "train", "update": 1934, "total_env_steps": 6188800, "episode_reward": 0.26667067408561707, "value_loss": 0.007464300468564033, "policy_loss": -0.0011429827470706756, "dist_entropy": 0.6147273540496826, "actor_grad_norm": 0.08944405615329742, "critic_grad_norm": 0.08872050791978836, "ratio": 1.0000866651535034, "entropy": 0.6147273540496826, "incre_win_rate": 0.9333333333333333, "step": 1934}
{"time": 1767160810.6443298, "phase": "train", "update": 1935, "total_env_steps": 6192000, "episode_reward": 0.25991979241371155, "value_loss": 0.008944745548069477, "policy_loss": -0.0012330590380628336, "dist_entropy": 0.6139248728752136, "actor_grad_norm": 0.08373130857944489, "critic_grad_norm": 0.1921406239271164, "ratio": 0.9998942613601685, "entropy": 0.6139248728752136, "incre_win_rate": 0.8409090909090909, "step": 1935}
{"time": 1767160815.0159533, "phase": "train", "update": 1936, "total_env_steps": 6195200, "episode_reward": 0.27172186970710754, "value_loss": 0.007315686624497175, "policy_loss": -0.0015118091757566176, "dist_entropy": 0.6269836783409118, "actor_grad_norm": 0.0881032943725586, "critic_grad_norm": 0.10729321092367172, "ratio": 0.9999070167541504, "entropy": 0.6269836783409118, "incre_win_rate": 0.8636363636363636, "step": 1936}
{"time": 1767160819.3543823, "phase": "train", "update": 1937, "total_env_steps": 6198400, "episode_reward": 0.2846357822418213, "value_loss": 0.004088671924546361, "policy_loss": -0.001034144620898836, "dist_entropy": 0.6480983138084412, "actor_grad_norm": 0.09048359841108322, "critic_grad_norm": 0.0983504131436348, "ratio": 1.000235915184021, "entropy": 0.6480983138084412, "incre_win_rate": 1.0, "step": 1937}
{"time": 1767160823.7256362, "phase": "train", "update": 1938, "total_env_steps": 6201600, "episode_reward": 0.27897199988365173, "value_loss": 0.005817937757819891, "policy_loss": -0.0015634031491217116, "dist_entropy": 0.6456561207771301, "actor_grad_norm": 0.09745972603559494, "critic_grad_norm": 0.08176233619451523, "ratio": 0.9997318387031555, "entropy": 0.6456561207771301, "incre_win_rate": 0.9361702127659575, "step": 1938}
{"time": 1767160828.0506616, "phase": "train", "update": 1939, "total_env_steps": 6204800, "episode_reward": 0.27783113718032837, "value_loss": 0.004323878325521946, "policy_loss": -0.0014025720532457875, "dist_entropy": 0.6604315400123596, "actor_grad_norm": 0.0881945788860321, "critic_grad_norm": 0.0772821232676506, "ratio": 0.999377429485321, "entropy": 0.6604315400123596, "incre_win_rate": 0.9302325581395349, "step": 1939}
{"time": 1767160832.3600996, "phase": "train", "update": 1940, "total_env_steps": 6208000, "episode_reward": 0.2693946659564972, "value_loss": 0.009201482497155666, "policy_loss": -0.0015366243697524594, "dist_entropy": 0.6520262002944947, "actor_grad_norm": 0.09623764455318451, "critic_grad_norm": 0.07014717906713486, "ratio": 1.0001931190490723, "entropy": 0.6520262002944947, "incre_win_rate": 0.8444444444444444, "step": 1940}
{"time": 1767160836.7020962, "phase": "train", "update": 1941, "total_env_steps": 6211200, "episode_reward": 0.27455297112464905, "value_loss": 0.005604453384876251, "policy_loss": -0.0010009459138863974, "dist_entropy": 0.657461416721344, "actor_grad_norm": 0.07961643487215042, "critic_grad_norm": 0.0692703053355217, "ratio": 0.9999634623527527, "entropy": 0.657461416721344, "incre_win_rate": 0.9534883720930233, "step": 1941}
{"time": 1767160846.6614048, "phase": "eval", "update": 1941, "total_env_steps": 6211200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.82119205298013, "step": 1941}
{"time": 1767160850.9931345, "phase": "train", "update": 1942, "total_env_steps": 6214400, "episode_reward": 0.2812541425228119, "value_loss": 0.0034511743113398554, "policy_loss": -0.0010432977484597927, "dist_entropy": 0.6542803764343261, "actor_grad_norm": 0.10041149705648422, "critic_grad_norm": 0.09042885154485703, "ratio": 0.9998741149902344, "entropy": 0.6542803764343261, "incre_win_rate": 0.9583333333333334, "step": 1942}
{"time": 1767160855.290257, "phase": "train", "update": 1943, "total_env_steps": 6217600, "episode_reward": 0.277966171503067, "value_loss": 0.0044497006572782995, "policy_loss": -0.0009736520190514852, "dist_entropy": 0.6848598003387452, "actor_grad_norm": 0.09954798221588135, "critic_grad_norm": 0.0605471208691597, "ratio": 0.999983012676239, "entropy": 0.6848598003387452, "incre_win_rate": 0.9534883720930233, "step": 1943}
{"time": 1767160859.5402706, "phase": "train", "update": 1944, "total_env_steps": 6220800, "episode_reward": 0.260099858045578, "value_loss": 0.007573031540960074, "policy_loss": -0.0008015088123595859, "dist_entropy": 0.6769530415534973, "actor_grad_norm": 0.07803688943386078, "critic_grad_norm": 0.09154169261455536, "ratio": 0.9997531771659851, "entropy": 0.6769530415534973, "incre_win_rate": 0.7777777777777778, "step": 1944}
{"time": 1767160863.8503594, "phase": "train", "update": 1945, "total_env_steps": 6224000, "episode_reward": 0.2737375795841217, "value_loss": 0.005234215501695871, "policy_loss": -0.001420174238355898, "dist_entropy": 0.6643692970275878, "actor_grad_norm": 0.08659479767084122, "critic_grad_norm": 0.050597649067640305, "ratio": 1.0002473592758179, "entropy": 0.6643692970275878, "incre_win_rate": 0.9090909090909091, "step": 1945}
{"time": 1767160868.1509895, "phase": "train", "update": 1946, "total_env_steps": 6227200, "episode_reward": 0.26962336897850037, "value_loss": 0.0090151596814394, "policy_loss": -0.0011343302688914037, "dist_entropy": 0.6634387254714966, "actor_grad_norm": 0.08894836157560349, "critic_grad_norm": 0.10496070235967636, "ratio": 0.999699056148529, "entropy": 0.6634387254714966, "incre_win_rate": 0.8666666666666667, "step": 1946}
{"time": 1767160872.5002964, "phase": "train", "update": 1947, "total_env_steps": 6230400, "episode_reward": 0.2758919596672058, "value_loss": 0.00685534868389368, "policy_loss": -0.0010913734006699372, "dist_entropy": 0.6781345486640931, "actor_grad_norm": 0.1138266921043396, "critic_grad_norm": 0.11399605125188828, "ratio": 1.000218391418457, "entropy": 0.6781345486640931, "incre_win_rate": 0.9130434782608695, "step": 1947}
{"time": 1767160876.8187156, "phase": "train", "update": 1948, "total_env_steps": 6233600, "episode_reward": 0.2830825746059418, "value_loss": 0.002497462602332234, "policy_loss": -0.0013437768441562526, "dist_entropy": 0.6968684792518616, "actor_grad_norm": 0.08087042719125748, "critic_grad_norm": 0.10125049203634262, "ratio": 0.9999290704727173, "entropy": 0.6968684792518616, "incre_win_rate": 0.9767441860465116, "step": 1948}
{"time": 1767160881.0904343, "phase": "train", "update": 1949, "total_env_steps": 6236800, "episode_reward": 0.27036839723587036, "value_loss": 0.0062136220745742324, "policy_loss": -0.0013105083977563935, "dist_entropy": 0.683999526500702, "actor_grad_norm": 0.07424565404653549, "critic_grad_norm": 0.12251978367567062, "ratio": 0.9999523162841797, "entropy": 0.683999526500702, "incre_win_rate": 0.9347826086956522, "step": 1949}
{"time": 1767160885.3987536, "phase": "train", "update": 1950, "total_env_steps": 6240000, "episode_reward": 0.2717730700969696, "value_loss": 0.004938671924173832, "policy_loss": -0.0015028544782264674, "dist_entropy": 0.6816829562187194, "actor_grad_norm": 0.07817687094211578, "critic_grad_norm": 0.05499814823269844, "ratio": 0.9996981620788574, "entropy": 0.6816829562187194, "incre_win_rate": 0.9111111111111111, "step": 1950}
{"time": 1767160889.7373624, "phase": "train", "update": 1951, "total_env_steps": 6243200, "episode_reward": 0.26957783102989197, "value_loss": 0.005405669286847115, "policy_loss": -0.0014625289131721785, "dist_entropy": 0.6657143592834472, "actor_grad_norm": 0.07290085405111313, "critic_grad_norm": 0.047577984631061554, "ratio": 0.9998268485069275, "entropy": 0.6657143592834472, "incre_win_rate": 0.8863636363636364, "step": 1951}
{"time": 1767160894.0731733, "phase": "train", "update": 1952, "total_env_steps": 6246400, "episode_reward": 0.2679134011268616, "value_loss": 0.006150382850319147, "policy_loss": -0.0010515472792906877, "dist_entropy": 0.6655735015869141, "actor_grad_norm": 0.07763729989528656, "critic_grad_norm": 0.047387685626745224, "ratio": 0.9999144673347473, "entropy": 0.6655735015869141, "incre_win_rate": 0.8409090909090909, "step": 1952}
{"time": 1767160898.427795, "phase": "train", "update": 1953, "total_env_steps": 6249600, "episode_reward": 0.275154709815979, "value_loss": 0.005281826481223106, "policy_loss": -0.0012150302425322224, "dist_entropy": 0.682280445098877, "actor_grad_norm": 0.09701599925756454, "critic_grad_norm": 0.07531891018152237, "ratio": 1.0002609491348267, "entropy": 0.682280445098877, "incre_win_rate": 0.9130434782608695, "step": 1953}
{"time": 1767160902.7411807, "phase": "train", "update": 1954, "total_env_steps": 6252800, "episode_reward": 0.2721880078315735, "value_loss": 0.004931530170142651, "policy_loss": -0.0010643631544292377, "dist_entropy": 0.682761836051941, "actor_grad_norm": 0.09173788130283356, "critic_grad_norm": 0.09517163038253784, "ratio": 0.9998578429222107, "entropy": 0.682761836051941, "incre_win_rate": 0.9545454545454546, "step": 1954}
{"time": 1767160906.998152, "phase": "train", "update": 1955, "total_env_steps": 6256000, "episode_reward": 0.2776945233345032, "value_loss": 0.0057481957599520685, "policy_loss": -0.001344289074461358, "dist_entropy": 0.676785123348236, "actor_grad_norm": 0.10700578987598419, "critic_grad_norm": 0.06037883087992668, "ratio": 1.000081181526184, "entropy": 0.676785123348236, "incre_win_rate": 0.9333333333333333, "step": 1955}
{"time": 1767160911.2669485, "phase": "train", "update": 1956, "total_env_steps": 6259200, "episode_reward": 0.26811671257019043, "value_loss": 0.0074574404396116735, "policy_loss": -0.0011925671141471029, "dist_entropy": 0.6630377650260926, "actor_grad_norm": 0.08167245984077454, "critic_grad_norm": 0.09302746504545212, "ratio": 0.9998534321784973, "entropy": 0.6630377650260926, "incre_win_rate": 0.9090909090909091, "step": 1956}
{"time": 1767160915.5747821, "phase": "train", "update": 1957, "total_env_steps": 6262400, "episode_reward": 0.2622092366218567, "value_loss": 0.006074689514935017, "policy_loss": -0.0011479203310297615, "dist_entropy": 0.6596662998199463, "actor_grad_norm": 0.0761888399720192, "critic_grad_norm": 0.07096876204013824, "ratio": 1.0001367330551147, "entropy": 0.6596662998199463, "incre_win_rate": 0.8636363636363636, "step": 1957}
{"time": 1767160919.895219, "phase": "train", "update": 1958, "total_env_steps": 6265600, "episode_reward": 0.2711144685745239, "value_loss": 0.006310743000358343, "policy_loss": -0.001287455730484055, "dist_entropy": 0.6858656644821167, "actor_grad_norm": 0.0739704892039299, "critic_grad_norm": 0.13198322057724, "ratio": 0.9997507929801941, "entropy": 0.6858656644821167, "incre_win_rate": 0.8666666666666667, "step": 1958}
{"time": 1767160924.2792222, "phase": "train", "update": 1959, "total_env_steps": 6268800, "episode_reward": 0.27507397532463074, "value_loss": 0.008407258242368699, "policy_loss": -0.0014428618816836546, "dist_entropy": 0.6837049961090088, "actor_grad_norm": 0.07849003374576569, "critic_grad_norm": 0.12379804998636246, "ratio": 0.9997685551643372, "entropy": 0.6837049961090088, "incre_win_rate": 0.9302325581395349, "step": 1959}
{"time": 1767160962.7417378, "phase": "train", "update": 1960, "total_env_steps": 6272000, "episode_reward": 0.27404800057411194, "value_loss": 0.07946691662073135, "policy_loss": -0.0009079410445632874, "dist_entropy": 0.7009397745132446, "actor_grad_norm": 0.06918004155158997, "critic_grad_norm": 0.34540998935699463, "ratio": 1.0000594854354858, "entropy": 0.7009397745132446, "incre_win_rate": 1.0, "step": 1960}
{"time": 1767160967.0115695, "phase": "train", "update": 1961, "total_env_steps": 6275200, "episode_reward": 0.2684892416000366, "value_loss": 0.007061727717518807, "policy_loss": -0.0010474970927682125, "dist_entropy": 0.6771993637084961, "actor_grad_norm": 0.07245772331953049, "critic_grad_norm": 0.16838984191417694, "ratio": 0.9999135136604309, "entropy": 0.6771993637084961, "incre_win_rate": 0.8604651162790697, "step": 1961}
{"time": 1767160976.9775708, "phase": "eval", "update": 1961, "total_env_steps": 6275200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.78280215231788, "step": 1961}
{"time": 1767160981.2433152, "phase": "train", "update": 1962, "total_env_steps": 6278400, "episode_reward": 0.2757755517959595, "value_loss": 0.004831096529960633, "policy_loss": -0.0010133107671276066, "dist_entropy": 0.68597811460495, "actor_grad_norm": 0.06703981757164001, "critic_grad_norm": 0.18353821337223053, "ratio": 1.0000494718551636, "entropy": 0.68597811460495, "incre_win_rate": 0.9347826086956522, "step": 1962}
{"time": 1767160985.5507858, "phase": "train", "update": 1963, "total_env_steps": 6281600, "episode_reward": 0.2748882472515106, "value_loss": 0.0034522196743637323, "policy_loss": -0.0016170868856088204, "dist_entropy": 0.704791522026062, "actor_grad_norm": 0.09286879748106003, "critic_grad_norm": 0.05758198723196983, "ratio": 1.0001388788223267, "entropy": 0.704791522026062, "incre_win_rate": 0.9333333333333333, "step": 1963}
{"time": 1767160989.798269, "phase": "train", "update": 1964, "total_env_steps": 6284800, "episode_reward": 0.27036839723587036, "value_loss": 0.006457831803709268, "policy_loss": -0.0013822708967410335, "dist_entropy": 0.6828367948532105, "actor_grad_norm": 0.08737186342477798, "critic_grad_norm": 0.11990614980459213, "ratio": 0.9997992515563965, "entropy": 0.6828367948532105, "incre_win_rate": 0.9318181818181818, "step": 1964}
{"time": 1767160994.037346, "phase": "train", "update": 1965, "total_env_steps": 6288000, "episode_reward": 0.2668822407722473, "value_loss": 0.006578101310878992, "policy_loss": -0.0015416391932429718, "dist_entropy": 0.716116189956665, "actor_grad_norm": 0.097039595246315, "critic_grad_norm": 0.14255864918231964, "ratio": 1.0002025365829468, "entropy": 0.716116189956665, "incre_win_rate": 0.9285714285714286, "step": 1965}
{"time": 1767160998.2585094, "phase": "train", "update": 1966, "total_env_steps": 6291200, "episode_reward": 0.26917633414268494, "value_loss": 0.0063456914387643336, "policy_loss": -0.001345313805515147, "dist_entropy": 0.6942954421043396, "actor_grad_norm": 0.08193386346101761, "critic_grad_norm": 0.07107935845851898, "ratio": 1.0002524852752686, "entropy": 0.6942954421043396, "incre_win_rate": 0.9090909090909091, "step": 1966}
{"time": 1767161002.561244, "phase": "train", "update": 1967, "total_env_steps": 6294400, "episode_reward": 0.27664369344711304, "value_loss": 0.00723067345097661, "policy_loss": -0.001115763289176641, "dist_entropy": 0.6769523978233337, "actor_grad_norm": 0.07293566316366196, "critic_grad_norm": 0.12522220611572266, "ratio": 0.9999818801879883, "entropy": 0.6769523978233337, "incre_win_rate": 0.9130434782608695, "step": 1967}
{"time": 1767161006.8407173, "phase": "train", "update": 1968, "total_env_steps": 6297600, "episode_reward": 0.27803394198417664, "value_loss": 0.004981969390064478, "policy_loss": -0.0012612760959449076, "dist_entropy": 0.6862241625785828, "actor_grad_norm": 0.08266431093215942, "critic_grad_norm": 0.09011942148208618, "ratio": 1.0001798868179321, "entropy": 0.6862241625785828, "incre_win_rate": 0.9347826086956522, "step": 1968}
{"time": 1767161011.1361005, "phase": "train", "update": 1969, "total_env_steps": 6300800, "episode_reward": 0.2805122137069702, "value_loss": 0.00429402943700552, "policy_loss": -0.0012506095239007919, "dist_entropy": 0.6808814406394958, "actor_grad_norm": 0.10184264183044434, "critic_grad_norm": 0.07020453363656998, "ratio": 1.0000966787338257, "entropy": 0.6808814406394958, "incre_win_rate": 0.9545454545454546, "step": 1969}
{"time": 1767161015.431041, "phase": "train", "update": 1970, "total_env_steps": 6304000, "episode_reward": 0.2741515040397644, "value_loss": 0.00571632981300354, "policy_loss": -0.001341808874214223, "dist_entropy": 0.6886194705963135, "actor_grad_norm": 0.08778514713048935, "critic_grad_norm": 0.1451273262500763, "ratio": 1.00019109249115, "entropy": 0.6886194705963135, "incre_win_rate": 0.9777777777777777, "step": 1970}
{"time": 1767161019.7076828, "phase": "train", "update": 1971, "total_env_steps": 6307200, "episode_reward": 0.26305878162384033, "value_loss": 0.004933394119143486, "policy_loss": -0.00104566133560553, "dist_entropy": 0.6796082258224487, "actor_grad_norm": 0.07990675419569016, "critic_grad_norm": 0.07011225819587708, "ratio": 1.0000183582305908, "entropy": 0.6796082258224487, "incre_win_rate": 0.8636363636363636, "step": 1971}
{"time": 1767161024.0303524, "phase": "train", "update": 1972, "total_env_steps": 6310400, "episode_reward": 0.27788496017456055, "value_loss": 0.00364050786010921, "policy_loss": -0.0009644886953864784, "dist_entropy": 0.7023625850677491, "actor_grad_norm": 0.08485441654920578, "critic_grad_norm": 0.0985707938671112, "ratio": 1.000209093093872, "entropy": 0.7023625850677491, "incre_win_rate": 0.9318181818181818, "step": 1972}
{"time": 1767161028.3408363, "phase": "train", "update": 1973, "total_env_steps": 6313600, "episode_reward": 0.28145694732666016, "value_loss": 0.0035038515459746124, "policy_loss": -0.0010093724038618746, "dist_entropy": 0.7089952945709228, "actor_grad_norm": 0.08796609938144684, "critic_grad_norm": 0.0963524729013443, "ratio": 0.9996041655540466, "entropy": 0.7089952945709228, "incre_win_rate": 1.0, "step": 1973}
{"time": 1767161032.5819213, "phase": "train", "update": 1974, "total_env_steps": 6316800, "episode_reward": 0.2825620770454407, "value_loss": 0.003248278982937336, "policy_loss": -0.0011250204692160536, "dist_entropy": 0.7199012756347656, "actor_grad_norm": 0.08480805903673172, "critic_grad_norm": 0.045973390340805054, "ratio": 0.999945342540741, "entropy": 0.7199012756347656, "incre_win_rate": 0.9574468085106383, "step": 1974}
{"time": 1767161036.8178332, "phase": "train", "update": 1975, "total_env_steps": 6320000, "episode_reward": 0.2678394317626953, "value_loss": 0.00447352509945631, "policy_loss": -0.0013133253172739501, "dist_entropy": 0.7120610117912293, "actor_grad_norm": 0.08235640823841095, "critic_grad_norm": 0.11713851988315582, "ratio": 1.0001572370529175, "entropy": 0.7120610117912293, "incre_win_rate": 0.9285714285714286, "step": 1975}
{"time": 1767161041.0874083, "phase": "train", "update": 1976, "total_env_steps": 6323200, "episode_reward": 0.2684566378593445, "value_loss": 0.0049822784028947355, "policy_loss": -0.0017981750593676793, "dist_entropy": 0.7280364871025086, "actor_grad_norm": 0.09530586004257202, "critic_grad_norm": 0.10284560173749924, "ratio": 1.0000355243682861, "entropy": 0.7280364871025086, "incre_win_rate": 0.9302325581395349, "step": 1976}
{"time": 1767161045.3771544, "phase": "train", "update": 1977, "total_env_steps": 6326400, "episode_reward": 0.26133689284324646, "value_loss": 0.005315674468874931, "policy_loss": -0.0014171183333710146, "dist_entropy": 0.7371275782585144, "actor_grad_norm": 0.094557024538517, "critic_grad_norm": 0.058895956724882126, "ratio": 1.0000238418579102, "entropy": 0.7371275782585144, "incre_win_rate": 0.8666666666666667, "step": 1977}
{"time": 1767161049.7091856, "phase": "train", "update": 1978, "total_env_steps": 6329600, "episode_reward": 0.2741059362888336, "value_loss": 0.004386633448302746, "policy_loss": -0.0012779136143031167, "dist_entropy": 0.7250723719596863, "actor_grad_norm": 0.08672229945659637, "critic_grad_norm": 0.10938489437103271, "ratio": 1.000014305114746, "entropy": 0.7250723719596863, "incre_win_rate": 0.9534883720930233, "step": 1978}
{"time": 1767161054.0124478, "phase": "train", "update": 1979, "total_env_steps": 6332800, "episode_reward": 0.2714434862136841, "value_loss": 0.0068417412228882315, "policy_loss": -0.0011440969247104248, "dist_entropy": 0.7140209674835205, "actor_grad_norm": 0.07779616862535477, "critic_grad_norm": 0.09956236183643341, "ratio": 0.9999114871025085, "entropy": 0.7140209674835205, "incre_win_rate": 0.9111111111111111, "step": 1979}
{"time": 1767161058.273675, "phase": "train", "update": 1980, "total_env_steps": 6336000, "episode_reward": 0.2618372142314911, "value_loss": 0.008093013521283865, "policy_loss": -0.0015036901309883888, "dist_entropy": 0.6813485741615295, "actor_grad_norm": 0.09217723459005356, "critic_grad_norm": 0.05917973071336746, "ratio": 0.999977707862854, "entropy": 0.6813485741615295, "incre_win_rate": 0.8409090909090909, "step": 1980}
{"time": 1767161062.5450935, "phase": "train", "update": 1981, "total_env_steps": 6339200, "episode_reward": 0.27112945914268494, "value_loss": 0.00871981494128704, "policy_loss": -0.0013395543173430724, "dist_entropy": 0.6951246619224548, "actor_grad_norm": 0.07945825904607773, "critic_grad_norm": 0.08310603350400925, "ratio": 0.9998658299446106, "entropy": 0.6951246619224548, "incre_win_rate": 0.8863636363636364, "step": 1981}
{"time": 1767161077.1392164, "phase": "eval", "update": 1981, "total_env_steps": 6339200, "eval_win_rate": 0.8125, "eval_episode_reward": 18.799254966887418, "step": 1981}
{"time": 1767161081.486845, "phase": "train", "update": 1982, "total_env_steps": 6342400, "episode_reward": 0.28095200657844543, "value_loss": 0.0068122980184853075, "policy_loss": -0.0008772706170525168, "dist_entropy": 0.6943315744400025, "actor_grad_norm": 0.08483569324016571, "critic_grad_norm": 0.10319345444440842, "ratio": 0.9998368620872498, "entropy": 0.6943315744400025, "incre_win_rate": 0.9148936170212766, "step": 1982}
{"time": 1767161085.8352227, "phase": "train", "update": 1983, "total_env_steps": 6345600, "episode_reward": 0.2750362157821655, "value_loss": 0.004820059891790152, "policy_loss": -0.0014861071520194003, "dist_entropy": 0.6936204075813294, "actor_grad_norm": 0.08281341195106506, "critic_grad_norm": 0.07657559961080551, "ratio": 0.9996950030326843, "entropy": 0.6936204075813294, "incre_win_rate": 0.9777777777777777, "step": 1983}
{"time": 1767161090.173021, "phase": "train", "update": 1984, "total_env_steps": 6348800, "episode_reward": 0.27717456221580505, "value_loss": 0.00616110498085618, "policy_loss": -0.0012597471979514552, "dist_entropy": 0.6855147242546081, "actor_grad_norm": 0.07985168695449829, "critic_grad_norm": 0.07628440111875534, "ratio": 1.000146508216858, "entropy": 0.6855147242546081, "incre_win_rate": 0.9069767441860465, "step": 1984}
{"time": 1767161094.4787788, "phase": "train", "update": 1985, "total_env_steps": 6352000, "episode_reward": 0.2676686644554138, "value_loss": 0.006454378366470337, "policy_loss": -0.0014856958940594467, "dist_entropy": 0.6936367988586426, "actor_grad_norm": 0.0802328810095787, "critic_grad_norm": 0.07026231288909912, "ratio": 1.000038743019104, "entropy": 0.6936367988586426, "incre_win_rate": 0.8913043478260869, "step": 1985}
{"time": 1767161098.7753751, "phase": "train", "update": 1986, "total_env_steps": 6355200, "episode_reward": 0.27162665128707886, "value_loss": 0.006246592663228512, "policy_loss": -0.001098850272382279, "dist_entropy": 0.7008238196372986, "actor_grad_norm": 0.07794984430074692, "critic_grad_norm": 0.09848730266094208, "ratio": 0.9999957084655762, "entropy": 0.7008238196372986, "incre_win_rate": 0.9285714285714286, "step": 1986}
{"time": 1767161103.0797615, "phase": "train", "update": 1987, "total_env_steps": 6358400, "episode_reward": 0.264689564704895, "value_loss": 0.006538690533488989, "policy_loss": -0.0015067708513807232, "dist_entropy": 0.6737985253334046, "actor_grad_norm": 0.08718931674957275, "critic_grad_norm": 0.09177304804325104, "ratio": 0.9998984336853027, "entropy": 0.6737985253334046, "incre_win_rate": 0.8888888888888888, "step": 1987}
{"time": 1767161107.426831, "phase": "train", "update": 1988, "total_env_steps": 6361600, "episode_reward": 0.26828333735466003, "value_loss": 0.004614435881376266, "policy_loss": -0.0013494140506921325, "dist_entropy": 0.6987440943717956, "actor_grad_norm": 0.08487202227115631, "critic_grad_norm": 0.05818195268511772, "ratio": 1.0003050565719604, "entropy": 0.6987440943717956, "incre_win_rate": 0.8636363636363636, "step": 1988}
{"time": 1767161111.7449641, "phase": "train", "update": 1989, "total_env_steps": 6364800, "episode_reward": 0.27038079500198364, "value_loss": 0.004854844138026238, "policy_loss": -0.0010280306354452761, "dist_entropy": 0.7050615668296814, "actor_grad_norm": 0.07163295894861221, "critic_grad_norm": 0.03579435124993324, "ratio": 1.0001741647720337, "entropy": 0.7050615668296814, "incre_win_rate": 0.9090909090909091, "step": 1989}
{"time": 1767161116.0413525, "phase": "train", "update": 1990, "total_env_steps": 6368000, "episode_reward": 0.26158732175827026, "value_loss": 0.007770637795329094, "policy_loss": -0.0012564781458273444, "dist_entropy": 0.7050837516784668, "actor_grad_norm": 0.0939248576760292, "critic_grad_norm": 0.04322230443358421, "ratio": 0.9997524619102478, "entropy": 0.7050837516784668, "incre_win_rate": 0.9069767441860465, "step": 1990}
{"time": 1767161120.3555872, "phase": "train", "update": 1991, "total_env_steps": 6371200, "episode_reward": 0.273468554019928, "value_loss": 0.00440729008987546, "policy_loss": -0.0009413407250065342, "dist_entropy": 0.7033874154090881, "actor_grad_norm": 0.07862656563520432, "critic_grad_norm": 0.0748119056224823, "ratio": 0.9999767541885376, "entropy": 0.7033874154090881, "incre_win_rate": 0.9555555555555556, "step": 1991}
{"time": 1767161124.6370757, "phase": "train", "update": 1992, "total_env_steps": 6374400, "episode_reward": 0.2645985186100006, "value_loss": 0.004894848074764013, "policy_loss": -0.001629618920970799, "dist_entropy": 0.7333820819854736, "actor_grad_norm": 0.09432017058134079, "critic_grad_norm": 0.038879480212926865, "ratio": 1.0000702142715454, "entropy": 0.7333820819854736, "incre_win_rate": 0.8604651162790697, "step": 1992}
{"time": 1767161128.9311087, "phase": "train", "update": 1993, "total_env_steps": 6377600, "episode_reward": 0.25891348719596863, "value_loss": 0.008997819572687148, "policy_loss": -0.0011423701210986792, "dist_entropy": 0.7098106384277344, "actor_grad_norm": 0.09311238676309586, "critic_grad_norm": 0.18473108112812042, "ratio": 0.9999532103538513, "entropy": 0.7098106384277344, "incre_win_rate": 0.8863636363636364, "step": 1993}
{"time": 1767161133.378157, "phase": "train", "update": 1994, "total_env_steps": 6380800, "episode_reward": 0.2709742486476898, "value_loss": 0.006070896703749895, "policy_loss": -0.0013369844977118462, "dist_entropy": 0.7127304196357727, "actor_grad_norm": 0.10744550079107285, "critic_grad_norm": 0.11834650486707687, "ratio": 0.9999476671218872, "entropy": 0.7127304196357727, "incre_win_rate": 0.8372093023255814, "step": 1994}
{"time": 1767161137.693635, "phase": "train", "update": 1995, "total_env_steps": 6384000, "episode_reward": 0.26193398237228394, "value_loss": 0.006842340901494026, "policy_loss": -0.0013923141193892263, "dist_entropy": 0.7188333392143249, "actor_grad_norm": 0.09329920262098312, "critic_grad_norm": 0.1050570160150528, "ratio": 0.9998292922973633, "entropy": 0.7188333392143249, "incre_win_rate": 0.8666666666666667, "step": 1995}
{"time": 1767161142.0193634, "phase": "train", "update": 1996, "total_env_steps": 6387200, "episode_reward": 0.2523137331008911, "value_loss": 0.007714880537241698, "policy_loss": -0.001277113459601864, "dist_entropy": 0.7140506148338318, "actor_grad_norm": 0.09527920931577682, "critic_grad_norm": 0.10054057836532593, "ratio": 0.9998896718025208, "entropy": 0.7140506148338318, "incre_win_rate": 0.8048780487804879, "step": 1996}
{"time": 1767161146.3622336, "phase": "train", "update": 1997, "total_env_steps": 6390400, "episode_reward": 0.2588653862476349, "value_loss": 0.008851681835949421, "policy_loss": -0.0013254012730037346, "dist_entropy": 0.7038774490356445, "actor_grad_norm": 0.08171107620000839, "critic_grad_norm": 0.08875960111618042, "ratio": 0.9999763369560242, "entropy": 0.7038774490356445, "incre_win_rate": 0.8181818181818182, "step": 1997}
{"time": 1767161150.654588, "phase": "train", "update": 1998, "total_env_steps": 6393600, "episode_reward": 0.2715024948120117, "value_loss": 0.006620746664702892, "policy_loss": -0.0011175503045656398, "dist_entropy": 0.7114345550537109, "actor_grad_norm": 0.08685179799795151, "critic_grad_norm": 0.0747416540980339, "ratio": 0.999973714351654, "entropy": 0.7114345550537109, "incre_win_rate": 0.9347826086956522, "step": 1998}
{"time": 1767161155.0072696, "phase": "train", "update": 1999, "total_env_steps": 6396800, "episode_reward": 0.2663120925426483, "value_loss": 0.006779570132493973, "policy_loss": -0.0010766050762607727, "dist_entropy": 0.697796630859375, "actor_grad_norm": 0.09300197660923004, "critic_grad_norm": 0.07190760970115662, "ratio": 0.9998599290847778, "entropy": 0.697796630859375, "incre_win_rate": 0.8837209302325582, "step": 1999}
{"time": 1767161159.3467407, "phase": "train", "update": 2000, "total_env_steps": 6400000, "episode_reward": 0.27765727043151855, "value_loss": 0.003544556815177202, "policy_loss": -0.0010177786518113408, "dist_entropy": 0.6856512427330017, "actor_grad_norm": 0.10077059268951416, "critic_grad_norm": 0.12181060761213303, "ratio": 0.9997563362121582, "entropy": 0.6856512427330017, "incre_win_rate": 0.9545454545454546, "step": 2000}
{"time": 1767161163.688258, "phase": "train", "update": 2001, "total_env_steps": 6403200, "episode_reward": 0.2706705331802368, "value_loss": 0.0031417782418429853, "policy_loss": -0.0010525980851291195, "dist_entropy": 0.6857894539833069, "actor_grad_norm": 0.09733803570270538, "critic_grad_norm": 0.10047223418951035, "ratio": 1.0001089572906494, "entropy": 0.6857894539833069, "incre_win_rate": 0.9534883720930233, "step": 2001}
{"time": 1767161173.3748353, "phase": "eval", "update": 2001, "total_env_steps": 6403200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.806084437086092, "step": 2001}
{"time": 1767161177.6386156, "phase": "train", "update": 2002, "total_env_steps": 6406400, "episode_reward": 0.2661030888557434, "value_loss": 0.004756500571966171, "policy_loss": -0.0013065644273538624, "dist_entropy": 0.6781762719154358, "actor_grad_norm": 0.08467092365026474, "critic_grad_norm": 0.10424409061670303, "ratio": 0.9998894929885864, "entropy": 0.6781762719154358, "incre_win_rate": 0.9333333333333333, "step": 2002}
{"time": 1767161181.955273, "phase": "train", "update": 2003, "total_env_steps": 6409600, "episode_reward": 0.2737944722175598, "value_loss": 0.0071068346500396725, "policy_loss": -0.0009779354043423893, "dist_entropy": 0.6976090192794799, "actor_grad_norm": 0.07520090788602829, "critic_grad_norm": 0.09310811012983322, "ratio": 0.9997008442878723, "entropy": 0.6976090192794799, "incre_win_rate": 0.9111111111111111, "step": 2003}
{"time": 1767161186.257171, "phase": "train", "update": 2004, "total_env_steps": 6412800, "episode_reward": 0.261209636926651, "value_loss": 0.009061440452933311, "policy_loss": -0.0009148519423924029, "dist_entropy": 0.6779286861419678, "actor_grad_norm": 0.09277189522981644, "critic_grad_norm": 0.10569506883621216, "ratio": 0.9999704360961914, "entropy": 0.6779286861419678, "incre_win_rate": 0.8222222222222222, "step": 2004}
{"time": 1767161190.6180272, "phase": "train", "update": 2005, "total_env_steps": 6416000, "episode_reward": 0.26788339018821716, "value_loss": 0.007919019181281328, "policy_loss": -0.0009228766212928008, "dist_entropy": 0.6771579027175904, "actor_grad_norm": 0.08792871236801147, "critic_grad_norm": 0.1353578418493271, "ratio": 0.9998978972434998, "entropy": 0.6771579027175904, "incre_win_rate": 0.9069767441860465, "step": 2005}
{"time": 1767161194.9303608, "phase": "train", "update": 2006, "total_env_steps": 6419200, "episode_reward": 0.27161112427711487, "value_loss": 0.007382533699274063, "policy_loss": -0.0012318300302339934, "dist_entropy": 0.6787354230880738, "actor_grad_norm": 0.1123354583978653, "critic_grad_norm": 0.07238113880157471, "ratio": 0.9996890425682068, "entropy": 0.6787354230880738, "incre_win_rate": 0.8666666666666667, "step": 2006}
{"time": 1767161199.3520868, "phase": "train", "update": 2007, "total_env_steps": 6422400, "episode_reward": 0.27190399169921875, "value_loss": 0.006945557799190283, "policy_loss": -0.0012894057480366428, "dist_entropy": 0.6949355363845825, "actor_grad_norm": 0.098990298807621, "critic_grad_norm": 0.0738406702876091, "ratio": 0.9998502731323242, "entropy": 0.6949355363845825, "incre_win_rate": 0.9069767441860465, "step": 2007}
{"time": 1767161203.686556, "phase": "train", "update": 2008, "total_env_steps": 6425600, "episode_reward": 0.272959440946579, "value_loss": 0.0058301351964473724, "policy_loss": -0.001396953099500209, "dist_entropy": 0.6794411540031433, "actor_grad_norm": 0.083267442882061, "critic_grad_norm": 0.05721172317862511, "ratio": 0.9997865557670593, "entropy": 0.6794411540031433, "incre_win_rate": 0.9166666666666666, "step": 2008}
{"time": 1767161208.0163178, "phase": "train", "update": 2009, "total_env_steps": 6428800, "episode_reward": 0.2669163942337036, "value_loss": 0.006959091871976852, "policy_loss": -0.0014520943945225185, "dist_entropy": 0.6862378478050232, "actor_grad_norm": 0.08436348289251328, "critic_grad_norm": 0.12216317653656006, "ratio": 0.9995558857917786, "entropy": 0.6862378478050232, "incre_win_rate": 0.8372093023255814, "step": 2009}
{"time": 1767161212.3205187, "phase": "train", "update": 2010, "total_env_steps": 6432000, "episode_reward": 0.25945156812667847, "value_loss": 0.0064743515104055405, "policy_loss": -0.0015633093768322227, "dist_entropy": 0.6822112560272217, "actor_grad_norm": 0.09959571808576584, "critic_grad_norm": 0.12056922912597656, "ratio": 1.0001415014266968, "entropy": 0.6822112560272217, "incre_win_rate": 0.8181818181818182, "step": 2010}
{"time": 1767161216.6743774, "phase": "train", "update": 2011, "total_env_steps": 6435200, "episode_reward": 0.26588112115859985, "value_loss": 0.008938953280448914, "policy_loss": -0.0010847316398891137, "dist_entropy": 0.6797078728675843, "actor_grad_norm": 0.08014645427465439, "critic_grad_norm": 0.09742182493209839, "ratio": 0.9996902346611023, "entropy": 0.6797078728675843, "incre_win_rate": 0.8222222222222222, "step": 2011}
{"time": 1767161221.020323, "phase": "train", "update": 2012, "total_env_steps": 6438400, "episode_reward": 0.27679377794265747, "value_loss": 0.005274220276623965, "policy_loss": -0.0011950884705484554, "dist_entropy": 0.6786974191665649, "actor_grad_norm": 0.07648256421089172, "critic_grad_norm": 0.07465936988592148, "ratio": 0.9997259378433228, "entropy": 0.6786974191665649, "incre_win_rate": 0.9111111111111111, "step": 2012}
{"time": 1767161225.3738024, "phase": "train", "update": 2013, "total_env_steps": 6441600, "episode_reward": 0.26475268602371216, "value_loss": 0.009182686731219292, "policy_loss": -0.0015869507239635538, "dist_entropy": 0.6655417084693909, "actor_grad_norm": 0.11929582804441452, "critic_grad_norm": 0.11681395024061203, "ratio": 0.9997539520263672, "entropy": 0.6655417084693909, "incre_win_rate": 0.8372093023255814, "step": 2013}
{"time": 1767161229.7097006, "phase": "train", "update": 2014, "total_env_steps": 6444800, "episode_reward": 0.2741432189941406, "value_loss": 0.005926236975938082, "policy_loss": -0.0010058355240559536, "dist_entropy": 0.6520439147949219, "actor_grad_norm": 0.08311984688043594, "critic_grad_norm": 0.09996294230222702, "ratio": 0.9999187588691711, "entropy": 0.6520439147949219, "incre_win_rate": 0.9347826086956522, "step": 2014}
{"time": 1767161234.0405369, "phase": "train", "update": 2015, "total_env_steps": 6448000, "episode_reward": 0.27538907527923584, "value_loss": 0.005903381016105413, "policy_loss": -0.001039428678937071, "dist_entropy": 0.6611778140068054, "actor_grad_norm": 0.06840471923351288, "critic_grad_norm": 0.08306334912776947, "ratio": 1.0000554323196411, "entropy": 0.6611778140068054, "incre_win_rate": 0.9333333333333333, "step": 2015}
{"time": 1767161238.3404114, "phase": "train", "update": 2016, "total_env_steps": 6451200, "episode_reward": 0.2717948257923126, "value_loss": 0.006107129249721765, "policy_loss": -0.0015070810907808151, "dist_entropy": 0.6585410714149476, "actor_grad_norm": 0.08804836124181747, "critic_grad_norm": 0.06806732714176178, "ratio": 0.9997869729995728, "entropy": 0.6585410714149476, "incre_win_rate": 0.9090909090909091, "step": 2016}
{"time": 1767161242.6714756, "phase": "train", "update": 2017, "total_env_steps": 6454400, "episode_reward": 0.27750828862190247, "value_loss": 0.005144179984927178, "policy_loss": -0.0011854325398463316, "dist_entropy": 0.6781669735908509, "actor_grad_norm": 0.07744058221578598, "critic_grad_norm": 0.03539567068219185, "ratio": 0.9999548196792603, "entropy": 0.6781669735908509, "incre_win_rate": 0.9347826086956522, "step": 2017}
{"time": 1767161247.0579069, "phase": "train", "update": 2018, "total_env_steps": 6457600, "episode_reward": 0.28033941984176636, "value_loss": 0.0040515884291380646, "policy_loss": -0.0012850117060260401, "dist_entropy": 0.6637900829315185, "actor_grad_norm": 0.0928688570857048, "critic_grad_norm": 0.035484861582517624, "ratio": 0.999442994594574, "entropy": 0.6637900829315185, "incre_win_rate": 0.9111111111111111, "step": 2018}
{"time": 1767161251.3518302, "phase": "train", "update": 2019, "total_env_steps": 6460800, "episode_reward": 0.26657283306121826, "value_loss": 0.003970684111118316, "policy_loss": -0.0010212292250464828, "dist_entropy": 0.661229944229126, "actor_grad_norm": 0.08580320328474045, "critic_grad_norm": 0.057099368423223495, "ratio": 1.0001147985458374, "entropy": 0.661229944229126, "incre_win_rate": 0.9090909090909091, "step": 2019}
{"time": 1767161255.743965, "phase": "train", "update": 2020, "total_env_steps": 6464000, "episode_reward": 0.2750605642795563, "value_loss": 0.006355086900293827, "policy_loss": -0.001180990736637, "dist_entropy": 0.6670642256736755, "actor_grad_norm": 0.08774416893720627, "critic_grad_norm": 0.05921081453561783, "ratio": 1.0001856088638306, "entropy": 0.6670642256736755, "incre_win_rate": 0.9130434782608695, "step": 2020}
{"time": 1767161260.0522118, "phase": "train", "update": 2021, "total_env_steps": 6467200, "episode_reward": 0.273514062166214, "value_loss": 0.006021477747708559, "policy_loss": -0.001098815043253154, "dist_entropy": 0.6721936821937561, "actor_grad_norm": 0.08909400552511215, "critic_grad_norm": 0.06092400476336479, "ratio": 1.0000898838043213, "entropy": 0.6721936821937561, "incre_win_rate": 0.95, "step": 2021}
{"time": 1767161269.7373297, "phase": "eval", "update": 2021, "total_env_steps": 6467200, "eval_win_rate": 1.0, "eval_episode_reward": 20.0, "step": 2021}
{"time": 1767161274.0043755, "phase": "train", "update": 2022, "total_env_steps": 6470400, "episode_reward": 0.26249173283576965, "value_loss": 0.0058938836678862575, "policy_loss": -0.001366672062301255, "dist_entropy": 0.6465962767601013, "actor_grad_norm": 0.07960854470729828, "critic_grad_norm": 0.03586142882704735, "ratio": 0.9999989867210388, "entropy": 0.6465962767601013, "incre_win_rate": 0.9166666666666666, "step": 2022}
{"time": 1767161278.2732406, "phase": "train", "update": 2023, "total_env_steps": 6473600, "episode_reward": 0.2635006308555603, "value_loss": 0.005704131536185741, "policy_loss": -0.0011580259638257929, "dist_entropy": 0.6716137647628784, "actor_grad_norm": 0.08833228796720505, "critic_grad_norm": 0.018201014026999474, "ratio": 1.000344157218933, "entropy": 0.6716137647628784, "incre_win_rate": 0.9230769230769231, "step": 2023}
{"time": 1767161282.5068889, "phase": "train", "update": 2024, "total_env_steps": 6476800, "episode_reward": 0.2702069580554962, "value_loss": 0.0057340490631759165, "policy_loss": -0.0012520067973841975, "dist_entropy": 0.6587939858436584, "actor_grad_norm": 0.08332587778568268, "critic_grad_norm": 0.031595103442668915, "ratio": 0.9995765686035156, "entropy": 0.6587939858436584, "incre_win_rate": 0.9148936170212766, "step": 2024}
{"time": 1767161286.8162038, "phase": "train", "update": 2025, "total_env_steps": 6480000, "episode_reward": 0.2716778814792633, "value_loss": 0.005611066520214081, "policy_loss": -0.0011127473636790342, "dist_entropy": 0.6528477430343628, "actor_grad_norm": 0.07372575253248215, "critic_grad_norm": 0.033389050513505936, "ratio": 1.0000380277633667, "entropy": 0.6528477430343628, "incre_win_rate": 0.9047619047619048, "step": 2025}
{"time": 1767161291.082621, "phase": "train", "update": 2026, "total_env_steps": 6483200, "episode_reward": 0.25991305708885193, "value_loss": 0.01071237251162529, "policy_loss": -0.0011624360801832268, "dist_entropy": 0.6328582644462586, "actor_grad_norm": 0.0811532735824585, "critic_grad_norm": 0.10976684093475342, "ratio": 0.9998423457145691, "entropy": 0.6328582644462586, "incre_win_rate": 0.782608695652174, "step": 2026}
{"time": 1767161295.4127002, "phase": "train", "update": 2027, "total_env_steps": 6486400, "episode_reward": 0.27710264921188354, "value_loss": 0.0034347066190093755, "policy_loss": -0.0015259019936920027, "dist_entropy": 0.6573763370513916, "actor_grad_norm": 0.101336769759655, "critic_grad_norm": 0.12082880735397339, "ratio": 1.000006079673767, "entropy": 0.6573763370513916, "incre_win_rate": 0.9772727272727273, "step": 2027}
{"time": 1767161299.6441247, "phase": "train", "update": 2028, "total_env_steps": 6489600, "episode_reward": 0.2830919027328491, "value_loss": 0.002416273159906268, "policy_loss": -0.0010919812031737308, "dist_entropy": 0.6324350118637085, "actor_grad_norm": 0.08528947830200195, "critic_grad_norm": 0.1090192198753357, "ratio": 0.9997917413711548, "entropy": 0.6324350118637085, "incre_win_rate": 1.0, "step": 2028}
{"time": 1767161303.969198, "phase": "train", "update": 2029, "total_env_steps": 6492800, "episode_reward": 0.28033941984176636, "value_loss": 0.0030433116015046837, "policy_loss": -0.001218988923407238, "dist_entropy": 0.6331471085548401, "actor_grad_norm": 0.06820698827505112, "critic_grad_norm": 0.07703747600317001, "ratio": 1.0002480745315552, "entropy": 0.6331471085548401, "incre_win_rate": 0.9767441860465116, "step": 2029}
{"time": 1767161308.2524884, "phase": "train", "update": 2030, "total_env_steps": 6496000, "episode_reward": 0.27717041969299316, "value_loss": 0.003371962672099471, "policy_loss": -0.0013447002017464627, "dist_entropy": 0.6230471134185791, "actor_grad_norm": 0.07976948469877243, "critic_grad_norm": 0.04829050227999687, "ratio": 1.0000261068344116, "entropy": 0.6230471134185791, "incre_win_rate": 0.9565217391304348, "step": 2030}
{"time": 1767161312.5223658, "phase": "train", "update": 2031, "total_env_steps": 6499200, "episode_reward": 0.27522504329681396, "value_loss": 0.003904886357486248, "policy_loss": -0.0010929070864648337, "dist_entropy": 0.616078507900238, "actor_grad_norm": 0.07097666710615158, "critic_grad_norm": 0.07035490870475769, "ratio": 0.999740719795227, "entropy": 0.616078507900238, "incre_win_rate": 0.9318181818181818, "step": 2031}
{"time": 1767161316.8354063, "phase": "train", "update": 2032, "total_env_steps": 6502400, "episode_reward": 0.27793872356414795, "value_loss": 0.002992394519969821, "policy_loss": -0.0011617513422606863, "dist_entropy": 0.6271474719047546, "actor_grad_norm": 0.09624596685171127, "critic_grad_norm": 0.034777794033288956, "ratio": 1.0001016855239868, "entropy": 0.6271474719047546, "incre_win_rate": 0.9772727272727273, "step": 2032}
{"time": 1767161321.2116034, "phase": "train", "update": 2033, "total_env_steps": 6505600, "episode_reward": 0.26457419991493225, "value_loss": 0.0052760706283152105, "policy_loss": -0.0015015146493066566, "dist_entropy": 0.6337336301803589, "actor_grad_norm": 0.08884269744157791, "critic_grad_norm": 0.06966277956962585, "ratio": 0.9998947381973267, "entropy": 0.6337336301803589, "incre_win_rate": 0.8863636363636364, "step": 2033}
{"time": 1767161325.538585, "phase": "train", "update": 2034, "total_env_steps": 6508800, "episode_reward": 0.26547133922576904, "value_loss": 0.004385707899928093, "policy_loss": -0.0013605827549291404, "dist_entropy": 0.6474489212036133, "actor_grad_norm": 0.09499648213386536, "critic_grad_norm": 0.032614730298519135, "ratio": 1.000275731086731, "entropy": 0.6474489212036133, "incre_win_rate": 0.9090909090909091, "step": 2034}
{"time": 1767161329.916602, "phase": "train", "update": 2035, "total_env_steps": 6512000, "episode_reward": 0.281332790851593, "value_loss": 0.0034707854967564343, "policy_loss": -0.0009477420552094884, "dist_entropy": 0.6621693253517151, "actor_grad_norm": 0.08432235568761826, "critic_grad_norm": 0.08707690984010696, "ratio": 0.9996652007102966, "entropy": 0.6621693253517151, "incre_win_rate": 1.0, "step": 2035}
{"time": 1767161334.215133, "phase": "train", "update": 2036, "total_env_steps": 6515200, "episode_reward": 0.2657543420791626, "value_loss": 0.0033253527246415613, "policy_loss": -0.0010118388375182975, "dist_entropy": 0.666867458820343, "actor_grad_norm": 0.07511010766029358, "critic_grad_norm": 0.07120759785175323, "ratio": 1.0000571012496948, "entropy": 0.666867458820343, "incre_win_rate": 0.9333333333333333, "step": 2036}
{"time": 1767161338.527702, "phase": "train", "update": 2037, "total_env_steps": 6518400, "episode_reward": 0.2805670499801636, "value_loss": 0.001930749136954546, "policy_loss": -0.0015654430821015809, "dist_entropy": 0.6858834385871887, "actor_grad_norm": 0.0872785672545433, "critic_grad_norm": 0.05820193514227867, "ratio": 0.9996140599250793, "entropy": 0.6858834385871887, "incre_win_rate": 1.0, "step": 2037}
{"time": 1767161342.898453, "phase": "train", "update": 2038, "total_env_steps": 6521600, "episode_reward": 0.2705836296081543, "value_loss": 0.0033560861367732285, "policy_loss": -0.0010000346358495448, "dist_entropy": 0.6873021125793457, "actor_grad_norm": 0.07338570058345795, "critic_grad_norm": 0.03904999792575836, "ratio": 0.9997052550315857, "entropy": 0.6873021125793457, "incre_win_rate": 0.9555555555555556, "step": 2038}
{"time": 1767161347.1712272, "phase": "train", "update": 2039, "total_env_steps": 6524800, "episode_reward": 0.2746993899345398, "value_loss": 0.004338361416012048, "policy_loss": -0.0011954650623053453, "dist_entropy": 0.674494469165802, "actor_grad_norm": 0.08338078111410141, "critic_grad_norm": 0.09565235674381256, "ratio": 0.999649167060852, "entropy": 0.674494469165802, "incre_win_rate": 0.8913043478260869, "step": 2039}
{"time": 1767161351.4845057, "phase": "train", "update": 2040, "total_env_steps": 6528000, "episode_reward": 0.2767508327960968, "value_loss": 0.0024790553376078605, "policy_loss": -0.0015672123990341901, "dist_entropy": 0.6614934921264648, "actor_grad_norm": 0.07973908632993698, "critic_grad_norm": 0.07410930842161179, "ratio": 0.9996593594551086, "entropy": 0.6614934921264648, "incre_win_rate": 0.9777777777777777, "step": 2040}
{"time": 1767161355.7837636, "phase": "train", "update": 2041, "total_env_steps": 6531200, "episode_reward": 0.26852235198020935, "value_loss": 0.0059505986049771305, "policy_loss": -0.00153551453748193, "dist_entropy": 0.6474300861358643, "actor_grad_norm": 0.12001097202301025, "critic_grad_norm": 0.09829964488744736, "ratio": 0.9996871948242188, "entropy": 0.6474300861358643, "incre_win_rate": 0.926829268292683, "step": 2041}
{"time": 1767161365.578972, "phase": "eval", "update": 2041, "total_env_steps": 6531200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.67673841059603, "step": 2041}
{"time": 1767161369.870532, "phase": "train", "update": 2042, "total_env_steps": 6534400, "episode_reward": 0.260699987411499, "value_loss": 0.008785880170762539, "policy_loss": -0.001102305061714759, "dist_entropy": 0.6322677373886109, "actor_grad_norm": 0.08940357714891434, "critic_grad_norm": 0.1816423088312149, "ratio": 1.0000026226043701, "entropy": 0.6322677373886109, "incre_win_rate": 0.851063829787234, "step": 2042}
{"time": 1767161374.179429, "phase": "train", "update": 2043, "total_env_steps": 6537600, "episode_reward": 0.27505484223365784, "value_loss": 0.004626170545816421, "policy_loss": -0.0010774842203552736, "dist_entropy": 0.6212321162223816, "actor_grad_norm": 0.07835643738508224, "critic_grad_norm": 0.10858990252017975, "ratio": 1.0002204179763794, "entropy": 0.6212321162223816, "incre_win_rate": 0.9523809523809523, "step": 2043}
{"time": 1767161378.5006747, "phase": "train", "update": 2044, "total_env_steps": 6540800, "episode_reward": 0.2760968506336212, "value_loss": 0.0059800131246447565, "policy_loss": -0.000851376882647692, "dist_entropy": 0.6190716385841369, "actor_grad_norm": 0.08094072341918945, "critic_grad_norm": 0.07948047667741776, "ratio": 0.999890148639679, "entropy": 0.6190716385841369, "incre_win_rate": 0.9333333333333333, "step": 2044}
{"time": 1767161382.796524, "phase": "train", "update": 2045, "total_env_steps": 6544000, "episode_reward": 0.26031407713890076, "value_loss": 0.00827397285029292, "policy_loss": -0.0012253522269315199, "dist_entropy": 0.6242220401763916, "actor_grad_norm": 0.09017474949359894, "critic_grad_norm": 0.15755267441272736, "ratio": 0.9998748898506165, "entropy": 0.6242220401763916, "incre_win_rate": 0.7954545454545454, "step": 2045}
{"time": 1767161387.1471603, "phase": "train", "update": 2046, "total_env_steps": 6547200, "episode_reward": 0.2831043004989624, "value_loss": 0.003604283882305026, "policy_loss": -0.000991550189407775, "dist_entropy": 0.6286856055259704, "actor_grad_norm": 0.07161416858434677, "critic_grad_norm": 0.16372647881507874, "ratio": 0.9997531175613403, "entropy": 0.6286856055259704, "incre_win_rate": 0.9565217391304348, "step": 2046}
{"time": 1767161391.4548473, "phase": "train", "update": 2047, "total_env_steps": 6550400, "episode_reward": 0.26898592710494995, "value_loss": 0.0048021825961768625, "policy_loss": -0.0018269695960051457, "dist_entropy": 0.6491799354553223, "actor_grad_norm": 0.10334078222513199, "critic_grad_norm": 0.12761859595775604, "ratio": 0.9996762275695801, "entropy": 0.6491799354553223, "incre_win_rate": 0.8666666666666667, "step": 2047}
{"time": 1767161395.7544127, "phase": "train", "update": 2048, "total_env_steps": 6553600, "episode_reward": 0.2763897180557251, "value_loss": 0.005059105344116688, "policy_loss": -0.001180009431027873, "dist_entropy": 0.6236979484558105, "actor_grad_norm": 0.07841294258832932, "critic_grad_norm": 0.09245390444993973, "ratio": 0.9993733763694763, "entropy": 0.6236979484558105, "incre_win_rate": 0.8888888888888888, "step": 2048}
{"time": 1767161400.069511, "phase": "train", "update": 2049, "total_env_steps": 6556800, "episode_reward": 0.2796352207660675, "value_loss": 0.006588363274931908, "policy_loss": -0.0010431989755304016, "dist_entropy": 0.6474494695663452, "actor_grad_norm": 0.07087583839893341, "critic_grad_norm": 0.1514468640089035, "ratio": 1.000069260597229, "entropy": 0.6474494695663452, "incre_win_rate": 0.9130434782608695, "step": 2049}
{"time": 1767161404.473747, "phase": "train", "update": 2050, "total_env_steps": 6560000, "episode_reward": 0.2794784605503082, "value_loss": 0.0065071783028542995, "policy_loss": -0.0010976283224522377, "dist_entropy": 0.6263909697532654, "actor_grad_norm": 0.07604679465293884, "critic_grad_norm": 0.09325871616601944, "ratio": 0.9999485015869141, "entropy": 0.6263909697532654, "incre_win_rate": 0.9333333333333333, "step": 2050}
{"time": 1767161408.9233634, "phase": "train", "update": 2051, "total_env_steps": 6563200, "episode_reward": 0.27118638157844543, "value_loss": 0.007653102464973927, "policy_loss": -0.0011680037044055514, "dist_entropy": 0.6221083641052246, "actor_grad_norm": 0.07658807188272476, "critic_grad_norm": 0.08346936851739883, "ratio": 0.9996793866157532, "entropy": 0.6221083641052246, "incre_win_rate": 0.9111111111111111, "step": 2051}
{"time": 1767161413.252698, "phase": "train", "update": 2052, "total_env_steps": 6566400, "episode_reward": 0.2742467224597931, "value_loss": 0.007983588706701994, "policy_loss": -0.0012353536107479357, "dist_entropy": 0.6410491228103637, "actor_grad_norm": 0.09602781385183334, "critic_grad_norm": 0.15691445767879486, "ratio": 1.0002331733703613, "entropy": 0.6410491228103637, "incre_win_rate": 0.8888888888888888, "step": 2052}
{"time": 1767161417.6015587, "phase": "train", "update": 2053, "total_env_steps": 6569600, "episode_reward": 0.26878467202186584, "value_loss": 0.006178436428308487, "policy_loss": -0.0008622016768669027, "dist_entropy": 0.6526816606521606, "actor_grad_norm": 0.09880723804235458, "critic_grad_norm": 0.07152190059423447, "ratio": 1.0002070665359497, "entropy": 0.6526816606521606, "incre_win_rate": 0.8888888888888888, "step": 2053}
{"time": 1767161421.9407568, "phase": "train", "update": 2054, "total_env_steps": 6572800, "episode_reward": 0.28841784596443176, "value_loss": 0.004464728944003582, "policy_loss": -0.0013155222453818283, "dist_entropy": 0.6613832831382751, "actor_grad_norm": 0.10653646290302277, "critic_grad_norm": 0.07966066151857376, "ratio": 1.0000718832015991, "entropy": 0.6613832831382751, "incre_win_rate": 0.9777777777777777, "step": 2054}
{"time": 1767161426.2686238, "phase": "train", "update": 2055, "total_env_steps": 6576000, "episode_reward": 0.26862895488739014, "value_loss": 0.008121149148792028, "policy_loss": -0.0013249646833116912, "dist_entropy": 0.6582069516181945, "actor_grad_norm": 0.08540686219930649, "critic_grad_norm": 0.1789894849061966, "ratio": 1.0000836849212646, "entropy": 0.6582069516181945, "incre_win_rate": 0.8888888888888888, "step": 2055}
{"time": 1767161430.632773, "phase": "train", "update": 2056, "total_env_steps": 6579200, "episode_reward": 0.27167218923568726, "value_loss": 0.008224955573678017, "policy_loss": -0.0014081340932875718, "dist_entropy": 0.6750332593917847, "actor_grad_norm": 0.10658647119998932, "critic_grad_norm": 0.1476176530122757, "ratio": 0.999796986579895, "entropy": 0.6750332593917847, "incre_win_rate": 0.8723404255319149, "step": 2056}
{"time": 1767161434.951787, "phase": "train", "update": 2057, "total_env_steps": 6582400, "episode_reward": 0.2796812951564789, "value_loss": 0.006472716014832259, "policy_loss": -0.0010922143047537246, "dist_entropy": 0.6591329216957093, "actor_grad_norm": 0.0809946358203888, "critic_grad_norm": 0.16873948276042938, "ratio": 0.9998259544372559, "entropy": 0.6591329216957093, "incre_win_rate": 0.9347826086956522, "step": 2057}
{"time": 1767161439.285237, "phase": "train", "update": 2058, "total_env_steps": 6585600, "episode_reward": 0.27180051803588867, "value_loss": 0.0072310931980609896, "policy_loss": -0.0010142123704095952, "dist_entropy": 0.6485021948814392, "actor_grad_norm": 0.0810771957039833, "critic_grad_norm": 0.12521539628505707, "ratio": 1.0002117156982422, "entropy": 0.6485021948814392, "incre_win_rate": 0.9047619047619048, "step": 2058}
{"time": 1767161443.590808, "phase": "train", "update": 2059, "total_env_steps": 6588800, "episode_reward": 0.26686879992485046, "value_loss": 0.005397623591125012, "policy_loss": -0.0011045904546815421, "dist_entropy": 0.6484037876129151, "actor_grad_norm": 0.07931988686323166, "critic_grad_norm": 0.05881735309958458, "ratio": 0.9997833371162415, "entropy": 0.6484037876129151, "incre_win_rate": 0.8936170212765957, "step": 2059}
{"time": 1767161447.929496, "phase": "train", "update": 2060, "total_env_steps": 6592000, "episode_reward": 0.28551527857780457, "value_loss": 0.0032849604729563, "policy_loss": -0.0011212355755717772, "dist_entropy": 0.6689558267593384, "actor_grad_norm": 0.07345301657915115, "critic_grad_norm": 0.03570170700550079, "ratio": 1.0002050399780273, "entropy": 0.6689558267593384, "incre_win_rate": 0.9555555555555556, "step": 2060}
{"time": 1767161452.2488427, "phase": "train", "update": 2061, "total_env_steps": 6595200, "episode_reward": 0.28311261534690857, "value_loss": 0.00269324304535985, "policy_loss": -0.0011369702824827854, "dist_entropy": 0.6741564750671387, "actor_grad_norm": 0.1019487977027893, "critic_grad_norm": 0.029743466526269913, "ratio": 0.999509334564209, "entropy": 0.6741564750671387, "incre_win_rate": 0.9777777777777777, "step": 2061}
{"time": 1767161462.0461953, "phase": "eval", "update": 2061, "total_env_steps": 6595200, "eval_win_rate": 0.84375, "eval_episode_reward": 19.115324917218544, "step": 2061}
{"time": 1767161466.368384, "phase": "train", "update": 2062, "total_env_steps": 6598400, "episode_reward": 0.27046462893486023, "value_loss": 0.006016160454601049, "policy_loss": -0.0012993552304383371, "dist_entropy": 0.6519598960876465, "actor_grad_norm": 0.0887191966176033, "critic_grad_norm": 0.09929347038269043, "ratio": 1.000077247619629, "entropy": 0.6519598960876465, "incre_win_rate": 0.8636363636363636, "step": 2062}
{"time": 1767161470.6895537, "phase": "train", "update": 2063, "total_env_steps": 6601600, "episode_reward": 0.27685120701789856, "value_loss": 0.009037336334586143, "policy_loss": -0.0012648045310481137, "dist_entropy": 0.6623826265335083, "actor_grad_norm": 0.09503543376922607, "critic_grad_norm": 0.09577412903308868, "ratio": 0.9999269843101501, "entropy": 0.6623826265335083, "incre_win_rate": 0.9347826086956522, "step": 2063}
{"time": 1767161474.9854922, "phase": "train", "update": 2064, "total_env_steps": 6604800, "episode_reward": 0.2781001925468445, "value_loss": 0.006392624136060477, "policy_loss": -0.001343277992245273, "dist_entropy": 0.6683854341506958, "actor_grad_norm": 0.0960906371474266, "critic_grad_norm": 0.08795294165611267, "ratio": 1.000090479850769, "entropy": 0.6683854341506958, "incre_win_rate": 0.9361702127659575, "step": 2064}
{"time": 1767161479.29493, "phase": "train", "update": 2065, "total_env_steps": 6608000, "episode_reward": 0.27692049741744995, "value_loss": 0.004593903105705977, "policy_loss": -0.0013087425507237072, "dist_entropy": 0.6564172267913818, "actor_grad_norm": 0.1041426882147789, "critic_grad_norm": 0.09058398008346558, "ratio": 1.0000755786895752, "entropy": 0.6564172267913818, "incre_win_rate": 0.9302325581395349, "step": 2065}
{"time": 1767161483.634871, "phase": "train", "update": 2066, "total_env_steps": 6611200, "episode_reward": 0.2775419056415558, "value_loss": 0.005274452734738588, "policy_loss": -0.001152367217125061, "dist_entropy": 0.6604033708572388, "actor_grad_norm": 0.09084352105855942, "critic_grad_norm": 0.09814101457595825, "ratio": 1.0001840591430664, "entropy": 0.6604033708572388, "incre_win_rate": 0.8913043478260869, "step": 2066}
{"time": 1767161487.9923518, "phase": "train", "update": 2067, "total_env_steps": 6614400, "episode_reward": 0.2839590311050415, "value_loss": 0.004159076930955052, "policy_loss": -0.0008435130675735536, "dist_entropy": 0.6857287764549256, "actor_grad_norm": 0.0838470309972763, "critic_grad_norm": 0.06804469972848892, "ratio": 1.0001423358917236, "entropy": 0.6857287764549256, "incre_win_rate": 0.9583333333333334, "step": 2067}
{"time": 1767161492.29666, "phase": "train", "update": 2068, "total_env_steps": 6617600, "episode_reward": 0.27677151560783386, "value_loss": 0.006093303393572569, "policy_loss": -0.0014451175799550242, "dist_entropy": 0.6852136492729187, "actor_grad_norm": 0.08791586011648178, "critic_grad_norm": 0.08597921580076218, "ratio": 1.0001410245895386, "entropy": 0.6852136492729187, "incre_win_rate": 0.9285714285714286, "step": 2068}
{"time": 1767161496.5646565, "phase": "train", "update": 2069, "total_env_steps": 6620800, "episode_reward": 0.28010761737823486, "value_loss": 0.003586834017187357, "policy_loss": -0.0008781294280467477, "dist_entropy": 0.6838733077049255, "actor_grad_norm": 0.08291773498058319, "critic_grad_norm": 0.11339592933654785, "ratio": 1.0002597570419312, "entropy": 0.6838733077049255, "incre_win_rate": 0.9333333333333333, "step": 2069}
{"time": 1767161500.835872, "phase": "train", "update": 2070, "total_env_steps": 6624000, "episode_reward": 0.27618223428726196, "value_loss": 0.005999494530260563, "policy_loss": -0.001198700025451771, "dist_entropy": 0.6780638694763184, "actor_grad_norm": 0.0792461484670639, "critic_grad_norm": 0.0719979852437973, "ratio": 0.9999775886535645, "entropy": 0.6780638694763184, "incre_win_rate": 0.9130434782608695, "step": 2070}
{"time": 1767161505.134558, "phase": "train", "update": 2071, "total_env_steps": 6627200, "episode_reward": 0.2766975462436676, "value_loss": 0.004794568754732609, "policy_loss": -0.0009656602460751173, "dist_entropy": 0.6654496431350708, "actor_grad_norm": 0.07368279248476028, "critic_grad_norm": 0.045300569385290146, "ratio": 0.9998346567153931, "entropy": 0.6654496431350708, "incre_win_rate": 0.9111111111111111, "step": 2071}
{"time": 1767161509.4422703, "phase": "train", "update": 2072, "total_env_steps": 6630400, "episode_reward": 0.2756746709346771, "value_loss": 0.0052776033990085125, "policy_loss": -0.001253200965643586, "dist_entropy": 0.678667175769806, "actor_grad_norm": 0.08375147730112076, "critic_grad_norm": 0.07427185028791428, "ratio": 1.0000813007354736, "entropy": 0.678667175769806, "incre_win_rate": 0.9148936170212766, "step": 2072}
{"time": 1767161513.7770612, "phase": "train", "update": 2073, "total_env_steps": 6633600, "episode_reward": 0.2792632281780243, "value_loss": 0.00553509509190917, "policy_loss": -0.0010761998002138285, "dist_entropy": 0.6789331793785095, "actor_grad_norm": 0.07747446745634079, "critic_grad_norm": 0.04584136977791786, "ratio": 0.9998188018798828, "entropy": 0.6789331793785095, "incre_win_rate": 0.9090909090909091, "step": 2073}
{"time": 1767161518.161089, "phase": "train", "update": 2074, "total_env_steps": 6636800, "episode_reward": 0.2818543314933777, "value_loss": 0.004946209955960512, "policy_loss": -0.001104021376299258, "dist_entropy": 0.6662448287010193, "actor_grad_norm": 0.07833560556173325, "critic_grad_norm": 0.06341084837913513, "ratio": 1.0003447532653809, "entropy": 0.6662448287010193, "incre_win_rate": 0.9318181818181818, "step": 2074}
{"time": 1767161522.4954312, "phase": "train", "update": 2075, "total_env_steps": 6640000, "episode_reward": 0.28818297386169434, "value_loss": 0.0026524426881223916, "policy_loss": -0.0010938509067052848, "dist_entropy": 0.6573419094085693, "actor_grad_norm": 0.0759504958987236, "critic_grad_norm": 0.10753568261861801, "ratio": 1.000020980834961, "entropy": 0.6573419094085693, "incre_win_rate": 1.0, "step": 2075}
{"time": 1767161526.8490505, "phase": "train", "update": 2076, "total_env_steps": 6643200, "episode_reward": 0.27762314677238464, "value_loss": 0.0037247583735734225, "policy_loss": -0.0009270468873774362, "dist_entropy": 0.6596123099327087, "actor_grad_norm": 0.07772775739431381, "critic_grad_norm": 0.08727710694074631, "ratio": 1.0002669095993042, "entropy": 0.6596123099327087, "incre_win_rate": 0.9361702127659575, "step": 2076}
{"time": 1767161531.201317, "phase": "train", "update": 2077, "total_env_steps": 6646400, "episode_reward": 0.2727110981941223, "value_loss": 0.004417070560157299, "policy_loss": -0.001245831390877683, "dist_entropy": 0.6592366099357605, "actor_grad_norm": 0.08303678035736084, "critic_grad_norm": 0.10041897743940353, "ratio": 0.999910295009613, "entropy": 0.6592366099357605, "incre_win_rate": 0.9069767441860465, "step": 2077}
{"time": 1767161535.4855464, "phase": "train", "update": 2078, "total_env_steps": 6649600, "episode_reward": 0.27235203981399536, "value_loss": 0.005905619077384472, "policy_loss": -0.001162630869173853, "dist_entropy": 0.6559297204017639, "actor_grad_norm": 0.09181646257638931, "critic_grad_norm": 0.09286075085401535, "ratio": 1.0000799894332886, "entropy": 0.6559297204017639, "incre_win_rate": 0.9347826086956522, "step": 2078}
{"time": 1767161539.8106713, "phase": "train", "update": 2079, "total_env_steps": 6652800, "episode_reward": 0.28132864832878113, "value_loss": 0.004126329720020294, "policy_loss": -0.00117090262768329, "dist_entropy": 0.6657231569290161, "actor_grad_norm": 0.0929865762591362, "critic_grad_norm": 0.08177641779184341, "ratio": 1.000362753868103, "entropy": 0.6657231569290161, "incre_win_rate": 0.9777777777777777, "step": 2079}
{"time": 1767161544.1438859, "phase": "train", "update": 2080, "total_env_steps": 6656000, "episode_reward": 0.2689197063446045, "value_loss": 0.005769257061183452, "policy_loss": -0.0012872333389893243, "dist_entropy": 0.6656392335891723, "actor_grad_norm": 0.08363185077905655, "critic_grad_norm": 0.06255071610212326, "ratio": 1.0000991821289062, "entropy": 0.6656392335891723, "incre_win_rate": 0.9090909090909091, "step": 2080}
{"time": 1767161548.4801772, "phase": "train", "update": 2081, "total_env_steps": 6659200, "episode_reward": 0.26942363381385803, "value_loss": 0.005471364129334688, "policy_loss": -0.0016274442499742748, "dist_entropy": 0.6626099348068237, "actor_grad_norm": 0.08726858347654343, "critic_grad_norm": 0.053912270814180374, "ratio": 0.9995903968811035, "entropy": 0.6626099348068237, "incre_win_rate": 0.9111111111111111, "step": 2081}
{"time": 1767161558.5030003, "phase": "eval", "update": 2081, "total_env_steps": 6659200, "eval_win_rate": 0.8125, "eval_episode_reward": 18.8880380794702, "step": 2081}
{"time": 1767161562.8192315, "phase": "train", "update": 2082, "total_env_steps": 6662400, "episode_reward": 0.27030062675476074, "value_loss": 0.011331319250166417, "policy_loss": -0.0013314911112832562, "dist_entropy": 0.6349112272262574, "actor_grad_norm": 0.07924985885620117, "critic_grad_norm": 0.1759241223335266, "ratio": 1.0001178979873657, "entropy": 0.6349112272262574, "incre_win_rate": 0.8409090909090909, "step": 2082}
{"time": 1767161567.1493657, "phase": "train", "update": 2083, "total_env_steps": 6665600, "episode_reward": 0.26412150263786316, "value_loss": 0.009667262062430381, "policy_loss": -0.0012984766868157748, "dist_entropy": 0.6216558218002319, "actor_grad_norm": 0.07870261371135712, "critic_grad_norm": 0.12087105959653854, "ratio": 1.0000190734863281, "entropy": 0.6216558218002319, "incre_win_rate": 0.8666666666666667, "step": 2083}
{"time": 1767161571.440112, "phase": "train", "update": 2084, "total_env_steps": 6668800, "episode_reward": 0.2598649561405182, "value_loss": 0.010477968491613865, "policy_loss": -0.0014895271640799734, "dist_entropy": 0.6151089668273926, "actor_grad_norm": 0.0813937708735466, "critic_grad_norm": 0.1271420419216156, "ratio": 0.9998614192008972, "entropy": 0.6151089668273926, "incre_win_rate": 0.7906976744186046, "step": 2084}
{"time": 1767161575.747025, "phase": "train", "update": 2085, "total_env_steps": 6672000, "episode_reward": 0.26899784803390503, "value_loss": 0.010342279076576233, "policy_loss": -0.0013217523808464193, "dist_entropy": 0.5956403851509094, "actor_grad_norm": 0.0914526954293251, "critic_grad_norm": 0.14984984695911407, "ratio": 1.0000308752059937, "entropy": 0.5956403851509094, "incre_win_rate": 0.8222222222222222, "step": 2085}
{"time": 1767161580.080936, "phase": "train", "update": 2086, "total_env_steps": 6675200, "episode_reward": 0.26623913645744324, "value_loss": 0.011165003292262554, "policy_loss": -0.0012219665444511917, "dist_entropy": 0.6147302269935608, "actor_grad_norm": 0.09202495962381363, "critic_grad_norm": 0.10426624119281769, "ratio": 1.0001991987228394, "entropy": 0.6147302269935608, "incre_win_rate": 0.8297872340425532, "step": 2086}
{"time": 1767161584.3834555, "phase": "train", "update": 2087, "total_env_steps": 6678400, "episode_reward": 0.2688312530517578, "value_loss": 0.009976799041032791, "policy_loss": -0.0014822886620294185, "dist_entropy": 0.6138064384460449, "actor_grad_norm": 0.11621981859207153, "critic_grad_norm": 0.08189725875854492, "ratio": 1.0000391006469727, "entropy": 0.6138064384460449, "incre_win_rate": 0.8604651162790697, "step": 2087}
{"time": 1767161588.6678178, "phase": "train", "update": 2088, "total_env_steps": 6681600, "episode_reward": 0.2755205035209656, "value_loss": 0.007369556371122599, "policy_loss": -0.0016137403891551827, "dist_entropy": 0.6338662981987, "actor_grad_norm": 0.08915633708238602, "critic_grad_norm": 0.05250191316008568, "ratio": 0.999728798866272, "entropy": 0.6338662981987, "incre_win_rate": 0.8936170212765957, "step": 2088}
{"time": 1767161592.9615777, "phase": "train", "update": 2089, "total_env_steps": 6684800, "episode_reward": 0.27084437012672424, "value_loss": 0.008000040985643863, "policy_loss": -0.001170520561593591, "dist_entropy": 0.6559782028198242, "actor_grad_norm": 0.09582878649234772, "critic_grad_norm": 0.05776111036539078, "ratio": 0.9996421933174133, "entropy": 0.6559782028198242, "incre_win_rate": 0.8409090909090909, "step": 2089}
{"time": 1767161597.2625945, "phase": "train", "update": 2090, "total_env_steps": 6688000, "episode_reward": 0.26832470297813416, "value_loss": 0.007120731938630343, "policy_loss": -0.0013131293410552302, "dist_entropy": 0.6303553700447082, "actor_grad_norm": 0.07326247543096542, "critic_grad_norm": 0.13539846241474152, "ratio": 1.0001192092895508, "entropy": 0.6303553700447082, "incre_win_rate": 0.8863636363636364, "step": 2090}
{"time": 1767161601.845897, "phase": "train", "update": 2091, "total_env_steps": 6691200, "episode_reward": 0.277168869972229, "value_loss": 0.0034322502091526986, "policy_loss": -0.0012056310834083206, "dist_entropy": 0.6241978645324707, "actor_grad_norm": 0.0930255576968193, "critic_grad_norm": 0.06973477452993393, "ratio": 1.0003142356872559, "entropy": 0.6241978645324707, "incre_win_rate": 1.0, "step": 2091}
{"time": 1767161606.250718, "phase": "train", "update": 2092, "total_env_steps": 6694400, "episode_reward": 0.2691825330257416, "value_loss": 0.005615971516817808, "policy_loss": -0.0008097236158420174, "dist_entropy": 0.6426496982574463, "actor_grad_norm": 0.08630089461803436, "critic_grad_norm": 0.06299018114805222, "ratio": 1.000075340270996, "entropy": 0.6426496982574463, "incre_win_rate": 0.8809523809523809, "step": 2092}
{"time": 1767161610.8937395, "phase": "train", "update": 2093, "total_env_steps": 6697600, "episode_reward": 0.27519869804382324, "value_loss": 0.0035643041133880614, "policy_loss": -0.0011716532898256916, "dist_entropy": 0.6222004652023315, "actor_grad_norm": 0.08770682662725449, "critic_grad_norm": 0.04214286059141159, "ratio": 0.9995547533035278, "entropy": 0.6222004652023315, "incre_win_rate": 0.9782608695652174, "step": 2093}
{"time": 1767161615.587235, "phase": "train", "update": 2094, "total_env_steps": 6700800, "episode_reward": 0.2759023606777191, "value_loss": 0.005335923377424478, "policy_loss": -0.0011400675372918556, "dist_entropy": 0.6229945063591004, "actor_grad_norm": 0.08861665427684784, "critic_grad_norm": 0.06695395708084106, "ratio": 0.9994440078735352, "entropy": 0.6229945063591004, "incre_win_rate": 0.8837209302325582, "step": 2094}
{"time": 1767161620.233846, "phase": "train", "update": 2095, "total_env_steps": 6704000, "episode_reward": 0.2694278061389923, "value_loss": 0.006463093869388104, "policy_loss": -0.001046410156892108, "dist_entropy": 0.6062747955322265, "actor_grad_norm": 0.0714561864733696, "critic_grad_norm": 0.041797541081905365, "ratio": 1.000178337097168, "entropy": 0.6062747955322265, "incre_win_rate": 0.8723404255319149, "step": 2095}
{"time": 1767161624.6253395, "phase": "train", "update": 2096, "total_env_steps": 6707200, "episode_reward": 0.28980961441993713, "value_loss": 0.004874102305620909, "policy_loss": -0.0010800542256440338, "dist_entropy": 0.6204034328460694, "actor_grad_norm": 0.06563453376293182, "critic_grad_norm": 0.04268458113074303, "ratio": 1.0001846551895142, "entropy": 0.6204034328460694, "incre_win_rate": 0.9565217391304348, "step": 2096}
{"time": 1767161629.058228, "phase": "train", "update": 2097, "total_env_steps": 6710400, "episode_reward": 0.26528146862983704, "value_loss": 0.008114371914416552, "policy_loss": -0.0015417309348464414, "dist_entropy": 0.6165119767189026, "actor_grad_norm": 0.10036960989236832, "critic_grad_norm": 0.17001353204250336, "ratio": 1.0001996755599976, "entropy": 0.6165119767189026, "incre_win_rate": 0.8222222222222222, "step": 2097}
{"time": 1767161633.7622402, "phase": "train", "update": 2098, "total_env_steps": 6713600, "episode_reward": 0.28303393721580505, "value_loss": 0.0064318889752030374, "policy_loss": -0.0011443290235840565, "dist_entropy": 0.6177071094512939, "actor_grad_norm": 0.07796335220336914, "critic_grad_norm": 0.11679625511169434, "ratio": 0.9998148083686829, "entropy": 0.6177071094512939, "incre_win_rate": 0.9333333333333333, "step": 2098}
{"time": 1767161638.2453265, "phase": "train", "update": 2099, "total_env_steps": 6716800, "episode_reward": 0.28386589884757996, "value_loss": 0.00451540881767869, "policy_loss": -0.0009925913210917514, "dist_entropy": 0.60794095993042, "actor_grad_norm": 0.05996769666671753, "critic_grad_norm": 0.16140051186084747, "ratio": 0.9998869299888611, "entropy": 0.60794095993042, "incre_win_rate": 0.9555555555555556, "step": 2099}
{"time": 1767161642.5733721, "phase": "train", "update": 2100, "total_env_steps": 6720000, "episode_reward": 0.2801945209503174, "value_loss": 0.006577700469642877, "policy_loss": -0.0008536763085350785, "dist_entropy": 0.6094642043113708, "actor_grad_norm": 0.05824773386120796, "critic_grad_norm": 0.09626685827970505, "ratio": 0.9999622702598572, "entropy": 0.6094642043113708, "incre_win_rate": 0.9166666666666666, "step": 2100}
{"time": 1767161646.9472902, "phase": "train", "update": 2101, "total_env_steps": 6723200, "episode_reward": 0.2783511281013489, "value_loss": 0.008282784931361675, "policy_loss": -0.0011911712858136525, "dist_entropy": 0.615857744216919, "actor_grad_norm": 0.075518898665905, "critic_grad_norm": 0.10575216263532639, "ratio": 0.9998106360435486, "entropy": 0.615857744216919, "incre_win_rate": 0.8888888888888888, "step": 2101}
{"time": 1767161656.6234267, "phase": "eval", "update": 2101, "total_env_steps": 6723200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.911941225165563, "step": 2101}
{"time": 1767161660.9262872, "phase": "train", "update": 2102, "total_env_steps": 6726400, "episode_reward": 0.26996275782585144, "value_loss": 0.00795666165649891, "policy_loss": -0.0012957300870603205, "dist_entropy": 0.5934722423553467, "actor_grad_norm": 0.08941024541854858, "critic_grad_norm": 0.13844738900661469, "ratio": 0.9999125599861145, "entropy": 0.5934722423553467, "incre_win_rate": 0.8888888888888888, "step": 2102}
{"time": 1767161665.2343662, "phase": "train", "update": 2103, "total_env_steps": 6729600, "episode_reward": 0.28180256485939026, "value_loss": 0.006256881542503834, "policy_loss": -0.0017022370092330875, "dist_entropy": 0.6148387789726257, "actor_grad_norm": 0.08489132672548294, "critic_grad_norm": 0.056987423449754715, "ratio": 0.9997591376304626, "entropy": 0.6148387789726257, "incre_win_rate": 0.9574468085106383, "step": 2103}
{"time": 1767161669.59136, "phase": "train", "update": 2104, "total_env_steps": 6732800, "episode_reward": 0.279631644487381, "value_loss": 0.00520915612578392, "policy_loss": -0.0011602229134325625, "dist_entropy": 0.6141865015029907, "actor_grad_norm": 0.08018900454044342, "critic_grad_norm": 0.04658237472176552, "ratio": 0.9998072981834412, "entropy": 0.6141865015029907, "incre_win_rate": 0.9318181818181818, "step": 2104}
{"time": 1767161673.882366, "phase": "train", "update": 2105, "total_env_steps": 6736000, "episode_reward": 0.2687138020992279, "value_loss": 0.004261461645364761, "policy_loss": -0.0010336084737684104, "dist_entropy": 0.6223511695861816, "actor_grad_norm": 0.08158445358276367, "critic_grad_norm": 0.0624096505343914, "ratio": 1.0000336170196533, "entropy": 0.6223511695861816, "incre_win_rate": 0.9302325581395349, "step": 2105}
{"time": 1767161678.124821, "phase": "train", "update": 2106, "total_env_steps": 6739200, "episode_reward": 0.26849234104156494, "value_loss": 0.006309816893190145, "policy_loss": -0.001010976259906471, "dist_entropy": 0.6205391168594361, "actor_grad_norm": 0.07522626966238022, "critic_grad_norm": 0.047146350145339966, "ratio": 0.9999021887779236, "entropy": 0.6205391168594361, "incre_win_rate": 0.8695652173913043, "step": 2106}
{"time": 1767161682.3606124, "phase": "train", "update": 2107, "total_env_steps": 6742400, "episode_reward": 0.28437498211860657, "value_loss": 0.002959275199100375, "policy_loss": -0.0012154131363715237, "dist_entropy": 0.6481837272644043, "actor_grad_norm": 0.08568676561117172, "critic_grad_norm": 0.07260561734437943, "ratio": 0.999919593334198, "entropy": 0.6481837272644043, "incre_win_rate": 1.0, "step": 2107}
{"time": 1767161686.6183867, "phase": "train", "update": 2108, "total_env_steps": 6745600, "episode_reward": 0.2706131041049957, "value_loss": 0.005265338905155658, "policy_loss": -0.0011042438080998806, "dist_entropy": 0.6362034797668457, "actor_grad_norm": 0.07517165690660477, "critic_grad_norm": 0.08898954093456268, "ratio": 1.000258445739746, "entropy": 0.6362034797668457, "incre_win_rate": 0.8837209302325582, "step": 2108}
{"time": 1767161690.9041908, "phase": "train", "update": 2109, "total_env_steps": 6748800, "episode_reward": 0.2760523557662964, "value_loss": 0.0030637184623628854, "policy_loss": -0.0011495608695469173, "dist_entropy": 0.6417192220687866, "actor_grad_norm": 0.08263547718524933, "critic_grad_norm": 0.05621389299631119, "ratio": 1.0002084970474243, "entropy": 0.6417192220687866, "incre_win_rate": 0.9565217391304348, "step": 2109}
{"time": 1767161695.221549, "phase": "train", "update": 2110, "total_env_steps": 6752000, "episode_reward": 0.283279687166214, "value_loss": 0.004521498363465071, "policy_loss": -0.0011605431767414132, "dist_entropy": 0.6177348256111145, "actor_grad_norm": 0.07864473760128021, "critic_grad_norm": 0.061360348016023636, "ratio": 1.0000061988830566, "entropy": 0.6177348256111145, "incre_win_rate": 0.9318181818181818, "step": 2110}
{"time": 1767161699.5137951, "phase": "train", "update": 2111, "total_env_steps": 6755200, "episode_reward": 0.2664388418197632, "value_loss": 0.006144672725349664, "policy_loss": -0.001281025756895815, "dist_entropy": 0.6189504384994506, "actor_grad_norm": 0.08498703688383102, "critic_grad_norm": 0.08527864515781403, "ratio": 0.9997706413269043, "entropy": 0.6189504384994506, "incre_win_rate": 0.8913043478260869, "step": 2111}
{"time": 1767161703.829209, "phase": "train", "update": 2112, "total_env_steps": 6758400, "episode_reward": 0.2855013608932495, "value_loss": 0.0032318411860615013, "policy_loss": -0.0013774586387460986, "dist_entropy": 0.6302047729492187, "actor_grad_norm": 0.09771289676427841, "critic_grad_norm": 0.08768822997808456, "ratio": 1.0001288652420044, "entropy": 0.6302047729492187, "incre_win_rate": 0.9574468085106383, "step": 2112}
{"time": 1767161708.163216, "phase": "train", "update": 2113, "total_env_steps": 6761600, "episode_reward": 0.2810140550136566, "value_loss": 0.005180996283888817, "policy_loss": -0.0010168347389786446, "dist_entropy": 0.6227572917938232, "actor_grad_norm": 0.09376265108585358, "critic_grad_norm": 0.062371816486120224, "ratio": 0.999980628490448, "entropy": 0.6227572917938232, "incre_win_rate": 0.9767441860465116, "step": 2113}
{"time": 1767161712.4765565, "phase": "train", "update": 2114, "total_env_steps": 6764800, "episode_reward": 0.27840957045555115, "value_loss": 0.0047987431287765505, "policy_loss": -0.0008541046845643053, "dist_entropy": 0.6147254228591919, "actor_grad_norm": 0.08263890445232391, "critic_grad_norm": 0.05465305596590042, "ratio": 1.0002888441085815, "entropy": 0.6147254228591919, "incre_win_rate": 0.8936170212765957, "step": 2114}
{"time": 1767161716.8171024, "phase": "train", "update": 2115, "total_env_steps": 6768000, "episode_reward": 0.2737784683704376, "value_loss": 0.007038395013660192, "policy_loss": -0.0016364922362441803, "dist_entropy": 0.6216188907623291, "actor_grad_norm": 0.08669409155845642, "critic_grad_norm": 0.08019102364778519, "ratio": 0.9998866319656372, "entropy": 0.6216188907623291, "incre_win_rate": 0.9555555555555556, "step": 2115}
{"time": 1767161721.1132677, "phase": "train", "update": 2116, "total_env_steps": 6771200, "episode_reward": 0.27363359928131104, "value_loss": 0.006824705563485622, "policy_loss": -0.0016026765286738965, "dist_entropy": 0.6220245599746704, "actor_grad_norm": 0.11244045943021774, "critic_grad_norm": 0.08903033286333084, "ratio": 0.9996142387390137, "entropy": 0.6220245599746704, "incre_win_rate": 0.8604651162790697, "step": 2116}
{"time": 1767161725.4421136, "phase": "train", "update": 2117, "total_env_steps": 6774400, "episode_reward": 0.2786961793899536, "value_loss": 0.0061510525643825534, "policy_loss": -0.0011017181649863872, "dist_entropy": 0.623984944820404, "actor_grad_norm": 0.08782757073640823, "critic_grad_norm": 0.08299671858549118, "ratio": 1.0000797510147095, "entropy": 0.623984944820404, "incre_win_rate": 0.875, "step": 2117}
{"time": 1767161729.75472, "phase": "train", "update": 2118, "total_env_steps": 6777600, "episode_reward": 0.2809721827507019, "value_loss": 0.0056441986002027985, "policy_loss": -0.0008715117485280643, "dist_entropy": 0.6090912222862244, "actor_grad_norm": 0.0716199204325676, "critic_grad_norm": 0.09306836128234863, "ratio": 1.0000377893447876, "entropy": 0.6090912222862244, "incre_win_rate": 0.9347826086956522, "step": 2118}
{"time": 1767161734.0642173, "phase": "train", "update": 2119, "total_env_steps": 6780800, "episode_reward": 0.2846885025501251, "value_loss": 0.007609349861741066, "policy_loss": -0.0010906699976843015, "dist_entropy": 0.6227671146392822, "actor_grad_norm": 0.06903260201215744, "critic_grad_norm": 0.06838256865739822, "ratio": 1.000091791152954, "entropy": 0.6227671146392822, "incre_win_rate": 0.9375, "step": 2119}
{"time": 1767161738.4272983, "phase": "train", "update": 2120, "total_env_steps": 6784000, "episode_reward": 0.27845871448516846, "value_loss": 0.005940346606075763, "policy_loss": -0.0013035009812838894, "dist_entropy": 0.6251597046852112, "actor_grad_norm": 0.10706876963376999, "critic_grad_norm": 0.058760710060596466, "ratio": 0.9997211694717407, "entropy": 0.6251597046852112, "incre_win_rate": 0.9069767441860465, "step": 2120}
{"time": 1767161742.7164032, "phase": "train", "update": 2121, "total_env_steps": 6787200, "episode_reward": 0.28057947754859924, "value_loss": 0.004171251785010099, "policy_loss": -0.0009297453829525182, "dist_entropy": 0.6119522094726563, "actor_grad_norm": 0.0908723920583725, "critic_grad_norm": 0.04736974462866783, "ratio": 1.0003551244735718, "entropy": 0.6119522094726563, "incre_win_rate": 0.9333333333333333, "step": 2121}
{"time": 1767161752.7152784, "phase": "eval", "update": 2121, "total_env_steps": 6787200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.758226407284766, "step": 2121}
{"time": 1767161757.0216048, "phase": "train", "update": 2122, "total_env_steps": 6790400, "episode_reward": 0.2674560248851776, "value_loss": 0.006800620537251234, "policy_loss": -0.001538102145586251, "dist_entropy": 0.6045263886451722, "actor_grad_norm": 0.08980289101600647, "critic_grad_norm": 0.09581026434898376, "ratio": 0.9997362494468689, "entropy": 0.6045263886451722, "incre_win_rate": 0.8913043478260869, "step": 2122}
{"time": 1767161761.2864456, "phase": "train", "update": 2123, "total_env_steps": 6793600, "episode_reward": 0.2671450674533844, "value_loss": 0.0056932827457785605, "policy_loss": -0.0009108599635734294, "dist_entropy": 0.6200038313865661, "actor_grad_norm": 0.08009827882051468, "critic_grad_norm": 0.06513296067714691, "ratio": 0.9997168779373169, "entropy": 0.6200038313865661, "incre_win_rate": 0.8863636363636364, "step": 2123}
{"time": 1767161799.7291222, "phase": "train", "update": 2124, "total_env_steps": 6796800, "episode_reward": 0.2538291811943054, "value_loss": 0.06666913479566575, "policy_loss": -0.0012350879948655803, "dist_entropy": 0.6203907251358032, "actor_grad_norm": 0.0866151750087738, "critic_grad_norm": 0.4602173864841461, "ratio": 0.999804675579071, "entropy": 0.6203907251358032, "incre_win_rate": 0.775, "step": 2124}
{"time": 1767161804.0616505, "phase": "train", "update": 2125, "total_env_steps": 6800000, "episode_reward": 0.2893584370613098, "value_loss": 0.006046523805707693, "policy_loss": -0.0013146009987607954, "dist_entropy": 0.6430222988128662, "actor_grad_norm": 0.09510726481676102, "critic_grad_norm": 0.43349337577819824, "ratio": 1.0002793073654175, "entropy": 0.6430222988128662, "incre_win_rate": 0.9583333333333334, "step": 2125}
{"time": 1767161808.4333982, "phase": "train", "update": 2126, "total_env_steps": 6803200, "episode_reward": 0.2825000286102295, "value_loss": 0.005178439244627952, "policy_loss": -0.000882873413223706, "dist_entropy": 0.6381339311599732, "actor_grad_norm": 0.0883655846118927, "critic_grad_norm": 0.33484846353530884, "ratio": 1.0003608465194702, "entropy": 0.6381339311599732, "incre_win_rate": 0.9772727272727273, "step": 2126}
{"time": 1767161812.7587745, "phase": "train", "update": 2127, "total_env_steps": 6806400, "episode_reward": 0.27600371837615967, "value_loss": 0.006020655110478401, "policy_loss": -0.001133211853949234, "dist_entropy": 0.6377575993537903, "actor_grad_norm": 0.08250822871923447, "critic_grad_norm": 0.13592775166034698, "ratio": 1.0001773834228516, "entropy": 0.6377575993537903, "incre_win_rate": 0.9111111111111111, "step": 2127}
{"time": 1767161817.0647862, "phase": "train", "update": 2128, "total_env_steps": 6809600, "episode_reward": 0.28716474771499634, "value_loss": 0.003719585482031107, "policy_loss": -0.0011251133353525234, "dist_entropy": 0.6384461283683777, "actor_grad_norm": 0.09906121343374252, "critic_grad_norm": 0.20773382484912872, "ratio": 0.9997348785400391, "entropy": 0.6384461283683777, "incre_win_rate": 1.0, "step": 2128}
{"time": 1767161821.3726258, "phase": "train", "update": 2129, "total_env_steps": 6812800, "episode_reward": 0.2754092514514923, "value_loss": 0.005133959464728832, "policy_loss": -0.001607700917330135, "dist_entropy": 0.6530193209648132, "actor_grad_norm": 0.0859031081199646, "critic_grad_norm": 0.20828579366207123, "ratio": 0.9998828768730164, "entropy": 0.6530193209648132, "incre_win_rate": 0.9318181818181818, "step": 2129}
{"time": 1767161825.677292, "phase": "train", "update": 2130, "total_env_steps": 6816000, "episode_reward": 0.27598199248313904, "value_loss": 0.010537385009229183, "policy_loss": -0.001576698995523884, "dist_entropy": 0.6418081521987915, "actor_grad_norm": 0.08233865350484848, "critic_grad_norm": 0.11218315362930298, "ratio": 0.9997148513793945, "entropy": 0.6418081521987915, "incre_win_rate": 0.8636363636363636, "step": 2130}
{"time": 1767161831.4494307, "phase": "train", "update": 2131, "total_env_steps": 6819200, "episode_reward": 0.27950331568717957, "value_loss": 0.008517936058342456, "policy_loss": -0.001096944396894628, "dist_entropy": 0.6611013889312745, "actor_grad_norm": 0.08704038709402084, "critic_grad_norm": 0.2745799720287323, "ratio": 1.0003446340560913, "entropy": 0.6611013889312745, "incre_win_rate": 0.9375, "step": 2131}
{"time": 1767161836.1414497, "phase": "train", "update": 2132, "total_env_steps": 6822400, "episode_reward": 0.27664685249328613, "value_loss": 0.008637957740575075, "policy_loss": -0.0011939935370946842, "dist_entropy": 0.6595973372459412, "actor_grad_norm": 0.07979458570480347, "critic_grad_norm": 0.18063388764858246, "ratio": 0.9996448755264282, "entropy": 0.6595973372459412, "incre_win_rate": 0.8913043478260869, "step": 2132}
{"time": 1767161840.5776672, "phase": "train", "update": 2133, "total_env_steps": 6825600, "episode_reward": 0.27927565574645996, "value_loss": 0.007558953110128641, "policy_loss": -0.0011266059531592986, "dist_entropy": 0.698887026309967, "actor_grad_norm": 0.0844891294836998, "critic_grad_norm": 0.11911463737487793, "ratio": 0.9999697804450989, "entropy": 0.698887026309967, "incre_win_rate": 0.9111111111111111, "step": 2133}
{"time": 1767161844.992313, "phase": "train", "update": 2134, "total_env_steps": 6828800, "episode_reward": 0.25903406739234924, "value_loss": 0.0100931191816926, "policy_loss": -0.0013655547738525176, "dist_entropy": 0.6815511107444763, "actor_grad_norm": 0.08199208229780197, "critic_grad_norm": 0.29247069358825684, "ratio": 1.0000464916229248, "entropy": 0.6815511107444763, "incre_win_rate": 0.813953488372093, "step": 2134}
{"time": 1767161849.3588011, "phase": "train", "update": 2135, "total_env_steps": 6832000, "episode_reward": 0.25810325145721436, "value_loss": 0.00770398648455739, "policy_loss": -0.0011874080671773867, "dist_entropy": 0.7012258887290954, "actor_grad_norm": 0.08373972028493881, "critic_grad_norm": 0.1802700161933899, "ratio": 0.9998431205749512, "entropy": 0.7012258887290954, "incre_win_rate": 0.8409090909090909, "step": 2135}
{"time": 1767161853.6933324, "phase": "train", "update": 2136, "total_env_steps": 6835200, "episode_reward": 0.24305100739002228, "value_loss": 0.012427624501287936, "policy_loss": -0.0013394867375218667, "dist_entropy": 0.69443781375885, "actor_grad_norm": 0.09139510244131088, "critic_grad_norm": 0.1266385167837143, "ratio": 0.9996930360794067, "entropy": 0.69443781375885, "incre_win_rate": 0.775, "step": 2136}
{"time": 1767161858.0041382, "phase": "train", "update": 2137, "total_env_steps": 6838400, "episode_reward": 0.25713005661964417, "value_loss": 0.009465571306645871, "policy_loss": -0.0014994854516089617, "dist_entropy": 0.6813887357711792, "actor_grad_norm": 0.08988336473703384, "critic_grad_norm": 0.309028297662735, "ratio": 1.0000733137130737, "entropy": 0.6813887357711792, "incre_win_rate": 0.8837209302325582, "step": 2137}
{"time": 1767161862.4087224, "phase": "train", "update": 2138, "total_env_steps": 6841600, "episode_reward": 0.2656017243862152, "value_loss": 0.011403376981616021, "policy_loss": -0.0010965534676973475, "dist_entropy": 0.6686748385429382, "actor_grad_norm": 0.07674794644117355, "critic_grad_norm": 0.1444922238588333, "ratio": 1.0002248287200928, "entropy": 0.6686748385429382, "incre_win_rate": 0.7727272727272727, "step": 2138}
{"time": 1767161866.7833347, "phase": "train", "update": 2139, "total_env_steps": 6844800, "episode_reward": 0.2744743227958679, "value_loss": 0.00670721959322691, "policy_loss": -0.0011835371113360083, "dist_entropy": 0.6950859189033508, "actor_grad_norm": 0.08134084194898605, "critic_grad_norm": 0.11950194090604782, "ratio": 0.9999700784683228, "entropy": 0.6950859189033508, "incre_win_rate": 0.9130434782608695, "step": 2139}
{"time": 1767161873.0529366, "phase": "train", "update": 2140, "total_env_steps": 6848000, "episode_reward": 0.264180451631546, "value_loss": 0.012249855138361455, "policy_loss": -0.001065640509215271, "dist_entropy": 0.6674976706504822, "actor_grad_norm": 0.071573905646801, "critic_grad_norm": 0.3609740436077118, "ratio": 1.0001713037490845, "entropy": 0.6674976706504822, "incre_win_rate": 0.7906976744186046, "step": 2140}
{"time": 1767161878.4092443, "phase": "train", "update": 2141, "total_env_steps": 6851200, "episode_reward": 0.27249792218208313, "value_loss": 0.006536662578582764, "policy_loss": -0.001411995668339472, "dist_entropy": 0.6783684015274047, "actor_grad_norm": 0.08963847905397415, "critic_grad_norm": 0.17527224123477936, "ratio": 0.9996883273124695, "entropy": 0.6783684015274047, "incre_win_rate": 0.9545454545454546, "step": 2141}
{"time": 1767161888.35859, "phase": "eval", "update": 2141, "total_env_steps": 6851200, "eval_win_rate": 0.875, "eval_episode_reward": 19.4440190397351, "step": 2141}
{"time": 1767161892.752815, "phase": "train", "update": 2142, "total_env_steps": 6854400, "episode_reward": 0.2653088867664337, "value_loss": 0.007082572765648365, "policy_loss": -0.0012125618407755833, "dist_entropy": 0.6603869438171387, "actor_grad_norm": 0.08108839392662048, "critic_grad_norm": 0.15449930727481842, "ratio": 0.999945342540741, "entropy": 0.6603869438171387, "incre_win_rate": 0.9090909090909091, "step": 2142}
{"time": 1767161898.9003558, "phase": "train", "update": 2143, "total_env_steps": 6857600, "episode_reward": 0.2772325277328491, "value_loss": 0.007464250084012747, "policy_loss": -0.001231033708635465, "dist_entropy": 0.6599877357482911, "actor_grad_norm": 0.08896900713443756, "critic_grad_norm": 0.260877788066864, "ratio": 0.9996944665908813, "entropy": 0.6599877357482911, "incre_win_rate": 0.9555555555555556, "step": 2143}
{"time": 1767161903.1634524, "phase": "train", "update": 2144, "total_env_steps": 6860800, "episode_reward": 0.2613529562950134, "value_loss": 0.009834510460495948, "policy_loss": -0.0012829256628512197, "dist_entropy": 0.6407466888427734, "actor_grad_norm": 0.08872751146554947, "critic_grad_norm": 0.12608163058757782, "ratio": 0.9999329447746277, "entropy": 0.6407466888427734, "incre_win_rate": 0.8571428571428571, "step": 2144}
{"time": 1767161907.4428933, "phase": "train", "update": 2145, "total_env_steps": 6864000, "episode_reward": 0.2702504098415375, "value_loss": 0.006248326972126961, "policy_loss": -0.0014146897711842855, "dist_entropy": 0.6675374627113342, "actor_grad_norm": 0.08615072816610336, "critic_grad_norm": 0.10378650575876236, "ratio": 1.0000486373901367, "entropy": 0.6675374627113342, "incre_win_rate": 0.9333333333333333, "step": 2145}
{"time": 1767161911.787495, "phase": "train", "update": 2146, "total_env_steps": 6867200, "episode_reward": 0.27427929639816284, "value_loss": 0.008394698612391949, "policy_loss": -0.0007726969730924793, "dist_entropy": 0.661335027217865, "actor_grad_norm": 0.08417145907878876, "critic_grad_norm": 0.1905038207769394, "ratio": 1.0002799034118652, "entropy": 0.661335027217865, "incre_win_rate": 0.9318181818181818, "step": 2146}
{"time": 1767161916.1068375, "phase": "train", "update": 2147, "total_env_steps": 6870400, "episode_reward": 0.2581860423088074, "value_loss": 0.008361362665891648, "policy_loss": -0.0014104033212078092, "dist_entropy": 0.6661720395088195, "actor_grad_norm": 0.11042773723602295, "critic_grad_norm": 0.21084380149841309, "ratio": 1.0000132322311401, "entropy": 0.6661720395088195, "incre_win_rate": 0.8181818181818182, "step": 2147}
{"time": 1767161920.4687984, "phase": "train", "update": 2148, "total_env_steps": 6873600, "episode_reward": 0.28080296516418457, "value_loss": 0.006967132072895765, "policy_loss": -0.0010928574215320452, "dist_entropy": 0.6732101559638977, "actor_grad_norm": 0.08702027797698975, "critic_grad_norm": 0.17312327027320862, "ratio": 0.9994434714317322, "entropy": 0.6732101559638977, "incre_win_rate": 0.9318181818181818, "step": 2148}
{"time": 1767161924.756453, "phase": "train", "update": 2149, "total_env_steps": 6876800, "episode_reward": 0.27301064133644104, "value_loss": 0.006261393707245588, "policy_loss": -0.001454154993496104, "dist_entropy": 0.6765427827835083, "actor_grad_norm": 0.07887738198041916, "critic_grad_norm": 0.1636568009853363, "ratio": 0.9999117851257324, "entropy": 0.6765427827835083, "incre_win_rate": 0.9148936170212766, "step": 2149}
{"time": 1767161928.981353, "phase": "train", "update": 2150, "total_env_steps": 6880000, "episode_reward": 0.2716639041900635, "value_loss": 0.006268885266035795, "policy_loss": -0.0014586699430436667, "dist_entropy": 0.6536707043647766, "actor_grad_norm": 0.07370125502347946, "critic_grad_norm": 0.09139753133058548, "ratio": 0.9997523427009583, "entropy": 0.6536707043647766, "incre_win_rate": 0.9047619047619048, "step": 2150}
{"time": 1767161933.3054614, "phase": "train", "update": 2151, "total_env_steps": 6883200, "episode_reward": 0.26565396785736084, "value_loss": 0.005188062973320484, "policy_loss": -0.0009256169536852709, "dist_entropy": 0.6553779602050781, "actor_grad_norm": 0.07406029850244522, "critic_grad_norm": 0.08208148926496506, "ratio": 1.00007963180542, "entropy": 0.6553779602050781, "incre_win_rate": 0.8863636363636364, "step": 2151}
{"time": 1767161937.6304178, "phase": "train", "update": 2152, "total_env_steps": 6886400, "episode_reward": 0.2733153998851776, "value_loss": 0.005929089337587357, "policy_loss": -0.0009107137113140596, "dist_entropy": 0.6592295169830322, "actor_grad_norm": 0.06217452511191368, "critic_grad_norm": 0.08391313254833221, "ratio": 0.9998590350151062, "entropy": 0.6592295169830322, "incre_win_rate": 0.8837209302325582, "step": 2152}
{"time": 1767161941.9954507, "phase": "train", "update": 2153, "total_env_steps": 6889600, "episode_reward": 0.27913492918014526, "value_loss": 0.006240107491612435, "policy_loss": -0.0012675698256632729, "dist_entropy": 0.6429388880729675, "actor_grad_norm": 0.07806196063756943, "critic_grad_norm": 0.09736719727516174, "ratio": 1.0001469850540161, "entropy": 0.6429388880729675, "incre_win_rate": 0.9375, "step": 2153}
{"time": 1767161946.2437613, "phase": "train", "update": 2154, "total_env_steps": 6892800, "episode_reward": 0.276022344827652, "value_loss": 0.006932947225868702, "policy_loss": -0.001511170022627084, "dist_entropy": 0.6349457859992981, "actor_grad_norm": 0.08622647821903229, "critic_grad_norm": 0.09450706094503403, "ratio": 0.9998960494995117, "entropy": 0.6349457859992981, "incre_win_rate": 0.9130434782608695, "step": 2154}
{"time": 1767161950.4690435, "phase": "train", "update": 2155, "total_env_steps": 6896000, "episode_reward": 0.27584436535835266, "value_loss": 0.0053682345896959305, "policy_loss": -0.0010325951473276972, "dist_entropy": 0.627829372882843, "actor_grad_norm": 0.08535725623369217, "critic_grad_norm": 0.11913616955280304, "ratio": 0.9996646046638489, "entropy": 0.627829372882843, "incre_win_rate": 0.9318181818181818, "step": 2155}
{"time": 1767161954.730604, "phase": "train", "update": 2156, "total_env_steps": 6899200, "episode_reward": 0.26732614636421204, "value_loss": 0.00825822465121746, "policy_loss": -0.0012286778352940785, "dist_entropy": 0.6432542204856873, "actor_grad_norm": 0.0951162576675415, "critic_grad_norm": 0.0921911895275116, "ratio": 0.9998478293418884, "entropy": 0.6432542204856873, "incre_win_rate": 0.8409090909090909, "step": 2156}
{"time": 1767161959.0427487, "phase": "train", "update": 2157, "total_env_steps": 6902400, "episode_reward": 0.2806074023246765, "value_loss": 0.00766513803973794, "policy_loss": -0.0007638676711856363, "dist_entropy": 0.6513211727142334, "actor_grad_norm": 0.08073651045560837, "critic_grad_norm": 0.11455688625574112, "ratio": 0.999790370464325, "entropy": 0.6513211727142334, "incre_win_rate": 0.8913043478260869, "step": 2157}
{"time": 1767161963.3037548, "phase": "train", "update": 2158, "total_env_steps": 6905600, "episode_reward": 0.27532443404197693, "value_loss": 0.006904817093163729, "policy_loss": -0.0011966364977055832, "dist_entropy": 0.6720558524131774, "actor_grad_norm": 0.11299331486225128, "critic_grad_norm": 0.11432180553674698, "ratio": 1.0002111196517944, "entropy": 0.6720558524131774, "incre_win_rate": 0.8478260869565217, "step": 2158}
{"time": 1767161967.587105, "phase": "train", "update": 2159, "total_env_steps": 6908800, "episode_reward": 0.2735477387905121, "value_loss": 0.00839578900486231, "policy_loss": -0.0011770465066895496, "dist_entropy": 0.6507638216018676, "actor_grad_norm": 0.07147981971502304, "critic_grad_norm": 0.1430748552083969, "ratio": 0.9998806118965149, "entropy": 0.6507638216018676, "incre_win_rate": 0.8666666666666667, "step": 2159}
{"time": 1767161971.809808, "phase": "train", "update": 2160, "total_env_steps": 6912000, "episode_reward": 0.26061102747917175, "value_loss": 0.010602311417460441, "policy_loss": -0.0016758561077281798, "dist_entropy": 0.6578391194343567, "actor_grad_norm": 0.11508233845233917, "critic_grad_norm": 0.11547007411718369, "ratio": 0.9994300007820129, "entropy": 0.6578391194343567, "incre_win_rate": 0.8181818181818182, "step": 2160}
{"time": 1767161976.0807455, "phase": "train", "update": 2161, "total_env_steps": 6915200, "episode_reward": 0.2687603235244751, "value_loss": 0.0073348828591406345, "policy_loss": -0.0009843669103460685, "dist_entropy": 0.6701107382774353, "actor_grad_norm": 0.10084047168493271, "critic_grad_norm": 0.0976593866944313, "ratio": 1.0001081228256226, "entropy": 0.6701107382774353, "incre_win_rate": 0.8222222222222222, "step": 2161}
{"time": 1767161986.1713727, "phase": "eval", "update": 2161, "total_env_steps": 6915200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.600889900662253, "step": 2161}
{"time": 1767161990.487951, "phase": "train", "update": 2162, "total_env_steps": 6918400, "episode_reward": 0.2770855724811554, "value_loss": 0.006497889291495085, "policy_loss": -0.0011999186080824842, "dist_entropy": 0.6637724876403809, "actor_grad_norm": 0.09978705644607544, "critic_grad_norm": 0.10163532942533493, "ratio": 0.9998205304145813, "entropy": 0.6637724876403809, "incre_win_rate": 0.8888888888888888, "step": 2162}
{"time": 1767161994.756413, "phase": "train", "update": 2163, "total_env_steps": 6921600, "episode_reward": 0.2635844349861145, "value_loss": 0.005206363741308451, "policy_loss": -0.0009919329095879447, "dist_entropy": 0.6788944721221923, "actor_grad_norm": 0.08185260742902756, "critic_grad_norm": 0.07641866058111191, "ratio": 0.999988853931427, "entropy": 0.6788944721221923, "incre_win_rate": 0.8837209302325582, "step": 2163}
{"time": 1767161999.0460284, "phase": "train", "update": 2164, "total_env_steps": 6924800, "episode_reward": 0.2772744297981262, "value_loss": 0.003416173905134201, "policy_loss": -0.0010830436562113022, "dist_entropy": 0.6715413570404053, "actor_grad_norm": 0.0710517168045044, "critic_grad_norm": 0.045555632561445236, "ratio": 1.000228762626648, "entropy": 0.6715413570404053, "incre_win_rate": 0.9361702127659575, "step": 2164}
{"time": 1767162003.3406985, "phase": "train", "update": 2165, "total_env_steps": 6928000, "episode_reward": 0.2827659547328949, "value_loss": 0.003113471111282706, "policy_loss": -0.0014467915810037369, "dist_entropy": 0.6783378839492797, "actor_grad_norm": 0.08399715274572372, "critic_grad_norm": 0.05537012964487076, "ratio": 0.9998936653137207, "entropy": 0.6783378839492797, "incre_win_rate": 0.9777777777777777, "step": 2165}
{"time": 1767162007.6108744, "phase": "train", "update": 2166, "total_env_steps": 6931200, "episode_reward": 0.2743149995803833, "value_loss": 0.005867662094533444, "policy_loss": -0.0013213239443089718, "dist_entropy": 0.6723319530487061, "actor_grad_norm": 0.08217179030179977, "critic_grad_norm": 0.1151803508400917, "ratio": 1.0000118017196655, "entropy": 0.6723319530487061, "incre_win_rate": 0.8837209302325582, "step": 2166}
{"time": 1767162011.8572068, "phase": "train", "update": 2167, "total_env_steps": 6934400, "episode_reward": 0.26977238059043884, "value_loss": 0.004099862277507782, "policy_loss": -0.0011730669967484175, "dist_entropy": 0.6781621098518371, "actor_grad_norm": 0.07590251415967941, "critic_grad_norm": 0.060597896575927734, "ratio": 0.9998034834861755, "entropy": 0.6781621098518371, "incre_win_rate": 0.9347826086956522, "step": 2167}
{"time": 1767162016.0778227, "phase": "train", "update": 2168, "total_env_steps": 6937600, "episode_reward": 0.26911166310310364, "value_loss": 0.00657449783757329, "policy_loss": -0.0012913540083715701, "dist_entropy": 0.6768872499465942, "actor_grad_norm": 0.09174128621816635, "critic_grad_norm": 0.09940192848443985, "ratio": 0.9995179176330566, "entropy": 0.6768872499465942, "incre_win_rate": 0.8604651162790697, "step": 2168}
{"time": 1767162020.4020355, "phase": "train", "update": 2169, "total_env_steps": 6940800, "episode_reward": 0.27253881096839905, "value_loss": 0.004657168313860894, "policy_loss": -0.0011333100267576946, "dist_entropy": 0.6748437404632568, "actor_grad_norm": 0.08952347189188004, "critic_grad_norm": 0.06473670154809952, "ratio": 0.9999117255210876, "entropy": 0.6748437404632568, "incre_win_rate": 0.9090909090909091, "step": 2169}
{"time": 1767162024.675787, "phase": "train", "update": 2170, "total_env_steps": 6944000, "episode_reward": 0.2753973603248596, "value_loss": 0.0058310975320637224, "policy_loss": -0.0012889564878381776, "dist_entropy": 0.6706448316574096, "actor_grad_norm": 0.07805568724870682, "critic_grad_norm": 0.0483071431517601, "ratio": 0.9999828338623047, "entropy": 0.6706448316574096, "incre_win_rate": 0.9361702127659575, "step": 2170}
{"time": 1767162028.953412, "phase": "train", "update": 2171, "total_env_steps": 6947200, "episode_reward": 0.2799130976200104, "value_loss": 0.007045564800500869, "policy_loss": -0.0012487902801243678, "dist_entropy": 0.6466724872589111, "actor_grad_norm": 0.08824189752340317, "critic_grad_norm": 0.05225174501538277, "ratio": 0.9996339082717896, "entropy": 0.6466724872589111, "incre_win_rate": 0.9130434782608695, "step": 2171}
{"time": 1767162033.2391431, "phase": "train", "update": 2172, "total_env_steps": 6950400, "episode_reward": 0.27483031153678894, "value_loss": 0.0066298461519181725, "policy_loss": -0.0012383606300282678, "dist_entropy": 0.6336113929748535, "actor_grad_norm": 0.0797533243894577, "critic_grad_norm": 0.036553870886564255, "ratio": 1.0002930164337158, "entropy": 0.6336113929748535, "incre_win_rate": 0.9318181818181818, "step": 2172}
{"time": 1767162037.5473354, "phase": "train", "update": 2173, "total_env_steps": 6953600, "episode_reward": 0.2836548089981079, "value_loss": 0.006067729648202657, "policy_loss": -0.00158044386296865, "dist_entropy": 0.657326626777649, "actor_grad_norm": 0.08770595490932465, "critic_grad_norm": 0.029408765956759453, "ratio": 0.999782383441925, "entropy": 0.657326626777649, "incre_win_rate": 0.9130434782608695, "step": 2173}
{"time": 1767162041.8432283, "phase": "train", "update": 2174, "total_env_steps": 6956800, "episode_reward": 0.2781125605106354, "value_loss": 0.003254619101062417, "policy_loss": -0.0013823590300425792, "dist_entropy": 0.6630777359008789, "actor_grad_norm": 0.12199204415082932, "critic_grad_norm": 0.038991253823041916, "ratio": 0.9999179840087891, "entropy": 0.6630777359008789, "incre_win_rate": 0.9555555555555556, "step": 2174}
{"time": 1767162046.1510549, "phase": "train", "update": 2175, "total_env_steps": 6960000, "episode_reward": 0.2752116322517395, "value_loss": 0.006856772117316723, "policy_loss": -0.0014670827952109277, "dist_entropy": 0.654749870300293, "actor_grad_norm": 0.1075870543718338, "critic_grad_norm": 0.05365562438964844, "ratio": 0.9997299313545227, "entropy": 0.654749870300293, "incre_win_rate": 0.8936170212765957, "step": 2175}
{"time": 1767162050.4677715, "phase": "train", "update": 2176, "total_env_steps": 6963200, "episode_reward": 0.27758124470710754, "value_loss": 0.00931740365922451, "policy_loss": -0.0015143235517593111, "dist_entropy": 0.6750918507575989, "actor_grad_norm": 0.10425704717636108, "critic_grad_norm": 0.05700346827507019, "ratio": 0.9994882941246033, "entropy": 0.6750918507575989, "incre_win_rate": 0.8666666666666667, "step": 2176}
{"time": 1767162054.7485566, "phase": "train", "update": 2177, "total_env_steps": 6966400, "episode_reward": 0.27247464656829834, "value_loss": 0.007928106375038624, "policy_loss": -0.0013085388461687053, "dist_entropy": 0.6395079612731933, "actor_grad_norm": 0.07925160974264145, "critic_grad_norm": 0.04497631639242172, "ratio": 1.0000137090682983, "entropy": 0.6395079612731933, "incre_win_rate": 0.8666666666666667, "step": 2177}
{"time": 1767162059.064324, "phase": "train", "update": 2178, "total_env_steps": 6969600, "episode_reward": 0.28697434067726135, "value_loss": 0.004092972353100776, "policy_loss": -0.001123958903838229, "dist_entropy": 0.6546343922615051, "actor_grad_norm": 0.07827175408601761, "critic_grad_norm": 0.029205260798335075, "ratio": 1.000076174736023, "entropy": 0.6546343922615051, "incre_win_rate": 0.9565217391304348, "step": 2178}
{"time": 1767162063.3978, "phase": "train", "update": 2179, "total_env_steps": 6972800, "episode_reward": 0.27912667393684387, "value_loss": 0.005616559088230133, "policy_loss": -0.0015810704963371337, "dist_entropy": 0.6337812900543213, "actor_grad_norm": 0.08087315410375595, "critic_grad_norm": 0.03840993717312813, "ratio": 1.0001027584075928, "entropy": 0.6337812900543213, "incre_win_rate": 0.8695652173913043, "step": 2179}
{"time": 1767162067.6835191, "phase": "train", "update": 2180, "total_env_steps": 6976000, "episode_reward": 0.2821424901485443, "value_loss": 0.003771836683154106, "policy_loss": -0.0013335305386384278, "dist_entropy": 0.6150359034538269, "actor_grad_norm": 0.07915697246789932, "critic_grad_norm": 0.0536021962761879, "ratio": 1.0000534057617188, "entropy": 0.6150359034538269, "incre_win_rate": 0.9565217391304348, "step": 2180}
{"time": 1767162071.9442184, "phase": "train", "update": 2181, "total_env_steps": 6979200, "episode_reward": 0.27145642042160034, "value_loss": 0.006630458496510982, "policy_loss": -0.0013003149239584123, "dist_entropy": 0.6065675020217896, "actor_grad_norm": 0.08430027961730957, "critic_grad_norm": 0.044735729694366455, "ratio": 1.0000895261764526, "entropy": 0.6065675020217896, "incre_win_rate": 0.9318181818181818, "step": 2181}
{"time": 1767162081.135553, "phase": "eval", "update": 2181, "total_env_steps": 6979200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.78394039735099, "step": 2181}
{"time": 1767162085.375619, "phase": "train", "update": 2182, "total_env_steps": 6982400, "episode_reward": 0.28409820795059204, "value_loss": 0.005594257451593876, "policy_loss": -0.001208588625530993, "dist_entropy": 0.6256911158561707, "actor_grad_norm": 0.09955378621816635, "critic_grad_norm": 0.06154312565922737, "ratio": 1.0001966953277588, "entropy": 0.6256911158561707, "incre_win_rate": 0.9183673469387755, "step": 2182}
{"time": 1767162089.6615477, "phase": "train", "update": 2183, "total_env_steps": 6985600, "episode_reward": 0.278696209192276, "value_loss": 0.009708377905189991, "policy_loss": -0.0009841058366546918, "dist_entropy": 0.6135135889053345, "actor_grad_norm": 0.1057976707816124, "critic_grad_norm": 0.13422806560993195, "ratio": 1.000087022781372, "entropy": 0.6135135889053345, "incre_win_rate": 0.8604651162790697, "step": 2183}
{"time": 1767162093.9571137, "phase": "train", "update": 2184, "total_env_steps": 6988800, "episode_reward": 0.2702685594558716, "value_loss": 0.009346765093505382, "policy_loss": -0.0013525184618956132, "dist_entropy": 0.6108006834983826, "actor_grad_norm": 0.09140171110630035, "critic_grad_norm": 0.11694937199354172, "ratio": 1.0001457929611206, "entropy": 0.6108006834983826, "incre_win_rate": 0.8695652173913043, "step": 2184}
{"time": 1767162098.2641156, "phase": "train", "update": 2185, "total_env_steps": 6992000, "episode_reward": 0.27603062987327576, "value_loss": 0.008107317239046096, "policy_loss": -0.0014524415613585973, "dist_entropy": 0.6283333897590637, "actor_grad_norm": 0.10175120085477829, "critic_grad_norm": 0.05279010534286499, "ratio": 0.9997450709342957, "entropy": 0.6283333897590637, "incre_win_rate": 0.8695652173913043, "step": 2185}
{"time": 1767162102.586036, "phase": "train", "update": 2186, "total_env_steps": 6995200, "episode_reward": 0.27495449781417847, "value_loss": 0.008195766620337963, "policy_loss": -0.0014264995443738827, "dist_entropy": 0.6443350791931153, "actor_grad_norm": 0.0939386859536171, "critic_grad_norm": 0.04817710816860199, "ratio": 0.9999310374259949, "entropy": 0.6443350791931153, "incre_win_rate": 0.9130434782608695, "step": 2186}
{"time": 1767162106.863438, "phase": "train", "update": 2187, "total_env_steps": 6998400, "episode_reward": 0.27581074833869934, "value_loss": 0.007226195465773344, "policy_loss": -0.0013943098842503332, "dist_entropy": 0.6317914724349976, "actor_grad_norm": 0.08207511156797409, "critic_grad_norm": 0.08902004361152649, "ratio": 0.9999470710754395, "entropy": 0.6317914724349976, "incre_win_rate": 0.8888888888888888, "step": 2187}
{"time": 1767162111.161615, "phase": "train", "update": 2188, "total_env_steps": 7001600, "episode_reward": 0.26793718338012695, "value_loss": 0.009101967513561248, "policy_loss": -0.002009239459458456, "dist_entropy": 0.6319439172744751, "actor_grad_norm": 0.08701694756746292, "critic_grad_norm": 0.16560332477092743, "ratio": 0.9997618794441223, "entropy": 0.6319439172744751, "incre_win_rate": 0.8, "step": 2188}
{"time": 1767162115.4373462, "phase": "train", "update": 2189, "total_env_steps": 7004800, "episode_reward": 0.28116050362586975, "value_loss": 0.005818053800612688, "policy_loss": -0.00114194251504518, "dist_entropy": 0.6299821853637695, "actor_grad_norm": 0.077046699821949, "critic_grad_norm": 0.2280249446630478, "ratio": 1.000002145767212, "entropy": 0.6299821853637695, "incre_win_rate": 0.8913043478260869, "step": 2189}
{"time": 1767162119.767173, "phase": "train", "update": 2190, "total_env_steps": 7008000, "episode_reward": 0.26683154702186584, "value_loss": 0.006725315097719431, "policy_loss": -0.0012677865759378904, "dist_entropy": 0.6150083661079406, "actor_grad_norm": 0.07413854449987411, "critic_grad_norm": 0.17348968982696533, "ratio": 0.9997256398200989, "entropy": 0.6150083661079406, "incre_win_rate": 0.8863636363636364, "step": 2190}
{"time": 1767162124.1052692, "phase": "train", "update": 2191, "total_env_steps": 7011200, "episode_reward": 0.2629051208496094, "value_loss": 0.009610425680875778, "policy_loss": -0.0013460759343239203, "dist_entropy": 0.6151735424995423, "actor_grad_norm": 0.08275526016950607, "critic_grad_norm": 0.11814125627279282, "ratio": 1.0002896785736084, "entropy": 0.6151735424995423, "incre_win_rate": 0.8333333333333334, "step": 2191}
{"time": 1767162128.4439337, "phase": "train", "update": 2192, "total_env_steps": 7014400, "episode_reward": 0.27358341217041016, "value_loss": 0.00769605515524745, "policy_loss": -0.0008188494658480039, "dist_entropy": 0.6363637447357178, "actor_grad_norm": 0.08731383085250854, "critic_grad_norm": 0.07069098204374313, "ratio": 1.0002098083496094, "entropy": 0.6363637447357178, "incre_win_rate": 0.9111111111111111, "step": 2192}
{"time": 1767162132.7633493, "phase": "train", "update": 2193, "total_env_steps": 7017600, "episode_reward": 0.2803073227405548, "value_loss": 0.003999926103278995, "policy_loss": -0.0013641907619248883, "dist_entropy": 0.6529191851615905, "actor_grad_norm": 0.08135576546192169, "critic_grad_norm": 0.09691022336483002, "ratio": 1.0000249147415161, "entropy": 0.6529191851615905, "incre_win_rate": 0.9166666666666666, "step": 2193}
{"time": 1767162137.0782866, "phase": "train", "update": 2194, "total_env_steps": 7020800, "episode_reward": 0.266112357378006, "value_loss": 0.007747664116322994, "policy_loss": -0.0011780818786101932, "dist_entropy": 0.6557237029075622, "actor_grad_norm": 0.07511251419782639, "critic_grad_norm": 0.0731607973575592, "ratio": 0.9997938275337219, "entropy": 0.6557237029075622, "incre_win_rate": 0.8837209302325582, "step": 2194}
{"time": 1767162141.5096729, "phase": "train", "update": 2195, "total_env_steps": 7024000, "episode_reward": 0.26446297764778137, "value_loss": 0.009486743435263633, "policy_loss": -0.001424542882705282, "dist_entropy": 0.6338564395904541, "actor_grad_norm": 0.0976020023226738, "critic_grad_norm": 0.14858803153038025, "ratio": 0.9995004534721375, "entropy": 0.6338564395904541, "incre_win_rate": 0.7777777777777778, "step": 2195}
{"time": 1767162145.8359084, "phase": "train", "update": 2196, "total_env_steps": 7027200, "episode_reward": 0.26354771852493286, "value_loss": 0.009008384868502617, "policy_loss": -0.001009949428173229, "dist_entropy": 0.6404516935348511, "actor_grad_norm": 0.06717240065336227, "critic_grad_norm": 0.11858885735273361, "ratio": 0.999715268611908, "entropy": 0.6404516935348511, "incre_win_rate": 0.8636363636363636, "step": 2196}
{"time": 1767162150.2103035, "phase": "train", "update": 2197, "total_env_steps": 7030400, "episode_reward": 0.27067673206329346, "value_loss": 0.007954313699156047, "policy_loss": -0.001195553720515008, "dist_entropy": 0.6597039341926575, "actor_grad_norm": 0.09639787673950195, "critic_grad_norm": 0.1334567368030548, "ratio": 1.0000637769699097, "entropy": 0.6597039341926575, "incre_win_rate": 0.9285714285714286, "step": 2197}
{"time": 1767162154.5112727, "phase": "train", "update": 2198, "total_env_steps": 7033600, "episode_reward": 0.2593977749347687, "value_loss": 0.0070833247154951096, "policy_loss": -0.0017167920688255123, "dist_entropy": 0.6468823790550232, "actor_grad_norm": 0.09288085997104645, "critic_grad_norm": 0.08128911256790161, "ratio": 0.9996552467346191, "entropy": 0.6468823790550232, "incre_win_rate": 0.8636363636363636, "step": 2198}
{"time": 1767162158.7947237, "phase": "train", "update": 2199, "total_env_steps": 7036800, "episode_reward": 0.25726407766342163, "value_loss": 0.00882783830165863, "policy_loss": -0.0015911909106144152, "dist_entropy": 0.662499463558197, "actor_grad_norm": 0.11171280592679977, "critic_grad_norm": 0.08753857016563416, "ratio": 0.9998170733451843, "entropy": 0.662499463558197, "incre_win_rate": 0.8, "step": 2199}
{"time": 1767162163.1047032, "phase": "train", "update": 2200, "total_env_steps": 7040000, "episode_reward": 0.28070777654647827, "value_loss": 0.00392295066267252, "policy_loss": -0.0009546547515498105, "dist_entropy": 0.6930771350860596, "actor_grad_norm": 0.09394347667694092, "critic_grad_norm": 0.17582064867019653, "ratio": 1.0003697872161865, "entropy": 0.6930771350860596, "incre_win_rate": 0.9772727272727273, "step": 2200}
{"time": 1767162167.3699758, "phase": "train", "update": 2201, "total_env_steps": 7043200, "episode_reward": 0.2698551416397095, "value_loss": 0.005365476012229919, "policy_loss": -0.0010378943249850891, "dist_entropy": 0.7012667894363404, "actor_grad_norm": 0.08178327232599258, "critic_grad_norm": 0.13321596384048462, "ratio": 0.9999819993972778, "entropy": 0.7012667894363404, "incre_win_rate": 0.9130434782608695, "step": 2201}
{"time": 1767162176.9037046, "phase": "eval", "update": 2201, "total_env_steps": 7043200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.700745033112582, "step": 2201}
{"time": 1767162181.2137976, "phase": "train", "update": 2202, "total_env_steps": 7046400, "episode_reward": 0.27948880195617676, "value_loss": 0.004692843370139599, "policy_loss": -0.0017277071829752799, "dist_entropy": 0.7104298710823059, "actor_grad_norm": 0.10654880851507187, "critic_grad_norm": 0.09289758652448654, "ratio": 0.9996033906936646, "entropy": 0.7104298710823059, "incre_win_rate": 0.9318181818181818, "step": 2202}
{"time": 1767162185.5118334, "phase": "train", "update": 2203, "total_env_steps": 7049600, "episode_reward": 0.2721921503543854, "value_loss": 0.004972339048981667, "policy_loss": -0.0009543052676794339, "dist_entropy": 0.6981133818626404, "actor_grad_norm": 0.08814243972301483, "critic_grad_norm": 0.08837468922138214, "ratio": 0.999886155128479, "entropy": 0.6981133818626404, "incre_win_rate": 0.9090909090909091, "step": 2203}
{"time": 1767162189.8602836, "phase": "train", "update": 2204, "total_env_steps": 7052800, "episode_reward": 0.27358806133270264, "value_loss": 0.0054800213314592835, "policy_loss": -0.001106661391553132, "dist_entropy": 0.6980041861534119, "actor_grad_norm": 0.0851060152053833, "critic_grad_norm": 0.05916723236441612, "ratio": 0.9994665384292603, "entropy": 0.6980041861534119, "incre_win_rate": 0.9333333333333333, "step": 2204}
{"time": 1767162194.2108989, "phase": "train", "update": 2205, "total_env_steps": 7056000, "episode_reward": 0.26897454261779785, "value_loss": 0.007753862999379635, "policy_loss": -0.0013213072526822244, "dist_entropy": 0.6953046917915344, "actor_grad_norm": 0.09123010188341141, "critic_grad_norm": 0.08454253524541855, "ratio": 1.0000174045562744, "entropy": 0.6953046917915344, "incre_win_rate": 0.8666666666666667, "step": 2205}
{"time": 1767162198.5554793, "phase": "train", "update": 2206, "total_env_steps": 7059200, "episode_reward": 0.2718750238418579, "value_loss": 0.005989262647926807, "policy_loss": -0.001134918379712957, "dist_entropy": 0.6971479892730713, "actor_grad_norm": 0.09568341076374054, "critic_grad_norm": 0.05384429916739464, "ratio": 1.0002174377441406, "entropy": 0.6971479892730713, "incre_win_rate": 0.8863636363636364, "step": 2206}
{"time": 1767162202.9144576, "phase": "train", "update": 2207, "total_env_steps": 7062400, "episode_reward": 0.271331250667572, "value_loss": 0.007608520425856113, "policy_loss": -0.0011269918498413745, "dist_entropy": 0.6788246631622314, "actor_grad_norm": 0.09834402054548264, "critic_grad_norm": 0.10403453558683395, "ratio": 1.0000712871551514, "entropy": 0.6788246631622314, "incre_win_rate": 0.8666666666666667, "step": 2207}
{"time": 1767162207.281899, "phase": "train", "update": 2208, "total_env_steps": 7065600, "episode_reward": 0.27064570784568787, "value_loss": 0.00919991247355938, "policy_loss": -0.001467457239126091, "dist_entropy": 0.6517461657524108, "actor_grad_norm": 0.10457026213407516, "critic_grad_norm": 0.058409836143255234, "ratio": 0.9999306797981262, "entropy": 0.6517461657524108, "incre_win_rate": 0.8444444444444444, "step": 2208}
{"time": 1767162211.6756785, "phase": "train", "update": 2209, "total_env_steps": 7068800, "episode_reward": 0.284631609916687, "value_loss": 0.004127477947622538, "policy_loss": -0.0011347507715754545, "dist_entropy": 0.6778316020965576, "actor_grad_norm": 0.08400234580039978, "critic_grad_norm": 0.12649908661842346, "ratio": 0.9998067021369934, "entropy": 0.6778316020965576, "incre_win_rate": 0.9787234042553191, "step": 2209}
{"time": 1767162216.0107036, "phase": "train", "update": 2210, "total_env_steps": 7072000, "episode_reward": 0.27565813064575195, "value_loss": 0.005821382906287908, "policy_loss": -0.0012605418694974445, "dist_entropy": 0.6611721038818359, "actor_grad_norm": 0.080763079226017, "critic_grad_norm": 0.05273396894335747, "ratio": 0.9998815655708313, "entropy": 0.6611721038818359, "incre_win_rate": 0.9318181818181818, "step": 2210}
{"time": 1767162220.8650942, "phase": "train", "update": 2211, "total_env_steps": 7075200, "episode_reward": 0.28224441409111023, "value_loss": 0.006552057527005673, "policy_loss": -0.0013282039120886325, "dist_entropy": 0.6687084197998047, "actor_grad_norm": 0.07894401997327805, "critic_grad_norm": 0.04838114604353905, "ratio": 1.000077486038208, "entropy": 0.6687084197998047, "incre_win_rate": 0.9347826086956522, "step": 2211}
{"time": 1767162225.2665591, "phase": "train", "update": 2212, "total_env_steps": 7078400, "episode_reward": 0.2798509895801544, "value_loss": 0.0034494464751333, "policy_loss": -0.0013117702424256805, "dist_entropy": 0.6881676554679871, "actor_grad_norm": 0.0862555131316185, "critic_grad_norm": 0.026939919218420982, "ratio": 1.0000059604644775, "entropy": 0.6881676554679871, "incre_win_rate": 0.9782608695652174, "step": 2212}
{"time": 1767162229.6155207, "phase": "train", "update": 2213, "total_env_steps": 7081600, "episode_reward": 0.2822102904319763, "value_loss": 0.0033851266372948883, "policy_loss": -0.0011176620042537167, "dist_entropy": 0.6925179719924927, "actor_grad_norm": 0.09780361503362656, "critic_grad_norm": 0.05197315290570259, "ratio": 0.9999210238456726, "entropy": 0.6925179719924927, "incre_win_rate": 0.9772727272727273, "step": 2213}
{"time": 1767162233.9457066, "phase": "train", "update": 2214, "total_env_steps": 7084800, "episode_reward": 0.2635192275047302, "value_loss": 0.006603542063385248, "policy_loss": -0.001170894271024281, "dist_entropy": 0.6952866315841675, "actor_grad_norm": 0.09039068222045898, "critic_grad_norm": 0.12279044836759567, "ratio": 0.9998241662979126, "entropy": 0.6952866315841675, "incre_win_rate": 0.8260869565217391, "step": 2214}
{"time": 1767162238.2471595, "phase": "train", "update": 2215, "total_env_steps": 7088000, "episode_reward": 0.27296513319015503, "value_loss": 0.008595963753759862, "policy_loss": -0.0013232781455776888, "dist_entropy": 0.689038872718811, "actor_grad_norm": 0.09508068859577179, "critic_grad_norm": 0.07277246564626694, "ratio": 1.0000829696655273, "entropy": 0.689038872718811, "incre_win_rate": 0.8604651162790697, "step": 2215}
{"time": 1767162242.573428, "phase": "train", "update": 2216, "total_env_steps": 7091200, "episode_reward": 0.25862839818000793, "value_loss": 0.010331115126609803, "policy_loss": -0.0013789197592158687, "dist_entropy": 0.692731511592865, "actor_grad_norm": 0.10045246034860611, "critic_grad_norm": 0.0924345999956131, "ratio": 0.9997642636299133, "entropy": 0.692731511592865, "incre_win_rate": 0.8043478260869565, "step": 2216}
{"time": 1767162246.9226415, "phase": "train", "update": 2217, "total_env_steps": 7094400, "episode_reward": 0.26951053738594055, "value_loss": 0.007661863695830107, "policy_loss": -0.0014843839363479106, "dist_entropy": 0.7140580654144287, "actor_grad_norm": 0.08753123134374619, "critic_grad_norm": 0.07339954376220703, "ratio": 0.9998845458030701, "entropy": 0.7140580654144287, "incre_win_rate": 0.8222222222222222, "step": 2217}
{"time": 1767162251.2538433, "phase": "train", "update": 2218, "total_env_steps": 7097600, "episode_reward": 0.27653974294662476, "value_loss": 0.007743711676448583, "policy_loss": -0.0014628648451360249, "dist_entropy": 0.7129980087280273, "actor_grad_norm": 0.07941629737615585, "critic_grad_norm": 0.07123754173517227, "ratio": 0.9997851252555847, "entropy": 0.7129980087280273, "incre_win_rate": 0.9347826086956522, "step": 2218}
{"time": 1767162255.5975978, "phase": "train", "update": 2219, "total_env_steps": 7100800, "episode_reward": 0.2701117694377899, "value_loss": 0.006098739802837372, "policy_loss": -0.0014868225611263774, "dist_entropy": 0.6998793125152588, "actor_grad_norm": 0.10848908871412277, "critic_grad_norm": 0.039855074137449265, "ratio": 0.999698281288147, "entropy": 0.6998793125152588, "incre_win_rate": 0.8604651162790697, "step": 2219}
{"time": 1767162259.9414048, "phase": "train", "update": 2220, "total_env_steps": 7104000, "episode_reward": 0.2660430669784546, "value_loss": 0.004960777796804905, "policy_loss": -0.0012382218035860149, "dist_entropy": 0.7015164971351624, "actor_grad_norm": 0.09714213758707047, "critic_grad_norm": 0.08679714798927307, "ratio": 1.0002126693725586, "entropy": 0.7015164971351624, "incre_win_rate": 0.9302325581395349, "step": 2220}
{"time": 1767162264.2938018, "phase": "train", "update": 2221, "total_env_steps": 7107200, "episode_reward": 0.27175548672676086, "value_loss": 0.006754085887223482, "policy_loss": -0.0012107661226546718, "dist_entropy": 0.69341641664505, "actor_grad_norm": 0.09342887997627258, "critic_grad_norm": 0.04719774052500725, "ratio": 1.0000286102294922, "entropy": 0.69341641664505, "incre_win_rate": 0.8837209302325582, "step": 2221}
{"time": 1767162273.847115, "phase": "eval", "update": 2221, "total_env_steps": 7107200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.903145695364238, "step": 2221}
{"time": 1767162278.1521785, "phase": "train", "update": 2222, "total_env_steps": 7110400, "episode_reward": 0.2766762971878052, "value_loss": 0.00624968372285366, "policy_loss": -0.0010787256896188425, "dist_entropy": 0.6901159524917603, "actor_grad_norm": 0.0975119099020958, "critic_grad_norm": 0.08917970210313797, "ratio": 0.9999300241470337, "entropy": 0.6901159524917603, "incre_win_rate": 0.9361702127659575, "step": 2222}
{"time": 1767162282.4476051, "phase": "train", "update": 2223, "total_env_steps": 7113600, "episode_reward": 0.2688865661621094, "value_loss": 0.006101248599588871, "policy_loss": -0.001476371888072947, "dist_entropy": 0.6700414180755615, "actor_grad_norm": 0.09480249136686325, "critic_grad_norm": 0.0865321159362793, "ratio": 0.9999967813491821, "entropy": 0.6700414180755615, "incre_win_rate": 0.8888888888888888, "step": 2223}
{"time": 1767162286.7013502, "phase": "train", "update": 2224, "total_env_steps": 7116800, "episode_reward": 0.26940035820007324, "value_loss": 0.006607447750866413, "policy_loss": -0.0012552479184058996, "dist_entropy": 0.6905649185180665, "actor_grad_norm": 0.07807856798171997, "critic_grad_norm": 0.06679733842611313, "ratio": 1.000009536743164, "entropy": 0.6905649185180665, "incre_win_rate": 0.8837209302325582, "step": 2224}
{"time": 1767162291.0248744, "phase": "train", "update": 2225, "total_env_steps": 7120000, "episode_reward": 0.2758723199367523, "value_loss": 0.0038182142656296492, "policy_loss": -0.0012304779936883393, "dist_entropy": 0.6767145395278931, "actor_grad_norm": 0.09929640591144562, "critic_grad_norm": 0.0740506649017334, "ratio": 0.9998872876167297, "entropy": 0.6767145395278931, "incre_win_rate": 0.9574468085106383, "step": 2225}
{"time": 1767162295.3399715, "phase": "train", "update": 2226, "total_env_steps": 7123200, "episode_reward": 0.26569846272468567, "value_loss": 0.010272105410695075, "policy_loss": -0.0013790029905705215, "dist_entropy": 0.6521950602531433, "actor_grad_norm": 0.09802401810884476, "critic_grad_norm": 0.18261288106441498, "ratio": 0.9999222159385681, "entropy": 0.6521950602531433, "incre_win_rate": 0.8292682926829268, "step": 2226}
{"time": 1767162299.6509495, "phase": "train", "update": 2227, "total_env_steps": 7126400, "episode_reward": 0.2657662332057953, "value_loss": 0.007750357501208782, "policy_loss": -0.0012196970010384333, "dist_entropy": 0.6609762191772461, "actor_grad_norm": 0.08076293766498566, "critic_grad_norm": 0.13206838071346283, "ratio": 1.0000799894332886, "entropy": 0.6609762191772461, "incre_win_rate": 0.8260869565217391, "step": 2227}
{"time": 1767162304.00413, "phase": "train", "update": 2228, "total_env_steps": 7129600, "episode_reward": 0.27058517932891846, "value_loss": 0.00848994068801403, "policy_loss": -0.0016169092829812826, "dist_entropy": 0.6648915410041809, "actor_grad_norm": 0.08774694055318832, "critic_grad_norm": 0.09216632694005966, "ratio": 0.9999980926513672, "entropy": 0.6648915410041809, "incre_win_rate": 0.8888888888888888, "step": 2228}
{"time": 1767162308.3351355, "phase": "train", "update": 2229, "total_env_steps": 7132800, "episode_reward": 0.28108030557632446, "value_loss": 0.0049588121473789215, "policy_loss": -0.0014414704014144685, "dist_entropy": 0.6405219078063965, "actor_grad_norm": 0.09267034381628036, "critic_grad_norm": 0.0843605026602745, "ratio": 1.0000360012054443, "entropy": 0.6405219078063965, "incre_win_rate": 0.9777777777777777, "step": 2229}
{"time": 1767162312.7080579, "phase": "train", "update": 2230, "total_env_steps": 7136000, "episode_reward": 0.26900455355644226, "value_loss": 0.004871146846562624, "policy_loss": -0.0011950069982276546, "dist_entropy": 0.6261623740196228, "actor_grad_norm": 0.10586684197187424, "critic_grad_norm": 0.10957498848438263, "ratio": 0.9998375177383423, "entropy": 0.6261623740196228, "incre_win_rate": 0.8888888888888888, "step": 2230}
{"time": 1767162317.0301933, "phase": "train", "update": 2231, "total_env_steps": 7139200, "episode_reward": 0.2646104097366333, "value_loss": 0.004927741270512343, "policy_loss": -0.0010673784141587816, "dist_entropy": 0.653041410446167, "actor_grad_norm": 0.08978234976530075, "critic_grad_norm": 0.08641838282346725, "ratio": 1.0002391338348389, "entropy": 0.653041410446167, "incre_win_rate": 0.8837209302325582, "step": 2231}
{"time": 1767162321.4059417, "phase": "train", "update": 2232, "total_env_steps": 7142400, "episode_reward": 0.2795239984989166, "value_loss": 0.0039023291785269974, "policy_loss": -0.0012970844201376508, "dist_entropy": 0.6563673615455627, "actor_grad_norm": 0.100956991314888, "critic_grad_norm": 0.06213369965553284, "ratio": 1.0002034902572632, "entropy": 0.6563673615455627, "incre_win_rate": 0.9555555555555556, "step": 2232}
{"time": 1767162325.7731576, "phase": "train", "update": 2233, "total_env_steps": 7145600, "episode_reward": 0.28070467710494995, "value_loss": 0.003171566454693675, "policy_loss": -0.0011720427276785017, "dist_entropy": 0.6680513024330139, "actor_grad_norm": 0.06492181867361069, "critic_grad_norm": 0.04236400127410889, "ratio": 1.0001857280731201, "entropy": 0.6680513024330139, "incre_win_rate": 0.9361702127659575, "step": 2233}
{"time": 1767162330.1114476, "phase": "train", "update": 2234, "total_env_steps": 7148800, "episode_reward": 0.2807326316833496, "value_loss": 0.003458380326628685, "policy_loss": -0.001148691837456539, "dist_entropy": 0.6609820365905762, "actor_grad_norm": 0.0814298689365387, "critic_grad_norm": 0.05140584707260132, "ratio": 1.000097632408142, "entropy": 0.6609820365905762, "incre_win_rate": 0.9545454545454546, "step": 2234}
{"time": 1767162334.5274606, "phase": "train", "update": 2235, "total_env_steps": 7152000, "episode_reward": 0.2795219123363495, "value_loss": 0.0028496764600276945, "policy_loss": -0.0012440120949349875, "dist_entropy": 0.6586370825767517, "actor_grad_norm": 0.08066672086715698, "critic_grad_norm": 0.024878209456801414, "ratio": 0.9998896718025208, "entropy": 0.6586370825767517, "incre_win_rate": 0.9777777777777777, "step": 2235}
{"time": 1767162339.2058601, "phase": "train", "update": 2236, "total_env_steps": 7155200, "episode_reward": 0.279707133769989, "value_loss": 0.003699416760355234, "policy_loss": -0.0013002045438810228, "dist_entropy": 0.6245246052742004, "actor_grad_norm": 0.07881023734807968, "critic_grad_norm": 0.022190267220139503, "ratio": 1.0002373456954956, "entropy": 0.6245246052742004, "incre_win_rate": 0.9782608695652174, "step": 2236}
{"time": 1767162343.5004153, "phase": "train", "update": 2237, "total_env_steps": 7158400, "episode_reward": 0.27742135524749756, "value_loss": 0.005703829228878021, "policy_loss": -0.0012781214635886329, "dist_entropy": 0.6364224433898926, "actor_grad_norm": 0.0972394049167633, "critic_grad_norm": 0.04146893322467804, "ratio": 0.999814510345459, "entropy": 0.6364224433898926, "incre_win_rate": 0.9090909090909091, "step": 2237}
{"time": 1767162347.7552738, "phase": "train", "update": 2238, "total_env_steps": 7161600, "episode_reward": 0.2772216796875, "value_loss": 0.0031267613172531127, "policy_loss": -0.001292245331376307, "dist_entropy": 0.6039868474006653, "actor_grad_norm": 0.09519421309232712, "critic_grad_norm": 0.09422051161527634, "ratio": 0.9998926520347595, "entropy": 0.6039868474006653, "incre_win_rate": 0.9777777777777777, "step": 2238}
{"time": 1767162352.088244, "phase": "train", "update": 2239, "total_env_steps": 7164800, "episode_reward": 0.28214144706726074, "value_loss": 0.003981344541534782, "policy_loss": -0.0012887871786084304, "dist_entropy": 0.6217258930206299, "actor_grad_norm": 0.09193675965070724, "critic_grad_norm": 0.07032794505357742, "ratio": 1.0000693798065186, "entropy": 0.6217258930206299, "incre_win_rate": 0.9555555555555556, "step": 2239}
{"time": 1767162356.3875344, "phase": "train", "update": 2240, "total_env_steps": 7168000, "episode_reward": 0.276378333568573, "value_loss": 0.0032434192020446063, "policy_loss": -0.0012402043312135902, "dist_entropy": 0.5967805743217468, "actor_grad_norm": 0.09720617532730103, "critic_grad_norm": 0.031744230538606644, "ratio": 1.0003180503845215, "entropy": 0.5967805743217468, "incre_win_rate": 0.9555555555555556, "step": 2240}
{"time": 1767162360.7136629, "phase": "train", "update": 2241, "total_env_steps": 7171200, "episode_reward": 0.2812582850456238, "value_loss": 0.005116517934948206, "policy_loss": -0.001372192258517657, "dist_entropy": 0.6067467927932739, "actor_grad_norm": 0.09043912589550018, "critic_grad_norm": 0.0984148383140564, "ratio": 1.0000524520874023, "entropy": 0.6067467927932739, "incre_win_rate": 0.8936170212765957, "step": 2241}
{"time": 1767162370.188341, "phase": "eval", "update": 2241, "total_env_steps": 7171200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.84028352649007, "step": 2241}
{"time": 1767162374.4914403, "phase": "train", "update": 2242, "total_env_steps": 7174400, "episode_reward": 0.2814735174179077, "value_loss": 0.004409482330083847, "policy_loss": -0.0011451166811646373, "dist_entropy": 0.6244392037391663, "actor_grad_norm": 0.07779747992753983, "critic_grad_norm": 0.09257394075393677, "ratio": 0.9997965097427368, "entropy": 0.6244392037391663, "incre_win_rate": 0.9787234042553191, "step": 2242}
{"time": 1767162378.8119133, "phase": "train", "update": 2243, "total_env_steps": 7177600, "episode_reward": 0.2815009355545044, "value_loss": 0.00545477382838726, "policy_loss": -0.0014086670132904544, "dist_entropy": 0.6443911910057067, "actor_grad_norm": 0.08951430767774582, "critic_grad_norm": 0.053844351321458817, "ratio": 0.9998024106025696, "entropy": 0.6443911910057067, "incre_win_rate": 0.9318181818181818, "step": 2243}
{"time": 1767162383.1355894, "phase": "train", "update": 2244, "total_env_steps": 7180800, "episode_reward": 0.2820943593978882, "value_loss": 0.004458901379257441, "policy_loss": -0.0010282147434014012, "dist_entropy": 0.6329164862632751, "actor_grad_norm": 0.07456310093402863, "critic_grad_norm": 0.07941063493490219, "ratio": 1.0002083778381348, "entropy": 0.6329164862632751, "incre_win_rate": 0.9555555555555556, "step": 2244}
{"time": 1767162387.4781244, "phase": "train", "update": 2245, "total_env_steps": 7184000, "episode_reward": 0.2739729881286621, "value_loss": 0.006634815689176321, "policy_loss": -0.0013545604242599651, "dist_entropy": 0.6120646357536316, "actor_grad_norm": 0.1008930578827858, "critic_grad_norm": 0.037669774144887924, "ratio": 1.0001745223999023, "entropy": 0.6120646357536316, "incre_win_rate": 0.9090909090909091, "step": 2245}
{"time": 1767162391.8513846, "phase": "train", "update": 2246, "total_env_steps": 7187200, "episode_reward": 0.28716886043548584, "value_loss": 0.004872926976531744, "policy_loss": -0.0010352194973030748, "dist_entropy": 0.6119969725608826, "actor_grad_norm": 0.09440173953771591, "critic_grad_norm": 0.05864013358950615, "ratio": 1.0002354383468628, "entropy": 0.6119969725608826, "incre_win_rate": 0.9787234042553191, "step": 2246}
{"time": 1767162396.1933377, "phase": "train", "update": 2247, "total_env_steps": 7190400, "episode_reward": 0.28254449367523193, "value_loss": 0.004370957612991333, "policy_loss": -0.0012407107400054685, "dist_entropy": 0.6309130787849426, "actor_grad_norm": 0.08062433451414108, "critic_grad_norm": 0.05410560593008995, "ratio": 1.0000237226486206, "entropy": 0.6309130787849426, "incre_win_rate": 0.9574468085106383, "step": 2247}
{"time": 1767162400.557141, "phase": "train", "update": 2248, "total_env_steps": 7193600, "episode_reward": 0.2793460190296173, "value_loss": 0.00466204397380352, "policy_loss": -0.0013933662329977281, "dist_entropy": 0.6362545251846313, "actor_grad_norm": 0.07412871718406677, "critic_grad_norm": 0.10145186632871628, "ratio": 0.9998173117637634, "entropy": 0.6362545251846313, "incre_win_rate": 0.9545454545454546, "step": 2248}
{"time": 1767162404.8745353, "phase": "train", "update": 2249, "total_env_steps": 7196800, "episode_reward": 0.2824539542198181, "value_loss": 0.005933906510472297, "policy_loss": -0.0011841752148185948, "dist_entropy": 0.6275088548660278, "actor_grad_norm": 0.07363110035657883, "critic_grad_norm": 0.051452577114105225, "ratio": 1.0000733137130737, "entropy": 0.6275088548660278, "incre_win_rate": 0.9347826086956522, "step": 2249}
{"time": 1767162409.188136, "phase": "train", "update": 2250, "total_env_steps": 7200000, "episode_reward": 0.2801365852355957, "value_loss": 0.0034120975993573665, "policy_loss": -0.0011641488054130456, "dist_entropy": 0.6293065905570984, "actor_grad_norm": 0.0878712460398674, "critic_grad_norm": 0.05131421610713005, "ratio": 1.0002567768096924, "entropy": 0.6293065905570984, "incre_win_rate": 0.9333333333333333, "step": 2250}
{"time": 1767162413.4928153, "phase": "train", "update": 2251, "total_env_steps": 7203200, "episode_reward": 0.2751091718673706, "value_loss": 0.005046297889202833, "policy_loss": -0.001460659817253429, "dist_entropy": 0.6286045432090759, "actor_grad_norm": 0.09859894961118698, "critic_grad_norm": 0.037759359925985336, "ratio": 0.999794602394104, "entropy": 0.6286045432090759, "incre_win_rate": 0.8913043478260869, "step": 2251}
{"time": 1767162417.8002806, "phase": "train", "update": 2252, "total_env_steps": 7206400, "episode_reward": 0.286502480506897, "value_loss": 0.004655360337346792, "policy_loss": -0.000921505713041082, "dist_entropy": 0.6452755570411682, "actor_grad_norm": 0.09152491390705109, "critic_grad_norm": 0.043603286147117615, "ratio": 1.0002862215042114, "entropy": 0.6452755570411682, "incre_win_rate": 0.9777777777777777, "step": 2252}
{"time": 1767162422.128431, "phase": "train", "update": 2253, "total_env_steps": 7209600, "episode_reward": 0.27688637375831604, "value_loss": 0.005823569558560848, "policy_loss": -0.000980539718767659, "dist_entropy": 0.6326265573501587, "actor_grad_norm": 0.08038616180419922, "critic_grad_norm": 0.06899090856313705, "ratio": 0.9998897910118103, "entropy": 0.6326265573501587, "incre_win_rate": 0.9545454545454546, "step": 2253}
{"time": 1767162426.4560523, "phase": "train", "update": 2254, "total_env_steps": 7212800, "episode_reward": 0.2807326018810272, "value_loss": 0.004111741855740547, "policy_loss": -0.0011188056534654268, "dist_entropy": 0.6417548418045044, "actor_grad_norm": 0.08524692058563232, "critic_grad_norm": 0.035117264837026596, "ratio": 0.9997686743736267, "entropy": 0.6417548418045044, "incre_win_rate": 0.9583333333333334, "step": 2254}
{"time": 1767162430.8470538, "phase": "train", "update": 2255, "total_env_steps": 7216000, "episode_reward": 0.2886796295642853, "value_loss": 0.0032479623332619667, "policy_loss": -0.0011440289520297854, "dist_entropy": 0.6402977705001831, "actor_grad_norm": 0.07730530202388763, "critic_grad_norm": 0.045171286910772324, "ratio": 0.9999435544013977, "entropy": 0.6402977705001831, "incre_win_rate": 0.9777777777777777, "step": 2255}
{"time": 1767162435.2360604, "phase": "train", "update": 2256, "total_env_steps": 7219200, "episode_reward": 0.27565810084342957, "value_loss": 0.007359559182077646, "policy_loss": -0.0015130098568087113, "dist_entropy": 0.6360902428627014, "actor_grad_norm": 0.08599893748760223, "critic_grad_norm": 0.1377400904893875, "ratio": 1.000116229057312, "entropy": 0.6360902428627014, "incre_win_rate": 0.8695652173913043, "step": 2256}
{"time": 1767162439.6356032, "phase": "train", "update": 2257, "total_env_steps": 7222400, "episode_reward": 0.2878890931606293, "value_loss": 0.0034136335365474225, "policy_loss": -0.0012767594338388478, "dist_entropy": 0.6133013606071472, "actor_grad_norm": 0.08424405008554459, "critic_grad_norm": 0.11189769953489304, "ratio": 1.0000789165496826, "entropy": 0.6133013606071472, "incre_win_rate": 0.9791666666666666, "step": 2257}
{"time": 1767162443.9824483, "phase": "train", "update": 2258, "total_env_steps": 7225600, "episode_reward": 0.277950644493103, "value_loss": 0.0053319806233048436, "policy_loss": -0.0010584701257648987, "dist_entropy": 0.6285221457481385, "actor_grad_norm": 0.06858300417661667, "critic_grad_norm": 0.07522868365049362, "ratio": 1.0000447034835815, "entropy": 0.6285221457481385, "incre_win_rate": 0.9130434782608695, "step": 2258}
{"time": 1767162448.268131, "phase": "train", "update": 2259, "total_env_steps": 7228800, "episode_reward": 0.2710823714733124, "value_loss": 0.006702118925750256, "policy_loss": -0.0015289641749035355, "dist_entropy": 0.60411297082901, "actor_grad_norm": 0.09081723541021347, "critic_grad_norm": 0.0680832788348198, "ratio": 0.9996450543403625, "entropy": 0.60411297082901, "incre_win_rate": 0.9047619047619048, "step": 2259}
{"time": 1767162452.629358, "phase": "train", "update": 2260, "total_env_steps": 7232000, "episode_reward": 0.2789968252182007, "value_loss": 0.004353443905711174, "policy_loss": -0.0014502341313374246, "dist_entropy": 0.6142688632011414, "actor_grad_norm": 0.07202241569757462, "critic_grad_norm": 0.07737240940332413, "ratio": 1.0000461339950562, "entropy": 0.6142688632011414, "incre_win_rate": 0.9347826086956522, "step": 2260}
{"time": 1767162456.9480195, "phase": "train", "update": 2261, "total_env_steps": 7235200, "episode_reward": 0.2715831995010376, "value_loss": 0.008119679801166058, "policy_loss": -0.0011188874398143866, "dist_entropy": 0.6176766872406005, "actor_grad_norm": 0.07879888266324997, "critic_grad_norm": 0.102364681661129, "ratio": 1.0000271797180176, "entropy": 0.6176766872406005, "incre_win_rate": 0.8913043478260869, "step": 2261}
{"time": 1767162466.2094445, "phase": "eval", "update": 2261, "total_env_steps": 7235200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.913389900662253, "step": 2261}
{"time": 1767162470.528401, "phase": "train", "update": 2262, "total_env_steps": 7238400, "episode_reward": 0.2893543243408203, "value_loss": 0.0050707033835351465, "policy_loss": -0.0012338912421078873, "dist_entropy": 0.6200987815856933, "actor_grad_norm": 0.07389591634273529, "critic_grad_norm": 0.0522921159863472, "ratio": 1.0001716613769531, "entropy": 0.6200987815856933, "incre_win_rate": 0.9777777777777777, "step": 2262}
{"time": 1767162474.8419533, "phase": "train", "update": 2263, "total_env_steps": 7241600, "episode_reward": 0.2753342390060425, "value_loss": 0.007552566565573215, "policy_loss": -0.0013146403357851, "dist_entropy": 0.5993173360824585, "actor_grad_norm": 0.09329663962125778, "critic_grad_norm": 0.0856415331363678, "ratio": 1.0002249479293823, "entropy": 0.5993173360824585, "incre_win_rate": 0.8936170212765957, "step": 2263}
{"time": 1767162479.1495638, "phase": "train", "update": 2264, "total_env_steps": 7244800, "episode_reward": 0.2876366078853607, "value_loss": 0.003922696132212878, "policy_loss": -0.0011040981862610265, "dist_entropy": 0.6110936284065247, "actor_grad_norm": 0.09142597764730453, "critic_grad_norm": 0.11734235286712646, "ratio": 0.9996038675308228, "entropy": 0.6110936284065247, "incre_win_rate": 0.9782608695652174, "step": 2264}
{"time": 1767162483.4763813, "phase": "train", "update": 2265, "total_env_steps": 7248000, "episode_reward": 0.27555879950523376, "value_loss": 0.004700639005750418, "policy_loss": -0.0009400194863900424, "dist_entropy": 0.6185707569122314, "actor_grad_norm": 0.09697709232568741, "critic_grad_norm": 0.09193024784326553, "ratio": 1.000311255455017, "entropy": 0.6185707569122314, "incre_win_rate": 0.9545454545454546, "step": 2265}
{"time": 1767162487.7971864, "phase": "train", "update": 2266, "total_env_steps": 7251200, "episode_reward": 0.2755163609981537, "value_loss": 0.003938489779829979, "policy_loss": -0.0013573494682145083, "dist_entropy": 0.6190822839736938, "actor_grad_norm": 0.09589151293039322, "critic_grad_norm": 0.08560221642255783, "ratio": 0.9999756217002869, "entropy": 0.6190822839736938, "incre_win_rate": 0.9555555555555556, "step": 2266}
{"time": 1767162492.1560886, "phase": "train", "update": 2267, "total_env_steps": 7254400, "episode_reward": 0.2795323133468628, "value_loss": 0.004175188764929771, "policy_loss": -0.0016571243646581024, "dist_entropy": 0.6215240716934204, "actor_grad_norm": 0.10669815540313721, "critic_grad_norm": 0.07558154314756393, "ratio": 1.0000139474868774, "entropy": 0.6215240716934204, "incre_win_rate": 0.9777777777777777, "step": 2267}
{"time": 1767162496.5319643, "phase": "train", "update": 2268, "total_env_steps": 7257600, "episode_reward": 0.2864528298377991, "value_loss": 0.0038974513299763203, "policy_loss": -0.0009226159690598479, "dist_entropy": 0.6288986682891846, "actor_grad_norm": 0.07681018114089966, "critic_grad_norm": 0.07720396667718887, "ratio": 1.0001866817474365, "entropy": 0.6288986682891846, "incre_win_rate": 0.9347826086956522, "step": 2268}
{"time": 1767162500.9105988, "phase": "train", "update": 2269, "total_env_steps": 7260800, "episode_reward": 0.2801448702812195, "value_loss": 0.003615983296185732, "policy_loss": -0.0010316219133969184, "dist_entropy": 0.6267538189888, "actor_grad_norm": 0.09326028823852539, "critic_grad_norm": 0.044904910027980804, "ratio": 1.0002501010894775, "entropy": 0.6267538189888, "incre_win_rate": 0.9347826086956522, "step": 2269}
{"time": 1767162505.2621925, "phase": "train", "update": 2270, "total_env_steps": 7264000, "episode_reward": 0.27477961778640747, "value_loss": 0.005071123782545328, "policy_loss": -0.001243655718298964, "dist_entropy": 0.6182436108589172, "actor_grad_norm": 0.08962538838386536, "critic_grad_norm": 0.0518970862030983, "ratio": 1.000038981437683, "entropy": 0.6182436108589172, "incre_win_rate": 0.9333333333333333, "step": 2270}
{"time": 1767162509.6172936, "phase": "train", "update": 2271, "total_env_steps": 7267200, "episode_reward": 0.2863979935646057, "value_loss": 0.00491676814854145, "policy_loss": -0.0015630445932782067, "dist_entropy": 0.6373170137405395, "actor_grad_norm": 0.1157500371336937, "critic_grad_norm": 0.05089884623885155, "ratio": 1.0000026226043701, "entropy": 0.6373170137405395, "incre_win_rate": 0.9347826086956522, "step": 2271}
{"time": 1767162513.9162052, "phase": "train", "update": 2272, "total_env_steps": 7270400, "episode_reward": 0.2569955587387085, "value_loss": 0.01256365180015564, "policy_loss": -0.0008766401920944133, "dist_entropy": 0.6006457328796386, "actor_grad_norm": 0.0829017385840416, "critic_grad_norm": 0.17859342694282532, "ratio": 0.999647319316864, "entropy": 0.6006457328796386, "incre_win_rate": 0.7272727272727273, "step": 2272}
{"time": 1767162518.270162, "phase": "train", "update": 2273, "total_env_steps": 7273600, "episode_reward": 0.2840935289859772, "value_loss": 0.007048355415463448, "policy_loss": -0.0010135466860448973, "dist_entropy": 0.6348104119300843, "actor_grad_norm": 0.09668464958667755, "critic_grad_norm": 0.1606341451406479, "ratio": 1.0001078844070435, "entropy": 0.6348104119300843, "incre_win_rate": 0.9148936170212766, "step": 2273}
{"time": 1767162522.6388304, "phase": "train", "update": 2274, "total_env_steps": 7276800, "episode_reward": 0.2833392024040222, "value_loss": 0.004068344458937645, "policy_loss": -0.0010469699884456895, "dist_entropy": 0.6317631363868713, "actor_grad_norm": 0.0911049172282219, "critic_grad_norm": 0.15421263873577118, "ratio": 1.0001202821731567, "entropy": 0.6317631363868713, "incre_win_rate": 0.9347826086956522, "step": 2274}
{"time": 1767162527.011104, "phase": "train", "update": 2275, "total_env_steps": 7280000, "episode_reward": 0.2893134355545044, "value_loss": 0.006338847056031227, "policy_loss": -0.0012059610159766976, "dist_entropy": 0.6360864758491516, "actor_grad_norm": 0.08584531396627426, "critic_grad_norm": 0.07639521360397339, "ratio": 0.9999990463256836, "entropy": 0.6360864758491516, "incre_win_rate": 0.9361702127659575, "step": 2275}
{"time": 1767162531.3431265, "phase": "train", "update": 2276, "total_env_steps": 7283200, "episode_reward": 0.28081953525543213, "value_loss": 0.004365795757621527, "policy_loss": -0.00170081255288288, "dist_entropy": 0.6239282846450805, "actor_grad_norm": 0.1060771495103836, "critic_grad_norm": 0.048689909279346466, "ratio": 0.9998502135276794, "entropy": 0.6239282846450805, "incre_win_rate": 0.9130434782608695, "step": 2276}
{"time": 1767162535.6311662, "phase": "train", "update": 2277, "total_env_steps": 7286400, "episode_reward": 0.2595804035663605, "value_loss": 0.011573377437889576, "policy_loss": -0.001193327668013211, "dist_entropy": 0.5884777188301087, "actor_grad_norm": 0.09744114428758621, "critic_grad_norm": 0.23480725288391113, "ratio": 0.9998382925987244, "entropy": 0.5884777188301087, "incre_win_rate": 0.7555555555555555, "step": 2277}
{"time": 1767162539.955746, "phase": "train", "update": 2278, "total_env_steps": 7289600, "episode_reward": 0.274722695350647, "value_loss": 0.007904505636543036, "policy_loss": -0.0015133821629177645, "dist_entropy": 0.6324960589408875, "actor_grad_norm": 0.0974702537059784, "critic_grad_norm": 0.12998990714550018, "ratio": 0.9999015927314758, "entropy": 0.6324960589408875, "incre_win_rate": 0.8888888888888888, "step": 2278}
{"time": 1767162544.3309712, "phase": "train", "update": 2279, "total_env_steps": 7292800, "episode_reward": 0.26709023118019104, "value_loss": 0.009617742896080018, "policy_loss": -0.001128741457726079, "dist_entropy": 0.6290879964828491, "actor_grad_norm": 0.07770074903964996, "critic_grad_norm": 0.12347207218408585, "ratio": 1.000152587890625, "entropy": 0.6290879964828491, "incre_win_rate": 0.8181818181818182, "step": 2279}
{"time": 1767162548.7057045, "phase": "train", "update": 2280, "total_env_steps": 7296000, "episode_reward": 0.27089715003967285, "value_loss": 0.011586565338075162, "policy_loss": -0.001053816987912981, "dist_entropy": 0.6541664242744446, "actor_grad_norm": 0.08046537637710571, "critic_grad_norm": 0.06913375109434128, "ratio": 1.0000345706939697, "entropy": 0.6541664242744446, "incre_win_rate": 0.8, "step": 2280}
{"time": 1767162553.0417452, "phase": "train", "update": 2281, "total_env_steps": 7299200, "episode_reward": 0.28239238262176514, "value_loss": 0.0046113069169223305, "policy_loss": -0.0013475012204434479, "dist_entropy": 0.6716404795646668, "actor_grad_norm": 0.07856377214193344, "critic_grad_norm": 0.07153290510177612, "ratio": 0.9997990727424622, "entropy": 0.6716404795646668, "incre_win_rate": 0.9782608695652174, "step": 2281}
{"time": 1767162562.8442307, "phase": "eval", "update": 2281, "total_env_steps": 7299200, "eval_win_rate": 0.875, "eval_episode_reward": 19.25532905629139, "step": 2281}
{"time": 1767162567.1525526, "phase": "train", "update": 2282, "total_env_steps": 7302400, "episode_reward": 0.26430776715278625, "value_loss": 0.010107215307652951, "policy_loss": -0.0013056221574771598, "dist_entropy": 0.6428348898887635, "actor_grad_norm": 0.09190003573894501, "critic_grad_norm": 0.2096332609653473, "ratio": 0.9997647404670715, "entropy": 0.6428348898887635, "incre_win_rate": 0.75, "step": 2282}
{"time": 1767162571.4753098, "phase": "train", "update": 2283, "total_env_steps": 7305600, "episode_reward": 0.26819899678230286, "value_loss": 0.008027625735849142, "policy_loss": -0.001411308313835491, "dist_entropy": 0.6464820265769958, "actor_grad_norm": 0.0923188254237175, "critic_grad_norm": 0.1698392927646637, "ratio": 0.9998679161071777, "entropy": 0.6464820265769958, "incre_win_rate": 0.9318181818181818, "step": 2283}
{"time": 1767162575.8665116, "phase": "train", "update": 2284, "total_env_steps": 7308800, "episode_reward": 0.2742798328399658, "value_loss": 0.007459125109016895, "policy_loss": -0.0012331928465471264, "dist_entropy": 0.6381397843360901, "actor_grad_norm": 0.07799335569143295, "critic_grad_norm": 0.14162267744541168, "ratio": 1.0001300573349, "entropy": 0.6381397843360901, "incre_win_rate": 0.8958333333333334, "step": 2284}
{"time": 1767162580.150682, "phase": "train", "update": 2285, "total_env_steps": 7312000, "episode_reward": 0.2690598964691162, "value_loss": 0.008350582793354988, "policy_loss": -0.0016549124329429787, "dist_entropy": 0.6448649406433106, "actor_grad_norm": 0.11692523956298828, "critic_grad_norm": 0.11880256235599518, "ratio": 1.0001922845840454, "entropy": 0.6448649406433106, "incre_win_rate": 0.8604651162790697, "step": 2285}
{"time": 1767162584.457076, "phase": "train", "update": 2286, "total_env_steps": 7315200, "episode_reward": 0.27674150466918945, "value_loss": 0.009459317848086356, "policy_loss": -0.00099815621280257, "dist_entropy": 0.6455324530601502, "actor_grad_norm": 0.11867133527994156, "critic_grad_norm": 0.0888577327132225, "ratio": 0.99980229139328, "entropy": 0.6455324530601502, "incre_win_rate": 0.8695652173913043, "step": 2286}
{"time": 1767162618.1878827, "phase": "train", "update": 2287, "total_env_steps": 7318400, "episode_reward": 0.2612841725349426, "value_loss": 0.05727207586169243, "policy_loss": -0.0010310861660050464, "dist_entropy": 0.6422354340553283, "actor_grad_norm": 0.08675604313611984, "critic_grad_norm": 0.48060688376426697, "ratio": 0.9994794726371765, "entropy": 0.6422354340553283, "incre_win_rate": 0.85, "step": 2287}
{"time": 1767162622.4818575, "phase": "train", "update": 2288, "total_env_steps": 7321600, "episode_reward": 0.26911577582359314, "value_loss": 0.011389437317848205, "policy_loss": -0.001332442877709461, "dist_entropy": 0.6540306806564331, "actor_grad_norm": 0.10223149508237839, "critic_grad_norm": 0.23605473339557648, "ratio": 0.9999861121177673, "entropy": 0.6540306806564331, "incre_win_rate": 0.8888888888888888, "step": 2288}
{"time": 1767162626.8304765, "phase": "train", "update": 2289, "total_env_steps": 7324800, "episode_reward": 0.2735275328159332, "value_loss": 0.006929650530219078, "policy_loss": -0.001731643477788225, "dist_entropy": 0.6717397809028626, "actor_grad_norm": 0.10976677387952805, "critic_grad_norm": 0.2341577559709549, "ratio": 0.9997035264968872, "entropy": 0.6717397809028626, "incre_win_rate": 0.8936170212765957, "step": 2289}
{"time": 1767162631.1240897, "phase": "train", "update": 2290, "total_env_steps": 7328000, "episode_reward": 0.270997554063797, "value_loss": 0.012266225554049015, "policy_loss": -0.0009307927919905978, "dist_entropy": 0.659935200214386, "actor_grad_norm": 0.08863147348165512, "critic_grad_norm": 0.24075336754322052, "ratio": 1.0000243186950684, "entropy": 0.659935200214386, "incre_win_rate": 0.8604651162790697, "step": 2290}
{"time": 1767162635.4378216, "phase": "train", "update": 2291, "total_env_steps": 7331200, "episode_reward": 0.2706493139266968, "value_loss": 0.011030886881053447, "policy_loss": -0.0016371274139238778, "dist_entropy": 0.6475459814071656, "actor_grad_norm": 0.11392795294523239, "critic_grad_norm": 0.16948838531970978, "ratio": 1.0002319812774658, "entropy": 0.6475459814071656, "incre_win_rate": 0.8723404255319149, "step": 2291}
{"time": 1767162639.7414446, "phase": "train", "update": 2292, "total_env_steps": 7334400, "episode_reward": 0.2731669247150421, "value_loss": 0.009251316636800766, "policy_loss": -0.0010699654733382856, "dist_entropy": 0.6614360332489013, "actor_grad_norm": 0.07552354037761688, "critic_grad_norm": 0.13208812475204468, "ratio": 0.9998780488967896, "entropy": 0.6614360332489013, "incre_win_rate": 0.8372093023255814, "step": 2292}
{"time": 1767162644.0489125, "phase": "train", "update": 2293, "total_env_steps": 7337600, "episode_reward": 0.2731332778930664, "value_loss": 0.0096852608025074, "policy_loss": -0.0016195589952812562, "dist_entropy": 0.6616578102111816, "actor_grad_norm": 0.1020730510354042, "critic_grad_norm": 0.21992754936218262, "ratio": 0.9998347163200378, "entropy": 0.6616578102111816, "incre_win_rate": 0.9565217391304348, "step": 2293}
{"time": 1767162648.2830832, "phase": "train", "update": 2294, "total_env_steps": 7340800, "episode_reward": 0.27440395951271057, "value_loss": 0.0066989541985094546, "policy_loss": -0.0011816036832120514, "dist_entropy": 0.67823166847229, "actor_grad_norm": 0.09129216521978378, "critic_grad_norm": 0.13015872240066528, "ratio": 0.9994967579841614, "entropy": 0.67823166847229, "incre_win_rate": 0.8863636363636364, "step": 2294}
{"time": 1767162652.5879493, "phase": "train", "update": 2295, "total_env_steps": 7344000, "episode_reward": 0.2735735774040222, "value_loss": 0.006109332200139761, "policy_loss": -0.0013052062422104882, "dist_entropy": 0.6890062928199768, "actor_grad_norm": 0.10366132110357285, "critic_grad_norm": 0.08905836194753647, "ratio": 1.000100016593933, "entropy": 0.6890062928199768, "incre_win_rate": 0.9148936170212766, "step": 2295}
{"time": 1767162656.8595047, "phase": "train", "update": 2296, "total_env_steps": 7347200, "episode_reward": 0.26986393332481384, "value_loss": 0.008528977818787097, "policy_loss": -0.001386504602127303, "dist_entropy": 0.6879436612129212, "actor_grad_norm": 0.09064608812332153, "critic_grad_norm": 0.10311124473810196, "ratio": 0.9998299479484558, "entropy": 0.6879436612129212, "incre_win_rate": 0.9047619047619048, "step": 2296}
{"time": 1767162661.1378484, "phase": "train", "update": 2297, "total_env_steps": 7350400, "episode_reward": 0.2732274532318115, "value_loss": 0.008014790341258049, "policy_loss": -0.0012329229199718127, "dist_entropy": 0.6863394021987915, "actor_grad_norm": 0.07639817893505096, "critic_grad_norm": 0.12363876402378082, "ratio": 1.0002285242080688, "entropy": 0.6863394021987915, "incre_win_rate": 0.8695652173913043, "step": 2297}
{"time": 1767162665.4530568, "phase": "train", "update": 2298, "total_env_steps": 7353600, "episode_reward": 0.27409353852272034, "value_loss": 0.006792926043272018, "policy_loss": -0.0012608359722591444, "dist_entropy": 0.7056210041046143, "actor_grad_norm": 0.07988621294498444, "critic_grad_norm": 0.10085978358983994, "ratio": 0.9998003244400024, "entropy": 0.7056210041046143, "incre_win_rate": 0.8695652173913043, "step": 2298}
{"time": 1767162669.7543516, "phase": "train", "update": 2299, "total_env_steps": 7356800, "episode_reward": 0.27681654691696167, "value_loss": 0.009388136118650437, "policy_loss": -0.0015392826906666323, "dist_entropy": 0.7030817151069642, "actor_grad_norm": 0.09370114654302597, "critic_grad_norm": 0.17347055673599243, "ratio": 1.0001908540725708, "entropy": 0.7030817151069642, "incre_win_rate": 0.8888888888888888, "step": 2299}
{"time": 1767162674.0722828, "phase": "train", "update": 2300, "total_env_steps": 7360000, "episode_reward": 0.268884539604187, "value_loss": 0.008741161413490772, "policy_loss": -0.0013346256577769112, "dist_entropy": 0.7037387132644654, "actor_grad_norm": 0.0776512548327446, "critic_grad_norm": 0.08979535102844238, "ratio": 0.9996356964111328, "entropy": 0.7037387132644654, "incre_win_rate": 0.8666666666666667, "step": 2300}
{"time": 1767162678.35126, "phase": "train", "update": 2301, "total_env_steps": 7363200, "episode_reward": 0.25512003898620605, "value_loss": 0.010712898522615432, "policy_loss": -0.0015723277346545218, "dist_entropy": 0.6819038987159729, "actor_grad_norm": 0.09913754463195801, "critic_grad_norm": 0.05968058854341507, "ratio": 0.999839723110199, "entropy": 0.6819038987159729, "incre_win_rate": 0.7619047619047619, "step": 2301}
{"time": 1767162688.1480436, "phase": "eval", "update": 2301, "total_env_steps": 7363200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.512831125827816, "step": 2301}
{"time": 1767162692.4269109, "phase": "train", "update": 2302, "total_env_steps": 7366400, "episode_reward": 0.2756979465484619, "value_loss": 0.007496735546737909, "policy_loss": -0.0011038882339192923, "dist_entropy": 0.690587854385376, "actor_grad_norm": 0.09980888664722443, "critic_grad_norm": 0.19569548964500427, "ratio": 0.9995951652526855, "entropy": 0.690587854385376, "incre_win_rate": 0.8913043478260869, "step": 2302}
{"time": 1767162696.7604206, "phase": "train", "update": 2303, "total_env_steps": 7369600, "episode_reward": 0.2776520848274231, "value_loss": 0.006540278624743223, "policy_loss": -0.0010271265706933263, "dist_entropy": 0.7046319127082825, "actor_grad_norm": 0.09342753142118454, "critic_grad_norm": 0.15843218564987183, "ratio": 1.000451922416687, "entropy": 0.7046319127082825, "incre_win_rate": 0.9318181818181818, "step": 2303}
{"time": 1767162701.0925474, "phase": "train", "update": 2304, "total_env_steps": 7372800, "episode_reward": 0.26146575808525085, "value_loss": 0.011167112737894058, "policy_loss": -0.0013393581422178613, "dist_entropy": 0.6778221726417542, "actor_grad_norm": 0.08886674046516418, "critic_grad_norm": 0.1938740462064743, "ratio": 1.0000945329666138, "entropy": 0.6778221726417542, "incre_win_rate": 0.8260869565217391, "step": 2304}
{"time": 1767162705.423161, "phase": "train", "update": 2305, "total_env_steps": 7376000, "episode_reward": 0.26897507905960083, "value_loss": 0.013004365004599094, "policy_loss": -0.0013592946261653082, "dist_entropy": 0.6826593995094299, "actor_grad_norm": 0.08001642674207687, "critic_grad_norm": 0.15026496350765228, "ratio": 0.9997987151145935, "entropy": 0.6826593995094299, "incre_win_rate": 0.8409090909090909, "step": 2305}
{"time": 1767162709.7634337, "phase": "train", "update": 2306, "total_env_steps": 7379200, "episode_reward": 0.27709025144577026, "value_loss": 0.007580821309238673, "policy_loss": -0.0012236509620766611, "dist_entropy": 0.6923352718353272, "actor_grad_norm": 0.08463489264249802, "critic_grad_norm": 0.05399922654032707, "ratio": 0.9997575879096985, "entropy": 0.6923352718353272, "incre_win_rate": 0.9148936170212766, "step": 2306}
{"time": 1767162714.0705285, "phase": "train", "update": 2307, "total_env_steps": 7382400, "episode_reward": 0.283841073513031, "value_loss": 0.004500652756541967, "policy_loss": -0.0013877651525938007, "dist_entropy": 0.6748579502105713, "actor_grad_norm": 0.08084238320589066, "critic_grad_norm": 0.06574081629514694, "ratio": 0.9999417662620544, "entropy": 0.6748579502105713, "incre_win_rate": 0.9555555555555556, "step": 2307}
{"time": 1767162718.3704405, "phase": "train", "update": 2308, "total_env_steps": 7385600, "episode_reward": 0.26540666818618774, "value_loss": 0.009148797765374184, "policy_loss": -0.0012549280566645394, "dist_entropy": 0.6786912083625793, "actor_grad_norm": 0.0845932811498642, "critic_grad_norm": 0.08365605026483536, "ratio": 0.9997972846031189, "entropy": 0.6786912083625793, "incre_win_rate": 0.8809523809523809, "step": 2308}
{"time": 1767162722.671981, "phase": "train", "update": 2309, "total_env_steps": 7388800, "episode_reward": 0.2777116000652313, "value_loss": 0.0037212499883025885, "policy_loss": -0.0014102222729798664, "dist_entropy": 0.6861077070236206, "actor_grad_norm": 0.09151972830295563, "critic_grad_norm": 0.1836288422346115, "ratio": 1.0003048181533813, "entropy": 0.6861077070236206, "incre_win_rate": 0.9347826086956522, "step": 2309}
{"time": 1767162727.010591, "phase": "train", "update": 2310, "total_env_steps": 7392000, "episode_reward": 0.2863084673881531, "value_loss": 0.005019979923963547, "policy_loss": -0.0011661099145669595, "dist_entropy": 0.6752787828445435, "actor_grad_norm": 0.0896260067820549, "critic_grad_norm": 0.08154363930225372, "ratio": 1.00007963180542, "entropy": 0.6752787828445435, "incre_win_rate": 0.9574468085106383, "step": 2310}
{"time": 1767162731.3423772, "phase": "train", "update": 2311, "total_env_steps": 7395200, "episode_reward": 0.27237996459007263, "value_loss": 0.005569929629564286, "policy_loss": -0.0013357884669051856, "dist_entropy": 0.6767893075942993, "actor_grad_norm": 0.0927356481552124, "critic_grad_norm": 0.1226007491350174, "ratio": 0.9998226165771484, "entropy": 0.6767893075942993, "incre_win_rate": 0.8863636363636364, "step": 2311}
{"time": 1767162735.6859307, "phase": "train", "update": 2312, "total_env_steps": 7398400, "episode_reward": 0.2733567953109741, "value_loss": 0.0049063492566347126, "policy_loss": -0.0014196401683271632, "dist_entropy": 0.6914136528968811, "actor_grad_norm": 0.079659104347229, "critic_grad_norm": 0.08214467763900757, "ratio": 1.0001434087753296, "entropy": 0.6914136528968811, "incre_win_rate": 0.9565217391304348, "step": 2312}
{"time": 1767162740.0208077, "phase": "train", "update": 2313, "total_env_steps": 7401600, "episode_reward": 0.2838307321071625, "value_loss": 0.003169849421828985, "policy_loss": -0.001568451720150321, "dist_entropy": 0.679757559299469, "actor_grad_norm": 0.10419721901416779, "critic_grad_norm": 0.04419601708650589, "ratio": 0.9995408058166504, "entropy": 0.679757559299469, "incre_win_rate": 0.9545454545454546, "step": 2313}
{"time": 1767162744.3109813, "phase": "train", "update": 2314, "total_env_steps": 7404800, "episode_reward": 0.2766566574573517, "value_loss": 0.005071273073554039, "policy_loss": -0.0010118306381627917, "dist_entropy": 0.6710817694664002, "actor_grad_norm": 0.1015145555138588, "critic_grad_norm": 0.04346517100930214, "ratio": 1.000106692314148, "entropy": 0.6710817694664002, "incre_win_rate": 0.9111111111111111, "step": 2314}
{"time": 1767162748.62306, "phase": "train", "update": 2315, "total_env_steps": 7408000, "episode_reward": 0.2715687155723572, "value_loss": 0.008228763658553361, "policy_loss": -0.0014709459360631172, "dist_entropy": 0.6863322734832764, "actor_grad_norm": 0.09981169551610947, "critic_grad_norm": 0.05310894921422005, "ratio": 0.9997081756591797, "entropy": 0.6863322734832764, "incre_win_rate": 0.9148936170212766, "step": 2315}
{"time": 1767162752.9657702, "phase": "train", "update": 2316, "total_env_steps": 7411200, "episode_reward": 0.26517385244369507, "value_loss": 0.009678443521261215, "policy_loss": -0.0011634071535738145, "dist_entropy": 0.6684308886528015, "actor_grad_norm": 0.09289761632680893, "critic_grad_norm": 0.09709378331899643, "ratio": 1.0000683069229126, "entropy": 0.6684308886528015, "incre_win_rate": 0.813953488372093, "step": 2316}
{"time": 1767162757.310644, "phase": "train", "update": 2317, "total_env_steps": 7414400, "episode_reward": 0.27438583970069885, "value_loss": 0.007336543221026659, "policy_loss": -0.001474574839566145, "dist_entropy": 0.681301748752594, "actor_grad_norm": 0.08855219185352325, "critic_grad_norm": 0.09690999239683151, "ratio": 1.0000804662704468, "entropy": 0.681301748752594, "incre_win_rate": 0.8666666666666667, "step": 2317}
{"time": 1767162761.644246, "phase": "train", "update": 2318, "total_env_steps": 7417600, "episode_reward": 0.2720623314380646, "value_loss": 0.007705020532011986, "policy_loss": -0.0017839652295386088, "dist_entropy": 0.6882203102111817, "actor_grad_norm": 0.0924312099814415, "critic_grad_norm": 0.0724630057811737, "ratio": 0.9999597668647766, "entropy": 0.6882203102111817, "incre_win_rate": 0.8695652173913043, "step": 2318}
{"time": 1767162765.9569337, "phase": "train", "update": 2319, "total_env_steps": 7420800, "episode_reward": 0.2708764374256134, "value_loss": 0.00886402726173401, "policy_loss": -0.0014607647834353088, "dist_entropy": 0.68306884765625, "actor_grad_norm": 0.08231960982084274, "critic_grad_norm": 0.13467858731746674, "ratio": 1.0000605583190918, "entropy": 0.68306884765625, "incre_win_rate": 0.8409090909090909, "step": 2319}
{"time": 1767162770.2795157, "phase": "train", "update": 2320, "total_env_steps": 7424000, "episode_reward": 0.27493274211883545, "value_loss": 0.007242119032889604, "policy_loss": -0.0013361023294041984, "dist_entropy": 0.7203285336494446, "actor_grad_norm": 0.09399985522031784, "critic_grad_norm": 0.12972377240657806, "ratio": 0.9996001124382019, "entropy": 0.7203285336494446, "incre_win_rate": 0.8936170212765957, "step": 2320}
{"time": 1767162774.5669258, "phase": "train", "update": 2321, "total_env_steps": 7427200, "episode_reward": 0.2810647785663605, "value_loss": 0.005757781211286783, "policy_loss": -0.0018618711051132664, "dist_entropy": 0.7211185812950134, "actor_grad_norm": 0.10407727211713791, "critic_grad_norm": 0.14495138823986053, "ratio": 1.0006122589111328, "entropy": 0.7211185812950134, "incre_win_rate": 0.9333333333333333, "step": 2321}
{"time": 1767162784.218958, "phase": "eval", "update": 2321, "total_env_steps": 7427200, "eval_win_rate": 1.0, "eval_episode_reward": 20.0, "step": 2321}
{"time": 1767162788.4858823, "phase": "train", "update": 2322, "total_env_steps": 7430400, "episode_reward": 0.2672811448574066, "value_loss": 0.008071865420788527, "policy_loss": -0.0011431061876784553, "dist_entropy": 0.665788722038269, "actor_grad_norm": 0.08487996459007263, "critic_grad_norm": 0.08223970979452133, "ratio": 0.9999362826347351, "entropy": 0.665788722038269, "incre_win_rate": 0.8372093023255814, "step": 2322}
{"time": 1767162792.789988, "phase": "train", "update": 2323, "total_env_steps": 7433600, "episode_reward": 0.2788451910018921, "value_loss": 0.006121048517525196, "policy_loss": -0.0013682594013164184, "dist_entropy": 0.6930951356887818, "actor_grad_norm": 0.09865367412567139, "critic_grad_norm": 0.061913419514894485, "ratio": 0.9992673993110657, "entropy": 0.6930951356887818, "incre_win_rate": 0.9148936170212766, "step": 2323}
{"time": 1767162797.1181722, "phase": "train", "update": 2324, "total_env_steps": 7436800, "episode_reward": 0.26623088121414185, "value_loss": 0.012610781751573086, "policy_loss": -0.0014663708650512585, "dist_entropy": 0.6959153652191162, "actor_grad_norm": 0.09834805130958557, "critic_grad_norm": 0.22917349636554718, "ratio": 1.0000720024108887, "entropy": 0.6959153652191162, "incre_win_rate": 0.782608695652174, "step": 2324}
{"time": 1767162801.3965364, "phase": "train", "update": 2325, "total_env_steps": 7440000, "episode_reward": 0.27548325061798096, "value_loss": 0.005934237129986286, "policy_loss": -0.00134244643942516, "dist_entropy": 0.6977049231529235, "actor_grad_norm": 0.0835912749171257, "critic_grad_norm": 0.11626579612493515, "ratio": 0.9999430775642395, "entropy": 0.6977049231529235, "incre_win_rate": 0.9069767441860465, "step": 2325}
{"time": 1767162805.6883826, "phase": "train", "update": 2326, "total_env_steps": 7443200, "episode_reward": 0.2738203704357147, "value_loss": 0.0053076139651238915, "policy_loss": -0.0013219588337197053, "dist_entropy": 0.7071800827980042, "actor_grad_norm": 0.0899718776345253, "critic_grad_norm": 0.09024889767169952, "ratio": 0.9996285438537598, "entropy": 0.7071800827980042, "incre_win_rate": 0.9148936170212766, "step": 2326}
{"time": 1767162809.9063861, "phase": "train", "update": 2327, "total_env_steps": 7446400, "episode_reward": 0.27429068088531494, "value_loss": 0.007497814949601889, "policy_loss": -0.0015716652271919429, "dist_entropy": 0.7009687900543213, "actor_grad_norm": 0.08840500563383102, "critic_grad_norm": 0.1214548870921135, "ratio": 0.9998471140861511, "entropy": 0.7009687900543213, "incre_win_rate": 0.8409090909090909, "step": 2327}
{"time": 1767162814.2050202, "phase": "train", "update": 2328, "total_env_steps": 7449600, "episode_reward": 0.28104254603385925, "value_loss": 0.007359447330236435, "policy_loss": -0.0011540131542894017, "dist_entropy": 0.7223776340484619, "actor_grad_norm": 0.09282004833221436, "critic_grad_norm": 0.10804995149374008, "ratio": 0.99989253282547, "entropy": 0.7223776340484619, "incre_win_rate": 0.9148936170212766, "step": 2328}
{"time": 1767162818.4311922, "phase": "train", "update": 2329, "total_env_steps": 7452800, "episode_reward": 0.2594267427921295, "value_loss": 0.007457525841891766, "policy_loss": -0.001552317771468381, "dist_entropy": 0.708680272102356, "actor_grad_norm": 0.08636321872472763, "critic_grad_norm": 0.10277660936117172, "ratio": 0.9999740719795227, "entropy": 0.708680272102356, "incre_win_rate": 0.8604651162790697, "step": 2329}
{"time": 1767162822.706638, "phase": "train", "update": 2330, "total_env_steps": 7456000, "episode_reward": 0.27034714818000793, "value_loss": 0.006151783932000399, "policy_loss": -0.0013590664683576393, "dist_entropy": 0.6998573184013367, "actor_grad_norm": 0.0753793865442276, "critic_grad_norm": 0.0928332731127739, "ratio": 0.9996929168701172, "entropy": 0.6998573184013367, "incre_win_rate": 0.9090909090909091, "step": 2330}
{"time": 1767162826.9810998, "phase": "train", "update": 2331, "total_env_steps": 7459200, "episode_reward": 0.2718987762928009, "value_loss": 0.0059287303127348425, "policy_loss": -0.0014423678356408232, "dist_entropy": 0.7039822578430176, "actor_grad_norm": 0.0894811674952507, "critic_grad_norm": 0.0747154951095581, "ratio": 0.9997396469116211, "entropy": 0.7039822578430176, "incre_win_rate": 0.8863636363636364, "step": 2331}
{"time": 1767162831.2778375, "phase": "train", "update": 2332, "total_env_steps": 7462400, "episode_reward": 0.2694314122200012, "value_loss": 0.007145681604743004, "policy_loss": -0.0012887310017219988, "dist_entropy": 0.6948628306388855, "actor_grad_norm": 0.09542785584926605, "critic_grad_norm": 0.04397120699286461, "ratio": 0.9999107718467712, "entropy": 0.6948628306388855, "incre_win_rate": 0.8888888888888888, "step": 2332}
{"time": 1767162835.5880451, "phase": "train", "update": 2333, "total_env_steps": 7465600, "episode_reward": 0.27783524990081787, "value_loss": 0.0050192358903586864, "policy_loss": -0.0010458489013302596, "dist_entropy": 0.7342216610908509, "actor_grad_norm": 0.08641502261161804, "critic_grad_norm": 0.08341263979673386, "ratio": 1.0000956058502197, "entropy": 0.7342216610908509, "incre_win_rate": 0.9555555555555556, "step": 2333}
{"time": 1767162839.887793, "phase": "train", "update": 2334, "total_env_steps": 7468800, "episode_reward": 0.2717379033565521, "value_loss": 0.003716817731037736, "policy_loss": -0.00136916284540618, "dist_entropy": 0.7065824151039124, "actor_grad_norm": 0.09973229467868805, "critic_grad_norm": 0.02838086150586605, "ratio": 1.000017523765564, "entropy": 0.7065824151039124, "incre_win_rate": 0.9767441860465116, "step": 2334}
{"time": 1767162844.2211318, "phase": "train", "update": 2335, "total_env_steps": 7472000, "episode_reward": 0.26671773195266724, "value_loss": 0.0054492662660777565, "policy_loss": -0.0010201830333514295, "dist_entropy": 0.7141436219215394, "actor_grad_norm": 0.09176776558160782, "critic_grad_norm": 0.07309660315513611, "ratio": 0.9998287558555603, "entropy": 0.7141436219215394, "incre_win_rate": 0.8888888888888888, "step": 2335}
{"time": 1767162848.5408103, "phase": "train", "update": 2336, "total_env_steps": 7475200, "episode_reward": 0.27998343110084534, "value_loss": 0.0035560701508075, "policy_loss": -0.0014022746999227565, "dist_entropy": 0.7176173567771912, "actor_grad_norm": 0.10419566929340363, "critic_grad_norm": 0.054192978888750076, "ratio": 0.9998984336853027, "entropy": 0.7176173567771912, "incre_win_rate": 0.9782608695652174, "step": 2336}
{"time": 1767162852.816562, "phase": "train", "update": 2337, "total_env_steps": 7478400, "episode_reward": 0.26132193207740784, "value_loss": 0.007576531358063221, "policy_loss": -0.0015353895608678058, "dist_entropy": 0.679128634929657, "actor_grad_norm": 0.09016697853803635, "critic_grad_norm": 0.11563348770141602, "ratio": 1.0000903606414795, "entropy": 0.679128634929657, "incre_win_rate": 0.8181818181818182, "step": 2337}
{"time": 1767162857.1411393, "phase": "train", "update": 2338, "total_env_steps": 7481600, "episode_reward": 0.27125415205955505, "value_loss": 0.005980848055332899, "policy_loss": -0.0017559450074433158, "dist_entropy": 0.6908377528190612, "actor_grad_norm": 0.09442537277936935, "critic_grad_norm": 0.044560253620147705, "ratio": 0.999921977519989, "entropy": 0.6908377528190612, "incre_win_rate": 0.8809523809523809, "step": 2338}
{"time": 1767162861.412129, "phase": "train", "update": 2339, "total_env_steps": 7484800, "episode_reward": 0.26754501461982727, "value_loss": 0.006931062694638968, "policy_loss": -0.0012746440529550983, "dist_entropy": 0.661902379989624, "actor_grad_norm": 0.07898840308189392, "critic_grad_norm": 0.05752978473901749, "ratio": 1.0002055168151855, "entropy": 0.661902379989624, "incre_win_rate": 0.9111111111111111, "step": 2339}
{"time": 1767162865.7044067, "phase": "train", "update": 2340, "total_env_steps": 7488000, "episode_reward": 0.267654687166214, "value_loss": 0.006759298034012318, "policy_loss": -0.0014704579755971281, "dist_entropy": 0.6609863877296448, "actor_grad_norm": 0.08637811243534088, "critic_grad_norm": 0.02550271712243557, "ratio": 0.9995647668838501, "entropy": 0.6609863877296448, "incre_win_rate": 0.8636363636363636, "step": 2340}
{"time": 1767162869.9914205, "phase": "train", "update": 2341, "total_env_steps": 7491200, "episode_reward": 0.2662820816040039, "value_loss": 0.006413718592375517, "policy_loss": -0.0013793612457163817, "dist_entropy": 0.6667164921760559, "actor_grad_norm": 0.08404017239809036, "critic_grad_norm": 0.03677664324641228, "ratio": 1.000322699546814, "entropy": 0.6667164921760559, "incre_win_rate": 0.8666666666666667, "step": 2341}
{"time": 1767162879.6735299, "phase": "eval", "update": 2341, "total_env_steps": 7491200, "eval_win_rate": 0.875, "eval_episode_reward": 19.507450331125828, "step": 2341}
{"time": 1767162883.9296288, "phase": "train", "update": 2342, "total_env_steps": 7494400, "episode_reward": 0.27300703525543213, "value_loss": 0.00744932172819972, "policy_loss": -0.0013183302352153703, "dist_entropy": 0.6686583399772644, "actor_grad_norm": 0.09023429453372955, "critic_grad_norm": 0.043286681175231934, "ratio": 0.999728798866272, "entropy": 0.6686583399772644, "incre_win_rate": 0.9090909090909091, "step": 2342}
{"time": 1767162888.1735184, "phase": "train", "update": 2343, "total_env_steps": 7497600, "episode_reward": 0.2673686146736145, "value_loss": 0.0069111366756260395, "policy_loss": -0.0013517121932455467, "dist_entropy": 0.6549435138702393, "actor_grad_norm": 0.08687229454517365, "critic_grad_norm": 0.045489199459552765, "ratio": 0.9998917579650879, "entropy": 0.6549435138702393, "incre_win_rate": 0.8863636363636364, "step": 2343}
{"time": 1767162892.4164772, "phase": "train", "update": 2344, "total_env_steps": 7500800, "episode_reward": 0.2763327658176422, "value_loss": 0.005219100136309862, "policy_loss": -0.0010614188686915327, "dist_entropy": 0.6732784628868103, "actor_grad_norm": 0.08355332165956497, "critic_grad_norm": 0.04097340255975723, "ratio": 1.0002185106277466, "entropy": 0.6732784628868103, "incre_win_rate": 0.9333333333333333, "step": 2344}
{"time": 1767162896.6747541, "phase": "train", "update": 2345, "total_env_steps": 7504000, "episode_reward": 0.27803391218185425, "value_loss": 0.0059000816196203235, "policy_loss": -0.001192842153409046, "dist_entropy": 0.6548867702484131, "actor_grad_norm": 0.09641910344362259, "critic_grad_norm": 0.03322180360555649, "ratio": 0.999855637550354, "entropy": 0.6548867702484131, "incre_win_rate": 0.9318181818181818, "step": 2345}
{"time": 1767162900.8882883, "phase": "train", "update": 2346, "total_env_steps": 7507200, "episode_reward": 0.27007243037223816, "value_loss": 0.006247188989073038, "policy_loss": -0.0014212387318686126, "dist_entropy": 0.641607654094696, "actor_grad_norm": 0.09637554734945297, "critic_grad_norm": 0.04107886180281639, "ratio": 1.0003021955490112, "entropy": 0.641607654094696, "incre_win_rate": 0.8695652173913043, "step": 2346}
{"time": 1767162905.1162207, "phase": "train", "update": 2347, "total_env_steps": 7510400, "episode_reward": 0.27621638774871826, "value_loss": 0.004481520503759384, "policy_loss": -0.0013817903525900732, "dist_entropy": 0.6370308756828308, "actor_grad_norm": 0.09078962355852127, "critic_grad_norm": 0.027298588305711746, "ratio": 1.000055193901062, "entropy": 0.6370308756828308, "incre_win_rate": 0.9318181818181818, "step": 2347}
{"time": 1767162909.3692088, "phase": "train", "update": 2348, "total_env_steps": 7513600, "episode_reward": 0.2803828716278076, "value_loss": 0.0035839101765304804, "policy_loss": -0.001037062797203747, "dist_entropy": 0.6393389463424682, "actor_grad_norm": 0.07387920469045639, "critic_grad_norm": 0.027027452364563942, "ratio": 0.9999055862426758, "entropy": 0.6393389463424682, "incre_win_rate": 0.9347826086956522, "step": 2348}
{"time": 1767162913.6806664, "phase": "train", "update": 2349, "total_env_steps": 7516800, "episode_reward": 0.2840687036514282, "value_loss": 0.0051980243995785715, "policy_loss": -0.0014858012209838733, "dist_entropy": 0.648411238193512, "actor_grad_norm": 0.08085495233535767, "critic_grad_norm": 0.049171317368745804, "ratio": 0.9997841119766235, "entropy": 0.648411238193512, "incre_win_rate": 0.9777777777777777, "step": 2349}
{"time": 1767162917.9345462, "phase": "train", "update": 2350, "total_env_steps": 7520000, "episode_reward": 0.2548365294933319, "value_loss": 0.008502584882080555, "policy_loss": -0.001473865854316614, "dist_entropy": 0.6518178939819336, "actor_grad_norm": 0.08889295160770416, "critic_grad_norm": 0.09065023064613342, "ratio": 0.9999945759773254, "entropy": 0.6518178939819336, "incre_win_rate": 0.8837209302325582, "step": 2350}
{"time": 1767162922.206827, "phase": "train", "update": 2351, "total_env_steps": 7523200, "episode_reward": 0.27334851026535034, "value_loss": 0.006115949340164661, "policy_loss": -0.0015350061759971112, "dist_entropy": 0.679479718208313, "actor_grad_norm": 0.11469709873199463, "critic_grad_norm": 0.07154775410890579, "ratio": 1.000197410583496, "entropy": 0.679479718208313, "incre_win_rate": 0.9318181818181818, "step": 2351}
{"time": 1767162926.500655, "phase": "train", "update": 2352, "total_env_steps": 7526400, "episode_reward": 0.27705708146095276, "value_loss": 0.004190638847649098, "policy_loss": -0.0013664884356529682, "dist_entropy": 0.6747325539588929, "actor_grad_norm": 0.10528538376092911, "critic_grad_norm": 0.06932594627141953, "ratio": 1.0002822875976562, "entropy": 0.6747325539588929, "incre_win_rate": 0.9130434782608695, "step": 2352}
{"time": 1767162930.799023, "phase": "train", "update": 2353, "total_env_steps": 7529600, "episode_reward": 0.2562101483345032, "value_loss": 0.01081636007875204, "policy_loss": -0.001418564417736512, "dist_entropy": 0.6572725415229798, "actor_grad_norm": 0.10886452347040176, "critic_grad_norm": 0.21459904313087463, "ratio": 0.9996759295463562, "entropy": 0.6572725415229798, "incre_win_rate": 0.7111111111111111, "step": 2353}
{"time": 1767162935.0887253, "phase": "train", "update": 2354, "total_env_steps": 7532800, "episode_reward": 0.26819953322410583, "value_loss": 0.00817616917192936, "policy_loss": -0.001219225793775891, "dist_entropy": 0.6549723982810974, "actor_grad_norm": 0.09602414816617966, "critic_grad_norm": 0.08934960514307022, "ratio": 0.9997144937515259, "entropy": 0.6549723982810974, "incre_win_rate": 0.8222222222222222, "step": 2354}
{"time": 1767162939.282379, "phase": "train", "update": 2355, "total_env_steps": 7536000, "episode_reward": 0.27067726850509644, "value_loss": 0.0068132271058857444, "policy_loss": -0.0010895118155005434, "dist_entropy": 0.6533692717552185, "actor_grad_norm": 0.11158601194620132, "critic_grad_norm": 0.13127075135707855, "ratio": 0.9999635815620422, "entropy": 0.6533692717552185, "incre_win_rate": 0.8809523809523809, "step": 2355}
{"time": 1767162943.4452803, "phase": "train", "update": 2356, "total_env_steps": 7539200, "episode_reward": 0.2714434862136841, "value_loss": 0.00777529114857316, "policy_loss": -0.0011610498741852382, "dist_entropy": 0.6462254405021668, "actor_grad_norm": 0.08666803687810898, "critic_grad_norm": 0.06737040728330612, "ratio": 0.9998709559440613, "entropy": 0.6462254405021668, "incre_win_rate": 0.8723404255319149, "step": 2356}
{"time": 1767162947.7078755, "phase": "train", "update": 2357, "total_env_steps": 7542400, "episode_reward": 0.2697019875049591, "value_loss": 0.006044550985097885, "policy_loss": -0.001026758288830365, "dist_entropy": 0.6648173809051514, "actor_grad_norm": 0.0924048200249672, "critic_grad_norm": 0.061623454093933105, "ratio": 1.0002193450927734, "entropy": 0.6648173809051514, "incre_win_rate": 0.9069767441860465, "step": 2357}
{"time": 1767162951.9571497, "phase": "train", "update": 2358, "total_env_steps": 7545600, "episode_reward": 0.2619779706001282, "value_loss": 0.007110962364822626, "policy_loss": -0.0010968934825690724, "dist_entropy": 0.6679627537727356, "actor_grad_norm": 0.08521979302167892, "critic_grad_norm": 0.06977071613073349, "ratio": 1.000019907951355, "entropy": 0.6679627537727356, "incre_win_rate": 0.8181818181818182, "step": 2358}
{"time": 1767162956.2266529, "phase": "train", "update": 2359, "total_env_steps": 7548800, "episode_reward": 0.2803228497505188, "value_loss": 0.002715160883963108, "policy_loss": -0.0014423847321594963, "dist_entropy": 0.6752763748168945, "actor_grad_norm": 0.08297741413116455, "critic_grad_norm": 0.07885432243347168, "ratio": 1.000226616859436, "entropy": 0.6752763748168945, "incre_win_rate": 0.9565217391304348, "step": 2359}
{"time": 1767162960.5078652, "phase": "train", "update": 2360, "total_env_steps": 7552000, "episode_reward": 0.279950350522995, "value_loss": 0.0035483586136251686, "policy_loss": -0.0011236356056031128, "dist_entropy": 0.6857736349105835, "actor_grad_norm": 0.08385337889194489, "critic_grad_norm": 0.057057883590459824, "ratio": 1.0000728368759155, "entropy": 0.6857736349105835, "incre_win_rate": 0.9772727272727273, "step": 2360}
{"time": 1767162964.796723, "phase": "train", "update": 2361, "total_env_steps": 7555200, "episode_reward": 0.26692208647727966, "value_loss": 0.008063634485006332, "policy_loss": -0.0009021985546411315, "dist_entropy": 0.6719706177711486, "actor_grad_norm": 0.07343468070030212, "critic_grad_norm": 0.08343514800071716, "ratio": 0.9998974800109863, "entropy": 0.6719706177711486, "incre_win_rate": 0.8666666666666667, "step": 2361}
{"time": 1767162974.745255, "phase": "eval", "update": 2361, "total_env_steps": 7555200, "eval_win_rate": 0.8125, "eval_episode_reward": 19.21988824503311, "step": 2361}
{"time": 1767162979.0019295, "phase": "train", "update": 2362, "total_env_steps": 7558400, "episode_reward": 0.2523437738418579, "value_loss": 0.008186388574540616, "policy_loss": -0.001050212851934873, "dist_entropy": 0.6556069612503052, "actor_grad_norm": 0.09626241773366928, "critic_grad_norm": 0.11642219126224518, "ratio": 0.9999710321426392, "entropy": 0.6556069612503052, "incre_win_rate": 0.7906976744186046, "step": 2362}
{"time": 1767162983.3204048, "phase": "train", "update": 2363, "total_env_steps": 7561600, "episode_reward": 0.27996018528938293, "value_loss": 0.0068134965375065805, "policy_loss": -0.0010919621742002227, "dist_entropy": 0.6807625412940979, "actor_grad_norm": 0.09864765405654907, "critic_grad_norm": 0.19846071302890778, "ratio": 1.0000261068344116, "entropy": 0.6807625412940979, "incre_win_rate": 0.8913043478260869, "step": 2363}
{"time": 1767162987.6547518, "phase": "train", "update": 2364, "total_env_steps": 7564800, "episode_reward": 0.2743874192237854, "value_loss": 0.00844914112240076, "policy_loss": -0.0017777146271722444, "dist_entropy": 0.6802664875984192, "actor_grad_norm": 0.11721795797348022, "critic_grad_norm": 0.11708419770002365, "ratio": 0.9998180270195007, "entropy": 0.6802664875984192, "incre_win_rate": 0.8863636363636364, "step": 2364}
{"time": 1767162991.9620175, "phase": "train", "update": 2365, "total_env_steps": 7568000, "episode_reward": 0.27093595266342163, "value_loss": 0.006043552048504352, "policy_loss": -0.0012329955144707583, "dist_entropy": 0.6836169123649597, "actor_grad_norm": 0.09573765844106674, "critic_grad_norm": 0.09069674462080002, "ratio": 0.9999038577079773, "entropy": 0.6836169123649597, "incre_win_rate": 0.8297872340425532, "step": 2365}
{"time": 1767162996.2227836, "phase": "train", "update": 2366, "total_env_steps": 7571200, "episode_reward": 0.26404285430908203, "value_loss": 0.009784102812409401, "policy_loss": -0.0013363684288250966, "dist_entropy": 0.6806450843811035, "actor_grad_norm": 0.0948108583688736, "critic_grad_norm": 0.18792493641376495, "ratio": 0.9999066591262817, "entropy": 0.6806450843811035, "incre_win_rate": 0.8809523809523809, "step": 2366}
{"time": 1767163000.5597496, "phase": "train", "update": 2367, "total_env_steps": 7574400, "episode_reward": 0.2794743478298187, "value_loss": 0.00795599203556776, "policy_loss": -0.0012113443420114223, "dist_entropy": 0.6796440958976746, "actor_grad_norm": 0.08953223377466202, "critic_grad_norm": 0.08049900829792023, "ratio": 0.9995846152305603, "entropy": 0.6796440958976746, "incre_win_rate": 0.8888888888888888, "step": 2367}
{"time": 1767163004.8275707, "phase": "train", "update": 2368, "total_env_steps": 7577600, "episode_reward": 0.2725827693939209, "value_loss": 0.005479083955287933, "policy_loss": -0.0014198072764855852, "dist_entropy": 0.6892823457717896, "actor_grad_norm": 0.09016155451536179, "critic_grad_norm": 0.07120471447706223, "ratio": 0.9997693300247192, "entropy": 0.6892823457717896, "incre_win_rate": 0.8936170212765957, "step": 2368}
{"time": 1767163009.1341896, "phase": "train", "update": 2369, "total_env_steps": 7580800, "episode_reward": 0.28303807973861694, "value_loss": 0.003481509769335389, "policy_loss": -0.0012539282592705092, "dist_entropy": 0.7083974242210388, "actor_grad_norm": 0.08387386053800583, "critic_grad_norm": 0.0842304453253746, "ratio": 0.9996512532234192, "entropy": 0.7083974242210388, "incre_win_rate": 0.9772727272727273, "step": 2369}
{"time": 1767163013.4779513, "phase": "train", "update": 2370, "total_env_steps": 7584000, "episode_reward": 0.27944332361221313, "value_loss": 0.004640263970941305, "policy_loss": -0.0010864093039606782, "dist_entropy": 0.692491614818573, "actor_grad_norm": 0.08182164281606674, "critic_grad_norm": 0.03822843357920647, "ratio": 0.9997734427452087, "entropy": 0.692491614818573, "incre_win_rate": 0.9361702127659575, "step": 2370}
{"time": 1767163017.8435814, "phase": "train", "update": 2371, "total_env_steps": 7587200, "episode_reward": 0.2708304226398468, "value_loss": 0.004811499640345574, "policy_loss": -0.0012358739884554381, "dist_entropy": 0.7020148396492004, "actor_grad_norm": 0.08683035522699356, "critic_grad_norm": 0.06228390336036682, "ratio": 0.9996601939201355, "entropy": 0.7020148396492004, "incre_win_rate": 0.8863636363636364, "step": 2371}
{"time": 1767163022.125988, "phase": "train", "update": 2372, "total_env_steps": 7590400, "episode_reward": 0.27403557300567627, "value_loss": 0.0034087767358869313, "policy_loss": -0.0010611537205761578, "dist_entropy": 0.7162148833274842, "actor_grad_norm": 0.10264017432928085, "critic_grad_norm": 0.044025059789419174, "ratio": 1.000099539756775, "entropy": 0.7162148833274842, "incre_win_rate": 0.9545454545454546, "step": 2372}
{"time": 1767163026.3697355, "phase": "train", "update": 2373, "total_env_steps": 7593600, "episode_reward": 0.2762303352355957, "value_loss": 0.0036057820077985527, "policy_loss": -0.0010255894705004209, "dist_entropy": 0.7076700448989868, "actor_grad_norm": 0.09029471129179001, "critic_grad_norm": 0.02980700135231018, "ratio": 0.9999374747276306, "entropy": 0.7076700448989868, "incre_win_rate": 0.9130434782608695, "step": 2373}
{"time": 1767163030.6585205, "phase": "train", "update": 2374, "total_env_steps": 7596800, "episode_reward": 0.2761465013027191, "value_loss": 0.004375198483467102, "policy_loss": -0.0015644391230141609, "dist_entropy": 0.6997815251350403, "actor_grad_norm": 0.09670622646808624, "critic_grad_norm": 0.03990766778588295, "ratio": 0.9997463226318359, "entropy": 0.6997815251350403, "incre_win_rate": 0.9318181818181818, "step": 2374}
{"time": 1767163034.9618704, "phase": "train", "update": 2375, "total_env_steps": 7600000, "episode_reward": 0.2796274721622467, "value_loss": 0.002608890272676945, "policy_loss": -0.001506375469374177, "dist_entropy": 0.7002032995223999, "actor_grad_norm": 0.0978635624051094, "critic_grad_norm": 0.051947303116321564, "ratio": 1.0002440214157104, "entropy": 0.7002032995223999, "incre_win_rate": 0.9777777777777777, "step": 2375}
{"time": 1767163039.2960875, "phase": "train", "update": 2376, "total_env_steps": 7603200, "episode_reward": 0.27571192383766174, "value_loss": 0.0038596995174884794, "policy_loss": -0.0011800511228686084, "dist_entropy": 0.708279812335968, "actor_grad_norm": 0.06831522285938263, "critic_grad_norm": 0.03278953954577446, "ratio": 0.9999527931213379, "entropy": 0.708279812335968, "incre_win_rate": 0.9772727272727273, "step": 2376}
{"time": 1767163043.6498287, "phase": "train", "update": 2377, "total_env_steps": 7606400, "episode_reward": 0.2705727517604828, "value_loss": 0.008537197113037109, "policy_loss": -0.0014709111931615836, "dist_entropy": 0.6701149582862854, "actor_grad_norm": 0.11919604986906052, "critic_grad_norm": 0.12392725050449371, "ratio": 0.9997674822807312, "entropy": 0.6701149582862854, "incre_win_rate": 0.8444444444444444, "step": 2377}
{"time": 1767163047.884872, "phase": "train", "update": 2378, "total_env_steps": 7609600, "episode_reward": 0.24496379494667053, "value_loss": 0.011783183179795742, "policy_loss": -0.0012978840959705807, "dist_entropy": 0.6642097592353821, "actor_grad_norm": 0.10237584263086319, "critic_grad_norm": 0.15043915808200836, "ratio": 0.9997736215591431, "entropy": 0.6642097592353821, "incre_win_rate": 0.6744186046511628, "step": 2378}
{"time": 1767163052.1263793, "phase": "train", "update": 2379, "total_env_steps": 7612800, "episode_reward": 0.2720286548137665, "value_loss": 0.009151660278439522, "policy_loss": -0.0008619352810818271, "dist_entropy": 0.699602735042572, "actor_grad_norm": 0.07238280028104782, "critic_grad_norm": 0.12408530712127686, "ratio": 0.9999624490737915, "entropy": 0.699602735042572, "incre_win_rate": 0.8695652173913043, "step": 2379}
{"time": 1767163056.3800495, "phase": "train", "update": 2380, "total_env_steps": 7616000, "episode_reward": 0.266180157661438, "value_loss": 0.0077571383677423, "policy_loss": -0.0015039942814517814, "dist_entropy": 0.6812837600708008, "actor_grad_norm": 0.08153419941663742, "critic_grad_norm": 0.09502281993627548, "ratio": 0.999975323677063, "entropy": 0.6812837600708008, "incre_win_rate": 0.8863636363636364, "step": 2380}
{"time": 1767163060.5958931, "phase": "train", "update": 2381, "total_env_steps": 7619200, "episode_reward": 0.2611522376537323, "value_loss": 0.01069051567465067, "policy_loss": -0.0011717949042245658, "dist_entropy": 0.6920693993568421, "actor_grad_norm": 0.06999825686216354, "critic_grad_norm": 0.10348265618085861, "ratio": 1.0001049041748047, "entropy": 0.6920693993568421, "incre_win_rate": 0.8, "step": 2381}
{"time": 1767163070.4595811, "phase": "eval", "update": 2381, "total_env_steps": 7619200, "eval_win_rate": 0.84375, "eval_episode_reward": 19.25181084437086, "step": 2381}
{"time": 1767163074.779267, "phase": "train", "update": 2382, "total_env_steps": 7622400, "episode_reward": 0.27166804671287537, "value_loss": 0.010381855443120003, "policy_loss": -0.0013966780290786574, "dist_entropy": 0.6895654797554016, "actor_grad_norm": 0.08278217166662216, "critic_grad_norm": 0.06140424683690071, "ratio": 0.999786376953125, "entropy": 0.6895654797554016, "incre_win_rate": 0.9090909090909091, "step": 2382}
{"time": 1767163079.1115563, "phase": "train", "update": 2383, "total_env_steps": 7625600, "episode_reward": 0.260814368724823, "value_loss": 0.007215073052793741, "policy_loss": -0.001177914930005386, "dist_entropy": 0.7251739144325257, "actor_grad_norm": 0.08330260962247849, "critic_grad_norm": 0.08099965006113052, "ratio": 0.9998919367790222, "entropy": 0.7251739144325257, "incre_win_rate": 0.8, "step": 2383}
{"time": 1767163083.4407847, "phase": "train", "update": 2384, "total_env_steps": 7628800, "episode_reward": 0.2705034017562866, "value_loss": 0.008227997832000256, "policy_loss": -0.001078634078924523, "dist_entropy": 0.7223958492279052, "actor_grad_norm": 0.08561406284570694, "critic_grad_norm": 0.08624918758869171, "ratio": 0.9998526573181152, "entropy": 0.7223958492279052, "incre_win_rate": 0.8666666666666667, "step": 2384}
{"time": 1767163087.7262979, "phase": "train", "update": 2385, "total_env_steps": 7632000, "episode_reward": 0.2765713036060333, "value_loss": 0.006625903211534024, "policy_loss": -0.001200465228014025, "dist_entropy": 0.7392166137695313, "actor_grad_norm": 0.083561472594738, "critic_grad_norm": 0.08106429129838943, "ratio": 0.999925434589386, "entropy": 0.7392166137695313, "incre_win_rate": 0.9069767441860465, "step": 2385}
{"time": 1767163092.0351734, "phase": "train", "update": 2386, "total_env_steps": 7635200, "episode_reward": 0.27502068877220154, "value_loss": 0.005566306598484516, "policy_loss": -0.0009212041547659311, "dist_entropy": 0.717296028137207, "actor_grad_norm": 0.0834231823682785, "critic_grad_norm": 0.07041076570749283, "ratio": 1.0000370740890503, "entropy": 0.717296028137207, "incre_win_rate": 0.9148936170212766, "step": 2386}
{"time": 1767163096.3572419, "phase": "train", "update": 2387, "total_env_steps": 7638400, "episode_reward": 0.27751657366752625, "value_loss": 0.004615239333361387, "policy_loss": -0.0011810232376319619, "dist_entropy": 0.7088219881057739, "actor_grad_norm": 0.0848187804222107, "critic_grad_norm": 0.042478207498788834, "ratio": 1.000089406967163, "entropy": 0.7088219881057739, "incre_win_rate": 0.9318181818181818, "step": 2387}
{"time": 1767163100.657245, "phase": "train", "update": 2388, "total_env_steps": 7641600, "episode_reward": 0.27828797698020935, "value_loss": 0.005434851348400116, "policy_loss": -0.0011705071294585423, "dist_entropy": 0.6956342816352844, "actor_grad_norm": 0.09546945244073868, "critic_grad_norm": 0.047523029148578644, "ratio": 0.9997644424438477, "entropy": 0.6956342816352844, "incre_win_rate": 0.9555555555555556, "step": 2388}
{"time": 1767163104.9432423, "phase": "train", "update": 2389, "total_env_steps": 7644800, "episode_reward": 0.27489808201789856, "value_loss": 0.0054269470274448395, "policy_loss": -0.0011803183490115999, "dist_entropy": 0.6841099500656128, "actor_grad_norm": 0.08352608233690262, "critic_grad_norm": 0.03195364400744438, "ratio": 1.0002257823944092, "entropy": 0.6841099500656128, "incre_win_rate": 0.9333333333333333, "step": 2389}
{"time": 1767163109.2487586, "phase": "train", "update": 2390, "total_env_steps": 7648000, "episode_reward": 0.27991312742233276, "value_loss": 0.004356606677174568, "policy_loss": -0.0009546293774693737, "dist_entropy": 0.6830864310264587, "actor_grad_norm": 0.08305774629116058, "critic_grad_norm": 0.07414565980434418, "ratio": 1.0004761219024658, "entropy": 0.6830864310264587, "incre_win_rate": 0.8958333333333334, "step": 2390}
{"time": 1767163113.5227883, "phase": "train", "update": 2391, "total_env_steps": 7651200, "episode_reward": 0.2808402478694916, "value_loss": 0.0034060906153172256, "policy_loss": -0.0012168560933787376, "dist_entropy": 0.6727210879325867, "actor_grad_norm": 0.07564346492290497, "critic_grad_norm": 0.051220912486314774, "ratio": 0.9998136758804321, "entropy": 0.6727210879325867, "incre_win_rate": 0.9545454545454546, "step": 2391}
{"time": 1767163117.9105387, "phase": "train", "update": 2392, "total_env_steps": 7654400, "episode_reward": 0.28065812587738037, "value_loss": 0.0040498489513993265, "policy_loss": -0.0012551216204130355, "dist_entropy": 0.6515862822532654, "actor_grad_norm": 0.08576646447181702, "critic_grad_norm": 0.044908057898283005, "ratio": 1.0001455545425415, "entropy": 0.6515862822532654, "incre_win_rate": 0.9565217391304348, "step": 2392}
{"time": 1767163122.2405593, "phase": "train", "update": 2393, "total_env_steps": 7657600, "episode_reward": 0.27917736768722534, "value_loss": 0.003922724025323987, "policy_loss": -0.0014143443440417514, "dist_entropy": 0.6459851384162902, "actor_grad_norm": 0.08092396706342697, "critic_grad_norm": 0.06758861988782883, "ratio": 0.99949711561203, "entropy": 0.6459851384162902, "incre_win_rate": 0.9777777777777777, "step": 2393}
{"time": 1767163126.5255187, "phase": "train", "update": 2394, "total_env_steps": 7660800, "episode_reward": 0.2715728282928467, "value_loss": 0.00583417322486639, "policy_loss": -0.00141370058890935, "dist_entropy": 0.6522941827774048, "actor_grad_norm": 0.0940013900399208, "critic_grad_norm": 0.075030617415905, "ratio": 1.0006235837936401, "entropy": 0.6522941827774048, "incre_win_rate": 0.9111111111111111, "step": 2394}
{"time": 1767163130.8574343, "phase": "train", "update": 2395, "total_env_steps": 7664000, "episode_reward": 0.2772946059703827, "value_loss": 0.005815898720175028, "policy_loss": -0.0012825210688525602, "dist_entropy": 0.6512444496154786, "actor_grad_norm": 0.07371073961257935, "critic_grad_norm": 0.0537780299782753, "ratio": 0.9998710751533508, "entropy": 0.6512444496154786, "incre_win_rate": 0.9069767441860465, "step": 2395}
{"time": 1767163135.1923454, "phase": "train", "update": 2396, "total_env_steps": 7667200, "episode_reward": 0.2822226881980896, "value_loss": 0.006004527676850557, "policy_loss": -0.000781998898240488, "dist_entropy": 0.6376344203948975, "actor_grad_norm": 0.09496910870075226, "critic_grad_norm": 0.07678543776273727, "ratio": 0.9996024370193481, "entropy": 0.6376344203948975, "incre_win_rate": 0.9148936170212766, "step": 2396}
{"time": 1767163139.5076866, "phase": "train", "update": 2397, "total_env_steps": 7670400, "episode_reward": 0.27008122205734253, "value_loss": 0.00938124768435955, "policy_loss": -0.001154722261120611, "dist_entropy": 0.6380213379859925, "actor_grad_norm": 0.09579562395811081, "critic_grad_norm": 0.054866988211870193, "ratio": 1.000118613243103, "entropy": 0.6380213379859925, "incre_win_rate": 0.8297872340425532, "step": 2397}
{"time": 1767163143.8542557, "phase": "train", "update": 2398, "total_env_steps": 7673600, "episode_reward": 0.28461870551109314, "value_loss": 0.007046424690634013, "policy_loss": -0.0010238939110763568, "dist_entropy": 0.6475825905799866, "actor_grad_norm": 0.094367116689682, "critic_grad_norm": 0.05549538880586624, "ratio": 1.0001083612442017, "entropy": 0.6475825905799866, "incre_win_rate": 0.9090909090909091, "step": 2398}
{"time": 1767163148.248194, "phase": "train", "update": 2399, "total_env_steps": 7676800, "episode_reward": 0.28678810596466064, "value_loss": 0.003516162233427167, "policy_loss": -0.0012237405986525117, "dist_entropy": 0.6670093774795532, "actor_grad_norm": 0.09612295031547546, "critic_grad_norm": 0.06313859671354294, "ratio": 1.0006048679351807, "entropy": 0.6670093774795532, "incre_win_rate": 1.0, "step": 2399}
{"time": 1767163152.5552356, "phase": "train", "update": 2400, "total_env_steps": 7680000, "episode_reward": 0.27913907170295715, "value_loss": 0.004193249996751547, "policy_loss": -0.001009792052730063, "dist_entropy": 0.655036187171936, "actor_grad_norm": 0.07749027758836746, "critic_grad_norm": 0.04110974073410034, "ratio": 1.000032663345337, "entropy": 0.655036187171936, "incre_win_rate": 0.9361702127659575, "step": 2400}
{"time": 1767163156.8579113, "phase": "train", "update": 2401, "total_env_steps": 7683200, "episode_reward": 0.2702193856239319, "value_loss": 0.006092043686658144, "policy_loss": -0.0012276015391265104, "dist_entropy": 0.6503544926643372, "actor_grad_norm": 0.08323129266500473, "critic_grad_norm": 0.0654662698507309, "ratio": 0.999819278717041, "entropy": 0.6503544926643372, "incre_win_rate": 0.8837209302325582, "step": 2401}
{"time": 1767163166.7668982, "phase": "eval", "update": 2401, "total_env_steps": 7683200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.503725165562912, "step": 2401}
{"time": 1767163171.045147, "phase": "train", "update": 2402, "total_env_steps": 7686400, "episode_reward": 0.2757740020751953, "value_loss": 0.008708705194294453, "policy_loss": -0.001338657104079033, "dist_entropy": 0.6492753863334656, "actor_grad_norm": 0.0962509885430336, "critic_grad_norm": 0.08169026672840118, "ratio": 0.9995376467704773, "entropy": 0.6492753863334656, "incre_win_rate": 0.8478260869565217, "step": 2402}
{"time": 1767163175.3692105, "phase": "train", "update": 2403, "total_env_steps": 7689600, "episode_reward": 0.27994462847709656, "value_loss": 0.006785002816468477, "policy_loss": -0.0009179327221531253, "dist_entropy": 0.6495590925216674, "actor_grad_norm": 0.08464702218770981, "critic_grad_norm": 0.0884753167629242, "ratio": 1.000099778175354, "entropy": 0.6495590925216674, "incre_win_rate": 0.8695652173913043, "step": 2403}
{"time": 1767163179.695478, "phase": "train", "update": 2404, "total_env_steps": 7692800, "episode_reward": 0.2813493311405182, "value_loss": 0.004629276692867279, "policy_loss": -0.0008964978311176708, "dist_entropy": 0.6501789093017578, "actor_grad_norm": 0.08345091342926025, "critic_grad_norm": 0.07939263433218002, "ratio": 0.9998630881309509, "entropy": 0.6501789093017578, "incre_win_rate": 0.9555555555555556, "step": 2404}
{"time": 1767163184.0001287, "phase": "train", "update": 2405, "total_env_steps": 7696000, "episode_reward": 0.2744370996952057, "value_loss": 0.007020792178809643, "policy_loss": -0.0010643562786441408, "dist_entropy": 0.6264985918998718, "actor_grad_norm": 0.09152200073003769, "critic_grad_norm": 0.14184458553791046, "ratio": 0.9998357892036438, "entropy": 0.6264985918998718, "incre_win_rate": 0.8936170212765957, "step": 2405}
{"time": 1767163188.3091688, "phase": "train", "update": 2406, "total_env_steps": 7699200, "episode_reward": 0.2802199125289917, "value_loss": 0.007163423299789429, "policy_loss": -0.001777895181474598, "dist_entropy": 0.6296413898468017, "actor_grad_norm": 0.09149772673845291, "critic_grad_norm": 0.05521833896636963, "ratio": 0.9994075894355774, "entropy": 0.6296413898468017, "incre_win_rate": 0.8695652173913043, "step": 2406}
{"time": 1767163192.5735855, "phase": "train", "update": 2407, "total_env_steps": 7702400, "episode_reward": 0.2781788110733032, "value_loss": 0.008072818629443645, "policy_loss": -0.0010638934916418208, "dist_entropy": 0.6185263156890869, "actor_grad_norm": 0.09561341255903244, "critic_grad_norm": 0.09956817328929901, "ratio": 1.0001124143600464, "entropy": 0.6185263156890869, "incre_win_rate": 0.9090909090909091, "step": 2407}
{"time": 1767163196.9066453, "phase": "train", "update": 2408, "total_env_steps": 7705600, "episode_reward": 0.287458598613739, "value_loss": 0.0031822198070585728, "policy_loss": -0.0012712499836652568, "dist_entropy": 0.6279418468475342, "actor_grad_norm": 0.10464010387659073, "critic_grad_norm": 0.13516542315483093, "ratio": 0.9999603629112244, "entropy": 0.6279418468475342, "incre_win_rate": 1.0, "step": 2408}
{"time": 1767163201.218166, "phase": "train", "update": 2409, "total_env_steps": 7708800, "episode_reward": 0.27532699704170227, "value_loss": 0.003137589618563652, "policy_loss": -0.0011643092682653844, "dist_entropy": 0.6265925526618957, "actor_grad_norm": 0.09918602555990219, "critic_grad_norm": 0.049299027770757675, "ratio": 0.999889075756073, "entropy": 0.6265925526618957, "incre_win_rate": 0.9545454545454546, "step": 2409}
{"time": 1767163205.4988217, "phase": "train", "update": 2410, "total_env_steps": 7712000, "episode_reward": 0.26949813961982727, "value_loss": 0.005502271093428135, "policy_loss": -0.001202586314276033, "dist_entropy": 0.6232040286064148, "actor_grad_norm": 0.09485515207052231, "critic_grad_norm": 0.11146754026412964, "ratio": 0.9998928308486938, "entropy": 0.6232040286064148, "incre_win_rate": 0.8863636363636364, "step": 2410}
{"time": 1767163209.8363738, "phase": "train", "update": 2411, "total_env_steps": 7715200, "episode_reward": 0.28039321303367615, "value_loss": 0.005816980544477701, "policy_loss": -0.0011232638996954592, "dist_entropy": 0.6301722645759582, "actor_grad_norm": 0.08938466757535934, "critic_grad_norm": 0.07444625347852707, "ratio": 0.9997125864028931, "entropy": 0.6301722645759582, "incre_win_rate": 0.9555555555555556, "step": 2411}
{"time": 1767163214.1464436, "phase": "train", "update": 2412, "total_env_steps": 7718400, "episode_reward": 0.2644282877445221, "value_loss": 0.007226104754954577, "policy_loss": -0.0013842311763255567, "dist_entropy": 0.6348133444786072, "actor_grad_norm": 0.09734827280044556, "critic_grad_norm": 0.12369326502084732, "ratio": 0.9998275637626648, "entropy": 0.6348133444786072, "incre_win_rate": 0.8297872340425532, "step": 2412}
{"time": 1767163218.47922, "phase": "train", "update": 2413, "total_env_steps": 7721600, "episode_reward": 0.27994051575660706, "value_loss": 0.005098921526223421, "policy_loss": -0.0013963744242488473, "dist_entropy": 0.6550907969474793, "actor_grad_norm": 0.08827944844961166, "critic_grad_norm": 0.08932536095380783, "ratio": 0.9998793005943298, "entropy": 0.6550907969474793, "incre_win_rate": 0.9090909090909091, "step": 2413}
{"time": 1767163222.7503667, "phase": "train", "update": 2414, "total_env_steps": 7724800, "episode_reward": 0.27662718296051025, "value_loss": 0.005444045271724462, "policy_loss": -0.001639463035223443, "dist_entropy": 0.6613460898399353, "actor_grad_norm": 0.07942499965429306, "critic_grad_norm": 0.08336180448532104, "ratio": 1.0001763105392456, "entropy": 0.6613460898399353, "incre_win_rate": 0.9111111111111111, "step": 2414}
{"time": 1767163227.052054, "phase": "train", "update": 2415, "total_env_steps": 7728000, "episode_reward": 0.274676114320755, "value_loss": 0.007099266164004803, "policy_loss": -0.0013890184038064745, "dist_entropy": 0.6810519337654114, "actor_grad_norm": 0.07434814423322678, "critic_grad_norm": 0.06489682197570801, "ratio": 0.9997591376304626, "entropy": 0.6810519337654114, "incre_win_rate": 0.9347826086956522, "step": 2415}
{"time": 1767163231.3850787, "phase": "train", "update": 2416, "total_env_steps": 7731200, "episode_reward": 0.27894866466522217, "value_loss": 0.007034598104655743, "policy_loss": -0.0015767434009681836, "dist_entropy": 0.6860673546791076, "actor_grad_norm": 0.08714946359395981, "critic_grad_norm": 0.05884576961398125, "ratio": 0.9998249411582947, "entropy": 0.6860673546791076, "incre_win_rate": 0.9090909090909091, "step": 2416}
{"time": 1767163235.6680193, "phase": "train", "update": 2417, "total_env_steps": 7734400, "episode_reward": 0.26471030712127686, "value_loss": 0.007015009690076113, "policy_loss": -0.0015608801866065392, "dist_entropy": 0.7012670159339904, "actor_grad_norm": 0.07374724000692368, "critic_grad_norm": 0.08824580907821655, "ratio": 0.9999073147773743, "entropy": 0.7012670159339904, "incre_win_rate": 0.8444444444444444, "step": 2417}
{"time": 1767163240.014466, "phase": "train", "update": 2418, "total_env_steps": 7737600, "episode_reward": 0.2816489338874817, "value_loss": 0.005349293816834688, "policy_loss": -0.0013211980930549316, "dist_entropy": 0.7156673789024353, "actor_grad_norm": 0.08833690732717514, "critic_grad_norm": 0.06845154613256454, "ratio": 1.0002363920211792, "entropy": 0.7156673789024353, "incre_win_rate": 0.8936170212765957, "step": 2418}
{"time": 1767163244.3195593, "phase": "train", "update": 2419, "total_env_steps": 7740800, "episode_reward": 0.2741965055465698, "value_loss": 0.006948161218315363, "policy_loss": -0.0016332806932553012, "dist_entropy": 0.7009775280952454, "actor_grad_norm": 0.09957843273878098, "critic_grad_norm": 0.09122741222381592, "ratio": 0.9998351335525513, "entropy": 0.7009775280952454, "incre_win_rate": 0.8636363636363636, "step": 2419}
{"time": 1767163248.6309154, "phase": "train", "update": 2420, "total_env_steps": 7744000, "episode_reward": 0.2694675922393799, "value_loss": 0.01304314862936735, "policy_loss": -0.001189780636789095, "dist_entropy": 0.6862360596656799, "actor_grad_norm": 0.08713098615407944, "critic_grad_norm": 0.1778717190027237, "ratio": 0.99978107213974, "entropy": 0.6862360596656799, "incre_win_rate": 0.8, "step": 2420}
{"time": 1767163252.9602826, "phase": "train", "update": 2421, "total_env_steps": 7747200, "episode_reward": 0.2771812975406647, "value_loss": 0.00629481915384531, "policy_loss": -0.0011313905442420947, "dist_entropy": 0.6788233280181885, "actor_grad_norm": 0.08140150457620621, "critic_grad_norm": 0.1652836799621582, "ratio": 0.9997300505638123, "entropy": 0.6788233280181885, "incre_win_rate": 0.8913043478260869, "step": 2421}
{"time": 1767163262.658398, "phase": "eval", "update": 2421, "total_env_steps": 7747200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.840645695364238, "step": 2421}
{"time": 1767163266.937828, "phase": "train", "update": 2422, "total_env_steps": 7750400, "episode_reward": 0.28128519654273987, "value_loss": 0.0047102455049753186, "policy_loss": -0.0010618913146831944, "dist_entropy": 0.685454249382019, "actor_grad_norm": 0.09194235503673553, "critic_grad_norm": 0.11477519571781158, "ratio": 1.0003715753555298, "entropy": 0.685454249382019, "incre_win_rate": 0.9347826086956522, "step": 2422}
{"time": 1767163271.269811, "phase": "train", "update": 2423, "total_env_steps": 7753600, "episode_reward": 0.2772185504436493, "value_loss": 0.005477714445441961, "policy_loss": -0.0015900794985315603, "dist_entropy": 0.703947913646698, "actor_grad_norm": 0.09102117270231247, "critic_grad_norm": 0.07857610285282135, "ratio": 1.0002211332321167, "entropy": 0.703947913646698, "incre_win_rate": 0.9148936170212766, "step": 2423}
{"time": 1767163275.6089554, "phase": "train", "update": 2424, "total_env_steps": 7756800, "episode_reward": 0.28943347930908203, "value_loss": 0.00444242674857378, "policy_loss": -0.0014996707064192094, "dist_entropy": 0.6875129818916321, "actor_grad_norm": 0.0896439254283905, "critic_grad_norm": 0.054220397025346756, "ratio": 0.9997444152832031, "entropy": 0.6875129818916321, "incre_win_rate": 0.9130434782608695, "step": 2424}
{"time": 1767163279.9264326, "phase": "train", "update": 2425, "total_env_steps": 7760000, "episode_reward": 0.28071555495262146, "value_loss": 0.005616031680256128, "policy_loss": -0.0012706581094334979, "dist_entropy": 0.7050844192504883, "actor_grad_norm": 0.08826949447393417, "critic_grad_norm": 0.07493601739406586, "ratio": 0.9995235800743103, "entropy": 0.7050844192504883, "incre_win_rate": 0.9555555555555556, "step": 2425}
{"time": 1767163284.220528, "phase": "train", "update": 2426, "total_env_steps": 7763200, "episode_reward": 0.273278146982193, "value_loss": 0.006436518486589193, "policy_loss": -0.0010973375255787232, "dist_entropy": 0.690889549255371, "actor_grad_norm": 0.09284680336713791, "critic_grad_norm": 0.030166013166308403, "ratio": 0.9997052550315857, "entropy": 0.690889549255371, "incre_win_rate": 0.8913043478260869, "step": 2426}
{"time": 1767163288.507021, "phase": "train", "update": 2427, "total_env_steps": 7766400, "episode_reward": 0.272177129983902, "value_loss": 0.005626524519175291, "policy_loss": -0.0009862065677921806, "dist_entropy": 0.6860202074050903, "actor_grad_norm": 0.08814867585897446, "critic_grad_norm": 0.028215879574418068, "ratio": 1.0000882148742676, "entropy": 0.6860202074050903, "incre_win_rate": 0.9302325581395349, "step": 2427}
{"time": 1767163292.7746408, "phase": "train", "update": 2428, "total_env_steps": 7769600, "episode_reward": 0.2496393918991089, "value_loss": 0.007144529093056917, "policy_loss": -0.0013271908605872796, "dist_entropy": 0.699443244934082, "actor_grad_norm": 0.09724844992160797, "critic_grad_norm": 0.07342340052127838, "ratio": 0.9997698664665222, "entropy": 0.699443244934082, "incre_win_rate": 0.8333333333333334, "step": 2428}
{"time": 1767163297.0763874, "phase": "train", "update": 2429, "total_env_steps": 7772800, "episode_reward": 0.2645188271999359, "value_loss": 0.004251082986593246, "policy_loss": -0.0011927392333693555, "dist_entropy": 0.7139617562294006, "actor_grad_norm": 0.0875421091914177, "critic_grad_norm": 0.052439238876104355, "ratio": 0.9996616244316101, "entropy": 0.7139617562294006, "incre_win_rate": 0.9069767441860465, "step": 2429}
{"time": 1767163301.4638042, "phase": "train", "update": 2430, "total_env_steps": 7776000, "episode_reward": 0.2782890200614929, "value_loss": 0.004201446659862995, "policy_loss": -0.0011720218079432243, "dist_entropy": 0.6957277417182922, "actor_grad_norm": 0.08999945968389511, "critic_grad_norm": 0.05047693848609924, "ratio": 1.0003247261047363, "entropy": 0.6957277417182922, "incre_win_rate": 0.9333333333333333, "step": 2430}
{"time": 1767163305.8114324, "phase": "train", "update": 2431, "total_env_steps": 7779200, "episode_reward": 0.27829262614250183, "value_loss": 0.0032749623525887726, "policy_loss": -0.0010576015363263024, "dist_entropy": 0.6876729369163513, "actor_grad_norm": 0.0872308686375618, "critic_grad_norm": 0.04891053959727287, "ratio": 0.9999763369560242, "entropy": 0.6876729369163513, "incre_win_rate": 0.9361702127659575, "step": 2431}
{"time": 1767163310.1195874, "phase": "train", "update": 2432, "total_env_steps": 7782400, "episode_reward": 0.2695830166339874, "value_loss": 0.006013963744044304, "policy_loss": -0.001151691885210937, "dist_entropy": 0.6843490839004517, "actor_grad_norm": 0.0935753583908081, "critic_grad_norm": 0.07740756124258041, "ratio": 1.000083327293396, "entropy": 0.6843490839004517, "incre_win_rate": 0.9069767441860465, "step": 2432}
{"time": 1767163314.365378, "phase": "train", "update": 2433, "total_env_steps": 7785600, "episode_reward": 0.2751893699169159, "value_loss": 0.0057759840041399, "policy_loss": -0.0012403436488661157, "dist_entropy": 0.69262855052948, "actor_grad_norm": 0.10597624629735947, "critic_grad_norm": 0.04981882497668266, "ratio": 1.0004570484161377, "entropy": 0.69262855052948, "incre_win_rate": 0.8888888888888888, "step": 2433}
{"time": 1767163318.650206, "phase": "train", "update": 2434, "total_env_steps": 7788800, "episode_reward": 0.276531457901001, "value_loss": 0.008551082015037537, "policy_loss": -0.001220708902109635, "dist_entropy": 0.6898964881896973, "actor_grad_norm": 0.1069779023528099, "critic_grad_norm": 0.06128673627972603, "ratio": 0.9997833371162415, "entropy": 0.6898964881896973, "incre_win_rate": 0.9130434782608695, "step": 2434}
{"time": 1767163322.9114482, "phase": "train", "update": 2435, "total_env_steps": 7792000, "episode_reward": 0.26650866866111755, "value_loss": 0.010072953999042511, "policy_loss": -0.0013013706610379926, "dist_entropy": 0.6959055423736572, "actor_grad_norm": 0.07570063322782516, "critic_grad_norm": 0.06885496526956558, "ratio": 0.999842643737793, "entropy": 0.6959055423736572, "incre_win_rate": 0.8478260869565217, "step": 2435}
{"time": 1767163327.1733277, "phase": "train", "update": 2436, "total_env_steps": 7795200, "episode_reward": 0.2681260406970978, "value_loss": 0.007934589870274067, "policy_loss": -0.0015281325073196682, "dist_entropy": 0.6910495162010193, "actor_grad_norm": 0.08223460614681244, "critic_grad_norm": 0.06343766301870346, "ratio": 0.9999565482139587, "entropy": 0.6910495162010193, "incre_win_rate": 0.8409090909090909, "step": 2436}
{"time": 1767163331.4474301, "phase": "train", "update": 2437, "total_env_steps": 7798400, "episode_reward": 0.2802969813346863, "value_loss": 0.006730713229626417, "policy_loss": -0.0014178768883045477, "dist_entropy": 0.6993772506713867, "actor_grad_norm": 0.08673330396413803, "critic_grad_norm": 0.061641134321689606, "ratio": 0.9999500513076782, "entropy": 0.6993772506713867, "incre_win_rate": 0.9555555555555556, "step": 2437}
{"time": 1767163335.6848822, "phase": "train", "update": 2438, "total_env_steps": 7801600, "episode_reward": 0.26194173097610474, "value_loss": 0.008019966259598731, "policy_loss": -0.0019533797774222705, "dist_entropy": 0.6803015470504761, "actor_grad_norm": 0.0970197543501854, "critic_grad_norm": 0.07406052201986313, "ratio": 1.0000529289245605, "entropy": 0.6803015470504761, "incre_win_rate": 0.9069767441860465, "step": 2438}
{"time": 1767163339.9191587, "phase": "train", "update": 2439, "total_env_steps": 7804800, "episode_reward": 0.26220303773880005, "value_loss": 0.006036942638456821, "policy_loss": -0.0010190602297967643, "dist_entropy": 0.6836876749992371, "actor_grad_norm": 0.06875204294919968, "critic_grad_norm": 0.16295333206653595, "ratio": 1.000171184539795, "entropy": 0.6836876749992371, "incre_win_rate": 0.8571428571428571, "step": 2439}
{"time": 1767163344.16639, "phase": "train", "update": 2440, "total_env_steps": 7808000, "episode_reward": 0.275997519493103, "value_loss": 0.004934719577431679, "policy_loss": -0.0012020476860243434, "dist_entropy": 0.726723575592041, "actor_grad_norm": 0.10067298263311386, "critic_grad_norm": 0.10178988426923752, "ratio": 1.0006211996078491, "entropy": 0.726723575592041, "incre_win_rate": 0.8913043478260869, "step": 2440}
{"time": 1767163348.41692, "phase": "train", "update": 2441, "total_env_steps": 7811200, "episode_reward": 0.2601448893547058, "value_loss": 0.009007097780704498, "policy_loss": -0.0013987813308048657, "dist_entropy": 0.6976750373840332, "actor_grad_norm": 0.10275019705295563, "critic_grad_norm": 0.2060054987668991, "ratio": 1.0000994205474854, "entropy": 0.6976750373840332, "incre_win_rate": 0.8409090909090909, "step": 2441}
{"time": 1767163358.5327682, "phase": "eval", "update": 2441, "total_env_steps": 7811200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.704056291390728, "step": 2441}
{"time": 1767163362.7747564, "phase": "train", "update": 2442, "total_env_steps": 7814400, "episode_reward": 0.27237996459007263, "value_loss": 0.00853964351117611, "policy_loss": -0.0011262792779376696, "dist_entropy": 0.7077414274215699, "actor_grad_norm": 0.08574024587869644, "critic_grad_norm": 0.12060149013996124, "ratio": 1.0000087022781372, "entropy": 0.7077414274215699, "incre_win_rate": 0.8666666666666667, "step": 2442}
{"time": 1767163367.0385895, "phase": "train", "update": 2443, "total_env_steps": 7817600, "episode_reward": 0.270230770111084, "value_loss": 0.007193540502339601, "policy_loss": -0.001112349784766309, "dist_entropy": 0.7166037321090698, "actor_grad_norm": 0.09809834510087967, "critic_grad_norm": 0.13121823966503143, "ratio": 1.0001214742660522, "entropy": 0.7166037321090698, "incre_win_rate": 0.9318181818181818, "step": 2443}
{"time": 1767163371.34809, "phase": "train", "update": 2444, "total_env_steps": 7820800, "episode_reward": 0.2615624964237213, "value_loss": 0.010299484990537167, "policy_loss": -0.001320703059900552, "dist_entropy": 0.7198446035385132, "actor_grad_norm": 0.09386517852544785, "critic_grad_norm": 0.11123435944318771, "ratio": 0.9998722076416016, "entropy": 0.7198446035385132, "incre_win_rate": 0.8372093023255814, "step": 2444}
{"time": 1767163375.5993168, "phase": "train", "update": 2445, "total_env_steps": 7824000, "episode_reward": 0.264052152633667, "value_loss": 0.007972597982734442, "policy_loss": -0.0011959763699579185, "dist_entropy": 0.7277274608612061, "actor_grad_norm": 0.09412015229463577, "critic_grad_norm": 0.15418587625026703, "ratio": 1.0000944137573242, "entropy": 0.7277274608612061, "incre_win_rate": 0.8444444444444444, "step": 2445}
{"time": 1767163379.870843, "phase": "train", "update": 2446, "total_env_steps": 7827200, "episode_reward": 0.27179738879203796, "value_loss": 0.009203879348933696, "policy_loss": -0.0010972252420984319, "dist_entropy": 0.7289964079856872, "actor_grad_norm": 0.10472144186496735, "critic_grad_norm": 0.05092313513159752, "ratio": 0.9996458888053894, "entropy": 0.7289964079856872, "incre_win_rate": 0.8444444444444444, "step": 2446}
{"time": 1767163384.1789434, "phase": "train", "update": 2447, "total_env_steps": 7830400, "episode_reward": 0.26418355107307434, "value_loss": 0.010404085926711559, "policy_loss": -0.0008270156721650324, "dist_entropy": 0.7439067125320434, "actor_grad_norm": 0.10373418778181076, "critic_grad_norm": 0.12914501130580902, "ratio": 0.9998515248298645, "entropy": 0.7439067125320434, "incre_win_rate": 0.7777777777777778, "step": 2447}
{"time": 1767163388.492345, "phase": "train", "update": 2448, "total_env_steps": 7833600, "episode_reward": 0.26713523268699646, "value_loss": 0.00803872812539339, "policy_loss": -0.001485416999413669, "dist_entropy": 0.7489109873771668, "actor_grad_norm": 0.11521197855472565, "critic_grad_norm": 0.16100764274597168, "ratio": 0.9997096061706543, "entropy": 0.7489109873771668, "incre_win_rate": 0.8, "step": 2448}
{"time": 1767163392.8594477, "phase": "train", "update": 2449, "total_env_steps": 7836800, "episode_reward": 0.2612546682357788, "value_loss": 0.01262570433318615, "policy_loss": -0.0014557122339999063, "dist_entropy": 0.7250002861022949, "actor_grad_norm": 0.12827637791633606, "critic_grad_norm": 0.16976229846477509, "ratio": 0.9992262721061707, "entropy": 0.7250002861022949, "incre_win_rate": 0.7111111111111111, "step": 2449}
{"time": 1767163426.6085372, "phase": "train", "update": 2450, "total_env_steps": 7840000, "episode_reward": 0.2510456442832947, "value_loss": 0.061232981830835344, "policy_loss": -0.0005974861905702955, "dist_entropy": 0.7278303384780884, "actor_grad_norm": 0.10504620522260666, "critic_grad_norm": 0.4845426678657532, "ratio": 1.0001145601272583, "entropy": 0.7278303384780884, "incre_win_rate": 0.7441860465116279, "step": 2450}
{"time": 1767163430.9199014, "phase": "train", "update": 2451, "total_env_steps": 7843200, "episode_reward": 0.27445781230926514, "value_loss": 0.00844874493777752, "policy_loss": -0.0011495910190554071, "dist_entropy": 0.7325030565261841, "actor_grad_norm": 0.09249570220708847, "critic_grad_norm": 0.20169630646705627, "ratio": 0.9998783469200134, "entropy": 0.7325030565261841, "incre_win_rate": 0.8095238095238095, "step": 2451}
{"time": 1767163435.177264, "phase": "train", "update": 2452, "total_env_steps": 7846400, "episode_reward": 0.2673541009426117, "value_loss": 0.01181997861713171, "policy_loss": -0.0012227097976506228, "dist_entropy": 0.7186337471008301, "actor_grad_norm": 0.09524518996477127, "critic_grad_norm": 0.13105151057243347, "ratio": 1.0001863241195679, "entropy": 0.7186337471008301, "incre_win_rate": 0.782608695652174, "step": 2452}
{"time": 1767163439.4076889, "phase": "train", "update": 2453, "total_env_steps": 7849600, "episode_reward": 0.2558661103248596, "value_loss": 0.011654412001371383, "policy_loss": -0.001562456370910681, "dist_entropy": 0.7339317798614502, "actor_grad_norm": 0.09257327765226364, "critic_grad_norm": 0.07527140527963638, "ratio": 1.000002145767212, "entropy": 0.7339317798614502, "incre_win_rate": 0.782608695652174, "step": 2453}
{"time": 1767163443.6863122, "phase": "train", "update": 2454, "total_env_steps": 7852800, "episode_reward": 0.26376500725746155, "value_loss": 0.011407358385622502, "policy_loss": -0.0014985910363193966, "dist_entropy": 0.7164348721504211, "actor_grad_norm": 0.09813379496335983, "critic_grad_norm": 0.15559186041355133, "ratio": 0.9997214674949646, "entropy": 0.7164348721504211, "incre_win_rate": 0.7555555555555555, "step": 2454}
{"time": 1767163447.9766662, "phase": "train", "update": 2455, "total_env_steps": 7856000, "episode_reward": 0.262129545211792, "value_loss": 0.01098784189671278, "policy_loss": -0.001171710234952883, "dist_entropy": 0.7260282397270202, "actor_grad_norm": 0.10022120922803879, "critic_grad_norm": 0.1797885000705719, "ratio": 1.0003589391708374, "entropy": 0.7260282397270202, "incre_win_rate": 0.7906976744186046, "step": 2455}
{"time": 1767163452.2318716, "phase": "train", "update": 2456, "total_env_steps": 7859200, "episode_reward": 0.26708194613456726, "value_loss": 0.007208489999175072, "policy_loss": -0.0014625896477786782, "dist_entropy": 0.7590472817420959, "actor_grad_norm": 0.09962373971939087, "critic_grad_norm": 0.06084897741675377, "ratio": 1.0000666379928589, "entropy": 0.7590472817420959, "incre_win_rate": 0.8636363636363636, "step": 2456}
{"time": 1767163456.4978075, "phase": "train", "update": 2457, "total_env_steps": 7862400, "episode_reward": 0.2800025939941406, "value_loss": 0.005403862800449133, "policy_loss": -0.0013453294668096306, "dist_entropy": 0.7493537187576294, "actor_grad_norm": 0.09291594475507736, "critic_grad_norm": 0.09664013236761093, "ratio": 0.9999683499336243, "entropy": 0.7493537187576294, "incre_win_rate": 0.9555555555555556, "step": 2457}
{"time": 1767163460.8102236, "phase": "train", "update": 2458, "total_env_steps": 7865600, "episode_reward": 0.2700584828853607, "value_loss": 0.008045016415417194, "policy_loss": -0.0012064315362351862, "dist_entropy": 0.7453759431838989, "actor_grad_norm": 0.09107169508934021, "critic_grad_norm": 0.08364524692296982, "ratio": 0.9998834729194641, "entropy": 0.7453759431838989, "incre_win_rate": 0.8478260869565217, "step": 2458}
{"time": 1767163465.063047, "phase": "train", "update": 2459, "total_env_steps": 7868800, "episode_reward": 0.28011903166770935, "value_loss": 0.004899312742054462, "policy_loss": -0.0011884882663130369, "dist_entropy": 0.7413673043251038, "actor_grad_norm": 0.09375778585672379, "critic_grad_norm": 0.1270447075366974, "ratio": 0.9994926452636719, "entropy": 0.7413673043251038, "incre_win_rate": 0.9534883720930233, "step": 2459}
{"time": 1767163469.3407102, "phase": "train", "update": 2460, "total_env_steps": 7872000, "episode_reward": 0.2668558657169342, "value_loss": 0.007831163797527551, "policy_loss": -0.001169147558118766, "dist_entropy": 0.7227845907211303, "actor_grad_norm": 0.08739441633224487, "critic_grad_norm": 0.14430658519268036, "ratio": 0.9997650980949402, "entropy": 0.7227845907211303, "incre_win_rate": 0.8723404255319149, "step": 2460}
{"time": 1767163473.6075451, "phase": "train", "update": 2461, "total_env_steps": 7875200, "episode_reward": 0.2663659155368805, "value_loss": 0.00829656794667244, "policy_loss": -0.0010961654909358743, "dist_entropy": 0.7147426724433898, "actor_grad_norm": 0.08027727901935577, "critic_grad_norm": 0.0809478908777237, "ratio": 0.9997789263725281, "entropy": 0.7147426724433898, "incre_win_rate": 0.8333333333333334, "step": 2461}
{"time": 1767163483.0214024, "phase": "eval", "update": 2461, "total_env_steps": 7875200, "eval_win_rate": 1.0, "eval_episode_reward": 20.0, "step": 2461}
{"time": 1767163487.308285, "phase": "train", "update": 2462, "total_env_steps": 7878400, "episode_reward": 0.27925392985343933, "value_loss": 0.0037357625085860493, "policy_loss": -0.0015890593001408604, "dist_entropy": 0.7116462230682373, "actor_grad_norm": 0.10059446096420288, "critic_grad_norm": 0.09920671582221985, "ratio": 1.000141978263855, "entropy": 0.7116462230682373, "incre_win_rate": 0.9574468085106383, "step": 2462}
{"time": 1767163491.5759113, "phase": "train", "update": 2463, "total_env_steps": 7881600, "episode_reward": 0.27164116501808167, "value_loss": 0.005872963089495897, "policy_loss": -0.0014479534540825512, "dist_entropy": 0.6994062900543213, "actor_grad_norm": 0.08874034136533737, "critic_grad_norm": 0.03751595690846443, "ratio": 0.9995312690734863, "entropy": 0.6994062900543213, "incre_win_rate": 0.9318181818181818, "step": 2463}
{"time": 1767163495.8507633, "phase": "train", "update": 2464, "total_env_steps": 7884800, "episode_reward": 0.27078741788864136, "value_loss": 0.00527291763573885, "policy_loss": -0.0010299830194398397, "dist_entropy": 0.6709132313728332, "actor_grad_norm": 0.08676987141370773, "critic_grad_norm": 0.040456127375364304, "ratio": 0.9999651312828064, "entropy": 0.6709132313728332, "incre_win_rate": 0.8863636363636364, "step": 2464}
{"time": 1767163500.1117785, "phase": "train", "update": 2465, "total_env_steps": 7888000, "episode_reward": 0.2659830152988434, "value_loss": 0.01252647303044796, "policy_loss": -0.001322693497187899, "dist_entropy": 0.6650650262832641, "actor_grad_norm": 0.0971718579530716, "critic_grad_norm": 0.15606525540351868, "ratio": 0.9998369216918945, "entropy": 0.6650650262832641, "incre_win_rate": 0.8444444444444444, "step": 2465}
{"time": 1767163504.3939226, "phase": "train", "update": 2466, "total_env_steps": 7891200, "episode_reward": 0.2765847444534302, "value_loss": 0.007768906746059656, "policy_loss": -0.0010204702193902903, "dist_entropy": 0.6432766795158387, "actor_grad_norm": 0.0952523946762085, "critic_grad_norm": 0.1631534993648529, "ratio": 1.0000286102294922, "entropy": 0.6432766795158387, "incre_win_rate": 0.9111111111111111, "step": 2466}
{"time": 1767163508.6731417, "phase": "train", "update": 2467, "total_env_steps": 7894400, "episode_reward": 0.2681167423725128, "value_loss": 0.010535175912082195, "policy_loss": -0.0014770205872266073, "dist_entropy": 0.6505464553833008, "actor_grad_norm": 0.100274458527565, "critic_grad_norm": 0.1180693507194519, "ratio": 0.999903678894043, "entropy": 0.6505464553833008, "incre_win_rate": 0.8666666666666667, "step": 2467}
{"time": 1767163512.957028, "phase": "train", "update": 2468, "total_env_steps": 7897600, "episode_reward": 0.2608443796634674, "value_loss": 0.0058644721284508705, "policy_loss": -0.0014306922920557241, "dist_entropy": 0.651966655254364, "actor_grad_norm": 0.08102499693632126, "critic_grad_norm": 0.12260379642248154, "ratio": 0.9997718930244446, "entropy": 0.651966655254364, "incre_win_rate": 0.8695652173913043, "step": 2468}
{"time": 1767163517.2144258, "phase": "train", "update": 2469, "total_env_steps": 7900800, "episode_reward": 0.282421350479126, "value_loss": 0.005986025370657444, "policy_loss": -0.0009817116863906961, "dist_entropy": 0.6674151062965393, "actor_grad_norm": 0.07577728480100632, "critic_grad_norm": 0.09720565378665924, "ratio": 0.9998989105224609, "entropy": 0.6674151062965393, "incre_win_rate": 0.975, "step": 2469}
{"time": 1767163521.486153, "phase": "train", "update": 2470, "total_env_steps": 7904000, "episode_reward": 0.2779289186000824, "value_loss": 0.003608176251873374, "policy_loss": -0.0010484377687760115, "dist_entropy": 0.6821428537368774, "actor_grad_norm": 0.08878887444734573, "critic_grad_norm": 0.06426485627889633, "ratio": 1.0000531673431396, "entropy": 0.6821428537368774, "incre_win_rate": 0.9361702127659575, "step": 2470}
{"time": 1767163525.7546144, "phase": "train", "update": 2471, "total_env_steps": 7907200, "episode_reward": 0.26893264055252075, "value_loss": 0.0055740284733474255, "policy_loss": -0.0013630261753903028, "dist_entropy": 0.6753600835800171, "actor_grad_norm": 0.08914696425199509, "critic_grad_norm": 0.06358959525823593, "ratio": 0.9993875622749329, "entropy": 0.6753600835800171, "incre_win_rate": 0.9130434782608695, "step": 2471}
{"time": 1767163530.0578823, "phase": "train", "update": 2472, "total_env_steps": 7910400, "episode_reward": 0.2781793177127838, "value_loss": 0.004092082660645246, "policy_loss": -0.0011303377662059688, "dist_entropy": 0.6831150650978088, "actor_grad_norm": 0.0826820582151413, "critic_grad_norm": 0.07271511852741241, "ratio": 0.9998505711555481, "entropy": 0.6831150650978088, "incre_win_rate": 0.9545454545454546, "step": 2472}
{"time": 1767163534.3308296, "phase": "train", "update": 2473, "total_env_steps": 7913600, "episode_reward": 0.28362739086151123, "value_loss": 0.0029287973884493113, "policy_loss": -0.0008912371728502678, "dist_entropy": 0.7027970075607299, "actor_grad_norm": 0.07043734937906265, "critic_grad_norm": 0.05234479531645775, "ratio": 1.0002503395080566, "entropy": 0.7027970075607299, "incre_win_rate": 0.9574468085106383, "step": 2473}
{"time": 1767163538.6252832, "phase": "train", "update": 2474, "total_env_steps": 7916800, "episode_reward": 0.2749037444591522, "value_loss": 0.004477507062256336, "policy_loss": -0.0014802784828031434, "dist_entropy": 0.7053910374641419, "actor_grad_norm": 0.09433543682098389, "critic_grad_norm": 0.054422225803136826, "ratio": 0.9998647570610046, "entropy": 0.7053910374641419, "incre_win_rate": 0.9318181818181818, "step": 2474}
{"time": 1767163542.928245, "phase": "train", "update": 2475, "total_env_steps": 7920000, "episode_reward": 0.2699917256832123, "value_loss": 0.007683927193284035, "policy_loss": -0.0014312007869595079, "dist_entropy": 0.7154903650283814, "actor_grad_norm": 0.0915747806429863, "critic_grad_norm": 0.08261676132678986, "ratio": 1.0000178813934326, "entropy": 0.7154903650283814, "incre_win_rate": 0.8666666666666667, "step": 2475}
{"time": 1767163547.236186, "phase": "train", "update": 2476, "total_env_steps": 7923200, "episode_reward": 0.27571192383766174, "value_loss": 0.008587085083127022, "policy_loss": -0.0011966498116620984, "dist_entropy": 0.7327630877494812, "actor_grad_norm": 0.09116894006729126, "critic_grad_norm": 0.11580204963684082, "ratio": 0.9993045926094055, "entropy": 0.7327630877494812, "incre_win_rate": 0.8888888888888888, "step": 2476}
{"time": 1767163551.5042658, "phase": "train", "update": 2477, "total_env_steps": 7926400, "episode_reward": 0.26658526062965393, "value_loss": 0.0060648518614470955, "policy_loss": -0.001142499653973772, "dist_entropy": 0.7290565252304078, "actor_grad_norm": 0.09233248233795166, "critic_grad_norm": 0.10615775734186172, "ratio": 0.9999548196792603, "entropy": 0.7290565252304078, "incre_win_rate": 0.8837209302325582, "step": 2477}
{"time": 1767163555.7808495, "phase": "train", "update": 2478, "total_env_steps": 7929600, "episode_reward": 0.26838988065719604, "value_loss": 0.005525671318173409, "policy_loss": -0.0008100596158826078, "dist_entropy": 0.7254427433013916, "actor_grad_norm": 0.08450635522603989, "critic_grad_norm": 0.06742602586746216, "ratio": 1.0002561807632446, "entropy": 0.7254427433013916, "incre_win_rate": 0.8666666666666667, "step": 2478}
{"time": 1767163560.0925436, "phase": "train", "update": 2479, "total_env_steps": 7932800, "episode_reward": 0.2687453627586365, "value_loss": 0.006446860916912556, "policy_loss": -0.0013719021577742296, "dist_entropy": 0.7256258249282836, "actor_grad_norm": 0.08424270153045654, "critic_grad_norm": 0.10596483200788498, "ratio": 0.9999094009399414, "entropy": 0.7256258249282836, "incre_win_rate": 0.8888888888888888, "step": 2479}
{"time": 1767163564.4175432, "phase": "train", "update": 2480, "total_env_steps": 7936000, "episode_reward": 0.2756829559803009, "value_loss": 0.0036229337099939586, "policy_loss": -0.0012221470752201923, "dist_entropy": 0.7244125604629517, "actor_grad_norm": 0.08292297273874283, "critic_grad_norm": 0.04187042638659477, "ratio": 1.0000933408737183, "entropy": 0.7244125604629517, "incre_win_rate": 0.9545454545454546, "step": 2480}
{"time": 1767163568.7231317, "phase": "train", "update": 2481, "total_env_steps": 7939200, "episode_reward": 0.27011847496032715, "value_loss": 0.007021626085042953, "policy_loss": -0.0011861572757737803, "dist_entropy": 0.7208146214485168, "actor_grad_norm": 0.08915585279464722, "critic_grad_norm": 0.06816127151250839, "ratio": 0.9997705817222595, "entropy": 0.7208146214485168, "incre_win_rate": 0.8666666666666667, "step": 2481}
{"time": 1767163578.1545825, "phase": "eval", "update": 2481, "total_env_steps": 7939200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.736754966887418, "step": 2481}
{"time": 1767163582.396552, "phase": "train", "update": 2482, "total_env_steps": 7942400, "episode_reward": 0.27631932497024536, "value_loss": 0.005656516179442406, "policy_loss": -0.0013033046169262264, "dist_entropy": 0.7245853066444397, "actor_grad_norm": 0.09440261870622635, "critic_grad_norm": 0.09241761267185211, "ratio": 1.0003645420074463, "entropy": 0.7245853066444397, "incre_win_rate": 0.9555555555555556, "step": 2482}
{"time": 1767163586.6537027, "phase": "train", "update": 2483, "total_env_steps": 7945600, "episode_reward": 0.2617637813091278, "value_loss": 0.007801404967904091, "policy_loss": -0.001281319122095681, "dist_entropy": 0.7078029751777649, "actor_grad_norm": 0.08613480627536774, "critic_grad_norm": 0.11062798649072647, "ratio": 0.9996895790100098, "entropy": 0.7078029751777649, "incre_win_rate": 0.8571428571428571, "step": 2483}
{"time": 1767163590.9818308, "phase": "train", "update": 2484, "total_env_steps": 7948800, "episode_reward": 0.26596078276634216, "value_loss": 0.006680891942232847, "policy_loss": -0.0011686515931277341, "dist_entropy": 0.7152253866195679, "actor_grad_norm": 0.08884243667125702, "critic_grad_norm": 0.053673919290304184, "ratio": 1.0000821352005005, "entropy": 0.7152253866195679, "incre_win_rate": 0.8260869565217391, "step": 2484}
{"time": 1767163595.2728064, "phase": "train", "update": 2485, "total_env_steps": 7952000, "episode_reward": 0.27004140615463257, "value_loss": 0.007514678314328194, "policy_loss": -0.001344951001127015, "dist_entropy": 0.7127452492713928, "actor_grad_norm": 0.09788510203361511, "critic_grad_norm": 0.0851638987660408, "ratio": 1.0000218152999878, "entropy": 0.7127452492713928, "incre_win_rate": 0.8863636363636364, "step": 2485}
{"time": 1767163599.6332688, "phase": "train", "update": 2486, "total_env_steps": 7955200, "episode_reward": 0.279060423374176, "value_loss": 0.008399053849279881, "policy_loss": -0.0013977361549353696, "dist_entropy": 0.7231408476829528, "actor_grad_norm": 0.0944783091545105, "critic_grad_norm": 0.054993242025375366, "ratio": 0.9996764063835144, "entropy": 0.7231408476829528, "incre_win_rate": 0.8913043478260869, "step": 2486}
{"time": 1767163603.907718, "phase": "train", "update": 2487, "total_env_steps": 7958400, "episode_reward": 0.2827235162258148, "value_loss": 0.004940154124051332, "policy_loss": -0.0010763434200597999, "dist_entropy": 0.708746337890625, "actor_grad_norm": 0.06606128066778183, "critic_grad_norm": 0.07039174437522888, "ratio": 0.9999544024467468, "entropy": 0.708746337890625, "incre_win_rate": 0.9333333333333333, "step": 2487}
{"time": 1767163608.1675558, "phase": "train", "update": 2488, "total_env_steps": 7961600, "episode_reward": 0.2756043076515198, "value_loss": 0.00556408278644085, "policy_loss": -0.0013615483856909804, "dist_entropy": 0.7193327069282531, "actor_grad_norm": 0.08453543484210968, "critic_grad_norm": 0.04521679878234863, "ratio": 0.9999745488166809, "entropy": 0.7193327069282531, "incre_win_rate": 0.9130434782608695, "step": 2488}
{"time": 1767163612.489901, "phase": "train", "update": 2489, "total_env_steps": 7964800, "episode_reward": 0.2698841094970703, "value_loss": 0.00620571244508028, "policy_loss": -0.0014990501520898646, "dist_entropy": 0.722687029838562, "actor_grad_norm": 0.08324545621871948, "critic_grad_norm": 0.03728773072361946, "ratio": 1.000238299369812, "entropy": 0.722687029838562, "incre_win_rate": 0.8837209302325582, "step": 2489}
{"time": 1767163616.832992, "phase": "train", "update": 2490, "total_env_steps": 7968000, "episode_reward": 0.2680794596672058, "value_loss": 0.00983784832060337, "policy_loss": -0.0012809439238736786, "dist_entropy": 0.7251923561096192, "actor_grad_norm": 0.09731645882129669, "critic_grad_norm": 0.11950056999921799, "ratio": 1.0000369548797607, "entropy": 0.7251923561096192, "incre_win_rate": 0.7872340425531915, "step": 2490}
{"time": 1767163621.1396039, "phase": "train", "update": 2491, "total_env_steps": 7971200, "episode_reward": 0.26469478011131287, "value_loss": 0.0099540114402771, "policy_loss": -0.0013325233245968348, "dist_entropy": 0.7317882537841797, "actor_grad_norm": 0.08207850903272629, "critic_grad_norm": 0.11933746188879013, "ratio": 0.9999670386314392, "entropy": 0.7317882537841797, "incre_win_rate": 0.7777777777777778, "step": 2491}
{"time": 1767163625.4223418, "phase": "train", "update": 2492, "total_env_steps": 7974400, "episode_reward": 0.2709525227546692, "value_loss": 0.010179177857935429, "policy_loss": -0.001687013462252196, "dist_entropy": 0.7404410600662231, "actor_grad_norm": 0.09870275855064392, "critic_grad_norm": 0.1049313098192215, "ratio": 0.999677836894989, "entropy": 0.7404410600662231, "incre_win_rate": 0.8863636363636364, "step": 2492}
{"time": 1767163629.6742785, "phase": "train", "update": 2493, "total_env_steps": 7977600, "episode_reward": 0.26081228256225586, "value_loss": 0.0077214142307639125, "policy_loss": -0.0014779432090485044, "dist_entropy": 0.7208840012550354, "actor_grad_norm": 0.09149638563394547, "critic_grad_norm": 0.07051354646682739, "ratio": 0.9996468424797058, "entropy": 0.7208840012550354, "incre_win_rate": 0.7727272727272727, "step": 2493}
{"time": 1767163633.961861, "phase": "train", "update": 2494, "total_env_steps": 7980800, "episode_reward": 0.26475784182548523, "value_loss": 0.009540832974016667, "policy_loss": -0.0011706173427327826, "dist_entropy": 0.7212191224098206, "actor_grad_norm": 0.10134866088628769, "critic_grad_norm": 0.0615464448928833, "ratio": 0.9998921751976013, "entropy": 0.7212191224098206, "incre_win_rate": 0.8409090909090909, "step": 2494}
{"time": 1767163638.2662106, "phase": "train", "update": 2495, "total_env_steps": 7984000, "episode_reward": 0.2679460048675537, "value_loss": 0.00722079249098897, "policy_loss": -0.0014361364976348766, "dist_entropy": 0.7117562174797059, "actor_grad_norm": 0.0998719111084938, "critic_grad_norm": 0.05515044927597046, "ratio": 0.9998418092727661, "entropy": 0.7117562174797059, "incre_win_rate": 0.8478260869565217, "step": 2495}
{"time": 1767163642.550877, "phase": "train", "update": 2496, "total_env_steps": 7987200, "episode_reward": 0.2672656178474426, "value_loss": 0.009266767464578152, "policy_loss": -0.0015433692296546564, "dist_entropy": 0.70643630027771, "actor_grad_norm": 0.08945576101541519, "critic_grad_norm": 0.07781388610601425, "ratio": 0.9997729659080505, "entropy": 0.70643630027771, "incre_win_rate": 0.8181818181818182, "step": 2496}
{"time": 1767163646.8119543, "phase": "train", "update": 2497, "total_env_steps": 7990400, "episode_reward": 0.26051223278045654, "value_loss": 0.011346510984003544, "policy_loss": -0.0012558767416575023, "dist_entropy": 0.6920549392700195, "actor_grad_norm": 0.08382748812437057, "critic_grad_norm": 0.08558637648820877, "ratio": 1.0000044107437134, "entropy": 0.6920549392700195, "incre_win_rate": 0.7777777777777778, "step": 2497}
{"time": 1767163651.103449, "phase": "train", "update": 2498, "total_env_steps": 7993600, "episode_reward": 0.27482670545578003, "value_loss": 0.008068654872477054, "policy_loss": -0.001848425712547197, "dist_entropy": 0.7026294827461242, "actor_grad_norm": 0.11320900917053223, "critic_grad_norm": 0.077054463326931, "ratio": 1.0000072717666626, "entropy": 0.7026294827461242, "incre_win_rate": 0.8666666666666667, "step": 2498}
{"time": 1767163655.404224, "phase": "train", "update": 2499, "total_env_steps": 7996800, "episode_reward": 0.275025337934494, "value_loss": 0.007123913057148457, "policy_loss": -0.0009780546503122879, "dist_entropy": 0.7000348091125488, "actor_grad_norm": 0.13020312786102295, "critic_grad_norm": 0.0947716161608696, "ratio": 0.9990999102592468, "entropy": 0.7000348091125488, "incre_win_rate": 0.8936170212765957, "step": 2499}
{"time": 1767163659.6573281, "phase": "train", "update": 2500, "total_env_steps": 8000000, "episode_reward": 0.26707780361175537, "value_loss": 0.006374968774616718, "policy_loss": -0.0009560360957927116, "dist_entropy": 0.6957752108573914, "actor_grad_norm": 0.11922593414783478, "critic_grad_norm": 0.06006857380270958, "ratio": 1.0001071691513062, "entropy": 0.6957752108573914, "incre_win_rate": 0.9090909090909091, "step": 2500}
{"time": 1767163663.9855227, "phase": "train", "update": 2501, "total_env_steps": 8003200, "episode_reward": 0.27636176347732544, "value_loss": 0.0044241083785891535, "policy_loss": -0.0008632401193537475, "dist_entropy": 0.7140060663223267, "actor_grad_norm": 0.09862645715475082, "critic_grad_norm": 0.08469941467046738, "ratio": 1.000001311302185, "entropy": 0.7140060663223267, "incre_win_rate": 0.9318181818181818, "step": 2501}
{"time": 1767163673.8610566, "phase": "eval", "update": 2501, "total_env_steps": 8003200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.761175496688743, "step": 2501}
{"time": 1767163678.1363764, "phase": "train", "update": 2502, "total_env_steps": 8006400, "episode_reward": 0.26971906423568726, "value_loss": 0.006451273057609797, "policy_loss": -0.0013061556683041432, "dist_entropy": 0.7017658710479736, "actor_grad_norm": 0.10701096057891846, "critic_grad_norm": 0.10484402626752853, "ratio": 0.9998943209648132, "entropy": 0.7017658710479736, "incre_win_rate": 0.8444444444444444, "step": 2502}
{"time": 1767163682.4737155, "phase": "train", "update": 2503, "total_env_steps": 8009600, "episode_reward": 0.28215229511260986, "value_loss": 0.0052458283491432665, "policy_loss": -0.0007541123209090728, "dist_entropy": 0.7301722526550293, "actor_grad_norm": 0.09602528065443039, "critic_grad_norm": 0.06993237137794495, "ratio": 0.9995325207710266, "entropy": 0.7301722526550293, "incre_win_rate": 0.9333333333333333, "step": 2503}
{"time": 1767163686.7358077, "phase": "train", "update": 2504, "total_env_steps": 8012800, "episode_reward": 0.26415562629699707, "value_loss": 0.008448715321719646, "policy_loss": -0.0010898472609720878, "dist_entropy": 0.7037113428115844, "actor_grad_norm": 0.10516355186700821, "critic_grad_norm": 0.1899842917919159, "ratio": 1.0001450777053833, "entropy": 0.7037113428115844, "incre_win_rate": 0.8222222222222222, "step": 2504}
{"time": 1767163691.036628, "phase": "train", "update": 2505, "total_env_steps": 8016000, "episode_reward": 0.2708728313446045, "value_loss": 0.008837230317294598, "policy_loss": -0.0014520813216266858, "dist_entropy": 0.7190593004226684, "actor_grad_norm": 0.09665635973215103, "critic_grad_norm": 0.15242980420589447, "ratio": 0.9998779296875, "entropy": 0.7190593004226684, "incre_win_rate": 0.8444444444444444, "step": 2505}
{"time": 1767163695.3455782, "phase": "train", "update": 2506, "total_env_steps": 8019200, "episode_reward": 0.27694588899612427, "value_loss": 0.00551510825753212, "policy_loss": -0.0011558332289681062, "dist_entropy": 0.7286456823348999, "actor_grad_norm": 0.10584024339914322, "critic_grad_norm": 0.1633310616016388, "ratio": 1.0002774000167847, "entropy": 0.7286456823348999, "incre_win_rate": 0.9347826086956522, "step": 2506}
{"time": 1767163699.624126, "phase": "train", "update": 2507, "total_env_steps": 8022400, "episode_reward": 0.2735016644001007, "value_loss": 0.005000709649175405, "policy_loss": -0.001369850187336441, "dist_entropy": 0.7465634703636169, "actor_grad_norm": 0.11579102277755737, "critic_grad_norm": 0.05614263564348221, "ratio": 1.0000985860824585, "entropy": 0.7465634703636169, "incre_win_rate": 0.9111111111111111, "step": 2507}
{"time": 1767163703.951943, "phase": "train", "update": 2508, "total_env_steps": 8025600, "episode_reward": 0.2713679373264313, "value_loss": 0.005296899657696486, "policy_loss": -0.0009330232223451418, "dist_entropy": 0.728605580329895, "actor_grad_norm": 0.09472846239805222, "critic_grad_norm": 0.07387806475162506, "ratio": 1.0000156164169312, "entropy": 0.728605580329895, "incre_win_rate": 0.8636363636363636, "step": 2508}
{"time": 1767163708.236464, "phase": "train", "update": 2509, "total_env_steps": 8028800, "episode_reward": 0.2660311460494995, "value_loss": 0.008523198030889034, "policy_loss": -0.0014854771240401022, "dist_entropy": 0.7493610620498657, "actor_grad_norm": 0.0969507023692131, "critic_grad_norm": 0.06194864585995674, "ratio": 1.0000853538513184, "entropy": 0.7493610620498657, "incre_win_rate": 0.9285714285714286, "step": 2509}
{"time": 1767163712.4786751, "phase": "train", "update": 2510, "total_env_steps": 8032000, "episode_reward": 0.2739320993423462, "value_loss": 0.0044511152431368824, "policy_loss": -0.0010338328213737925, "dist_entropy": 0.7301715970039367, "actor_grad_norm": 0.07254020124673843, "critic_grad_norm": 0.05209809169173241, "ratio": 0.9999251365661621, "entropy": 0.7301715970039367, "incre_win_rate": 0.9361702127659575, "step": 2510}
{"time": 1767163716.7216525, "phase": "train", "update": 2511, "total_env_steps": 8035200, "episode_reward": 0.27236342430114746, "value_loss": 0.004976769164204598, "policy_loss": -0.0014177597808487264, "dist_entropy": 0.7235964417457581, "actor_grad_norm": 0.07964618504047394, "critic_grad_norm": 0.05219079181551933, "ratio": 0.999179482460022, "entropy": 0.7235964417457581, "incre_win_rate": 0.9512195121951219, "step": 2511}
{"time": 1767163720.9777853, "phase": "train", "update": 2512, "total_env_steps": 8038400, "episode_reward": 0.27000001072883606, "value_loss": 0.005795738752931356, "policy_loss": -0.0010816858166296406, "dist_entropy": 0.7089958548545837, "actor_grad_norm": 0.08208141475915909, "critic_grad_norm": 0.08048601448535919, "ratio": 1.0001097917556763, "entropy": 0.7089958548545837, "incre_win_rate": 0.8936170212765957, "step": 2512}
{"time": 1767163725.2213373, "phase": "train", "update": 2513, "total_env_steps": 8041600, "episode_reward": 0.2833195626735687, "value_loss": 0.0047249277122318745, "policy_loss": -0.00100251182412876, "dist_entropy": 0.7211982607841492, "actor_grad_norm": 0.07577182352542877, "critic_grad_norm": 0.07752702385187149, "ratio": 1.0001991987228394, "entropy": 0.7211982607841492, "incre_win_rate": 0.9565217391304348, "step": 2513}
{"time": 1767163729.4359174, "phase": "train", "update": 2514, "total_env_steps": 8044800, "episode_reward": 0.27441227436065674, "value_loss": 0.004621221870183945, "policy_loss": -0.0012482818431124088, "dist_entropy": 0.7192859292030335, "actor_grad_norm": 0.07766329497098923, "critic_grad_norm": 0.05085780844092369, "ratio": 0.9999276399612427, "entropy": 0.7192859292030335, "incre_win_rate": 0.9767441860465116, "step": 2514}
{"time": 1767163733.6927435, "phase": "train", "update": 2515, "total_env_steps": 8048000, "episode_reward": 0.275390088558197, "value_loss": 0.0033944374416023495, "policy_loss": -0.001264268057555995, "dist_entropy": 0.7390812993049621, "actor_grad_norm": 0.07744251936674118, "critic_grad_norm": 0.03874677047133446, "ratio": 1.000054121017456, "entropy": 0.7390812993049621, "incre_win_rate": 0.9130434782608695, "step": 2515}
{"time": 1767163737.996934, "phase": "train", "update": 2516, "total_env_steps": 8051200, "episode_reward": 0.27812084555625916, "value_loss": 0.004403842892497778, "policy_loss": -0.001396966362305818, "dist_entropy": 0.7280916094779968, "actor_grad_norm": 0.0816858634352684, "critic_grad_norm": 0.026056993752717972, "ratio": 1.0001672506332397, "entropy": 0.7280916094779968, "incre_win_rate": 0.9333333333333333, "step": 2516}
{"time": 1767163742.3051972, "phase": "train", "update": 2517, "total_env_steps": 8054400, "episode_reward": 0.27054479718208313, "value_loss": 0.006201147846877575, "policy_loss": -0.0011217537948795097, "dist_entropy": 0.7477313160896302, "actor_grad_norm": 0.06181485205888748, "critic_grad_norm": 0.07342704385519028, "ratio": 1.0000149011611938, "entropy": 0.7477313160896302, "incre_win_rate": 0.8666666666666667, "step": 2517}
{"time": 1767163746.6393661, "phase": "train", "update": 2518, "total_env_steps": 8057600, "episode_reward": 0.28064465522766113, "value_loss": 0.00434225108474493, "policy_loss": -0.0014370831791648442, "dist_entropy": 0.7487918257713317, "actor_grad_norm": 0.07903523743152618, "critic_grad_norm": 0.038421135395765305, "ratio": 0.9999887347221375, "entropy": 0.7487918257713317, "incre_win_rate": 0.9069767441860465, "step": 2518}
{"time": 1767163750.9214501, "phase": "train", "update": 2519, "total_env_steps": 8060800, "episode_reward": 0.2692420482635498, "value_loss": 0.006316087022423744, "policy_loss": -0.0012244539810623678, "dist_entropy": 0.7440504550933837, "actor_grad_norm": 0.07480265200138092, "critic_grad_norm": 0.08965980261564255, "ratio": 0.9998316764831543, "entropy": 0.7440504550933837, "incre_win_rate": 0.8913043478260869, "step": 2519}
{"time": 1767163755.1404188, "phase": "train", "update": 2520, "total_env_steps": 8064000, "episode_reward": 0.27677980065345764, "value_loss": 0.005817323457449675, "policy_loss": -0.0012265991636901674, "dist_entropy": 0.720768392086029, "actor_grad_norm": 0.07616705447435379, "critic_grad_norm": 0.06507762521505356, "ratio": 1.000092625617981, "entropy": 0.720768392086029, "incre_win_rate": 0.8888888888888888, "step": 2520}
{"time": 1767163759.340934, "phase": "train", "update": 2521, "total_env_steps": 8067200, "episode_reward": 0.2632160782814026, "value_loss": 0.00425520958378911, "policy_loss": -0.0013363323152400853, "dist_entropy": 0.7373137235641479, "actor_grad_norm": 0.0922887995839119, "critic_grad_norm": 0.06238725408911705, "ratio": 0.9999901056289673, "entropy": 0.7373137235641479, "incre_win_rate": 0.9047619047619048, "step": 2521}
{"time": 1767163768.777713, "phase": "eval", "update": 2521, "total_env_steps": 8067200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.834333609271525, "step": 2521}
{"time": 1767163773.0433297, "phase": "train", "update": 2522, "total_env_steps": 8070400, "episode_reward": 0.26621174812316895, "value_loss": 0.007484422717243433, "policy_loss": -0.00128833405601938, "dist_entropy": 0.7148303508758544, "actor_grad_norm": 0.08511018007993698, "critic_grad_norm": 0.15909728407859802, "ratio": 1.000106930732727, "entropy": 0.7148303508758544, "incre_win_rate": 0.8913043478260869, "step": 2522}
{"time": 1767163777.3379865, "phase": "train", "update": 2523, "total_env_steps": 8073600, "episode_reward": 0.2734607756137848, "value_loss": 0.007686306722462177, "policy_loss": -0.0013398645752744187, "dist_entropy": 0.7277734160423279, "actor_grad_norm": 0.09342098981142044, "critic_grad_norm": 0.06402807682752609, "ratio": 1.000095009803772, "entropy": 0.7277734160423279, "incre_win_rate": 0.8478260869565217, "step": 2523}
{"time": 1767163781.7090533, "phase": "train", "update": 2524, "total_env_steps": 8076800, "episode_reward": 0.27552980184555054, "value_loss": 0.008215487748384476, "policy_loss": -0.0013311594940901728, "dist_entropy": 0.7376137018203736, "actor_grad_norm": 0.09408848732709885, "critic_grad_norm": 0.04937589541077614, "ratio": 1.0002092123031616, "entropy": 0.7376137018203736, "incre_win_rate": 0.8636363636363636, "step": 2524}
{"time": 1767163786.0313714, "phase": "train", "update": 2525, "total_env_steps": 8080000, "episode_reward": 0.27335211634635925, "value_loss": 0.007576968241482973, "policy_loss": -0.0013591534882415601, "dist_entropy": 0.7048664808273315, "actor_grad_norm": 0.10871974378824234, "critic_grad_norm": 0.04328100010752678, "ratio": 1.0001949071884155, "entropy": 0.7048664808273315, "incre_win_rate": 0.8478260869565217, "step": 2525}
{"time": 1767163790.3101711, "phase": "train", "update": 2526, "total_env_steps": 8083200, "episode_reward": 0.27027425169944763, "value_loss": 0.008005059976130723, "policy_loss": -0.0010412691784129403, "dist_entropy": 0.7043981075286865, "actor_grad_norm": 0.08942940086126328, "critic_grad_norm": 0.09757619351148605, "ratio": 1.0001373291015625, "entropy": 0.7043981075286865, "incre_win_rate": 0.9534883720930233, "step": 2526}
{"time": 1767163794.6030343, "phase": "train", "update": 2527, "total_env_steps": 8086400, "episode_reward": 0.27051016688346863, "value_loss": 0.006088737491518259, "policy_loss": -0.0011097276192359117, "dist_entropy": 0.6948122501373291, "actor_grad_norm": 0.08593893051147461, "critic_grad_norm": 0.08296000957489014, "ratio": 0.9998869895935059, "entropy": 0.6948122501373291, "incre_win_rate": 0.8297872340425532, "step": 2527}
{"time": 1767163798.9119873, "phase": "train", "update": 2528, "total_env_steps": 8089600, "episode_reward": 0.28582367300987244, "value_loss": 0.0035537803545594216, "policy_loss": -0.0011247333337543353, "dist_entropy": 0.7060875535011292, "actor_grad_norm": 0.08643092960119247, "critic_grad_norm": 0.053659554570913315, "ratio": 0.9999297261238098, "entropy": 0.7060875535011292, "incre_win_rate": 0.9333333333333333, "step": 2528}
{"time": 1767163803.2473242, "phase": "train", "update": 2529, "total_env_steps": 8092800, "episode_reward": 0.2804149389266968, "value_loss": 0.003907929640263319, "policy_loss": -0.0009372112824664214, "dist_entropy": 0.7050920963287354, "actor_grad_norm": 0.0886445865035057, "critic_grad_norm": 0.05930256471037865, "ratio": 0.999673068523407, "entropy": 0.7050920963287354, "incre_win_rate": 0.9777777777777777, "step": 2529}
{"time": 1767163807.5413604, "phase": "train", "update": 2530, "total_env_steps": 8096000, "episode_reward": 0.2729170322418213, "value_loss": 0.0053706572391092776, "policy_loss": -0.0012222689597400915, "dist_entropy": 0.7251054644584656, "actor_grad_norm": 0.09922599047422409, "critic_grad_norm": 0.05605192855000496, "ratio": 1.000231146812439, "entropy": 0.7251054644584656, "incre_win_rate": 0.8913043478260869, "step": 2530}
{"time": 1767163811.8730109, "phase": "train", "update": 2531, "total_env_steps": 8099200, "episode_reward": 0.2867709994316101, "value_loss": 0.005546955298632384, "policy_loss": -0.0011804137796900705, "dist_entropy": 0.7042054414749146, "actor_grad_norm": 0.09580910950899124, "critic_grad_norm": 0.04231887683272362, "ratio": 0.9999761581420898, "entropy": 0.7042054414749146, "incre_win_rate": 0.9347826086956522, "step": 2531}
{"time": 1767163816.1837811, "phase": "train", "update": 2532, "total_env_steps": 8102400, "episode_reward": 0.2797558009624481, "value_loss": 0.00674413787201047, "policy_loss": -0.0010926860316899933, "dist_entropy": 0.6868954062461853, "actor_grad_norm": 0.08775971084833145, "critic_grad_norm": 0.09008711576461792, "ratio": 0.9996005892753601, "entropy": 0.6868954062461853, "incre_win_rate": 0.9333333333333333, "step": 2532}
{"time": 1767163820.472154, "phase": "train", "update": 2533, "total_env_steps": 8105600, "episode_reward": 0.2830406427383423, "value_loss": 0.0038805752992630005, "policy_loss": -0.0011786732970037405, "dist_entropy": 0.697689664363861, "actor_grad_norm": 0.08546040207147598, "critic_grad_norm": 0.03951605409383774, "ratio": 0.9996482729911804, "entropy": 0.697689664363861, "incre_win_rate": 0.9555555555555556, "step": 2533}
{"time": 1767163824.7268865, "phase": "train", "update": 2534, "total_env_steps": 8108800, "episode_reward": 0.2734452486038208, "value_loss": 0.004709322936832905, "policy_loss": -0.0013256546830016092, "dist_entropy": 0.6893035650253296, "actor_grad_norm": 0.0830235406756401, "critic_grad_norm": 0.03211885318160057, "ratio": 0.9998372197151184, "entropy": 0.6893035650253296, "incre_win_rate": 0.8958333333333334, "step": 2534}
{"time": 1767163829.0755336, "phase": "train", "update": 2535, "total_env_steps": 8112000, "episode_reward": 0.28780627250671387, "value_loss": 0.004963423684239387, "policy_loss": -0.001523819088729539, "dist_entropy": 0.7152715444564819, "actor_grad_norm": 0.10134027153253555, "critic_grad_norm": 0.06549303233623505, "ratio": 1.0000122785568237, "entropy": 0.7152715444564819, "incre_win_rate": 0.9555555555555556, "step": 2535}
{"time": 1767163833.420697, "phase": "train", "update": 2536, "total_env_steps": 8115200, "episode_reward": 0.28456541895866394, "value_loss": 0.004074128065258265, "policy_loss": -0.0009996997282954111, "dist_entropy": 0.6968639850616455, "actor_grad_norm": 0.07830528169870377, "critic_grad_norm": 0.06854619830846786, "ratio": 1.0003117322921753, "entropy": 0.6968639850616455, "incre_win_rate": 0.9574468085106383, "step": 2536}
{"time": 1767163837.6720662, "phase": "train", "update": 2537, "total_env_steps": 8118400, "episode_reward": 0.2790087163448334, "value_loss": 0.003468941571190953, "policy_loss": -0.001751103147233124, "dist_entropy": 0.695121967792511, "actor_grad_norm": 0.08777496963739395, "critic_grad_norm": 0.039343833923339844, "ratio": 1.000258445739746, "entropy": 0.695121967792511, "incre_win_rate": 0.9545454545454546, "step": 2537}
{"time": 1767163841.9816525, "phase": "train", "update": 2538, "total_env_steps": 8121600, "episode_reward": 0.27643677592277527, "value_loss": 0.004228389449417591, "policy_loss": -0.0010842976077640287, "dist_entropy": 0.6703845620155334, "actor_grad_norm": 0.0800241231918335, "critic_grad_norm": 0.026831308379769325, "ratio": 1.0002342462539673, "entropy": 0.6703845620155334, "incre_win_rate": 0.9555555555555556, "step": 2538}
{"time": 1767163846.273994, "phase": "train", "update": 2539, "total_env_steps": 8124800, "episode_reward": 0.2802349030971527, "value_loss": 0.0033499333076179028, "policy_loss": -0.001033977063502789, "dist_entropy": 0.6505343198776246, "actor_grad_norm": 0.09158527106046677, "critic_grad_norm": 0.022449586540460587, "ratio": 0.9998869299888611, "entropy": 0.6505343198776246, "incre_win_rate": 0.9545454545454546, "step": 2539}
{"time": 1767163850.540649, "phase": "train", "update": 2540, "total_env_steps": 8128000, "episode_reward": 0.2757978141307831, "value_loss": 0.003856964549049735, "policy_loss": -0.0013599807502011174, "dist_entropy": 0.6513738393783569, "actor_grad_norm": 0.10920285433530807, "critic_grad_norm": 0.0264825951308012, "ratio": 1.000104308128357, "entropy": 0.6513738393783569, "incre_win_rate": 0.9347826086956522, "step": 2540}
{"time": 1767163854.8366952, "phase": "train", "update": 2541, "total_env_steps": 8131200, "episode_reward": 0.271537184715271, "value_loss": 0.008406305499374867, "policy_loss": -0.0014998836241378656, "dist_entropy": 0.6442476153373718, "actor_grad_norm": 0.08023854345083237, "critic_grad_norm": 0.06956096738576889, "ratio": 0.9998784065246582, "entropy": 0.6442476153373718, "incre_win_rate": 0.8478260869565217, "step": 2541}
{"time": 1767163864.807396, "phase": "eval", "update": 2541, "total_env_steps": 8131200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.55406663907285, "step": 2541}
{"time": 1767163869.0909417, "phase": "train", "update": 2542, "total_env_steps": 8134400, "episode_reward": 0.2767166793346405, "value_loss": 0.00522635206580162, "policy_loss": -0.0013601763041755533, "dist_entropy": 0.6574024558067322, "actor_grad_norm": 0.08645503968000412, "critic_grad_norm": 0.02823501266539097, "ratio": 1.0004123449325562, "entropy": 0.6574024558067322, "incre_win_rate": 0.9090909090909091, "step": 2542}
{"time": 1767163873.3374994, "phase": "train", "update": 2543, "total_env_steps": 8137600, "episode_reward": 0.25839248299598694, "value_loss": 0.005777769535779953, "policy_loss": -0.0010599131376963556, "dist_entropy": 0.6610670804977417, "actor_grad_norm": 0.07197433710098267, "critic_grad_norm": 0.04142984375357628, "ratio": 1.0000017881393433, "entropy": 0.6610670804977417, "incre_win_rate": 0.8409090909090909, "step": 2543}
{"time": 1767163877.6275568, "phase": "train", "update": 2544, "total_env_steps": 8140800, "episode_reward": 0.2658081650733948, "value_loss": 0.012131439708173274, "policy_loss": -0.0014226991484203922, "dist_entropy": 0.6538527846336365, "actor_grad_norm": 0.07780706137418747, "critic_grad_norm": 0.16693930327892303, "ratio": 0.9997350573539734, "entropy": 0.6538527846336365, "incre_win_rate": 0.7954545454545454, "step": 2544}
{"time": 1767163881.9076834, "phase": "train", "update": 2545, "total_env_steps": 8144000, "episode_reward": 0.26216164231300354, "value_loss": 0.011058124899864196, "policy_loss": -0.0013751532457952464, "dist_entropy": 0.6566808462142945, "actor_grad_norm": 0.0909682959318161, "critic_grad_norm": 0.11530990898609161, "ratio": 1.0000118017196655, "entropy": 0.6566808462142945, "incre_win_rate": 0.8085106382978723, "step": 2545}
{"time": 1767163886.1674395, "phase": "train", "update": 2546, "total_env_steps": 8147200, "episode_reward": 0.27205920219421387, "value_loss": 0.008973156102001667, "policy_loss": -0.0010986744772063961, "dist_entropy": 0.6523991107940674, "actor_grad_norm": 0.08772382885217667, "critic_grad_norm": 0.05913595110177994, "ratio": 1.0002728700637817, "entropy": 0.6523991107940674, "incre_win_rate": 0.8409090909090909, "step": 2546}
{"time": 1767163890.4436038, "phase": "train", "update": 2547, "total_env_steps": 8150400, "episode_reward": 0.27384883165359497, "value_loss": 0.005202433001250029, "policy_loss": -0.0010255629396596078, "dist_entropy": 0.6624754786491394, "actor_grad_norm": 0.08578427881002426, "critic_grad_norm": 0.09238870441913605, "ratio": 1.0003328323364258, "entropy": 0.6624754786491394, "incre_win_rate": 0.9111111111111111, "step": 2547}
{"time": 1767163894.7589853, "phase": "train", "update": 2548, "total_env_steps": 8153600, "episode_reward": 0.2672956585884094, "value_loss": 0.009919985570013523, "policy_loss": -0.00104899312709108, "dist_entropy": 0.6706817150115967, "actor_grad_norm": 0.10100611299276352, "critic_grad_norm": 0.06806373596191406, "ratio": 0.9999764561653137, "entropy": 0.6706817150115967, "incre_win_rate": 0.8444444444444444, "step": 2548}
{"time": 1767163899.0970604, "phase": "train", "update": 2549, "total_env_steps": 8156800, "episode_reward": 0.26125311851501465, "value_loss": 0.010818418115377426, "policy_loss": -0.0013242450983113941, "dist_entropy": 0.6551220178604126, "actor_grad_norm": 0.09000145643949509, "critic_grad_norm": 0.11139022558927536, "ratio": 0.9995746612548828, "entropy": 0.6551220178604126, "incre_win_rate": 0.7209302325581395, "step": 2549}
{"time": 1767163903.3565793, "phase": "train", "update": 2550, "total_env_steps": 8160000, "episode_reward": 0.2716328501701355, "value_loss": 0.007665344513952732, "policy_loss": -0.0015794786679303341, "dist_entropy": 0.6528441905975342, "actor_grad_norm": 0.1137479692697525, "critic_grad_norm": 0.10901807993650436, "ratio": 0.9995344281196594, "entropy": 0.6528441905975342, "incre_win_rate": 0.8636363636363636, "step": 2550}
{"time": 1767163907.5872064, "phase": "train", "update": 2551, "total_env_steps": 8163200, "episode_reward": 0.2586625814437866, "value_loss": 0.01463882178068161, "policy_loss": -0.0014593349034328184, "dist_entropy": 0.6003214597702027, "actor_grad_norm": 0.11507562547922134, "critic_grad_norm": 0.19764946401119232, "ratio": 0.9997175335884094, "entropy": 0.6003214597702027, "incre_win_rate": 0.7659574468085106, "step": 2551}
{"time": 1767163911.8440113, "phase": "train", "update": 2552, "total_env_steps": 8166400, "episode_reward": 0.2692187428474426, "value_loss": 0.010328926146030426, "policy_loss": -0.001648357500546993, "dist_entropy": 0.6246063828468322, "actor_grad_norm": 0.09236607700586319, "critic_grad_norm": 0.1891516149044037, "ratio": 0.9995072484016418, "entropy": 0.6246063828468322, "incre_win_rate": 0.8222222222222222, "step": 2552}
{"time": 1767163916.1454499, "phase": "train", "update": 2553, "total_env_steps": 8169600, "episode_reward": 0.27035441994667053, "value_loss": 0.010013520158827305, "policy_loss": -0.0014389648876541373, "dist_entropy": 0.651649534702301, "actor_grad_norm": 0.0927620381116867, "critic_grad_norm": 0.13747701048851013, "ratio": 0.9998689889907837, "entropy": 0.651649534702301, "incre_win_rate": 0.8409090909090909, "step": 2553}
{"time": 1767163920.4338582, "phase": "train", "update": 2554, "total_env_steps": 8172800, "episode_reward": 0.27238979935646057, "value_loss": 0.0058843671344220635, "policy_loss": -0.0014000762961678959, "dist_entropy": 0.6697418570518494, "actor_grad_norm": 0.0959966704249382, "critic_grad_norm": 0.11643395572900772, "ratio": 0.9998111724853516, "entropy": 0.6697418570518494, "incre_win_rate": 0.8222222222222222, "step": 2554}
{"time": 1767163924.703538, "phase": "train", "update": 2555, "total_env_steps": 8176000, "episode_reward": 0.26310276985168457, "value_loss": 0.010321424342691898, "policy_loss": -0.001542736810970524, "dist_entropy": 0.6539224624633789, "actor_grad_norm": 0.08093620091676712, "critic_grad_norm": 0.20739245414733887, "ratio": 1.000152826309204, "entropy": 0.6539224624633789, "incre_win_rate": 0.7555555555555555, "step": 2555}
{"time": 1767163928.9200578, "phase": "train", "update": 2556, "total_env_steps": 8179200, "episode_reward": 0.25030526518821716, "value_loss": 0.012393070757389069, "policy_loss": -0.0012012734295851145, "dist_entropy": 0.6619558930397034, "actor_grad_norm": 0.09302794933319092, "critic_grad_norm": 0.2551611661911011, "ratio": 1.0000417232513428, "entropy": 0.6619558930397034, "incre_win_rate": 0.6444444444444445, "step": 2556}
{"time": 1767163933.203636, "phase": "train", "update": 2557, "total_env_steps": 8182400, "episode_reward": 0.2628099322319031, "value_loss": 0.005130031704902649, "policy_loss": -0.0007058987121041582, "dist_entropy": 0.6733290791511536, "actor_grad_norm": 0.07857117801904678, "critic_grad_norm": 0.10770487040281296, "ratio": 1.0001283884048462, "entropy": 0.6733290791511536, "incre_win_rate": 0.8636363636363636, "step": 2557}
{"time": 1767163937.4581823, "phase": "train", "update": 2558, "total_env_steps": 8185600, "episode_reward": 0.24933618307113647, "value_loss": 0.00884563773870468, "policy_loss": -0.0013596301037637204, "dist_entropy": 0.6599039196968078, "actor_grad_norm": 0.08451234549283981, "critic_grad_norm": 0.12099398672580719, "ratio": 1.0003178119659424, "entropy": 0.6599039196968078, "incre_win_rate": 0.8292682926829268, "step": 2558}
{"time": 1767163941.68371, "phase": "train", "update": 2559, "total_env_steps": 8188800, "episode_reward": 0.2552897334098816, "value_loss": 0.008493240550160408, "policy_loss": -0.0014223164291787605, "dist_entropy": 0.682671046257019, "actor_grad_norm": 0.09198733419179916, "critic_grad_norm": 0.11274415254592896, "ratio": 1.000280499458313, "entropy": 0.682671046257019, "incre_win_rate": 0.7674418604651163, "step": 2559}
{"time": 1767163945.8964753, "phase": "train", "update": 2560, "total_env_steps": 8192000, "episode_reward": 0.25425341725349426, "value_loss": 0.013606199808418751, "policy_loss": -0.0015152014512793243, "dist_entropy": 0.6836744666099548, "actor_grad_norm": 0.08869843930006027, "critic_grad_norm": 0.19808994233608246, "ratio": 0.9999315142631531, "entropy": 0.6836744666099548, "incre_win_rate": 0.7045454545454546, "step": 2560}
{"time": 1767163950.15615, "phase": "train", "update": 2561, "total_env_steps": 8195200, "episode_reward": 0.2599664032459259, "value_loss": 0.010380199924111367, "policy_loss": -0.0012897830122838628, "dist_entropy": 0.6662628889083863, "actor_grad_norm": 0.08139213174581528, "critic_grad_norm": 0.14121808111667633, "ratio": 0.999825656414032, "entropy": 0.6662628889083863, "incre_win_rate": 0.7777777777777778, "step": 2561}
{"time": 1767163965.3903215, "phase": "eval", "update": 2561, "total_env_steps": 8195200, "eval_win_rate": 0.875, "eval_episode_reward": 19.571399006622517, "step": 2561}
{"time": 1767163969.583994, "phase": "train", "update": 2562, "total_env_steps": 8198400, "episode_reward": 0.26996535062789917, "value_loss": 0.010164487920701504, "policy_loss": -0.001973710987083166, "dist_entropy": 0.6837907075881958, "actor_grad_norm": 0.10715200752019882, "critic_grad_norm": 0.1419418305158615, "ratio": 1.000141978263855, "entropy": 0.6837907075881958, "incre_win_rate": 0.9090909090909091, "step": 2562}
{"time": 1767163973.8043535, "phase": "train", "update": 2563, "total_env_steps": 8201600, "episode_reward": 0.25582262873649597, "value_loss": 0.009946667775511741, "policy_loss": -0.0013952841061858124, "dist_entropy": 0.673715341091156, "actor_grad_norm": 0.08890100568532944, "critic_grad_norm": 0.10732773691415787, "ratio": 0.9999428987503052, "entropy": 0.673715341091156, "incre_win_rate": 0.7209302325581395, "step": 2563}
{"time": 1767163978.0243464, "phase": "train", "update": 2564, "total_env_steps": 8204800, "episode_reward": 0.2640562951564789, "value_loss": 0.006572987139225006, "policy_loss": -0.001451641171548257, "dist_entropy": 0.690606164932251, "actor_grad_norm": 0.0871361494064331, "critic_grad_norm": 0.0541900098323822, "ratio": 0.9999211430549622, "entropy": 0.690606164932251, "incre_win_rate": 0.8478260869565217, "step": 2564}
{"time": 1767163982.2838109, "phase": "train", "update": 2565, "total_env_steps": 8208000, "episode_reward": 0.2740335464477539, "value_loss": 0.005880743730813265, "policy_loss": -0.0015709133237464812, "dist_entropy": 0.7053536176681519, "actor_grad_norm": 0.08460613340139389, "critic_grad_norm": 0.04060953110456467, "ratio": 1.0000529289245605, "entropy": 0.7053536176681519, "incre_win_rate": 0.8809523809523809, "step": 2565}
{"time": 1767163986.5779016, "phase": "train", "update": 2566, "total_env_steps": 8211200, "episode_reward": 0.2787070572376251, "value_loss": 0.0056134328246116635, "policy_loss": -0.0016368927140799627, "dist_entropy": 0.723716676235199, "actor_grad_norm": 0.07847081869840622, "critic_grad_norm": 0.13338603079319, "ratio": 1.0002273321151733, "entropy": 0.723716676235199, "incre_win_rate": 0.9361702127659575, "step": 2566}
{"time": 1767163990.850422, "phase": "train", "update": 2567, "total_env_steps": 8214400, "episode_reward": 0.2656513750553131, "value_loss": 0.008226187899708748, "policy_loss": -0.0017264564599699384, "dist_entropy": 0.6988011479377747, "actor_grad_norm": 0.10690394788980484, "critic_grad_norm": 0.10283203423023224, "ratio": 0.9996218085289001, "entropy": 0.6988011479377747, "incre_win_rate": 0.8444444444444444, "step": 2567}
{"time": 1767163995.1561136, "phase": "train", "update": 2568, "total_env_steps": 8217600, "episode_reward": 0.26506516337394714, "value_loss": 0.012137423269450665, "policy_loss": -0.0009900942602747876, "dist_entropy": 0.6968940854072571, "actor_grad_norm": 0.07978267967700958, "critic_grad_norm": 0.11165018379688263, "ratio": 0.9999219179153442, "entropy": 0.6968940854072571, "incre_win_rate": 0.782608695652174, "step": 2568}
{"time": 1767163999.4308126, "phase": "train", "update": 2569, "total_env_steps": 8220800, "episode_reward": 0.2830473780632019, "value_loss": 0.007361396308988332, "policy_loss": -0.001039497234507536, "dist_entropy": 0.6829068064689636, "actor_grad_norm": 0.08045343309640884, "critic_grad_norm": 0.14986853301525116, "ratio": 0.9999346733093262, "entropy": 0.6829068064689636, "incre_win_rate": 0.9090909090909091, "step": 2569}
{"time": 1767164003.7479835, "phase": "train", "update": 2570, "total_env_steps": 8224000, "episode_reward": 0.2764197289943695, "value_loss": 0.007743707112967968, "policy_loss": -0.0011468070519988771, "dist_entropy": 0.6916735410690308, "actor_grad_norm": 0.0923490822315216, "critic_grad_norm": 0.08013090491294861, "ratio": 0.9999427795410156, "entropy": 0.6916735410690308, "incre_win_rate": 0.8478260869565217, "step": 2570}
{"time": 1767164008.0736833, "phase": "train", "update": 2571, "total_env_steps": 8227200, "episode_reward": 0.2713550329208374, "value_loss": 0.0106900280341506, "policy_loss": -0.001188175316866591, "dist_entropy": 0.6949946284294128, "actor_grad_norm": 0.10032790154218674, "critic_grad_norm": 0.08341965079307556, "ratio": 0.9994710087776184, "entropy": 0.6949946284294128, "incre_win_rate": 0.8085106382978723, "step": 2571}
{"time": 1767164012.354152, "phase": "train", "update": 2572, "total_env_steps": 8230400, "episode_reward": 0.2740495502948761, "value_loss": 0.011711654812097549, "policy_loss": -0.0015388668691706186, "dist_entropy": 0.6952438831329346, "actor_grad_norm": 0.090323306620121, "critic_grad_norm": 0.16550591588020325, "ratio": 0.9998258948326111, "entropy": 0.6952438831329346, "incre_win_rate": 0.8409090909090909, "step": 2572}
{"time": 1767164016.617555, "phase": "train", "update": 2573, "total_env_steps": 8233600, "episode_reward": 0.2691887617111206, "value_loss": 0.010566940903663636, "policy_loss": -0.0012391045039365166, "dist_entropy": 0.6804338812828064, "actor_grad_norm": 0.10890346020460129, "critic_grad_norm": 0.12036937475204468, "ratio": 1.000108003616333, "entropy": 0.6804338812828064, "incre_win_rate": 0.8333333333333334, "step": 2573}
{"time": 1767164020.8934133, "phase": "train", "update": 2574, "total_env_steps": 8236800, "episode_reward": 0.26162460446357727, "value_loss": 0.009515529125928878, "policy_loss": -0.00185421348510868, "dist_entropy": 0.7034233212471008, "actor_grad_norm": 0.10804498195648193, "critic_grad_norm": 0.096079520881176, "ratio": 0.9996587038040161, "entropy": 0.7034233212471008, "incre_win_rate": 0.8333333333333334, "step": 2574}
{"time": 1767164025.1677554, "phase": "train", "update": 2575, "total_env_steps": 8240000, "episode_reward": 0.27547651529312134, "value_loss": 0.008442970737814904, "policy_loss": -0.001649361829542073, "dist_entropy": 0.7131016612052917, "actor_grad_norm": 0.09289276599884033, "critic_grad_norm": 0.1854809820652008, "ratio": 1.0000542402267456, "entropy": 0.7131016612052917, "incre_win_rate": 0.8666666666666667, "step": 2575}
{"time": 1767164029.402645, "phase": "train", "update": 2576, "total_env_steps": 8243200, "episode_reward": 0.27241048216819763, "value_loss": 0.00736330896615982, "policy_loss": -0.0012489755067147002, "dist_entropy": 0.6855054497718811, "actor_grad_norm": 0.0773790255188942, "critic_grad_norm": 0.10053028911352158, "ratio": 1.0001434087753296, "entropy": 0.6855054497718811, "incre_win_rate": 0.851063829787234, "step": 2576}
{"time": 1767164033.677822, "phase": "train", "update": 2577, "total_env_steps": 8246400, "episode_reward": 0.2819764018058777, "value_loss": 0.005022882204502821, "policy_loss": -0.0010642780586394452, "dist_entropy": 0.6816016435623169, "actor_grad_norm": 0.07562923431396484, "critic_grad_norm": 0.07850641012191772, "ratio": 1.0000947713851929, "entropy": 0.6816016435623169, "incre_win_rate": 0.9318181818181818, "step": 2577}
{"time": 1767164038.0126631, "phase": "train", "update": 2578, "total_env_steps": 8249600, "episode_reward": 0.25575125217437744, "value_loss": 0.013688721507787705, "policy_loss": -0.00151232600810971, "dist_entropy": 0.6803513169288635, "actor_grad_norm": 0.07521884888410568, "critic_grad_norm": 0.27895718812942505, "ratio": 1.0001461505889893, "entropy": 0.6803513169288635, "incre_win_rate": 0.7727272727272727, "step": 2578}
{"time": 1767164042.3191636, "phase": "train", "update": 2579, "total_env_steps": 8252800, "episode_reward": 0.27865222096443176, "value_loss": 0.007933013699948787, "policy_loss": -0.001792414798934061, "dist_entropy": 0.6691339373588562, "actor_grad_norm": 0.08757881820201874, "critic_grad_norm": 0.16787102818489075, "ratio": 0.9997780919075012, "entropy": 0.6691339373588562, "incre_win_rate": 0.8936170212765957, "step": 2579}
{"time": 1767164046.5724516, "phase": "train", "update": 2580, "total_env_steps": 8256000, "episode_reward": 0.2665102481842041, "value_loss": 0.008416110463440419, "policy_loss": -0.0012786240919348657, "dist_entropy": 0.6613973259925843, "actor_grad_norm": 0.08076395094394684, "critic_grad_norm": 0.12374122440814972, "ratio": 0.999919593334198, "entropy": 0.6613973259925843, "incre_win_rate": 0.8837209302325582, "step": 2580}
{"time": 1767164050.8175633, "phase": "train", "update": 2581, "total_env_steps": 8259200, "episode_reward": 0.27274835109710693, "value_loss": 0.004835000727325678, "policy_loss": -0.0011079821532902657, "dist_entropy": 0.6822571635246277, "actor_grad_norm": 0.08055504411458969, "critic_grad_norm": 0.08057539910078049, "ratio": 1.0002351999282837, "entropy": 0.6822571635246277, "incre_win_rate": 0.9347826086956522, "step": 2581}
{"time": 1767164060.8816116, "phase": "eval", "update": 2581, "total_env_steps": 8259200, "eval_win_rate": 0.8125, "eval_episode_reward": 18.429221854304636, "step": 2581}
{"time": 1767164065.1665459, "phase": "train", "update": 2582, "total_env_steps": 8262400, "episode_reward": 0.2695276439189911, "value_loss": 0.007105436734855175, "policy_loss": -0.0012327591875347821, "dist_entropy": 0.6685585618019104, "actor_grad_norm": 0.08054130524396896, "critic_grad_norm": 0.08253923803567886, "ratio": 1.0001027584075928, "entropy": 0.6685585618019104, "incre_win_rate": 0.8222222222222222, "step": 2582}
{"time": 1767164069.4484959, "phase": "train", "update": 2583, "total_env_steps": 8265600, "episode_reward": 0.2768418788909912, "value_loss": 0.004192348476499319, "policy_loss": -0.0014332599729506511, "dist_entropy": 0.6923457026481629, "actor_grad_norm": 0.08430834114551544, "critic_grad_norm": 0.06507017463445663, "ratio": 0.9997672438621521, "entropy": 0.6923457026481629, "incre_win_rate": 0.9555555555555556, "step": 2583}
{"time": 1767164073.7624068, "phase": "train", "update": 2584, "total_env_steps": 8268800, "episode_reward": 0.2736087739467621, "value_loss": 0.009834662079811096, "policy_loss": -0.0014215706129604654, "dist_entropy": 0.6701856017112732, "actor_grad_norm": 0.08232276886701584, "critic_grad_norm": 0.05176230147480965, "ratio": 0.999832272529602, "entropy": 0.6701856017112732, "incre_win_rate": 0.8863636363636364, "step": 2584}
{"time": 1767164078.0534406, "phase": "train", "update": 2585, "total_env_steps": 8272000, "episode_reward": 0.26512157917022705, "value_loss": 0.00936525482684374, "policy_loss": -0.001379624750285302, "dist_entropy": 0.649271821975708, "actor_grad_norm": 0.10351485013961792, "critic_grad_norm": 0.05872925743460655, "ratio": 0.9998393058776855, "entropy": 0.649271821975708, "incre_win_rate": 0.8478260869565217, "step": 2585}
{"time": 1767164082.284271, "phase": "train", "update": 2586, "total_env_steps": 8275200, "episode_reward": 0.27228477597236633, "value_loss": 0.010165397077798843, "policy_loss": -0.0013117721796174209, "dist_entropy": 0.6398446917533874, "actor_grad_norm": 0.08172937482595444, "critic_grad_norm": 0.11302131414413452, "ratio": 1.000072956085205, "entropy": 0.6398446917533874, "incre_win_rate": 0.8837209302325582, "step": 2586}
{"time": 1767164086.5614061, "phase": "train", "update": 2587, "total_env_steps": 8278400, "episode_reward": 0.275154173374176, "value_loss": 0.006106965895742178, "policy_loss": -0.001706310020309587, "dist_entropy": 0.6367070794105529, "actor_grad_norm": 0.12669497728347778, "critic_grad_norm": 0.08854659646749496, "ratio": 1.0001535415649414, "entropy": 0.6367070794105529, "incre_win_rate": 0.8913043478260869, "step": 2587}
{"time": 1767164090.8637667, "phase": "train", "update": 2588, "total_env_steps": 8281600, "episode_reward": 0.2779718339443207, "value_loss": 0.0042340438812971115, "policy_loss": -0.0013085451587919294, "dist_entropy": 0.6192292809486389, "actor_grad_norm": 0.09927532821893692, "critic_grad_norm": 0.06481494754552841, "ratio": 0.9996909499168396, "entropy": 0.6192292809486389, "incre_win_rate": 0.9772727272727273, "step": 2588}
{"time": 1767164095.147555, "phase": "train", "update": 2589, "total_env_steps": 8284800, "episode_reward": 0.26759520173072815, "value_loss": 0.006857962626963854, "policy_loss": -0.0013167263883015145, "dist_entropy": 0.6084626317024231, "actor_grad_norm": 0.08055429905653, "critic_grad_norm": 0.11090641468763351, "ratio": 1.0000284910202026, "entropy": 0.6084626317024231, "incre_win_rate": 0.8888888888888888, "step": 2589}
{"time": 1767164099.466734, "phase": "train", "update": 2590, "total_env_steps": 8288000, "episode_reward": 0.2763410806655884, "value_loss": 0.004678645264357328, "policy_loss": -0.0011576557960850664, "dist_entropy": 0.6452720284461975, "actor_grad_norm": 0.06881510466337204, "critic_grad_norm": 0.10313787311315536, "ratio": 1.000105619430542, "entropy": 0.6452720284461975, "incre_win_rate": 0.9111111111111111, "step": 2590}
{"time": 1767164103.798629, "phase": "train", "update": 2591, "total_env_steps": 8291200, "episode_reward": 0.2807512581348419, "value_loss": 0.006552445795387029, "policy_loss": -0.001273101935085208, "dist_entropy": 0.6531812906265259, "actor_grad_norm": 0.07362774014472961, "critic_grad_norm": 0.06704395264387131, "ratio": 0.9999933242797852, "entropy": 0.6531812906265259, "incre_win_rate": 0.8958333333333334, "step": 2591}
{"time": 1767164108.1062, "phase": "train", "update": 2592, "total_env_steps": 8294400, "episode_reward": 0.2799089550971985, "value_loss": 0.003400485636666417, "policy_loss": -0.001250585443459329, "dist_entropy": 0.6605992078781128, "actor_grad_norm": 0.07764362543821335, "critic_grad_norm": 0.04183607175946236, "ratio": 0.9998101592063904, "entropy": 0.6605992078781128, "incre_win_rate": 0.9772727272727273, "step": 2592}
{"time": 1767164112.3855317, "phase": "train", "update": 2593, "total_env_steps": 8297600, "episode_reward": 0.2805050015449524, "value_loss": 0.004756497591733933, "policy_loss": -0.001576356358761899, "dist_entropy": 0.6485261917114258, "actor_grad_norm": 0.08437333256006241, "critic_grad_norm": 0.07257641851902008, "ratio": 1.000213623046875, "entropy": 0.6485261917114258, "incre_win_rate": 0.9545454545454546, "step": 2593}
{"time": 1767164116.675335, "phase": "train", "update": 2594, "total_env_steps": 8300800, "episode_reward": 0.2726691961288452, "value_loss": 0.005869930237531662, "policy_loss": -0.001529887013248654, "dist_entropy": 0.6810720086097717, "actor_grad_norm": 0.10770343989133835, "critic_grad_norm": 0.10583346337080002, "ratio": 0.9999270439147949, "entropy": 0.6810720086097717, "incre_win_rate": 0.8913043478260869, "step": 2594}
{"time": 1767164120.9676275, "phase": "train", "update": 2595, "total_env_steps": 8304000, "episode_reward": 0.276804655790329, "value_loss": 0.0045674721710383896, "policy_loss": -0.0010604754509770942, "dist_entropy": 0.673337996006012, "actor_grad_norm": 0.08156470954418182, "critic_grad_norm": 0.08474355190992355, "ratio": 1.0000288486480713, "entropy": 0.673337996006012, "incre_win_rate": 0.9318181818181818, "step": 2595}
{"time": 1767164125.2837117, "phase": "train", "update": 2596, "total_env_steps": 8307200, "episode_reward": 0.2666235566139221, "value_loss": 0.006433198601007462, "policy_loss": -0.001340375627113488, "dist_entropy": 0.6665072560310363, "actor_grad_norm": 0.08789781481027603, "critic_grad_norm": 0.07152798026800156, "ratio": 1.0001174211502075, "entropy": 0.6665072560310363, "incre_win_rate": 0.9090909090909091, "step": 2596}
{"time": 1767164129.6455696, "phase": "train", "update": 2597, "total_env_steps": 8310400, "episode_reward": 0.2887158691883087, "value_loss": 0.0039917032700032, "policy_loss": -0.0015000321649509373, "dist_entropy": 0.6624968528747559, "actor_grad_norm": 0.09817531704902649, "critic_grad_norm": 0.08598694205284119, "ratio": 0.9999901652336121, "entropy": 0.6624968528747559, "incre_win_rate": 0.9787234042553191, "step": 2597}
{"time": 1767164133.9658394, "phase": "train", "update": 2598, "total_env_steps": 8313600, "episode_reward": 0.2773742973804474, "value_loss": 0.005148035474121571, "policy_loss": -0.0012176181857846303, "dist_entropy": 0.6558321714401245, "actor_grad_norm": 0.07809504121541977, "critic_grad_norm": 0.06926464289426804, "ratio": 1.0000135898590088, "entropy": 0.6558321714401245, "incre_win_rate": 0.8863636363636364, "step": 2598}
{"time": 1767164138.23889, "phase": "train", "update": 2599, "total_env_steps": 8316800, "episode_reward": 0.26917943358421326, "value_loss": 0.004985297750681639, "policy_loss": -0.001220646296181016, "dist_entropy": 0.6728144526481629, "actor_grad_norm": 0.0953933373093605, "critic_grad_norm": 0.1223735585808754, "ratio": 0.9999173283576965, "entropy": 0.6728144526481629, "incre_win_rate": 0.8666666666666667, "step": 2599}
{"time": 1767164142.5070848, "phase": "train", "update": 2600, "total_env_steps": 8320000, "episode_reward": 0.276576966047287, "value_loss": 0.005924282036721707, "policy_loss": -0.001285431923929181, "dist_entropy": 0.6442378997802735, "actor_grad_norm": 0.09268245100975037, "critic_grad_norm": 0.09239783883094788, "ratio": 0.9998639225959778, "entropy": 0.6442378997802735, "incre_win_rate": 0.9302325581395349, "step": 2600}
{"time": 1767164146.809601, "phase": "train", "update": 2601, "total_env_steps": 8323200, "episode_reward": 0.2823592722415924, "value_loss": 0.005437070410698653, "policy_loss": -0.0016932789414617843, "dist_entropy": 0.6505931138992309, "actor_grad_norm": 0.1129191517829895, "critic_grad_norm": 0.06408797204494476, "ratio": 1.0003772974014282, "entropy": 0.6505931138992309, "incre_win_rate": 0.9166666666666666, "step": 2601}
{"time": 1767164156.211087, "phase": "eval", "update": 2601, "total_env_steps": 8323200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.649110099337747, "step": 2601}
{"time": 1767164160.4905531, "phase": "train", "update": 2602, "total_env_steps": 8326400, "episode_reward": 0.26451575756073, "value_loss": 0.009203258715569974, "policy_loss": -0.0014400736828321214, "dist_entropy": 0.6285206198692321, "actor_grad_norm": 0.09803163260221481, "critic_grad_norm": 0.07760972529649734, "ratio": 0.9995514154434204, "entropy": 0.6285206198692321, "incre_win_rate": 0.813953488372093, "step": 2602}
{"time": 1767164164.7868447, "phase": "train", "update": 2603, "total_env_steps": 8329600, "episode_reward": 0.26774832606315613, "value_loss": 0.007386768329888582, "policy_loss": -0.0013212516316081669, "dist_entropy": 0.6390928387641907, "actor_grad_norm": 0.07456444203853607, "critic_grad_norm": 0.13117197155952454, "ratio": 1.0002033710479736, "entropy": 0.6390928387641907, "incre_win_rate": 0.8666666666666667, "step": 2603}
{"time": 1767164169.0779192, "phase": "train", "update": 2604, "total_env_steps": 8332800, "episode_reward": 0.27748551964759827, "value_loss": 0.005135096423327923, "policy_loss": -0.0013100318713568982, "dist_entropy": 0.6326071619987488, "actor_grad_norm": 0.07837574928998947, "critic_grad_norm": 0.09887923300266266, "ratio": 1.0001143217086792, "entropy": 0.6326071619987488, "incre_win_rate": 0.9148936170212766, "step": 2604}
{"time": 1767164173.375371, "phase": "train", "update": 2605, "total_env_steps": 8336000, "episode_reward": 0.2852173149585724, "value_loss": 0.00402015964500606, "policy_loss": -0.001611813501519066, "dist_entropy": 0.6378797292709351, "actor_grad_norm": 0.11060207337141037, "critic_grad_norm": 0.06011856719851494, "ratio": 0.9998500943183899, "entropy": 0.6378797292709351, "incre_win_rate": 0.9555555555555556, "step": 2605}
{"time": 1767164177.6538343, "phase": "train", "update": 2606, "total_env_steps": 8339200, "episode_reward": 0.2809188961982727, "value_loss": 0.0049190792255103585, "policy_loss": -0.0013847387941043454, "dist_entropy": 0.6408571481704712, "actor_grad_norm": 0.08860844373703003, "critic_grad_norm": 0.0877961665391922, "ratio": 1.0000661611557007, "entropy": 0.6408571481704712, "incre_win_rate": 0.9130434782608695, "step": 2606}
{"time": 1767164181.9454575, "phase": "train", "update": 2607, "total_env_steps": 8342400, "episode_reward": 0.2748996317386627, "value_loss": 0.00783586259931326, "policy_loss": -0.0011318333093306876, "dist_entropy": 0.6583089709281922, "actor_grad_norm": 0.08406955748796463, "critic_grad_norm": 0.07355015724897385, "ratio": 0.9999706149101257, "entropy": 0.6583089709281922, "incre_win_rate": 0.9318181818181818, "step": 2607}
{"time": 1767164186.308236, "phase": "train", "update": 2608, "total_env_steps": 8345600, "episode_reward": 0.2784499228000641, "value_loss": 0.008130186051130295, "policy_loss": -0.0011367508806614524, "dist_entropy": 0.6223398566246032, "actor_grad_norm": 0.11699618399143219, "critic_grad_norm": 0.0580463670194149, "ratio": 0.9994457364082336, "entropy": 0.6223398566246032, "incre_win_rate": 0.8695652173913043, "step": 2608}
{"time": 1767164190.58791, "phase": "train", "update": 2609, "total_env_steps": 8348800, "episode_reward": 0.2679190933704376, "value_loss": 0.008265756443142891, "policy_loss": -0.0015286734446853245, "dist_entropy": 0.6306446075439454, "actor_grad_norm": 0.12061270326375961, "critic_grad_norm": 0.04134413227438927, "ratio": 0.9994804263114929, "entropy": 0.6306446075439454, "incre_win_rate": 0.9130434782608695, "step": 2609}
{"time": 1767164194.8670106, "phase": "train", "update": 2610, "total_env_steps": 8352000, "episode_reward": 0.2735518515110016, "value_loss": 0.008384170569479465, "policy_loss": -0.0011041254199085416, "dist_entropy": 0.6235016822814942, "actor_grad_norm": 0.09476827085018158, "critic_grad_norm": 0.08072274178266525, "ratio": 0.999931812286377, "entropy": 0.6235016822814942, "incre_win_rate": 0.8181818181818182, "step": 2610}
{"time": 1767164199.1847758, "phase": "train", "update": 2611, "total_env_steps": 8355200, "episode_reward": 0.27565398812294006, "value_loss": 0.004930405505001545, "policy_loss": -0.0010090667934028019, "dist_entropy": 0.6281398057937622, "actor_grad_norm": 0.08722198754549026, "critic_grad_norm": 0.06495995819568634, "ratio": 0.9998060464859009, "entropy": 0.6281398057937622, "incre_win_rate": 0.9347826086956522, "step": 2611}
{"time": 1767164203.5203977, "phase": "train", "update": 2612, "total_env_steps": 8358400, "episode_reward": 0.28145694732666016, "value_loss": 0.0046732182614505294, "policy_loss": -0.0011667183489997512, "dist_entropy": 0.6342388033866883, "actor_grad_norm": 0.08274554461240768, "critic_grad_norm": 0.048734989017248154, "ratio": 0.9995509386062622, "entropy": 0.6342388033866883, "incre_win_rate": 0.9361702127659575, "step": 2612}
{"time": 1767164241.866316, "phase": "train", "update": 2613, "total_env_steps": 8361600, "episode_reward": 0.27700746059417725, "value_loss": 0.05549934059381485, "policy_loss": -0.0010398684974791904, "dist_entropy": 0.6466544270515442, "actor_grad_norm": 0.07331818342208862, "critic_grad_norm": 0.3644088804721832, "ratio": 0.9998772740364075, "entropy": 0.6466544270515442, "incre_win_rate": 0.9743589743589743, "step": 2613}
{"time": 1767164246.1785438, "phase": "train", "update": 2614, "total_env_steps": 8364800, "episode_reward": 0.2873758375644684, "value_loss": 0.007587194163352251, "policy_loss": -0.0012555687075753497, "dist_entropy": 0.6499668240547181, "actor_grad_norm": 0.10472755879163742, "critic_grad_norm": 0.37500640749931335, "ratio": 1.000122308731079, "entropy": 0.6499668240547181, "incre_win_rate": 0.9583333333333334, "step": 2614}
{"time": 1767164250.4624677, "phase": "train", "update": 2615, "total_env_steps": 8368000, "episode_reward": 0.282185435295105, "value_loss": 0.00585752185434103, "policy_loss": -0.0009392209036931832, "dist_entropy": 0.6555073499679566, "actor_grad_norm": 0.10009429603815079, "critic_grad_norm": 0.2527565658092499, "ratio": 0.9998945593833923, "entropy": 0.6555073499679566, "incre_win_rate": 0.9148936170212766, "step": 2615}
{"time": 1767164254.767991, "phase": "train", "update": 2616, "total_env_steps": 8371200, "episode_reward": 0.27663078904151917, "value_loss": 0.005546033848077059, "policy_loss": -0.000996960470086705, "dist_entropy": 0.679445493221283, "actor_grad_norm": 0.09242407232522964, "critic_grad_norm": 0.18824872374534607, "ratio": 0.9997273683547974, "entropy": 0.679445493221283, "incre_win_rate": 0.8888888888888888, "step": 2616}
{"time": 1767164259.101609, "phase": "train", "update": 2617, "total_env_steps": 8374400, "episode_reward": 0.2820297181606293, "value_loss": 0.005420713592320681, "policy_loss": -0.0012968621224779043, "dist_entropy": 0.6742825627326965, "actor_grad_norm": 0.082429438829422, "critic_grad_norm": 0.18554307520389557, "ratio": 0.9999803900718689, "entropy": 0.6742825627326965, "incre_win_rate": 0.9555555555555556, "step": 2617}
{"time": 1767164263.4281619, "phase": "train", "update": 2618, "total_env_steps": 8377600, "episode_reward": 0.271628737449646, "value_loss": 0.006215317826718092, "policy_loss": -0.0010502885635126802, "dist_entropy": 0.6536560893058777, "actor_grad_norm": 0.06352434307336807, "critic_grad_norm": 0.13673754036426544, "ratio": 0.999804675579071, "entropy": 0.6536560893058777, "incre_win_rate": 0.8888888888888888, "step": 2618}
{"time": 1767164267.7096944, "phase": "train", "update": 2619, "total_env_steps": 8380800, "episode_reward": 0.28209125995635986, "value_loss": 0.004447659756988287, "policy_loss": -0.001256130737503014, "dist_entropy": 0.6645683169364929, "actor_grad_norm": 0.07186853885650635, "critic_grad_norm": 0.11121769994497299, "ratio": 0.9998928904533386, "entropy": 0.6645683169364929, "incre_win_rate": 0.9565217391304348, "step": 2619}
{"time": 1767164271.9616807, "phase": "train", "update": 2620, "total_env_steps": 8384000, "episode_reward": 0.27266865968704224, "value_loss": 0.007097906526178121, "policy_loss": -0.0015965273414850322, "dist_entropy": 0.6428751349449158, "actor_grad_norm": 0.09071189910173416, "critic_grad_norm": 0.07131672650575638, "ratio": 1.000400424003601, "entropy": 0.6428751349449158, "incre_win_rate": 0.8837209302325582, "step": 2620}
{"time": 1767164276.2871916, "phase": "train", "update": 2621, "total_env_steps": 8387200, "episode_reward": 0.2753989100456238, "value_loss": 0.00804445818066597, "policy_loss": -0.0014116943033670281, "dist_entropy": 0.6491837739944458, "actor_grad_norm": 0.07469137758016586, "critic_grad_norm": 0.05909150838851929, "ratio": 0.9996822476387024, "entropy": 0.6491837739944458, "incre_win_rate": 0.8913043478260869, "step": 2621}
{"time": 1767164285.7962909, "phase": "eval", "update": 2621, "total_env_steps": 8387200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.579108029801326, "step": 2621}
{"time": 1767164290.105549, "phase": "train", "update": 2622, "total_env_steps": 8390400, "episode_reward": 0.28367963433265686, "value_loss": 0.007439903635531664, "policy_loss": -0.001184721923475962, "dist_entropy": 0.6470547676086426, "actor_grad_norm": 0.0715097114443779, "critic_grad_norm": 0.047378599643707275, "ratio": 1.0004076957702637, "entropy": 0.6470547676086426, "incre_win_rate": 0.9387755102040817, "step": 2622}
{"time": 1767164294.441331, "phase": "train", "update": 2623, "total_env_steps": 8393600, "episode_reward": 0.28514179587364197, "value_loss": 0.004097216855734586, "policy_loss": -0.0015940225733608315, "dist_entropy": 0.6641764998435974, "actor_grad_norm": 0.09638398140668869, "critic_grad_norm": 0.03931235149502754, "ratio": 0.9998306632041931, "entropy": 0.6641764998435974, "incre_win_rate": 0.9318181818181818, "step": 2623}
{"time": 1767164298.754717, "phase": "train", "update": 2624, "total_env_steps": 8396800, "episode_reward": 0.28429222106933594, "value_loss": 0.004511248972266913, "policy_loss": -0.0013717182218098145, "dist_entropy": 0.6534820079803467, "actor_grad_norm": 0.08068840950727463, "critic_grad_norm": 0.06888587027788162, "ratio": 0.9997096061706543, "entropy": 0.6534820079803467, "incre_win_rate": 1.0, "step": 2624}
{"time": 1767164303.0366461, "phase": "train", "update": 2625, "total_env_steps": 8400000, "episode_reward": 0.2698965072631836, "value_loss": 0.00436531649902463, "policy_loss": -0.0012393602023855975, "dist_entropy": 0.6460517048835754, "actor_grad_norm": 0.08214495331048965, "critic_grad_norm": 0.040194205939769745, "ratio": 0.9999883770942688, "entropy": 0.6460517048835754, "incre_win_rate": 0.9555555555555556, "step": 2625}
{"time": 1767164307.3548558, "phase": "train", "update": 2626, "total_env_steps": 8403200, "episode_reward": 0.27136173844337463, "value_loss": 0.006195223517715931, "policy_loss": -0.0010235451095923053, "dist_entropy": 0.660407567024231, "actor_grad_norm": 0.08496548980474472, "critic_grad_norm": 0.09407792240381241, "ratio": 1.0000051259994507, "entropy": 0.660407567024231, "incre_win_rate": 0.8666666666666667, "step": 2626}
{"time": 1767164311.6978033, "phase": "train", "update": 2627, "total_env_steps": 8406400, "episode_reward": 0.2821016013622284, "value_loss": 0.00508703887462616, "policy_loss": -0.0015138767354869742, "dist_entropy": 0.6764164328575134, "actor_grad_norm": 0.08752759546041489, "critic_grad_norm": 0.05644705891609192, "ratio": 1.0000076293945312, "entropy": 0.6764164328575134, "incre_win_rate": 0.9347826086956522, "step": 2627}
{"time": 1767164316.0036793, "phase": "train", "update": 2628, "total_env_steps": 8409600, "episode_reward": 0.2693972587585449, "value_loss": 0.008432497829198837, "policy_loss": -0.0011194175932073946, "dist_entropy": 0.6656929016113281, "actor_grad_norm": 0.08060236275196075, "critic_grad_norm": 0.1200605183839798, "ratio": 1.0000556707382202, "entropy": 0.6656929016113281, "incre_win_rate": 0.8809523809523809, "step": 2628}
{"time": 1767164320.3408167, "phase": "train", "update": 2629, "total_env_steps": 8412800, "episode_reward": 0.2806415557861328, "value_loss": 0.006101113092154264, "policy_loss": -0.0014126411217702639, "dist_entropy": 0.6733270645141601, "actor_grad_norm": 0.07558304071426392, "critic_grad_norm": 0.038300301879644394, "ratio": 1.0001319646835327, "entropy": 0.6733270645141601, "incre_win_rate": 0.9583333333333334, "step": 2629}
{"time": 1767164324.6508546, "phase": "train", "update": 2630, "total_env_steps": 8416000, "episode_reward": 0.2701836824417114, "value_loss": 0.0068708562292158605, "policy_loss": -0.001204131108239892, "dist_entropy": 0.6570638537406921, "actor_grad_norm": 0.08220547437667847, "critic_grad_norm": 0.07770621031522751, "ratio": 0.9997350573539734, "entropy": 0.6570638537406921, "incre_win_rate": 0.9090909090909091, "step": 2630}
{"time": 1767164328.9540362, "phase": "train", "update": 2631, "total_env_steps": 8419200, "episode_reward": 0.2720803916454315, "value_loss": 0.006489870883524418, "policy_loss": -0.0010003483097200672, "dist_entropy": 0.6463080763816833, "actor_grad_norm": 0.08564308285713196, "critic_grad_norm": 0.10293953865766525, "ratio": 0.9999098181724548, "entropy": 0.6463080763816833, "incre_win_rate": 0.8888888888888888, "step": 2631}
{"time": 1767164333.2249181, "phase": "train", "update": 2632, "total_env_steps": 8422400, "episode_reward": 0.2807409167289734, "value_loss": 0.0032023088075220584, "policy_loss": -0.0012598865617967192, "dist_entropy": 0.6515195965766907, "actor_grad_norm": 0.09218868613243103, "critic_grad_norm": 0.08526431769132614, "ratio": 1.0002408027648926, "entropy": 0.6515195965766907, "incre_win_rate": 0.9767441860465116, "step": 2632}
{"time": 1767164337.5277019, "phase": "train", "update": 2633, "total_env_steps": 8425600, "episode_reward": 0.27065396308898926, "value_loss": 0.004777506832033396, "policy_loss": -0.0014969098884328957, "dist_entropy": 0.6549855589866638, "actor_grad_norm": 0.08488667011260986, "critic_grad_norm": 0.049675602465867996, "ratio": 0.9999111294746399, "entropy": 0.6549855589866638, "incre_win_rate": 0.9333333333333333, "step": 2633}
{"time": 1767164341.7005115, "phase": "train", "update": 2634, "total_env_steps": 8428800, "episode_reward": 0.26951417326927185, "value_loss": 0.005219075828790665, "policy_loss": -0.0013486655910838862, "dist_entropy": 0.6319441437721253, "actor_grad_norm": 0.08618354052305222, "critic_grad_norm": 0.05236726626753807, "ratio": 1.0000542402267456, "entropy": 0.6319441437721253, "incre_win_rate": 0.8888888888888888, "step": 2634}
{"time": 1767164345.9495826, "phase": "train", "update": 2635, "total_env_steps": 8432000, "episode_reward": 0.2694743275642395, "value_loss": 0.0067037432454526424, "policy_loss": -0.0013542621493588315, "dist_entropy": 0.6305853486061096, "actor_grad_norm": 0.08547748625278473, "critic_grad_norm": 0.06465581804513931, "ratio": 1.0001987218856812, "entropy": 0.6305853486061096, "incre_win_rate": 0.8636363636363636, "step": 2635}
{"time": 1767164350.2449808, "phase": "train", "update": 2636, "total_env_steps": 8435200, "episode_reward": 0.28122103214263916, "value_loss": 0.003994960058480501, "policy_loss": -0.001163213248150896, "dist_entropy": 0.6319703817367553, "actor_grad_norm": 0.0825151577591896, "critic_grad_norm": 0.05363157391548157, "ratio": 0.9998785853385925, "entropy": 0.6319703817367553, "incre_win_rate": 0.9565217391304348, "step": 2636}
{"time": 1767164354.5706117, "phase": "train", "update": 2637, "total_env_steps": 8438400, "episode_reward": 0.2785927355289459, "value_loss": 0.0072577445767819885, "policy_loss": -0.0015760714999397685, "dist_entropy": 0.6204740524291992, "actor_grad_norm": 0.10540487617254257, "critic_grad_norm": 0.0493236742913723, "ratio": 0.999539315700531, "entropy": 0.6204740524291992, "incre_win_rate": 0.9347826086956522, "step": 2637}
{"time": 1767164358.879943, "phase": "train", "update": 2638, "total_env_steps": 8441600, "episode_reward": 0.28178393840789795, "value_loss": 0.003464424842968583, "policy_loss": -0.0007052135189731246, "dist_entropy": 0.6142257928848267, "actor_grad_norm": 0.0845116451382637, "critic_grad_norm": 0.08696424216032028, "ratio": 1.0002731084823608, "entropy": 0.6142257928848267, "incre_win_rate": 0.9347826086956522, "step": 2638}
{"time": 1767164363.1988409, "phase": "train", "update": 2639, "total_env_steps": 8444800, "episode_reward": 0.28489911556243896, "value_loss": 0.00301462234929204, "policy_loss": -0.0010882294964481786, "dist_entropy": 0.6223352074623107, "actor_grad_norm": 0.07227563112974167, "critic_grad_norm": 0.04381907731294632, "ratio": 1.0001589059829712, "entropy": 0.6223352074623107, "incre_win_rate": 0.9361702127659575, "step": 2639}
{"time": 1767164367.5151603, "phase": "train", "update": 2640, "total_env_steps": 8448000, "episode_reward": 0.2843211889266968, "value_loss": 0.002854953380301595, "policy_loss": -0.0015906247305338185, "dist_entropy": 0.6175890684127807, "actor_grad_norm": 0.0820695236325264, "critic_grad_norm": 0.05971219018101692, "ratio": 0.999727189540863, "entropy": 0.6175890684127807, "incre_win_rate": 0.9534883720930233, "step": 2640}
{"time": 1767164371.8045788, "phase": "train", "update": 2641, "total_env_steps": 8451200, "episode_reward": 0.29082316160202026, "value_loss": 0.003765989700332284, "policy_loss": -0.001066007091790766, "dist_entropy": 0.6113310217857361, "actor_grad_norm": 0.07385235279798508, "critic_grad_norm": 0.05553172901272774, "ratio": 0.9997626543045044, "entropy": 0.6113310217857361, "incre_win_rate": 0.9574468085106383, "step": 2641}
{"time": 1767164381.2308729, "phase": "eval", "update": 2641, "total_env_steps": 8451200, "eval_win_rate": 0.875, "eval_episode_reward": 19.333764486754966, "step": 2641}
{"time": 1767164385.540474, "phase": "train", "update": 2642, "total_env_steps": 8454400, "episode_reward": 0.28309187293052673, "value_loss": 0.003473268402740359, "policy_loss": -0.0014264952192007741, "dist_entropy": 0.6002658843994141, "actor_grad_norm": 0.08776666969060898, "critic_grad_norm": 0.038616035133600235, "ratio": 0.9998593330383301, "entropy": 0.6002658843994141, "incre_win_rate": 0.9565217391304348, "step": 2642}
{"time": 1767164389.8454692, "phase": "train", "update": 2643, "total_env_steps": 8457600, "episode_reward": 0.2750175893306732, "value_loss": 0.008378392830491067, "policy_loss": -0.0011810178985555808, "dist_entropy": 0.5925885081291199, "actor_grad_norm": 0.07917110621929169, "critic_grad_norm": 0.0663195252418518, "ratio": 0.9997838139533997, "entropy": 0.5925885081291199, "incre_win_rate": 0.8936170212765957, "step": 2643}
{"time": 1767164394.1747994, "phase": "train", "update": 2644, "total_env_steps": 8460800, "episode_reward": 0.28051531314849854, "value_loss": 0.0051188871264457704, "policy_loss": -0.0016243724142498196, "dist_entropy": 0.5811791181564331, "actor_grad_norm": 0.10573792457580566, "critic_grad_norm": 0.048641450703144073, "ratio": 0.9996910095214844, "entropy": 0.5811791181564331, "incre_win_rate": 0.9333333333333333, "step": 2644}
{"time": 1767164398.5059698, "phase": "train", "update": 2645, "total_env_steps": 8464000, "episode_reward": 0.2771461308002472, "value_loss": 0.00438818596303463, "policy_loss": -0.0011890317614348333, "dist_entropy": 0.604115116596222, "actor_grad_norm": 0.09488526731729507, "critic_grad_norm": 0.034093718975782394, "ratio": 1.000098466873169, "entropy": 0.604115116596222, "incre_win_rate": 0.8913043478260869, "step": 2645}
{"time": 1767164402.7911737, "phase": "train", "update": 2646, "total_env_steps": 8467200, "episode_reward": 0.26992547512054443, "value_loss": 0.007774427346885204, "policy_loss": -0.001623771077481706, "dist_entropy": 0.5763211131095887, "actor_grad_norm": 0.1112341657280922, "critic_grad_norm": 0.09596623480319977, "ratio": 0.9998507499694824, "entropy": 0.5763211131095887, "incre_win_rate": 0.8837209302325582, "step": 2646}
{"time": 1767164407.0637681, "phase": "train", "update": 2647, "total_env_steps": 8470400, "episode_reward": 0.2809799313545227, "value_loss": 0.00482949111610651, "policy_loss": -0.0008660552752701278, "dist_entropy": 0.5872773408889771, "actor_grad_norm": 0.08573179692029953, "critic_grad_norm": 0.09655813127756119, "ratio": 0.999481201171875, "entropy": 0.5872773408889771, "incre_win_rate": 0.9583333333333334, "step": 2647}
{"time": 1767164411.3654792, "phase": "train", "update": 2648, "total_env_steps": 8473600, "episode_reward": 0.2804599404335022, "value_loss": 0.004263100679963827, "policy_loss": -0.0012460907583317748, "dist_entropy": 0.5980299949645996, "actor_grad_norm": 0.09676069021224976, "critic_grad_norm": 0.09723975509405136, "ratio": 0.9997887015342712, "entropy": 0.5980299949645996, "incre_win_rate": 0.9333333333333333, "step": 2648}
{"time": 1767164415.6364803, "phase": "train", "update": 2649, "total_env_steps": 8476800, "episode_reward": 0.27476823329925537, "value_loss": 0.007761940360069275, "policy_loss": -0.0013021896095480657, "dist_entropy": 0.6157051801681519, "actor_grad_norm": 0.07585292309522629, "critic_grad_norm": 0.04370469972491264, "ratio": 0.9999143481254578, "entropy": 0.6157051801681519, "incre_win_rate": 0.9069767441860465, "step": 2649}
{"time": 1767164419.9664066, "phase": "train", "update": 2650, "total_env_steps": 8480000, "episode_reward": 0.27919134497642517, "value_loss": 0.006152572389692068, "policy_loss": -0.001314154447531024, "dist_entropy": 0.6152735233306885, "actor_grad_norm": 0.06896237283945084, "critic_grad_norm": 0.06854994595050812, "ratio": 1.0001094341278076, "entropy": 0.6152735233306885, "incre_win_rate": 0.9148936170212766, "step": 2650}
{"time": 1767164424.2704053, "phase": "train", "update": 2651, "total_env_steps": 8483200, "episode_reward": 0.2780706584453583, "value_loss": 0.006668203603476286, "policy_loss": -0.0010790162731673548, "dist_entropy": 0.6328593730926514, "actor_grad_norm": 0.07208576053380966, "critic_grad_norm": 0.046873461455106735, "ratio": 0.9997722506523132, "entropy": 0.6328593730926514, "incre_win_rate": 0.8695652173913043, "step": 2651}
{"time": 1767164428.6162233, "phase": "train", "update": 2652, "total_env_steps": 8486400, "episode_reward": 0.2879801392555237, "value_loss": 0.004675496648997068, "policy_loss": -0.001182872796099188, "dist_entropy": 0.6040014863014221, "actor_grad_norm": 0.08167626708745956, "critic_grad_norm": 0.04504924640059471, "ratio": 1.0000146627426147, "entropy": 0.6040014863014221, "incre_win_rate": 0.9777777777777777, "step": 2652}
{"time": 1767164432.8927634, "phase": "train", "update": 2653, "total_env_steps": 8489600, "episode_reward": 0.2813664376735687, "value_loss": 0.0066403285600245, "policy_loss": -0.0012674246892039776, "dist_entropy": 0.6257726311683655, "actor_grad_norm": 0.10397499799728394, "critic_grad_norm": 0.070226289331913, "ratio": 0.9999195337295532, "entropy": 0.6257726311683655, "incre_win_rate": 0.9148936170212766, "step": 2653}
{"time": 1767164437.2188208, "phase": "train", "update": 2654, "total_env_steps": 8492800, "episode_reward": 0.2781151831150055, "value_loss": 0.007597710192203522, "policy_loss": -0.0013409457734290698, "dist_entropy": 0.6485994338989258, "actor_grad_norm": 0.10785720497369766, "critic_grad_norm": 0.07068954408168793, "ratio": 1.0001124143600464, "entropy": 0.6485994338989258, "incre_win_rate": 0.8541666666666666, "step": 2654}
{"time": 1767164441.5489538, "phase": "train", "update": 2655, "total_env_steps": 8496000, "episode_reward": 0.2751733064651489, "value_loss": 0.006727669108659029, "policy_loss": -0.001167651385063806, "dist_entropy": 0.6410057067871093, "actor_grad_norm": 0.08745793253183365, "critic_grad_norm": 0.05157407745718956, "ratio": 0.9998461008071899, "entropy": 0.6410057067871093, "incre_win_rate": 0.8888888888888888, "step": 2655}
{"time": 1767164445.9296234, "phase": "train", "update": 2656, "total_env_steps": 8499200, "episode_reward": 0.2910430431365967, "value_loss": 0.005595463793724775, "policy_loss": -0.00120984842534142, "dist_entropy": 0.6501354813575745, "actor_grad_norm": 0.08758649975061417, "critic_grad_norm": 0.056929271668195724, "ratio": 1.0002692937850952, "entropy": 0.6501354813575745, "incre_win_rate": 0.9375, "step": 2656}
{"time": 1767164450.248998, "phase": "train", "update": 2657, "total_env_steps": 8502400, "episode_reward": 0.2788555324077606, "value_loss": 0.006813233345746994, "policy_loss": -0.0009241936804883722, "dist_entropy": 0.6513394355773926, "actor_grad_norm": 0.09167790412902832, "critic_grad_norm": 0.05814000591635704, "ratio": 0.9998190999031067, "entropy": 0.6513394355773926, "incre_win_rate": 0.8863636363636364, "step": 2657}
{"time": 1767164454.5698514, "phase": "train", "update": 2658, "total_env_steps": 8505600, "episode_reward": 0.2784959673881531, "value_loss": 0.006383957434445619, "policy_loss": -0.0012303065181042071, "dist_entropy": 0.6838024973869323, "actor_grad_norm": 0.09077803045511246, "critic_grad_norm": 0.0651882216334343, "ratio": 1.0002750158309937, "entropy": 0.6838024973869323, "incre_win_rate": 0.9111111111111111, "step": 2658}
{"time": 1767164458.900764, "phase": "train", "update": 2659, "total_env_steps": 8508800, "episode_reward": 0.269203245639801, "value_loss": 0.008388754539191723, "policy_loss": -0.001149752940742843, "dist_entropy": 0.6598380923271179, "actor_grad_norm": 0.09736119955778122, "critic_grad_norm": 0.1338529735803604, "ratio": 0.999972939491272, "entropy": 0.6598380923271179, "incre_win_rate": 0.782608695652174, "step": 2659}
{"time": 1767164463.1797535, "phase": "train", "update": 2660, "total_env_steps": 8512000, "episode_reward": 0.28263142704963684, "value_loss": 0.004383454378694296, "policy_loss": -0.0013547212237881468, "dist_entropy": 0.6759526371955872, "actor_grad_norm": 0.09724827110767365, "critic_grad_norm": 0.1463620513677597, "ratio": 0.9996377229690552, "entropy": 0.6759526371955872, "incre_win_rate": 0.9130434782608695, "step": 2660}
{"time": 1767164467.4999897, "phase": "train", "update": 2661, "total_env_steps": 8515200, "episode_reward": 0.29169702529907227, "value_loss": 0.0037375667598098516, "policy_loss": -0.0011022104675561194, "dist_entropy": 0.7005363821983337, "actor_grad_norm": 0.0914686843752861, "critic_grad_norm": 0.11790724843740463, "ratio": 0.9999380111694336, "entropy": 0.7005363821983337, "incre_win_rate": 0.9791666666666666, "step": 2661}
{"time": 1767164477.25438, "phase": "eval", "update": 2661, "total_env_steps": 8515200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.551427980132452, "step": 2661}
{"time": 1767164481.4905229, "phase": "train", "update": 2662, "total_env_steps": 8518400, "episode_reward": 0.2757507264614105, "value_loss": 0.005799294821918011, "policy_loss": -0.0018059419555434887, "dist_entropy": 0.6835439801216125, "actor_grad_norm": 0.09805680811405182, "critic_grad_norm": 0.09103063493967056, "ratio": 1.0000593662261963, "entropy": 0.6835439801216125, "incre_win_rate": 0.8695652173913043, "step": 2662}
{"time": 1767164485.7627332, "phase": "train", "update": 2663, "total_env_steps": 8521600, "episode_reward": 0.2756896913051605, "value_loss": 0.0064329513348639015, "policy_loss": -0.0010067066732119656, "dist_entropy": 0.6807002902030945, "actor_grad_norm": 0.0892690122127533, "critic_grad_norm": 0.11303894966840744, "ratio": 1.0000791549682617, "entropy": 0.6807002902030945, "incre_win_rate": 0.9090909090909091, "step": 2663}
{"time": 1767164490.0377839, "phase": "train", "update": 2664, "total_env_steps": 8524800, "episode_reward": 0.2809726893901825, "value_loss": 0.004350291192531585, "policy_loss": -0.001322321641127644, "dist_entropy": 0.6621180415153504, "actor_grad_norm": 0.09386631101369858, "critic_grad_norm": 0.07295472919940948, "ratio": 1.0001404285430908, "entropy": 0.6621180415153504, "incre_win_rate": 0.9148936170212766, "step": 2664}
{"time": 1767164494.3208947, "phase": "train", "update": 2665, "total_env_steps": 8528000, "episode_reward": 0.2839730381965637, "value_loss": 0.0059618732891976835, "policy_loss": -0.001097643840096163, "dist_entropy": 0.6561296463012696, "actor_grad_norm": 0.07891794294118881, "critic_grad_norm": 0.04523010179400444, "ratio": 1.0000723600387573, "entropy": 0.6561296463012696, "incre_win_rate": 0.9111111111111111, "step": 2665}
{"time": 1767164498.5700006, "phase": "train", "update": 2666, "total_env_steps": 8531200, "episode_reward": 0.2581612169742584, "value_loss": 0.00801218869164586, "policy_loss": -0.0014347173456924268, "dist_entropy": 0.6445466756820679, "actor_grad_norm": 0.0885428860783577, "critic_grad_norm": 0.07480624318122864, "ratio": 0.9999322891235352, "entropy": 0.6445466756820679, "incre_win_rate": 0.7555555555555555, "step": 2666}
{"time": 1767164502.840235, "phase": "train", "update": 2667, "total_env_steps": 8534400, "episode_reward": 0.2864331603050232, "value_loss": 0.006179616320878267, "policy_loss": -0.0012234334946739978, "dist_entropy": 0.6543008804321289, "actor_grad_norm": 0.09552186727523804, "critic_grad_norm": 0.05555080249905586, "ratio": 1.0000075101852417, "entropy": 0.6543008804321289, "incre_win_rate": 0.9347826086956522, "step": 2667}
{"time": 1767164507.090666, "phase": "train", "update": 2668, "total_env_steps": 8537600, "episode_reward": 0.27561622858047485, "value_loss": 0.007614807784557342, "policy_loss": -0.0013034476188789057, "dist_entropy": 0.6488349676132202, "actor_grad_norm": 0.08173992484807968, "critic_grad_norm": 0.057823359966278076, "ratio": 0.9999977350234985, "entropy": 0.6488349676132202, "incre_win_rate": 0.8666666666666667, "step": 2668}
{"time": 1767164511.3159742, "phase": "train", "update": 2669, "total_env_steps": 8540800, "episode_reward": 0.284374475479126, "value_loss": 0.005217245500534773, "policy_loss": -0.0014618444934981767, "dist_entropy": 0.6309041619300843, "actor_grad_norm": 0.09055822342634201, "critic_grad_norm": 0.053415026515722275, "ratio": 0.999976634979248, "entropy": 0.6309041619300843, "incre_win_rate": 0.9130434782608695, "step": 2669}
{"time": 1767164515.5627186, "phase": "train", "update": 2670, "total_env_steps": 8544000, "episode_reward": 0.2768537998199463, "value_loss": 0.010604173876345158, "policy_loss": -0.0014974830007332685, "dist_entropy": 0.6407301306724549, "actor_grad_norm": 0.10400702804327011, "critic_grad_norm": 0.13424737751483917, "ratio": 0.9999756217002869, "entropy": 0.6407301306724549, "incre_win_rate": 0.8723404255319149, "step": 2670}
{"time": 1767164519.835672, "phase": "train", "update": 2671, "total_env_steps": 8547200, "episode_reward": 0.2819826006889343, "value_loss": 0.008150972053408622, "policy_loss": -0.0011765154613371464, "dist_entropy": 0.638352918624878, "actor_grad_norm": 0.08394014835357666, "critic_grad_norm": 0.14273975789546967, "ratio": 1.0000337362289429, "entropy": 0.638352918624878, "incre_win_rate": 0.8913043478260869, "step": 2671}
{"time": 1767164524.1319885, "phase": "train", "update": 2672, "total_env_steps": 8550400, "episode_reward": 0.27574917674064636, "value_loss": 0.006057070475071669, "policy_loss": -0.00106613836104259, "dist_entropy": 0.648666250705719, "actor_grad_norm": 0.09859920293092728, "critic_grad_norm": 0.11808554083108902, "ratio": 1.000046968460083, "entropy": 0.648666250705719, "incre_win_rate": 0.9130434782608695, "step": 2672}
{"time": 1767164528.4374795, "phase": "train", "update": 2673, "total_env_steps": 8553600, "episode_reward": 0.28581124544143677, "value_loss": 0.00506772929802537, "policy_loss": -0.0010990556321985423, "dist_entropy": 0.6448439598083496, "actor_grad_norm": 0.09752088040113449, "critic_grad_norm": 0.036725904792547226, "ratio": 1.0000559091567993, "entropy": 0.6448439598083496, "incre_win_rate": 0.9347826086956522, "step": 2673}
{"time": 1767164532.7154374, "phase": "train", "update": 2674, "total_env_steps": 8556800, "episode_reward": 0.269834965467453, "value_loss": 0.008020816836506128, "policy_loss": -0.0010658656962235114, "dist_entropy": 0.659195351600647, "actor_grad_norm": 0.06971053779125214, "critic_grad_norm": 0.14933791756629944, "ratio": 1.0000373125076294, "entropy": 0.659195351600647, "incre_win_rate": 0.782608695652174, "step": 2674}
{"time": 1767164536.9984803, "phase": "train", "update": 2675, "total_env_steps": 8560000, "episode_reward": 0.2727566361427307, "value_loss": 0.009315710328519345, "policy_loss": -0.0014485714808188277, "dist_entropy": 0.6576801300048828, "actor_grad_norm": 0.07367097586393356, "critic_grad_norm": 0.11051373928785324, "ratio": 0.9998238682746887, "entropy": 0.6576801300048828, "incre_win_rate": 0.8666666666666667, "step": 2675}
{"time": 1767164541.2302268, "phase": "train", "update": 2676, "total_env_steps": 8563200, "episode_reward": 0.27423378825187683, "value_loss": 0.007915174495428801, "policy_loss": -0.0012630066978545074, "dist_entropy": 0.6452482461929321, "actor_grad_norm": 0.0967700406908989, "critic_grad_norm": 0.10004811733961105, "ratio": 0.9998853802680969, "entropy": 0.6452482461929321, "incre_win_rate": 0.9318181818181818, "step": 2676}
{"time": 1767164545.4986591, "phase": "train", "update": 2677, "total_env_steps": 8566400, "episode_reward": 0.2715097665786743, "value_loss": 0.005198530200868845, "policy_loss": -0.0013057178017376713, "dist_entropy": 0.6359030365943908, "actor_grad_norm": 0.09509863704442978, "critic_grad_norm": 0.07487775385379791, "ratio": 1.0001248121261597, "entropy": 0.6359030365943908, "incre_win_rate": 0.9130434782608695, "step": 2677}
{"time": 1767164549.8149445, "phase": "train", "update": 2678, "total_env_steps": 8569600, "episode_reward": 0.2794857323169708, "value_loss": 0.007779211364686489, "policy_loss": -0.0010674354720293876, "dist_entropy": 0.6641041040420532, "actor_grad_norm": 0.09861874580383301, "critic_grad_norm": 0.06231823191046715, "ratio": 0.9997329711914062, "entropy": 0.6641041040420532, "incre_win_rate": 0.8863636363636364, "step": 2678}
{"time": 1767164554.0899699, "phase": "train", "update": 2679, "total_env_steps": 8572800, "episode_reward": 0.28181809186935425, "value_loss": 0.004428658075630665, "policy_loss": -0.001307072901356321, "dist_entropy": 0.6641976952552795, "actor_grad_norm": 0.08895144611597061, "critic_grad_norm": 0.04210382327437401, "ratio": 0.9998131990432739, "entropy": 0.6641976952552795, "incre_win_rate": 0.9782608695652174, "step": 2679}
{"time": 1767164558.3689091, "phase": "train", "update": 2680, "total_env_steps": 8576000, "episode_reward": 0.28228890895843506, "value_loss": 0.0055969227105379105, "policy_loss": -0.0009079426001500579, "dist_entropy": 0.6572609424591065, "actor_grad_norm": 0.08358418941497803, "critic_grad_norm": 0.07083971053361893, "ratio": 0.9999731183052063, "entropy": 0.6572609424591065, "incre_win_rate": 0.9361702127659575, "step": 2680}
{"time": 1767164562.5862637, "phase": "train", "update": 2681, "total_env_steps": 8579200, "episode_reward": 0.2781731188297272, "value_loss": 0.0047763468697667125, "policy_loss": -0.0010282240588463053, "dist_entropy": 0.6732253432273865, "actor_grad_norm": 0.08104818314313889, "critic_grad_norm": 0.05273042991757393, "ratio": 0.9997138381004333, "entropy": 0.6732253432273865, "incre_win_rate": 0.9333333333333333, "step": 2681}
{"time": 1767164572.1665392, "phase": "eval", "update": 2681, "total_env_steps": 8579200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.237582781456954, "step": 2681}
{"time": 1767164576.507981, "phase": "train", "update": 2682, "total_env_steps": 8582400, "episode_reward": 0.2891536056995392, "value_loss": 0.0041692969389259815, "policy_loss": -0.001068888973177451, "dist_entropy": 0.6675698757171631, "actor_grad_norm": 0.07835894823074341, "critic_grad_norm": 0.06365623325109482, "ratio": 1.0000087022781372, "entropy": 0.6675698757171631, "incre_win_rate": 0.9148936170212766, "step": 2682}
{"time": 1767164580.85123, "phase": "train", "update": 2683, "total_env_steps": 8585600, "episode_reward": 0.28104719519615173, "value_loss": 0.00574546568095684, "policy_loss": -0.001245962661775124, "dist_entropy": 0.6718029499053955, "actor_grad_norm": 0.098358154296875, "critic_grad_norm": 0.054656583815813065, "ratio": 0.9997453093528748, "entropy": 0.6718029499053955, "incre_win_rate": 0.9565217391304348, "step": 2683}
{"time": 1767164585.190209, "phase": "train", "update": 2684, "total_env_steps": 8588800, "episode_reward": 0.2885761559009552, "value_loss": 0.0037500934675335886, "policy_loss": -0.0012197598515122365, "dist_entropy": 0.6775219082832337, "actor_grad_norm": 0.08223260939121246, "critic_grad_norm": 0.03509236499667168, "ratio": 0.9998764395713806, "entropy": 0.6775219082832337, "incre_win_rate": 0.9574468085106383, "step": 2684}
{"time": 1767164589.47207, "phase": "train", "update": 2685, "total_env_steps": 8592000, "episode_reward": 0.27444741129875183, "value_loss": 0.006478101573884487, "policy_loss": -0.0016522534398518474, "dist_entropy": 0.655962598323822, "actor_grad_norm": 0.08750107884407043, "critic_grad_norm": 0.06595354527235031, "ratio": 0.999714195728302, "entropy": 0.655962598323822, "incre_win_rate": 0.9130434782608695, "step": 2685}
{"time": 1767164593.728853, "phase": "train", "update": 2686, "total_env_steps": 8595200, "episode_reward": 0.289329469203949, "value_loss": 0.004300884716212749, "policy_loss": -0.0015355414007430569, "dist_entropy": 0.6596904873847962, "actor_grad_norm": 0.09077510982751846, "critic_grad_norm": 0.07875453680753708, "ratio": 1.0000219345092773, "entropy": 0.6596904873847962, "incre_win_rate": 0.9555555555555556, "step": 2686}
{"time": 1767164597.974412, "phase": "train", "update": 2687, "total_env_steps": 8598400, "episode_reward": 0.28410184383392334, "value_loss": 0.0032881650142371653, "policy_loss": -0.0009331465246923187, "dist_entropy": 0.6333446383476258, "actor_grad_norm": 0.07220567017793655, "critic_grad_norm": 0.05543949827551842, "ratio": 0.9998478889465332, "entropy": 0.6333446383476258, "incre_win_rate": 0.9555555555555556, "step": 2687}
{"time": 1767164602.2368412, "phase": "train", "update": 2688, "total_env_steps": 8601600, "episode_reward": 0.2876490354537964, "value_loss": 0.0029958637431263925, "policy_loss": -0.001036469400274953, "dist_entropy": 0.6328568577766418, "actor_grad_norm": 0.07482969015836716, "critic_grad_norm": 0.039320964366197586, "ratio": 1.0000345706939697, "entropy": 0.6328568577766418, "incre_win_rate": 0.9565217391304348, "step": 2688}
{"time": 1767164606.5612495, "phase": "train", "update": 2689, "total_env_steps": 8604800, "episode_reward": 0.2928844392299652, "value_loss": 0.004724758584052325, "policy_loss": -0.0009647081523453949, "dist_entropy": 0.6224002361297607, "actor_grad_norm": 0.07191988825798035, "critic_grad_norm": 0.05213048681616783, "ratio": 1.0001161098480225, "entropy": 0.6224002361297607, "incre_win_rate": 0.94, "step": 2689}
{"time": 1767164610.8305452, "phase": "train", "update": 2690, "total_env_steps": 8608000, "episode_reward": 0.28112998604774475, "value_loss": 0.003822770481929183, "policy_loss": -0.001292492046769933, "dist_entropy": 0.623512864112854, "actor_grad_norm": 0.08082139492034912, "critic_grad_norm": 0.03922988101840019, "ratio": 1.0002927780151367, "entropy": 0.623512864112854, "incre_win_rate": 0.9333333333333333, "step": 2690}
{"time": 1767164615.135675, "phase": "train", "update": 2691, "total_env_steps": 8611200, "episode_reward": 0.2889610826969147, "value_loss": 0.005912456568330527, "policy_loss": -0.0010520027942966693, "dist_entropy": 0.6146023154258728, "actor_grad_norm": 0.06746087223291397, "critic_grad_norm": 0.04629078507423401, "ratio": 0.9999432563781738, "entropy": 0.6146023154258728, "incre_win_rate": 0.9361702127659575, "step": 2691}
{"time": 1767164619.4666486, "phase": "train", "update": 2692, "total_env_steps": 8614400, "episode_reward": 0.28949761390686035, "value_loss": 0.0040235849097371105, "policy_loss": -0.0009825821418282033, "dist_entropy": 0.6114659905433655, "actor_grad_norm": 0.08282174915075302, "critic_grad_norm": 0.04738062247633934, "ratio": 1.0000966787338257, "entropy": 0.6114659905433655, "incre_win_rate": 0.9565217391304348, "step": 2692}
{"time": 1767164623.792069, "phase": "train", "update": 2693, "total_env_steps": 8617600, "episode_reward": 0.28503260016441345, "value_loss": 0.005183531157672405, "policy_loss": -0.001491413199382663, "dist_entropy": 0.6096073627471924, "actor_grad_norm": 0.09826745837926865, "critic_grad_norm": 0.03993277624249458, "ratio": 1.0001033544540405, "entropy": 0.6096073627471924, "incre_win_rate": 0.9148936170212766, "step": 2693}
{"time": 1767164628.1315184, "phase": "train", "update": 2694, "total_env_steps": 8620800, "episode_reward": 0.2890273332595825, "value_loss": 0.0035126805771142243, "policy_loss": -0.0008082591618478574, "dist_entropy": 0.6225210666656494, "actor_grad_norm": 0.06820737570524216, "critic_grad_norm": 0.049560848623514175, "ratio": 0.9998981356620789, "entropy": 0.6225210666656494, "incre_win_rate": 0.9782608695652174, "step": 2694}
{"time": 1767164632.4991639, "phase": "train", "update": 2695, "total_env_steps": 8624000, "episode_reward": 0.29968541860580444, "value_loss": 0.0043100322596728805, "policy_loss": -0.0011508115046780175, "dist_entropy": 0.6239528656005859, "actor_grad_norm": 0.08166339248418808, "critic_grad_norm": 0.02045964077115059, "ratio": 1.0000942945480347, "entropy": 0.6239528656005859, "incre_win_rate": 0.98, "step": 2695}
{"time": 1767164636.8174682, "phase": "train", "update": 2696, "total_env_steps": 8627200, "episode_reward": 0.28407958149909973, "value_loss": 0.0041660677641630174, "policy_loss": -0.0015730509081635091, "dist_entropy": 0.6066807508468628, "actor_grad_norm": 0.10342811793088913, "critic_grad_norm": 0.028193816542625427, "ratio": 0.9995986819267273, "entropy": 0.6066807508468628, "incre_win_rate": 0.9333333333333333, "step": 2696}
{"time": 1767164641.154178, "phase": "train", "update": 2697, "total_env_steps": 8630400, "episode_reward": 0.2822495698928833, "value_loss": 0.005056182760745287, "policy_loss": -0.0011867394911242001, "dist_entropy": 0.6150788903236389, "actor_grad_norm": 0.09918669611215591, "critic_grad_norm": 0.02704242803156376, "ratio": 1.0000346899032593, "entropy": 0.6150788903236389, "incre_win_rate": 0.9347826086956522, "step": 2697}
{"time": 1767164645.4646719, "phase": "train", "update": 2698, "total_env_steps": 8633600, "episode_reward": 0.28739237785339355, "value_loss": 0.006916305981576443, "policy_loss": -0.000973273917082551, "dist_entropy": 0.620453929901123, "actor_grad_norm": 0.1255865842103958, "critic_grad_norm": 0.030807828530669212, "ratio": 0.9997267127037048, "entropy": 0.620453929901123, "incre_win_rate": 0.9148936170212766, "step": 2698}
{"time": 1767164649.8134022, "phase": "train", "update": 2699, "total_env_steps": 8636800, "episode_reward": 0.28706538677215576, "value_loss": 0.004763202834874391, "policy_loss": -0.0013611961208781053, "dist_entropy": 0.6305935382843018, "actor_grad_norm": 0.09869597107172012, "critic_grad_norm": 0.04802772030234337, "ratio": 1.00002121925354, "entropy": 0.6305935382843018, "incre_win_rate": 0.9574468085106383, "step": 2699}
{"time": 1767164654.1463468, "phase": "train", "update": 2700, "total_env_steps": 8640000, "episode_reward": 0.2885110080242157, "value_loss": 0.007663959637284279, "policy_loss": -0.0009910676957154863, "dist_entropy": 0.6428660988807678, "actor_grad_norm": 0.10330948978662491, "critic_grad_norm": 0.07235894352197647, "ratio": 0.9997648596763611, "entropy": 0.6428660988807678, "incre_win_rate": 0.9166666666666666, "step": 2700}
{"time": 1767164658.4811285, "phase": "train", "update": 2701, "total_env_steps": 8643200, "episode_reward": 0.2875082492828369, "value_loss": 0.00424653273075819, "policy_loss": -0.0012041216285666677, "dist_entropy": 0.6535420298576355, "actor_grad_norm": 0.13248316943645477, "critic_grad_norm": 0.059228815138339996, "ratio": 1.000274658203125, "entropy": 0.6535420298576355, "incre_win_rate": 0.9565217391304348, "step": 2701}
{"time": 1767164667.9905827, "phase": "eval", "update": 2701, "total_env_steps": 8643200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.544495033112582, "step": 2701}
{"time": 1767164672.2375526, "phase": "train", "update": 2702, "total_env_steps": 8646400, "episode_reward": 0.2762914001941681, "value_loss": 0.005583619605749846, "policy_loss": -0.001309221347035927, "dist_entropy": 0.6640081644058228, "actor_grad_norm": 0.09706256538629532, "critic_grad_norm": 0.08818187564611435, "ratio": 1.0000137090682983, "entropy": 0.6640081644058228, "incre_win_rate": 0.8888888888888888, "step": 2702}
{"time": 1767164677.6695492, "phase": "train", "update": 2703, "total_env_steps": 8649600, "episode_reward": 0.28696349263191223, "value_loss": 0.004817664343863726, "policy_loss": -0.0014084247892352409, "dist_entropy": 0.6634052515029907, "actor_grad_norm": 0.09423559159040451, "critic_grad_norm": 0.08694156259298325, "ratio": 1.0000441074371338, "entropy": 0.6634052515029907, "incre_win_rate": 0.9130434782608695, "step": 2703}
{"time": 1767164682.5381217, "phase": "train", "update": 2704, "total_env_steps": 8652800, "episode_reward": 0.28218957781791687, "value_loss": 0.008609267324209214, "policy_loss": -0.0010280479820021782, "dist_entropy": 0.6661965727806092, "actor_grad_norm": 0.09688092768192291, "critic_grad_norm": 0.058539342135190964, "ratio": 0.9997736215591431, "entropy": 0.6661965727806092, "incre_win_rate": 0.8936170212765957, "step": 2704}
{"time": 1767164687.249675, "phase": "train", "update": 2705, "total_env_steps": 8656000, "episode_reward": 0.2736610174179077, "value_loss": 0.01004931963980198, "policy_loss": -0.0012699363880983583, "dist_entropy": 0.6386445522308349, "actor_grad_norm": 0.09799345582723618, "critic_grad_norm": 0.07664548605680466, "ratio": 1.000187873840332, "entropy": 0.6386445522308349, "incre_win_rate": 0.7872340425531915, "step": 2705}
{"time": 1767164691.9194312, "phase": "train", "update": 2706, "total_env_steps": 8659200, "episode_reward": 0.27460938692092896, "value_loss": 0.010716068930923939, "policy_loss": -0.0018874854230446659, "dist_entropy": 0.6274660110473633, "actor_grad_norm": 0.12251196056604385, "critic_grad_norm": 0.08354310691356659, "ratio": 1.000240445137024, "entropy": 0.6274660110473633, "incre_win_rate": 0.8297872340425532, "step": 2706}
{"time": 1767164696.555423, "phase": "train", "update": 2707, "total_env_steps": 8662400, "episode_reward": 0.2735559940338135, "value_loss": 0.01149265058338642, "policy_loss": -0.0011134404752301207, "dist_entropy": 0.6070189356803894, "actor_grad_norm": 0.09173202514648438, "critic_grad_norm": 0.18771563470363617, "ratio": 1.0000377893447876, "entropy": 0.6070189356803894, "incre_win_rate": 0.8043478260869565, "step": 2707}
{"time": 1767164702.333045, "phase": "train", "update": 2708, "total_env_steps": 8665600, "episode_reward": 0.2720695436000824, "value_loss": 0.008011545706540345, "policy_loss": -0.0012722162320833342, "dist_entropy": 0.5961190223693847, "actor_grad_norm": 0.09279464930295944, "critic_grad_norm": 0.1434515416622162, "ratio": 1.000320553779602, "entropy": 0.5961190223693847, "incre_win_rate": 0.7954545454545454, "step": 2708}
{"time": 1767164707.1381755, "phase": "train", "update": 2709, "total_env_steps": 8668800, "episode_reward": 0.2799994945526123, "value_loss": 0.008650448080152274, "policy_loss": -0.0010982514214859407, "dist_entropy": 0.6141137838363647, "actor_grad_norm": 0.07906793802976608, "critic_grad_norm": 0.10182180255651474, "ratio": 0.9996208548545837, "entropy": 0.6141137838363647, "incre_win_rate": 0.9148936170212766, "step": 2709}
{"time": 1767164711.5048945, "phase": "train", "update": 2710, "total_env_steps": 8672000, "episode_reward": 0.28243377804756165, "value_loss": 0.006717806495726108, "policy_loss": -0.001047111366430553, "dist_entropy": 0.5988810420036316, "actor_grad_norm": 0.08680523186922073, "critic_grad_norm": 0.12804128229618073, "ratio": 0.9999502301216125, "entropy": 0.5988810420036316, "incre_win_rate": 0.9545454545454546, "step": 2710}
{"time": 1767164715.9199734, "phase": "train", "update": 2711, "total_env_steps": 8675200, "episode_reward": 0.2762867212295532, "value_loss": 0.00878327488899231, "policy_loss": -0.0016249156271449295, "dist_entropy": 0.5912986278533936, "actor_grad_norm": 0.11448682844638824, "critic_grad_norm": 0.08795754611492157, "ratio": 0.9997574090957642, "entropy": 0.5912986278533936, "incre_win_rate": 0.8723404255319149, "step": 2711}
{"time": 1767164720.1974695, "phase": "train", "update": 2712, "total_env_steps": 8678400, "episode_reward": 0.2757512629032135, "value_loss": 0.008410718850791454, "policy_loss": -0.00117135069560792, "dist_entropy": 0.5888830065727234, "actor_grad_norm": 0.09906726330518723, "critic_grad_norm": 0.09796839207410812, "ratio": 0.9998891949653625, "entropy": 0.5888830065727234, "incre_win_rate": 0.8936170212765957, "step": 2712}
{"time": 1767164724.503919, "phase": "train", "update": 2713, "total_env_steps": 8681600, "episode_reward": 0.2760854661464691, "value_loss": 0.007761524990200996, "policy_loss": -0.0012550500312569213, "dist_entropy": 0.5654436945915222, "actor_grad_norm": 0.07798191159963608, "critic_grad_norm": 0.07106860727071762, "ratio": 1.0001567602157593, "entropy": 0.5654436945915222, "incre_win_rate": 0.9090909090909091, "step": 2713}
{"time": 1767164728.8461926, "phase": "train", "update": 2714, "total_env_steps": 8684800, "episode_reward": 0.2801179587841034, "value_loss": 0.00672897445037961, "policy_loss": -0.001082513563576981, "dist_entropy": 0.5949299812316895, "actor_grad_norm": 0.07914739102125168, "critic_grad_norm": 0.08728578686714172, "ratio": 0.9999926686286926, "entropy": 0.5949299812316895, "incre_win_rate": 0.8666666666666667, "step": 2714}
{"time": 1767164733.2141573, "phase": "train", "update": 2715, "total_env_steps": 8688000, "episode_reward": 0.28513967990875244, "value_loss": 0.0056245018728077415, "policy_loss": -0.0010331961973228942, "dist_entropy": 0.592148756980896, "actor_grad_norm": 0.07917924970388412, "critic_grad_norm": 0.0372745655477047, "ratio": 1.0001853704452515, "entropy": 0.592148756980896, "incre_win_rate": 0.8936170212765957, "step": 2715}
{"time": 1767164737.594798, "phase": "train", "update": 2716, "total_env_steps": 8691200, "episode_reward": 0.2849844992160797, "value_loss": 0.005399139970541001, "policy_loss": -0.0011375312037870343, "dist_entropy": 0.6054325580596924, "actor_grad_norm": 0.07704805582761765, "critic_grad_norm": 0.05576071888208389, "ratio": 1.0001121759414673, "entropy": 0.6054325580596924, "incre_win_rate": 0.9347826086956522, "step": 2716}
{"time": 1767164741.9145215, "phase": "train", "update": 2717, "total_env_steps": 8694400, "episode_reward": 0.2800294756889343, "value_loss": 0.005274727381765843, "policy_loss": -0.0012666922404093838, "dist_entropy": 0.6165842056274414, "actor_grad_norm": 0.0869327187538147, "critic_grad_norm": 0.07961689680814743, "ratio": 1.0001929998397827, "entropy": 0.6165842056274414, "incre_win_rate": 0.8913043478260869, "step": 2717}
{"time": 1767164746.2067287, "phase": "train", "update": 2718, "total_env_steps": 8697600, "episode_reward": 0.28291285037994385, "value_loss": 0.005958854034543037, "policy_loss": -0.0014941460646447525, "dist_entropy": 0.5922561645507812, "actor_grad_norm": 0.11783081293106079, "critic_grad_norm": 0.08403585106134415, "ratio": 0.9997987151145935, "entropy": 0.5922561645507812, "incre_win_rate": 0.9347826086956522, "step": 2718}
{"time": 1767164750.545553, "phase": "train", "update": 2719, "total_env_steps": 8700800, "episode_reward": 0.27491360902786255, "value_loss": 0.006836589705199003, "policy_loss": -0.0012851651007245834, "dist_entropy": 0.6073770523071289, "actor_grad_norm": 0.0720847025513649, "critic_grad_norm": 0.04961041361093521, "ratio": 0.9998218417167664, "entropy": 0.6073770523071289, "incre_win_rate": 0.8695652173913043, "step": 2719}
{"time": 1767164754.8806617, "phase": "train", "update": 2720, "total_env_steps": 8704000, "episode_reward": 0.2849689722061157, "value_loss": 0.0067869463004171845, "policy_loss": -0.0015120042248994991, "dist_entropy": 0.6247583031654358, "actor_grad_norm": 0.0924653634428978, "critic_grad_norm": 0.06085243448615074, "ratio": 1.0002164840698242, "entropy": 0.6247583031654358, "incre_win_rate": 0.9148936170212766, "step": 2720}
{"time": 1767164759.191542, "phase": "train", "update": 2721, "total_env_steps": 8707200, "episode_reward": 0.28655940294265747, "value_loss": 0.007128852605819702, "policy_loss": -0.0013547811727420366, "dist_entropy": 0.5946569681167603, "actor_grad_norm": 0.10356215387582779, "critic_grad_norm": 0.11455674469470978, "ratio": 1.000116229057312, "entropy": 0.5946569681167603, "incre_win_rate": 0.9565217391304348, "step": 2721}
{"time": 1767164768.8854966, "phase": "eval", "update": 2721, "total_env_steps": 8707200, "eval_win_rate": 0.8125, "eval_episode_reward": 18.831281043046356, "step": 2721}
{"time": 1767164773.1721358, "phase": "train", "update": 2722, "total_env_steps": 8710400, "episode_reward": 0.28093233704566956, "value_loss": 0.00648074671626091, "policy_loss": -0.0011023203951115335, "dist_entropy": 0.6085896134376526, "actor_grad_norm": 0.10465283691883087, "critic_grad_norm": 0.10857498645782471, "ratio": 1.0001256465911865, "entropy": 0.6085896134376526, "incre_win_rate": 0.9333333333333333, "step": 2722}
{"time": 1767164777.4726582, "phase": "train", "update": 2723, "total_env_steps": 8713600, "episode_reward": 0.2886134386062622, "value_loss": 0.004065620433539152, "policy_loss": -0.001468441479929794, "dist_entropy": 0.619920015335083, "actor_grad_norm": 0.10078727453947067, "critic_grad_norm": 0.09172900021076202, "ratio": 1.000055193901062, "entropy": 0.619920015335083, "incre_win_rate": 0.9361702127659575, "step": 2723}
{"time": 1767164781.7840376, "phase": "train", "update": 2724, "total_env_steps": 8716800, "episode_reward": 0.2864031493663788, "value_loss": 0.0022534113377332687, "policy_loss": -0.0012923654128215389, "dist_entropy": 0.6297950029373169, "actor_grad_norm": 0.09921558946371078, "critic_grad_norm": 0.053776007145643234, "ratio": 1.000177025794983, "entropy": 0.6297950029373169, "incre_win_rate": 1.0, "step": 2724}
{"time": 1767164786.1202145, "phase": "train", "update": 2725, "total_env_steps": 8720000, "episode_reward": 0.2905505299568176, "value_loss": 0.0029807107523083685, "policy_loss": -0.0013140798512414121, "dist_entropy": 0.6393096685409546, "actor_grad_norm": 0.08714329451322556, "critic_grad_norm": 0.04008464142680168, "ratio": 0.9996532797813416, "entropy": 0.6393096685409546, "incre_win_rate": 0.9574468085106383, "step": 2725}
{"time": 1767164790.4687886, "phase": "train", "update": 2726, "total_env_steps": 8723200, "episode_reward": 0.27782750129699707, "value_loss": 0.007933262176811695, "policy_loss": -0.001634461485755878, "dist_entropy": 0.6379251956939698, "actor_grad_norm": 0.08302115648984909, "critic_grad_norm": 0.12885871529579163, "ratio": 0.9998435974121094, "entropy": 0.6379251956939698, "incre_win_rate": 0.8723404255319149, "step": 2726}
{"time": 1767164794.79424, "phase": "train", "update": 2727, "total_env_steps": 8726400, "episode_reward": 0.2772987186908722, "value_loss": 0.008233619667589665, "policy_loss": -0.0011741580377815808, "dist_entropy": 0.6313746809959412, "actor_grad_norm": 0.09746714681386948, "critic_grad_norm": 0.08357097208499908, "ratio": 1.0000113248825073, "entropy": 0.6313746809959412, "incre_win_rate": 0.8478260869565217, "step": 2727}
{"time": 1767164799.1669958, "phase": "train", "update": 2728, "total_env_steps": 8729600, "episode_reward": 0.2729852795600891, "value_loss": 0.009271968714892864, "policy_loss": -0.0012334570373765175, "dist_entropy": 0.6274125456809998, "actor_grad_norm": 0.09409919381141663, "critic_grad_norm": 0.16309329867362976, "ratio": 0.9999491572380066, "entropy": 0.6274125456809998, "incre_win_rate": 0.8181818181818182, "step": 2728}
{"time": 1767164803.4759703, "phase": "train", "update": 2729, "total_env_steps": 8732800, "episode_reward": 0.26905009150505066, "value_loss": 0.009939434938132763, "policy_loss": -0.0014669364126007167, "dist_entropy": 0.6130727767944336, "actor_grad_norm": 0.07973025739192963, "critic_grad_norm": 0.07498811930418015, "ratio": 0.9998095631599426, "entropy": 0.6130727767944336, "incre_win_rate": 0.7659574468085106, "step": 2729}
{"time": 1767164807.82539, "phase": "train", "update": 2730, "total_env_steps": 8736000, "episode_reward": 0.28620445728302, "value_loss": 0.005824629310518503, "policy_loss": -0.0008563268397040247, "dist_entropy": 0.6191774845123291, "actor_grad_norm": 0.08095494657754898, "critic_grad_norm": 0.09559489041566849, "ratio": 0.9999588131904602, "entropy": 0.6191774845123291, "incre_win_rate": 0.9565217391304348, "step": 2730}
{"time": 1767164812.128926, "phase": "train", "update": 2731, "total_env_steps": 8739200, "episode_reward": 0.2755463719367981, "value_loss": 0.00607823757454753, "policy_loss": -0.001363870005145884, "dist_entropy": 0.6179646611213684, "actor_grad_norm": 0.0796409547328949, "critic_grad_norm": 0.04375716671347618, "ratio": 0.9998760223388672, "entropy": 0.6179646611213684, "incre_win_rate": 0.9111111111111111, "step": 2731}
{"time": 1767164816.4937732, "phase": "train", "update": 2732, "total_env_steps": 8742400, "episode_reward": 0.284297913312912, "value_loss": 0.00561553006991744, "policy_loss": -0.001106025150657075, "dist_entropy": 0.6146905064582825, "actor_grad_norm": 0.08521444350481033, "critic_grad_norm": 0.09381943196058273, "ratio": 0.9996538162231445, "entropy": 0.6146905064582825, "incre_win_rate": 0.8936170212765957, "step": 2732}
{"time": 1767164820.8447452, "phase": "train", "update": 2733, "total_env_steps": 8745600, "episode_reward": 0.27602702379226685, "value_loss": 0.007114232797175646, "policy_loss": -0.0010810264473750664, "dist_entropy": 0.6258989334106445, "actor_grad_norm": 0.0886383131146431, "critic_grad_norm": 0.09047239273786545, "ratio": 1.000045657157898, "entropy": 0.6258989334106445, "incre_win_rate": 0.8888888888888888, "step": 2733}
{"time": 1767164825.214814, "phase": "train", "update": 2734, "total_env_steps": 8748800, "episode_reward": 0.277709037065506, "value_loss": 0.006906148698180914, "policy_loss": -0.0010807721990445883, "dist_entropy": 0.6160114884376526, "actor_grad_norm": 0.09225630760192871, "critic_grad_norm": 0.09200671315193176, "ratio": 1.0002422332763672, "entropy": 0.6160114884376526, "incre_win_rate": 0.8695652173913043, "step": 2734}
{"time": 1767164829.5221877, "phase": "train", "update": 2735, "total_env_steps": 8752000, "episode_reward": 0.2854682207107544, "value_loss": 0.004504507966339588, "policy_loss": -0.0014998687161112301, "dist_entropy": 0.6032377123832703, "actor_grad_norm": 0.09485077857971191, "critic_grad_norm": 0.1241077184677124, "ratio": 1.0001335144042969, "entropy": 0.6032377123832703, "incre_win_rate": 0.9574468085106383, "step": 2735}
{"time": 1767164833.8427894, "phase": "train", "update": 2736, "total_env_steps": 8755200, "episode_reward": 0.27813950181007385, "value_loss": 0.005612760689109564, "policy_loss": -0.0011195161702417522, "dist_entropy": 0.60804603099823, "actor_grad_norm": 0.07327870279550552, "critic_grad_norm": 0.14796356856822968, "ratio": 0.9997408986091614, "entropy": 0.60804603099823, "incre_win_rate": 0.8913043478260869, "step": 2736}
{"time": 1767164838.1693027, "phase": "train", "update": 2737, "total_env_steps": 8758400, "episode_reward": 0.2859768569469452, "value_loss": 0.006564275454729795, "policy_loss": -0.0012871360517657138, "dist_entropy": 0.6030862092971802, "actor_grad_norm": 0.10123250633478165, "critic_grad_norm": 0.08616235107183456, "ratio": 0.9999716877937317, "entropy": 0.6030862092971802, "incre_win_rate": 0.9130434782608695, "step": 2737}
{"time": 1767164842.481179, "phase": "train", "update": 2738, "total_env_steps": 8761600, "episode_reward": 0.28980547189712524, "value_loss": 0.004049541335552931, "policy_loss": -0.0013140306043851525, "dist_entropy": 0.6021764278411865, "actor_grad_norm": 0.0921323373913765, "critic_grad_norm": 0.1688164919614792, "ratio": 1.0002342462539673, "entropy": 0.6021764278411865, "incre_win_rate": 0.9787234042553191, "step": 2738}
{"time": 1767164846.852419, "phase": "train", "update": 2739, "total_env_steps": 8764800, "episode_reward": 0.29834073781967163, "value_loss": 0.004197026789188385, "policy_loss": -0.0012118868846442866, "dist_entropy": 0.6331138968467712, "actor_grad_norm": 0.0791449323296547, "critic_grad_norm": 0.08056231588125229, "ratio": 1.0000526905059814, "entropy": 0.6331138968467712, "incre_win_rate": 0.9583333333333334, "step": 2739}
{"time": 1767164851.214204, "phase": "train", "update": 2740, "total_env_steps": 8768000, "episode_reward": 0.2851904034614563, "value_loss": 0.005456717684864998, "policy_loss": -0.0009732924914818142, "dist_entropy": 0.623429799079895, "actor_grad_norm": 0.08510825783014297, "critic_grad_norm": 0.10795829445123672, "ratio": 0.9999195337295532, "entropy": 0.623429799079895, "incre_win_rate": 0.9333333333333333, "step": 2740}
{"time": 1767164855.575174, "phase": "train", "update": 2741, "total_env_steps": 8771200, "episode_reward": 0.28611651062965393, "value_loss": 0.0030140085611492394, "policy_loss": -0.0009792500696832462, "dist_entropy": 0.6111283898353577, "actor_grad_norm": 0.10241057723760605, "critic_grad_norm": 0.055230606347322464, "ratio": 0.9995929598808289, "entropy": 0.6111283898353577, "incre_win_rate": 0.9148936170212766, "step": 2741}
{"time": 1767164865.412062, "phase": "eval", "update": 2741, "total_env_steps": 8771200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.02167839403974, "step": 2741}
{"time": 1767164869.7769442, "phase": "train", "update": 2742, "total_env_steps": 8774400, "episode_reward": 0.2961340844631195, "value_loss": 0.0031557613983750343, "policy_loss": -0.0011222274934141296, "dist_entropy": 0.6461931347846985, "actor_grad_norm": 0.10479308664798737, "critic_grad_norm": 0.06658967584371567, "ratio": 0.999291718006134, "entropy": 0.6461931347846985, "incre_win_rate": 0.9591836734693877, "step": 2742}
{"time": 1767164874.0962272, "phase": "train", "update": 2743, "total_env_steps": 8777600, "episode_reward": 0.281241238117218, "value_loss": 0.004492813535034656, "policy_loss": -0.0011928256058354237, "dist_entropy": 0.6265648484230042, "actor_grad_norm": 0.09763343632221222, "critic_grad_norm": 0.04503794386982918, "ratio": 0.9997218251228333, "entropy": 0.6265648484230042, "incre_win_rate": 0.9333333333333333, "step": 2743}
{"time": 1767164878.4085314, "phase": "train", "update": 2744, "total_env_steps": 8780800, "episode_reward": 0.2780313789844513, "value_loss": 0.007726117409765721, "policy_loss": -0.0009223874801726594, "dist_entropy": 0.61828773021698, "actor_grad_norm": 0.09536883980035782, "critic_grad_norm": 0.07524009793996811, "ratio": 1.0003042221069336, "entropy": 0.61828773021698, "incre_win_rate": 0.8936170212765957, "step": 2744}
{"time": 1767164882.7547104, "phase": "train", "update": 2745, "total_env_steps": 8784000, "episode_reward": 0.2851448655128479, "value_loss": 0.006413642223924399, "policy_loss": -0.000934755276858823, "dist_entropy": 0.6027340769767762, "actor_grad_norm": 0.0924132913351059, "critic_grad_norm": 0.0595235712826252, "ratio": 1.0002174377441406, "entropy": 0.6027340769767762, "incre_win_rate": 0.8936170212765957, "step": 2745}
{"time": 1767164887.0583138, "phase": "train", "update": 2746, "total_env_steps": 8787200, "episode_reward": 0.2766830325126648, "value_loss": 0.0052625065669417385, "policy_loss": -0.0009269836898717187, "dist_entropy": 0.6098309636116028, "actor_grad_norm": 0.10839977115392685, "critic_grad_norm": 0.07364841550588608, "ratio": 0.9998558163642883, "entropy": 0.6098309636116028, "incre_win_rate": 0.9318181818181818, "step": 2746}
{"time": 1767164891.418749, "phase": "train", "update": 2747, "total_env_steps": 8790400, "episode_reward": 0.291622519493103, "value_loss": 0.003258885303512216, "policy_loss": -0.0014624694442620268, "dist_entropy": 0.6302438974380493, "actor_grad_norm": 0.093978650867939, "critic_grad_norm": 0.04803964123129845, "ratio": 0.999772846698761, "entropy": 0.6302438974380493, "incre_win_rate": 0.9787234042553191, "step": 2747}
{"time": 1767164895.757357, "phase": "train", "update": 2748, "total_env_steps": 8793600, "episode_reward": 0.28704163432121277, "value_loss": 0.004841795470565557, "policy_loss": -0.0011474522503242212, "dist_entropy": 0.6204959154129028, "actor_grad_norm": 0.07417452335357666, "critic_grad_norm": 0.03730246052145958, "ratio": 1.0002259016036987, "entropy": 0.6204959154129028, "incre_win_rate": 0.9583333333333334, "step": 2748}
{"time": 1767164900.116666, "phase": "train", "update": 2749, "total_env_steps": 8796800, "episode_reward": 0.2825413942337036, "value_loss": 0.006053559388965369, "policy_loss": -0.0013333823713225002, "dist_entropy": 0.6295417904853821, "actor_grad_norm": 0.0844295546412468, "critic_grad_norm": 0.043142106384038925, "ratio": 1.0001901388168335, "entropy": 0.6295417904853821, "incre_win_rate": 0.9333333333333333, "step": 2749}
{"time": 1767164904.4793017, "phase": "train", "update": 2750, "total_env_steps": 8800000, "episode_reward": 0.2834349274635315, "value_loss": 0.005606297124177218, "policy_loss": -0.0015364868537679933, "dist_entropy": 0.6337659955024719, "actor_grad_norm": 0.09087660163640976, "critic_grad_norm": 0.05667487531900406, "ratio": 0.9997841715812683, "entropy": 0.6337659955024719, "incre_win_rate": 0.9361702127659575, "step": 2750}
{"time": 1767164908.8336742, "phase": "train", "update": 2751, "total_env_steps": 8803200, "episode_reward": 0.28314828872680664, "value_loss": 0.006375378556549549, "policy_loss": -0.0014543677397593768, "dist_entropy": 0.6475674748420716, "actor_grad_norm": 0.08407580107450485, "critic_grad_norm": 0.07047563046216965, "ratio": 0.9999991655349731, "entropy": 0.6475674748420716, "incre_win_rate": 0.9534883720930233, "step": 2751}
{"time": 1767164913.1802263, "phase": "train", "update": 2752, "total_env_steps": 8806400, "episode_reward": 0.28402528166770935, "value_loss": 0.0036826681345701216, "policy_loss": -0.0013639963333827332, "dist_entropy": 0.632639718055725, "actor_grad_norm": 0.07972507923841476, "critic_grad_norm": 0.04551906883716583, "ratio": 1.0001752376556396, "entropy": 0.632639718055725, "incre_win_rate": 0.9375, "step": 2752}
{"time": 1767164917.6340046, "phase": "train", "update": 2753, "total_env_steps": 8809600, "episode_reward": 0.28470200300216675, "value_loss": 0.005333623103797436, "policy_loss": -0.0013263183270911584, "dist_entropy": 0.6451151967048645, "actor_grad_norm": 0.0866408571600914, "critic_grad_norm": 0.031083619222044945, "ratio": 0.9998647570610046, "entropy": 0.6451151967048645, "incre_win_rate": 0.9574468085106383, "step": 2753}
{"time": 1767164922.0767393, "phase": "train", "update": 2754, "total_env_steps": 8812800, "episode_reward": 0.28644248843193054, "value_loss": 0.004483980964869261, "policy_loss": -0.001374412588281615, "dist_entropy": 0.6357852697372437, "actor_grad_norm": 0.07560227811336517, "critic_grad_norm": 0.07777594774961472, "ratio": 0.9998775720596313, "entropy": 0.6357852697372437, "incre_win_rate": 0.9565217391304348, "step": 2754}
{"time": 1767164926.3913205, "phase": "train", "update": 2755, "total_env_steps": 8816000, "episode_reward": 0.2910119891166687, "value_loss": 0.003943197289481759, "policy_loss": -0.0009875318688536082, "dist_entropy": 0.6140774965286255, "actor_grad_norm": 0.07872851938009262, "critic_grad_norm": 0.06271969527006149, "ratio": 1.0000077486038208, "entropy": 0.6140774965286255, "incre_win_rate": 0.9555555555555556, "step": 2755}
{"time": 1767164930.7981207, "phase": "train", "update": 2756, "total_env_steps": 8819200, "episode_reward": 0.27632758021354675, "value_loss": 0.008204362541437148, "policy_loss": -0.0011182597468309297, "dist_entropy": 0.608642292022705, "actor_grad_norm": 0.07431264966726303, "critic_grad_norm": 0.1382002979516983, "ratio": 1.0000661611557007, "entropy": 0.608642292022705, "incre_win_rate": 0.8541666666666666, "step": 2756}
{"time": 1767164935.1217701, "phase": "train", "update": 2757, "total_env_steps": 8822400, "episode_reward": 0.28393420577049255, "value_loss": 0.006014160253107548, "policy_loss": -0.0013557923470543186, "dist_entropy": 0.6220288872718811, "actor_grad_norm": 0.07714642584323883, "critic_grad_norm": 0.08630301803350449, "ratio": 0.9997143149375916, "entropy": 0.6220288872718811, "incre_win_rate": 0.9555555555555556, "step": 2757}
{"time": 1767164939.4730105, "phase": "train", "update": 2758, "total_env_steps": 8825600, "episode_reward": 0.2809794247150421, "value_loss": 0.006715373136103153, "policy_loss": -0.001055512484923593, "dist_entropy": 0.606600308418274, "actor_grad_norm": 0.07057062536478043, "critic_grad_norm": 0.04386412724852562, "ratio": 0.9995279312133789, "entropy": 0.606600308418274, "incre_win_rate": 0.8723404255319149, "step": 2758}
{"time": 1767164943.9192264, "phase": "train", "update": 2759, "total_env_steps": 8828800, "episode_reward": 0.2755380868911743, "value_loss": 0.00741442758589983, "policy_loss": -0.0014631799673892943, "dist_entropy": 0.5993014216423035, "actor_grad_norm": 0.08409341424703598, "critic_grad_norm": 0.06774040311574936, "ratio": 1.0002050399780273, "entropy": 0.5993014216423035, "incre_win_rate": 0.875, "step": 2759}
{"time": 1767164948.3419259, "phase": "train", "update": 2760, "total_env_steps": 8832000, "episode_reward": 0.28738412261009216, "value_loss": 0.006762221455574036, "policy_loss": -0.0008803685270635242, "dist_entropy": 0.5949267625808716, "actor_grad_norm": 0.08708276599645615, "critic_grad_norm": 0.0993514135479927, "ratio": 0.9999294281005859, "entropy": 0.5949267625808716, "incre_win_rate": 0.9111111111111111, "step": 2760}
{"time": 1767164952.7123373, "phase": "train", "update": 2761, "total_env_steps": 8835200, "episode_reward": 0.2874829173088074, "value_loss": 0.0057465387508273125, "policy_loss": -0.001175930160819938, "dist_entropy": 0.5910815477371216, "actor_grad_norm": 0.10022129863500595, "critic_grad_norm": 0.05050472542643547, "ratio": 1.0002387762069702, "entropy": 0.5910815477371216, "incre_win_rate": 0.9148936170212766, "step": 2761}
{"time": 1767164962.136428, "phase": "eval", "update": 2761, "total_env_steps": 8835200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.475165562913908, "step": 2761}
{"time": 1767164966.4246585, "phase": "train", "update": 2762, "total_env_steps": 8838400, "episode_reward": 0.2879759669303894, "value_loss": 0.004848226346075535, "policy_loss": -0.0013624897172263672, "dist_entropy": 0.5818964123725892, "actor_grad_norm": 0.11260616779327393, "critic_grad_norm": 0.10601971298456192, "ratio": 0.9998703002929688, "entropy": 0.5818964123725892, "incre_win_rate": 0.9565217391304348, "step": 2762}
{"time": 1767164970.75179, "phase": "train", "update": 2763, "total_env_steps": 8841600, "episode_reward": 0.29296359419822693, "value_loss": 0.004395858384668827, "policy_loss": -0.0009002445259540081, "dist_entropy": 0.5797361493110657, "actor_grad_norm": 0.06727809458971024, "critic_grad_norm": 0.05375378206372261, "ratio": 0.9999690055847168, "entropy": 0.5797361493110657, "incre_win_rate": 0.9591836734693877, "step": 2763}
{"time": 1767164975.0398684, "phase": "train", "update": 2764, "total_env_steps": 8844800, "episode_reward": 0.2881777882575989, "value_loss": 0.006373742315918207, "policy_loss": -0.001480842967755791, "dist_entropy": 0.5895345091819764, "actor_grad_norm": 0.08129582554101944, "critic_grad_norm": 0.09329279512166977, "ratio": 0.9998329281806946, "entropy": 0.5895345091819764, "incre_win_rate": 0.8913043478260869, "step": 2764}
{"time": 1767164979.3881474, "phase": "train", "update": 2765, "total_env_steps": 8848000, "episode_reward": 0.2790045440196991, "value_loss": 0.006596539262682199, "policy_loss": -0.0009054175993405522, "dist_entropy": 0.56720871925354, "actor_grad_norm": 0.09862037748098373, "critic_grad_norm": 0.15438582003116608, "ratio": 1.0002856254577637, "entropy": 0.56720871925354, "incre_win_rate": 0.9111111111111111, "step": 2765}
{"time": 1767164983.7664812, "phase": "train", "update": 2766, "total_env_steps": 8851200, "episode_reward": 0.2962789833545685, "value_loss": 0.0028144810814410446, "policy_loss": -0.0010096062401979467, "dist_entropy": 0.5638319373130798, "actor_grad_norm": 0.0869712382555008, "critic_grad_norm": 0.1708299219608307, "ratio": 0.9999290704727173, "entropy": 0.5638319373130798, "incre_win_rate": 1.0, "step": 2766}
{"time": 1767164988.0803106, "phase": "train", "update": 2767, "total_env_steps": 8854400, "episode_reward": 0.27596595883369446, "value_loss": 0.005974587611854076, "policy_loss": -0.0015915112987261893, "dist_entropy": 0.5781610012054443, "actor_grad_norm": 0.08116640895605087, "critic_grad_norm": 0.10859113186597824, "ratio": 1.000639796257019, "entropy": 0.5781610012054443, "incre_win_rate": 0.8913043478260869, "step": 2767}
{"time": 1767164992.4523082, "phase": "train", "update": 2768, "total_env_steps": 8857600, "episode_reward": 0.29360461235046387, "value_loss": 0.005339638236910105, "policy_loss": -0.0009809479197421922, "dist_entropy": 0.5753727197647095, "actor_grad_norm": 0.06984104961156845, "critic_grad_norm": 0.05532795190811157, "ratio": 0.9999629855155945, "entropy": 0.5753727197647095, "incre_win_rate": 0.9375, "step": 2768}
{"time": 1767164996.7977772, "phase": "train", "update": 2769, "total_env_steps": 8860800, "episode_reward": 0.29596441984176636, "value_loss": 0.004483776446431875, "policy_loss": -0.0010554325281802335, "dist_entropy": 0.5855136275291443, "actor_grad_norm": 0.07234051078557968, "critic_grad_norm": 0.0707356259226799, "ratio": 0.9999446272850037, "entropy": 0.5855136275291443, "incre_win_rate": 0.9583333333333334, "step": 2769}
{"time": 1767165001.163225, "phase": "train", "update": 2770, "total_env_steps": 8864000, "episode_reward": 0.28998860716819763, "value_loss": 0.00634182346984744, "policy_loss": -0.0012657048343481137, "dist_entropy": 0.5955208897590637, "actor_grad_norm": 0.08386242389678955, "critic_grad_norm": 0.05294326692819595, "ratio": 0.9997661709785461, "entropy": 0.5955208897590637, "incre_win_rate": 0.9361702127659575, "step": 2770}
{"time": 1767165005.7291052, "phase": "train", "update": 2771, "total_env_steps": 8867200, "episode_reward": 0.2804413139820099, "value_loss": 0.00751312579959631, "policy_loss": -0.0009650801325335578, "dist_entropy": 0.5935709476470947, "actor_grad_norm": 0.09250427037477493, "critic_grad_norm": 0.037998683750629425, "ratio": 0.9996682405471802, "entropy": 0.5935709476470947, "incre_win_rate": 0.8723404255319149, "step": 2771}
{"time": 1767165010.8613858, "phase": "train", "update": 2772, "total_env_steps": 8870400, "episode_reward": 0.2963286340236664, "value_loss": 0.0037702278234064577, "policy_loss": -0.0011958726226012572, "dist_entropy": 0.5991174936294555, "actor_grad_norm": 0.0923125147819519, "critic_grad_norm": 0.09677822142839432, "ratio": 1.0000616312026978, "entropy": 0.5991174936294555, "incre_win_rate": 0.9574468085106383, "step": 2772}
{"time": 1767165015.252054, "phase": "train", "update": 2773, "total_env_steps": 8873600, "episode_reward": 0.2885802984237671, "value_loss": 0.005995975993573666, "policy_loss": -0.001317647502484931, "dist_entropy": 0.5767667293548584, "actor_grad_norm": 0.07728340476751328, "critic_grad_norm": 0.0694369375705719, "ratio": 0.9999361038208008, "entropy": 0.5767667293548584, "incre_win_rate": 0.9183673469387755, "step": 2773}
{"time": 1767165019.8804097, "phase": "train", "update": 2774, "total_env_steps": 8876800, "episode_reward": 0.28769606351852417, "value_loss": 0.003413244057446718, "policy_loss": -0.0009572028141657585, "dist_entropy": 0.5937158226966858, "actor_grad_norm": 0.0702456533908844, "critic_grad_norm": 0.042313527315855026, "ratio": 1.0004539489746094, "entropy": 0.5937158226966858, "incre_win_rate": 0.9347826086956522, "step": 2774}
{"time": 1767165024.2109363, "phase": "train", "update": 2775, "total_env_steps": 8880000, "episode_reward": 0.27939465641975403, "value_loss": 0.006777993775904179, "policy_loss": -0.0012229661840454042, "dist_entropy": 0.5952905416488647, "actor_grad_norm": 0.07471112906932831, "critic_grad_norm": 0.06582527607679367, "ratio": 0.9998188018798828, "entropy": 0.5952905416488647, "incre_win_rate": 0.9111111111111111, "step": 2775}
{"time": 1767165028.5362089, "phase": "train", "update": 2776, "total_env_steps": 8883200, "episode_reward": 0.2890159487724304, "value_loss": 0.005299010593444109, "policy_loss": -0.0011470131029113872, "dist_entropy": 0.6012372851371766, "actor_grad_norm": 0.072648786008358, "critic_grad_norm": 0.09770351648330688, "ratio": 1.000077486038208, "entropy": 0.6012372851371766, "incre_win_rate": 0.9565217391304348, "step": 2776}
{"time": 1767165067.1053548, "phase": "train", "update": 2777, "total_env_steps": 8886400, "episode_reward": 0.2659794092178345, "value_loss": 0.07616818994283676, "policy_loss": -0.001116395667825998, "dist_entropy": 0.6183289408683776, "actor_grad_norm": 0.06925516575574875, "critic_grad_norm": 0.5298534035682678, "ratio": 1.0001105070114136, "entropy": 0.6183289408683776, "incre_win_rate": 0.813953488372093, "step": 2777}
{"time": 1767165071.4800398, "phase": "train", "update": 2778, "total_env_steps": 8889600, "episode_reward": 0.28024783730506897, "value_loss": 0.006397362146526575, "policy_loss": -0.0009780297750225486, "dist_entropy": 0.6271822094917298, "actor_grad_norm": 0.06833191215991974, "critic_grad_norm": 0.3862960934638977, "ratio": 1.0002306699752808, "entropy": 0.6271822094917298, "incre_win_rate": 0.9130434782608695, "step": 2778}
{"time": 1767165075.8109422, "phase": "train", "update": 2779, "total_env_steps": 8892800, "episode_reward": 0.2818010449409485, "value_loss": 0.006130267959088087, "policy_loss": -0.0012534080870949538, "dist_entropy": 0.6184394240379334, "actor_grad_norm": 0.07988286018371582, "critic_grad_norm": 0.25740334391593933, "ratio": 0.9997715950012207, "entropy": 0.6184394240379334, "incre_win_rate": 0.9347826086956522, "step": 2779}
{"time": 1767165080.164885, "phase": "train", "update": 2780, "total_env_steps": 8896000, "episode_reward": 0.286190003156662, "value_loss": 0.005232138186693191, "policy_loss": -0.0008981961494995971, "dist_entropy": 0.612137234210968, "actor_grad_norm": 0.06992251425981522, "critic_grad_norm": 0.19976013898849487, "ratio": 0.999816358089447, "entropy": 0.612137234210968, "incre_win_rate": 0.9361702127659575, "step": 2780}
{"time": 1767165084.5424879, "phase": "train", "update": 2781, "total_env_steps": 8899200, "episode_reward": 0.28042635321617126, "value_loss": 0.008507708460092545, "policy_loss": -0.001049433954135992, "dist_entropy": 0.612760317325592, "actor_grad_norm": 0.08553766459226608, "critic_grad_norm": 0.23558521270751953, "ratio": 0.9999917149543762, "entropy": 0.612760317325592, "incre_win_rate": 0.8913043478260869, "step": 2781}
{"time": 1767165094.20827, "phase": "eval", "update": 2781, "total_env_steps": 8899200, "eval_win_rate": 0.875, "eval_episode_reward": 19.26510761589404, "step": 2781}
{"time": 1767165098.4837422, "phase": "train", "update": 2782, "total_env_steps": 8902400, "episode_reward": 0.26417994499206543, "value_loss": 0.011090412549674512, "policy_loss": -0.001252248445487325, "dist_entropy": 0.6295568823814393, "actor_grad_norm": 0.08349686861038208, "critic_grad_norm": 0.21074126660823822, "ratio": 0.9999563097953796, "entropy": 0.6295568823814393, "incre_win_rate": 0.7674418604651163, "step": 2782}
{"time": 1767165102.8624766, "phase": "train", "update": 2783, "total_env_steps": 8905600, "episode_reward": 0.28281405568122864, "value_loss": 0.008697077073156834, "policy_loss": -0.0008621457589850223, "dist_entropy": 0.6018753767013549, "actor_grad_norm": 0.07533741742372513, "critic_grad_norm": 0.04727135971188545, "ratio": 0.9999926686286926, "entropy": 0.6018753767013549, "incre_win_rate": 0.8571428571428571, "step": 2783}
{"time": 1767165107.1701343, "phase": "train", "update": 2784, "total_env_steps": 8908800, "episode_reward": 0.2822635769844055, "value_loss": 0.006732822768390179, "policy_loss": -0.0010962033305375485, "dist_entropy": 0.5945148468017578, "actor_grad_norm": 0.08896870911121368, "critic_grad_norm": 0.08941536396741867, "ratio": 0.9999799728393555, "entropy": 0.5945148468017578, "incre_win_rate": 0.9333333333333333, "step": 2784}
{"time": 1767165111.460568, "phase": "train", "update": 2785, "total_env_steps": 8912000, "episode_reward": 0.28219112753868103, "value_loss": 0.0052613201551139355, "policy_loss": -0.001214110107406441, "dist_entropy": 0.6009954810142517, "actor_grad_norm": 0.09037380665540695, "critic_grad_norm": 0.07034530490636826, "ratio": 1.000313639640808, "entropy": 0.6009954810142517, "incre_win_rate": 0.8913043478260869, "step": 2785}
{"time": 1767165115.744157, "phase": "train", "update": 2786, "total_env_steps": 8915200, "episode_reward": 0.27308154106140137, "value_loss": 0.005161524191498757, "policy_loss": -0.001611227382445346, "dist_entropy": 0.6026120662689209, "actor_grad_norm": 0.08099614828824997, "critic_grad_norm": 0.06979115307331085, "ratio": 1.0003843307495117, "entropy": 0.6026120662689209, "incre_win_rate": 0.9111111111111111, "step": 2786}
{"time": 1767165120.0064282, "phase": "train", "update": 2787, "total_env_steps": 8918400, "episode_reward": 0.25783011317253113, "value_loss": 0.010819366760551929, "policy_loss": -0.0011151370828727635, "dist_entropy": 0.6080456018447876, "actor_grad_norm": 0.08283433318138123, "critic_grad_norm": 0.23007142543792725, "ratio": 0.999816358089447, "entropy": 0.6080456018447876, "incre_win_rate": 0.7441860465116279, "step": 2787}
{"time": 1767165124.3506937, "phase": "train", "update": 2788, "total_env_steps": 8921600, "episode_reward": 0.27968281507492065, "value_loss": 0.007692885491997004, "policy_loss": -0.0009646758041001125, "dist_entropy": 0.6317377924919129, "actor_grad_norm": 0.06867040693759918, "critic_grad_norm": 0.18264833092689514, "ratio": 0.9998416304588318, "entropy": 0.6317377924919129, "incre_win_rate": 0.8695652173913043, "step": 2788}
{"time": 1767165128.6861246, "phase": "train", "update": 2789, "total_env_steps": 8924800, "episode_reward": 0.2700243294239044, "value_loss": 0.011208819411695003, "policy_loss": -0.0024398195501589724, "dist_entropy": 0.6140616774559021, "actor_grad_norm": 0.09804072231054306, "critic_grad_norm": 0.1612665057182312, "ratio": 0.9999220967292786, "entropy": 0.6140616774559021, "incre_win_rate": 0.851063829787234, "step": 2789}
{"time": 1767165133.0942454, "phase": "train", "update": 2790, "total_env_steps": 8928000, "episode_reward": 0.2870183289051056, "value_loss": 0.009145433828234673, "policy_loss": -0.001044152037754742, "dist_entropy": 0.6214357495307923, "actor_grad_norm": 0.08605962991714478, "critic_grad_norm": 0.1295408308506012, "ratio": 1.0001577138900757, "entropy": 0.6214357495307923, "incre_win_rate": 0.875, "step": 2790}
{"time": 1767165137.4372451, "phase": "train", "update": 2791, "total_env_steps": 8931200, "episode_reward": 0.28182119131088257, "value_loss": 0.008939061872661113, "policy_loss": -0.0012939357850399347, "dist_entropy": 0.5986431837081909, "actor_grad_norm": 0.08159532397985458, "critic_grad_norm": 0.11022650450468063, "ratio": 0.9999389052391052, "entropy": 0.5986431837081909, "incre_win_rate": 0.8913043478260869, "step": 2791}
{"time": 1767165141.789577, "phase": "train", "update": 2792, "total_env_steps": 8934400, "episode_reward": 0.27691638469696045, "value_loss": 0.00734262764453888, "policy_loss": -0.0013948818437889087, "dist_entropy": 0.5948509335517883, "actor_grad_norm": 0.09485061466693878, "critic_grad_norm": 0.05398852378129959, "ratio": 0.9999237060546875, "entropy": 0.5948509335517883, "incre_win_rate": 0.8913043478260869, "step": 2792}
{"time": 1767165146.1479673, "phase": "train", "update": 2793, "total_env_steps": 8937600, "episode_reward": 0.2853606343269348, "value_loss": 0.005596440006047487, "policy_loss": -0.0010092618803199116, "dist_entropy": 0.6210677266120911, "actor_grad_norm": 0.08250129222869873, "critic_grad_norm": 0.054664213210344315, "ratio": 0.9996303915977478, "entropy": 0.6210677266120911, "incre_win_rate": 0.9347826086956522, "step": 2793}
{"time": 1767165150.458894, "phase": "train", "update": 2794, "total_env_steps": 8940800, "episode_reward": 0.28920066356658936, "value_loss": 0.004609576519578695, "policy_loss": -0.0010567757687946155, "dist_entropy": 0.6265598654747009, "actor_grad_norm": 0.08940967172384262, "critic_grad_norm": 0.052985191345214844, "ratio": 0.9997788667678833, "entropy": 0.6265598654747009, "incre_win_rate": 0.9361702127659575, "step": 2794}
{"time": 1767165154.87332, "phase": "train", "update": 2795, "total_env_steps": 8944000, "episode_reward": 0.29576575756073, "value_loss": 0.004163454938679934, "policy_loss": -0.0012228455176594543, "dist_entropy": 0.6144104599952698, "actor_grad_norm": 0.08311760425567627, "critic_grad_norm": 0.04175321385264397, "ratio": 0.9998435378074646, "entropy": 0.6144104599952698, "incre_win_rate": 0.9787234042553191, "step": 2795}
{"time": 1767165159.2595277, "phase": "train", "update": 2796, "total_env_steps": 8947200, "episode_reward": 0.29365065693855286, "value_loss": 0.0032137144822627305, "policy_loss": -0.000969296737847003, "dist_entropy": 0.6093189358711243, "actor_grad_norm": 0.07309357076883316, "critic_grad_norm": 0.0354028195142746, "ratio": 0.9999610185623169, "entropy": 0.6093189358711243, "incre_win_rate": 0.8979591836734694, "step": 2796}
{"time": 1767165163.6729383, "phase": "train", "update": 2797, "total_env_steps": 8950400, "episode_reward": 0.28997206687927246, "value_loss": 0.005539822299033404, "policy_loss": -0.0010674487788620013, "dist_entropy": 0.5990338921546936, "actor_grad_norm": 0.08174538612365723, "critic_grad_norm": 0.05835813283920288, "ratio": 0.9997760057449341, "entropy": 0.5990338921546936, "incre_win_rate": 0.9555555555555556, "step": 2797}
{"time": 1767165168.024664, "phase": "train", "update": 2798, "total_env_steps": 8953600, "episode_reward": 0.2761382460594177, "value_loss": 0.0064304953441023825, "policy_loss": -0.0008710458710780245, "dist_entropy": 0.5932268381118775, "actor_grad_norm": 0.0724867433309555, "critic_grad_norm": 0.0709606185555458, "ratio": 1.0001283884048462, "entropy": 0.5932268381118775, "incre_win_rate": 0.875, "step": 2798}
{"time": 1767165172.3838973, "phase": "train", "update": 2799, "total_env_steps": 8956800, "episode_reward": 0.2916308045387268, "value_loss": 0.005538823362439871, "policy_loss": -0.0014303759037005647, "dist_entropy": 0.6177407145500183, "actor_grad_norm": 0.0864335149526596, "critic_grad_norm": 0.06942953914403915, "ratio": 1.0000536441802979, "entropy": 0.6177407145500183, "incre_win_rate": 0.9361702127659575, "step": 2799}
{"time": 1767165176.7765467, "phase": "train", "update": 2800, "total_env_steps": 8960000, "episode_reward": 0.2900952100753784, "value_loss": 0.0038068550638854504, "policy_loss": -0.0011291665324636214, "dist_entropy": 0.6237564802169799, "actor_grad_norm": 0.08946464210748672, "critic_grad_norm": 0.02358071878552437, "ratio": 1.0000841617584229, "entropy": 0.6237564802169799, "incre_win_rate": 0.9574468085106383, "step": 2800}
{"time": 1767165181.1558888, "phase": "train", "update": 2801, "total_env_steps": 8963200, "episode_reward": 0.27618688344955444, "value_loss": 0.004604542162269354, "policy_loss": -0.0012133253297747614, "dist_entropy": 0.6179242730140686, "actor_grad_norm": 0.09571841359138489, "critic_grad_norm": 0.04454328119754791, "ratio": 1.0002988576889038, "entropy": 0.6179242730140686, "incre_win_rate": 0.9545454545454546, "step": 2801}
{"time": 1767165190.93282, "phase": "eval", "update": 2801, "total_env_steps": 8963200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.441225165562912, "step": 2801}
{"time": 1767165195.2406695, "phase": "train", "update": 2802, "total_env_steps": 8966400, "episode_reward": 0.2752721905708313, "value_loss": 0.00563727505505085, "policy_loss": -0.0010872112864944937, "dist_entropy": 0.6271434426307678, "actor_grad_norm": 0.07896561175584793, "critic_grad_norm": 0.03595384210348129, "ratio": 0.9997528195381165, "entropy": 0.6271434426307678, "incre_win_rate": 0.9333333333333333, "step": 2802}
{"time": 1767165199.6379604, "phase": "train", "update": 2803, "total_env_steps": 8969600, "episode_reward": 0.2947656512260437, "value_loss": 0.005583255179226398, "policy_loss": -0.0010248888422754732, "dist_entropy": 0.6281167507171631, "actor_grad_norm": 0.06525178998708725, "critic_grad_norm": 0.06364651024341583, "ratio": 1.0000691413879395, "entropy": 0.6281167507171631, "incre_win_rate": 0.94, "step": 2803}
{"time": 1767165204.048367, "phase": "train", "update": 2804, "total_env_steps": 8972800, "episode_reward": 0.28064417839050293, "value_loss": 0.006196472700685263, "policy_loss": -0.0015768740706619156, "dist_entropy": 0.6205586433410645, "actor_grad_norm": 0.08388793468475342, "critic_grad_norm": 0.040756817907094955, "ratio": 1.000080943107605, "entropy": 0.6205586433410645, "incre_win_rate": 0.9285714285714286, "step": 2804}
{"time": 1767165208.3778508, "phase": "train", "update": 2805, "total_env_steps": 8976000, "episode_reward": 0.2815578281879425, "value_loss": 0.006066951248794794, "policy_loss": -0.0011852345029325305, "dist_entropy": 0.6322796106338501, "actor_grad_norm": 0.07911819219589233, "critic_grad_norm": 0.05470671132206917, "ratio": 1.0004383325576782, "entropy": 0.6322796106338501, "incre_win_rate": 0.8775510204081632, "step": 2805}
{"time": 1767165212.7588344, "phase": "train", "update": 2806, "total_env_steps": 8979200, "episode_reward": 0.29123759269714355, "value_loss": 0.004531216621398926, "policy_loss": -0.0010514718792613564, "dist_entropy": 0.6430126070976258, "actor_grad_norm": 0.09281536191701889, "critic_grad_norm": 0.0677403062582016, "ratio": 1.000070333480835, "entropy": 0.6430126070976258, "incre_win_rate": 0.9777777777777777, "step": 2806}
{"time": 1767165217.105965, "phase": "train", "update": 2807, "total_env_steps": 8982400, "episode_reward": 0.2859809696674347, "value_loss": 0.0032831506803631784, "policy_loss": -0.0012023076525998987, "dist_entropy": 0.6362096190452575, "actor_grad_norm": 0.07414209097623825, "critic_grad_norm": 0.03654230758547783, "ratio": 1.0000447034835815, "entropy": 0.6362096190452575, "incre_win_rate": 0.9787234042553191, "step": 2807}
{"time": 1767165221.5000665, "phase": "train", "update": 2808, "total_env_steps": 8985600, "episode_reward": 0.27693554759025574, "value_loss": 0.006944587174803019, "policy_loss": -0.0012934559682236113, "dist_entropy": 0.6414062023162842, "actor_grad_norm": 0.07620856910943985, "critic_grad_norm": 0.07040409743785858, "ratio": 0.9999163746833801, "entropy": 0.6414062023162842, "incre_win_rate": 0.8913043478260869, "step": 2808}
{"time": 1767165225.8854303, "phase": "train", "update": 2809, "total_env_steps": 8988800, "episode_reward": 0.2768615484237671, "value_loss": 0.0072607914917171, "policy_loss": -0.0011761697202302911, "dist_entropy": 0.6417056560516358, "actor_grad_norm": 0.08000791817903519, "critic_grad_norm": 0.06555259227752686, "ratio": 1.0000176429748535, "entropy": 0.6417056560516358, "incre_win_rate": 0.851063829787234, "step": 2809}
{"time": 1767165230.2189763, "phase": "train", "update": 2810, "total_env_steps": 8992000, "episode_reward": 0.28461506962776184, "value_loss": 0.006535048503428698, "policy_loss": -0.0010792365147537452, "dist_entropy": 0.6635306000709533, "actor_grad_norm": 0.08402714878320694, "critic_grad_norm": 0.04579368233680725, "ratio": 0.9997836351394653, "entropy": 0.6635306000709533, "incre_win_rate": 0.9111111111111111, "step": 2810}
{"time": 1767165234.574395, "phase": "train", "update": 2811, "total_env_steps": 8995200, "episode_reward": 0.28382033109664917, "value_loss": 0.006857044994831085, "policy_loss": -0.0012399291000715351, "dist_entropy": 0.6523970007896424, "actor_grad_norm": 0.07326983660459518, "critic_grad_norm": 0.05174165964126587, "ratio": 1.0000410079956055, "entropy": 0.6523970007896424, "incre_win_rate": 0.8888888888888888, "step": 2811}
{"time": 1767165238.91469, "phase": "train", "update": 2812, "total_env_steps": 8998400, "episode_reward": 0.28374433517456055, "value_loss": 0.004256707895547151, "policy_loss": -0.0012662522360425755, "dist_entropy": 0.6482560157775878, "actor_grad_norm": 0.07651913166046143, "critic_grad_norm": 0.032937727868556976, "ratio": 1.0000226497650146, "entropy": 0.6482560157775878, "incre_win_rate": 0.9361702127659575, "step": 2812}
{"time": 1767165243.3542569, "phase": "train", "update": 2813, "total_env_steps": 9001600, "episode_reward": 0.2925631105899811, "value_loss": 0.004992761369794607, "policy_loss": -0.0013924379010688882, "dist_entropy": 0.6602119565010071, "actor_grad_norm": 0.09479357302188873, "critic_grad_norm": 0.05841812491416931, "ratio": 0.9997809529304504, "entropy": 0.6602119565010071, "incre_win_rate": 0.9591836734693877, "step": 2813}
{"time": 1767165247.6939764, "phase": "train", "update": 2814, "total_env_steps": 9004800, "episode_reward": 0.2829760015010834, "value_loss": 0.006039150338619947, "policy_loss": -0.0011120673840068207, "dist_entropy": 0.6374902606010437, "actor_grad_norm": 0.08430445939302444, "critic_grad_norm": 0.058578748255968094, "ratio": 1.000161051750183, "entropy": 0.6374902606010437, "incre_win_rate": 0.9130434782608695, "step": 2814}
{"time": 1767165251.9807441, "phase": "train", "update": 2815, "total_env_steps": 9008000, "episode_reward": 0.28693243861198425, "value_loss": 0.007014941889792681, "policy_loss": -0.0016182047443709991, "dist_entropy": 0.6320213317871094, "actor_grad_norm": 0.09113999456167221, "critic_grad_norm": 0.040027279406785965, "ratio": 0.9999815225601196, "entropy": 0.6320213317871094, "incre_win_rate": 0.9361702127659575, "step": 2815}
{"time": 1767165256.3306527, "phase": "train", "update": 2816, "total_env_steps": 9011200, "episode_reward": 0.2893233001232147, "value_loss": 0.00787428766489029, "policy_loss": -0.0012997738841999285, "dist_entropy": 0.6374226331710815, "actor_grad_norm": 0.08990103006362915, "critic_grad_norm": 0.0331035777926445, "ratio": 0.9997691512107849, "entropy": 0.6374226331710815, "incre_win_rate": 0.9361702127659575, "step": 2816}
{"time": 1767165260.6927009, "phase": "train", "update": 2817, "total_env_steps": 9014400, "episode_reward": 0.2756146490573883, "value_loss": 0.009624428674578666, "policy_loss": -0.001346899787148459, "dist_entropy": 0.6197166085243225, "actor_grad_norm": 0.07787664979696274, "critic_grad_norm": 0.0912846252322197, "ratio": 0.9997607469558716, "entropy": 0.6197166085243225, "incre_win_rate": 0.8666666666666667, "step": 2817}
{"time": 1767165265.0653718, "phase": "train", "update": 2818, "total_env_steps": 9017600, "episode_reward": 0.295188307762146, "value_loss": 0.002445447305217385, "policy_loss": -0.0010441836038367568, "dist_entropy": 0.6534481525421143, "actor_grad_norm": 0.08330422639846802, "critic_grad_norm": 0.13887503743171692, "ratio": 0.9996436238288879, "entropy": 0.6534481525421143, "incre_win_rate": 1.0, "step": 2818}
{"time": 1767165269.387273, "phase": "train", "update": 2819, "total_env_steps": 9020800, "episode_reward": 0.29114651679992676, "value_loss": 0.004680330585688353, "policy_loss": -0.001306164066224369, "dist_entropy": 0.6436067938804626, "actor_grad_norm": 0.072193443775177, "critic_grad_norm": 0.05207415297627449, "ratio": 0.9998614192008972, "entropy": 0.6436067938804626, "incre_win_rate": 0.9361702127659575, "step": 2819}
{"time": 1767165273.7791603, "phase": "train", "update": 2820, "total_env_steps": 9024000, "episode_reward": 0.2947765290737152, "value_loss": 0.005047270562499762, "policy_loss": -0.001209896594475879, "dist_entropy": 0.6588974118232727, "actor_grad_norm": 0.06631877273321152, "critic_grad_norm": 0.06772038340568542, "ratio": 1.0003141164779663, "entropy": 0.6588974118232727, "incre_win_rate": 0.9166666666666666, "step": 2820}
{"time": 1767165278.1490736, "phase": "train", "update": 2821, "total_env_steps": 9027200, "episode_reward": 0.28510865569114685, "value_loss": 0.006217369716614485, "policy_loss": -0.0015446875695673157, "dist_entropy": 0.6540589332580566, "actor_grad_norm": 0.08165235817432404, "critic_grad_norm": 0.10671835392713547, "ratio": 0.9995643496513367, "entropy": 0.6540589332580566, "incre_win_rate": 0.8958333333333334, "step": 2821}
{"time": 1767165287.3359697, "phase": "eval", "update": 2821, "total_env_steps": 9027200, "eval_win_rate": 1.0, "eval_episode_reward": 20.0, "step": 2821}
{"time": 1767165291.7165012, "phase": "train", "update": 2822, "total_env_steps": 9030400, "episode_reward": 0.2909964621067047, "value_loss": 0.0034405858721584083, "policy_loss": -0.0015229872385255304, "dist_entropy": 0.6632675766944885, "actor_grad_norm": 0.0792216882109642, "critic_grad_norm": 0.04264167323708534, "ratio": 1.0001840591430664, "entropy": 0.6632675766944885, "incre_win_rate": 0.9565217391304348, "step": 2822}
{"time": 1767165296.0833347, "phase": "train", "update": 2823, "total_env_steps": 9033600, "episode_reward": 0.2837386429309845, "value_loss": 0.006480193324387073, "policy_loss": -0.0014537464544465805, "dist_entropy": 0.636671495437622, "actor_grad_norm": 0.0744386613368988, "critic_grad_norm": 0.09922950714826584, "ratio": 0.9998839497566223, "entropy": 0.636671495437622, "incre_win_rate": 0.8936170212765957, "step": 2823}
{"time": 1767165300.5074368, "phase": "train", "update": 2824, "total_env_steps": 9036800, "episode_reward": 0.2857559323310852, "value_loss": 0.00804436132311821, "policy_loss": -0.0011065123484456762, "dist_entropy": 0.642431104183197, "actor_grad_norm": 0.07667481154203415, "critic_grad_norm": 0.0834159255027771, "ratio": 1.0000046491622925, "entropy": 0.642431104183197, "incre_win_rate": 0.9148936170212766, "step": 2824}
{"time": 1767165304.8723688, "phase": "train", "update": 2825, "total_env_steps": 9040000, "episode_reward": 0.2870746850967407, "value_loss": 0.0044402191415429115, "policy_loss": -0.0010749370571787153, "dist_entropy": 0.6352053046226501, "actor_grad_norm": 0.08159670978784561, "critic_grad_norm": 0.06766079366207123, "ratio": 1.0001823902130127, "entropy": 0.6352053046226501, "incre_win_rate": 0.9361702127659575, "step": 2825}
{"time": 1767165309.2313068, "phase": "train", "update": 2826, "total_env_steps": 9043200, "episode_reward": 0.29108548164367676, "value_loss": 0.005210912320762873, "policy_loss": -0.0013260958936245793, "dist_entropy": 0.6379546165466309, "actor_grad_norm": 0.07257384806871414, "critic_grad_norm": 0.04547697305679321, "ratio": 1.0000447034835815, "entropy": 0.6379546165466309, "incre_win_rate": 0.9333333333333333, "step": 2826}
{"time": 1767165313.5848827, "phase": "train", "update": 2827, "total_env_steps": 9046400, "episode_reward": 0.286523699760437, "value_loss": 0.0053745218552649025, "policy_loss": -0.001081440292916369, "dist_entropy": 0.6538902878761291, "actor_grad_norm": 0.07218024879693985, "critic_grad_norm": 0.0353408046066761, "ratio": 1.0002540349960327, "entropy": 0.6538902878761291, "incre_win_rate": 0.8979591836734694, "step": 2827}
{"time": 1767165317.8921664, "phase": "train", "update": 2828, "total_env_steps": 9049600, "episode_reward": 0.28766554594039917, "value_loss": 0.004171845782548189, "policy_loss": -0.001465597016282061, "dist_entropy": 0.6582306146621704, "actor_grad_norm": 0.08992068469524384, "critic_grad_norm": 0.08392596244812012, "ratio": 0.999528706073761, "entropy": 0.6582306146621704, "incre_win_rate": 1.0, "step": 2828}
{"time": 1767165322.1692321, "phase": "train", "update": 2829, "total_env_steps": 9052800, "episode_reward": 0.27914735674858093, "value_loss": 0.006301954481750726, "policy_loss": -0.0011337717030606598, "dist_entropy": 0.637149977684021, "actor_grad_norm": 0.09580173343420029, "critic_grad_norm": 0.08563989400863647, "ratio": 0.9999440312385559, "entropy": 0.637149977684021, "incre_win_rate": 0.8695652173913043, "step": 2829}
{"time": 1767165326.4222608, "phase": "train", "update": 2830, "total_env_steps": 9056000, "episode_reward": 0.28128209710121155, "value_loss": 0.006745805870741606, "policy_loss": -0.0012670818943249173, "dist_entropy": 0.6120953798294068, "actor_grad_norm": 0.10023891925811768, "critic_grad_norm": 0.05218719318509102, "ratio": 1.0001769065856934, "entropy": 0.6120953798294068, "incre_win_rate": 0.8723404255319149, "step": 2830}
{"time": 1767165330.6972983, "phase": "train", "update": 2831, "total_env_steps": 9059200, "episode_reward": 0.2927561104297638, "value_loss": 0.006570851337164641, "policy_loss": -0.0011668733653195317, "dist_entropy": 0.6317295670509339, "actor_grad_norm": 0.0919124111533165, "critic_grad_norm": 0.05275294929742813, "ratio": 1.0000649690628052, "entropy": 0.6317295670509339, "incre_win_rate": 0.9574468085106383, "step": 2831}
{"time": 1767165335.1082199, "phase": "train", "update": 2832, "total_env_steps": 9062400, "episode_reward": 0.2824011743068695, "value_loss": 0.005023098364472389, "policy_loss": -0.0011235505556374647, "dist_entropy": 0.6504098892211914, "actor_grad_norm": 0.08203291893005371, "critic_grad_norm": 0.04254326596856117, "ratio": 0.9999608397483826, "entropy": 0.6504098892211914, "incre_win_rate": 0.8695652173913043, "step": 2832}
{"time": 1767165339.470236, "phase": "train", "update": 2833, "total_env_steps": 9065600, "episode_reward": 0.2944287955760956, "value_loss": 0.002765968721359968, "policy_loss": -0.0012193628350374297, "dist_entropy": 0.6358138680458069, "actor_grad_norm": 0.07834046334028244, "critic_grad_norm": 0.04460050165653229, "ratio": 1.0001499652862549, "entropy": 0.6358138680458069, "incre_win_rate": 1.0, "step": 2833}
{"time": 1767165343.8195336, "phase": "train", "update": 2834, "total_env_steps": 9068800, "episode_reward": 0.28215906023979187, "value_loss": 0.008037618733942509, "policy_loss": -0.0014234990794804504, "dist_entropy": 0.6182942152023315, "actor_grad_norm": 0.07973245531320572, "critic_grad_norm": 0.16720786690711975, "ratio": 0.9999653100967407, "entropy": 0.6182942152023315, "incre_win_rate": 0.8958333333333334, "step": 2834}
{"time": 1767165348.1317017, "phase": "train", "update": 2835, "total_env_steps": 9072000, "episode_reward": 0.282077819108963, "value_loss": 0.005889689642935991, "policy_loss": -0.001737097011345412, "dist_entropy": 0.6228177547454834, "actor_grad_norm": 0.09089697897434235, "critic_grad_norm": 0.12364788353443146, "ratio": 0.9996480345726013, "entropy": 0.6228177547454834, "incre_win_rate": 0.8723404255319149, "step": 2835}
{"time": 1767165352.4869359, "phase": "train", "update": 2836, "total_env_steps": 9075200, "episode_reward": 0.28958454728126526, "value_loss": 0.003371088020503521, "policy_loss": -0.001053904623769686, "dist_entropy": 0.6225954055786133, "actor_grad_norm": 0.07845166325569153, "critic_grad_norm": 0.10058172047138214, "ratio": 0.9999219179153442, "entropy": 0.6225954055786133, "incre_win_rate": 0.9777777777777777, "step": 2836}
{"time": 1767165356.8295424, "phase": "train", "update": 2837, "total_env_steps": 9078400, "episode_reward": 0.2869603633880615, "value_loss": 0.003447336470708251, "policy_loss": -0.001484757741677356, "dist_entropy": 0.6187675714492797, "actor_grad_norm": 0.09982287138700485, "critic_grad_norm": 0.056327540427446365, "ratio": 0.9999211430549622, "entropy": 0.6187675714492797, "incre_win_rate": 0.9347826086956522, "step": 2837}
{"time": 1767165361.1788602, "phase": "train", "update": 2838, "total_env_steps": 9081600, "episode_reward": 0.28228843212127686, "value_loss": 0.006806990131735802, "policy_loss": -0.0011232546561469547, "dist_entropy": 0.6353590250015259, "actor_grad_norm": 0.09485702961683273, "critic_grad_norm": 0.10213716328144073, "ratio": 0.9998896718025208, "entropy": 0.6353590250015259, "incre_win_rate": 0.9130434782608695, "step": 2838}
{"time": 1767165365.572844, "phase": "train", "update": 2839, "total_env_steps": 9084800, "episode_reward": 0.28953227400779724, "value_loss": 0.00309199052862823, "policy_loss": -0.0009871233909921173, "dist_entropy": 0.6383668899536132, "actor_grad_norm": 0.08838541805744171, "critic_grad_norm": 0.052415501326322556, "ratio": 0.9998728036880493, "entropy": 0.6383668899536132, "incre_win_rate": 0.9387755102040817, "step": 2839}
{"time": 1767165369.9243238, "phase": "train", "update": 2840, "total_env_steps": 9088000, "episode_reward": 0.288483589887619, "value_loss": 0.005148716736584902, "policy_loss": -0.00104667231787845, "dist_entropy": 0.6563425421714782, "actor_grad_norm": 0.08353330194950104, "critic_grad_norm": 0.08734183013439178, "ratio": 0.9996654391288757, "entropy": 0.6563425421714782, "incre_win_rate": 0.9148936170212766, "step": 2840}
{"time": 1767165374.2793052, "phase": "train", "update": 2841, "total_env_steps": 9091200, "episode_reward": 0.2778678834438324, "value_loss": 0.005450188554823399, "policy_loss": -0.001424000924465929, "dist_entropy": 0.6658127903938293, "actor_grad_norm": 0.08018721640110016, "critic_grad_norm": 0.06406936049461365, "ratio": 1.0000159740447998, "entropy": 0.6658127903938293, "incre_win_rate": 0.9333333333333333, "step": 2841}
{"time": 1767165383.5108626, "phase": "eval", "update": 2841, "total_env_steps": 9091200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.602493791390728, "step": 2841}
{"time": 1767165387.8930354, "phase": "train", "update": 2842, "total_env_steps": 9094400, "episode_reward": 0.28652524948120117, "value_loss": 0.004473185259848833, "policy_loss": -0.0011383491073154062, "dist_entropy": 0.6807661175727844, "actor_grad_norm": 0.09371433407068253, "critic_grad_norm": 0.0521395169198513, "ratio": 1.00032639503479, "entropy": 0.6807661175727844, "incre_win_rate": 0.9347826086956522, "step": 2842}
{"time": 1767165392.273074, "phase": "train", "update": 2843, "total_env_steps": 9097600, "episode_reward": 0.29174256324768066, "value_loss": 0.003608624218031764, "policy_loss": -0.0015135694348344941, "dist_entropy": 0.7137506008148193, "actor_grad_norm": 0.11125924438238144, "critic_grad_norm": 0.0829099714756012, "ratio": 1.0000828504562378, "entropy": 0.7137506008148193, "incre_win_rate": 0.9787234042553191, "step": 2843}
{"time": 1767165396.6101449, "phase": "train", "update": 2844, "total_env_steps": 9100800, "episode_reward": 0.27412712574005127, "value_loss": 0.00877916757017374, "policy_loss": -0.0013176217061417362, "dist_entropy": 0.6772203803062439, "actor_grad_norm": 0.07917364686727524, "critic_grad_norm": 0.11973905563354492, "ratio": 1.0000505447387695, "entropy": 0.6772203803062439, "incre_win_rate": 0.8666666666666667, "step": 2844}
{"time": 1767165401.051349, "phase": "train", "update": 2845, "total_env_steps": 9104000, "episode_reward": 0.28863877058029175, "value_loss": 0.003184926137328148, "policy_loss": -0.0013753619895538805, "dist_entropy": 0.6950650811195374, "actor_grad_norm": 0.08420906960964203, "critic_grad_norm": 0.09970906376838684, "ratio": 1.0002681016921997, "entropy": 0.6950650811195374, "incre_win_rate": 0.9574468085106383, "step": 2845}
{"time": 1767165405.359701, "phase": "train", "update": 2846, "total_env_steps": 9107200, "episode_reward": 0.2695426046848297, "value_loss": 0.007172448467463255, "policy_loss": -0.001784971992015727, "dist_entropy": 0.6764702916145324, "actor_grad_norm": 0.08307202905416489, "critic_grad_norm": 0.09992635250091553, "ratio": 0.9999615550041199, "entropy": 0.6764702916145324, "incre_win_rate": 0.7954545454545454, "step": 2846}
{"time": 1767165409.7758489, "phase": "train", "update": 2847, "total_env_steps": 9110400, "episode_reward": 0.28720253705978394, "value_loss": 0.008089476823806762, "policy_loss": -0.0016204562736675144, "dist_entropy": 0.6704208731651307, "actor_grad_norm": 0.09042046964168549, "critic_grad_norm": 0.0582088828086853, "ratio": 1.0000911951065063, "entropy": 0.6704208731651307, "incre_win_rate": 0.8936170212765957, "step": 2847}
{"time": 1767165414.143972, "phase": "train", "update": 2848, "total_env_steps": 9113600, "episode_reward": 0.28092509508132935, "value_loss": 0.007255225256085396, "policy_loss": -0.0016094230371074048, "dist_entropy": 0.6618831038475037, "actor_grad_norm": 0.10108890384435654, "critic_grad_norm": 0.04676492139697075, "ratio": 1.0005000829696655, "entropy": 0.6618831038475037, "incre_win_rate": 0.8333333333333334, "step": 2848}
{"time": 1767165418.4721017, "phase": "train", "update": 2849, "total_env_steps": 9116800, "episode_reward": 0.27460575103759766, "value_loss": 0.011475430987775325, "policy_loss": -0.0009953591596751465, "dist_entropy": 0.6455191493034362, "actor_grad_norm": 0.092290960252285, "critic_grad_norm": 0.10612335056066513, "ratio": 0.9998998045921326, "entropy": 0.6455191493034362, "incre_win_rate": 0.75, "step": 2849}
{"time": 1767165422.8560662, "phase": "train", "update": 2850, "total_env_steps": 9120000, "episode_reward": 0.2838720977306366, "value_loss": 0.009315492026507855, "policy_loss": -0.001576294983826898, "dist_entropy": 0.6598843932151794, "actor_grad_norm": 0.1129642128944397, "critic_grad_norm": 0.06388195604085922, "ratio": 1.0001449584960938, "entropy": 0.6598843932151794, "incre_win_rate": 0.8297872340425532, "step": 2850}
{"time": 1767165427.214126, "phase": "train", "update": 2851, "total_env_steps": 9123200, "episode_reward": 0.2806224524974823, "value_loss": 0.01089719757437706, "policy_loss": -0.0018234345573532097, "dist_entropy": 0.6708773016929627, "actor_grad_norm": 0.12188944965600967, "critic_grad_norm": 0.0486457459628582, "ratio": 0.9996981024742126, "entropy": 0.6708773016929627, "incre_win_rate": 0.8723404255319149, "step": 2851}
{"time": 1767165431.6246002, "phase": "train", "update": 2852, "total_env_steps": 9126400, "episode_reward": 0.285428911447525, "value_loss": 0.007639543991535902, "policy_loss": -0.0013742012315425712, "dist_entropy": 0.6515905022621155, "actor_grad_norm": 0.13847358524799347, "critic_grad_norm": 0.13527584075927734, "ratio": 0.9997367858886719, "entropy": 0.6515905022621155, "incre_win_rate": 0.8936170212765957, "step": 2852}
{"time": 1767165436.0332086, "phase": "train", "update": 2853, "total_env_steps": 9129600, "episode_reward": 0.29057949781417847, "value_loss": 0.006266933865845203, "policy_loss": -0.0011558767511573365, "dist_entropy": 0.6514335870742798, "actor_grad_norm": 0.07435079663991928, "critic_grad_norm": 0.07536421716213226, "ratio": 0.9999410510063171, "entropy": 0.6514335870742798, "incre_win_rate": 0.9183673469387755, "step": 2853}
{"time": 1767165440.3914464, "phase": "train", "update": 2854, "total_env_steps": 9132800, "episode_reward": 0.2844381034374237, "value_loss": 0.008704479224979878, "policy_loss": -0.0016469589381721051, "dist_entropy": 0.6432905435562134, "actor_grad_norm": 0.09036338329315186, "critic_grad_norm": 0.11278245598077774, "ratio": 0.9999706149101257, "entropy": 0.6432905435562134, "incre_win_rate": 0.7608695652173914, "step": 2854}
{"time": 1767165444.7633727, "phase": "train", "update": 2855, "total_env_steps": 9136000, "episode_reward": 0.291888952255249, "value_loss": 0.006284670345485211, "policy_loss": -0.0014616754952328393, "dist_entropy": 0.6183368563652039, "actor_grad_norm": 0.08682522922754288, "critic_grad_norm": 0.15481410920619965, "ratio": 0.99994957447052, "entropy": 0.6183368563652039, "incre_win_rate": 0.9583333333333334, "step": 2855}
{"time": 1767165449.0921133, "phase": "train", "update": 2856, "total_env_steps": 9139200, "episode_reward": 0.2862319052219391, "value_loss": 0.005525695253163576, "policy_loss": -0.0015735912868478862, "dist_entropy": 0.621992003917694, "actor_grad_norm": 0.11741659790277481, "critic_grad_norm": 0.11920022964477539, "ratio": 1.0001300573349, "entropy": 0.621992003917694, "incre_win_rate": 0.9166666666666666, "step": 2856}
{"time": 1767165453.460649, "phase": "train", "update": 2857, "total_env_steps": 9142400, "episode_reward": 0.29593130946159363, "value_loss": 0.0027661468368023632, "policy_loss": -0.0014690513792109173, "dist_entropy": 0.6048344254493714, "actor_grad_norm": 0.08964290469884872, "critic_grad_norm": 0.08973613381385803, "ratio": 0.9998181462287903, "entropy": 0.6048344254493714, "incre_win_rate": 0.9791666666666666, "step": 2857}
{"time": 1767165457.8818552, "phase": "train", "update": 2858, "total_env_steps": 9145600, "episode_reward": 0.29442206025123596, "value_loss": 0.00767744779586792, "policy_loss": -0.001518775133447292, "dist_entropy": 0.6025116205215454, "actor_grad_norm": 0.0894559994339943, "critic_grad_norm": 0.15067332983016968, "ratio": 0.9999096989631653, "entropy": 0.6025116205215454, "incre_win_rate": 0.875, "step": 2858}
{"time": 1767165462.275199, "phase": "train", "update": 2859, "total_env_steps": 9148800, "episode_reward": 0.28553032875061035, "value_loss": 0.008896256238222123, "policy_loss": -0.0011477830460592032, "dist_entropy": 0.571813440322876, "actor_grad_norm": 0.11896967142820358, "critic_grad_norm": 0.10586943477392197, "ratio": 0.999639630317688, "entropy": 0.571813440322876, "incre_win_rate": 0.8260869565217391, "step": 2859}
{"time": 1767165466.7042341, "phase": "train", "update": 2860, "total_env_steps": 9152000, "episode_reward": 0.2873220145702362, "value_loss": 0.0068078962154686454, "policy_loss": -0.001278086197149264, "dist_entropy": 0.5840568900108337, "actor_grad_norm": 0.08281946182250977, "critic_grad_norm": 0.048592425882816315, "ratio": 0.9996433258056641, "entropy": 0.5840568900108337, "incre_win_rate": 0.9148936170212766, "step": 2860}
{"time": 1767165471.0341225, "phase": "train", "update": 2861, "total_env_steps": 9155200, "episode_reward": 0.28124740719795227, "value_loss": 0.007855642959475518, "policy_loss": -0.0011145628490631053, "dist_entropy": 0.5637008428573609, "actor_grad_norm": 0.08113972842693329, "critic_grad_norm": 0.04578850418329239, "ratio": 0.9998895525932312, "entropy": 0.5637008428573609, "incre_win_rate": 0.8541666666666666, "step": 2861}
{"time": 1767165480.2897785, "phase": "eval", "update": 2861, "total_env_steps": 9155200, "eval_win_rate": 1.0, "eval_episode_reward": 20.001655629139073, "step": 2861}
{"time": 1767165484.6687515, "phase": "train", "update": 2862, "total_env_steps": 9158400, "episode_reward": 0.2880489230155945, "value_loss": 0.007183548528701067, "policy_loss": -0.001121051456372868, "dist_entropy": 0.5968001842498779, "actor_grad_norm": 0.10995495319366455, "critic_grad_norm": 0.09985020011663437, "ratio": 1.0000299215316772, "entropy": 0.5968001842498779, "incre_win_rate": 0.8695652173913043, "step": 2862}
{"time": 1767165489.0430157, "phase": "train", "update": 2863, "total_env_steps": 9161600, "episode_reward": 0.2799984812736511, "value_loss": 0.010040399618446827, "policy_loss": -0.0012392081118194898, "dist_entropy": 0.5877429127693177, "actor_grad_norm": 0.08980025351047516, "critic_grad_norm": 0.12993884086608887, "ratio": 0.9997132420539856, "entropy": 0.5877429127693177, "incre_win_rate": 0.8297872340425532, "step": 2863}
{"time": 1767165493.4735174, "phase": "train", "update": 2864, "total_env_steps": 9164800, "episode_reward": 0.2909354567527771, "value_loss": 0.006925105955451727, "policy_loss": -0.0009302144765015897, "dist_entropy": 0.5773806810379029, "actor_grad_norm": 0.08361488580703735, "critic_grad_norm": 0.06415753066539764, "ratio": 0.9997170567512512, "entropy": 0.5773806810379029, "incre_win_rate": 0.9148936170212766, "step": 2864}
{"time": 1767165497.8750007, "phase": "train", "update": 2865, "total_env_steps": 9168000, "episode_reward": 0.28724855184555054, "value_loss": 0.0062766183167696, "policy_loss": -0.0013627464790634037, "dist_entropy": 0.5908644318580627, "actor_grad_norm": 0.10369715839624405, "critic_grad_norm": 0.08162886649370193, "ratio": 0.9997082948684692, "entropy": 0.5908644318580627, "incre_win_rate": 0.8979591836734694, "step": 2865}
{"time": 1767165502.236672, "phase": "train", "update": 2866, "total_env_steps": 9171200, "episode_reward": 0.2865893840789795, "value_loss": 0.01125103048980236, "policy_loss": -0.001339313635021, "dist_entropy": 0.5735965967178345, "actor_grad_norm": 0.10558440536260605, "critic_grad_norm": 0.08560305088758469, "ratio": 1.0001201629638672, "entropy": 0.5735965967178345, "incre_win_rate": 0.8936170212765957, "step": 2866}
{"time": 1767165506.5758414, "phase": "train", "update": 2867, "total_env_steps": 9174400, "episode_reward": 0.28388503193855286, "value_loss": 0.008506136946380138, "policy_loss": -0.0011835335816954284, "dist_entropy": 0.6004000425338745, "actor_grad_norm": 0.11961200088262558, "critic_grad_norm": 0.1179015040397644, "ratio": 0.9999090433120728, "entropy": 0.6004000425338745, "incre_win_rate": 0.8478260869565217, "step": 2867}
{"time": 1767165510.9461222, "phase": "train", "update": 2868, "total_env_steps": 9177600, "episode_reward": 0.29561156034469604, "value_loss": 0.004710809793323278, "policy_loss": -0.001087171977317425, "dist_entropy": 0.5985270261764526, "actor_grad_norm": 0.10786543041467667, "critic_grad_norm": 0.118191659450531, "ratio": 0.9999052286148071, "entropy": 0.5985270261764526, "incre_win_rate": 0.9591836734693877, "step": 2868}
{"time": 1767165515.3864136, "phase": "train", "update": 2869, "total_env_steps": 9180800, "episode_reward": 0.2962251603603363, "value_loss": 0.004113272437825799, "policy_loss": -0.000744181628817131, "dist_entropy": 0.6188115358352662, "actor_grad_norm": 0.06216263771057129, "critic_grad_norm": 0.08705898374319077, "ratio": 0.9999786615371704, "entropy": 0.6188115358352662, "incre_win_rate": 0.9787234042553191, "step": 2869}
{"time": 1767165519.7702534, "phase": "train", "update": 2870, "total_env_steps": 9184000, "episode_reward": 0.2872816324234009, "value_loss": 0.004915893636643886, "policy_loss": -0.00123112913984329, "dist_entropy": 0.6118038654327392, "actor_grad_norm": 0.0689777061343193, "critic_grad_norm": 0.1079522892832756, "ratio": 1.0001442432403564, "entropy": 0.6118038654327392, "incre_win_rate": 0.9148936170212766, "step": 2870}
{"time": 1767165524.1684663, "phase": "train", "update": 2871, "total_env_steps": 9187200, "episode_reward": 0.2874855101108551, "value_loss": 0.0033688174095004796, "policy_loss": -0.0011221242973306288, "dist_entropy": 0.6221614718437195, "actor_grad_norm": 0.06881432980298996, "critic_grad_norm": 0.04119473695755005, "ratio": 0.9998874664306641, "entropy": 0.6221614718437195, "incre_win_rate": 0.9583333333333334, "step": 2871}
{"time": 1767165528.5313718, "phase": "train", "update": 2872, "total_env_steps": 9190400, "episode_reward": 0.28762829303741455, "value_loss": 0.006024274602532386, "policy_loss": -0.0013607972821930048, "dist_entropy": 0.6214119553565979, "actor_grad_norm": 0.10595395416021347, "critic_grad_norm": 0.05877212435007095, "ratio": 1.0003594160079956, "entropy": 0.6214119553565979, "incre_win_rate": 0.9130434782608695, "step": 2872}
{"time": 1767165532.932227, "phase": "train", "update": 2873, "total_env_steps": 9193600, "episode_reward": 0.296973317861557, "value_loss": 0.00441548116505146, "policy_loss": -0.0012087638326828908, "dist_entropy": 0.6358981966972351, "actor_grad_norm": 0.0831439420580864, "critic_grad_norm": 0.05810045078396797, "ratio": 0.9996055960655212, "entropy": 0.6358981966972351, "incre_win_rate": 0.9574468085106383, "step": 2873}
{"time": 1767165537.2999291, "phase": "train", "update": 2874, "total_env_steps": 9196800, "episode_reward": 0.2880867123603821, "value_loss": 0.007698760833591223, "policy_loss": -0.0013904449668046936, "dist_entropy": 0.6341190576553345, "actor_grad_norm": 0.08418156951665878, "critic_grad_norm": 0.09614742547273636, "ratio": 0.9999907612800598, "entropy": 0.6341190576553345, "incre_win_rate": 0.8936170212765957, "step": 2874}
{"time": 1767165541.6430922, "phase": "train", "update": 2875, "total_env_steps": 9200000, "episode_reward": 0.2750227749347687, "value_loss": 0.006711178738623857, "policy_loss": -0.0010740551208776594, "dist_entropy": 0.6023712635040284, "actor_grad_norm": 0.06755144894123077, "critic_grad_norm": 0.0525997169315815, "ratio": 0.9998367428779602, "entropy": 0.6023712635040284, "incre_win_rate": 0.851063829787234, "step": 2875}
{"time": 1767165546.3794, "phase": "train", "update": 2876, "total_env_steps": 9203200, "episode_reward": 0.28368014097213745, "value_loss": 0.00536328237503767, "policy_loss": -0.0011817031923044396, "dist_entropy": 0.6295574426651, "actor_grad_norm": 0.1043453961610794, "critic_grad_norm": 0.03133952245116234, "ratio": 1.000285029411316, "entropy": 0.6295574426651, "incre_win_rate": 0.8936170212765957, "step": 2876}
{"time": 1767165550.8912473, "phase": "train", "update": 2877, "total_env_steps": 9206400, "episode_reward": 0.28794601559638977, "value_loss": 0.005693765077739954, "policy_loss": -0.0009110921557454077, "dist_entropy": 0.6367244124412537, "actor_grad_norm": 0.08302231132984161, "critic_grad_norm": 0.030502334237098694, "ratio": 0.9999699592590332, "entropy": 0.6367244124412537, "incre_win_rate": 0.8936170212765957, "step": 2877}
{"time": 1767165555.2941387, "phase": "train", "update": 2878, "total_env_steps": 9209600, "episode_reward": 0.29236966371536255, "value_loss": 0.00643695704638958, "policy_loss": -0.001184730577741533, "dist_entropy": 0.6356899380683899, "actor_grad_norm": 0.0795590803027153, "critic_grad_norm": 0.07368730008602142, "ratio": 1.0000410079956055, "entropy": 0.6356899380683899, "incre_win_rate": 0.9361702127659575, "step": 2878}
{"time": 1767165559.6554198, "phase": "train", "update": 2879, "total_env_steps": 9212800, "episode_reward": 0.2787567377090454, "value_loss": 0.006334438174962998, "policy_loss": -0.001658676373731538, "dist_entropy": 0.6102962255477905, "actor_grad_norm": 0.10006501525640488, "critic_grad_norm": 0.05427103862166405, "ratio": 0.9999686479568481, "entropy": 0.6102962255477905, "incre_win_rate": 0.8666666666666667, "step": 2879}
{"time": 1767165564.0494394, "phase": "train", "update": 2880, "total_env_steps": 9216000, "episode_reward": 0.29093852639198303, "value_loss": 0.0025869492907077073, "policy_loss": -0.0013151723476376275, "dist_entropy": 0.6601547956466675, "actor_grad_norm": 0.08054637163877487, "critic_grad_norm": 0.07292516529560089, "ratio": 0.9998435378074646, "entropy": 0.6601547956466675, "incre_win_rate": 0.9787234042553191, "step": 2880}
{"time": 1767165568.4200287, "phase": "train", "update": 2881, "total_env_steps": 9219200, "episode_reward": 0.2865650951862335, "value_loss": 0.00489177843555808, "policy_loss": -0.0009439797485043755, "dist_entropy": 0.6453168869018555, "actor_grad_norm": 0.07351138442754745, "critic_grad_norm": 0.06666357815265656, "ratio": 0.999885082244873, "entropy": 0.6453168869018555, "incre_win_rate": 0.9375, "step": 2881}
{"time": 1767165577.4621675, "phase": "eval", "update": 2881, "total_env_steps": 9219200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.591887417218544, "step": 2881}
{"time": 1767165581.8572812, "phase": "train", "update": 2882, "total_env_steps": 9222400, "episode_reward": 0.2873794436454773, "value_loss": 0.007769382838159799, "policy_loss": -0.0016857706223774472, "dist_entropy": 0.6567302465438842, "actor_grad_norm": 0.08124997466802597, "critic_grad_norm": 0.07949816435575485, "ratio": 0.9999666213989258, "entropy": 0.6567302465438842, "incre_win_rate": 0.8541666666666666, "step": 2882}
{"time": 1767165586.2744637, "phase": "train", "update": 2883, "total_env_steps": 9225600, "episode_reward": 0.2839165925979614, "value_loss": 0.006316035054624081, "policy_loss": -0.001209515631630609, "dist_entropy": 0.6266661167144776, "actor_grad_norm": 0.08468972891569138, "critic_grad_norm": 0.03552288934588432, "ratio": 0.999865710735321, "entropy": 0.6266661167144776, "incre_win_rate": 0.9130434782608695, "step": 2883}
{"time": 1767165590.6568148, "phase": "train", "update": 2884, "total_env_steps": 9228800, "episode_reward": 0.2881736159324646, "value_loss": 0.007600524183362723, "policy_loss": -0.0008842400223642244, "dist_entropy": 0.6209755301475525, "actor_grad_norm": 0.08567690849304199, "critic_grad_norm": 0.05413895845413208, "ratio": 0.9999767541885376, "entropy": 0.6209755301475525, "incre_win_rate": 0.9148936170212766, "step": 2884}
{"time": 1767165595.0320325, "phase": "train", "update": 2885, "total_env_steps": 9232000, "episode_reward": 0.28226199746131897, "value_loss": 0.007875322923064232, "policy_loss": -0.0009577791673535784, "dist_entropy": 0.6047548532485962, "actor_grad_norm": 0.07740940898656845, "critic_grad_norm": 0.05551416426897049, "ratio": 0.9997609257698059, "entropy": 0.6047548532485962, "incre_win_rate": 0.8936170212765957, "step": 2885}
{"time": 1767165599.3677583, "phase": "train", "update": 2886, "total_env_steps": 9235200, "episode_reward": 0.28363460302352905, "value_loss": 0.005192908551543951, "policy_loss": -0.0014585992738741283, "dist_entropy": 0.6003395557403565, "actor_grad_norm": 0.12348722666501999, "critic_grad_norm": 0.04287918284535408, "ratio": 0.999837338924408, "entropy": 0.6003395557403565, "incre_win_rate": 0.9555555555555556, "step": 2886}
{"time": 1767165603.7609239, "phase": "train", "update": 2887, "total_env_steps": 9238400, "episode_reward": 0.28980910778045654, "value_loss": 0.005374349746853113, "policy_loss": -0.0014406254054911472, "dist_entropy": 0.6137428045272827, "actor_grad_norm": 0.09318030625581741, "critic_grad_norm": 0.04070815071463585, "ratio": 0.9997972846031189, "entropy": 0.6137428045272827, "incre_win_rate": 0.8958333333333334, "step": 2887}
{"time": 1767165608.1265125, "phase": "train", "update": 2888, "total_env_steps": 9241600, "episode_reward": 0.28670063614845276, "value_loss": 0.003948055161163211, "policy_loss": -0.0010728762729861785, "dist_entropy": 0.62985178232193, "actor_grad_norm": 0.07070696353912354, "critic_grad_norm": 0.02289050817489624, "ratio": 1.0000526905059814, "entropy": 0.62985178232193, "incre_win_rate": 0.9347826086956522, "step": 2888}
{"time": 1767165612.514175, "phase": "train", "update": 2889, "total_env_steps": 9244800, "episode_reward": 0.28748759627342224, "value_loss": 0.003935553412884474, "policy_loss": -0.0011030655668498924, "dist_entropy": 0.6422767400741577, "actor_grad_norm": 0.07253458350896835, "critic_grad_norm": 0.04335842654109001, "ratio": 0.9997367262840271, "entropy": 0.6422767400741577, "incre_win_rate": 0.9787234042553191, "step": 2889}
{"time": 1767165616.9064956, "phase": "train", "update": 2890, "total_env_steps": 9248000, "episode_reward": 0.2835880517959595, "value_loss": 0.005027896258980036, "policy_loss": -0.0013226209779602983, "dist_entropy": 0.6199671864509583, "actor_grad_norm": 0.08219683170318604, "critic_grad_norm": 0.0575806088745594, "ratio": 0.9999074339866638, "entropy": 0.6199671864509583, "incre_win_rate": 0.9130434782608695, "step": 2890}
{"time": 1767165621.257774, "phase": "train", "update": 2891, "total_env_steps": 9251200, "episode_reward": 0.28990480303764343, "value_loss": 0.005170428939163685, "policy_loss": -0.001782227667001024, "dist_entropy": 0.6311562180519104, "actor_grad_norm": 0.09842988103628159, "critic_grad_norm": 0.07692494243383408, "ratio": 0.9998445510864258, "entropy": 0.6311562180519104, "incre_win_rate": 0.9183673469387755, "step": 2891}
{"time": 1767165625.6125474, "phase": "train", "update": 2892, "total_env_steps": 9254400, "episode_reward": 0.27843955159187317, "value_loss": 0.006678200326859951, "policy_loss": -0.0016781433734383456, "dist_entropy": 0.6159581303596496, "actor_grad_norm": 0.08821902424097061, "critic_grad_norm": 0.10678213834762573, "ratio": 0.9997861981391907, "entropy": 0.6159581303596496, "incre_win_rate": 0.8837209302325582, "step": 2892}
{"time": 1767165629.8954825, "phase": "train", "update": 2893, "total_env_steps": 9257600, "episode_reward": 0.2722635567188263, "value_loss": 0.009273158758878708, "policy_loss": -0.001365351304467488, "dist_entropy": 0.615170705318451, "actor_grad_norm": 0.08083004504442215, "critic_grad_norm": 0.10908464342355728, "ratio": 0.9997310042381287, "entropy": 0.615170705318451, "incre_win_rate": 0.851063829787234, "step": 2893}
{"time": 1767165634.207932, "phase": "train", "update": 2894, "total_env_steps": 9260800, "episode_reward": 0.289442241191864, "value_loss": 0.006426038220524788, "policy_loss": -0.0015763547428997882, "dist_entropy": 0.6150356888771057, "actor_grad_norm": 0.09072832018136978, "critic_grad_norm": 0.07591171562671661, "ratio": 0.9999551773071289, "entropy": 0.6150356888771057, "incre_win_rate": 0.9148936170212766, "step": 2894}
{"time": 1767165638.5419455, "phase": "train", "update": 2895, "total_env_steps": 9264000, "episode_reward": 0.28233030438423157, "value_loss": 0.0045573792420327665, "policy_loss": -0.0015855434192033613, "dist_entropy": 0.6179030895233154, "actor_grad_norm": 0.09280013293027878, "critic_grad_norm": 0.05144546180963516, "ratio": 0.999786376953125, "entropy": 0.6179030895233154, "incre_win_rate": 0.9148936170212766, "step": 2895}
{"time": 1767165642.8612745, "phase": "train", "update": 2896, "total_env_steps": 9267200, "episode_reward": 0.2855096161365509, "value_loss": 0.005996737815439701, "policy_loss": -0.001489952570982922, "dist_entropy": 0.6226822733879089, "actor_grad_norm": 0.09065480530261993, "critic_grad_norm": 0.04601062461733818, "ratio": 1.0000102519989014, "entropy": 0.6226822733879089, "incre_win_rate": 0.9318181818181818, "step": 2896}
{"time": 1767165647.2150683, "phase": "train", "update": 2897, "total_env_steps": 9270400, "episode_reward": 0.2819065451622009, "value_loss": 0.006949939858168363, "policy_loss": -0.0012752083723626129, "dist_entropy": 0.5995173454284668, "actor_grad_norm": 0.08522407710552216, "critic_grad_norm": 0.06831029802560806, "ratio": 0.999164879322052, "entropy": 0.5995173454284668, "incre_win_rate": 0.9148936170212766, "step": 2897}
{"time": 1767165651.507893, "phase": "train", "update": 2898, "total_env_steps": 9273600, "episode_reward": 0.2787996828556061, "value_loss": 0.005533802136778831, "policy_loss": -0.0013042627031401466, "dist_entropy": 0.6284815311431885, "actor_grad_norm": 0.07377749681472778, "critic_grad_norm": 0.04002327844500542, "ratio": 1.0000289678573608, "entropy": 0.6284815311431885, "incre_win_rate": 0.8888888888888888, "step": 2898}
{"time": 1767165655.8198879, "phase": "train", "update": 2899, "total_env_steps": 9276800, "episode_reward": 0.2833288609981537, "value_loss": 0.0060067674145102504, "policy_loss": -0.001183358041548388, "dist_entropy": 0.6287645697593689, "actor_grad_norm": 0.07038549333810806, "critic_grad_norm": 0.07118238508701324, "ratio": 0.9999150633811951, "entropy": 0.6287645697593689, "incre_win_rate": 0.9361702127659575, "step": 2899}
{"time": 1767165660.1219609, "phase": "train", "update": 2900, "total_env_steps": 9280000, "episode_reward": 0.27889227867126465, "value_loss": 0.0043624522164464, "policy_loss": -0.0011636726742937143, "dist_entropy": 0.6195746898651123, "actor_grad_norm": 0.08269663900136948, "critic_grad_norm": 0.03651313856244087, "ratio": 0.9999686479568481, "entropy": 0.6195746898651123, "incre_win_rate": 0.9347826086956522, "step": 2900}
{"time": 1767165664.4946475, "phase": "train", "update": 2901, "total_env_steps": 9283200, "episode_reward": 0.2918087840080261, "value_loss": 0.003021388594061136, "policy_loss": -0.0012833198046706684, "dist_entropy": 0.6515235662460327, "actor_grad_norm": 0.08340450376272202, "critic_grad_norm": 0.02666592039167881, "ratio": 1.0000265836715698, "entropy": 0.6515235662460327, "incre_win_rate": 0.9583333333333334, "step": 2901}
{"time": 1767165673.7231524, "phase": "eval", "update": 2901, "total_env_steps": 9283200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.637262003311257, "step": 2901}
{"time": 1767165678.0748842, "phase": "train", "update": 2902, "total_env_steps": 9286400, "episode_reward": 0.28403714299201965, "value_loss": 0.004149648640304804, "policy_loss": -0.001042895117159226, "dist_entropy": 0.6298628091812134, "actor_grad_norm": 0.07702574133872986, "critic_grad_norm": 0.04504438117146492, "ratio": 1.0000783205032349, "entropy": 0.6298628091812134, "incre_win_rate": 0.8913043478260869, "step": 2902}
{"time": 1767165682.4187279, "phase": "train", "update": 2903, "total_env_steps": 9289600, "episode_reward": 0.28379812836647034, "value_loss": 0.005333514511585235, "policy_loss": -0.001374076916816591, "dist_entropy": 0.6516256332397461, "actor_grad_norm": 0.07890261709690094, "critic_grad_norm": 0.06806078553199768, "ratio": 0.9996911287307739, "entropy": 0.6516256332397461, "incre_win_rate": 0.8888888888888888, "step": 2903}
{"time": 1767165686.8405297, "phase": "train", "update": 2904, "total_env_steps": 9292800, "episode_reward": 0.2926231622695923, "value_loss": 0.00492329839617014, "policy_loss": -0.001148562897542682, "dist_entropy": 0.6280398011207581, "actor_grad_norm": 0.08537506312131882, "critic_grad_norm": 0.04176850989460945, "ratio": 0.9999198913574219, "entropy": 0.6280398011207581, "incre_win_rate": 0.875, "step": 2904}
{"time": 1767165691.1962304, "phase": "train", "update": 2905, "total_env_steps": 9296000, "episode_reward": 0.2865935266017914, "value_loss": 0.007822615932673216, "policy_loss": -0.0015624122151123743, "dist_entropy": 0.6148009896278381, "actor_grad_norm": 0.08962037414312363, "critic_grad_norm": 0.057182636111974716, "ratio": 0.9998440742492676, "entropy": 0.6148009896278381, "incre_win_rate": 0.9148936170212766, "step": 2905}
{"time": 1767165695.6393359, "phase": "train", "update": 2906, "total_env_steps": 9299200, "episode_reward": 0.2952535152435303, "value_loss": 0.005325397662818432, "policy_loss": -0.001381666762972067, "dist_entropy": 0.6508260846138001, "actor_grad_norm": 0.0902743861079216, "critic_grad_norm": 0.07419437170028687, "ratio": 1.0000507831573486, "entropy": 0.6508260846138001, "incre_win_rate": 0.9148936170212766, "step": 2906}
{"time": 1767165700.018888, "phase": "train", "update": 2907, "total_env_steps": 9302400, "episode_reward": 0.2815314531326294, "value_loss": 0.006921854335814714, "policy_loss": -0.0011358399993067537, "dist_entropy": 0.6559626579284668, "actor_grad_norm": 0.0966726765036583, "critic_grad_norm": 0.07392214983701706, "ratio": 0.9999731183052063, "entropy": 0.6559626579284668, "incre_win_rate": 0.8723404255319149, "step": 2907}
{"time": 1767165704.4139621, "phase": "train", "update": 2908, "total_env_steps": 9305600, "episode_reward": 0.28803807497024536, "value_loss": 0.003950793109834194, "policy_loss": -0.0014612307775196953, "dist_entropy": 0.6327107429504395, "actor_grad_norm": 0.09474042803049088, "critic_grad_norm": 0.08430861681699753, "ratio": 0.9998744130134583, "entropy": 0.6327107429504395, "incre_win_rate": 0.9787234042553191, "step": 2908}
{"time": 1767165708.7644231, "phase": "train", "update": 2909, "total_env_steps": 9308800, "episode_reward": 0.2824229300022125, "value_loss": 0.00875706747174263, "policy_loss": -0.0010462051737015088, "dist_entropy": 0.6179295539855957, "actor_grad_norm": 0.07139800488948822, "critic_grad_norm": 0.11576912552118301, "ratio": 1.0000218152999878, "entropy": 0.6179295539855957, "incre_win_rate": 0.8541666666666666, "step": 2909}
{"time": 1767165713.121475, "phase": "train", "update": 2910, "total_env_steps": 9312000, "episode_reward": 0.2830354869365692, "value_loss": 0.00469896961003542, "policy_loss": -0.0012885799633587825, "dist_entropy": 0.610192060470581, "actor_grad_norm": 0.06822013854980469, "critic_grad_norm": 0.08555760234594345, "ratio": 0.9998608827590942, "entropy": 0.610192060470581, "incre_win_rate": 0.9361702127659575, "step": 2910}
{"time": 1767165717.4475048, "phase": "train", "update": 2911, "total_env_steps": 9315200, "episode_reward": 0.2840697169303894, "value_loss": 0.0075575864873826505, "policy_loss": -0.0015672162952748425, "dist_entropy": 0.6216432452201843, "actor_grad_norm": 0.08976581692695618, "critic_grad_norm": 0.07477699220180511, "ratio": 0.9997115135192871, "entropy": 0.6216432452201843, "incre_win_rate": 0.8863636363636364, "step": 2911}
{"time": 1767165721.8212392, "phase": "train", "update": 2912, "total_env_steps": 9318400, "episode_reward": 0.28093647956848145, "value_loss": 0.009030879661440849, "policy_loss": -0.0011124200350696612, "dist_entropy": 0.6262093901634216, "actor_grad_norm": 0.11454947292804718, "critic_grad_norm": 0.08018845319747925, "ratio": 0.9996593594551086, "entropy": 0.6262093901634216, "incre_win_rate": 0.8163265306122449, "step": 2912}
{"time": 1767165726.2120423, "phase": "train", "update": 2913, "total_env_steps": 9321600, "episode_reward": 0.2848178744316101, "value_loss": 0.007740900013595819, "policy_loss": -0.0013160227689397175, "dist_entropy": 0.6406194806098938, "actor_grad_norm": 0.07376344501972198, "critic_grad_norm": 0.047532565891742706, "ratio": 1.0001739263534546, "entropy": 0.6406194806098938, "incre_win_rate": 0.8723404255319149, "step": 2913}
{"time": 1767165730.5682552, "phase": "train", "update": 2914, "total_env_steps": 9324800, "episode_reward": 0.27807170152664185, "value_loss": 0.007156346365809441, "policy_loss": -0.001685511643687221, "dist_entropy": 0.6467968463897705, "actor_grad_norm": 0.08606173098087311, "critic_grad_norm": 0.07106069475412369, "ratio": 0.9999514818191528, "entropy": 0.6467968463897705, "incre_win_rate": 0.8913043478260869, "step": 2914}
{"time": 1767165734.93531, "phase": "train", "update": 2915, "total_env_steps": 9328000, "episode_reward": 0.2777157425880432, "value_loss": 0.00892902109771967, "policy_loss": -0.0016027557719375807, "dist_entropy": 0.6296085953712464, "actor_grad_norm": 0.0924578532576561, "critic_grad_norm": 0.0809696838259697, "ratio": 0.999384343624115, "entropy": 0.6296085953712464, "incre_win_rate": 0.8666666666666667, "step": 2915}
{"time": 1767165739.2731562, "phase": "train", "update": 2916, "total_env_steps": 9331200, "episode_reward": 0.28813689947128296, "value_loss": 0.0066516176797449585, "policy_loss": -0.0015564141888482653, "dist_entropy": 0.6451728820800782, "actor_grad_norm": 0.09459399431943893, "critic_grad_norm": 0.09802805632352829, "ratio": 0.9993636012077332, "entropy": 0.6451728820800782, "incre_win_rate": 0.9166666666666666, "step": 2916}
{"time": 1767165743.6605525, "phase": "train", "update": 2917, "total_env_steps": 9334400, "episode_reward": 0.280839741230011, "value_loss": 0.00633336091414094, "policy_loss": -0.0015373844286482806, "dist_entropy": 0.652619230747223, "actor_grad_norm": 0.09012257307767868, "critic_grad_norm": 0.0950833335518837, "ratio": 0.9998073577880859, "entropy": 0.652619230747223, "incre_win_rate": 0.8913043478260869, "step": 2917}
{"time": 1767165748.0534105, "phase": "train", "update": 2918, "total_env_steps": 9337600, "episode_reward": 0.2894164025783539, "value_loss": 0.00697200708091259, "policy_loss": -0.0014337315319032484, "dist_entropy": 0.6685117721557617, "actor_grad_norm": 0.07142796367406845, "critic_grad_norm": 0.057598646730184555, "ratio": 0.9999408721923828, "entropy": 0.6685117721557617, "incre_win_rate": 0.9148936170212766, "step": 2918}
{"time": 1767165752.371637, "phase": "train", "update": 2919, "total_env_steps": 9340800, "episode_reward": 0.27702608704566956, "value_loss": 0.00838257372379303, "policy_loss": -0.0013071647634347982, "dist_entropy": 0.6326496601104736, "actor_grad_norm": 0.06879635900259018, "critic_grad_norm": 0.07220009714365005, "ratio": 1.000071406364441, "entropy": 0.6326496601104736, "incre_win_rate": 0.8913043478260869, "step": 2919}
{"time": 1767165756.7646751, "phase": "train", "update": 2920, "total_env_steps": 9344000, "episode_reward": 0.2813265919685364, "value_loss": 0.00837378976866603, "policy_loss": -0.0013747281640924315, "dist_entropy": 0.6354095458984375, "actor_grad_norm": 0.07535476982593536, "critic_grad_norm": 0.1002076268196106, "ratio": 0.9997491836547852, "entropy": 0.6354095458984375, "incre_win_rate": 0.9347826086956522, "step": 2920}
{"time": 1767165761.0741777, "phase": "train", "update": 2921, "total_env_steps": 9347200, "episode_reward": 0.2768615484237671, "value_loss": 0.007898525893688202, "policy_loss": -0.0014605936610116999, "dist_entropy": 0.652226448059082, "actor_grad_norm": 0.09035436809062958, "critic_grad_norm": 0.07207519561052322, "ratio": 1.0001418590545654, "entropy": 0.652226448059082, "incre_win_rate": 0.8913043478260869, "step": 2921}
{"time": 1767165770.2016492, "phase": "eval", "update": 2921, "total_env_steps": 9347200, "eval_win_rate": 1.0, "eval_episode_reward": 20.0, "step": 2921}
{"time": 1767165775.4627025, "phase": "train", "update": 2922, "total_env_steps": 9350400, "episode_reward": 0.27908268570899963, "value_loss": 0.004426252469420433, "policy_loss": -0.0010631924238889922, "dist_entropy": 0.638801121711731, "actor_grad_norm": 0.10551686584949493, "critic_grad_norm": 0.09897490590810776, "ratio": 0.9998456835746765, "entropy": 0.638801121711731, "incre_win_rate": 0.9318181818181818, "step": 2922}
{"time": 1767165780.2199538, "phase": "train", "update": 2923, "total_env_steps": 9353600, "episode_reward": 0.2855960428714752, "value_loss": 0.00481052827090025, "policy_loss": -0.001479107059940432, "dist_entropy": 0.6369077086448669, "actor_grad_norm": 0.08717995136976242, "critic_grad_norm": 0.08189572393894196, "ratio": 0.9997671246528625, "entropy": 0.6369077086448669, "incre_win_rate": 0.9361702127659575, "step": 2923}
{"time": 1767165784.9456906, "phase": "train", "update": 2924, "total_env_steps": 9356800, "episode_reward": 0.2784747779369354, "value_loss": 0.006580416485667229, "policy_loss": -0.0014056666463204692, "dist_entropy": 0.6372902274131775, "actor_grad_norm": 0.0873282179236412, "critic_grad_norm": 0.07538039982318878, "ratio": 0.9996953010559082, "entropy": 0.6372902274131775, "incre_win_rate": 0.8695652173913043, "step": 2924}
{"time": 1767165789.7744784, "phase": "train", "update": 2925, "total_env_steps": 9360000, "episode_reward": 0.27853116393089294, "value_loss": 0.006231580954045057, "policy_loss": -0.0010074500929249553, "dist_entropy": 0.6750751733779907, "actor_grad_norm": 0.07350701093673706, "critic_grad_norm": 0.03279721736907959, "ratio": 0.9998582005500793, "entropy": 0.6750751733779907, "incre_win_rate": 0.8863636363636364, "step": 2925}
{"time": 1767165794.6069, "phase": "train", "update": 2926, "total_env_steps": 9363200, "episode_reward": 0.2645907700061798, "value_loss": 0.007628725282847882, "policy_loss": -0.0015703555911599665, "dist_entropy": 0.6324849963188172, "actor_grad_norm": 0.07881386578083038, "critic_grad_norm": 0.03439654782414436, "ratio": 1.000048041343689, "entropy": 0.6324849963188172, "incre_win_rate": 0.8478260869565217, "step": 2926}
{"time": 1767165799.543977, "phase": "train", "update": 2927, "total_env_steps": 9366400, "episode_reward": 0.2706286311149597, "value_loss": 0.010235285945236683, "policy_loss": -0.0016809081324631325, "dist_entropy": 0.6401188373565674, "actor_grad_norm": 0.08084557205438614, "critic_grad_norm": 0.051544662564992905, "ratio": 1.0000799894332886, "entropy": 0.6401188373565674, "incre_win_rate": 0.8, "step": 2927}
{"time": 1767165805.4184399, "phase": "train", "update": 2928, "total_env_steps": 9369600, "episode_reward": 0.279805988073349, "value_loss": 0.0074222365394234656, "policy_loss": -0.0014621438221880112, "dist_entropy": 0.6165821433067322, "actor_grad_norm": 0.08177591860294342, "critic_grad_norm": 0.05678918957710266, "ratio": 0.9999158978462219, "entropy": 0.6165821433067322, "incre_win_rate": 0.8478260869565217, "step": 2928}
{"time": 1767165809.8040116, "phase": "train", "update": 2929, "total_env_steps": 9372800, "episode_reward": 0.29134106636047363, "value_loss": 0.005804474838078022, "policy_loss": -0.0011010599035117252, "dist_entropy": 0.600130021572113, "actor_grad_norm": 0.08297167718410492, "critic_grad_norm": 0.09016729891300201, "ratio": 1.0000056028366089, "entropy": 0.600130021572113, "incre_win_rate": 0.9574468085106383, "step": 2929}
{"time": 1767165814.1927183, "phase": "train", "update": 2930, "total_env_steps": 9376000, "episode_reward": 0.2854723632335663, "value_loss": 0.007267155218869448, "policy_loss": -0.001442998045276056, "dist_entropy": 0.6202046871185303, "actor_grad_norm": 0.08668967336416245, "critic_grad_norm": 0.07019785791635513, "ratio": 1.0001128911972046, "entropy": 0.6202046871185303, "incre_win_rate": 0.8571428571428571, "step": 2930}
{"time": 1767165818.5409794, "phase": "train", "update": 2931, "total_env_steps": 9379200, "episode_reward": 0.2783500552177429, "value_loss": 0.008933147788047791, "policy_loss": -0.0014537408811726494, "dist_entropy": 0.5788177967071533, "actor_grad_norm": 0.10376647859811783, "critic_grad_norm": 0.057965993881225586, "ratio": 1.0000261068344116, "entropy": 0.5788177967071533, "incre_win_rate": 0.8541666666666666, "step": 2931}
{"time": 1767165822.8920248, "phase": "train", "update": 2932, "total_env_steps": 9382400, "episode_reward": 0.27987945079803467, "value_loss": 0.006981443800032139, "policy_loss": -0.0008820887326461246, "dist_entropy": 0.5973401069641113, "actor_grad_norm": 0.08212224394083023, "critic_grad_norm": 0.062077250331640244, "ratio": 0.9996987581253052, "entropy": 0.5973401069641113, "incre_win_rate": 0.8837209302325582, "step": 2932}
{"time": 1767165827.314854, "phase": "train", "update": 2933, "total_env_steps": 9385600, "episode_reward": 0.2828911542892456, "value_loss": 0.006689654663205147, "policy_loss": -0.0012064376080317628, "dist_entropy": 0.5790947079658508, "actor_grad_norm": 0.08646558970212936, "critic_grad_norm": 0.04155580699443817, "ratio": 0.9999862909317017, "entropy": 0.5790947079658508, "incre_win_rate": 0.8695652173913043, "step": 2933}
{"time": 1767165831.6650703, "phase": "train", "update": 2934, "total_env_steps": 9388800, "episode_reward": 0.2908107340335846, "value_loss": 0.004625615663826466, "policy_loss": -0.0013575610010292394, "dist_entropy": 0.5874828577041626, "actor_grad_norm": 0.08166974782943726, "critic_grad_norm": 0.08698403835296631, "ratio": 0.9998424649238586, "entropy": 0.5874828577041626, "incre_win_rate": 0.9574468085106383, "step": 2934}
{"time": 1767165836.005439, "phase": "train", "update": 2935, "total_env_steps": 9392000, "episode_reward": 0.2783629894256592, "value_loss": 0.007202514447271824, "policy_loss": -0.0012758641049657627, "dist_entropy": 0.582687509059906, "actor_grad_norm": 0.07004902511835098, "critic_grad_norm": 0.07370716333389282, "ratio": 0.9998888969421387, "entropy": 0.582687509059906, "incre_win_rate": 0.8936170212765957, "step": 2935}
{"time": 1767165840.399204, "phase": "train", "update": 2936, "total_env_steps": 9395200, "episode_reward": 0.28674980998039246, "value_loss": 0.005702055059373379, "policy_loss": -0.0011727576360726743, "dist_entropy": 0.5901533961296082, "actor_grad_norm": 0.07270612567663193, "critic_grad_norm": 0.05655398964881897, "ratio": 0.9997497797012329, "entropy": 0.5901533961296082, "incre_win_rate": 0.9347826086956522, "step": 2936}
{"time": 1767165844.8141778, "phase": "train", "update": 2937, "total_env_steps": 9398400, "episode_reward": 0.28287458419799805, "value_loss": 0.008057749643921853, "policy_loss": -0.0011665234411850633, "dist_entropy": 0.573492455482483, "actor_grad_norm": 0.0755021721124649, "critic_grad_norm": 0.045526646077632904, "ratio": 1.0002377033233643, "entropy": 0.573492455482483, "incre_win_rate": 0.875, "step": 2937}
{"time": 1767165849.1894584, "phase": "train", "update": 2938, "total_env_steps": 9401600, "episode_reward": 0.2822335362434387, "value_loss": 0.005000986251980066, "policy_loss": -0.0010050385914027516, "dist_entropy": 0.5967121839523315, "actor_grad_norm": 0.07820285856723785, "critic_grad_norm": 0.05210193619132042, "ratio": 0.9999783635139465, "entropy": 0.5967121839523315, "incre_win_rate": 0.9361702127659575, "step": 2938}
{"time": 1767165853.6215713, "phase": "train", "update": 2939, "total_env_steps": 9404800, "episode_reward": 0.2817518711090088, "value_loss": 0.004657119978219271, "policy_loss": -0.001192301250124217, "dist_entropy": 0.6015762209892273, "actor_grad_norm": 0.0814831480383873, "critic_grad_norm": 0.031156277284026146, "ratio": 0.999677836894989, "entropy": 0.6015762209892273, "incre_win_rate": 0.8913043478260869, "step": 2939}
{"time": 1767165892.2658527, "phase": "train", "update": 2940, "total_env_steps": 9408000, "episode_reward": 0.2734644114971161, "value_loss": 0.07804826945066452, "policy_loss": -0.0010607253748332822, "dist_entropy": 0.5851605057716369, "actor_grad_norm": 0.08355831354856491, "critic_grad_norm": 0.5932812094688416, "ratio": 1.000258445739746, "entropy": 0.5851605057716369, "incre_win_rate": 0.9024390243902439, "step": 2940}
{"time": 1767165896.6008089, "phase": "train", "update": 2941, "total_env_steps": 9411200, "episode_reward": 0.2848706543445587, "value_loss": 0.010166415944695473, "policy_loss": -0.001265983517956748, "dist_entropy": 0.5907623171806335, "actor_grad_norm": 0.09296542406082153, "critic_grad_norm": 0.46042323112487793, "ratio": 0.9999513626098633, "entropy": 0.5907623171806335, "incre_win_rate": 0.8958333333333334, "step": 2941}
{"time": 1767165906.2071116, "phase": "eval", "update": 2941, "total_env_steps": 9411200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.512313741721854, "step": 2941}
{"time": 1767165910.5854287, "phase": "train", "update": 2942, "total_env_steps": 9414400, "episode_reward": 0.2937329411506653, "value_loss": 0.00680415341630578, "policy_loss": -0.0010354794946209722, "dist_entropy": 0.6012961506843567, "actor_grad_norm": 0.0768168568611145, "critic_grad_norm": 0.3061205744743347, "ratio": 0.9998241662979126, "entropy": 0.6012961506843567, "incre_win_rate": 0.9375, "step": 2942}
{"time": 1767165915.0084379, "phase": "train", "update": 2943, "total_env_steps": 9417600, "episode_reward": 0.2855587899684906, "value_loss": 0.008656372129917145, "policy_loss": -0.0011748634197147113, "dist_entropy": 0.5823566555976868, "actor_grad_norm": 0.09057965129613876, "critic_grad_norm": 0.20280872285366058, "ratio": 0.9999455809593201, "entropy": 0.5823566555976868, "incre_win_rate": 0.8723404255319149, "step": 2943}
{"time": 1767165919.4054835, "phase": "train", "update": 2944, "total_env_steps": 9420800, "episode_reward": 0.28659147024154663, "value_loss": 0.00813384922221303, "policy_loss": -0.0008122950852367695, "dist_entropy": 0.5930880427360534, "actor_grad_norm": 0.09348912537097931, "critic_grad_norm": 0.1804436296224594, "ratio": 1.0005114078521729, "entropy": 0.5930880427360534, "incre_win_rate": 0.8913043478260869, "step": 2944}
{"time": 1767165923.751653, "phase": "train", "update": 2945, "total_env_steps": 9424000, "episode_reward": 0.27568089962005615, "value_loss": 0.009075465425848962, "policy_loss": -0.001278575315241426, "dist_entropy": 0.5945055246353149, "actor_grad_norm": 0.07590030133724213, "critic_grad_norm": 0.1692715883255005, "ratio": 0.9998945593833923, "entropy": 0.5945055246353149, "incre_win_rate": 0.8043478260869565, "step": 2945}
{"time": 1767165928.1374226, "phase": "train", "update": 2946, "total_env_steps": 9427200, "episode_reward": 0.27898645401000977, "value_loss": 0.010047300532460213, "policy_loss": -0.001803089149666448, "dist_entropy": 0.6083935260772705, "actor_grad_norm": 0.13153712451457977, "critic_grad_norm": 0.06565587967634201, "ratio": 0.9995908141136169, "entropy": 0.6083935260772705, "incre_win_rate": 0.8085106382978723, "step": 2946}
{"time": 1767165932.5031612, "phase": "train", "update": 2947, "total_env_steps": 9430400, "episode_reward": 0.27212750911712646, "value_loss": 0.011686641164124012, "policy_loss": -0.0012825014128345913, "dist_entropy": 0.5877681255340577, "actor_grad_norm": 0.10313649475574493, "critic_grad_norm": 0.05867490917444229, "ratio": 1.0005481243133545, "entropy": 0.5877681255340577, "incre_win_rate": 0.8260869565217391, "step": 2947}
{"time": 1767165936.9094229, "phase": "train", "update": 2948, "total_env_steps": 9433600, "episode_reward": 0.29266247153282166, "value_loss": 0.004978764429688453, "policy_loss": -0.0012981201325153791, "dist_entropy": 0.6216880798339843, "actor_grad_norm": 0.1168743371963501, "critic_grad_norm": 0.1613597422838211, "ratio": 1.0002464056015015, "entropy": 0.6216880798339843, "incre_win_rate": 0.9361702127659575, "step": 2948}
{"time": 1767165941.2522967, "phase": "train", "update": 2949, "total_env_steps": 9436800, "episode_reward": 0.2787753641605377, "value_loss": 0.005186412949115038, "policy_loss": -0.0010745201470982123, "dist_entropy": 0.5972747802734375, "actor_grad_norm": 0.08357273787260056, "critic_grad_norm": 0.08725463598966599, "ratio": 1.0000245571136475, "entropy": 0.5972747802734375, "incre_win_rate": 0.8666666666666667, "step": 2949}
{"time": 1767165945.655768, "phase": "train", "update": 2950, "total_env_steps": 9440000, "episode_reward": 0.2846440374851227, "value_loss": 0.005038289912045002, "policy_loss": -0.0011743671947755275, "dist_entropy": 0.5990693092346191, "actor_grad_norm": 0.06892211735248566, "critic_grad_norm": 0.12011009454727173, "ratio": 0.9999991655349731, "entropy": 0.5990693092346191, "incre_win_rate": 0.9375, "step": 2950}
{"time": 1767165949.9815543, "phase": "train", "update": 2951, "total_env_steps": 9443200, "episode_reward": 0.2800408601760864, "value_loss": 0.005550446733832359, "policy_loss": -0.0011884383463069525, "dist_entropy": 0.6071457743644715, "actor_grad_norm": 0.08591549843549728, "critic_grad_norm": 0.11877676099538803, "ratio": 0.9997221231460571, "entropy": 0.6071457743644715, "incre_win_rate": 0.9111111111111111, "step": 2951}
{"time": 1767165954.2919931, "phase": "train", "update": 2952, "total_env_steps": 9446400, "episode_reward": 0.27161839604377747, "value_loss": 0.006524625606834889, "policy_loss": -0.0011192944411428484, "dist_entropy": 0.5976044178009033, "actor_grad_norm": 0.07548101246356964, "critic_grad_norm": 0.0644453838467598, "ratio": 0.9995338320732117, "entropy": 0.5976044178009033, "incre_win_rate": 0.8636363636363636, "step": 2952}
{"time": 1767165958.6405213, "phase": "train", "update": 2953, "total_env_steps": 9449600, "episode_reward": 0.2713364064693451, "value_loss": 0.007804559264332056, "policy_loss": -0.0011437032003534854, "dist_entropy": 0.599782121181488, "actor_grad_norm": 0.08756847679615021, "critic_grad_norm": 0.08031004667282104, "ratio": 0.9999088644981384, "entropy": 0.599782121181488, "incre_win_rate": 0.8181818181818182, "step": 2953}
{"time": 1767165962.9888813, "phase": "train", "update": 2954, "total_env_steps": 9452800, "episode_reward": 0.28483185172080994, "value_loss": 0.006934123765677214, "policy_loss": -0.0012711458211963843, "dist_entropy": 0.6336892008781433, "actor_grad_norm": 0.09969896078109741, "critic_grad_norm": 0.07364928722381592, "ratio": 0.9993512034416199, "entropy": 0.6336892008781433, "incre_win_rate": 0.9791666666666666, "step": 2954}
{"time": 1767165967.383799, "phase": "train", "update": 2955, "total_env_steps": 9456000, "episode_reward": 0.27939826250076294, "value_loss": 0.005837137904018163, "policy_loss": -0.0008528462799741732, "dist_entropy": 0.6524999856948852, "actor_grad_norm": 0.0815175399184227, "critic_grad_norm": 0.08694078773260117, "ratio": 0.9995604753494263, "entropy": 0.6524999856948852, "incre_win_rate": 0.9111111111111111, "step": 2955}
{"time": 1767165971.7297547, "phase": "train", "update": 2956, "total_env_steps": 9459200, "episode_reward": 0.28122463822364807, "value_loss": 0.004948091879487038, "policy_loss": -0.0013213343338811967, "dist_entropy": 0.6319216012954711, "actor_grad_norm": 0.07084591686725616, "critic_grad_norm": 0.11131073534488678, "ratio": 0.9997474551200867, "entropy": 0.6319216012954711, "incre_win_rate": 0.9130434782608695, "step": 2956}
{"time": 1767165976.113192, "phase": "train", "update": 2957, "total_env_steps": 9462400, "episode_reward": 0.272744745016098, "value_loss": 0.0062576794996857645, "policy_loss": -0.001231717805259791, "dist_entropy": 0.6464988112449646, "actor_grad_norm": 0.06338437646627426, "critic_grad_norm": 0.04488259553909302, "ratio": 0.9999917149543762, "entropy": 0.6464988112449646, "incre_win_rate": 0.8863636363636364, "step": 2957}
{"time": 1767165980.45112, "phase": "train", "update": 2958, "total_env_steps": 9465600, "episode_reward": 0.26812294125556946, "value_loss": 0.007415247336030007, "policy_loss": -0.001240367285999966, "dist_entropy": 0.6155689716339111, "actor_grad_norm": 0.06165151670575142, "critic_grad_norm": 0.03132755309343338, "ratio": 0.9998947978019714, "entropy": 0.6155689716339111, "incre_win_rate": 0.9130434782608695, "step": 2958}
{"time": 1767165984.810886, "phase": "train", "update": 2959, "total_env_steps": 9468800, "episode_reward": 0.2765604257583618, "value_loss": 0.007611896097660065, "policy_loss": -0.0011097159862210049, "dist_entropy": 0.6455828309059143, "actor_grad_norm": 0.07149209827184677, "critic_grad_norm": 0.05677530914545059, "ratio": 1.0002336502075195, "entropy": 0.6455828309059143, "incre_win_rate": 0.8695652173913043, "step": 2959}
{"time": 1767165989.1806126, "phase": "train", "update": 2960, "total_env_steps": 9472000, "episode_reward": 0.27035751938819885, "value_loss": 0.006903205905109644, "policy_loss": -0.0013418191894643884, "dist_entropy": 0.6430815815925598, "actor_grad_norm": 0.0773002877831459, "critic_grad_norm": 0.042773012071847916, "ratio": 1.0000942945480347, "entropy": 0.6430815815925598, "incre_win_rate": 0.9090909090909091, "step": 2960}
{"time": 1767165993.5586135, "phase": "train", "update": 2961, "total_env_steps": 9475200, "episode_reward": 0.2800491452217102, "value_loss": 0.006391189806163311, "policy_loss": -0.0010714560264858618, "dist_entropy": 0.6074053168296814, "actor_grad_norm": 0.08023829013109207, "critic_grad_norm": 0.03882504254579544, "ratio": 1.0003385543823242, "entropy": 0.6074053168296814, "incre_win_rate": 0.8666666666666667, "step": 2961}
{"time": 1767166003.047949, "phase": "eval", "update": 2961, "total_env_steps": 9475200, "eval_win_rate": 0.875, "eval_episode_reward": 19.500051738410594, "step": 2961}
{"time": 1767166007.3662364, "phase": "train", "update": 2962, "total_env_steps": 9478400, "episode_reward": 0.27386587858200073, "value_loss": 0.010662888176739216, "policy_loss": -0.001354592010476452, "dist_entropy": 0.6200693845748901, "actor_grad_norm": 0.07628416270017624, "critic_grad_norm": 0.08729427307844162, "ratio": 0.9998893737792969, "entropy": 0.6200693845748901, "incre_win_rate": 0.8478260869565217, "step": 2962}
{"time": 1767166011.6523156, "phase": "train", "update": 2963, "total_env_steps": 9481600, "episode_reward": 0.2684033513069153, "value_loss": 0.008911989443004132, "policy_loss": -0.0012927919544480915, "dist_entropy": 0.5972067713737488, "actor_grad_norm": 0.08272247761487961, "critic_grad_norm": 0.05533483624458313, "ratio": 1.0001837015151978, "entropy": 0.5972067713737488, "incre_win_rate": 0.8043478260869565, "step": 2963}
{"time": 1767166015.9797215, "phase": "train", "update": 2964, "total_env_steps": 9484800, "episode_reward": 0.2774161994457245, "value_loss": 0.006914328783750534, "policy_loss": -0.0011668791821588087, "dist_entropy": 0.6277747035026551, "actor_grad_norm": 0.08471622318029404, "critic_grad_norm": 0.09484588354825974, "ratio": 0.9999529719352722, "entropy": 0.6277747035026551, "incre_win_rate": 0.8863636363636364, "step": 2964}
{"time": 1767166020.3048735, "phase": "train", "update": 2965, "total_env_steps": 9488000, "episode_reward": 0.274189293384552, "value_loss": 0.00925299134105444, "policy_loss": -0.0013784274312428125, "dist_entropy": 0.5942438840866089, "actor_grad_norm": 0.07546888291835785, "critic_grad_norm": 0.03478722274303436, "ratio": 1.0001598596572876, "entropy": 0.5942438840866089, "incre_win_rate": 0.8888888888888888, "step": 2965}
{"time": 1767166024.6633265, "phase": "train", "update": 2966, "total_env_steps": 9491200, "episode_reward": 0.2758153975009918, "value_loss": 0.0055939205922186375, "policy_loss": -0.0009480882769093313, "dist_entropy": 0.625978970527649, "actor_grad_norm": 0.06607435643672943, "critic_grad_norm": 0.04752673581242561, "ratio": 1.0000841617584229, "entropy": 0.625978970527649, "incre_win_rate": 0.9130434782608695, "step": 2966}
{"time": 1767166028.9691799, "phase": "train", "update": 2967, "total_env_steps": 9494400, "episode_reward": 0.27693814039230347, "value_loss": 0.006905003916472197, "policy_loss": -0.0011772773125926506, "dist_entropy": 0.6144415855407714, "actor_grad_norm": 0.06883963942527771, "critic_grad_norm": 0.04585617780685425, "ratio": 0.999721348285675, "entropy": 0.6144415855407714, "incre_win_rate": 0.851063829787234, "step": 2967}
{"time": 1767166033.3366652, "phase": "train", "update": 2968, "total_env_steps": 9497600, "episode_reward": 0.28729870915412903, "value_loss": 0.006998436246067286, "policy_loss": -0.0011332013043684696, "dist_entropy": 0.6184274554252625, "actor_grad_norm": 0.0693475753068924, "critic_grad_norm": 0.040628641843795776, "ratio": 0.9999536871910095, "entropy": 0.6184274554252625, "incre_win_rate": 0.9111111111111111, "step": 2968}
{"time": 1767166037.6841218, "phase": "train", "update": 2969, "total_env_steps": 9500800, "episode_reward": 0.27651387453079224, "value_loss": 0.008383227698504924, "policy_loss": -0.0018253724138085846, "dist_entropy": 0.6194994449615479, "actor_grad_norm": 0.08855663985013962, "critic_grad_norm": 0.04445696994662285, "ratio": 1.0001018047332764, "entropy": 0.6194994449615479, "incre_win_rate": 0.875, "step": 2969}
{"time": 1767166042.029809, "phase": "train", "update": 2970, "total_env_steps": 9504000, "episode_reward": 0.28209903836250305, "value_loss": 0.006010414939373732, "policy_loss": -0.001319903737707584, "dist_entropy": 0.6117036819458008, "actor_grad_norm": 0.07683705538511276, "critic_grad_norm": 0.06082255765795708, "ratio": 1.000004529953003, "entropy": 0.6117036819458008, "incre_win_rate": 0.9545454545454546, "step": 2970}
{"time": 1767166046.530337, "phase": "train", "update": 2971, "total_env_steps": 9507200, "episode_reward": 0.2818884551525116, "value_loss": 0.005552255269140005, "policy_loss": -0.0009553089015270188, "dist_entropy": 0.6023038148880004, "actor_grad_norm": 0.07020866125822067, "critic_grad_norm": 0.035775940865278244, "ratio": 1.0000364780426025, "entropy": 0.6023038148880004, "incre_win_rate": 0.8936170212765957, "step": 2971}
{"time": 1767166050.8794181, "phase": "train", "update": 2972, "total_env_steps": 9510400, "episode_reward": 0.28600165247917175, "value_loss": 0.0043108342215418816, "policy_loss": -0.0007339818714529045, "dist_entropy": 0.6159657955169677, "actor_grad_norm": 0.06560315191745758, "critic_grad_norm": 0.05763911083340645, "ratio": 0.9999322891235352, "entropy": 0.6159657955169677, "incre_win_rate": 0.9574468085106383, "step": 2972}
{"time": 1767166055.2313766, "phase": "train", "update": 2973, "total_env_steps": 9513600, "episode_reward": 0.2782367467880249, "value_loss": 0.007232778239995241, "policy_loss": -0.00104265516409896, "dist_entropy": 0.6306453704833984, "actor_grad_norm": 0.09394112229347229, "critic_grad_norm": 0.058965932577848434, "ratio": 0.9999849200248718, "entropy": 0.6306453704833984, "incre_win_rate": 0.8636363636363636, "step": 2973}
{"time": 1767166059.5454512, "phase": "train", "update": 2974, "total_env_steps": 9516800, "episode_reward": 0.27720922231674194, "value_loss": 0.006619652267545462, "policy_loss": -0.0012138441471279294, "dist_entropy": 0.6395344734191895, "actor_grad_norm": 0.0984918400645256, "critic_grad_norm": 0.04434996098279953, "ratio": 1.0003141164779663, "entropy": 0.6395344734191895, "incre_win_rate": 0.875, "step": 2974}
{"time": 1767166063.9038632, "phase": "train", "update": 2975, "total_env_steps": 9520000, "episode_reward": 0.2787189781665802, "value_loss": 0.00721826795488596, "policy_loss": -0.0009778089253678957, "dist_entropy": 0.6592799901962281, "actor_grad_norm": 0.09488552808761597, "critic_grad_norm": 0.06312959641218185, "ratio": 0.9999004602432251, "entropy": 0.6592799901962281, "incre_win_rate": 0.8260869565217391, "step": 2975}
{"time": 1767166068.235182, "phase": "train", "update": 2976, "total_env_steps": 9523200, "episode_reward": 0.2898649573326111, "value_loss": 0.006522191315889358, "policy_loss": -0.0014292158389665132, "dist_entropy": 0.6410000801086426, "actor_grad_norm": 0.08118876814842224, "critic_grad_norm": 0.03273468092083931, "ratio": 1.0000574588775635, "entropy": 0.6410000801086426, "incre_win_rate": 0.8958333333333334, "step": 2976}
{"time": 1767166072.502627, "phase": "train", "update": 2977, "total_env_steps": 9526400, "episode_reward": 0.27027836441993713, "value_loss": 0.012806571274995803, "policy_loss": -0.00199029492804903, "dist_entropy": 0.6081946015357971, "actor_grad_norm": 0.10641562193632126, "critic_grad_norm": 0.09864985197782516, "ratio": 0.9998046159744263, "entropy": 0.6081946015357971, "incre_win_rate": 0.7608695652173914, "step": 2977}
{"time": 1767166076.8504045, "phase": "train", "update": 2978, "total_env_steps": 9529600, "episode_reward": 0.2852359116077423, "value_loss": 0.00682833343744278, "policy_loss": -0.0008567571061245616, "dist_entropy": 0.6090538620948791, "actor_grad_norm": 0.06571543216705322, "critic_grad_norm": 0.11720141023397446, "ratio": 1.0000860691070557, "entropy": 0.6090538620948791, "incre_win_rate": 0.8478260869565217, "step": 2978}
{"time": 1767166081.1748116, "phase": "train", "update": 2979, "total_env_steps": 9532800, "episode_reward": 0.27297651767730713, "value_loss": 0.0060380006209015845, "policy_loss": -0.001328015389168513, "dist_entropy": 0.6024356484413147, "actor_grad_norm": 0.08436128497123718, "critic_grad_norm": 0.10496427863836288, "ratio": 1.0000778436660767, "entropy": 0.6024356484413147, "incre_win_rate": 0.8695652173913043, "step": 2979}
{"time": 1767166085.5839753, "phase": "train", "update": 2980, "total_env_steps": 9536000, "episode_reward": 0.296167254447937, "value_loss": 0.0046932652592659, "policy_loss": -0.0012413359980556038, "dist_entropy": 0.6148992657661438, "actor_grad_norm": 0.07585456222295761, "critic_grad_norm": 0.12011867016553879, "ratio": 0.9998968243598938, "entropy": 0.6148992657661438, "incre_win_rate": 0.9787234042553191, "step": 2980}
{"time": 1767166089.9514637, "phase": "train", "update": 2981, "total_env_steps": 9539200, "episode_reward": 0.2770245373249054, "value_loss": 0.009702321328222751, "policy_loss": -0.0011181098246666465, "dist_entropy": 0.6007942676544189, "actor_grad_norm": 0.09379696846008301, "critic_grad_norm": 0.05315784364938736, "ratio": 1.0001767873764038, "entropy": 0.6007942676544189, "incre_win_rate": 0.8913043478260869, "step": 2981}
{"time": 1767166099.195652, "phase": "eval", "update": 2981, "total_env_steps": 9539200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.753414735099337, "step": 2981}
{"time": 1767166103.5376282, "phase": "train", "update": 2982, "total_env_steps": 9542400, "episode_reward": 0.2880970537662506, "value_loss": 0.005266429670155048, "policy_loss": -0.0009889589162604296, "dist_entropy": 0.6086116313934327, "actor_grad_norm": 0.08160735666751862, "critic_grad_norm": 0.11790414154529572, "ratio": 1.0002163648605347, "entropy": 0.6086116313934327, "incre_win_rate": 0.8958333333333334, "step": 2982}
{"time": 1767166107.8303995, "phase": "train", "update": 2983, "total_env_steps": 9545600, "episode_reward": 0.28396573662757874, "value_loss": 0.005964431725442409, "policy_loss": -0.0011092141688074264, "dist_entropy": 0.604534387588501, "actor_grad_norm": 0.08460024744272232, "critic_grad_norm": 0.0349397137761116, "ratio": 0.9998826384544373, "entropy": 0.604534387588501, "incre_win_rate": 0.9130434782608695, "step": 2983}
{"time": 1767166112.1167512, "phase": "train", "update": 2984, "total_env_steps": 9548800, "episode_reward": 0.2746724784374237, "value_loss": 0.009187092445790768, "policy_loss": -0.0015717637666767814, "dist_entropy": 0.5783198356628418, "actor_grad_norm": 0.08750420808792114, "critic_grad_norm": 0.17273198068141937, "ratio": 0.9997456669807434, "entropy": 0.5783198356628418, "incre_win_rate": 0.7872340425531915, "step": 2984}
{"time": 1767166116.417194, "phase": "train", "update": 2985, "total_env_steps": 9552000, "episode_reward": 0.27334436774253845, "value_loss": 0.007371466420590877, "policy_loss": -0.0016140713137403396, "dist_entropy": 0.6268457651138306, "actor_grad_norm": 0.08591693639755249, "critic_grad_norm": 0.10179930925369263, "ratio": 1.0001558065414429, "entropy": 0.6268457651138306, "incre_win_rate": 0.8409090909090909, "step": 2985}
{"time": 1767166120.7179983, "phase": "train", "update": 2986, "total_env_steps": 9555200, "episode_reward": 0.28427979350090027, "value_loss": 0.010026166774332523, "policy_loss": -0.0016743486918112892, "dist_entropy": 0.6048764944076538, "actor_grad_norm": 0.09019950032234192, "critic_grad_norm": 0.13337579369544983, "ratio": 0.9997231364250183, "entropy": 0.6048764944076538, "incre_win_rate": 0.9130434782608695, "step": 2986}
{"time": 1767166125.0190713, "phase": "train", "update": 2987, "total_env_steps": 9558400, "episode_reward": 0.27639278769493103, "value_loss": 0.011965543404221535, "policy_loss": -0.0016890497843903064, "dist_entropy": 0.6027205586433411, "actor_grad_norm": 0.0818873718380928, "critic_grad_norm": 0.07348709553480148, "ratio": 0.9997180104255676, "entropy": 0.6027205586433411, "incre_win_rate": 0.7872340425531915, "step": 2987}
{"time": 1767166129.4474268, "phase": "train", "update": 2988, "total_env_steps": 9561600, "episode_reward": 0.2816752791404724, "value_loss": 0.005667741689831018, "policy_loss": -0.0011196606732092995, "dist_entropy": 0.5998525619506836, "actor_grad_norm": 0.08167996257543564, "critic_grad_norm": 0.11459080129861832, "ratio": 1.0002506971359253, "entropy": 0.5998525619506836, "incre_win_rate": 0.9347826086956522, "step": 2988}
{"time": 1767166133.747489, "phase": "train", "update": 2989, "total_env_steps": 9564800, "episode_reward": 0.28416651487350464, "value_loss": 0.004502742365002632, "policy_loss": -0.0016556590895607571, "dist_entropy": 0.5922324299812317, "actor_grad_norm": 0.08597692102193832, "critic_grad_norm": 0.06918306648731232, "ratio": 0.9998388290405273, "entropy": 0.5922324299812317, "incre_win_rate": 0.9361702127659575, "step": 2989}
{"time": 1767166138.0066712, "phase": "train", "update": 2990, "total_env_steps": 9568000, "episode_reward": 0.28253722190856934, "value_loss": 0.004883257113397122, "policy_loss": -0.0011989840888418258, "dist_entropy": 0.5874797701835632, "actor_grad_norm": 0.07396016269922256, "critic_grad_norm": 0.05222160369157791, "ratio": 0.9997531771659851, "entropy": 0.5874797701835632, "incre_win_rate": 0.9111111111111111, "step": 2990}
{"time": 1767166142.339736, "phase": "train", "update": 2991, "total_env_steps": 9571200, "episode_reward": 0.30041804909706116, "value_loss": 0.00216161641292274, "policy_loss": -0.00107614674806058, "dist_entropy": 0.5891839385032653, "actor_grad_norm": 0.06813865154981613, "critic_grad_norm": 0.05812111124396324, "ratio": 0.9997208714485168, "entropy": 0.5891839385032653, "incre_win_rate": 1.0, "step": 2991}
{"time": 1767166146.6523979, "phase": "train", "update": 2992, "total_env_steps": 9574400, "episode_reward": 0.28956592082977295, "value_loss": 0.00755645614117384, "policy_loss": -0.0012763094371400995, "dist_entropy": 0.5849587321281433, "actor_grad_norm": 0.07147719711065292, "critic_grad_norm": 0.053897153586149216, "ratio": 1.0001194477081299, "entropy": 0.5849587321281433, "incre_win_rate": 0.9375, "step": 2992}
{"time": 1767166150.9426537, "phase": "train", "update": 2993, "total_env_steps": 9577600, "episode_reward": 0.2970985174179077, "value_loss": 0.00331638609059155, "policy_loss": -0.0012424544968268948, "dist_entropy": 0.6037681341171265, "actor_grad_norm": 0.08665912598371506, "critic_grad_norm": 0.06994286924600601, "ratio": 0.9998348355293274, "entropy": 0.6037681341171265, "incre_win_rate": 0.9574468085106383, "step": 2993}
{"time": 1767166155.3296232, "phase": "train", "update": 2994, "total_env_steps": 9580800, "episode_reward": 0.2881094813346863, "value_loss": 0.006972756143659354, "policy_loss": -0.0012830571797610713, "dist_entropy": 0.5748316884040833, "actor_grad_norm": 0.07275336235761642, "critic_grad_norm": 0.05777285248041153, "ratio": 0.9997461438179016, "entropy": 0.5748316884040833, "incre_win_rate": 0.9166666666666666, "step": 2994}
{"time": 1767166160.6624823, "phase": "train", "update": 2995, "total_env_steps": 9584000, "episode_reward": 0.27640265226364136, "value_loss": 0.00760559244081378, "policy_loss": -0.001373924407045024, "dist_entropy": 0.5772237658500672, "actor_grad_norm": 0.09215236455202103, "critic_grad_norm": 0.11299524456262589, "ratio": 0.9999205470085144, "entropy": 0.5772237658500672, "incre_win_rate": 0.8695652173913043, "step": 2995}
{"time": 1767166165.3452907, "phase": "train", "update": 2996, "total_env_steps": 9587200, "episode_reward": 0.28540509939193726, "value_loss": 0.0058145388960838314, "policy_loss": -0.0013834940653026707, "dist_entropy": 0.5751222848892212, "actor_grad_norm": 0.0695871040225029, "critic_grad_norm": 0.07558280229568481, "ratio": 1.0001333951950073, "entropy": 0.5751222848892212, "incre_win_rate": 0.8541666666666666, "step": 2996}
{"time": 1767166170.0740948, "phase": "train", "update": 2997, "total_env_steps": 9590400, "episode_reward": 0.292640745639801, "value_loss": 0.0036421937867999075, "policy_loss": -0.001089826375791958, "dist_entropy": 0.5873568534851075, "actor_grad_norm": 0.07520454376935959, "critic_grad_norm": 0.08595219999551773, "ratio": 0.9997736811637878, "entropy": 0.5873568534851075, "incre_win_rate": 0.9787234042553191, "step": 2997}
{"time": 1767166174.720617, "phase": "train", "update": 2998, "total_env_steps": 9593600, "episode_reward": 0.28654026985168457, "value_loss": 0.005415287241339684, "policy_loss": -0.0011720863309648167, "dist_entropy": 0.5548331141471863, "actor_grad_norm": 0.07603882998228073, "critic_grad_norm": 0.04622235149145126, "ratio": 1.0000817775726318, "entropy": 0.5548331141471863, "incre_win_rate": 0.9130434782608695, "step": 2998}
{"time": 1767166179.5049403, "phase": "train", "update": 2999, "total_env_steps": 9596800, "episode_reward": 0.29745858907699585, "value_loss": 0.0032945674378424884, "policy_loss": -0.0012390135021590255, "dist_entropy": 0.5831904411315918, "actor_grad_norm": 0.08133221417665482, "critic_grad_norm": 0.09618264436721802, "ratio": 0.9998884201049805, "entropy": 0.5831904411315918, "incre_win_rate": 1.0, "step": 2999}
{"time": 1767166184.1528292, "phase": "train", "update": 3000, "total_env_steps": 9600000, "episode_reward": 0.2898530662059784, "value_loss": 0.005723622534424067, "policy_loss": -0.000872153523398822, "dist_entropy": 0.5735846042633057, "actor_grad_norm": 0.06667210906744003, "critic_grad_norm": 0.06380947679281235, "ratio": 1.0003405809402466, "entropy": 0.5735846042633057, "incre_win_rate": 0.9347826086956522, "step": 3000}
{"time": 1767166188.8464894, "phase": "train", "update": 3001, "total_env_steps": 9603200, "episode_reward": 0.29443347454071045, "value_loss": 0.005511347204446793, "policy_loss": -0.0011754922727302386, "dist_entropy": 0.5720664858818054, "actor_grad_norm": 0.07209452241659164, "critic_grad_norm": 0.05823001265525818, "ratio": 1.0001760721206665, "entropy": 0.5720664858818054, "incre_win_rate": 0.8979591836734694, "step": 3001}
{"time": 1767166198.4991467, "phase": "eval", "update": 3001, "total_env_steps": 9603200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.829056291390728, "step": 3001}
{"time": 1767166204.6279805, "phase": "train", "update": 3002, "total_env_steps": 9606400, "episode_reward": 0.29879865050315857, "value_loss": 0.0034934278577566148, "policy_loss": -0.001297122882844448, "dist_entropy": 0.5726579070091248, "actor_grad_norm": 0.07789713144302368, "critic_grad_norm": 0.05172918364405632, "ratio": 1.000148057937622, "entropy": 0.5726579070091248, "incre_win_rate": 0.9583333333333334, "step": 3002}
{"time": 1767166209.0695322, "phase": "train", "update": 3003, "total_env_steps": 9609600, "episode_reward": 0.2924399971961975, "value_loss": 0.006654621940106154, "policy_loss": -0.0016789983282887333, "dist_entropy": 0.5903760910034179, "actor_grad_norm": 0.08705050498247147, "critic_grad_norm": 0.08902847021818161, "ratio": 0.99976646900177, "entropy": 0.5903760910034179, "incre_win_rate": 0.9375, "step": 3003}
{"time": 1767166213.5001173, "phase": "train", "update": 3004, "total_env_steps": 9612800, "episode_reward": 0.29224908351898193, "value_loss": 0.005037147086113691, "policy_loss": -0.0011332453407570497, "dist_entropy": 0.5947970032691956, "actor_grad_norm": 0.07764066010713577, "critic_grad_norm": 0.06356006115674973, "ratio": 1.000138521194458, "entropy": 0.5947970032691956, "incre_win_rate": 0.8936170212765957, "step": 3004}
{"time": 1767166217.9402063, "phase": "train", "update": 3005, "total_env_steps": 9616000, "episode_reward": 0.2981829345226288, "value_loss": 0.00516972104087472, "policy_loss": -0.0013055248204679516, "dist_entropy": 0.5918273448944091, "actor_grad_norm": 0.09334045648574829, "critic_grad_norm": 0.05266686901450157, "ratio": 0.9998079538345337, "entropy": 0.5918273448944091, "incre_win_rate": 0.9591836734693877, "step": 3005}
{"time": 1767166222.313341, "phase": "train", "update": 3006, "total_env_steps": 9619200, "episode_reward": 0.2962510585784912, "value_loss": 0.00626618517562747, "policy_loss": -0.0014927034917905147, "dist_entropy": 0.5915758490562439, "actor_grad_norm": 0.08083992451429367, "critic_grad_norm": 0.037411563098430634, "ratio": 0.9997916221618652, "entropy": 0.5915758490562439, "incre_win_rate": 0.9591836734693877, "step": 3006}
{"time": 1767166226.705029, "phase": "train", "update": 3007, "total_env_steps": 9622400, "episode_reward": 0.28289681673049927, "value_loss": 0.007079783361405134, "policy_loss": -0.0012402840436550378, "dist_entropy": 0.5766056895256042, "actor_grad_norm": 0.10179620236158371, "critic_grad_norm": 0.027206584811210632, "ratio": 0.9997221827507019, "entropy": 0.5766056895256042, "incre_win_rate": 0.8478260869565217, "step": 3007}
{"time": 1767166231.1483953, "phase": "train", "update": 3008, "total_env_steps": 9625600, "episode_reward": 0.3046181797981262, "value_loss": 0.0036806006915867328, "policy_loss": -0.0013092093248543435, "dist_entropy": 0.6107335925102234, "actor_grad_norm": 0.10137336701154709, "critic_grad_norm": 0.05854283645749092, "ratio": 1.000038981437683, "entropy": 0.6107335925102234, "incre_win_rate": 0.9607843137254902, "step": 3008}
{"time": 1767166235.6034868, "phase": "train", "update": 3009, "total_env_steps": 9628800, "episode_reward": 0.29322537779808044, "value_loss": 0.0032888602465391157, "policy_loss": -0.0015289838259622713, "dist_entropy": 0.6055130958557129, "actor_grad_norm": 0.0939575806260109, "critic_grad_norm": 0.027785539627075195, "ratio": 0.9996420741081238, "entropy": 0.6055130958557129, "incre_win_rate": 0.9574468085106383, "step": 3009}
{"time": 1767166240.0642354, "phase": "train", "update": 3010, "total_env_steps": 9632000, "episode_reward": 0.29185742139816284, "value_loss": 0.007327140774577856, "policy_loss": -0.0010110549399598768, "dist_entropy": 0.5906395316123962, "actor_grad_norm": 0.06898673623800278, "critic_grad_norm": 0.09545054286718369, "ratio": 0.9999420046806335, "entropy": 0.5906395316123962, "incre_win_rate": 0.8541666666666666, "step": 3010}
{"time": 1767166244.5330555, "phase": "train", "update": 3011, "total_env_steps": 9635200, "episode_reward": 0.30179014801979065, "value_loss": 0.003137924335896969, "policy_loss": -0.0010604762651841959, "dist_entropy": 0.6174023270606994, "actor_grad_norm": 0.0828757956624031, "critic_grad_norm": 0.07986944168806076, "ratio": 0.9997873306274414, "entropy": 0.6174023270606994, "incre_win_rate": 0.9787234042553191, "step": 3011}
{"time": 1767166248.9472146, "phase": "train", "update": 3012, "total_env_steps": 9638400, "episode_reward": 0.2957616150379181, "value_loss": 0.004090667050331831, "policy_loss": -0.001380251412456701, "dist_entropy": 0.5972489476203918, "actor_grad_norm": 0.09019383043050766, "critic_grad_norm": 0.03411062806844711, "ratio": 0.999686062335968, "entropy": 0.5972489476203918, "incre_win_rate": 0.9375, "step": 3012}
{"time": 1767166253.3226202, "phase": "train", "update": 3013, "total_env_steps": 9641600, "episode_reward": 0.29356062412261963, "value_loss": 0.004637127369642257, "policy_loss": -0.0014276744454612355, "dist_entropy": 0.5810042142868042, "actor_grad_norm": 0.08202226459980011, "critic_grad_norm": 0.0370708666741848, "ratio": 1.0000795125961304, "entropy": 0.5810042142868042, "incre_win_rate": 0.9387755102040817, "step": 3013}
{"time": 1767166257.685345, "phase": "train", "update": 3014, "total_env_steps": 9644800, "episode_reward": 0.2863524556159973, "value_loss": 0.007529093697667122, "policy_loss": -0.001059809691812319, "dist_entropy": 0.5886592507362366, "actor_grad_norm": 0.07854832708835602, "critic_grad_norm": 0.06967329233884811, "ratio": 1.000343918800354, "entropy": 0.5886592507362366, "incre_win_rate": 0.8723404255319149, "step": 3014}
{"time": 1767166262.127879, "phase": "train", "update": 3015, "total_env_steps": 9648000, "episode_reward": 0.28420063853263855, "value_loss": 0.008562666177749634, "policy_loss": -0.0011258223429171821, "dist_entropy": 0.5873972415924072, "actor_grad_norm": 0.1050996333360672, "critic_grad_norm": 0.047115348279476166, "ratio": 1.0000123977661133, "entropy": 0.5873972415924072, "incre_win_rate": 0.8478260869565217, "step": 3015}
{"time": 1767166266.594453, "phase": "train", "update": 3016, "total_env_steps": 9651200, "episode_reward": 0.2956943213939667, "value_loss": 0.005710805673152209, "policy_loss": -0.0012128233339524287, "dist_entropy": 0.5846655488014221, "actor_grad_norm": 0.07528455555438995, "critic_grad_norm": 0.06846822053194046, "ratio": 0.9996916651725769, "entropy": 0.5846655488014221, "incre_win_rate": 0.9166666666666666, "step": 3016}
{"time": 1767166272.0715694, "phase": "train", "update": 3017, "total_env_steps": 9654400, "episode_reward": 0.30192363262176514, "value_loss": 0.0038101781625300645, "policy_loss": -0.0012678990902957655, "dist_entropy": 0.577668035030365, "actor_grad_norm": 0.07064931094646454, "critic_grad_norm": 0.06033781170845032, "ratio": 1.0001128911972046, "entropy": 0.577668035030365, "incre_win_rate": 1.0, "step": 3017}
{"time": 1767166276.8681939, "phase": "train", "update": 3018, "total_env_steps": 9657600, "episode_reward": 0.2960544228553772, "value_loss": 0.0023018274921923878, "policy_loss": -0.0014059984646085156, "dist_entropy": 0.5837081670761108, "actor_grad_norm": 0.09424573928117752, "critic_grad_norm": 0.01576712727546692, "ratio": 1.0001288652420044, "entropy": 0.5837081670761108, "incre_win_rate": 0.9591836734693877, "step": 3018}
{"time": 1767166282.8479264, "phase": "train", "update": 3019, "total_env_steps": 9660800, "episode_reward": 0.2845565974712372, "value_loss": 0.006055837776511907, "policy_loss": -0.0014489660922421877, "dist_entropy": 0.562528932094574, "actor_grad_norm": 0.08952730149030685, "critic_grad_norm": 0.09044037014245987, "ratio": 0.9996904730796814, "entropy": 0.562528932094574, "incre_win_rate": 0.8936170212765957, "step": 3019}
{"time": 1767166287.6581933, "phase": "train", "update": 3020, "total_env_steps": 9664000, "episode_reward": 0.2895333468914032, "value_loss": 0.006986943725496531, "policy_loss": -0.0011672016134255613, "dist_entropy": 0.5759148001670837, "actor_grad_norm": 0.08347074687480927, "critic_grad_norm": 0.04613496735692024, "ratio": 0.9996287226676941, "entropy": 0.5759148001670837, "incre_win_rate": 0.8958333333333334, "step": 3020}
{"time": 1767166292.039167, "phase": "train", "update": 3021, "total_env_steps": 9667200, "episode_reward": 0.2825951874256134, "value_loss": 0.008085504546761513, "policy_loss": -0.0015280132389005273, "dist_entropy": 0.5726422667503357, "actor_grad_norm": 0.09073466062545776, "critic_grad_norm": 0.05120746046304703, "ratio": 0.9999517798423767, "entropy": 0.5726422667503357, "incre_win_rate": 0.8695652173913043, "step": 3021}
{"time": 1767166301.2831957, "phase": "eval", "update": 3021, "total_env_steps": 9667200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.825848509933778, "step": 3021}
{"time": 1767166305.6514676, "phase": "train", "update": 3022, "total_env_steps": 9670400, "episode_reward": 0.28949400782585144, "value_loss": 0.0048950607888400555, "policy_loss": -0.0015756001457704726, "dist_entropy": 0.573581063747406, "actor_grad_norm": 0.09153812378644943, "critic_grad_norm": 0.04445142671465874, "ratio": 1.0003002882003784, "entropy": 0.573581063747406, "incre_win_rate": 0.9166666666666666, "step": 3022}
{"time": 1767166309.9977047, "phase": "train", "update": 3023, "total_env_steps": 9673600, "episode_reward": 0.2760518491268158, "value_loss": 0.009291892684996129, "policy_loss": -0.0013667435479231215, "dist_entropy": 0.5731093406677246, "actor_grad_norm": 0.08687695115804672, "critic_grad_norm": 0.14907048642635345, "ratio": 0.9998198747634888, "entropy": 0.5731093406677246, "incre_win_rate": 0.8297872340425532, "step": 3023}
{"time": 1767166314.3332534, "phase": "train", "update": 3024, "total_env_steps": 9676800, "episode_reward": 0.2916463315486908, "value_loss": 0.005068145878612995, "policy_loss": -0.0015783038313962549, "dist_entropy": 0.5799436807632447, "actor_grad_norm": 0.0984882339835167, "critic_grad_norm": 0.13444344699382782, "ratio": 0.999790608882904, "entropy": 0.5799436807632447, "incre_win_rate": 0.8936170212765957, "step": 3024}
{"time": 1767166318.6892273, "phase": "train", "update": 3025, "total_env_steps": 9680000, "episode_reward": 0.27868637442588806, "value_loss": 0.012260909005999566, "policy_loss": -0.0015575167428025338, "dist_entropy": 0.5831019163131714, "actor_grad_norm": 0.09591090679168701, "critic_grad_norm": 0.16577669978141785, "ratio": 1.0000169277191162, "entropy": 0.5831019163131714, "incre_win_rate": 0.7959183673469388, "step": 3025}
{"time": 1767166323.0547738, "phase": "train", "update": 3026, "total_env_steps": 9683200, "episode_reward": 0.2939372956752777, "value_loss": 0.006939512863755226, "policy_loss": -0.0009954209798934243, "dist_entropy": 0.5871692538261414, "actor_grad_norm": 0.08217685669660568, "critic_grad_norm": 0.1776271015405655, "ratio": 1.0001310110092163, "entropy": 0.5871692538261414, "incre_win_rate": 0.9166666666666666, "step": 3026}
{"time": 1767166327.4398172, "phase": "train", "update": 3027, "total_env_steps": 9686400, "episode_reward": 0.29012420773506165, "value_loss": 0.007294781319797039, "policy_loss": -0.0012439822791503019, "dist_entropy": 0.6048763275146485, "actor_grad_norm": 0.07424250990152359, "critic_grad_norm": 0.15198811888694763, "ratio": 1.0001083612442017, "entropy": 0.6048763275146485, "incre_win_rate": 0.9130434782608695, "step": 3027}
{"time": 1767166331.8713431, "phase": "train", "update": 3028, "total_env_steps": 9689600, "episode_reward": 0.28879135847091675, "value_loss": 0.007741515152156353, "policy_loss": -0.00158135780954467, "dist_entropy": 0.6209566235542298, "actor_grad_norm": 0.0905679240822792, "critic_grad_norm": 0.09586556255817413, "ratio": 0.9998858571052551, "entropy": 0.6209566235542298, "incre_win_rate": 0.8571428571428571, "step": 3028}
{"time": 1767166336.202519, "phase": "train", "update": 3029, "total_env_steps": 9692800, "episode_reward": 0.29709023237228394, "value_loss": 0.006523204874247313, "policy_loss": -0.0008817913448938341, "dist_entropy": 0.6176951766014099, "actor_grad_norm": 0.08414504677057266, "critic_grad_norm": 0.09657329320907593, "ratio": 0.9998428225517273, "entropy": 0.6176951766014099, "incre_win_rate": 0.9565217391304348, "step": 3029}
{"time": 1767166340.5617096, "phase": "train", "update": 3030, "total_env_steps": 9696000, "episode_reward": 0.27832937240600586, "value_loss": 0.006717105023562908, "policy_loss": -0.001317838263680926, "dist_entropy": 0.6051285266876221, "actor_grad_norm": 0.09882721304893494, "critic_grad_norm": 0.06291104108095169, "ratio": 0.9998477101325989, "entropy": 0.6051285266876221, "incre_win_rate": 0.8913043478260869, "step": 3030}
{"time": 1767166344.9301636, "phase": "train", "update": 3031, "total_env_steps": 9699200, "episode_reward": 0.2920405864715576, "value_loss": 0.005008445959538222, "policy_loss": -0.0012925975933050005, "dist_entropy": 0.6282907843589782, "actor_grad_norm": 0.10020539909601212, "critic_grad_norm": 0.08476488292217255, "ratio": 0.9993880391120911, "entropy": 0.6282907843589782, "incre_win_rate": 0.9591836734693877, "step": 3031}
{"time": 1767166349.321434, "phase": "train", "update": 3032, "total_env_steps": 9702400, "episode_reward": 0.27227649092674255, "value_loss": 0.011395295709371566, "policy_loss": -0.0013543675214009454, "dist_entropy": 0.6237610936164856, "actor_grad_norm": 0.095621258020401, "critic_grad_norm": 0.10100217908620834, "ratio": 1.0000152587890625, "entropy": 0.6237610936164856, "incre_win_rate": 0.8043478260869565, "step": 3032}
{"time": 1767166353.665431, "phase": "train", "update": 3033, "total_env_steps": 9705600, "episode_reward": 0.2678280174732208, "value_loss": 0.010571340285241603, "policy_loss": -0.0013644738379667842, "dist_entropy": 0.6068653345108033, "actor_grad_norm": 0.10201606899499893, "critic_grad_norm": 0.05512698367238045, "ratio": 0.9999527335166931, "entropy": 0.6068653345108033, "incre_win_rate": 0.7906976744186046, "step": 3033}
{"time": 1767166358.017391, "phase": "train", "update": 3034, "total_env_steps": 9708800, "episode_reward": 0.2830546498298645, "value_loss": 0.00902375690639019, "policy_loss": -0.0014559444775862572, "dist_entropy": 0.6251762866973877, "actor_grad_norm": 0.10392359644174576, "critic_grad_norm": 0.043349750339984894, "ratio": 0.9998453259468079, "entropy": 0.6251762866973877, "incre_win_rate": 0.8367346938775511, "step": 3034}
{"time": 1767166362.4071972, "phase": "train", "update": 3035, "total_env_steps": 9712000, "episode_reward": 0.28308308124542236, "value_loss": 0.007281713932752609, "policy_loss": -0.001181929247930924, "dist_entropy": 0.6295315384864807, "actor_grad_norm": 0.1042272076010704, "critic_grad_norm": 0.04633304849267006, "ratio": 0.9998451471328735, "entropy": 0.6295315384864807, "incre_win_rate": 0.8695652173913043, "step": 3035}
{"time": 1767166366.7863908, "phase": "train", "update": 3036, "total_env_steps": 9715200, "episode_reward": 0.28367292881011963, "value_loss": 0.010814102925360202, "policy_loss": -0.0017002445882582152, "dist_entropy": 0.6112190246582031, "actor_grad_norm": 0.0914817526936531, "critic_grad_norm": 0.1228133961558342, "ratio": 0.9996455311775208, "entropy": 0.6112190246582031, "incre_win_rate": 0.8936170212765957, "step": 3036}
{"time": 1767166371.1447222, "phase": "train", "update": 3037, "total_env_steps": 9718400, "episode_reward": 0.28610825538635254, "value_loss": 0.00947199370712042, "policy_loss": -0.0012604264859405133, "dist_entropy": 0.6409188866615295, "actor_grad_norm": 0.08200394362211227, "critic_grad_norm": 0.08547935634851456, "ratio": 1.0001304149627686, "entropy": 0.6409188866615295, "incre_win_rate": 0.7959183673469388, "step": 3037}
{"time": 1767166375.4805067, "phase": "train", "update": 3038, "total_env_steps": 9721600, "episode_reward": 0.2799912393093109, "value_loss": 0.008842479251325131, "policy_loss": -0.0011019518236544457, "dist_entropy": 0.625871479511261, "actor_grad_norm": 0.07705651968717575, "critic_grad_norm": 0.08343278616666794, "ratio": 0.9998569488525391, "entropy": 0.625871479511261, "incre_win_rate": 0.8723404255319149, "step": 3038}
{"time": 1767166379.7942443, "phase": "train", "update": 3039, "total_env_steps": 9724800, "episode_reward": 0.27199557423591614, "value_loss": 0.009553966298699378, "policy_loss": -0.0010406302306506631, "dist_entropy": 0.6188771605491639, "actor_grad_norm": 0.068429134786129, "critic_grad_norm": 0.06221679970622063, "ratio": 1.0000847578048706, "entropy": 0.6188771605491639, "incre_win_rate": 0.7727272727272727, "step": 3039}
{"time": 1767166384.1624773, "phase": "train", "update": 3040, "total_env_steps": 9728000, "episode_reward": 0.2730158269405365, "value_loss": 0.011610752530395984, "policy_loss": -0.0017256852339956551, "dist_entropy": 0.6285038948059082, "actor_grad_norm": 0.08627309650182724, "critic_grad_norm": 0.04405882954597473, "ratio": 0.9996399879455566, "entropy": 0.6285038948059082, "incre_win_rate": 0.7659574468085106, "step": 3040}
{"time": 1767166388.5571392, "phase": "train", "update": 3041, "total_env_steps": 9731200, "episode_reward": 0.28430670499801636, "value_loss": 0.008574694395065308, "policy_loss": -0.0017153001725176864, "dist_entropy": 0.6047748446464538, "actor_grad_norm": 0.09239619225263596, "critic_grad_norm": 0.11886660009622574, "ratio": 1.0003911256790161, "entropy": 0.6047748446464538, "incre_win_rate": 0.8478260869565217, "step": 3041}
{"time": 1767166397.6351242, "phase": "eval", "update": 3041, "total_env_steps": 9731200, "eval_win_rate": 0.875, "eval_episode_reward": 19.39259105960265, "step": 3041}
{"time": 1767166401.9931476, "phase": "train", "update": 3042, "total_env_steps": 9734400, "episode_reward": 0.2794681489467621, "value_loss": 0.007947880122810603, "policy_loss": -0.0015446515841031072, "dist_entropy": 0.6250164628028869, "actor_grad_norm": 0.09041937440633774, "critic_grad_norm": 0.06792537868022919, "ratio": 0.9997406005859375, "entropy": 0.6250164628028869, "incre_win_rate": 0.8723404255319149, "step": 3042}
{"time": 1767166406.3838136, "phase": "train", "update": 3043, "total_env_steps": 9737600, "episode_reward": 0.2848183810710907, "value_loss": 0.009407460130751133, "policy_loss": -0.0009019307188502523, "dist_entropy": 0.6262181162834167, "actor_grad_norm": 0.07831566035747528, "critic_grad_norm": 0.05781373009085655, "ratio": 1.0001803636550903, "entropy": 0.6262181162834167, "incre_win_rate": 0.8297872340425532, "step": 3043}
{"time": 1767166410.758955, "phase": "train", "update": 3044, "total_env_steps": 9740800, "episode_reward": 0.2815568149089813, "value_loss": 0.0067972525954246524, "policy_loss": -0.0013197297226547277, "dist_entropy": 0.6299674153327942, "actor_grad_norm": 0.08529361337423325, "critic_grad_norm": 0.052130069583654404, "ratio": 1.0003455877304077, "entropy": 0.6299674153327942, "incre_win_rate": 0.8723404255319149, "step": 3044}
{"time": 1767166415.1341183, "phase": "train", "update": 3045, "total_env_steps": 9744000, "episode_reward": 0.2744717597961426, "value_loss": 0.007675284706056118, "policy_loss": -0.0014016510240992374, "dist_entropy": 0.6384767651557922, "actor_grad_norm": 0.07549121975898743, "critic_grad_norm": 0.06128585338592529, "ratio": 0.9999718070030212, "entropy": 0.6384767651557922, "incre_win_rate": 0.8478260869565217, "step": 3045}
{"time": 1767166419.5503218, "phase": "train", "update": 3046, "total_env_steps": 9747200, "episode_reward": 0.2697816789150238, "value_loss": 0.010875150561332703, "policy_loss": -0.0017243147313990904, "dist_entropy": 0.6600084066390991, "actor_grad_norm": 0.0815340206027031, "critic_grad_norm": 0.1414199322462082, "ratio": 0.999809205532074, "entropy": 0.6600084066390991, "incre_win_rate": 0.7333333333333333, "step": 3046}
{"time": 1767166423.9167845, "phase": "train", "update": 3047, "total_env_steps": 9750400, "episode_reward": 0.2684261202812195, "value_loss": 0.01026472207158804, "policy_loss": -0.0014070200747937633, "dist_entropy": 0.6800549983978271, "actor_grad_norm": 0.08908506482839584, "critic_grad_norm": 0.11205627769231796, "ratio": 0.9997937083244324, "entropy": 0.6800549983978271, "incre_win_rate": 0.7872340425531915, "step": 3047}
{"time": 1767166428.2698126, "phase": "train", "update": 3048, "total_env_steps": 9753600, "episode_reward": 0.2726629972457886, "value_loss": 0.009641222469508649, "policy_loss": -0.0014833803134802538, "dist_entropy": 0.6227804899215699, "actor_grad_norm": 0.08198060840368271, "critic_grad_norm": 0.11154093593358994, "ratio": 1.000011682510376, "entropy": 0.6227804899215699, "incre_win_rate": 0.8666666666666667, "step": 3048}
{"time": 1767166432.6256244, "phase": "train", "update": 3049, "total_env_steps": 9756800, "episode_reward": 0.2811371982097626, "value_loss": 0.006026296224445104, "policy_loss": -0.0013874490608486666, "dist_entropy": 0.6457589983940124, "actor_grad_norm": 0.08178360760211945, "critic_grad_norm": 0.15106609463691711, "ratio": 0.9999832510948181, "entropy": 0.6457589983940124, "incre_win_rate": 0.9333333333333333, "step": 3049}
{"time": 1767166436.981445, "phase": "train", "update": 3050, "total_env_steps": 9760000, "episode_reward": 0.2791784107685089, "value_loss": 0.006529068294912577, "policy_loss": -0.001579707014906262, "dist_entropy": 0.6371300697326661, "actor_grad_norm": 0.08971714228391647, "critic_grad_norm": 0.07689376920461655, "ratio": 0.9998663067817688, "entropy": 0.6371300697326661, "incre_win_rate": 0.8043478260869565, "step": 3050}
{"time": 1767166441.338471, "phase": "train", "update": 3051, "total_env_steps": 9763200, "episode_reward": 0.28126296401023865, "value_loss": 0.00949033685028553, "policy_loss": -0.0010396847956592125, "dist_entropy": 0.6429473876953125, "actor_grad_norm": 0.08127962797880173, "critic_grad_norm": 0.050680965185165405, "ratio": 0.9999033808708191, "entropy": 0.6429473876953125, "incre_win_rate": 0.8085106382978723, "step": 3051}
{"time": 1767166445.7571673, "phase": "train", "update": 3052, "total_env_steps": 9766400, "episode_reward": 0.27508899569511414, "value_loss": 0.011018087714910507, "policy_loss": -0.0017576168320033504, "dist_entropy": 0.6363680124282837, "actor_grad_norm": 0.09702155739068985, "critic_grad_norm": 0.17314738035202026, "ratio": 0.9996967315673828, "entropy": 0.6363680124282837, "incre_win_rate": 0.7446808510638298, "step": 3052}
{"time": 1767166450.1743355, "phase": "train", "update": 3053, "total_env_steps": 9769600, "episode_reward": 0.2716256380081177, "value_loss": 0.010978352278470993, "policy_loss": -0.0013871021483922163, "dist_entropy": 0.6128023386001586, "actor_grad_norm": 0.11379797756671906, "critic_grad_norm": 0.13659639656543732, "ratio": 1.000198483467102, "entropy": 0.6128023386001586, "incre_win_rate": 0.7916666666666666, "step": 3053}
{"time": 1767166454.556548, "phase": "train", "update": 3054, "total_env_steps": 9772800, "episode_reward": 0.2863689959049225, "value_loss": 0.009348541498184204, "policy_loss": -0.0013877263728261369, "dist_entropy": 0.6235689759254456, "actor_grad_norm": 0.11192726343870163, "critic_grad_norm": 0.1675986349582672, "ratio": 1.0002371072769165, "entropy": 0.6235689759254456, "incre_win_rate": 0.8541666666666666, "step": 3054}
{"time": 1767166458.9351375, "phase": "train", "update": 3055, "total_env_steps": 9776000, "episode_reward": 0.2887215316295624, "value_loss": 0.009213514998555184, "policy_loss": -0.0012961816739817777, "dist_entropy": 0.620367169380188, "actor_grad_norm": 0.07511215656995773, "critic_grad_norm": 0.12544813752174377, "ratio": 1.0001661777496338, "entropy": 0.620367169380188, "incre_win_rate": 0.8260869565217391, "step": 3055}
{"time": 1767166463.3379507, "phase": "train", "update": 3056, "total_env_steps": 9779200, "episode_reward": 0.2934452295303345, "value_loss": 0.007834648620337248, "policy_loss": -0.0014235859127103012, "dist_entropy": 0.6521182179450988, "actor_grad_norm": 0.10483600944280624, "critic_grad_norm": 0.12698006629943848, "ratio": 1.00011146068573, "entropy": 0.6521182179450988, "incre_win_rate": 0.8979591836734694, "step": 3056}
{"time": 1767166467.7255883, "phase": "train", "update": 3057, "total_env_steps": 9782400, "episode_reward": 0.28463679552078247, "value_loss": 0.007643911428749562, "policy_loss": -0.0013105365708947047, "dist_entropy": 0.6195914268493652, "actor_grad_norm": 0.08872783184051514, "critic_grad_norm": 0.08826347440481186, "ratio": 1.0002906322479248, "entropy": 0.6195914268493652, "incre_win_rate": 0.851063829787234, "step": 3057}
{"time": 1767166472.1353157, "phase": "train", "update": 3058, "total_env_steps": 9785600, "episode_reward": 0.28757244348526, "value_loss": 0.005860380828380585, "policy_loss": -0.0011716360851778517, "dist_entropy": 0.6178658962249756, "actor_grad_norm": 0.08379208296537399, "critic_grad_norm": 0.06991317123174667, "ratio": 1.0000447034835815, "entropy": 0.6178658962249756, "incre_win_rate": 0.8541666666666666, "step": 3058}
{"time": 1767166476.5405297, "phase": "train", "update": 3059, "total_env_steps": 9788800, "episode_reward": 0.29233601689338684, "value_loss": 0.007790469564497471, "policy_loss": -0.0010642688055554571, "dist_entropy": 0.6380641102790833, "actor_grad_norm": 0.0721738263964653, "critic_grad_norm": 0.07974420487880707, "ratio": 1.0000418424606323, "entropy": 0.6380641102790833, "incre_win_rate": 0.8958333333333334, "step": 3059}
{"time": 1767166480.9497979, "phase": "train", "update": 3060, "total_env_steps": 9792000, "episode_reward": 0.2864186763763428, "value_loss": 0.007835744228214026, "policy_loss": -0.0010194647208862761, "dist_entropy": 0.6525046229362488, "actor_grad_norm": 0.08306754380464554, "critic_grad_norm": 0.0727810487151146, "ratio": 0.9996793866157532, "entropy": 0.6525046229362488, "incre_win_rate": 0.8888888888888888, "step": 3060}
{"time": 1767166485.3511007, "phase": "train", "update": 3061, "total_env_steps": 9795200, "episode_reward": 0.27600112557411194, "value_loss": 0.006458557862788439, "policy_loss": -0.001465225826005323, "dist_entropy": 0.654387104511261, "actor_grad_norm": 0.08077188581228256, "critic_grad_norm": 0.05700491741299629, "ratio": 1.0000094175338745, "entropy": 0.654387104511261, "incre_win_rate": 0.8936170212765957, "step": 3061}
{"time": 1767166494.4506967, "phase": "eval", "update": 3061, "total_env_steps": 9795200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.672909768211923, "step": 3061}
{"time": 1767166498.8404505, "phase": "train", "update": 3062, "total_env_steps": 9798400, "episode_reward": 0.28089144825935364, "value_loss": 0.006834268476814032, "policy_loss": -0.0014460466803267735, "dist_entropy": 0.6516802906990051, "actor_grad_norm": 0.09242859482765198, "critic_grad_norm": 0.07069219648838043, "ratio": 1.0000264644622803, "entropy": 0.6516802906990051, "incre_win_rate": 0.8085106382978723, "step": 3062}
{"time": 1767166503.2426324, "phase": "train", "update": 3063, "total_env_steps": 9801600, "episode_reward": 0.28437551856040955, "value_loss": 0.007357936166226864, "policy_loss": -0.0011343261637492218, "dist_entropy": 0.6392711520195007, "actor_grad_norm": 0.08914536237716675, "critic_grad_norm": 0.0405711829662323, "ratio": 0.9999874234199524, "entropy": 0.6392711520195007, "incre_win_rate": 0.8541666666666666, "step": 3063}
{"time": 1767166507.6269011, "phase": "train", "update": 3064, "total_env_steps": 9804800, "episode_reward": 0.2833123207092285, "value_loss": 0.0065463571809232235, "policy_loss": -0.0015102794924928276, "dist_entropy": 0.6498913526535034, "actor_grad_norm": 0.08719505369663239, "critic_grad_norm": 0.05736752972006798, "ratio": 0.999602735042572, "entropy": 0.6498913526535034, "incre_win_rate": 0.9347826086956522, "step": 3064}
{"time": 1767166511.9837387, "phase": "train", "update": 3065, "total_env_steps": 9808000, "episode_reward": 0.2808811068534851, "value_loss": 0.007910818327218294, "policy_loss": -0.001307040428530648, "dist_entropy": 0.6243228554725647, "actor_grad_norm": 0.08008783310651779, "critic_grad_norm": 0.0462823286652565, "ratio": 0.9998127818107605, "entropy": 0.6243228554725647, "incre_win_rate": 0.8478260869565217, "step": 3065}
{"time": 1767166516.3549342, "phase": "train", "update": 3066, "total_env_steps": 9811200, "episode_reward": 0.2797118127346039, "value_loss": 0.009611602127552032, "policy_loss": -0.0015661064435612104, "dist_entropy": 0.6194858908653259, "actor_grad_norm": 0.08309293538331985, "critic_grad_norm": 0.058807529509067535, "ratio": 0.999384880065918, "entropy": 0.6194858908653259, "incre_win_rate": 0.7872340425531915, "step": 3066}
{"time": 1767166520.7018857, "phase": "train", "update": 3067, "total_env_steps": 9814400, "episode_reward": 0.287535160779953, "value_loss": 0.009574305824935436, "policy_loss": -0.0014022952188291527, "dist_entropy": 0.6292150020599365, "actor_grad_norm": 0.12578245997428894, "critic_grad_norm": 0.0772065743803978, "ratio": 1.000120759010315, "entropy": 0.6292150020599365, "incre_win_rate": 0.8571428571428571, "step": 3067}
{"time": 1767166525.1513073, "phase": "train", "update": 3068, "total_env_steps": 9817600, "episode_reward": 0.2854222059249878, "value_loss": 0.010729250498116016, "policy_loss": -0.001580994490906562, "dist_entropy": 0.6165851593017578, "actor_grad_norm": 0.0927322506904602, "critic_grad_norm": 0.07011041045188904, "ratio": 1.000069260597229, "entropy": 0.6165851593017578, "incre_win_rate": 0.8333333333333334, "step": 3068}
{"time": 1767166529.603674, "phase": "train", "update": 3069, "total_env_steps": 9820800, "episode_reward": 0.29111236333847046, "value_loss": 0.008617477864027024, "policy_loss": -0.0012017224831218699, "dist_entropy": 0.625678277015686, "actor_grad_norm": 0.0778009295463562, "critic_grad_norm": 0.06005517393350601, "ratio": 1.000307559967041, "entropy": 0.625678277015686, "incre_win_rate": 0.875, "step": 3069}
{"time": 1767166533.9999223, "phase": "train", "update": 3070, "total_env_steps": 9824000, "episode_reward": 0.2849673926830292, "value_loss": 0.009999762661755085, "policy_loss": -0.0010456534432741194, "dist_entropy": 0.63998441696167, "actor_grad_norm": 0.0844973623752594, "critic_grad_norm": 0.09439288079738617, "ratio": 0.9996137619018555, "entropy": 0.63998441696167, "incre_win_rate": 0.7872340425531915, "step": 3070}
{"time": 1767166538.409571, "phase": "train", "update": 3071, "total_env_steps": 9827200, "episode_reward": 0.27834129333496094, "value_loss": 0.010923300124704837, "policy_loss": -0.0013204050465510874, "dist_entropy": 0.6579936623573304, "actor_grad_norm": 0.08450572937726974, "critic_grad_norm": 0.10988998413085938, "ratio": 1.0000405311584473, "entropy": 0.6579936623573304, "incre_win_rate": 0.8085106382978723, "step": 3071}
{"time": 1767166542.8182778, "phase": "train", "update": 3072, "total_env_steps": 9830400, "episode_reward": 0.2791784107685089, "value_loss": 0.010441318154335022, "policy_loss": -0.001423622574692729, "dist_entropy": 0.6552691578865051, "actor_grad_norm": 0.07923418283462524, "critic_grad_norm": 0.072462297976017, "ratio": 1.0000357627868652, "entropy": 0.6552691578865051, "incre_win_rate": 0.8297872340425532, "step": 3072}
{"time": 1767166547.188538, "phase": "train", "update": 3073, "total_env_steps": 9833600, "episode_reward": 0.2683490216732025, "value_loss": 0.011718633025884629, "policy_loss": -0.001384405092446883, "dist_entropy": 0.6314257740974426, "actor_grad_norm": 0.09441878646612167, "critic_grad_norm": 0.0769263282418251, "ratio": 1.0000523328781128, "entropy": 0.6314257740974426, "incre_win_rate": 0.7555555555555555, "step": 3073}
{"time": 1767166551.5495665, "phase": "train", "update": 3074, "total_env_steps": 9836800, "episode_reward": 0.2731788158416748, "value_loss": 0.009349560923874378, "policy_loss": -0.0010540425500146, "dist_entropy": 0.6477067112922669, "actor_grad_norm": 0.07800126075744629, "critic_grad_norm": 0.057791437953710556, "ratio": 0.9999300837516785, "entropy": 0.6477067112922669, "incre_win_rate": 0.8260869565217391, "step": 3074}
{"time": 1767166555.9088566, "phase": "train", "update": 3075, "total_env_steps": 9840000, "episode_reward": 0.268482506275177, "value_loss": 0.010572858154773712, "policy_loss": -0.0015706119050150845, "dist_entropy": 0.6319405198097229, "actor_grad_norm": 0.08787482976913452, "critic_grad_norm": 0.11821191757917404, "ratio": 1.0002950429916382, "entropy": 0.6319405198097229, "incre_win_rate": 0.8222222222222222, "step": 3075}
{"time": 1767166560.2492852, "phase": "train", "update": 3076, "total_env_steps": 9843200, "episode_reward": 0.2729739248752594, "value_loss": 0.010353333689272404, "policy_loss": -0.0013545330262772382, "dist_entropy": 0.6496707916259765, "actor_grad_norm": 0.08527081459760666, "critic_grad_norm": 0.12607048451900482, "ratio": 0.999825656414032, "entropy": 0.6496707916259765, "incre_win_rate": 0.7659574468085106, "step": 3076}
{"time": 1767166564.636413, "phase": "train", "update": 3077, "total_env_steps": 9846400, "episode_reward": 0.281127393245697, "value_loss": 0.009174634516239167, "policy_loss": -0.0015548372288222367, "dist_entropy": 0.6461422920227051, "actor_grad_norm": 0.08604460209608078, "critic_grad_norm": 0.12500865757465363, "ratio": 1.0000253915786743, "entropy": 0.6461422920227051, "incre_win_rate": 0.8636363636363636, "step": 3077}
{"time": 1767166569.0512016, "phase": "train", "update": 3078, "total_env_steps": 9849600, "episode_reward": 0.2698473632335663, "value_loss": 0.009984732791781425, "policy_loss": -0.0015112656440280149, "dist_entropy": 0.6767547249794006, "actor_grad_norm": 0.08340869843959808, "critic_grad_norm": 0.08675729483366013, "ratio": 1.0000004768371582, "entropy": 0.6767547249794006, "incre_win_rate": 0.7755102040816326, "step": 3078}
{"time": 1767166573.454405, "phase": "train", "update": 3079, "total_env_steps": 9852800, "episode_reward": 0.28742343187332153, "value_loss": 0.007169677596539259, "policy_loss": -0.0013505555412564262, "dist_entropy": 0.6437278747558594, "actor_grad_norm": 0.08970929682254791, "critic_grad_norm": 0.1802472025156021, "ratio": 0.9997691512107849, "entropy": 0.6437278747558594, "incre_win_rate": 0.9574468085106383, "step": 3079}
{"time": 1767166577.7952166, "phase": "train", "update": 3080, "total_env_steps": 9856000, "episode_reward": 0.2781534492969513, "value_loss": 0.007484990078955889, "policy_loss": -0.0019751650574002964, "dist_entropy": 0.6415332674980163, "actor_grad_norm": 0.1033053770661354, "critic_grad_norm": 0.0806378722190857, "ratio": 1.000074863433838, "entropy": 0.6415332674980163, "incre_win_rate": 0.8444444444444444, "step": 3080}
{"time": 1767166582.1606472, "phase": "train", "update": 3081, "total_env_steps": 9859200, "episode_reward": 0.27621325850486755, "value_loss": 0.006200745515525341, "policy_loss": -0.0012460076324558144, "dist_entropy": 0.6355558633804321, "actor_grad_norm": 0.08588911592960358, "critic_grad_norm": 0.058611590415239334, "ratio": 1.0001410245895386, "entropy": 0.6355558633804321, "incre_win_rate": 0.8888888888888888, "step": 3081}
{"time": 1767166591.3358731, "phase": "eval", "update": 3081, "total_env_steps": 9859200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.598302980132452, "step": 3081}
{"time": 1767166595.673218, "phase": "train", "update": 3082, "total_env_steps": 9862400, "episode_reward": 0.2780960202217102, "value_loss": 0.006409309338778257, "policy_loss": -0.0015135350856738227, "dist_entropy": 0.6408048272132874, "actor_grad_norm": 0.08051920682191849, "critic_grad_norm": 0.05008618161082268, "ratio": 1.0000494718551636, "entropy": 0.6408048272132874, "incre_win_rate": 0.9148936170212766, "step": 3082}
{"time": 1767166600.0605314, "phase": "train", "update": 3083, "total_env_steps": 9865600, "episode_reward": 0.27341940999031067, "value_loss": 0.005414255708456039, "policy_loss": -0.0013824971914907281, "dist_entropy": 0.65737544298172, "actor_grad_norm": 0.08175564557313919, "critic_grad_norm": 0.08058317750692368, "ratio": 0.9998854994773865, "entropy": 0.65737544298172, "incre_win_rate": 0.8837209302325582, "step": 3083}
{"time": 1767166604.4928098, "phase": "train", "update": 3084, "total_env_steps": 9868800, "episode_reward": 0.279934823513031, "value_loss": 0.005139713827520609, "policy_loss": -0.0012905995194955721, "dist_entropy": 0.6619414329528809, "actor_grad_norm": 0.07885324954986572, "critic_grad_norm": 0.03965682163834572, "ratio": 1.000242829322815, "entropy": 0.6619414329528809, "incre_win_rate": 0.9347826086956522, "step": 3084}
{"time": 1767166608.8351185, "phase": "train", "update": 3085, "total_env_steps": 9872000, "episode_reward": 0.27571606636047363, "value_loss": 0.005116291902959346, "policy_loss": -0.001621960661632471, "dist_entropy": 0.6507647514343262, "actor_grad_norm": 0.0949743241071701, "critic_grad_norm": 0.0594857893884182, "ratio": 1.000147819519043, "entropy": 0.6507647514343262, "incre_win_rate": 0.8444444444444444, "step": 3085}
{"time": 1767166613.221219, "phase": "train", "update": 3086, "total_env_steps": 9875200, "episode_reward": 0.28230029344558716, "value_loss": 0.005967998784035445, "policy_loss": -0.0015522980261103215, "dist_entropy": 0.650821042060852, "actor_grad_norm": 0.0850270539522171, "critic_grad_norm": 0.05609956011176109, "ratio": 1.00022554397583, "entropy": 0.650821042060852, "incre_win_rate": 0.9130434782608695, "step": 3086}
{"time": 1767166617.5858905, "phase": "train", "update": 3087, "total_env_steps": 9878400, "episode_reward": 0.2736206352710724, "value_loss": 0.008686057291924953, "policy_loss": -0.0013251526505173139, "dist_entropy": 0.6534042239189148, "actor_grad_norm": 0.07831702381372452, "critic_grad_norm": 0.0619935467839241, "ratio": 1.0000272989273071, "entropy": 0.6534042239189148, "incre_win_rate": 0.851063829787234, "step": 3087}
{"time": 1767166621.8902044, "phase": "train", "update": 3088, "total_env_steps": 9881600, "episode_reward": 0.275246798992157, "value_loss": 0.007387806568294764, "policy_loss": -0.0011945188611854007, "dist_entropy": 0.6812534689903259, "actor_grad_norm": 0.07952354103326797, "critic_grad_norm": 0.054424431174993515, "ratio": 0.9999807476997375, "entropy": 0.6812534689903259, "incre_win_rate": 0.9090909090909091, "step": 3088}
{"time": 1767166626.2346888, "phase": "train", "update": 3089, "total_env_steps": 9884800, "episode_reward": 0.2797345817089081, "value_loss": 0.005430051870644092, "policy_loss": -0.0015482411260236972, "dist_entropy": 0.6437501788139344, "actor_grad_norm": 0.0857308879494667, "critic_grad_norm": 0.10057087242603302, "ratio": 0.9999740719795227, "entropy": 0.6437501788139344, "incre_win_rate": 0.9347826086956522, "step": 3089}
{"time": 1767166630.601447, "phase": "train", "update": 3090, "total_env_steps": 9888000, "episode_reward": 0.28197020292282104, "value_loss": 0.004980126116424799, "policy_loss": -0.002116130637318747, "dist_entropy": 0.6478564620018006, "actor_grad_norm": 0.10141988098621368, "critic_grad_norm": 0.05059003829956055, "ratio": 0.9998159408569336, "entropy": 0.6478564620018006, "incre_win_rate": 0.9565217391304348, "step": 3090}
{"time": 1767166634.9191399, "phase": "train", "update": 3091, "total_env_steps": 9891200, "episode_reward": 0.27330195903778076, "value_loss": 0.004223487246781588, "policy_loss": -0.0015078982715805544, "dist_entropy": 0.6422153830528259, "actor_grad_norm": 0.09680329263210297, "critic_grad_norm": 0.029195407405495644, "ratio": 0.9998794794082642, "entropy": 0.6422153830528259, "incre_win_rate": 0.9302325581395349, "step": 3091}
{"time": 1767166639.288257, "phase": "train", "update": 3092, "total_env_steps": 9894400, "episode_reward": 0.27404800057411194, "value_loss": 0.005806937161833048, "policy_loss": -0.0009794756468850974, "dist_entropy": 0.6496278285980225, "actor_grad_norm": 0.09396930038928986, "critic_grad_norm": 0.1005973368883133, "ratio": 1.0001686811447144, "entropy": 0.6496278285980225, "incre_win_rate": 0.8723404255319149, "step": 3092}
{"time": 1767166643.6669877, "phase": "train", "update": 3093, "total_env_steps": 9897600, "episode_reward": 0.28746169805526733, "value_loss": 0.0029535491950809954, "policy_loss": -0.0010220697059196483, "dist_entropy": 0.6687161803245545, "actor_grad_norm": 0.08333396911621094, "critic_grad_norm": 0.060076069086790085, "ratio": 1.0001890659332275, "entropy": 0.6687161803245545, "incre_win_rate": 0.9777777777777777, "step": 3093}
{"time": 1767166647.9784153, "phase": "train", "update": 3094, "total_env_steps": 9900800, "episode_reward": 0.28024008870124817, "value_loss": 0.00788015965372324, "policy_loss": -0.0011311679289150334, "dist_entropy": 0.6767385244369507, "actor_grad_norm": 0.0830186977982521, "critic_grad_norm": 0.059235990047454834, "ratio": 0.9999874234199524, "entropy": 0.6767385244369507, "incre_win_rate": 0.9111111111111111, "step": 3094}
{"time": 1767166652.2711463, "phase": "train", "update": 3095, "total_env_steps": 9904000, "episode_reward": 0.27508434653282166, "value_loss": 0.005414162203669548, "policy_loss": -0.001356735487297911, "dist_entropy": 0.6849185585975647, "actor_grad_norm": 0.09965446591377258, "critic_grad_norm": 0.07006543129682541, "ratio": 1.0002031326293945, "entropy": 0.6849185585975647, "incre_win_rate": 0.8260869565217391, "step": 3095}
{"time": 1767166656.5904093, "phase": "train", "update": 3096, "total_env_steps": 9907200, "episode_reward": 0.28274214267730713, "value_loss": 0.006918550748378038, "policy_loss": -0.001324689670342849, "dist_entropy": 0.6672445774078369, "actor_grad_norm": 0.09144321829080582, "critic_grad_norm": 0.054701365530490875, "ratio": 1.0000698566436768, "entropy": 0.6672445774078369, "incre_win_rate": 0.8936170212765957, "step": 3096}
{"time": 1767166660.951767, "phase": "train", "update": 3097, "total_env_steps": 9910400, "episode_reward": 0.28933775424957275, "value_loss": 0.003387173404917121, "policy_loss": -0.0012695960646610161, "dist_entropy": 0.6729941844940186, "actor_grad_norm": 0.09360217303037643, "critic_grad_norm": 0.07547751069068909, "ratio": 1.0000790357589722, "entropy": 0.6729941844940186, "incre_win_rate": 0.9565217391304348, "step": 3097}
{"time": 1767166665.290372, "phase": "train", "update": 3098, "total_env_steps": 9913600, "episode_reward": 0.277411550283432, "value_loss": 0.0064565369859337805, "policy_loss": -0.0015997331111215374, "dist_entropy": 0.6655459403991699, "actor_grad_norm": 0.08822949230670929, "critic_grad_norm": 0.17174427211284637, "ratio": 0.9996530413627625, "entropy": 0.6655459403991699, "incre_win_rate": 0.8695652173913043, "step": 3098}
{"time": 1767166669.5969808, "phase": "train", "update": 3099, "total_env_steps": 9916800, "episode_reward": 0.2779563367366791, "value_loss": 0.00919413547962904, "policy_loss": -0.0017044130542764435, "dist_entropy": 0.6446794629096985, "actor_grad_norm": 0.09575138241052628, "critic_grad_norm": 0.11060551553964615, "ratio": 0.9996787309646606, "entropy": 0.6446794629096985, "incre_win_rate": 0.8695652173913043, "step": 3099}
{"time": 1767166673.943698, "phase": "train", "update": 3100, "total_env_steps": 9920000, "episode_reward": 0.27915823459625244, "value_loss": 0.007629498094320297, "policy_loss": -0.0010489199264029025, "dist_entropy": 0.6428147196769715, "actor_grad_norm": 0.08744502812623978, "critic_grad_norm": 0.10237663239240646, "ratio": 0.999454915523529, "entropy": 0.6428147196769715, "incre_win_rate": 0.8695652173913043, "step": 3100}
{"time": 1767166678.2504182, "phase": "train", "update": 3101, "total_env_steps": 9923200, "episode_reward": 0.28431394696235657, "value_loss": 0.004169380944222212, "policy_loss": -0.0013503733321954315, "dist_entropy": 0.6354556918144226, "actor_grad_norm": 0.1044822484254837, "critic_grad_norm": 0.12299180030822754, "ratio": 1.0000125169754028, "entropy": 0.6354556918144226, "incre_win_rate": 0.9787234042553191, "step": 3101}
{"time": 1767166688.2084029, "phase": "eval", "update": 3101, "total_env_steps": 9923200, "eval_win_rate": 0.875, "eval_episode_reward": 19.538855546357617, "step": 3101}
{"time": 1767166692.453535, "phase": "train", "update": 3102, "total_env_steps": 9926400, "episode_reward": 0.27137261629104614, "value_loss": 0.006539544276893139, "policy_loss": -0.0017360029702516045, "dist_entropy": 0.6630787372589111, "actor_grad_norm": 0.11720038950443268, "critic_grad_norm": 0.0803479328751564, "ratio": 0.9995718002319336, "entropy": 0.6630787372589111, "incre_win_rate": 0.8695652173913043, "step": 3102}
{"time": 1767166726.1607757, "phase": "train", "update": 3103, "total_env_steps": 9929600, "episode_reward": 0.2760394215583801, "value_loss": 0.0528348945081234, "policy_loss": -0.0010324141228946538, "dist_entropy": 0.627513337135315, "actor_grad_norm": 0.06836673617362976, "critic_grad_norm": 0.29381269216537476, "ratio": 0.9999784827232361, "entropy": 0.627513337135315, "incre_win_rate": 0.9069767441860465, "step": 3103}
{"time": 1767166730.4142206, "phase": "train", "update": 3104, "total_env_steps": 9932800, "episode_reward": 0.27597683668136597, "value_loss": 0.004673920292407274, "policy_loss": -0.0012309886401176584, "dist_entropy": 0.6477989673614502, "actor_grad_norm": 0.08405666798353195, "critic_grad_norm": 0.15615788102149963, "ratio": 0.9994813799858093, "entropy": 0.6477989673614502, "incre_win_rate": 0.975609756097561, "step": 3104}
{"time": 1767166734.6867297, "phase": "train", "update": 3105, "total_env_steps": 9936000, "episode_reward": 0.2816597819328308, "value_loss": 0.005119217745959759, "policy_loss": -0.001455752733197535, "dist_entropy": 0.6532399892807007, "actor_grad_norm": 0.08175002783536911, "critic_grad_norm": 0.1457604169845581, "ratio": 0.9998349547386169, "entropy": 0.6532399892807007, "incre_win_rate": 0.9347826086956522, "step": 3105}
{"time": 1767166738.9104455, "phase": "train", "update": 3106, "total_env_steps": 9939200, "episode_reward": 0.2775765657424927, "value_loss": 0.0057815907523036, "policy_loss": -0.001348971175524838, "dist_entropy": 0.667177963256836, "actor_grad_norm": 0.08958621323108673, "critic_grad_norm": 0.09123803675174713, "ratio": 1.0003376007080078, "entropy": 0.667177963256836, "incre_win_rate": 0.8913043478260869, "step": 3106}
{"time": 1767166743.1943023, "phase": "train", "update": 3107, "total_env_steps": 9942400, "episode_reward": 0.2652095556259155, "value_loss": 0.004658221825957298, "policy_loss": -0.0009545040364471902, "dist_entropy": 0.6681850790977478, "actor_grad_norm": 0.07949893176555634, "critic_grad_norm": 0.09163036197423935, "ratio": 1.000217318534851, "entropy": 0.6681850790977478, "incre_win_rate": 0.8837209302325582, "step": 3107}
{"time": 1767166747.445937, "phase": "train", "update": 3108, "total_env_steps": 9945600, "episode_reward": 0.2773634195327759, "value_loss": 0.008751894347369671, "policy_loss": -0.0015360318800624385, "dist_entropy": 0.6595032691955567, "actor_grad_norm": 0.08799456804990768, "critic_grad_norm": 0.12687638401985168, "ratio": 1.0001450777053833, "entropy": 0.6595032691955567, "incre_win_rate": 0.8723404255319149, "step": 3108}
{"time": 1767166751.7370112, "phase": "train", "update": 3109, "total_env_steps": 9948800, "episode_reward": 0.26610204577445984, "value_loss": 0.007142629101872444, "policy_loss": -0.001862401971200711, "dist_entropy": 0.6426689743995666, "actor_grad_norm": 0.0968225821852684, "critic_grad_norm": 0.05927681922912598, "ratio": 1.0002076625823975, "entropy": 0.6426689743995666, "incre_win_rate": 0.8409090909090909, "step": 3109}
{"time": 1767166755.9796612, "phase": "train", "update": 3110, "total_env_steps": 9952000, "episode_reward": 0.27728787064552307, "value_loss": 0.0067083372734487055, "policy_loss": -0.0017137899689238622, "dist_entropy": 0.6384453177452087, "actor_grad_norm": 0.11965730041265488, "critic_grad_norm": 0.05420268699526787, "ratio": 0.9997855424880981, "entropy": 0.6384453177452087, "incre_win_rate": 0.8636363636363636, "step": 3110}
{"time": 1767166760.2370253, "phase": "train", "update": 3111, "total_env_steps": 9955200, "episode_reward": 0.2679190933704376, "value_loss": 0.0067448848858475685, "policy_loss": -0.0011986044093703185, "dist_entropy": 0.6436505079269409, "actor_grad_norm": 0.10097252577543259, "critic_grad_norm": 0.0377599373459816, "ratio": 1.000089168548584, "entropy": 0.6436505079269409, "incre_win_rate": 0.8723404255319149, "step": 3111}
{"time": 1767166764.4958687, "phase": "train", "update": 3112, "total_env_steps": 9958400, "episode_reward": 0.2688974440097809, "value_loss": 0.005527106579393148, "policy_loss": -0.0015570977339607773, "dist_entropy": 0.6535969138145447, "actor_grad_norm": 0.09433489292860031, "critic_grad_norm": 0.0288543738424778, "ratio": 1.0003526210784912, "entropy": 0.6535969138145447, "incre_win_rate": 0.8809523809523809, "step": 3112}
{"time": 1767166768.721653, "phase": "train", "update": 3113, "total_env_steps": 9961600, "episode_reward": 0.26047754287719727, "value_loss": 0.00886010993272066, "policy_loss": -0.0014857096811454085, "dist_entropy": 0.6467572927474976, "actor_grad_norm": 0.0775337964296341, "critic_grad_norm": 0.13500036299228668, "ratio": 1.0002046823501587, "entropy": 0.6467572927474976, "incre_win_rate": 0.7777777777777778, "step": 3113}
{"time": 1767166772.9876308, "phase": "train", "update": 3114, "total_env_steps": 9964800, "episode_reward": 0.2730106711387634, "value_loss": 0.006922945939004421, "policy_loss": -0.001791365461690475, "dist_entropy": 0.6599116683006286, "actor_grad_norm": 0.1114739179611206, "critic_grad_norm": 0.07964906096458435, "ratio": 0.9999178051948547, "entropy": 0.6599116683006286, "incre_win_rate": 0.9069767441860465, "step": 3114}
{"time": 1767166777.209382, "phase": "train", "update": 3115, "total_env_steps": 9968000, "episode_reward": 0.26906871795654297, "value_loss": 0.005248708929866552, "policy_loss": -0.0011953984775153082, "dist_entropy": 0.6288088798522949, "actor_grad_norm": 0.1057245060801506, "critic_grad_norm": 0.09552570432424545, "ratio": 0.9998669028282166, "entropy": 0.6288088798522949, "incre_win_rate": 0.9111111111111111, "step": 3115}
{"time": 1767166781.4925935, "phase": "train", "update": 3116, "total_env_steps": 9971200, "episode_reward": 0.2675056755542755, "value_loss": 0.008333748579025269, "policy_loss": -0.0012368385101979129, "dist_entropy": 0.609480082988739, "actor_grad_norm": 0.0802408829331398, "critic_grad_norm": 0.06718669831752777, "ratio": 1.00017511844635, "entropy": 0.609480082988739, "incre_win_rate": 0.8260869565217391, "step": 3116}
{"time": 1767166785.7733471, "phase": "train", "update": 3117, "total_env_steps": 9974400, "episode_reward": 0.27294546365737915, "value_loss": 0.0066677389666438104, "policy_loss": -0.0014781704555431486, "dist_entropy": 0.6303356409072876, "actor_grad_norm": 0.09305955469608307, "critic_grad_norm": 0.06204449012875557, "ratio": 0.9998623132705688, "entropy": 0.6303356409072876, "incre_win_rate": 0.8372093023255814, "step": 3117}
{"time": 1767166790.0424376, "phase": "train", "update": 3118, "total_env_steps": 9977600, "episode_reward": 0.280998557806015, "value_loss": 0.006427380349487066, "policy_loss": -0.0012562900532039124, "dist_entropy": 0.6244702577590943, "actor_grad_norm": 0.07278616726398468, "critic_grad_norm": 0.0588969849050045, "ratio": 0.9997158050537109, "entropy": 0.6244702577590943, "incre_win_rate": 0.8333333333333334, "step": 3118}
{"time": 1767166794.3610709, "phase": "train", "update": 3119, "total_env_steps": 9980800, "episode_reward": 0.27965283393859863, "value_loss": 0.004735040478408337, "policy_loss": -0.0012413874504069611, "dist_entropy": 0.6202780723571777, "actor_grad_norm": 0.08708646148443222, "critic_grad_norm": 0.04415915161371231, "ratio": 0.9999615550041199, "entropy": 0.6202780723571777, "incre_win_rate": 0.9333333333333333, "step": 3119}
{"time": 1767166798.6565723, "phase": "train", "update": 3120, "total_env_steps": 9984000, "episode_reward": 0.28209900856018066, "value_loss": 0.006258976738899946, "policy_loss": -0.001534677373988913, "dist_entropy": 0.6148296594619751, "actor_grad_norm": 0.08430884778499603, "critic_grad_norm": 0.09092701971530914, "ratio": 0.9998242259025574, "entropy": 0.6148296594619751, "incre_win_rate": 0.8695652173913043, "step": 3120}
{"time": 1767166802.955977, "phase": "train", "update": 3121, "total_env_steps": 9987200, "episode_reward": 0.2795581519603729, "value_loss": 0.006042663846164942, "policy_loss": -0.0011133293684011392, "dist_entropy": 0.6105299472808838, "actor_grad_norm": 0.09165456146001816, "critic_grad_norm": 0.0640980526804924, "ratio": 0.9996231198310852, "entropy": 0.6105299472808838, "incre_win_rate": 0.8723404255319149, "step": 3121}
{"time": 1767166812.4639857, "phase": "eval", "update": 3121, "total_env_steps": 9987200, "eval_win_rate": 1.0, "eval_episode_reward": 20.0, "step": 3121}
{"time": 1767166816.7407951, "phase": "train", "update": 3122, "total_env_steps": 9990400, "episode_reward": 0.2831043303012848, "value_loss": 0.007232162449508905, "policy_loss": -0.0015608001281538718, "dist_entropy": 0.6019852042198182, "actor_grad_norm": 0.08215203136205673, "critic_grad_norm": 0.10346837341785431, "ratio": 0.9997624754905701, "entropy": 0.6019852042198182, "incre_win_rate": 0.8936170212765957, "step": 3122}
{"time": 1767166821.0589862, "phase": "train", "update": 3123, "total_env_steps": 9993600, "episode_reward": 0.2835942506790161, "value_loss": 0.006399250309914351, "policy_loss": -0.0017012025126504683, "dist_entropy": 0.588550579547882, "actor_grad_norm": 0.10486345738172531, "critic_grad_norm": 0.081583671271801, "ratio": 1.0003160238265991, "entropy": 0.588550579547882, "incre_win_rate": 0.9130434782608695, "step": 3123}
{"time": 1767166825.3321838, "phase": "train", "update": 3124, "total_env_steps": 9996800, "episode_reward": 0.2636191248893738, "value_loss": 0.008599470742046833, "policy_loss": -0.0014930700671499154, "dist_entropy": 0.60872802734375, "actor_grad_norm": 0.10817565768957138, "critic_grad_norm": 0.057275574654340744, "ratio": 0.9998858571052551, "entropy": 0.60872802734375, "incre_win_rate": 0.7727272727272727, "step": 3124}
{"time": 1767166829.6515937, "phase": "train", "update": 3125, "total_env_steps": 10000000, "episode_reward": 0.27986085414886475, "value_loss": 0.007674817834049464, "policy_loss": -0.0013074141428251807, "dist_entropy": 0.6150913238525391, "actor_grad_norm": 0.09830481559038162, "critic_grad_norm": 0.03096504881978035, "ratio": 1.000258207321167, "entropy": 0.6150913238525391, "incre_win_rate": 0.875, "step": 3125}
