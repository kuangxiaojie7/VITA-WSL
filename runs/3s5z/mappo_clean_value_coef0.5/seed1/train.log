{"time": 1767331108.613474, "phase": "train", "update": 1, "total_env_steps": 3200, "episode_reward": 0.0857548639178276, "value_loss": 0.8916176915168762, "policy_loss": -0.001572091919811669, "dist_entropy": 2.027926206588745, "actor_grad_norm": 0.06966444849967957, "critic_grad_norm": 2.3180243968963623, "ratio": 0.9999815225601196, "entropy": 2.027926206588745, "incre_win_rate": 0.0, "step": 1}
{"time": 1767331120.7691588, "phase": "eval", "update": 1, "total_env_steps": 3200, "eval_win_rate": 0.0, "eval_episode_reward": 10.008329884105962, "step": 1}
{"time": 1767331125.4482458, "phase": "train", "update": 2, "total_env_steps": 6400, "episode_reward": 0.09423219412565231, "value_loss": 0.40805680155754087, "policy_loss": -0.0009165353487416538, "dist_entropy": 2.058390426635742, "actor_grad_norm": 0.06033298373222351, "critic_grad_norm": 2.2473530769348145, "ratio": 0.9999638795852661, "entropy": 2.058390426635742, "incre_win_rate": 0.0, "step": 2}
{"time": 1767331130.0628495, "phase": "train", "update": 3, "total_env_steps": 9600, "episode_reward": 0.09409302473068237, "value_loss": 0.19332662522792815, "policy_loss": -0.0010884799603523732, "dist_entropy": 2.0546710968017576, "actor_grad_norm": 0.0940423235297203, "critic_grad_norm": 0.7143088579177856, "ratio": 1.0000550746917725, "entropy": 2.0546710968017576, "incre_win_rate": 0.0, "step": 3}
{"time": 1767331134.4402044, "phase": "train", "update": 4, "total_env_steps": 12800, "episode_reward": 0.09246326237916946, "value_loss": 0.12869158685207366, "policy_loss": -0.001518499541331475, "dist_entropy": 2.031246852874756, "actor_grad_norm": 0.10369277000427246, "critic_grad_norm": 0.4157140851020813, "ratio": 0.9999150633811951, "entropy": 2.031246852874756, "incre_win_rate": 0.0, "step": 4}
{"time": 1767331138.8008943, "phase": "train", "update": 5, "total_env_steps": 16000, "episode_reward": 0.08648334443569183, "value_loss": 0.1023990735411644, "policy_loss": -0.0021584153639224724, "dist_entropy": 1.9830665826797484, "actor_grad_norm": 0.1256761997938156, "critic_grad_norm": 0.4343425929546356, "ratio": 1.0000983476638794, "entropy": 1.9830665826797484, "incre_win_rate": 0.0, "step": 5}
{"time": 1767331143.2086205, "phase": "train", "update": 6, "total_env_steps": 19200, "episode_reward": 0.08463212847709656, "value_loss": 0.09728789180517197, "policy_loss": -0.002018919726318913, "dist_entropy": 1.9391528606414794, "actor_grad_norm": 0.12431017309427261, "critic_grad_norm": 0.2403459995985031, "ratio": 1.0000720024108887, "entropy": 1.9391528606414794, "incre_win_rate": 0.0, "step": 6}
{"time": 1767331147.7624307, "phase": "train", "update": 7, "total_env_steps": 22400, "episode_reward": 0.08317466825246811, "value_loss": 0.08904685974121093, "policy_loss": -0.002741017279197777, "dist_entropy": 1.8940233707427978, "actor_grad_norm": 0.15701888501644135, "critic_grad_norm": 0.18781505525112152, "ratio": 1.0000914335250854, "entropy": 1.8940233707427978, "incre_win_rate": 0.0, "step": 7}
{"time": 1767331152.0422704, "phase": "train", "update": 8, "total_env_steps": 25600, "episode_reward": 0.08623292297124863, "value_loss": 0.08946695327758789, "policy_loss": -0.0023541425354778765, "dist_entropy": 1.835679531097412, "actor_grad_norm": 0.11895184963941574, "critic_grad_norm": 0.28616052865982056, "ratio": 0.9996513724327087, "entropy": 1.835679531097412, "incre_win_rate": 0.0, "step": 8}
{"time": 1767331156.2263913, "phase": "train", "update": 9, "total_env_steps": 28800, "episode_reward": 0.08843129128217697, "value_loss": 0.09892810732126237, "policy_loss": -0.0016811091400629862, "dist_entropy": 1.7927248001098632, "actor_grad_norm": 0.11544934660196304, "critic_grad_norm": 0.360745370388031, "ratio": 0.9995887875556946, "entropy": 1.7927248001098632, "incre_win_rate": 0.0, "step": 9}
{"time": 1767331160.6155932, "phase": "train", "update": 10, "total_env_steps": 32000, "episode_reward": 0.09598509967327118, "value_loss": 0.09591406732797622, "policy_loss": -0.0018915277017271138, "dist_entropy": 1.7380234241485595, "actor_grad_norm": 0.1354767084121704, "critic_grad_norm": 0.23589204251766205, "ratio": 1.000302791595459, "entropy": 1.7380234241485595, "incre_win_rate": 0.0, "step": 10}
{"time": 1767331164.884736, "phase": "train", "update": 11, "total_env_steps": 35200, "episode_reward": 0.09829159826040268, "value_loss": 0.09469168335199356, "policy_loss": -0.0013910176377762928, "dist_entropy": 1.6894251585006714, "actor_grad_norm": 0.08614148199558258, "critic_grad_norm": 0.15496447682380676, "ratio": 1.0000239610671997, "entropy": 1.6894251585006714, "incre_win_rate": 0.0, "step": 11}
{"time": 1767331169.1327941, "phase": "train", "update": 12, "total_env_steps": 38400, "episode_reward": 0.10430929064750671, "value_loss": 0.08341507315635681, "policy_loss": -0.0018251787659392615, "dist_entropy": 1.6450590372085572, "actor_grad_norm": 0.1375882476568222, "critic_grad_norm": 0.15362343192100525, "ratio": 1.000221610069275, "entropy": 1.6450590372085572, "incre_win_rate": 0.0, "step": 12}
{"time": 1767331173.2606995, "phase": "train", "update": 13, "total_env_steps": 41600, "episode_reward": 0.10158577561378479, "value_loss": 0.07441226989030839, "policy_loss": -0.00119080713747568, "dist_entropy": 1.5802430868148805, "actor_grad_norm": 0.07783596962690353, "critic_grad_norm": 0.1347573846578598, "ratio": 1.00008225440979, "entropy": 1.5802430868148805, "incre_win_rate": 0.0, "step": 13}
{"time": 1767331177.3609498, "phase": "train", "update": 14, "total_env_steps": 44800, "episode_reward": 0.10615945607423782, "value_loss": 0.06647559106349946, "policy_loss": -0.0004802070229612099, "dist_entropy": 1.544827651977539, "actor_grad_norm": 0.061310913413763046, "critic_grad_norm": 0.08517448604106903, "ratio": 0.9999479651451111, "entropy": 1.544827651977539, "incre_win_rate": 0.0, "step": 14}
{"time": 1767331182.1450768, "phase": "train", "update": 15, "total_env_steps": 48000, "episode_reward": 0.10044962167739868, "value_loss": 0.05992396771907806, "policy_loss": -0.0006245184832643247, "dist_entropy": 1.488210129737854, "actor_grad_norm": 0.06215013936161995, "critic_grad_norm": 0.1309666931629181, "ratio": 1.0001109838485718, "entropy": 1.488210129737854, "incre_win_rate": 0.0, "step": 15}
{"time": 1767331186.2625391, "phase": "train", "update": 16, "total_env_steps": 51200, "episode_reward": 0.10244879126548767, "value_loss": 0.05272933542728424, "policy_loss": -0.000618366530009995, "dist_entropy": 1.4737331867218018, "actor_grad_norm": 0.05366438627243042, "critic_grad_norm": 0.08472335338592529, "ratio": 1.0002111196517944, "entropy": 1.4737331867218018, "incre_win_rate": 0.0, "step": 16}
{"time": 1767331190.3050435, "phase": "train", "update": 17, "total_env_steps": 54400, "episode_reward": 0.09831126034259796, "value_loss": 0.05172505378723145, "policy_loss": -0.0008870876144939643, "dist_entropy": 1.4369665861129761, "actor_grad_norm": 0.05629882961511612, "critic_grad_norm": 0.11741098016500473, "ratio": 1.000146508216858, "entropy": 1.4369665861129761, "incre_win_rate": 0.0, "step": 17}
{"time": 1767331194.34842, "phase": "train", "update": 18, "total_env_steps": 57600, "episode_reward": 0.10201417654752731, "value_loss": 0.04887418523430824, "policy_loss": -0.0008731432503363834, "dist_entropy": 1.4380412817001342, "actor_grad_norm": 0.06028102710843086, "critic_grad_norm": 0.1051676794886589, "ratio": 0.99990314245224, "entropy": 1.4380412817001342, "incre_win_rate": 0.0, "step": 18}
{"time": 1767331200.3247716, "phase": "train", "update": 19, "total_env_steps": 60800, "episode_reward": 0.10060585290193558, "value_loss": 0.04649995267391205, "policy_loss": -0.0011149800743101457, "dist_entropy": 1.4015617370605469, "actor_grad_norm": 0.07460799813270569, "critic_grad_norm": 0.08601535856723785, "ratio": 0.9999268651008606, "entropy": 1.4015617370605469, "incre_win_rate": 0.0, "step": 19}
{"time": 1767331204.4759455, "phase": "train", "update": 20, "total_env_steps": 64000, "episode_reward": 0.09232565015554428, "value_loss": 0.05340827703475952, "policy_loss": -0.001047327788444008, "dist_entropy": 1.3535763263702392, "actor_grad_norm": 0.061994682997465134, "critic_grad_norm": 0.0930270180106163, "ratio": 1.0001343488693237, "entropy": 1.3535763263702392, "incre_win_rate": 0.0, "step": 20}
{"time": 1767331208.558833, "phase": "train", "update": 21, "total_env_steps": 67200, "episode_reward": 0.09810792654752731, "value_loss": 0.05037649422883987, "policy_loss": -0.0011727616915422345, "dist_entropy": 1.3447639703750611, "actor_grad_norm": 0.07742410898208618, "critic_grad_norm": 0.08537600934505463, "ratio": 1.0000823736190796, "entropy": 1.3447639703750611, "incre_win_rate": 0.0, "step": 21}
{"time": 1767331212.5559986, "phase": "train", "update": 22, "total_env_steps": 70400, "episode_reward": 0.0851050317287445, "value_loss": 0.053545400500297546, "policy_loss": -0.001800102594086761, "dist_entropy": 1.3115006685256958, "actor_grad_norm": 0.1215895563364029, "critic_grad_norm": 0.11916668713092804, "ratio": 1.00009286403656, "entropy": 1.3115006685256958, "incre_win_rate": 0.0, "step": 22}
{"time": 1767331216.587926, "phase": "train", "update": 23, "total_env_steps": 73600, "episode_reward": 0.0812675952911377, "value_loss": 0.07160449177026748, "policy_loss": -0.0004157414055777853, "dist_entropy": 1.2348433256149292, "actor_grad_norm": 0.04494422301650047, "critic_grad_norm": 0.322969526052475, "ratio": 0.9998693466186523, "entropy": 1.2348433256149292, "incre_win_rate": 0.0, "step": 23}
{"time": 1767331220.6169918, "phase": "train", "update": 24, "total_env_steps": 76800, "episode_reward": 0.07704160362482071, "value_loss": 0.06061404570937157, "policy_loss": -0.0005539958401910017, "dist_entropy": 1.2210283994674682, "actor_grad_norm": 0.052555765956640244, "critic_grad_norm": 0.18367044627666473, "ratio": 1.000077486038208, "entropy": 1.2210283994674682, "incre_win_rate": 0.0, "step": 24}
{"time": 1767331224.6613388, "phase": "train", "update": 25, "total_env_steps": 80000, "episode_reward": 0.08240117877721786, "value_loss": 0.05754499435424805, "policy_loss": -0.0007208631953470324, "dist_entropy": 1.250581979751587, "actor_grad_norm": 0.06788765639066696, "critic_grad_norm": 0.16027884185314178, "ratio": 0.9999054074287415, "entropy": 1.250581979751587, "incre_win_rate": 0.0, "step": 25}
{"time": 1767331228.7440782, "phase": "train", "update": 26, "total_env_steps": 83200, "episode_reward": 0.09316639602184296, "value_loss": 0.052117142081260684, "policy_loss": -0.0009146870430102539, "dist_entropy": 1.3416900873184203, "actor_grad_norm": 0.07822418957948685, "critic_grad_norm": 0.2764514684677124, "ratio": 1.000080943107605, "entropy": 1.3416900873184203, "incre_win_rate": 0.0, "step": 26}
{"time": 1767331240.9643307, "phase": "eval", "update": 26, "total_env_steps": 83200, "eval_win_rate": 0.0, "eval_episode_reward": 3.4228580298013247, "step": 26}
{"time": 1767331245.0002046, "phase": "train", "update": 27, "total_env_steps": 86400, "episode_reward": 0.08771057426929474, "value_loss": 0.059610826522111894, "policy_loss": -0.0006368235017490065, "dist_entropy": 1.2636221885681151, "actor_grad_norm": 0.05983882024884224, "critic_grad_norm": 0.17433765530586243, "ratio": 1.0001182556152344, "entropy": 1.2636221885681151, "incre_win_rate": 0.0, "step": 27}
{"time": 1767331249.1008832, "phase": "train", "update": 28, "total_env_steps": 89600, "episode_reward": 0.09845923632383347, "value_loss": 0.05246355161070824, "policy_loss": -0.0005321962933579449, "dist_entropy": 1.346012020111084, "actor_grad_norm": 0.06014684960246086, "critic_grad_norm": 0.2155228704214096, "ratio": 0.9999666213989258, "entropy": 1.346012020111084, "incre_win_rate": 0.0, "step": 28}
{"time": 1767331253.1864562, "phase": "train", "update": 29, "total_env_steps": 92800, "episode_reward": 0.09136278927326202, "value_loss": 0.05754225105047226, "policy_loss": -0.0008307211602758713, "dist_entropy": 1.300529384613037, "actor_grad_norm": 0.04898298531770706, "critic_grad_norm": 0.20824463665485382, "ratio": 1.0000314712524414, "entropy": 1.300529384613037, "incre_win_rate": 0.0, "step": 29}
{"time": 1767331257.1992598, "phase": "train", "update": 30, "total_env_steps": 96000, "episode_reward": 0.09317725151777267, "value_loss": 0.0436478890478611, "policy_loss": -0.0007000864683060825, "dist_entropy": 1.3127287864685058, "actor_grad_norm": 0.04940163716673851, "critic_grad_norm": 0.12129578739404678, "ratio": 0.9999496340751648, "entropy": 1.3127287864685058, "incre_win_rate": 0.0, "step": 30}
{"time": 1767331261.2958522, "phase": "train", "update": 31, "total_env_steps": 99200, "episode_reward": 0.10507191717624664, "value_loss": 0.04537166878581047, "policy_loss": -0.0008220352907233775, "dist_entropy": 1.3580201625823975, "actor_grad_norm": 0.05228828266263008, "critic_grad_norm": 0.14485111832618713, "ratio": 0.9998522996902466, "entropy": 1.3580201625823975, "incre_win_rate": 0.0, "step": 31}
{"time": 1767331265.3841956, "phase": "train", "update": 32, "total_env_steps": 102400, "episode_reward": 0.10288545489311218, "value_loss": 0.047327883541584015, "policy_loss": -0.0006447080931728522, "dist_entropy": 1.3521446704864502, "actor_grad_norm": 0.05511434003710747, "critic_grad_norm": 0.1533743143081665, "ratio": 1.0000206232070923, "entropy": 1.3521446704864502, "incre_win_rate": 0.0, "step": 32}
{"time": 1767331269.4485002, "phase": "train", "update": 33, "total_env_steps": 105600, "episode_reward": 0.10348768532276154, "value_loss": 0.042220254242420194, "policy_loss": -0.0008730879916461376, "dist_entropy": 1.332345962524414, "actor_grad_norm": 0.06567633897066116, "critic_grad_norm": 0.14316973090171814, "ratio": 1.000200629234314, "entropy": 1.332345962524414, "incre_win_rate": 0.0, "step": 33}
{"time": 1767331273.6154823, "phase": "train", "update": 34, "total_env_steps": 108800, "episode_reward": 0.10277421027421951, "value_loss": 0.07353783696889878, "policy_loss": -0.0006558695613534838, "dist_entropy": 1.2457934617996216, "actor_grad_norm": 0.05492071062326431, "critic_grad_norm": 0.39589789509773254, "ratio": 1.0001440048217773, "entropy": 1.2457934617996216, "incre_win_rate": 0.0, "step": 34}
{"time": 1767331277.723443, "phase": "train", "update": 35, "total_env_steps": 112000, "episode_reward": 0.10158734023571014, "value_loss": 0.04418876767158508, "policy_loss": -0.000736462002998195, "dist_entropy": 1.28273606300354, "actor_grad_norm": 0.06618190556764603, "critic_grad_norm": 0.20454151928424835, "ratio": 1.0000015497207642, "entropy": 1.28273606300354, "incre_win_rate": 0.0, "step": 35}
{"time": 1767331281.8055427, "phase": "train", "update": 36, "total_env_steps": 115200, "episode_reward": 0.10663752257823944, "value_loss": 0.049551072716712954, "policy_loss": -0.001188285706247072, "dist_entropy": 1.2999877691268922, "actor_grad_norm": 0.08037417382001877, "critic_grad_norm": 0.1873534917831421, "ratio": 1.0000065565109253, "entropy": 1.2999877691268922, "incre_win_rate": 0.0, "step": 36}
{"time": 1767331285.9110613, "phase": "train", "update": 37, "total_env_steps": 118400, "episode_reward": 0.10178859531879425, "value_loss": 0.04725257232785225, "policy_loss": -0.0006289985321927816, "dist_entropy": 1.3195885181427003, "actor_grad_norm": 0.08668316900730133, "critic_grad_norm": 0.1637275665998459, "ratio": 0.9998510479927063, "entropy": 1.3195885181427003, "incre_win_rate": 0.0, "step": 37}
{"time": 1767331289.955692, "phase": "train", "update": 38, "total_env_steps": 121600, "episode_reward": 0.08310998976230621, "value_loss": 0.06634312272071838, "policy_loss": -0.0004203836283146245, "dist_entropy": 1.1489688396453857, "actor_grad_norm": 0.05112694576382637, "critic_grad_norm": 0.40057307481765747, "ratio": 1.0000120401382446, "entropy": 1.1489688396453857, "incre_win_rate": 0.0, "step": 38}
{"time": 1767331294.1054826, "phase": "train", "update": 39, "total_env_steps": 124800, "episode_reward": 0.0973639190196991, "value_loss": 0.0646099254488945, "policy_loss": -0.0004008737793977701, "dist_entropy": 1.2888880729675294, "actor_grad_norm": 0.056819766759872437, "critic_grad_norm": 0.27105712890625, "ratio": 0.9996004104614258, "entropy": 1.2888880729675294, "incre_win_rate": 0.0, "step": 39}
{"time": 1767331298.4985518, "phase": "train", "update": 40, "total_env_steps": 128000, "episode_reward": 0.09876344352960587, "value_loss": 0.06754038780927658, "policy_loss": -0.0005190594581045537, "dist_entropy": 1.259308433532715, "actor_grad_norm": 0.05612288787961006, "critic_grad_norm": 0.21544666588306427, "ratio": 1.0001741647720337, "entropy": 1.259308433532715, "incre_win_rate": 0.0, "step": 40}
{"time": 1767331302.6279445, "phase": "train", "update": 41, "total_env_steps": 131200, "episode_reward": 0.10682068020105362, "value_loss": 0.060076145082712175, "policy_loss": -0.0005187626219932184, "dist_entropy": 1.3176304340362548, "actor_grad_norm": 0.05890409275889397, "critic_grad_norm": 0.25505468249320984, "ratio": 0.9999562501907349, "entropy": 1.3176304340362548, "incre_win_rate": 0.0, "step": 41}
{"time": 1767331306.7506728, "phase": "train", "update": 42, "total_env_steps": 134400, "episode_reward": 0.10575021058320999, "value_loss": 0.052709905058145524, "policy_loss": -0.0010017181630374238, "dist_entropy": 1.3390273809432984, "actor_grad_norm": 0.07621430605649948, "critic_grad_norm": 0.2198723554611206, "ratio": 1.0001498460769653, "entropy": 1.3390273809432984, "incre_win_rate": 0.0, "step": 42}
{"time": 1767331310.8634615, "phase": "train", "update": 43, "total_env_steps": 137600, "episode_reward": 0.10672910511493683, "value_loss": 0.0664406880736351, "policy_loss": -0.0003220997046870622, "dist_entropy": 1.3457734823226928, "actor_grad_norm": 0.06719130277633667, "critic_grad_norm": 0.2031611055135727, "ratio": 1.000125765800476, "entropy": 1.3457734823226928, "incre_win_rate": 0.0, "step": 43}
{"time": 1767331314.986479, "phase": "train", "update": 44, "total_env_steps": 140800, "episode_reward": 0.11504397541284561, "value_loss": 0.04756471887230873, "policy_loss": -0.0008644542376607944, "dist_entropy": 1.4225898265838623, "actor_grad_norm": 0.07327871769666672, "critic_grad_norm": 0.2265196144580841, "ratio": 1.0002344846725464, "entropy": 1.4225898265838623, "incre_win_rate": 0.0, "step": 44}
{"time": 1767331319.0861456, "phase": "train", "update": 45, "total_env_steps": 144000, "episode_reward": 0.12161165475845337, "value_loss": 0.039585402607917784, "policy_loss": -0.0004295987012508107, "dist_entropy": 1.4883506059646607, "actor_grad_norm": 0.08393847942352295, "critic_grad_norm": 0.08621615916490555, "ratio": 0.9998673796653748, "entropy": 1.4883506059646607, "incre_win_rate": 0.0, "step": 45}
{"time": 1767331323.1880229, "phase": "train", "update": 46, "total_env_steps": 147200, "episode_reward": 0.11593594402074814, "value_loss": 0.042086727917194366, "policy_loss": -0.0007565903317704681, "dist_entropy": 1.405677580833435, "actor_grad_norm": 0.09221502393484116, "critic_grad_norm": 0.08218672126531601, "ratio": 1.000088095664978, "entropy": 1.405677580833435, "incre_win_rate": 0.0, "step": 46}
{"time": 1767331327.2537308, "phase": "train", "update": 47, "total_env_steps": 150400, "episode_reward": 0.11303601413965225, "value_loss": 0.04071517437696457, "policy_loss": -0.00043643449262011915, "dist_entropy": 1.3857697248458862, "actor_grad_norm": 0.07655283808708191, "critic_grad_norm": 0.11894452571868896, "ratio": 0.999779999256134, "entropy": 1.3857697248458862, "incre_win_rate": 0.0, "step": 47}
{"time": 1767331331.3697176, "phase": "train", "update": 48, "total_env_steps": 153600, "episode_reward": 0.11883484572172165, "value_loss": 0.032478855550289155, "policy_loss": -0.0010210507950062287, "dist_entropy": 1.4275338172912597, "actor_grad_norm": 0.08544731140136719, "critic_grad_norm": 0.10515756905078888, "ratio": 1.000168800354004, "entropy": 1.4275338172912597, "incre_win_rate": 0.0, "step": 48}
{"time": 1767331335.4745173, "phase": "train", "update": 49, "total_env_steps": 156800, "episode_reward": 0.11760244518518448, "value_loss": 0.028440263494849204, "policy_loss": -0.000591407290113466, "dist_entropy": 1.3948203086853028, "actor_grad_norm": 0.07527066767215729, "critic_grad_norm": 0.1194894090294838, "ratio": 1.000035047531128, "entropy": 1.3948203086853028, "incre_win_rate": 0.0, "step": 49}
{"time": 1767331339.5785875, "phase": "train", "update": 50, "total_env_steps": 160000, "episode_reward": 0.11310482025146484, "value_loss": 0.03729029893875122, "policy_loss": -0.0006872785828932138, "dist_entropy": 1.3167803764343262, "actor_grad_norm": 0.06217729672789574, "critic_grad_norm": 0.06143921613693237, "ratio": 0.9999611973762512, "entropy": 1.3167803764343262, "incre_win_rate": 0.0, "step": 50}
{"time": 1767331343.6905553, "phase": "train", "update": 51, "total_env_steps": 163200, "episode_reward": 0.11844992637634277, "value_loss": 0.04318221360445022, "policy_loss": -0.0007107151555594271, "dist_entropy": 1.3447015047073365, "actor_grad_norm": 0.07148819416761398, "critic_grad_norm": 0.19133953750133514, "ratio": 0.9999276995658875, "entropy": 1.3447015047073365, "incre_win_rate": 0.0, "step": 51}
{"time": 1767331354.817065, "phase": "eval", "update": 51, "total_env_steps": 163200, "eval_win_rate": 0.0, "eval_episode_reward": 7.347733857615894, "step": 51}
{"time": 1767331358.9056258, "phase": "train", "update": 52, "total_env_steps": 166400, "episode_reward": 0.11805463582277298, "value_loss": 0.04129130393266678, "policy_loss": -0.0010995432549359974, "dist_entropy": 1.2820151329040528, "actor_grad_norm": 0.06624037027359009, "critic_grad_norm": 0.10387436300516129, "ratio": 0.999737560749054, "entropy": 1.2820151329040528, "incre_win_rate": 0.0, "step": 52}
{"time": 1767331363.027734, "phase": "train", "update": 53, "total_env_steps": 169600, "episode_reward": 0.11625620722770691, "value_loss": 0.03529550731182098, "policy_loss": -0.0007959368309546022, "dist_entropy": 1.369235634803772, "actor_grad_norm": 0.08488939702510834, "critic_grad_norm": 0.1720971316099167, "ratio": 1.0001438856124878, "entropy": 1.369235634803772, "incre_win_rate": 0.0, "step": 53}
{"time": 1767331367.1277587, "phase": "train", "update": 54, "total_env_steps": 172800, "episode_reward": 0.11730753630399704, "value_loss": 0.038214628398418424, "policy_loss": -0.0006260949550473515, "dist_entropy": 1.3119108438491822, "actor_grad_norm": 0.06669338792562485, "critic_grad_norm": 0.14524760842323303, "ratio": 0.9999426007270813, "entropy": 1.3119108438491822, "incre_win_rate": 0.0, "step": 54}
{"time": 1767331371.1889591, "phase": "train", "update": 55, "total_env_steps": 176000, "episode_reward": 0.11095251142978668, "value_loss": 0.032475877553224564, "policy_loss": -0.0008998853812248076, "dist_entropy": 1.2872736215591432, "actor_grad_norm": 0.07176952809095383, "critic_grad_norm": 0.14772634208202362, "ratio": 0.9999749064445496, "entropy": 1.2872736215591432, "incre_win_rate": 0.0, "step": 55}
{"time": 1767331375.2363026, "phase": "train", "update": 56, "total_env_steps": 179200, "episode_reward": 0.10108856856822968, "value_loss": 0.04623954445123672, "policy_loss": -0.0010205966435588465, "dist_entropy": 1.2616304159164429, "actor_grad_norm": 0.0948011502623558, "critic_grad_norm": 0.20368042588233948, "ratio": 1.0000683069229126, "entropy": 1.2616304159164429, "incre_win_rate": 0.0, "step": 56}
{"time": 1767331379.3157146, "phase": "train", "update": 57, "total_env_steps": 182400, "episode_reward": 0.10781767964363098, "value_loss": 0.0317708533257246, "policy_loss": -0.0008934161105164096, "dist_entropy": 1.3046348810195922, "actor_grad_norm": 0.06619849056005478, "critic_grad_norm": 0.11701046675443649, "ratio": 1.0000816583633423, "entropy": 1.3046348810195922, "incre_win_rate": 0.0, "step": 57}
{"time": 1767331383.408495, "phase": "train", "update": 58, "total_env_steps": 185600, "episode_reward": 0.11031042784452438, "value_loss": 0.04490251913666725, "policy_loss": -0.0007816761925257155, "dist_entropy": 1.2286466121673585, "actor_grad_norm": 0.08083552122116089, "critic_grad_norm": 0.14436998963356018, "ratio": 0.9998676180839539, "entropy": 1.2286466121673585, "incre_win_rate": 0.0, "step": 58}
{"time": 1767331387.5074615, "phase": "train", "update": 59, "total_env_steps": 188800, "episode_reward": 0.10672859102487564, "value_loss": 0.04609508663415909, "policy_loss": -0.000530053942299702, "dist_entropy": 1.213466215133667, "actor_grad_norm": 0.06640562415122986, "critic_grad_norm": 0.1475682258605957, "ratio": 0.9999580383300781, "entropy": 1.213466215133667, "incre_win_rate": 0.0, "step": 59}
{"time": 1767331391.619993, "phase": "train", "update": 60, "total_env_steps": 192000, "episode_reward": 0.11304894089698792, "value_loss": 0.038225960731506345, "policy_loss": -0.0007443527703550501, "dist_entropy": 1.2889685153961181, "actor_grad_norm": 0.05978572368621826, "critic_grad_norm": 0.18559525907039642, "ratio": 1.0001673698425293, "entropy": 1.2889685153961181, "incre_win_rate": 0.0, "step": 60}
{"time": 1767331395.7212934, "phase": "train", "update": 61, "total_env_steps": 195200, "episode_reward": 0.12291183322668076, "value_loss": 0.04694956094026566, "policy_loss": -0.0008414948712367476, "dist_entropy": 1.260390281677246, "actor_grad_norm": 0.0601639449596405, "critic_grad_norm": 0.2232295721769333, "ratio": 0.9999314546585083, "entropy": 1.260390281677246, "incre_win_rate": 0.02631578947368421, "step": 61}
{"time": 1767331399.8566647, "phase": "train", "update": 62, "total_env_steps": 198400, "episode_reward": 0.10726200044155121, "value_loss": 0.043581323325634004, "policy_loss": -0.0008364661711294019, "dist_entropy": 1.208779263496399, "actor_grad_norm": 0.1155945286154747, "critic_grad_norm": 0.2329518347978592, "ratio": 1.0003606081008911, "entropy": 1.208779263496399, "incre_win_rate": 0.0, "step": 62}
{"time": 1767331403.9423013, "phase": "train", "update": 63, "total_env_steps": 201600, "episode_reward": 0.11526593565940857, "value_loss": 0.03814625963568687, "policy_loss": -0.0008119534812095708, "dist_entropy": 1.250162124633789, "actor_grad_norm": 0.0761740505695343, "critic_grad_norm": 0.15269863605499268, "ratio": 0.999968945980072, "entropy": 1.250162124633789, "incre_win_rate": 0.0, "step": 63}
{"time": 1767331408.0637422, "phase": "train", "update": 64, "total_env_steps": 204800, "episode_reward": 0.11749430745840073, "value_loss": 0.036382751911878584, "policy_loss": -0.0011050366839342018, "dist_entropy": 1.2950485944747925, "actor_grad_norm": 0.09410662204027176, "critic_grad_norm": 0.14760999381542206, "ratio": 0.9999046325683594, "entropy": 1.2950485944747925, "incre_win_rate": 0.0, "step": 64}
{"time": 1767331412.145784, "phase": "train", "update": 65, "total_env_steps": 208000, "episode_reward": 0.10778146982192993, "value_loss": 0.051614845544099806, "policy_loss": -0.00020922245284111797, "dist_entropy": 1.1600360870361328, "actor_grad_norm": 0.05728231742978096, "critic_grad_norm": 0.18068188428878784, "ratio": 0.9998846054077148, "entropy": 1.1600360870361328, "incre_win_rate": 0.0, "step": 65}
{"time": 1767331416.2681556, "phase": "train", "update": 66, "total_env_steps": 211200, "episode_reward": 0.11617755889892578, "value_loss": 0.05727293789386749, "policy_loss": -0.0009202874422029605, "dist_entropy": 1.24359929561615, "actor_grad_norm": 0.1124151274561882, "critic_grad_norm": 0.12666000425815582, "ratio": 1.0003645420074463, "entropy": 1.24359929561615, "incre_win_rate": 0.025, "step": 66}
{"time": 1767331420.4366589, "phase": "train", "update": 67, "total_env_steps": 214400, "episode_reward": 0.12066122144460678, "value_loss": 0.04696923941373825, "policy_loss": -0.0007050615299807994, "dist_entropy": 1.2634377241134644, "actor_grad_norm": 0.06529008597135544, "critic_grad_norm": 0.12628956139087677, "ratio": 1.0000362396240234, "entropy": 1.2634377241134644, "incre_win_rate": 0.025, "step": 67}
{"time": 1767331424.5589828, "phase": "train", "update": 68, "total_env_steps": 217600, "episode_reward": 0.1253797709941864, "value_loss": 0.03525702878832817, "policy_loss": -0.0005524950848673881, "dist_entropy": 1.352288556098938, "actor_grad_norm": 0.06550934165716171, "critic_grad_norm": 0.07258736342191696, "ratio": 0.9998354911804199, "entropy": 1.352288556098938, "incre_win_rate": 0.0, "step": 68}
{"time": 1767331428.7162359, "phase": "train", "update": 69, "total_env_steps": 220800, "episode_reward": 0.12296461313962936, "value_loss": 0.032785624265670776, "policy_loss": -0.0006084858673883531, "dist_entropy": 1.36928551197052, "actor_grad_norm": 0.05058720335364342, "critic_grad_norm": 0.08433116227388382, "ratio": 0.9999081492424011, "entropy": 1.36928551197052, "incre_win_rate": 0.0, "step": 69}
{"time": 1767331432.7608666, "phase": "train", "update": 70, "total_env_steps": 224000, "episode_reward": 0.12303756922483444, "value_loss": 0.03261501267552376, "policy_loss": -0.0012863480079897017, "dist_entropy": 1.3327497005462647, "actor_grad_norm": 0.06563376635313034, "critic_grad_norm": 0.07219912111759186, "ratio": 0.9998138546943665, "entropy": 1.3327497005462647, "incre_win_rate": 0.0, "step": 70}
{"time": 1767331436.8207033, "phase": "train", "update": 71, "total_env_steps": 227200, "episode_reward": 0.1291758120059967, "value_loss": 0.031168783083558083, "policy_loss": -0.0010422238672617822, "dist_entropy": 1.330301332473755, "actor_grad_norm": 0.07306700199842453, "critic_grad_norm": 0.12198565155267715, "ratio": 1.0002087354660034, "entropy": 1.330301332473755, "incre_win_rate": 0.0, "step": 71}
{"time": 1767331441.093295, "phase": "train", "update": 72, "total_env_steps": 230400, "episode_reward": 0.12826521694660187, "value_loss": 0.04392412304878235, "policy_loss": -0.0009120135717406441, "dist_entropy": 1.2958318710327148, "actor_grad_norm": 0.05723002552986145, "critic_grad_norm": 0.07920252531766891, "ratio": 1.0000841617584229, "entropy": 1.2958318710327148, "incre_win_rate": 0.023255813953488372, "step": 72}
{"time": 1767331445.181146, "phase": "train", "update": 73, "total_env_steps": 233600, "episode_reward": 0.11845716834068298, "value_loss": 0.03450693488121033, "policy_loss": -0.00090489920655763, "dist_entropy": 1.2298817396163941, "actor_grad_norm": 0.0907961055636406, "critic_grad_norm": 0.10727027803659439, "ratio": 0.9998893737792969, "entropy": 1.2298817396163941, "incre_win_rate": 0.0, "step": 73}
{"time": 1767331449.238149, "phase": "train", "update": 74, "total_env_steps": 236800, "episode_reward": 0.11052669584751129, "value_loss": 0.04885318577289581, "policy_loss": -0.00032659189341615046, "dist_entropy": 1.230446219444275, "actor_grad_norm": 0.0668189749121666, "critic_grad_norm": 0.3480546176433563, "ratio": 0.999785840511322, "entropy": 1.230446219444275, "incre_win_rate": 0.0, "step": 74}
{"time": 1767331453.2887275, "phase": "train", "update": 75, "total_env_steps": 240000, "episode_reward": 0.11842094361782074, "value_loss": 0.038305705040693284, "policy_loss": -0.0007812647377747339, "dist_entropy": 1.2346846342086792, "actor_grad_norm": 0.08261052519083023, "critic_grad_norm": 0.2918669581413269, "ratio": 0.9998407363891602, "entropy": 1.2346846342086792, "incre_win_rate": 0.0, "step": 75}
{"time": 1767331457.3237844, "phase": "train", "update": 76, "total_env_steps": 243200, "episode_reward": 0.11952556669712067, "value_loss": 0.03198118358850479, "policy_loss": -0.0006023949645538096, "dist_entropy": 1.24851233959198, "actor_grad_norm": 0.09963728487491608, "critic_grad_norm": 0.21419472992420197, "ratio": 1.0001541376113892, "entropy": 1.24851233959198, "incre_win_rate": 0.0, "step": 76}
{"time": 1767331468.7499735, "phase": "eval", "update": 76, "total_env_steps": 243200, "eval_win_rate": 0.0, "eval_episode_reward": 8.633536837748345, "step": 76}
{"time": 1767331472.7971323, "phase": "train", "update": 77, "total_env_steps": 246400, "episode_reward": 0.11169495433568954, "value_loss": 0.03685650676488876, "policy_loss": -0.0008246984200724228, "dist_entropy": 1.1933200120925904, "actor_grad_norm": 0.059785403311252594, "critic_grad_norm": 0.22081318497657776, "ratio": 1.0000801086425781, "entropy": 1.1933200120925904, "incre_win_rate": 0.0, "step": 77}
{"time": 1767331476.8689804, "phase": "train", "update": 78, "total_env_steps": 249600, "episode_reward": 0.12623396515846252, "value_loss": 0.03685493916273117, "policy_loss": -0.0008781284304957282, "dist_entropy": 1.201350712776184, "actor_grad_norm": 0.07332449406385422, "critic_grad_norm": 0.18872380256652832, "ratio": 0.9998642802238464, "entropy": 1.201350712776184, "incre_win_rate": 0.02702702702702703, "step": 78}
{"time": 1767331480.8930128, "phase": "train", "update": 79, "total_env_steps": 252800, "episode_reward": 0.12278870493173599, "value_loss": 0.03235192224383354, "policy_loss": -0.0009452371750088506, "dist_entropy": 1.2064173221588135, "actor_grad_norm": 0.10393702983856201, "critic_grad_norm": 0.0771855041384697, "ratio": 1.0000554323196411, "entropy": 1.2064173221588135, "incre_win_rate": 0.025, "step": 79}
{"time": 1767331484.9146128, "phase": "train", "update": 80, "total_env_steps": 256000, "episode_reward": 0.11978891491889954, "value_loss": 0.04036907702684402, "policy_loss": -0.0008356201762424575, "dist_entropy": 1.1632079839706422, "actor_grad_norm": 0.08532297611236572, "critic_grad_norm": 0.0718977302312851, "ratio": 1.000005841255188, "entropy": 1.1632079839706422, "incre_win_rate": 0.0, "step": 80}
{"time": 1767331489.0082066, "phase": "train", "update": 81, "total_env_steps": 259200, "episode_reward": 0.11676273494958878, "value_loss": 0.06035707890987396, "policy_loss": -0.0006461120263401732, "dist_entropy": 1.166175079345703, "actor_grad_norm": 0.04540696740150452, "critic_grad_norm": 0.15200011432170868, "ratio": 1.0001499652862549, "entropy": 1.166175079345703, "incre_win_rate": 0.0, "step": 81}
{"time": 1767331493.093014, "phase": "train", "update": 82, "total_env_steps": 262400, "episode_reward": 0.12131208181381226, "value_loss": 0.032793375104665755, "policy_loss": -0.0007987227875252856, "dist_entropy": 1.235123872756958, "actor_grad_norm": 0.1007828488945961, "critic_grad_norm": 0.12284999340772629, "ratio": 1.0000828504562378, "entropy": 1.235123872756958, "incre_win_rate": 0.0, "step": 82}
{"time": 1767331497.2071016, "phase": "train", "update": 83, "total_env_steps": 265600, "episode_reward": 0.1302928477525711, "value_loss": 0.028633153811097146, "policy_loss": -0.0007041793928905804, "dist_entropy": 1.2404643535614013, "actor_grad_norm": 0.08339174836874008, "critic_grad_norm": 0.09101484715938568, "ratio": 1.0000355243682861, "entropy": 1.2404643535614013, "incre_win_rate": 0.0, "step": 83}
{"time": 1767331501.2553866, "phase": "train", "update": 84, "total_env_steps": 268800, "episode_reward": 0.12748965620994568, "value_loss": 0.03025510795414448, "policy_loss": -0.0009532237959220425, "dist_entropy": 1.2506013870239259, "actor_grad_norm": 0.10069821029901505, "critic_grad_norm": 0.10008063167333603, "ratio": 1.0002857446670532, "entropy": 1.2506013870239259, "incre_win_rate": 0.0, "step": 84}
{"time": 1767331505.312641, "phase": "train", "update": 85, "total_env_steps": 272000, "episode_reward": 0.12290924787521362, "value_loss": 0.025118349865078927, "policy_loss": -0.0007016443986632481, "dist_entropy": 1.185779070854187, "actor_grad_norm": 0.07920044660568237, "critic_grad_norm": 0.07431348413228989, "ratio": 1.0000553131103516, "entropy": 1.185779070854187, "incre_win_rate": 0.0, "step": 85}
{"time": 1767331509.3305483, "phase": "train", "update": 86, "total_env_steps": 275200, "episode_reward": 0.12841679155826569, "value_loss": 0.030430595949292184, "policy_loss": -0.000798352298282623, "dist_entropy": 1.2139095306396483, "actor_grad_norm": 0.08428388088941574, "critic_grad_norm": 0.10981060564517975, "ratio": 0.9999675750732422, "entropy": 1.2139095306396483, "incre_win_rate": 0.0, "step": 86}
{"time": 1767331513.4140692, "phase": "train", "update": 87, "total_env_steps": 278400, "episode_reward": 0.12441949546337128, "value_loss": 0.02945825457572937, "policy_loss": -0.0005988580778237384, "dist_entropy": 1.2684990167617798, "actor_grad_norm": 0.07190593332052231, "critic_grad_norm": 0.1630784273147583, "ratio": 0.99998539686203, "entropy": 1.2684990167617798, "incre_win_rate": 0.0, "step": 87}
{"time": 1767331517.515746, "phase": "train", "update": 88, "total_env_steps": 281600, "episode_reward": 0.12470871955156326, "value_loss": 0.02439371570944786, "policy_loss": -0.0007329288312270422, "dist_entropy": 1.2758923530578614, "actor_grad_norm": 0.07424324750900269, "critic_grad_norm": 0.09575743973255157, "ratio": 0.9998890161514282, "entropy": 1.2758923530578614, "incre_win_rate": 0.0, "step": 88}
{"time": 1767331521.6190164, "phase": "train", "update": 89, "total_env_steps": 284800, "episode_reward": 0.1267663538455963, "value_loss": 0.029542948678135873, "policy_loss": -0.0006573353957112005, "dist_entropy": 1.3260027647018433, "actor_grad_norm": 0.08457022905349731, "critic_grad_norm": 0.07827621698379517, "ratio": 0.9999740719795227, "entropy": 1.3260027647018433, "incre_win_rate": 0.023809523809523808, "step": 89}
{"time": 1767331525.7121964, "phase": "train", "update": 90, "total_env_steps": 288000, "episode_reward": 0.128618061542511, "value_loss": 0.030382321029901505, "policy_loss": -0.0009450788996129944, "dist_entropy": 1.288776421546936, "actor_grad_norm": 0.10236097872257233, "critic_grad_norm": 0.14426901936531067, "ratio": 1.0003608465194702, "entropy": 1.288776421546936, "incre_win_rate": 0.024390243902439025, "step": 90}
{"time": 1767331529.7707663, "phase": "train", "update": 91, "total_env_steps": 291200, "episode_reward": 0.12739601731300354, "value_loss": 0.027529347315430643, "policy_loss": -0.0006445175346861731, "dist_entropy": 1.2837740421295165, "actor_grad_norm": 0.07247500866651535, "critic_grad_norm": 0.10581153631210327, "ratio": 0.9997214674949646, "entropy": 1.2837740421295165, "incre_win_rate": 0.0, "step": 91}
{"time": 1767331533.839034, "phase": "train", "update": 92, "total_env_steps": 294400, "episode_reward": 0.12715697288513184, "value_loss": 0.03123326599597931, "policy_loss": -0.0007317516772552324, "dist_entropy": 1.3128485441207887, "actor_grad_norm": 0.05826658010482788, "critic_grad_norm": 0.20361952483654022, "ratio": 1.000184416770935, "entropy": 1.3128485441207887, "incre_win_rate": 0.0, "step": 92}
{"time": 1767331537.9134896, "phase": "train", "update": 93, "total_env_steps": 297600, "episode_reward": 0.12560896575450897, "value_loss": 0.026410339772701262, "policy_loss": -0.0015136240854629391, "dist_entropy": 1.3023802757263183, "actor_grad_norm": 0.09626064449548721, "critic_grad_norm": 0.1074245497584343, "ratio": 0.9999765753746033, "entropy": 1.3023802757263183, "incre_win_rate": 0.0, "step": 93}
{"time": 1767331541.9584768, "phase": "train", "update": 94, "total_env_steps": 300800, "episode_reward": 0.12761226296424866, "value_loss": 0.03117789402604103, "policy_loss": -0.0011081230250342244, "dist_entropy": 1.2685554504394532, "actor_grad_norm": 0.13710586726665497, "critic_grad_norm": 0.2697235643863678, "ratio": 1.000388741493225, "entropy": 1.2685554504394532, "incre_win_rate": 0.0, "step": 94}
{"time": 1767331546.0839238, "phase": "train", "update": 95, "total_env_steps": 304000, "episode_reward": 0.1318134367465973, "value_loss": 0.028683341667056085, "policy_loss": -0.0005559076654179762, "dist_entropy": 1.2812160968780517, "actor_grad_norm": 0.0581883005797863, "critic_grad_norm": 0.10634162276983261, "ratio": 1.0001081228256226, "entropy": 1.2812160968780517, "incre_win_rate": 0.0, "step": 95}
{"time": 1767331550.152352, "phase": "train", "update": 96, "total_env_steps": 307200, "episode_reward": 0.12769711017608643, "value_loss": 0.028872216865420342, "policy_loss": -0.0011545162121443298, "dist_entropy": 1.2609758138656617, "actor_grad_norm": 0.06821729987859726, "critic_grad_norm": 0.14562946557998657, "ratio": 1.0001497268676758, "entropy": 1.2609758138656617, "incre_win_rate": 0.0, "step": 96}
{"time": 1767331554.2105083, "phase": "train", "update": 97, "total_env_steps": 310400, "episode_reward": 0.12380948662757874, "value_loss": 0.041858378797769547, "policy_loss": -0.0005650295695289742, "dist_entropy": 1.1717364072799683, "actor_grad_norm": 0.042110320180654526, "critic_grad_norm": 0.15211789309978485, "ratio": 0.9997060894966125, "entropy": 1.1717364072799683, "incre_win_rate": 0.0, "step": 97}
{"time": 1767331558.28712, "phase": "train", "update": 98, "total_env_steps": 313600, "episode_reward": 0.12951676547527313, "value_loss": 0.025852692872285844, "policy_loss": -0.0008501450046200177, "dist_entropy": 1.2099265813827516, "actor_grad_norm": 0.07642916589975357, "critic_grad_norm": 0.20278072357177734, "ratio": 0.999753475189209, "entropy": 1.2099265813827516, "incre_win_rate": 0.0, "step": 98}
{"time": 1767331562.349946, "phase": "train", "update": 99, "total_env_steps": 316800, "episode_reward": 0.12828436493873596, "value_loss": 0.03524295464158058, "policy_loss": -0.0005737765208409518, "dist_entropy": 1.1676172971725465, "actor_grad_norm": 0.05698384717106819, "critic_grad_norm": 0.10812350362539291, "ratio": 1.0000568628311157, "entropy": 1.1676172971725465, "incre_win_rate": 0.023809523809523808, "step": 99}
{"time": 1767331566.4437864, "phase": "train", "update": 100, "total_env_steps": 320000, "episode_reward": 0.13070157170295715, "value_loss": 0.03532596677541733, "policy_loss": -0.0009226104490680953, "dist_entropy": 1.186326026916504, "actor_grad_norm": 0.07129669189453125, "critic_grad_norm": 0.25214889645576477, "ratio": 1.0000214576721191, "entropy": 1.186326026916504, "incre_win_rate": 0.023809523809523808, "step": 100}
{"time": 1767331570.504681, "phase": "train", "update": 101, "total_env_steps": 323200, "episode_reward": 0.124285489320755, "value_loss": 0.043145619332790375, "policy_loss": -0.0005048133042333091, "dist_entropy": 1.1154416084289551, "actor_grad_norm": 0.07607000321149826, "critic_grad_norm": 0.15383978188037872, "ratio": 0.9999213218688965, "entropy": 1.1154416084289551, "incre_win_rate": 0.0, "step": 101}
{"time": 1767331581.899422, "phase": "eval", "update": 101, "total_env_steps": 323200, "eval_win_rate": 0.03125, "eval_episode_reward": 9.670788493377483, "step": 101}
{"time": 1767331585.9687243, "phase": "train", "update": 102, "total_env_steps": 326400, "episode_reward": 0.12617136538028717, "value_loss": 0.038235824555158615, "policy_loss": -0.0005282347938830867, "dist_entropy": 1.1701170921325683, "actor_grad_norm": 0.10770756006240845, "critic_grad_norm": 0.27613565325737, "ratio": 1.0000922679901123, "entropy": 1.1701170921325683, "incre_win_rate": 0.0, "step": 102}
{"time": 1767331590.8058383, "phase": "train", "update": 103, "total_env_steps": 329600, "episode_reward": 0.13149885833263397, "value_loss": 0.034393825381994245, "policy_loss": -0.0009775775447883107, "dist_entropy": 1.1561182975769042, "actor_grad_norm": 0.07931912690401077, "critic_grad_norm": 0.27424395084381104, "ratio": 0.9998235702514648, "entropy": 1.1561182975769042, "incre_win_rate": 0.02564102564102564, "step": 103}
{"time": 1767331595.1519816, "phase": "train", "update": 104, "total_env_steps": 332800, "episode_reward": 0.12895230948925018, "value_loss": 0.031214714422821997, "policy_loss": -0.0007318797122145782, "dist_entropy": 1.197956347465515, "actor_grad_norm": 0.11930973827838898, "critic_grad_norm": 0.21042779088020325, "ratio": 1.0000804662704468, "entropy": 1.197956347465515, "incre_win_rate": 0.0, "step": 104}
{"time": 1767331599.252239, "phase": "train", "update": 105, "total_env_steps": 336000, "episode_reward": 0.13294650614261627, "value_loss": 0.030243022739887236, "policy_loss": -0.0011438639728787337, "dist_entropy": 1.1950873136520386, "actor_grad_norm": 0.08679639548063278, "critic_grad_norm": 0.21063752472400665, "ratio": 0.9998016357421875, "entropy": 1.1950873136520386, "incre_win_rate": 0.0, "step": 105}
{"time": 1767331603.3419101, "phase": "train", "update": 106, "total_env_steps": 339200, "episode_reward": 0.13328434526920319, "value_loss": 0.026899304240942, "policy_loss": -0.0008872296018221703, "dist_entropy": 1.1926070690155028, "actor_grad_norm": 0.08449491113424301, "critic_grad_norm": 0.1542629450559616, "ratio": 1.0000914335250854, "entropy": 1.1926070690155028, "incre_win_rate": 0.0, "step": 106}
{"time": 1767331607.38499, "phase": "train", "update": 107, "total_env_steps": 342400, "episode_reward": 0.12760552763938904, "value_loss": 0.03296118676662445, "policy_loss": -0.0007395384819076867, "dist_entropy": 1.140504002571106, "actor_grad_norm": 0.07932338118553162, "critic_grad_norm": 0.14703060686588287, "ratio": 0.9999677538871765, "entropy": 1.140504002571106, "incre_win_rate": 0.0, "step": 107}
{"time": 1767331611.4525933, "phase": "train", "update": 108, "total_env_steps": 345600, "episode_reward": 0.12826469540596008, "value_loss": 0.025385895743966103, "policy_loss": -0.0008202025497077159, "dist_entropy": 1.182024931907654, "actor_grad_norm": 0.10751044750213623, "critic_grad_norm": 0.08701761066913605, "ratio": 1.000287413597107, "entropy": 1.182024931907654, "incre_win_rate": 0.0, "step": 108}
{"time": 1767331615.4802136, "phase": "train", "update": 109, "total_env_steps": 348800, "episode_reward": 0.11874586343765259, "value_loss": 0.03613305315375328, "policy_loss": -0.000643197028391107, "dist_entropy": 1.1313770294189454, "actor_grad_norm": 0.08119451999664307, "critic_grad_norm": 0.2596871554851532, "ratio": 0.9997995495796204, "entropy": 1.1313770294189454, "incre_win_rate": 0.0, "step": 109}
{"time": 1767331619.9432907, "phase": "train", "update": 110, "total_env_steps": 352000, "episode_reward": 0.12239755690097809, "value_loss": 0.03563187047839165, "policy_loss": -0.0008958293450934462, "dist_entropy": 1.1878526210784912, "actor_grad_norm": 0.11273064464330673, "critic_grad_norm": 0.13838428258895874, "ratio": 1.0001674890518188, "entropy": 1.1878526210784912, "incre_win_rate": 0.0, "step": 110}
{"time": 1767331623.9682639, "phase": "train", "update": 111, "total_env_steps": 355200, "episode_reward": 0.11878672242164612, "value_loss": 0.026811764389276505, "policy_loss": -0.0013058600579178403, "dist_entropy": 1.177231788635254, "actor_grad_norm": 0.10919249057769775, "critic_grad_norm": 0.1301899403333664, "ratio": 0.999860942363739, "entropy": 1.177231788635254, "incre_win_rate": 0.0, "step": 111}
{"time": 1767331628.0174677, "phase": "train", "update": 112, "total_env_steps": 358400, "episode_reward": 0.12686362862586975, "value_loss": 0.02509751506149769, "policy_loss": -0.0007584597527911186, "dist_entropy": 1.2156482696533204, "actor_grad_norm": 0.11441735178232193, "critic_grad_norm": 0.0847945585846901, "ratio": 0.9999057650566101, "entropy": 1.2156482696533204, "incre_win_rate": 0.0, "step": 112}
{"time": 1767331632.0437014, "phase": "train", "update": 113, "total_env_steps": 361600, "episode_reward": 0.12997879087924957, "value_loss": 0.0298006035387516, "policy_loss": -0.0010222422494857498, "dist_entropy": 1.2173186540603638, "actor_grad_norm": 0.09270410239696503, "critic_grad_norm": 0.07841818779706955, "ratio": 0.9998915791511536, "entropy": 1.2173186540603638, "incre_win_rate": 0.05263157894736842, "step": 113}
{"time": 1767331636.0632546, "phase": "train", "update": 114, "total_env_steps": 364800, "episode_reward": 0.11974389851093292, "value_loss": 0.04927726462483406, "policy_loss": -0.0006392497318149281, "dist_entropy": 1.1411208152770995, "actor_grad_norm": 0.06680092215538025, "critic_grad_norm": 0.17796017229557037, "ratio": 1.0001200437545776, "entropy": 1.1411208152770995, "incre_win_rate": 0.0, "step": 114}
{"time": 1767331640.081479, "phase": "train", "update": 115, "total_env_steps": 368000, "episode_reward": 0.13265469670295715, "value_loss": 0.02908168062567711, "policy_loss": -0.0010260939524346924, "dist_entropy": 1.2322548627853394, "actor_grad_norm": 0.0969720408320427, "critic_grad_norm": 0.24595868587493896, "ratio": 0.9996296167373657, "entropy": 1.2322548627853394, "incre_win_rate": 0.0, "step": 115}
{"time": 1767331644.1140869, "phase": "train", "update": 116, "total_env_steps": 371200, "episode_reward": 0.13053031265735626, "value_loss": 0.051426928490400314, "policy_loss": -0.0012921170646030156, "dist_entropy": 1.1990638017654418, "actor_grad_norm": 0.09339666366577148, "critic_grad_norm": 0.22316506505012512, "ratio": 0.9997783899307251, "entropy": 1.1990638017654418, "incre_win_rate": 0.07894736842105263, "step": 116}
{"time": 1767331648.1393225, "phase": "train", "update": 117, "total_env_steps": 374400, "episode_reward": 0.1307383030653, "value_loss": 0.030993104726076127, "policy_loss": -0.0011406735923273458, "dist_entropy": 1.2473926067352294, "actor_grad_norm": 0.066444531083107, "critic_grad_norm": 0.17089097201824188, "ratio": 1.000178337097168, "entropy": 1.2473926067352294, "incre_win_rate": 0.02564102564102564, "step": 117}
{"time": 1767331652.2153094, "phase": "train", "update": 118, "total_env_steps": 377600, "episode_reward": 0.12829263508319855, "value_loss": 0.033143005520105365, "policy_loss": -0.0008965550355652496, "dist_entropy": 1.221306848526001, "actor_grad_norm": 0.08847490698099136, "critic_grad_norm": 0.1520697921514511, "ratio": 0.9997793436050415, "entropy": 1.221306848526001, "incre_win_rate": 0.0, "step": 118}
{"time": 1767331656.2254639, "phase": "train", "update": 119, "total_env_steps": 380800, "episode_reward": 0.12509208917617798, "value_loss": 0.02784508019685745, "policy_loss": -0.001132168593343863, "dist_entropy": 1.2371697664260863, "actor_grad_norm": 0.1271437555551529, "critic_grad_norm": 0.09190821647644043, "ratio": 1.000232219696045, "entropy": 1.2371697664260863, "incre_win_rate": 0.0, "step": 119}
{"time": 1767331660.2762918, "phase": "train", "update": 120, "total_env_steps": 384000, "episode_reward": 0.13087283074855804, "value_loss": 0.027081167325377464, "policy_loss": -0.0013634903392130582, "dist_entropy": 1.2775915622711183, "actor_grad_norm": 0.08191808313131332, "critic_grad_norm": 0.12013359367847443, "ratio": 1.000130534172058, "entropy": 1.2775915622711183, "incre_win_rate": 0.0, "step": 120}
{"time": 1767331664.2848854, "phase": "train", "update": 121, "total_env_steps": 387200, "episode_reward": 0.12930256128311157, "value_loss": 0.03682816028594971, "policy_loss": -0.0010104110980237557, "dist_entropy": 1.2163116455078125, "actor_grad_norm": 0.07180320471525192, "critic_grad_norm": 0.11652659624814987, "ratio": 1.000083088874817, "entropy": 1.2163116455078125, "incre_win_rate": 0.02564102564102564, "step": 121}
{"time": 1767331668.2778473, "phase": "train", "update": 122, "total_env_steps": 390400, "episode_reward": 0.13539786636829376, "value_loss": 0.039638309925794604, "policy_loss": -0.0013034274710882698, "dist_entropy": 1.1944386959075928, "actor_grad_norm": 0.07941881567239761, "critic_grad_norm": 0.3459230065345764, "ratio": 1.0000056028366089, "entropy": 1.1944386959075928, "incre_win_rate": 0.0, "step": 122}
{"time": 1767331672.2917051, "phase": "train", "update": 123, "total_env_steps": 393600, "episode_reward": 0.13635864853858948, "value_loss": 0.04017149657011032, "policy_loss": -0.001314098754664883, "dist_entropy": 1.1818426132202149, "actor_grad_norm": 0.08704296499490738, "critic_grad_norm": 0.17762601375579834, "ratio": 1.0000613927841187, "entropy": 1.1818426132202149, "incre_win_rate": 0.07894736842105263, "step": 123}
{"time": 1767331676.3538804, "phase": "train", "update": 124, "total_env_steps": 396800, "episode_reward": 0.1367259919643402, "value_loss": 0.035250868648290634, "policy_loss": -0.0012609789297343354, "dist_entropy": 1.2129148244857788, "actor_grad_norm": 0.0884041041135788, "critic_grad_norm": 0.23273184895515442, "ratio": 0.9997382164001465, "entropy": 1.2129148244857788, "incre_win_rate": 0.02564102564102564, "step": 124}
{"time": 1767331680.414977, "phase": "train", "update": 125, "total_env_steps": 400000, "episode_reward": 0.13619878888130188, "value_loss": 0.02864345908164978, "policy_loss": -0.0008114325577484038, "dist_entropy": 1.1658414363861085, "actor_grad_norm": 0.086729496717453, "critic_grad_norm": 0.15691246092319489, "ratio": 0.9995343089103699, "entropy": 1.1658414363861085, "incre_win_rate": 0.02564102564102564, "step": 125}
{"time": 1767331684.4596179, "phase": "train", "update": 126, "total_env_steps": 403200, "episode_reward": 0.13311000168323517, "value_loss": 0.03154873251914978, "policy_loss": -0.0007382575002170099, "dist_entropy": 1.1632264614105225, "actor_grad_norm": 0.07452578842639923, "critic_grad_norm": 0.08663571625947952, "ratio": 1.0000860691070557, "entropy": 1.1632264614105225, "incre_win_rate": 0.05, "step": 126}
{"time": 1767331697.024864, "phase": "eval", "update": 126, "total_env_steps": 403200, "eval_win_rate": 0.0, "eval_episode_reward": 11.578228476821192, "step": 126}
{"time": 1767331701.0742369, "phase": "train", "update": 127, "total_env_steps": 406400, "episode_reward": 0.12952245771884918, "value_loss": 0.021213693544268608, "policy_loss": -0.0010465304393427743, "dist_entropy": 1.1879302501678466, "actor_grad_norm": 0.09095508605241776, "critic_grad_norm": 0.0753755271434784, "ratio": 1.0002366304397583, "entropy": 1.1879302501678466, "incre_win_rate": 0.0, "step": 127}
{"time": 1767331705.0948262, "phase": "train", "update": 128, "total_env_steps": 409600, "episode_reward": 0.13571348786354065, "value_loss": 0.033065105229616164, "policy_loss": -0.0015182482445553092, "dist_entropy": 1.1560296297073365, "actor_grad_norm": 0.1296035498380661, "critic_grad_norm": 0.189703568816185, "ratio": 0.9996885657310486, "entropy": 1.1560296297073365, "incre_win_rate": 0.02857142857142857, "step": 128}
{"time": 1767331709.1433372, "phase": "train", "update": 129, "total_env_steps": 412800, "episode_reward": 0.13610616326332092, "value_loss": 0.0360550120472908, "policy_loss": -0.0004973926448172961, "dist_entropy": 1.169791293144226, "actor_grad_norm": 0.08849216997623444, "critic_grad_norm": 0.1145208477973938, "ratio": 0.999869167804718, "entropy": 1.169791293144226, "incre_win_rate": 0.029411764705882353, "step": 129}
{"time": 1767331713.1766758, "phase": "train", "update": 130, "total_env_steps": 416000, "episode_reward": 0.12926478683948517, "value_loss": 0.0268376637250185, "policy_loss": -0.0008824861894821013, "dist_entropy": 1.1765429735183717, "actor_grad_norm": 0.09125366806983948, "critic_grad_norm": 0.27055007219314575, "ratio": 0.9998454451560974, "entropy": 1.1765429735183717, "incre_win_rate": 0.02564102564102564, "step": 130}
{"time": 1767331717.2087157, "phase": "train", "update": 131, "total_env_steps": 419200, "episode_reward": 0.13748136162757874, "value_loss": 0.031154512241482735, "policy_loss": -0.0006615965629038101, "dist_entropy": 1.2024211168289185, "actor_grad_norm": 0.07576226443052292, "critic_grad_norm": 0.16745321452617645, "ratio": 1.0002764463424683, "entropy": 1.2024211168289185, "incre_win_rate": 0.05555555555555555, "step": 131}
{"time": 1767331721.2203953, "phase": "train", "update": 132, "total_env_steps": 422400, "episode_reward": 0.12693502008914948, "value_loss": 0.02340015657246113, "policy_loss": -0.0008434245070503721, "dist_entropy": 1.1660115003585816, "actor_grad_norm": 0.09236571937799454, "critic_grad_norm": 0.10699162632226944, "ratio": 0.9996030926704407, "entropy": 1.1660115003585816, "incre_win_rate": 0.0, "step": 132}
{"time": 1767331725.266468, "phase": "train", "update": 133, "total_env_steps": 425600, "episode_reward": 0.1319541484117508, "value_loss": 0.02342710494995117, "policy_loss": -0.0011467996193600173, "dist_entropy": 1.2297152042388917, "actor_grad_norm": 0.12558215856552124, "critic_grad_norm": 0.12305285036563873, "ratio": 1.0003708600997925, "entropy": 1.2297152042388917, "incre_win_rate": 0.0, "step": 133}
{"time": 1767331729.3240182, "phase": "train", "update": 134, "total_env_steps": 428800, "episode_reward": 0.13223044574260712, "value_loss": 0.023577598109841346, "policy_loss": -0.0005673056752556249, "dist_entropy": 1.2109427213668824, "actor_grad_norm": 0.0804082527756691, "critic_grad_norm": 0.11324836313724518, "ratio": 1.0003591775894165, "entropy": 1.2109427213668824, "incre_win_rate": 0.024390243902439025, "step": 134}
{"time": 1767331733.3163133, "phase": "train", "update": 135, "total_env_steps": 432000, "episode_reward": 0.12895746529102325, "value_loss": 0.017293272912502287, "policy_loss": -0.0013734932744565499, "dist_entropy": 1.196613621711731, "actor_grad_norm": 0.11584477871656418, "critic_grad_norm": 0.0938686951994896, "ratio": 1.0000275373458862, "entropy": 1.196613621711731, "incre_win_rate": 0.0, "step": 135}
{"time": 1767331737.3446329, "phase": "train", "update": 136, "total_env_steps": 435200, "episode_reward": 0.1343625783920288, "value_loss": 0.026990774273872375, "policy_loss": -0.0006845248620766853, "dist_entropy": 1.2147072076797485, "actor_grad_norm": 0.10395445674657822, "critic_grad_norm": 0.07668375223875046, "ratio": 1.0002788305282593, "entropy": 1.2147072076797485, "incre_win_rate": 0.05128205128205128, "step": 136}
{"time": 1767331741.4284925, "phase": "train", "update": 137, "total_env_steps": 438400, "episode_reward": 0.1290692389011383, "value_loss": 0.025425539165735245, "policy_loss": -0.00047651789173386305, "dist_entropy": 1.228824210166931, "actor_grad_norm": 0.07493051886558533, "critic_grad_norm": 0.07337720692157745, "ratio": 1.0002416372299194, "entropy": 1.228824210166931, "incre_win_rate": 0.0, "step": 137}
{"time": 1767331745.451888, "phase": "train", "update": 138, "total_env_steps": 441600, "episode_reward": 0.13124224543571472, "value_loss": 0.022092654556035995, "policy_loss": -0.0015759246808329408, "dist_entropy": 1.2010858535766602, "actor_grad_norm": 0.08871836215257645, "critic_grad_norm": 0.1267271488904953, "ratio": 1.0002741813659668, "entropy": 1.2010858535766602, "incre_win_rate": 0.0, "step": 138}
{"time": 1767331749.4846902, "phase": "train", "update": 139, "total_env_steps": 444800, "episode_reward": 0.13246844708919525, "value_loss": 0.023584984987974168, "policy_loss": -0.0012133269430165683, "dist_entropy": 1.2046778202056885, "actor_grad_norm": 0.10292041301727295, "critic_grad_norm": 0.06717211753129959, "ratio": 0.9998853802680969, "entropy": 1.2046778202056885, "incre_win_rate": 0.0, "step": 139}
{"time": 1767331753.5554318, "phase": "train", "update": 140, "total_env_steps": 448000, "episode_reward": 0.13134831190109253, "value_loss": 0.03028273656964302, "policy_loss": -0.0006864283676204508, "dist_entropy": 1.2329360008239747, "actor_grad_norm": 0.07905483990907669, "critic_grad_norm": 0.13750028610229492, "ratio": 1.0000650882720947, "entropy": 1.2329360008239747, "incre_win_rate": 0.0, "step": 140}
{"time": 1767331757.6025786, "phase": "train", "update": 141, "total_env_steps": 451200, "episode_reward": 0.1281275898218155, "value_loss": 0.03221170678734779, "policy_loss": -0.0007898606023406529, "dist_entropy": 1.22641122341156, "actor_grad_norm": 0.083612360060215, "critic_grad_norm": 0.07963792234659195, "ratio": 0.9997235536575317, "entropy": 1.22641122341156, "incre_win_rate": 0.0, "step": 141}
{"time": 1767331761.6543024, "phase": "train", "update": 142, "total_env_steps": 454400, "episode_reward": 0.12994515895843506, "value_loss": 0.02897019162774086, "policy_loss": -0.00096004566206922, "dist_entropy": 1.224702501296997, "actor_grad_norm": 0.08085110038518906, "critic_grad_norm": 0.08548546582460403, "ratio": 1.0000393390655518, "entropy": 1.224702501296997, "incre_win_rate": 0.02631578947368421, "step": 142}
{"time": 1767331765.7011118, "phase": "train", "update": 143, "total_env_steps": 457600, "episode_reward": 0.12159302830696106, "value_loss": 0.03295207619667053, "policy_loss": -0.0007616323309875383, "dist_entropy": 1.1932342290878295, "actor_grad_norm": 0.07815896719694138, "critic_grad_norm": 0.06210410222411156, "ratio": 0.9999366998672485, "entropy": 1.1932342290878295, "incre_win_rate": 0.02631578947368421, "step": 143}
{"time": 1767331769.7741978, "phase": "train", "update": 144, "total_env_steps": 460800, "episode_reward": 0.12791597843170166, "value_loss": 0.04594249799847603, "policy_loss": -0.0008824271466181699, "dist_entropy": 1.2128406286239624, "actor_grad_norm": 0.09236874431371689, "critic_grad_norm": 0.19240374863147736, "ratio": 0.9999664425849915, "entropy": 1.2128406286239624, "incre_win_rate": 0.0, "step": 144}
{"time": 1767331773.8529212, "phase": "train", "update": 145, "total_env_steps": 464000, "episode_reward": 0.12145644426345825, "value_loss": 0.03452850729227066, "policy_loss": -0.0011081322363978075, "dist_entropy": 1.1818765163421632, "actor_grad_norm": 0.10695574432611465, "critic_grad_norm": 0.16012662649154663, "ratio": 1.0005801916122437, "entropy": 1.1818765163421632, "incre_win_rate": 0.0, "step": 145}
{"time": 1767331777.868097, "phase": "train", "update": 146, "total_env_steps": 467200, "episode_reward": 0.13040925562381744, "value_loss": 0.02459680996835232, "policy_loss": -0.0013693719754570566, "dist_entropy": 1.1751148700714111, "actor_grad_norm": 0.12412365525960922, "critic_grad_norm": 0.09119150787591934, "ratio": 1.0000568628311157, "entropy": 1.1751148700714111, "incre_win_rate": 0.0, "step": 146}
{"time": 1767331781.915228, "phase": "train", "update": 147, "total_env_steps": 470400, "episode_reward": 0.12995654344558716, "value_loss": 0.031752441078424454, "policy_loss": -0.001131565745980545, "dist_entropy": 1.2065784215927124, "actor_grad_norm": 0.08387047052383423, "critic_grad_norm": 0.10017426311969757, "ratio": 1.0000518560409546, "entropy": 1.2065784215927124, "incre_win_rate": 0.025, "step": 147}
{"time": 1767331785.980729, "phase": "train", "update": 148, "total_env_steps": 473600, "episode_reward": 0.13473716378211975, "value_loss": 0.021489213779568674, "policy_loss": -0.0010176428438199991, "dist_entropy": 1.2145262718200684, "actor_grad_norm": 0.06282863020896912, "critic_grad_norm": 0.10126890987157822, "ratio": 0.9999187588691711, "entropy": 1.2145262718200684, "incre_win_rate": 0.0, "step": 148}
{"time": 1767331790.029037, "phase": "train", "update": 149, "total_env_steps": 476800, "episode_reward": 0.13137158751487732, "value_loss": 0.028346530348062515, "policy_loss": -0.0012066539520695584, "dist_entropy": 1.2323216199874878, "actor_grad_norm": 0.10812000185251236, "critic_grad_norm": 0.047313142567873, "ratio": 0.9999829530715942, "entropy": 1.2323216199874878, "incre_win_rate": 0.02857142857142857, "step": 149}
{"time": 1767331794.0930753, "phase": "train", "update": 150, "total_env_steps": 480000, "episode_reward": 0.13266246020793915, "value_loss": 0.025043694674968718, "policy_loss": -0.0008214659625259913, "dist_entropy": 1.266438937187195, "actor_grad_norm": 0.07600521296262741, "critic_grad_norm": 0.09963760524988174, "ratio": 1.0000540018081665, "entropy": 1.266438937187195, "incre_win_rate": 0.023255813953488372, "step": 150}
{"time": 1767331798.1481383, "phase": "train", "update": 151, "total_env_steps": 483200, "episode_reward": 0.13086766004562378, "value_loss": 0.021365755051374436, "policy_loss": -0.0009742442734527401, "dist_entropy": 1.3058252811431885, "actor_grad_norm": 0.10904564708471298, "critic_grad_norm": 0.14110147953033447, "ratio": 1.0000104904174805, "entropy": 1.3058252811431885, "incre_win_rate": 0.0, "step": 151}
{"time": 1767331809.7349544, "phase": "eval", "update": 151, "total_env_steps": 483200, "eval_win_rate": 0.125, "eval_episode_reward": 11.55292839403974, "step": 151}
{"time": 1767331813.7577136, "phase": "train", "update": 152, "total_env_steps": 486400, "episode_reward": 0.13304895162582397, "value_loss": 0.02135435529053211, "policy_loss": -0.0008248583208391835, "dist_entropy": 1.2667417526245117, "actor_grad_norm": 0.07329867035150528, "critic_grad_norm": 0.07280705124139786, "ratio": 0.9998174905776978, "entropy": 1.2667417526245117, "incre_win_rate": 0.0, "step": 152}
{"time": 1767331817.8359375, "phase": "train", "update": 153, "total_env_steps": 489600, "episode_reward": 0.1353280246257782, "value_loss": 0.022150370851159097, "policy_loss": -0.0011136495540560176, "dist_entropy": 1.2934081554412842, "actor_grad_norm": 0.10625455528497696, "critic_grad_norm": 0.1497817039489746, "ratio": 1.0002530813217163, "entropy": 1.2934081554412842, "incre_win_rate": 0.0, "step": 153}
{"time": 1767331821.8594537, "phase": "train", "update": 154, "total_env_steps": 492800, "episode_reward": 0.12561722099781036, "value_loss": 0.02019704766571522, "policy_loss": -0.0008459623528764837, "dist_entropy": 1.3003180980682374, "actor_grad_norm": 0.0867551788687706, "critic_grad_norm": 0.10637533664703369, "ratio": 0.9999948740005493, "entropy": 1.3003180980682374, "incre_win_rate": 0.0, "step": 154}
{"time": 1767331825.8727365, "phase": "train", "update": 155, "total_env_steps": 496000, "episode_reward": 0.13079573214054108, "value_loss": 0.02633064016699791, "policy_loss": -0.001097797695460656, "dist_entropy": 1.2481664896011353, "actor_grad_norm": 0.08281812816858292, "critic_grad_norm": 0.08604608476161957, "ratio": 1.0002506971359253, "entropy": 1.2481664896011353, "incre_win_rate": 0.0, "step": 155}
{"time": 1767331829.9216754, "phase": "train", "update": 156, "total_env_steps": 499200, "episode_reward": 0.14352287352085114, "value_loss": 0.032574744522571565, "policy_loss": -0.0010004665954307158, "dist_entropy": 1.2558271169662476, "actor_grad_norm": 0.07589014619588852, "critic_grad_norm": 0.15852372348308563, "ratio": 1.000359058380127, "entropy": 1.2558271169662476, "incre_win_rate": 0.04878048780487805, "step": 156}
{"time": 1767331833.979926, "phase": "train", "update": 157, "total_env_steps": 502400, "episode_reward": 0.13626812398433685, "value_loss": 0.02288091890513897, "policy_loss": -0.0009153379228308723, "dist_entropy": 1.260886001586914, "actor_grad_norm": 0.1290694624185562, "critic_grad_norm": 0.054081257432699203, "ratio": 1.0002398490905762, "entropy": 1.260886001586914, "incre_win_rate": 0.0, "step": 157}
{"time": 1767331838.0048587, "phase": "train", "update": 158, "total_env_steps": 505600, "episode_reward": 0.13340698182582855, "value_loss": 0.025379909574985503, "policy_loss": -0.001170069507842797, "dist_entropy": 1.245579433441162, "actor_grad_norm": 0.08574002236127853, "critic_grad_norm": 0.04468584805727005, "ratio": 1.000067949295044, "entropy": 1.245579433441162, "incre_win_rate": 0.0, "step": 158}
{"time": 1767331842.0607386, "phase": "train", "update": 159, "total_env_steps": 508800, "episode_reward": 0.13890106976032257, "value_loss": 0.021805194765329362, "policy_loss": -0.0012477770723499759, "dist_entropy": 1.3052812814712524, "actor_grad_norm": 0.0907796174287796, "critic_grad_norm": 0.11320260912179947, "ratio": 1.0001976490020752, "entropy": 1.3052812814712524, "incre_win_rate": 0.0, "step": 159}
{"time": 1767331846.0712287, "phase": "train", "update": 160, "total_env_steps": 512000, "episode_reward": 0.13403819501399994, "value_loss": 0.020552870631217957, "policy_loss": -0.0011091067490170304, "dist_entropy": 1.2684457302093506, "actor_grad_norm": 0.10296111553907394, "critic_grad_norm": 0.06997421383857727, "ratio": 1.0001503229141235, "entropy": 1.2684457302093506, "incre_win_rate": 0.0, "step": 160}
{"time": 1767331850.1005511, "phase": "train", "update": 161, "total_env_steps": 515200, "episode_reward": 0.13136175274848938, "value_loss": 0.023613445088267328, "policy_loss": -0.0005392913312871172, "dist_entropy": 1.2783484697341918, "actor_grad_norm": 0.09938973188400269, "critic_grad_norm": 0.05810133367776871, "ratio": 1.0000423192977905, "entropy": 1.2783484697341918, "incre_win_rate": 0.0, "step": 161}
{"time": 1767331854.0967402, "phase": "train", "update": 162, "total_env_steps": 518400, "episode_reward": 0.1324327439069748, "value_loss": 0.023266037181019782, "policy_loss": -0.0009280563013302157, "dist_entropy": 1.2260053396224975, "actor_grad_norm": 0.09150585532188416, "critic_grad_norm": 0.10978589206933975, "ratio": 0.9996834993362427, "entropy": 1.2260053396224975, "incre_win_rate": 0.0, "step": 162}
{"time": 1767331858.1005101, "phase": "train", "update": 163, "total_env_steps": 521600, "episode_reward": 0.12549617886543274, "value_loss": 0.025296657159924508, "policy_loss": -0.0012755280902602805, "dist_entropy": 1.1867773294448853, "actor_grad_norm": 0.08685294538736343, "critic_grad_norm": 0.07360651344060898, "ratio": 0.9998952150344849, "entropy": 1.1867773294448853, "incre_win_rate": 0.02702702702702703, "step": 163}
{"time": 1767331877.3552494, "phase": "train", "update": 164, "total_env_steps": 524800, "episode_reward": 0.14011020958423615, "value_loss": 0.029095957428216933, "policy_loss": -0.0010545227623769194, "dist_entropy": 1.1918986558914184, "actor_grad_norm": 0.08354096859693527, "critic_grad_norm": 0.0872872993350029, "ratio": 1.0000489950180054, "entropy": 1.1918986558914184, "incre_win_rate": 0.0, "step": 164}
{"time": 1767331881.3928192, "phase": "train", "update": 165, "total_env_steps": 528000, "episode_reward": 0.13311050832271576, "value_loss": 0.024934478104114532, "policy_loss": -0.0010733283770001378, "dist_entropy": 1.1771686553955079, "actor_grad_norm": 0.09281071275472641, "critic_grad_norm": 0.10208985954523087, "ratio": 1.0002721548080444, "entropy": 1.1771686553955079, "incre_win_rate": 0.027777777777777776, "step": 165}
{"time": 1767331885.387467, "phase": "train", "update": 166, "total_env_steps": 531200, "episode_reward": 0.13726666569709778, "value_loss": 0.0341726154088974, "policy_loss": -0.0011460930262067847, "dist_entropy": 1.1424196004867553, "actor_grad_norm": 0.09963240474462509, "critic_grad_norm": 0.31486010551452637, "ratio": 1.0000542402267456, "entropy": 1.1424196004867553, "incre_win_rate": 0.11764705882352941, "step": 166}
{"time": 1767331889.4422638, "phase": "train", "update": 167, "total_env_steps": 534400, "episode_reward": 0.14153766632080078, "value_loss": 0.029202990978956223, "policy_loss": -0.0008642511553981879, "dist_entropy": 1.16925790309906, "actor_grad_norm": 0.07401528209447861, "critic_grad_norm": 0.16937531530857086, "ratio": 0.9999039769172668, "entropy": 1.16925790309906, "incre_win_rate": 0.05263157894736842, "step": 167}
{"time": 1767331893.6017723, "phase": "train", "update": 168, "total_env_steps": 537600, "episode_reward": 0.14407388865947723, "value_loss": 0.031239217892289162, "policy_loss": -0.0011241139230952824, "dist_entropy": 1.1617646932601928, "actor_grad_norm": 0.0755956694483757, "critic_grad_norm": 0.1234075203537941, "ratio": 0.999975323677063, "entropy": 1.1617646932601928, "incre_win_rate": 0.07692307692307693, "step": 168}
{"time": 1767331897.6303465, "phase": "train", "update": 169, "total_env_steps": 540800, "episode_reward": 0.1419582962989807, "value_loss": 0.0323284275829792, "policy_loss": -0.0007685975049714245, "dist_entropy": 1.1739266872406007, "actor_grad_norm": 0.07545489817857742, "critic_grad_norm": 0.09251102805137634, "ratio": 0.9996001124382019, "entropy": 1.1739266872406007, "incre_win_rate": 0.05128205128205128, "step": 169}
{"time": 1767331901.674155, "phase": "train", "update": 170, "total_env_steps": 544000, "episode_reward": 0.14252586662769318, "value_loss": 0.024447214603424073, "policy_loss": -0.0008811310969750963, "dist_entropy": 1.1762848377227784, "actor_grad_norm": 0.1279633790254593, "critic_grad_norm": 0.06817393004894257, "ratio": 0.9998852014541626, "entropy": 1.1762848377227784, "incre_win_rate": 0.02564102564102564, "step": 170}
{"time": 1767331905.7074082, "phase": "train", "update": 171, "total_env_steps": 547200, "episode_reward": 0.1467844545841217, "value_loss": 0.03267304748296738, "policy_loss": -0.0012651341715635312, "dist_entropy": 1.1647038221359254, "actor_grad_norm": 0.15224693715572357, "critic_grad_norm": 0.21177129447460175, "ratio": 0.9998933672904968, "entropy": 1.1647038221359254, "incre_win_rate": 0.14285714285714285, "step": 171}
{"time": 1767331909.7680993, "phase": "train", "update": 172, "total_env_steps": 550400, "episode_reward": 0.13983288407325745, "value_loss": 0.02792682871222496, "policy_loss": -0.0014976055630969043, "dist_entropy": 1.2047542810440064, "actor_grad_norm": 0.14614680409431458, "critic_grad_norm": 0.147140234708786, "ratio": 1.0001273155212402, "entropy": 1.2047542810440064, "incre_win_rate": 0.0, "step": 172}
{"time": 1767331913.8270576, "phase": "train", "update": 173, "total_env_steps": 553600, "episode_reward": 0.1360575407743454, "value_loss": 0.0345929890871048, "policy_loss": -0.0012503291288965101, "dist_entropy": 1.1881893157958985, "actor_grad_norm": 0.12044878304004669, "critic_grad_norm": 0.1971621811389923, "ratio": 1.000363826751709, "entropy": 1.1881893157958985, "incre_win_rate": 0.07692307692307693, "step": 173}
{"time": 1767331917.858535, "phase": "train", "update": 174, "total_env_steps": 556800, "episode_reward": 0.1341954618692398, "value_loss": 0.04818567857146263, "policy_loss": -0.0013650440639935368, "dist_entropy": 1.1650564670562744, "actor_grad_norm": 0.0791110247373581, "critic_grad_norm": 0.22951047122478485, "ratio": 1.000087022781372, "entropy": 1.1650564670562744, "incre_win_rate": 0.02702702702702703, "step": 174}
{"time": 1767331921.99936, "phase": "train", "update": 175, "total_env_steps": 560000, "episode_reward": 0.14651335775852203, "value_loss": 0.042480211704969406, "policy_loss": -0.0007699076613725709, "dist_entropy": 1.1995763778686523, "actor_grad_norm": 0.11682888120412827, "critic_grad_norm": 0.2719559371471405, "ratio": 1.0004525184631348, "entropy": 1.1995763778686523, "incre_win_rate": 0.19444444444444445, "step": 175}
{"time": 1767331926.0688624, "phase": "train", "update": 176, "total_env_steps": 563200, "episode_reward": 0.12766297161579132, "value_loss": 0.04152166917920112, "policy_loss": -0.0014641612812503978, "dist_entropy": 1.1816614389419555, "actor_grad_norm": 0.10604994744062424, "critic_grad_norm": 0.20995239913463593, "ratio": 1.000091791152954, "entropy": 1.1816614389419555, "incre_win_rate": 0.0, "step": 176}
{"time": 1767331939.9843335, "phase": "eval", "update": 176, "total_env_steps": 563200, "eval_win_rate": 0.03125, "eval_episode_reward": 10.509002483443703, "step": 176}
{"time": 1767331943.948647, "phase": "train", "update": 177, "total_env_steps": 566400, "episode_reward": 0.1364683359861374, "value_loss": 0.044797585159540174, "policy_loss": -0.0011844534966165554, "dist_entropy": 1.1692747831344605, "actor_grad_norm": 0.08584295958280563, "critic_grad_norm": 0.3106749355792999, "ratio": 0.9995658993721008, "entropy": 1.1692747831344605, "incre_win_rate": 0.15625, "step": 177}
{"time": 1767331947.969962, "phase": "train", "update": 178, "total_env_steps": 569600, "episode_reward": 0.13274937868118286, "value_loss": 0.034848767518997195, "policy_loss": -0.001213602420723614, "dist_entropy": 1.1610893487930298, "actor_grad_norm": 0.0886974036693573, "critic_grad_norm": 0.30840978026390076, "ratio": 0.9998831152915955, "entropy": 1.1610893487930298, "incre_win_rate": 0.05405405405405406, "step": 178}
{"time": 1767331952.250013, "phase": "train", "update": 179, "total_env_steps": 572800, "episode_reward": 0.1429164856672287, "value_loss": 0.04726223796606064, "policy_loss": -0.0011358543253003005, "dist_entropy": 1.145086908340454, "actor_grad_norm": 0.10080759972333908, "critic_grad_norm": 0.17979489266872406, "ratio": 0.9998467564582825, "entropy": 1.145086908340454, "incre_win_rate": 0.22580645161290322, "step": 179}
{"time": 1767331956.5405996, "phase": "train", "update": 180, "total_env_steps": 576000, "episode_reward": 0.14378932118415833, "value_loss": 0.03721568137407303, "policy_loss": -0.0009530299458340163, "dist_entropy": 1.1476292848587035, "actor_grad_norm": 0.11070870608091354, "critic_grad_norm": 0.09830596297979355, "ratio": 0.9999999403953552, "entropy": 1.1476292848587035, "incre_win_rate": 0.125, "step": 180}
{"time": 1767331960.7341099, "phase": "train", "update": 181, "total_env_steps": 579200, "episode_reward": 0.13595664501190186, "value_loss": 0.040740064531564715, "policy_loss": -0.0009210196700191631, "dist_entropy": 1.1471739768981934, "actor_grad_norm": 0.1105170026421547, "critic_grad_norm": 0.1412157118320465, "ratio": 1.0003808736801147, "entropy": 1.1471739768981934, "incre_win_rate": 0.08571428571428572, "step": 181}
{"time": 1767331964.9386241, "phase": "train", "update": 182, "total_env_steps": 582400, "episode_reward": 0.1340552568435669, "value_loss": 0.06225247234106064, "policy_loss": -0.0006080448808610583, "dist_entropy": 1.1161944150924683, "actor_grad_norm": 0.08673452585935593, "critic_grad_norm": 0.23254159092903137, "ratio": 1.0004223585128784, "entropy": 1.1161944150924683, "incre_win_rate": 0.08571428571428572, "step": 182}
{"time": 1767331969.0377963, "phase": "train", "update": 183, "total_env_steps": 585600, "episode_reward": 0.14598044753074646, "value_loss": 0.05593579187989235, "policy_loss": -0.0009176607748173637, "dist_entropy": 1.15539870262146, "actor_grad_norm": 0.09118642657995224, "critic_grad_norm": 0.16842198371887207, "ratio": 1.0002011060714722, "entropy": 1.15539870262146, "incre_win_rate": 0.15789473684210525, "step": 183}
{"time": 1767331973.0909553, "phase": "train", "update": 184, "total_env_steps": 588800, "episode_reward": 0.1390785425901413, "value_loss": 0.04949191212654114, "policy_loss": -0.0013391151136612934, "dist_entropy": 1.1470085382461548, "actor_grad_norm": 0.10731463879346848, "critic_grad_norm": 0.132032111287117, "ratio": 1.0002470016479492, "entropy": 1.1470085382461548, "incre_win_rate": 0.027777777777777776, "step": 184}
{"time": 1767331977.171114, "phase": "train", "update": 185, "total_env_steps": 592000, "episode_reward": 0.14297859370708466, "value_loss": 0.03756054863333702, "policy_loss": -0.0007691139351649667, "dist_entropy": 1.185434889793396, "actor_grad_norm": 0.10774991661310196, "critic_grad_norm": 0.21666446328163147, "ratio": 1.0001516342163086, "entropy": 1.185434889793396, "incre_win_rate": 0.075, "step": 185}
{"time": 1767331981.255115, "phase": "train", "update": 186, "total_env_steps": 595200, "episode_reward": 0.1459406018257141, "value_loss": 0.03956648483872414, "policy_loss": -0.0021246694524144514, "dist_entropy": 1.1676551580429078, "actor_grad_norm": 0.13997480273246765, "critic_grad_norm": 0.20552514493465424, "ratio": 1.0003329515457153, "entropy": 1.1676551580429078, "incre_win_rate": 0.08571428571428572, "step": 186}
{"time": 1767331985.275796, "phase": "train", "update": 187, "total_env_steps": 598400, "episode_reward": 0.14240221679210663, "value_loss": 0.042424656450748444, "policy_loss": -0.0010941006954201526, "dist_entropy": 1.1997185230255127, "actor_grad_norm": 0.08367396891117096, "critic_grad_norm": 0.26483556628227234, "ratio": 0.9995028376579285, "entropy": 1.1997185230255127, "incre_win_rate": 0.17142857142857143, "step": 187}
{"time": 1767331989.3679276, "phase": "train", "update": 188, "total_env_steps": 601600, "episode_reward": 0.13737428188323975, "value_loss": 0.03848305270075798, "policy_loss": -0.0015665089845516178, "dist_entropy": 1.208692765235901, "actor_grad_norm": 0.084805928170681, "critic_grad_norm": 0.30262595415115356, "ratio": 1.0000020265579224, "entropy": 1.208692765235901, "incre_win_rate": 0.02564102564102564, "step": 188}
{"time": 1767331993.4323392, "phase": "train", "update": 189, "total_env_steps": 604800, "episode_reward": 0.1396828442811966, "value_loss": 0.04691332876682282, "policy_loss": -0.0007096736230099765, "dist_entropy": 1.178618884086609, "actor_grad_norm": 0.09268251061439514, "critic_grad_norm": 0.21351194381713867, "ratio": 1.0004018545150757, "entropy": 1.178618884086609, "incre_win_rate": 0.08571428571428572, "step": 189}
{"time": 1767331997.4724855, "phase": "train", "update": 190, "total_env_steps": 608000, "episode_reward": 0.12533682584762573, "value_loss": 0.046324451267719266, "policy_loss": -0.0008796405512839556, "dist_entropy": 1.124162983894348, "actor_grad_norm": 0.08336156606674194, "critic_grad_norm": 0.2926956117153168, "ratio": 1.0003641843795776, "entropy": 1.124162983894348, "incre_win_rate": 0.08108108108108109, "step": 190}
{"time": 1767332001.444045, "phase": "train", "update": 191, "total_env_steps": 611200, "episode_reward": 0.14320622384548187, "value_loss": 0.031661861762404445, "policy_loss": -0.0005418022124144883, "dist_entropy": 1.2007595777511597, "actor_grad_norm": 0.1194431409239769, "critic_grad_norm": 0.1717761605978012, "ratio": 1.0003042221069336, "entropy": 1.2007595777511597, "incre_win_rate": 0.02857142857142857, "step": 191}
{"time": 1767332005.4807186, "phase": "train", "update": 192, "total_env_steps": 614400, "episode_reward": 0.135677769780159, "value_loss": 0.03833243101835251, "policy_loss": -0.0012261673215689939, "dist_entropy": 1.186403250694275, "actor_grad_norm": 0.11332541704177856, "critic_grad_norm": 0.16655807197093964, "ratio": 1.0002344846725464, "entropy": 1.186403250694275, "incre_win_rate": 0.05263157894736842, "step": 192}
{"time": 1767332009.539401, "phase": "train", "update": 193, "total_env_steps": 617600, "episode_reward": 0.14131209254264832, "value_loss": 0.035545431077480316, "policy_loss": -0.0009000352236817833, "dist_entropy": 1.168968629837036, "actor_grad_norm": 0.1316559910774231, "critic_grad_norm": 0.18294928967952728, "ratio": 1.0001658201217651, "entropy": 1.168968629837036, "incre_win_rate": 0.08333333333333333, "step": 193}
{"time": 1767332013.6288016, "phase": "train", "update": 194, "total_env_steps": 620800, "episode_reward": 0.13915874063968658, "value_loss": 0.03946426212787628, "policy_loss": -0.0011656180106886182, "dist_entropy": 1.1158036708831787, "actor_grad_norm": 0.11221740394830704, "critic_grad_norm": 0.17352871596813202, "ratio": 1.0001298189163208, "entropy": 1.1158036708831787, "incre_win_rate": 0.11764705882352941, "step": 194}
{"time": 1767332017.6789436, "phase": "train", "update": 195, "total_env_steps": 624000, "episode_reward": 0.14477752149105072, "value_loss": 0.049863656610250474, "policy_loss": -0.0009035173027299948, "dist_entropy": 1.122176957130432, "actor_grad_norm": 0.06578384339809418, "critic_grad_norm": 0.17902417480945587, "ratio": 0.9997863173484802, "entropy": 1.122176957130432, "incre_win_rate": 0.10526315789473684, "step": 195}
{"time": 1767332021.72336, "phase": "train", "update": 196, "total_env_steps": 627200, "episode_reward": 0.14403973519802094, "value_loss": 0.03432310521602631, "policy_loss": -0.0014151368206754, "dist_entropy": 1.1249634981155396, "actor_grad_norm": 0.1156952753663063, "critic_grad_norm": 0.1470274031162262, "ratio": 0.9995245337486267, "entropy": 1.1249634981155396, "incre_win_rate": 0.08571428571428572, "step": 196}
{"time": 1767332025.7294695, "phase": "train", "update": 197, "total_env_steps": 630400, "episode_reward": 0.15503674745559692, "value_loss": 0.03721748515963554, "policy_loss": -0.0010629655914376813, "dist_entropy": 1.13589928150177, "actor_grad_norm": 0.09796217083930969, "critic_grad_norm": 0.11803191900253296, "ratio": 1.0001269578933716, "entropy": 1.13589928150177, "incre_win_rate": 0.16666666666666666, "step": 197}
{"time": 1767332029.7918632, "phase": "train", "update": 198, "total_env_steps": 633600, "episode_reward": 0.1532445102930069, "value_loss": 0.04989353120326996, "policy_loss": -0.0013727016121212188, "dist_entropy": 1.127616024017334, "actor_grad_norm": 0.10828317701816559, "critic_grad_norm": 0.15222075581550598, "ratio": 1.000543475151062, "entropy": 1.127616024017334, "incre_win_rate": 0.22857142857142856, "step": 198}
{"time": 1767332033.8060281, "phase": "train", "update": 199, "total_env_steps": 636800, "episode_reward": 0.14446191489696503, "value_loss": 0.037178822606801984, "policy_loss": -0.0008266548260394302, "dist_entropy": 1.1322976350784302, "actor_grad_norm": 0.07612364739179611, "critic_grad_norm": 0.1484815925359726, "ratio": 1.0001633167266846, "entropy": 1.1322976350784302, "incre_win_rate": 0.07692307692307693, "step": 199}
{"time": 1767332037.847539, "phase": "train", "update": 200, "total_env_steps": 640000, "episode_reward": 0.14644816517829895, "value_loss": 0.037768350541591646, "policy_loss": -0.0015722073107070854, "dist_entropy": 1.1080303907394409, "actor_grad_norm": 0.0870806872844696, "critic_grad_norm": 0.1053558960556984, "ratio": 0.9999080896377563, "entropy": 1.1080303907394409, "incre_win_rate": 0.13513513513513514, "step": 200}
{"time": 1767332041.915074, "phase": "train", "update": 201, "total_env_steps": 643200, "episode_reward": 0.13880328834056854, "value_loss": 0.04376437067985535, "policy_loss": -0.0009561059864594768, "dist_entropy": 1.0762476444244384, "actor_grad_norm": 0.08737380802631378, "critic_grad_norm": 0.226649671792984, "ratio": 0.9998982548713684, "entropy": 1.0762476444244384, "incre_win_rate": 0.05714285714285714, "step": 201}
{"time": 1767332054.9206948, "phase": "eval", "update": 201, "total_env_steps": 643200, "eval_win_rate": 0.21875, "eval_episode_reward": 14.210627069536422, "step": 201}
{"time": 1767332058.9428196, "phase": "train", "update": 202, "total_env_steps": 646400, "episode_reward": 0.1520850509405136, "value_loss": 0.04659075066447258, "policy_loss": -0.0013229311760980522, "dist_entropy": 1.1022936820983886, "actor_grad_norm": 0.1190970167517662, "critic_grad_norm": 0.18448369204998016, "ratio": 0.9996551871299744, "entropy": 1.1022936820983886, "incre_win_rate": 0.2, "step": 202}
{"time": 1767332062.9590573, "phase": "train", "update": 203, "total_env_steps": 649600, "episode_reward": 0.14588524401187897, "value_loss": 0.04744489192962646, "policy_loss": -0.0006889236457588765, "dist_entropy": 1.075886034965515, "actor_grad_norm": 0.10315924137830734, "critic_grad_norm": 0.2220689356327057, "ratio": 1.0004093647003174, "entropy": 1.075886034965515, "incre_win_rate": 0.14705882352941177, "step": 203}
{"time": 1767332066.9843397, "phase": "train", "update": 204, "total_env_steps": 652800, "episode_reward": 0.1500977873802185, "value_loss": 0.04474745392799377, "policy_loss": -0.0012656803882286737, "dist_entropy": 1.132538342475891, "actor_grad_norm": 0.14673565328121185, "critic_grad_norm": 0.1214045062661171, "ratio": 0.9998245239257812, "entropy": 1.132538342475891, "incre_win_rate": 0.19444444444444445, "step": 204}
{"time": 1767332071.0059183, "phase": "train", "update": 205, "total_env_steps": 656000, "episode_reward": 0.1375470757484436, "value_loss": 0.05001376643776893, "policy_loss": -0.0012288960571680719, "dist_entropy": 1.1211643934249877, "actor_grad_norm": 0.09573803097009659, "critic_grad_norm": 0.33363252878189087, "ratio": 1.000059962272644, "entropy": 1.1211643934249877, "incre_win_rate": 0.08333333333333333, "step": 205}
{"time": 1767332075.0710728, "phase": "train", "update": 206, "total_env_steps": 659200, "episode_reward": 0.15240687131881714, "value_loss": 0.035380953550338747, "policy_loss": -0.0008434135799831211, "dist_entropy": 1.1384140253067017, "actor_grad_norm": 0.09985940903425217, "critic_grad_norm": 0.216936856508255, "ratio": 1.0000308752059937, "entropy": 1.1384140253067017, "incre_win_rate": 0.10256410256410256, "step": 206}
{"time": 1767332079.088504, "phase": "train", "update": 207, "total_env_steps": 662400, "episode_reward": 0.13041597604751587, "value_loss": 0.03465511724352836, "policy_loss": -0.0015226129755191663, "dist_entropy": 1.1339046001434325, "actor_grad_norm": 0.09317079186439514, "critic_grad_norm": 0.24542053043842316, "ratio": 0.9996418952941895, "entropy": 1.1339046001434325, "incre_win_rate": 0.02702702702702703, "step": 207}
{"time": 1767332083.1221516, "phase": "train", "update": 208, "total_env_steps": 665600, "episode_reward": 0.1504785716533661, "value_loss": 0.03958182632923126, "policy_loss": -0.0011914474649614704, "dist_entropy": 1.1531208276748657, "actor_grad_norm": 0.09687685966491699, "critic_grad_norm": 0.27550849318504333, "ratio": 1.0001347064971924, "entropy": 1.1531208276748657, "incre_win_rate": 0.08571428571428572, "step": 208}
{"time": 1767332087.1719642, "phase": "train", "update": 209, "total_env_steps": 668800, "episode_reward": 0.14639900624752045, "value_loss": 0.031227235868573188, "policy_loss": -0.0011331530906332431, "dist_entropy": 1.1310823440551758, "actor_grad_norm": 0.1046084314584732, "critic_grad_norm": 0.2597787380218506, "ratio": 1.0001236200332642, "entropy": 1.1310823440551758, "incre_win_rate": 0.1, "step": 209}
{"time": 1767332091.183162, "phase": "train", "update": 210, "total_env_steps": 672000, "episode_reward": 0.1441820114850998, "value_loss": 0.03023698925971985, "policy_loss": -0.0012879661474023863, "dist_entropy": 1.1194249629974364, "actor_grad_norm": 0.09649725258350372, "critic_grad_norm": 0.1922215074300766, "ratio": 1.000085711479187, "entropy": 1.1194249629974364, "incre_win_rate": 0.027777777777777776, "step": 210}
{"time": 1767332095.1790867, "phase": "train", "update": 211, "total_env_steps": 675200, "episode_reward": 0.14315810799598694, "value_loss": 0.03992081061005592, "policy_loss": -0.0011320482010063414, "dist_entropy": 1.1426876306533813, "actor_grad_norm": 0.09012441337108612, "critic_grad_norm": 0.16873399913311005, "ratio": 0.9998151659965515, "entropy": 1.1426876306533813, "incre_win_rate": 0.10810810810810811, "step": 211}
{"time": 1767332099.199772, "phase": "train", "update": 212, "total_env_steps": 678400, "episode_reward": 0.1416432112455368, "value_loss": 0.032401769608259204, "policy_loss": -0.0008858004048164503, "dist_entropy": 1.1310463428497315, "actor_grad_norm": 0.11895964294672012, "critic_grad_norm": 0.12539134919643402, "ratio": 0.9999990463256836, "entropy": 1.1310463428497315, "incre_win_rate": 0.08108108108108109, "step": 212}
{"time": 1767332103.2949364, "phase": "train", "update": 213, "total_env_steps": 681600, "episode_reward": 0.13916340470314026, "value_loss": 0.026697210595011713, "policy_loss": -0.001219484012986527, "dist_entropy": 1.145464825630188, "actor_grad_norm": 0.09765457361936569, "critic_grad_norm": 0.13167798519134521, "ratio": 0.9999597668647766, "entropy": 1.145464825630188, "incre_win_rate": 0.05, "step": 213}
{"time": 1767332107.3367994, "phase": "train", "update": 214, "total_env_steps": 684800, "episode_reward": 0.15093180537223816, "value_loss": 0.03057943396270275, "policy_loss": -0.0011941111604969023, "dist_entropy": 1.1208217859268188, "actor_grad_norm": 0.07499092072248459, "critic_grad_norm": 0.16255943477153778, "ratio": 0.9999331831932068, "entropy": 1.1208217859268188, "incre_win_rate": 0.07894736842105263, "step": 214}
{"time": 1767332111.382698, "phase": "train", "update": 215, "total_env_steps": 688000, "episode_reward": 0.15375465154647827, "value_loss": 0.03246926739811897, "policy_loss": -0.0011563707280798142, "dist_entropy": 1.1346871376037597, "actor_grad_norm": 0.13556624948978424, "critic_grad_norm": 0.11746864765882492, "ratio": 0.9998207092285156, "entropy": 1.1346871376037597, "incre_win_rate": 0.125, "step": 215}
{"time": 1767332115.4050431, "phase": "train", "update": 216, "total_env_steps": 691200, "episode_reward": 0.14435017108917236, "value_loss": 0.02995062358677387, "policy_loss": -0.0011902498284463547, "dist_entropy": 1.1251526117324828, "actor_grad_norm": 0.15238456428050995, "critic_grad_norm": 0.08632641285657883, "ratio": 0.9998465776443481, "entropy": 1.1251526117324828, "incre_win_rate": 0.10810810810810811, "step": 216}
{"time": 1767332119.4566205, "phase": "train", "update": 217, "total_env_steps": 694400, "episode_reward": 0.14688639342784882, "value_loss": 0.02973664365708828, "policy_loss": -0.0012669982505887135, "dist_entropy": 1.1251912117004395, "actor_grad_norm": 0.1097823902964592, "critic_grad_norm": 0.14665327966213226, "ratio": 1.0000241994857788, "entropy": 1.1251912117004395, "incre_win_rate": 0.07317073170731707, "step": 217}
{"time": 1767332123.445229, "phase": "train", "update": 218, "total_env_steps": 697600, "episode_reward": 0.13600113987922668, "value_loss": 0.038796267658472064, "policy_loss": -0.0013549408546015052, "dist_entropy": 1.0914448022842407, "actor_grad_norm": 0.11187290400266647, "critic_grad_norm": 0.12497835606336594, "ratio": 0.9998875856399536, "entropy": 1.0914448022842407, "incre_win_rate": 0.05714285714285714, "step": 218}
{"time": 1767332127.4734445, "phase": "train", "update": 219, "total_env_steps": 700800, "episode_reward": 0.14611133933067322, "value_loss": 0.03133216612040997, "policy_loss": -0.0017984704518823947, "dist_entropy": 1.1532527923583984, "actor_grad_norm": 0.12497439235448837, "critic_grad_norm": 0.1293412297964096, "ratio": 1.0001319646835327, "entropy": 1.1532527923583984, "incre_win_rate": 0.075, "step": 219}
{"time": 1767332131.475992, "phase": "train", "update": 220, "total_env_steps": 704000, "episode_reward": 0.15150092542171478, "value_loss": 0.03449646383523941, "policy_loss": -0.0009119738094476304, "dist_entropy": 1.137650489807129, "actor_grad_norm": 0.12204849720001221, "critic_grad_norm": 0.108964703977108, "ratio": 1.000393271446228, "entropy": 1.137650489807129, "incre_win_rate": 0.11428571428571428, "step": 220}
{"time": 1767332135.5384488, "phase": "train", "update": 221, "total_env_steps": 707200, "episode_reward": 0.14889641106128693, "value_loss": 0.05215617343783378, "policy_loss": -0.0014433345472816938, "dist_entropy": 1.1250845909118652, "actor_grad_norm": 0.16580669581890106, "critic_grad_norm": 0.11262676864862442, "ratio": 0.9998540878295898, "entropy": 1.1250845909118652, "incre_win_rate": 0.2222222222222222, "step": 221}
{"time": 1767332139.5799334, "phase": "train", "update": 222, "total_env_steps": 710400, "episode_reward": 0.14194899797439575, "value_loss": 0.04255777075886726, "policy_loss": -0.0012075116260110263, "dist_entropy": 1.1357167720794679, "actor_grad_norm": 0.11685621738433838, "critic_grad_norm": 0.0957433208823204, "ratio": 0.9997450113296509, "entropy": 1.1357167720794679, "incre_win_rate": 0.13513513513513514, "step": 222}
{"time": 1767332143.632194, "phase": "train", "update": 223, "total_env_steps": 713600, "episode_reward": 0.14811983704566956, "value_loss": 0.043313073366880415, "policy_loss": -0.0009414411750555019, "dist_entropy": 1.1564696788787843, "actor_grad_norm": 0.08707856386899948, "critic_grad_norm": 0.09965530037879944, "ratio": 1.0001648664474487, "entropy": 1.1564696788787843, "incre_win_rate": 0.10526315789473684, "step": 223}
{"time": 1767332147.7165916, "phase": "train", "update": 224, "total_env_steps": 716800, "episode_reward": 0.14832988381385803, "value_loss": 0.040916557610034945, "policy_loss": -0.0009399510093558661, "dist_entropy": 1.1275947093963623, "actor_grad_norm": 0.08478042483329773, "critic_grad_norm": 0.09416236728429794, "ratio": 0.9999931454658508, "entropy": 1.1275947093963623, "incre_win_rate": 0.1282051282051282, "step": 224}
{"time": 1767332151.7248254, "phase": "train", "update": 225, "total_env_steps": 720000, "episode_reward": 0.15618430078029633, "value_loss": 0.04532813876867294, "policy_loss": -0.0012178035865936464, "dist_entropy": 1.0957355260849, "actor_grad_norm": 0.0924486294388771, "critic_grad_norm": 0.21211674809455872, "ratio": 0.9999732971191406, "entropy": 1.0957355260849, "incre_win_rate": 0.08571428571428572, "step": 225}
{"time": 1767332155.7154255, "phase": "train", "update": 226, "total_env_steps": 723200, "episode_reward": 0.14647608995437622, "value_loss": 0.03660455048084259, "policy_loss": -0.0010709487464453105, "dist_entropy": 1.0954480648040772, "actor_grad_norm": 0.07726623862981796, "critic_grad_norm": 0.24675726890563965, "ratio": 0.9997782707214355, "entropy": 1.0954480648040772, "incre_win_rate": 0.15789473684210525, "step": 226}
{"time": 1767332166.8453755, "phase": "eval", "update": 226, "total_env_steps": 723200, "eval_win_rate": 0.15625, "eval_episode_reward": 11.757605546357615, "step": 226}
{"time": 1767332170.8233664, "phase": "train", "update": 227, "total_env_steps": 726400, "episode_reward": 0.14723613858222961, "value_loss": 0.03662544339895248, "policy_loss": -0.001480069135263129, "dist_entropy": 1.0780250549316406, "actor_grad_norm": 0.0990297943353653, "critic_grad_norm": 0.15617284178733826, "ratio": 1.0002548694610596, "entropy": 1.0780250549316406, "incre_win_rate": 0.16666666666666666, "step": 227}
{"time": 1767332174.8449671, "phase": "train", "update": 228, "total_env_steps": 729600, "episode_reward": 0.1419132798910141, "value_loss": 0.039719315618276595, "policy_loss": -0.0012970014555044429, "dist_entropy": 1.065299916267395, "actor_grad_norm": 0.12094981968402863, "critic_grad_norm": 0.11981215327978134, "ratio": 1.0000970363616943, "entropy": 1.065299916267395, "incre_win_rate": 0.13513513513513514, "step": 228}
{"time": 1767332178.8589976, "phase": "train", "update": 229, "total_env_steps": 732800, "episode_reward": 0.1441623568534851, "value_loss": 0.03958957344293594, "policy_loss": -0.0013580286316797086, "dist_entropy": 1.0523258686065673, "actor_grad_norm": 0.07928561419248581, "critic_grad_norm": 0.09154330939054489, "ratio": 1.0002437829971313, "entropy": 1.0523258686065673, "incre_win_rate": 0.18181818181818182, "step": 229}
{"time": 1767332182.8699672, "phase": "train", "update": 230, "total_env_steps": 736000, "episode_reward": 0.14834022521972656, "value_loss": 0.046304679661989215, "policy_loss": -0.0010175148758804653, "dist_entropy": 1.0612342834472657, "actor_grad_norm": 0.07554629445075989, "critic_grad_norm": 0.11756652593612671, "ratio": 1.0000823736190796, "entropy": 1.0612342834472657, "incre_win_rate": 0.16216216216216217, "step": 230}
{"time": 1767332186.8740723, "phase": "train", "update": 231, "total_env_steps": 739200, "episode_reward": 0.1491556316614151, "value_loss": 0.040314361453056335, "policy_loss": -0.0010681920973567571, "dist_entropy": 1.048637819290161, "actor_grad_norm": 0.13505887985229492, "critic_grad_norm": 0.1640206277370453, "ratio": 1.0002107620239258, "entropy": 1.048637819290161, "incre_win_rate": 0.2, "step": 231}
{"time": 1767332190.8858614, "phase": "train", "update": 232, "total_env_steps": 742400, "episode_reward": 0.14424410462379456, "value_loss": 0.054303301870822905, "policy_loss": -0.0008147400805221139, "dist_entropy": 1.0496679067611694, "actor_grad_norm": 0.06960960477590561, "critic_grad_norm": 0.1642715185880661, "ratio": 1.0001089572906494, "entropy": 1.0496679067611694, "incre_win_rate": 0.16666666666666666, "step": 232}
{"time": 1767332194.9170737, "phase": "train", "update": 233, "total_env_steps": 745600, "episode_reward": 0.15764227509498596, "value_loss": 0.05025230124592781, "policy_loss": -0.0014082739224161144, "dist_entropy": 1.0538012266159058, "actor_grad_norm": 0.1014380007982254, "critic_grad_norm": 0.33208057284355164, "ratio": 1.0001161098480225, "entropy": 1.0538012266159058, "incre_win_rate": 0.2647058823529412, "step": 233}
{"time": 1767332198.9336238, "phase": "train", "update": 234, "total_env_steps": 748800, "episode_reward": 0.15649059414863586, "value_loss": 0.04352208599448204, "policy_loss": -0.0013711187184302532, "dist_entropy": 1.0500598907470704, "actor_grad_norm": 0.10000941902399063, "critic_grad_norm": 0.21313682198524475, "ratio": 0.9997686743736267, "entropy": 1.0500598907470704, "incre_win_rate": 0.2727272727272727, "step": 234}
{"time": 1767332202.9594924, "phase": "train", "update": 235, "total_env_steps": 752000, "episode_reward": 0.15101458132266998, "value_loss": 0.03693942651152611, "policy_loss": -0.0011145777976892645, "dist_entropy": 1.0793469190597533, "actor_grad_norm": 0.15830041468143463, "critic_grad_norm": 0.20734336972236633, "ratio": 1.0001071691513062, "entropy": 1.0793469190597533, "incre_win_rate": 0.13513513513513514, "step": 235}
{"time": 1767332206.9706821, "phase": "train", "update": 236, "total_env_steps": 755200, "episode_reward": 0.15072950720787048, "value_loss": 0.032405772060155866, "policy_loss": -0.0013472627759032463, "dist_entropy": 1.0617197036743165, "actor_grad_norm": 0.10688189417123795, "critic_grad_norm": 0.14525297284126282, "ratio": 0.9996426701545715, "entropy": 1.0617197036743165, "incre_win_rate": 0.08333333333333333, "step": 236}
{"time": 1767332211.007169, "phase": "train", "update": 237, "total_env_steps": 758400, "episode_reward": 0.14395643770694733, "value_loss": 0.0346266508102417, "policy_loss": -0.0011090435892889162, "dist_entropy": 1.083590292930603, "actor_grad_norm": 0.11439043283462524, "critic_grad_norm": 0.10775281488895416, "ratio": 1.0000487565994263, "entropy": 1.083590292930603, "incre_win_rate": 0.16216216216216217, "step": 237}
{"time": 1767332215.0151901, "phase": "train", "update": 238, "total_env_steps": 761600, "episode_reward": 0.1578875184059143, "value_loss": 0.035139694809913635, "policy_loss": -0.0011687219956868944, "dist_entropy": 1.079647994041443, "actor_grad_norm": 0.15079933404922485, "critic_grad_norm": 0.20216941833496094, "ratio": 1.0002764463424683, "entropy": 1.079647994041443, "incre_win_rate": 0.19444444444444445, "step": 238}
{"time": 1767332219.038832, "phase": "train", "update": 239, "total_env_steps": 764800, "episode_reward": 0.14935535192489624, "value_loss": 0.04600811526179314, "policy_loss": -0.001222073935172574, "dist_entropy": 1.0652369737625123, "actor_grad_norm": 0.1101636067032814, "critic_grad_norm": 0.16164356470108032, "ratio": 1.0001497268676758, "entropy": 1.0652369737625123, "incre_win_rate": 0.1891891891891892, "step": 239}
{"time": 1767332223.0855048, "phase": "train", "update": 240, "total_env_steps": 768000, "episode_reward": 0.15164735913276672, "value_loss": 0.05193547457456589, "policy_loss": -0.0012638984726898173, "dist_entropy": 1.026006531715393, "actor_grad_norm": 0.17076091468334198, "critic_grad_norm": 0.1148613840341568, "ratio": 0.9998334050178528, "entropy": 1.026006531715393, "incre_win_rate": 0.3055555555555556, "step": 240}
{"time": 1767332227.1405952, "phase": "train", "update": 241, "total_env_steps": 771200, "episode_reward": 0.16759778559207916, "value_loss": 0.05157135203480721, "policy_loss": -0.0013417741965170648, "dist_entropy": 1.0405773162841796, "actor_grad_norm": 0.12879273295402527, "critic_grad_norm": 0.1913987100124359, "ratio": 0.9995142221450806, "entropy": 1.0405773162841796, "incre_win_rate": 0.46875, "step": 241}
{"time": 1767332231.1360464, "phase": "train", "update": 242, "total_env_steps": 774400, "episode_reward": 0.15395592153072357, "value_loss": 0.0458158515393734, "policy_loss": -0.0010193412100278465, "dist_entropy": 1.0339401960372925, "actor_grad_norm": 0.0883118286728859, "critic_grad_norm": 0.12423297017812729, "ratio": 1.0000377893447876, "entropy": 1.0339401960372925, "incre_win_rate": 0.24324324324324326, "step": 242}
{"time": 1767332235.1448536, "phase": "train", "update": 243, "total_env_steps": 777600, "episode_reward": 0.15388193726539612, "value_loss": 0.05744493678212166, "policy_loss": -0.0013899169668317058, "dist_entropy": 1.0041676044464112, "actor_grad_norm": 0.13118363916873932, "critic_grad_norm": 0.12302520126104355, "ratio": 0.9999552965164185, "entropy": 1.0041676044464112, "incre_win_rate": 0.3055555555555556, "step": 243}
{"time": 1767332239.1788292, "phase": "train", "update": 244, "total_env_steps": 780800, "episode_reward": 0.16413907706737518, "value_loss": 0.05643849670886993, "policy_loss": -0.0010814990731994102, "dist_entropy": 1.0355928659439086, "actor_grad_norm": 0.1308758705854416, "critic_grad_norm": 0.1831120252609253, "ratio": 1.0001498460769653, "entropy": 1.0355928659439086, "incre_win_rate": 0.25, "step": 244}
{"time": 1767332243.1852927, "phase": "train", "update": 245, "total_env_steps": 784000, "episode_reward": 0.16271936893463135, "value_loss": 0.05016881227493286, "policy_loss": -0.0012693867416954997, "dist_entropy": 0.9876338243484497, "actor_grad_norm": 0.17861708998680115, "critic_grad_norm": 0.12684205174446106, "ratio": 1.0004161596298218, "entropy": 0.9876338243484497, "incre_win_rate": 0.34285714285714286, "step": 245}
{"time": 1767332247.2068458, "phase": "train", "update": 246, "total_env_steps": 787200, "episode_reward": 0.17226459085941315, "value_loss": 0.04110670015215874, "policy_loss": -0.001029951701710985, "dist_entropy": 0.9878579020500183, "actor_grad_norm": 0.06335554271936417, "critic_grad_norm": 0.14626236259937286, "ratio": 0.9997175335884094, "entropy": 0.9878579020500183, "incre_win_rate": 0.3333333333333333, "step": 246}
{"time": 1767332251.2497668, "phase": "train", "update": 247, "total_env_steps": 790400, "episode_reward": 0.1648147702217102, "value_loss": 0.04736151769757271, "policy_loss": -0.0015162205864008627, "dist_entropy": 0.9704205632209778, "actor_grad_norm": 0.10033120214939117, "critic_grad_norm": 0.10719247162342072, "ratio": 0.9997947812080383, "entropy": 0.9704205632209778, "incre_win_rate": 0.34285714285714286, "step": 247}
{"time": 1767332255.2592814, "phase": "train", "update": 248, "total_env_steps": 793600, "episode_reward": 0.15887314081192017, "value_loss": 0.0378366120159626, "policy_loss": -0.0011233499917089774, "dist_entropy": 1.0123997688293458, "actor_grad_norm": 0.12797410786151886, "critic_grad_norm": 0.08483099192380905, "ratio": 0.9998435378074646, "entropy": 1.0123997688293458, "incre_win_rate": 0.30303030303030304, "step": 248}
{"time": 1767332259.264316, "phase": "train", "update": 249, "total_env_steps": 796800, "episode_reward": 0.15446503460407257, "value_loss": 0.03590655252337456, "policy_loss": -0.0010457202337896376, "dist_entropy": 0.9759596824645996, "actor_grad_norm": 0.1032906323671341, "critic_grad_norm": 0.07788076996803284, "ratio": 0.9998043179512024, "entropy": 0.9759596824645996, "incre_win_rate": 0.21621621621621623, "step": 249}
{"time": 1767332263.2622707, "phase": "train", "update": 250, "total_env_steps": 800000, "episode_reward": 0.1630856692790985, "value_loss": 0.03914070203900337, "policy_loss": -0.0008597293995443068, "dist_entropy": 0.9827555060386658, "actor_grad_norm": 0.0937933474779129, "critic_grad_norm": 0.060948874801397324, "ratio": 0.9996703267097473, "entropy": 0.9827555060386658, "incre_win_rate": 0.30303030303030304, "step": 250}
{"time": 1767332267.257405, "phase": "train", "update": 251, "total_env_steps": 803200, "episode_reward": 0.15879087150096893, "value_loss": 0.033862514048814775, "policy_loss": -0.0010905808031722586, "dist_entropy": 0.9790706634521484, "actor_grad_norm": 0.09733486920595169, "critic_grad_norm": 0.062953881919384, "ratio": 1.0001550912857056, "entropy": 0.9790706634521484, "incre_win_rate": 0.29411764705882354, "step": 251}
{"time": 1767332280.3725793, "phase": "eval", "update": 251, "total_env_steps": 803200, "eval_win_rate": 0.625, "eval_episode_reward": 17.275093129139073, "step": 251}
{"time": 1767332284.4164937, "phase": "train", "update": 252, "total_env_steps": 806400, "episode_reward": 0.15405577421188354, "value_loss": 0.02990352362394333, "policy_loss": -0.0011078913615087949, "dist_entropy": 1.0086582899093628, "actor_grad_norm": 0.10773894935846329, "critic_grad_norm": 0.15683773159980774, "ratio": 1.0002787113189697, "entropy": 1.0086582899093628, "incre_win_rate": 0.15384615384615385, "step": 252}
{"time": 1767332288.4586496, "phase": "train", "update": 253, "total_env_steps": 809600, "episode_reward": 0.16808050870895386, "value_loss": 0.028848085179924966, "policy_loss": -0.0007873315576102158, "dist_entropy": 0.9732767224311829, "actor_grad_norm": 0.10515613853931427, "critic_grad_norm": 0.17569011449813843, "ratio": 1.000139594078064, "entropy": 0.9732767224311829, "incre_win_rate": 0.30303030303030304, "step": 253}
{"time": 1767332292.4505894, "phase": "train", "update": 254, "total_env_steps": 812800, "episode_reward": 0.16628001630306244, "value_loss": 0.03309647813439369, "policy_loss": -0.0013200730177040042, "dist_entropy": 0.9654030799865723, "actor_grad_norm": 0.07833968847990036, "critic_grad_norm": 0.24027542769908905, "ratio": 1.0001518726348877, "entropy": 0.9654030799865723, "incre_win_rate": 0.375, "step": 254}
{"time": 1767332296.4486492, "phase": "train", "update": 255, "total_env_steps": 816000, "episode_reward": 0.16112840175628662, "value_loss": 0.03939691483974457, "policy_loss": -0.0011735558068810548, "dist_entropy": 0.9578107357025146, "actor_grad_norm": 0.10134819895029068, "critic_grad_norm": 0.12927158176898956, "ratio": 1.0002387762069702, "entropy": 0.9578107357025146, "incre_win_rate": 0.3157894736842105, "step": 255}
{"time": 1767332300.4802027, "phase": "train", "update": 256, "total_env_steps": 819200, "episode_reward": 0.15491515398025513, "value_loss": 0.042361993342638016, "policy_loss": -0.001157237520465415, "dist_entropy": 0.9845660209655762, "actor_grad_norm": 0.12365539371967316, "critic_grad_norm": 0.1697588860988617, "ratio": 0.9997209906578064, "entropy": 0.9845660209655762, "incre_win_rate": 0.1875, "step": 256}
{"time": 1767332304.5044155, "phase": "train", "update": 257, "total_env_steps": 822400, "episode_reward": 0.16525766253471375, "value_loss": 0.03609951734542847, "policy_loss": -0.001646677077449965, "dist_entropy": 0.9577138543128967, "actor_grad_norm": 0.10635566711425781, "critic_grad_norm": 0.11677701771259308, "ratio": 1.0000951290130615, "entropy": 0.9577138543128967, "incre_win_rate": 0.4117647058823529, "step": 257}
{"time": 1767332308.556462, "phase": "train", "update": 258, "total_env_steps": 825600, "episode_reward": 0.1762406975030899, "value_loss": 0.03189579173922539, "policy_loss": -0.0006455488190340475, "dist_entropy": 0.9686185956001282, "actor_grad_norm": 0.10489115864038467, "critic_grad_norm": 0.12399189919233322, "ratio": 1.0001599788665771, "entropy": 0.9686185956001282, "incre_win_rate": 0.42857142857142855, "step": 258}
{"time": 1767332312.6028442, "phase": "train", "update": 259, "total_env_steps": 828800, "episode_reward": 0.1647733896970749, "value_loss": 0.03634429126977921, "policy_loss": -0.0011842832961825422, "dist_entropy": 0.9589172720909118, "actor_grad_norm": 0.1169976219534874, "critic_grad_norm": 0.11424686014652252, "ratio": 1.0003118515014648, "entropy": 0.9589172720909118, "incre_win_rate": 0.4375, "step": 259}
{"time": 1767332316.6176884, "phase": "train", "update": 260, "total_env_steps": 832000, "episode_reward": 0.16920427978038788, "value_loss": 0.031241676211357115, "policy_loss": -0.0009794846480605912, "dist_entropy": 0.9690482378005981, "actor_grad_norm": 0.12301509827375412, "critic_grad_norm": 0.09629777073860168, "ratio": 0.9998617172241211, "entropy": 0.9690482378005981, "incre_win_rate": 0.3888888888888889, "step": 260}
{"time": 1767332320.6048703, "phase": "train", "update": 261, "total_env_steps": 835200, "episode_reward": 0.16735149919986725, "value_loss": 0.035885629057884214, "policy_loss": -0.0010106787003788752, "dist_entropy": 0.9504229664802551, "actor_grad_norm": 0.10772200673818588, "critic_grad_norm": 0.0995054617524147, "ratio": 0.9999908804893494, "entropy": 0.9504229664802551, "incre_win_rate": 0.375, "step": 261}
{"time": 1767332324.6164663, "phase": "train", "update": 262, "total_env_steps": 838400, "episode_reward": 0.17021730542182922, "value_loss": 0.03527235761284828, "policy_loss": -0.0011771079896851333, "dist_entropy": 0.9627708792686462, "actor_grad_norm": 0.08948259800672531, "critic_grad_norm": 0.09165183454751968, "ratio": 0.9999359250068665, "entropy": 0.9627708792686462, "incre_win_rate": 0.42857142857142855, "step": 262}
{"time": 1767332328.6618986, "phase": "train", "update": 263, "total_env_steps": 841600, "episode_reward": 0.1651231348514557, "value_loss": 0.03685603439807892, "policy_loss": -0.001084816691814794, "dist_entropy": 0.9751820921897888, "actor_grad_norm": 0.08471429347991943, "critic_grad_norm": 0.18595729768276215, "ratio": 0.9997860789299011, "entropy": 0.9751820921897888, "incre_win_rate": 0.36363636363636365, "step": 263}
{"time": 1767332332.6724596, "phase": "train", "update": 264, "total_env_steps": 844800, "episode_reward": 0.1526329666376114, "value_loss": 0.03848871290683746, "policy_loss": -0.0013305229641392912, "dist_entropy": 0.9783376455307007, "actor_grad_norm": 0.11758571118116379, "critic_grad_norm": 0.15499545633792877, "ratio": 0.9995380640029907, "entropy": 0.9783376455307007, "incre_win_rate": 0.29411764705882354, "step": 264}
{"time": 1767332336.6475096, "phase": "train", "update": 265, "total_env_steps": 848000, "episode_reward": 0.15117602050304413, "value_loss": 0.029023627191781996, "policy_loss": -0.0009756103903798774, "dist_entropy": 0.9977101922035218, "actor_grad_norm": 0.09401997178792953, "critic_grad_norm": 0.08048322796821594, "ratio": 0.9999266862869263, "entropy": 0.9977101922035218, "incre_win_rate": 0.16129032258064516, "step": 265}
{"time": 1767332340.670551, "phase": "train", "update": 266, "total_env_steps": 851200, "episode_reward": 0.15430878102779388, "value_loss": 0.03942699357867241, "policy_loss": -0.0010620139166825026, "dist_entropy": 0.9901762962341308, "actor_grad_norm": 0.09937755763530731, "critic_grad_norm": 0.09056185930967331, "ratio": 0.9998220801353455, "entropy": 0.9901762962341308, "incre_win_rate": 0.16666666666666666, "step": 266}
{"time": 1767332344.7093875, "phase": "train", "update": 267, "total_env_steps": 854400, "episode_reward": 0.16775456070899963, "value_loss": 0.03162814937531948, "policy_loss": -0.0013441472702538705, "dist_entropy": 0.9811436653137207, "actor_grad_norm": 0.12545831501483917, "critic_grad_norm": 0.14302387833595276, "ratio": 0.999940037727356, "entropy": 0.9811436653137207, "incre_win_rate": 0.3055555555555556, "step": 267}
{"time": 1767332348.9353487, "phase": "train", "update": 268, "total_env_steps": 857600, "episode_reward": 0.15677152574062347, "value_loss": 0.03267273940145969, "policy_loss": -0.000907526588794294, "dist_entropy": 0.9913598775863648, "actor_grad_norm": 0.07135837525129318, "critic_grad_norm": 0.21790695190429688, "ratio": 0.9996137619018555, "entropy": 0.9913598775863648, "incre_win_rate": 0.28125, "step": 268}
{"time": 1767332353.0050259, "phase": "train", "update": 269, "total_env_steps": 860800, "episode_reward": 0.1467580646276474, "value_loss": 0.03193395361304283, "policy_loss": -0.0013243505592818393, "dist_entropy": 1.0069640159606934, "actor_grad_norm": 0.0801040455698967, "critic_grad_norm": 0.20685486495494843, "ratio": 0.9998356103897095, "entropy": 1.0069640159606934, "incre_win_rate": 0.13513513513513514, "step": 269}
{"time": 1767332357.0649552, "phase": "train", "update": 270, "total_env_steps": 864000, "episode_reward": 0.15969577431678772, "value_loss": 0.035178471356630325, "policy_loss": -0.0019822727583004964, "dist_entropy": 1.0275357007980346, "actor_grad_norm": 0.14000049233436584, "critic_grad_norm": 0.0945185199379921, "ratio": 1.000006079673767, "entropy": 1.0275357007980346, "incre_win_rate": 0.29411764705882354, "step": 270}
{"time": 1767332361.111265, "phase": "train", "update": 271, "total_env_steps": 867200, "episode_reward": 0.1514357477426529, "value_loss": 0.03544849082827568, "policy_loss": -0.0014547098477443398, "dist_entropy": 1.0348954677581788, "actor_grad_norm": 0.10400869697332382, "critic_grad_norm": 0.07942170649766922, "ratio": 0.9999001622200012, "entropy": 1.0348954677581788, "incre_win_rate": 0.20588235294117646, "step": 271}
{"time": 1767332365.1846285, "phase": "train", "update": 272, "total_env_steps": 870400, "episode_reward": 0.15658165514469147, "value_loss": 0.04099138751626015, "policy_loss": -0.001542847644386569, "dist_entropy": 1.0571927070617675, "actor_grad_norm": 0.08303678035736084, "critic_grad_norm": 0.07676903158426285, "ratio": 1.0000042915344238, "entropy": 1.0571927070617675, "incre_win_rate": 0.18421052631578946, "step": 272}
{"time": 1767332369.2177808, "phase": "train", "update": 273, "total_env_steps": 873600, "episode_reward": 0.14068087935447693, "value_loss": 0.03719828426837921, "policy_loss": -0.0011849500991047534, "dist_entropy": 1.0600829362869262, "actor_grad_norm": 0.11208903789520264, "critic_grad_norm": 0.179349884390831, "ratio": 1.0001955032348633, "entropy": 1.0600829362869262, "incre_win_rate": 0.16666666666666666, "step": 273}
{"time": 1767332373.240887, "phase": "train", "update": 274, "total_env_steps": 876800, "episode_reward": 0.16101770102977753, "value_loss": 0.0330106757581234, "policy_loss": -0.001459492504967841, "dist_entropy": 1.0335654973983766, "actor_grad_norm": 0.1138191744685173, "critic_grad_norm": 0.13675984740257263, "ratio": 0.9996057748794556, "entropy": 1.0335654973983766, "incre_win_rate": 0.29411764705882354, "step": 274}
{"time": 1767332377.238042, "phase": "train", "update": 275, "total_env_steps": 880000, "episode_reward": 0.14121688902378082, "value_loss": 0.04492531269788742, "policy_loss": -0.0017464189235113282, "dist_entropy": 1.032274031639099, "actor_grad_norm": 0.12142869085073471, "critic_grad_norm": 0.17111104726791382, "ratio": 1.0004304647445679, "entropy": 1.032274031639099, "incre_win_rate": 0.18181818181818182, "step": 275}
{"time": 1767332381.2683434, "phase": "train", "update": 276, "total_env_steps": 883200, "episode_reward": 0.16636796295642853, "value_loss": 0.03228765465319157, "policy_loss": -0.001122391682218904, "dist_entropy": 1.0308954477310182, "actor_grad_norm": 0.10530328005552292, "critic_grad_norm": 0.18530350923538208, "ratio": 0.9998238682746887, "entropy": 1.0308954477310182, "incre_win_rate": 0.29411764705882354, "step": 276}
{"time": 1767332394.9269094, "phase": "eval", "update": 276, "total_env_steps": 883200, "eval_win_rate": 0.5, "eval_episode_reward": 16.44236341059603, "step": 276}
{"time": 1767332398.956358, "phase": "train", "update": 277, "total_env_steps": 886400, "episode_reward": 0.15768314898014069, "value_loss": 0.04076952412724495, "policy_loss": -0.001241103322329451, "dist_entropy": 1.026831817626953, "actor_grad_norm": 0.10209038108587265, "critic_grad_norm": 0.15493521094322205, "ratio": 0.9997934699058533, "entropy": 1.026831817626953, "incre_win_rate": 0.2857142857142857, "step": 277}
{"time": 1767332403.0223377, "phase": "train", "update": 278, "total_env_steps": 889600, "episode_reward": 0.16444279253482819, "value_loss": 0.028964576497673988, "policy_loss": -0.0012591941721304067, "dist_entropy": 1.037937331199646, "actor_grad_norm": 0.14809933304786682, "critic_grad_norm": 0.10528475046157837, "ratio": 0.9999599456787109, "entropy": 1.037937331199646, "incre_win_rate": 0.29411764705882354, "step": 278}
{"time": 1767332407.0539913, "phase": "train", "update": 279, "total_env_steps": 892800, "episode_reward": 0.15435482561588287, "value_loss": 0.04488309994339943, "policy_loss": -0.0013638611612734053, "dist_entropy": 1.0672915935516358, "actor_grad_norm": 0.1798824816942215, "critic_grad_norm": 0.17256192862987518, "ratio": 0.9992334246635437, "entropy": 1.0672915935516358, "incre_win_rate": 0.24242424242424243, "step": 279}
{"time": 1767332411.0810833, "phase": "train", "update": 280, "total_env_steps": 896000, "episode_reward": 0.14540614187717438, "value_loss": 0.028121375665068626, "policy_loss": -0.0014220135517724942, "dist_entropy": 1.0433598518371583, "actor_grad_norm": 0.12947607040405273, "critic_grad_norm": 0.18692593276500702, "ratio": 1.0001200437545776, "entropy": 1.0433598518371583, "incre_win_rate": 0.14705882352941177, "step": 280}
{"time": 1767332415.082753, "phase": "train", "update": 281, "total_env_steps": 899200, "episode_reward": 0.16437086462974548, "value_loss": 0.03139204420149326, "policy_loss": -0.0017058524320302305, "dist_entropy": 1.058589792251587, "actor_grad_norm": 0.12394990772008896, "critic_grad_norm": 0.1465427428483963, "ratio": 1.000444769859314, "entropy": 1.058589792251587, "incre_win_rate": 0.2727272727272727, "step": 281}
{"time": 1767332419.121178, "phase": "train", "update": 282, "total_env_steps": 902400, "episode_reward": 0.15580402314662933, "value_loss": 0.029281819984316827, "policy_loss": -0.0017546915865475298, "dist_entropy": 1.028682541847229, "actor_grad_norm": 0.08334224671125412, "critic_grad_norm": 0.09316372871398926, "ratio": 1.0000463724136353, "entropy": 1.028682541847229, "incre_win_rate": 0.21212121212121213, "step": 282}
{"time": 1767332423.1337368, "phase": "train", "update": 283, "total_env_steps": 905600, "episode_reward": 0.15832212567329407, "value_loss": 0.02800293192267418, "policy_loss": -0.0015457721831939608, "dist_entropy": 1.0252332925796508, "actor_grad_norm": 0.11849095672369003, "critic_grad_norm": 0.07591318339109421, "ratio": 1.0003244876861572, "entropy": 1.0252332925796508, "incre_win_rate": 0.2571428571428571, "step": 283}
{"time": 1767332427.0921028, "phase": "train", "update": 284, "total_env_steps": 908800, "episode_reward": 0.14666597545146942, "value_loss": 0.02522875964641571, "policy_loss": -0.001321403622861972, "dist_entropy": 1.0208081007003784, "actor_grad_norm": 0.11963687092065811, "critic_grad_norm": 0.06356202811002731, "ratio": 0.9997998476028442, "entropy": 1.0208081007003784, "incre_win_rate": 0.20689655172413793, "step": 284}
{"time": 1767332431.1089606, "phase": "train", "update": 285, "total_env_steps": 912000, "episode_reward": 0.16146211326122284, "value_loss": 0.04370965361595154, "policy_loss": -0.0010640593561461742, "dist_entropy": 1.0037369132041931, "actor_grad_norm": 0.09655517339706421, "critic_grad_norm": 0.0699029266834259, "ratio": 1.0000324249267578, "entropy": 1.0037369132041931, "incre_win_rate": 0.34285714285714286, "step": 285}
{"time": 1767332435.155996, "phase": "train", "update": 286, "total_env_steps": 915200, "episode_reward": 0.1617787778377533, "value_loss": 0.026288560405373574, "policy_loss": -0.0016820431528273617, "dist_entropy": 1.021076774597168, "actor_grad_norm": 0.12660375237464905, "critic_grad_norm": 0.09030552953481674, "ratio": 1.000087022781372, "entropy": 1.021076774597168, "incre_win_rate": 0.29411764705882354, "step": 286}
{"time": 1767332439.1703823, "phase": "train", "update": 287, "total_env_steps": 918400, "episode_reward": 0.1639709323644638, "value_loss": 0.04620729014277458, "policy_loss": -0.0014539858216778613, "dist_entropy": 0.9930354356765747, "actor_grad_norm": 0.1273711770772934, "critic_grad_norm": 0.20684342086315155, "ratio": 0.9997345209121704, "entropy": 0.9930354356765747, "incre_win_rate": 0.3142857142857143, "step": 287}
{"time": 1767332443.1669562, "phase": "train", "update": 288, "total_env_steps": 921600, "episode_reward": 0.1617637574672699, "value_loss": 0.03483200892806053, "policy_loss": -0.0014599194315778163, "dist_entropy": 0.9839118123054504, "actor_grad_norm": 0.12429304420948029, "critic_grad_norm": 0.16708266735076904, "ratio": 0.9996506571769714, "entropy": 0.9839118123054504, "incre_win_rate": 0.375, "step": 288}
{"time": 1767332447.1935625, "phase": "train", "update": 289, "total_env_steps": 924800, "episode_reward": 0.17545995116233826, "value_loss": 0.028035755828022958, "policy_loss": -0.0013898594323393354, "dist_entropy": 0.9873081088066101, "actor_grad_norm": 0.1298944056034088, "critic_grad_norm": 0.15063612163066864, "ratio": 1.000109076499939, "entropy": 0.9873081088066101, "incre_win_rate": 0.42857142857142855, "step": 289}
{"time": 1767332451.2253218, "phase": "train", "update": 290, "total_env_steps": 928000, "episode_reward": 0.1749187856912613, "value_loss": 0.03561170622706413, "policy_loss": -0.0011716656522872348, "dist_entropy": 0.9887117505073547, "actor_grad_norm": 0.12045114487409592, "critic_grad_norm": 0.09996809810400009, "ratio": 0.9997145533561707, "entropy": 0.9887117505073547, "incre_win_rate": 0.4864864864864865, "step": 290}
{"time": 1767332455.26912, "phase": "train", "update": 291, "total_env_steps": 931200, "episode_reward": 0.1650160402059555, "value_loss": 0.0320028331130743, "policy_loss": -0.0013936400125128755, "dist_entropy": 1.0073375225067138, "actor_grad_norm": 0.14443568885326385, "critic_grad_norm": 0.05727599188685417, "ratio": 1.0000666379928589, "entropy": 1.0073375225067138, "incre_win_rate": 0.3939393939393939, "step": 291}
{"time": 1767332459.3277016, "phase": "train", "update": 292, "total_env_steps": 934400, "episode_reward": 0.17252379655838013, "value_loss": 0.03512319549918175, "policy_loss": -0.0010707043244970293, "dist_entropy": 0.9957521677017211, "actor_grad_norm": 0.09506825357675552, "critic_grad_norm": 0.07060029357671738, "ratio": 0.9998989105224609, "entropy": 0.9957521677017211, "incre_win_rate": 0.4, "step": 292}
{"time": 1767332463.4051135, "phase": "train", "update": 293, "total_env_steps": 937600, "episode_reward": 0.17869256436824799, "value_loss": 0.035112330317497255, "policy_loss": -0.0012496283680256016, "dist_entropy": 1.0316753387451172, "actor_grad_norm": 0.08692222088575363, "critic_grad_norm": 0.09570569545030594, "ratio": 0.9999570846557617, "entropy": 1.0316753387451172, "incre_win_rate": 0.4117647058823529, "step": 293}
{"time": 1767332467.4899805, "phase": "train", "update": 294, "total_env_steps": 940800, "episode_reward": 0.16678549349308014, "value_loss": 0.031208973750472067, "policy_loss": -0.001295385360570478, "dist_entropy": 1.0154996871948243, "actor_grad_norm": 0.13032975792884827, "critic_grad_norm": 0.07110592722892761, "ratio": 0.9999532103538513, "entropy": 1.0154996871948243, "incre_win_rate": 0.2777777777777778, "step": 294}
{"time": 1767332471.5414546, "phase": "train", "update": 295, "total_env_steps": 944000, "episode_reward": 0.17733599245548248, "value_loss": 0.03296758085489273, "policy_loss": -0.0011698668055256435, "dist_entropy": 1.0177348136901856, "actor_grad_norm": 0.09954753518104553, "critic_grad_norm": 0.08211512863636017, "ratio": 1.0003057718276978, "entropy": 1.0177348136901856, "incre_win_rate": 0.4117647058823529, "step": 295}
{"time": 1767332475.5627506, "phase": "train", "update": 296, "total_env_steps": 947200, "episode_reward": 0.17655888199806213, "value_loss": 0.029500066116452218, "policy_loss": -0.0015551609010104883, "dist_entropy": 1.0255014657974244, "actor_grad_norm": 0.10780950635671616, "critic_grad_norm": 0.07790311425924301, "ratio": 0.99984210729599, "entropy": 1.0255014657974244, "incre_win_rate": 0.47058823529411764, "step": 296}
{"time": 1767332479.6338532, "phase": "train", "update": 297, "total_env_steps": 950400, "episode_reward": 0.164229616522789, "value_loss": 0.030957676470279694, "policy_loss": -0.001375859485301234, "dist_entropy": 1.0148595094680786, "actor_grad_norm": 0.16972115635871887, "critic_grad_norm": 0.18966688215732574, "ratio": 1.000091791152954, "entropy": 1.0148595094680786, "incre_win_rate": 0.29411764705882354, "step": 297}
{"time": 1767332483.6888137, "phase": "train", "update": 298, "total_env_steps": 953600, "episode_reward": 0.16097009181976318, "value_loss": 0.03120087683200836, "policy_loss": -0.0012600255597874366, "dist_entropy": 0.9996734738349915, "actor_grad_norm": 0.10212656110525131, "critic_grad_norm": 0.2035142034292221, "ratio": 1.00008225440979, "entropy": 0.9996734738349915, "incre_win_rate": 0.3548387096774194, "step": 298}
{"time": 1767332487.7293327, "phase": "train", "update": 299, "total_env_steps": 956800, "episode_reward": 0.16648024320602417, "value_loss": 0.037222645431756976, "policy_loss": -0.001292706547675948, "dist_entropy": 0.9986278891563416, "actor_grad_norm": 0.0996445044875145, "critic_grad_norm": 0.15080490708351135, "ratio": 1.0003126859664917, "entropy": 0.9986278891563416, "incre_win_rate": 0.3611111111111111, "step": 299}
{"time": 1767332491.7833126, "phase": "train", "update": 300, "total_env_steps": 960000, "episode_reward": 0.16751344501972198, "value_loss": 0.03707292675971985, "policy_loss": -0.001582845692255397, "dist_entropy": 0.9783033490180969, "actor_grad_norm": 0.08922693878412247, "critic_grad_norm": 0.13707773387432098, "ratio": 1.0001052618026733, "entropy": 0.9783033490180969, "incre_win_rate": 0.35294117647058826, "step": 300}
{"time": 1767332495.872506, "phase": "train", "update": 301, "total_env_steps": 963200, "episode_reward": 0.16498397290706635, "value_loss": 0.039152519404888154, "policy_loss": -0.0010758097331331484, "dist_entropy": 0.980350661277771, "actor_grad_norm": 0.11620712280273438, "critic_grad_norm": 0.14128327369689941, "ratio": 0.9997138977050781, "entropy": 0.980350661277771, "incre_win_rate": 0.3142857142857143, "step": 301}
{"time": 1767332510.3358908, "phase": "eval", "update": 301, "total_env_steps": 963200, "eval_win_rate": 0.625, "eval_episode_reward": 17.980391142384107, "step": 301}
{"time": 1767332514.3717155, "phase": "train", "update": 302, "total_env_steps": 966400, "episode_reward": 0.173661008477211, "value_loss": 0.03196479231119156, "policy_loss": -0.0010335456172470003, "dist_entropy": 0.9491368293762207, "actor_grad_norm": 0.12859441339969635, "critic_grad_norm": 0.14594022929668427, "ratio": 1.0002321004867554, "entropy": 0.9491368293762207, "incre_win_rate": 0.4722222222222222, "step": 302}
{"time": 1767332518.3579452, "phase": "train", "update": 303, "total_env_steps": 969600, "episode_reward": 0.15989601612091064, "value_loss": 0.040225739032030104, "policy_loss": -0.0010536813857996209, "dist_entropy": 0.9916765093803406, "actor_grad_norm": 0.0779423639178276, "critic_grad_norm": 0.17582203447818756, "ratio": 0.9999678730964661, "entropy": 0.9916765093803406, "incre_win_rate": 0.3225806451612903, "step": 303}
{"time": 1767332522.5520465, "phase": "train", "update": 304, "total_env_steps": 972800, "episode_reward": 0.17397814989089966, "value_loss": 0.04887866154313088, "policy_loss": -0.0012448251547915845, "dist_entropy": 0.9798190236091614, "actor_grad_norm": 0.10797043889760971, "critic_grad_norm": 0.1224227175116539, "ratio": 0.9998680949211121, "entropy": 0.9798190236091614, "incre_win_rate": 0.5151515151515151, "step": 304}
{"time": 1767332526.887827, "phase": "train", "update": 305, "total_env_steps": 976000, "episode_reward": 0.17674358189105988, "value_loss": 0.042114054411649705, "policy_loss": -0.0014581379004802385, "dist_entropy": 0.9855478882789612, "actor_grad_norm": 0.13881678879261017, "critic_grad_norm": 0.197292298078537, "ratio": 1.0000861883163452, "entropy": 0.9855478882789612, "incre_win_rate": 0.5, "step": 305}
{"time": 1767332531.0102794, "phase": "train", "update": 306, "total_env_steps": 979200, "episode_reward": 0.174428790807724, "value_loss": 0.03913097009062767, "policy_loss": -0.0005709343517125376, "dist_entropy": 0.9878010392189026, "actor_grad_norm": 0.09154900908470154, "critic_grad_norm": 0.15037503838539124, "ratio": 1.000280499458313, "entropy": 0.9878010392189026, "incre_win_rate": 0.45714285714285713, "step": 306}
{"time": 1767332535.0505428, "phase": "train", "update": 307, "total_env_steps": 982400, "episode_reward": 0.18011589348316193, "value_loss": 0.028352859988808633, "policy_loss": -0.0012902614907499554, "dist_entropy": 0.9749825835227967, "actor_grad_norm": 0.10592593997716904, "critic_grad_norm": 0.1773059070110321, "ratio": 0.999810516834259, "entropy": 0.9749825835227967, "incre_win_rate": 0.5151515151515151, "step": 307}
{"time": 1767332539.06947, "phase": "train", "update": 308, "total_env_steps": 985600, "episode_reward": 0.16840749979019165, "value_loss": 0.030429475381970404, "policy_loss": -0.0009910964931247434, "dist_entropy": 0.9788409352302552, "actor_grad_norm": 0.11983153969049454, "critic_grad_norm": 0.16695444285869598, "ratio": 0.9997292757034302, "entropy": 0.9788409352302552, "incre_win_rate": 0.3783783783783784, "step": 308}
{"time": 1767332543.1192813, "phase": "train", "update": 309, "total_env_steps": 988800, "episode_reward": 0.17825278639793396, "value_loss": 0.044486530125141144, "policy_loss": -0.0009957703473515878, "dist_entropy": 0.9976468682289124, "actor_grad_norm": 0.14355239272117615, "critic_grad_norm": 0.19998036324977875, "ratio": 0.9999618530273438, "entropy": 0.9976468682289124, "incre_win_rate": 0.4117647058823529, "step": 309}
{"time": 1767332547.102275, "phase": "train", "update": 310, "total_env_steps": 992000, "episode_reward": 0.17064101994037628, "value_loss": 0.030779510736465454, "policy_loss": -0.0012139448577400459, "dist_entropy": 0.9886047005653381, "actor_grad_norm": 0.11100436747074127, "critic_grad_norm": 0.12414981424808502, "ratio": 1.0001929998397827, "entropy": 0.9886047005653381, "incre_win_rate": 0.42424242424242425, "step": 310}
{"time": 1767332551.1549199, "phase": "train", "update": 311, "total_env_steps": 995200, "episode_reward": 0.1614900529384613, "value_loss": 0.029878533259034157, "policy_loss": -0.0014044471400367798, "dist_entropy": 1.0002586007118226, "actor_grad_norm": 0.1356271356344223, "critic_grad_norm": 0.19270537793636322, "ratio": 0.9996552467346191, "entropy": 1.0002586007118226, "incre_win_rate": 0.2702702702702703, "step": 311}
{"time": 1767332555.2328112, "phase": "train", "update": 312, "total_env_steps": 998400, "episode_reward": 0.1765407770872116, "value_loss": 0.02996191754937172, "policy_loss": -0.001100366767938965, "dist_entropy": 0.9922014832496643, "actor_grad_norm": 0.0906282588839531, "critic_grad_norm": 0.1435580998659134, "ratio": 0.9998038411140442, "entropy": 0.9922014832496643, "incre_win_rate": 0.3888888888888889, "step": 312}
{"time": 1767332559.293204, "phase": "train", "update": 313, "total_env_steps": 1001600, "episode_reward": 0.16986961662769318, "value_loss": 0.0331943042576313, "policy_loss": -0.001087940083284522, "dist_entropy": 1.0086808919906616, "actor_grad_norm": 0.11318373680114746, "critic_grad_norm": 0.11079974472522736, "ratio": 0.9999038577079773, "entropy": 1.0086808919906616, "incre_win_rate": 0.34285714285714286, "step": 313}
{"time": 1767332563.3256438, "phase": "train", "update": 314, "total_env_steps": 1004800, "episode_reward": 0.17099855840206146, "value_loss": 0.03463393971323967, "policy_loss": -0.001386676201187953, "dist_entropy": 0.9708826780319214, "actor_grad_norm": 0.12062473595142365, "critic_grad_norm": 0.14425191283226013, "ratio": 1.0003890991210938, "entropy": 0.9708826780319214, "incre_win_rate": 0.42424242424242425, "step": 314}
{"time": 1767332567.3320503, "phase": "train", "update": 315, "total_env_steps": 1008000, "episode_reward": 0.16894039511680603, "value_loss": 0.0340709924697876, "policy_loss": -0.0015430145853358112, "dist_entropy": 0.99529527425766, "actor_grad_norm": 0.1719530075788498, "critic_grad_norm": 0.14158062636852264, "ratio": 1.0001384019851685, "entropy": 0.99529527425766, "incre_win_rate": 0.3142857142857143, "step": 315}
{"time": 1767332571.373216, "phase": "train", "update": 316, "total_env_steps": 1011200, "episode_reward": 0.16626553237438202, "value_loss": 0.033591876924037936, "policy_loss": -0.0014343471393736707, "dist_entropy": 0.9861364245414734, "actor_grad_norm": 0.11710201948881149, "critic_grad_norm": 0.17174087464809418, "ratio": 0.9998440742492676, "entropy": 0.9861364245414734, "incre_win_rate": 0.2702702702702703, "step": 316}
{"time": 1767332575.4398382, "phase": "train", "update": 317, "total_env_steps": 1014400, "episode_reward": 0.193115696310997, "value_loss": 0.024455302953720094, "policy_loss": -0.0008872715293591682, "dist_entropy": 0.981595802307129, "actor_grad_norm": 0.13729186356067657, "critic_grad_norm": 0.14037537574768066, "ratio": 1.000179409980774, "entropy": 0.981595802307129, "incre_win_rate": 0.4857142857142857, "step": 317}
{"time": 1767332579.4864933, "phase": "train", "update": 318, "total_env_steps": 1017600, "episode_reward": 0.17556239664554596, "value_loss": 0.03652390614151955, "policy_loss": -0.0012838960951519595, "dist_entropy": 0.9719332218170166, "actor_grad_norm": 0.10997610539197922, "critic_grad_norm": 0.12580473721027374, "ratio": 0.9998305439949036, "entropy": 0.9719332218170166, "incre_win_rate": 0.42857142857142855, "step": 318}
{"time": 1767332583.5752535, "phase": "train", "update": 319, "total_env_steps": 1020800, "episode_reward": 0.17750725150108337, "value_loss": 0.03323374316096306, "policy_loss": -0.0011354702486192636, "dist_entropy": 1.010408139228821, "actor_grad_norm": 0.09125848859548569, "critic_grad_norm": 0.08796992152929306, "ratio": 0.99993497133255, "entropy": 1.010408139228821, "incre_win_rate": 0.3611111111111111, "step": 319}
{"time": 1767332587.6639507, "phase": "train", "update": 320, "total_env_steps": 1024000, "episode_reward": 0.16471801698207855, "value_loss": 0.022122789174318314, "policy_loss": -0.0011152977127704133, "dist_entropy": 0.9801303267478942, "actor_grad_norm": 0.08112307637929916, "critic_grad_norm": 0.08879902213811874, "ratio": 0.9995574951171875, "entropy": 0.9801303267478942, "incre_win_rate": 0.34285714285714286, "step": 320}
{"time": 1767332591.6773224, "phase": "train", "update": 321, "total_env_steps": 1027200, "episode_reward": 0.17208091914653778, "value_loss": 0.031328405067324636, "policy_loss": -0.001183948492574416, "dist_entropy": 0.9869687557220459, "actor_grad_norm": 0.10605918616056442, "critic_grad_norm": 0.08749031275510788, "ratio": 0.9998002052307129, "entropy": 0.9869687557220459, "incre_win_rate": 0.3939393939393939, "step": 321}
{"time": 1767332595.7006931, "phase": "train", "update": 322, "total_env_steps": 1030400, "episode_reward": 0.17035700380802155, "value_loss": 0.02519863247871399, "policy_loss": -0.0012959561812909471, "dist_entropy": 0.9792383670806885, "actor_grad_norm": 0.14721880853176117, "critic_grad_norm": 0.09097009152173996, "ratio": 1.0001518726348877, "entropy": 0.9792383670806885, "incre_win_rate": 0.34285714285714286, "step": 322}
{"time": 1767332599.7572951, "phase": "train", "update": 323, "total_env_steps": 1033600, "episode_reward": 0.16892850399017334, "value_loss": 0.0295195247977972, "policy_loss": -0.001268389904332734, "dist_entropy": 0.9642643332481384, "actor_grad_norm": 0.0866803452372551, "critic_grad_norm": 0.06759898364543915, "ratio": 0.9997443556785583, "entropy": 0.9642643332481384, "incre_win_rate": 0.32432432432432434, "step": 323}
{"time": 1767332603.9544284, "phase": "train", "update": 324, "total_env_steps": 1036800, "episode_reward": 0.18385866284370422, "value_loss": 0.026184607297182083, "policy_loss": -0.0012609810930086951, "dist_entropy": 0.9863879203796386, "actor_grad_norm": 0.12415819615125656, "critic_grad_norm": 0.1463867574930191, "ratio": 0.9998933672904968, "entropy": 0.9863879203796386, "incre_win_rate": 0.38235294117647056, "step": 324}
{"time": 1767332608.0239449, "phase": "train", "update": 325, "total_env_steps": 1040000, "episode_reward": 0.1822899430990219, "value_loss": 0.02480728253722191, "policy_loss": -0.0011612468430765687, "dist_entropy": 0.9578307390213012, "actor_grad_norm": 0.10065684467554092, "critic_grad_norm": 0.11592111736536026, "ratio": 1.0001589059829712, "entropy": 0.9578307390213012, "incre_win_rate": 0.4722222222222222, "step": 325}
{"time": 1767332612.0702047, "phase": "train", "update": 326, "total_env_steps": 1043200, "episode_reward": 0.16505743563175201, "value_loss": 0.03016309216618538, "policy_loss": -0.0008322979769943117, "dist_entropy": 0.976282000541687, "actor_grad_norm": 0.1625199168920517, "critic_grad_norm": 0.25652623176574707, "ratio": 1.0000371932983398, "entropy": 0.976282000541687, "incre_win_rate": 0.3548387096774194, "step": 326}
{"time": 1767332624.9652493, "phase": "eval", "update": 326, "total_env_steps": 1043200, "eval_win_rate": 0.625, "eval_episode_reward": 17.966732201986755, "step": 326}
{"time": 1767332649.7854838, "phase": "train", "update": 327, "total_env_steps": 1046400, "episode_reward": 0.168212428689003, "value_loss": 0.07876304388046265, "policy_loss": -0.0009921090191724602, "dist_entropy": 0.9629295349121094, "actor_grad_norm": 0.1141727939248085, "critic_grad_norm": 0.40678080916404724, "ratio": 0.9994140863418579, "entropy": 0.9629295349121094, "incre_win_rate": 0.38235294117647056, "step": 327}
{"time": 1767332654.9870174, "phase": "train", "update": 328, "total_env_steps": 1049600, "episode_reward": 0.1717756688594818, "value_loss": 0.027849895507097246, "policy_loss": -0.0014673587488104544, "dist_entropy": 1.011681890487671, "actor_grad_norm": 0.11453618854284286, "critic_grad_norm": 0.2346811294555664, "ratio": 1.0005244016647339, "entropy": 1.011681890487671, "incre_win_rate": 0.2857142857142857, "step": 328}
{"time": 1767332659.7580113, "phase": "train", "update": 329, "total_env_steps": 1052800, "episode_reward": 0.17122672498226166, "value_loss": 0.029267734661698342, "policy_loss": -0.0012716952141062165, "dist_entropy": 0.9969121217727661, "actor_grad_norm": 0.12528680264949799, "critic_grad_norm": 0.14501158893108368, "ratio": 1.000286340713501, "entropy": 0.9969121217727661, "incre_win_rate": 0.40625, "step": 329}
{"time": 1767332664.4637046, "phase": "train", "update": 330, "total_env_steps": 1056000, "episode_reward": 0.1862608790397644, "value_loss": 0.03326914310455322, "policy_loss": -0.0011433167327266403, "dist_entropy": 1.0073882579803466, "actor_grad_norm": 0.11835245043039322, "critic_grad_norm": 0.20363859832286835, "ratio": 0.9998694658279419, "entropy": 1.0073882579803466, "incre_win_rate": 0.5588235294117647, "step": 330}
{"time": 1767332669.2634258, "phase": "train", "update": 331, "total_env_steps": 1059200, "episode_reward": 0.16801533102989197, "value_loss": 0.03826195299625397, "policy_loss": -0.001047981192724734, "dist_entropy": 0.9951789259910584, "actor_grad_norm": 0.0998256728053093, "critic_grad_norm": 0.15902599692344666, "ratio": 0.9999008178710938, "entropy": 0.9951789259910584, "incre_win_rate": 0.40540540540540543, "step": 331}
{"time": 1767332674.2396903, "phase": "train", "update": 332, "total_env_steps": 1062400, "episode_reward": 0.1788938343524933, "value_loss": 0.04097492545843125, "policy_loss": -0.0011357964551969245, "dist_entropy": 1.0027642488479613, "actor_grad_norm": 0.1216961145401001, "critic_grad_norm": 0.12848953902721405, "ratio": 0.9997963905334473, "entropy": 1.0027642488479613, "incre_win_rate": 0.5, "step": 332}
{"time": 1767332679.049075, "phase": "train", "update": 333, "total_env_steps": 1065600, "episode_reward": 0.18417581915855408, "value_loss": 0.04091294854879379, "policy_loss": -0.001535755546811579, "dist_entropy": 1.017065739631653, "actor_grad_norm": 0.1390065997838974, "critic_grad_norm": 0.16852693259716034, "ratio": 0.9996764063835144, "entropy": 1.017065739631653, "incre_win_rate": 0.5588235294117647, "step": 333}
{"time": 1767332683.7468688, "phase": "train", "update": 334, "total_env_steps": 1068800, "episode_reward": 0.1739719808101654, "value_loss": 0.04249038323760033, "policy_loss": -0.0013268059424959232, "dist_entropy": 0.986576771736145, "actor_grad_norm": 0.15397417545318604, "critic_grad_norm": 0.21371924877166748, "ratio": 1.000017762184143, "entropy": 0.986576771736145, "incre_win_rate": 0.5428571428571428, "step": 334}
{"time": 1767332688.5752156, "phase": "train", "update": 335, "total_env_steps": 1072000, "episode_reward": 0.18207162618637085, "value_loss": 0.030739599838852882, "policy_loss": -0.0013422598011928245, "dist_entropy": 0.9905722260475158, "actor_grad_norm": 0.07451504468917847, "critic_grad_norm": 0.14394135773181915, "ratio": 1.0000377893447876, "entropy": 0.9905722260475158, "incre_win_rate": 0.45454545454545453, "step": 335}
{"time": 1767332693.467329, "phase": "train", "update": 336, "total_env_steps": 1075200, "episode_reward": 0.16387778520584106, "value_loss": 0.03538676798343658, "policy_loss": -0.001273415601796657, "dist_entropy": 0.9815766453742981, "actor_grad_norm": 0.08229205757379532, "critic_grad_norm": 0.18867911398410797, "ratio": 0.9997872710227966, "entropy": 0.9815766453742981, "incre_win_rate": 0.21621621621621623, "step": 336}
{"time": 1767332698.1738207, "phase": "train", "update": 337, "total_env_steps": 1078400, "episode_reward": 0.16470767557621002, "value_loss": 0.0346549890935421, "policy_loss": -0.0014022587092114235, "dist_entropy": 0.9763930678367615, "actor_grad_norm": 0.12180524319410324, "critic_grad_norm": 0.15141385793685913, "ratio": 1.0000152587890625, "entropy": 0.9763930678367615, "incre_win_rate": 0.4166666666666667, "step": 337}
{"time": 1767332702.7571995, "phase": "train", "update": 338, "total_env_steps": 1081600, "episode_reward": 0.16799874603748322, "value_loss": 0.03435377851128578, "policy_loss": -0.0013471801311474962, "dist_entropy": 0.9870316743850708, "actor_grad_norm": 0.08012241125106812, "critic_grad_norm": 0.10744886845350266, "ratio": 0.9996474385261536, "entropy": 0.9870316743850708, "incre_win_rate": 0.35294117647058826, "step": 338}
{"time": 1767332707.474454, "phase": "train", "update": 339, "total_env_steps": 1084800, "episode_reward": 0.16086868941783905, "value_loss": 0.030860471725463866, "policy_loss": -0.0014980756417884323, "dist_entropy": 0.990002453327179, "actor_grad_norm": 0.15687239170074463, "critic_grad_norm": 0.131571963429451, "ratio": 1.0003174543380737, "entropy": 0.990002453327179, "incre_win_rate": 0.2857142857142857, "step": 339}
{"time": 1767332712.311047, "phase": "train", "update": 340, "total_env_steps": 1088000, "episode_reward": 0.1764538437128067, "value_loss": 0.029019977524876596, "policy_loss": -0.0013683485774123483, "dist_entropy": 0.9913833618164063, "actor_grad_norm": 0.15755882859230042, "critic_grad_norm": 0.20780961215496063, "ratio": 1.0002144575119019, "entropy": 0.9913833618164063, "incre_win_rate": 0.42857142857142855, "step": 340}
{"time": 1767332717.1208897, "phase": "train", "update": 341, "total_env_steps": 1091200, "episode_reward": 0.17130380868911743, "value_loss": 0.03356795012950897, "policy_loss": -0.001323001210120367, "dist_entropy": 0.9873498916625977, "actor_grad_norm": 0.1127576008439064, "critic_grad_norm": 0.14241348206996918, "ratio": 0.9998031854629517, "entropy": 0.9873498916625977, "incre_win_rate": 0.36363636363636365, "step": 341}
{"time": 1767332721.446002, "phase": "train", "update": 342, "total_env_steps": 1094400, "episode_reward": 0.1752116084098816, "value_loss": 0.030828974768519403, "policy_loss": -0.001328489165514668, "dist_entropy": 0.9774918913841247, "actor_grad_norm": 0.11835262924432755, "critic_grad_norm": 0.0837225392460823, "ratio": 0.9998155832290649, "entropy": 0.9774918913841247, "incre_win_rate": 0.4594594594594595, "step": 342}
{"time": 1767332725.7830136, "phase": "train", "update": 343, "total_env_steps": 1097600, "episode_reward": 0.17185430228710175, "value_loss": 0.02730262614786625, "policy_loss": -0.0008907147655563108, "dist_entropy": 0.9796607017517089, "actor_grad_norm": 0.26102250814437866, "critic_grad_norm": 0.1325281709432602, "ratio": 1.0003254413604736, "entropy": 0.9796607017517089, "incre_win_rate": 0.3939393939393939, "step": 343}
{"time": 1767332730.1421432, "phase": "train", "update": 344, "total_env_steps": 1100800, "episode_reward": 0.1824079155921936, "value_loss": 0.03322115167975426, "policy_loss": -0.0006633112935437779, "dist_entropy": 0.9766247987747192, "actor_grad_norm": 0.19260144233703613, "critic_grad_norm": 0.09124557673931122, "ratio": 1.0001376867294312, "entropy": 0.9766247987747192, "incre_win_rate": 0.4864864864864865, "step": 344}
{"time": 1767332734.209013, "phase": "train", "update": 345, "total_env_steps": 1104000, "episode_reward": 0.18280266225337982, "value_loss": 0.02927435114979744, "policy_loss": -0.001854560495925739, "dist_entropy": 0.9660347104072571, "actor_grad_norm": 0.12817451357841492, "critic_grad_norm": 0.07626676559448242, "ratio": 1.0001815557479858, "entropy": 0.9660347104072571, "incre_win_rate": 0.5294117647058824, "step": 345}
{"time": 1767332738.2704368, "phase": "train", "update": 346, "total_env_steps": 1107200, "episode_reward": 0.1778337061405182, "value_loss": 0.03202374167740345, "policy_loss": -0.0013669104037404623, "dist_entropy": 0.9924228072166443, "actor_grad_norm": 0.10415007919073105, "critic_grad_norm": 0.11134541034698486, "ratio": 1.0001766681671143, "entropy": 0.9924228072166443, "incre_win_rate": 0.38235294117647056, "step": 346}
{"time": 1767332742.290008, "phase": "train", "update": 347, "total_env_steps": 1110400, "episode_reward": 0.18033114075660706, "value_loss": 0.024722245708107948, "policy_loss": -0.0013610790099278347, "dist_entropy": 0.9682785034179687, "actor_grad_norm": 0.13272647559642792, "critic_grad_norm": 0.10493075102567673, "ratio": 0.9997333884239197, "entropy": 0.9682785034179687, "incre_win_rate": 0.5294117647058824, "step": 347}
{"time": 1767332746.2892394, "phase": "train", "update": 348, "total_env_steps": 1113600, "episode_reward": 0.1747480183839798, "value_loss": 0.0315177071839571, "policy_loss": -0.0013572298465550857, "dist_entropy": 0.9626779675483703, "actor_grad_norm": 0.17891938984394073, "critic_grad_norm": 0.14020423591136932, "ratio": 1.0000531673431396, "entropy": 0.9626779675483703, "incre_win_rate": 0.5142857142857142, "step": 348}
{"time": 1767332750.334597, "phase": "train", "update": 349, "total_env_steps": 1116800, "episode_reward": 0.17933620512485504, "value_loss": 0.038393928110599516, "policy_loss": -0.000983277793907078, "dist_entropy": 0.9942814707756042, "actor_grad_norm": 0.12768453359603882, "critic_grad_norm": 0.12858955562114716, "ratio": 0.9997181296348572, "entropy": 0.9942814707756042, "incre_win_rate": 0.47058823529411764, "step": 349}
{"time": 1767332754.3351169, "phase": "train", "update": 350, "total_env_steps": 1120000, "episode_reward": 0.17363876104354858, "value_loss": 0.027074197307229042, "policy_loss": -0.00131511543185745, "dist_entropy": 1.0082323789596557, "actor_grad_norm": 0.1460898369550705, "critic_grad_norm": 0.1326916664838791, "ratio": 1.0001355409622192, "entropy": 1.0082323789596557, "incre_win_rate": 0.5, "step": 350}
{"time": 1767332758.3717613, "phase": "train", "update": 351, "total_env_steps": 1123200, "episode_reward": 0.17085006833076477, "value_loss": 0.030274181813001632, "policy_loss": -0.0015427087717664989, "dist_entropy": 0.9749242424964905, "actor_grad_norm": 0.1609436720609665, "critic_grad_norm": 0.09280436486005783, "ratio": 0.9997486472129822, "entropy": 0.9749242424964905, "incre_win_rate": 0.38235294117647056, "step": 351}
{"time": 1767332773.3708222, "phase": "eval", "update": 351, "total_env_steps": 1123200, "eval_win_rate": 0.6875, "eval_episode_reward": 17.12851821192053, "step": 351}
{"time": 1767332777.4390574, "phase": "train", "update": 352, "total_env_steps": 1126400, "episode_reward": 0.1692342758178711, "value_loss": 0.03240720480680466, "policy_loss": -0.0012247891462884297, "dist_entropy": 0.9761821985244751, "actor_grad_norm": 0.08595257252454758, "critic_grad_norm": 0.06919534504413605, "ratio": 1.0001633167266846, "entropy": 0.9761821985244751, "incre_win_rate": 0.3939393939393939, "step": 352}
{"time": 1767332781.5348854, "phase": "train", "update": 353, "total_env_steps": 1129600, "episode_reward": 0.1834535449743271, "value_loss": 0.02997456192970276, "policy_loss": -0.0010668342851434254, "dist_entropy": 0.9995553374290467, "actor_grad_norm": 0.10832849889993668, "critic_grad_norm": 0.08460884541273117, "ratio": 0.999858558177948, "entropy": 0.9995553374290467, "incre_win_rate": 0.5428571428571428, "step": 353}
{"time": 1767332785.6345508, "phase": "train", "update": 354, "total_env_steps": 1132800, "episode_reward": 0.18546044826507568, "value_loss": 0.025609623268246652, "policy_loss": -0.0008402914187943366, "dist_entropy": 1.0022015810012816, "actor_grad_norm": 0.10050441324710846, "critic_grad_norm": 0.05511908605694771, "ratio": 0.9999932646751404, "entropy": 1.0022015810012816, "incre_win_rate": 0.5277777777777778, "step": 354}
{"time": 1767332789.7200634, "phase": "train", "update": 355, "total_env_steps": 1136000, "episode_reward": 0.1869334578514099, "value_loss": 0.027050064131617545, "policy_loss": -0.0014163346691326239, "dist_entropy": 0.9933119535446167, "actor_grad_norm": 0.18663443624973297, "critic_grad_norm": 0.08642896264791489, "ratio": 1.000450611114502, "entropy": 0.9933119535446167, "incre_win_rate": 0.5277777777777778, "step": 355}
{"time": 1767332793.8515818, "phase": "train", "update": 356, "total_env_steps": 1139200, "episode_reward": 0.1835487335920334, "value_loss": 0.0331511102616787, "policy_loss": -0.0014527371051343608, "dist_entropy": 0.9883568406105041, "actor_grad_norm": 0.1206943541765213, "critic_grad_norm": 0.11721719801425934, "ratio": 0.9999071359634399, "entropy": 0.9883568406105041, "incre_win_rate": 0.42857142857142855, "step": 356}
{"time": 1767332797.992416, "phase": "train", "update": 357, "total_env_steps": 1142400, "episode_reward": 0.19360202550888062, "value_loss": 0.02569063864648342, "policy_loss": -0.001140249816794281, "dist_entropy": 0.9476461768150329, "actor_grad_norm": 0.09915189445018768, "critic_grad_norm": 0.13022266328334808, "ratio": 0.9999690055847168, "entropy": 0.9476461768150329, "incre_win_rate": 0.6666666666666666, "step": 357}
{"time": 1767332802.0172122, "phase": "train", "update": 358, "total_env_steps": 1145600, "episode_reward": 0.17415715754032135, "value_loss": 0.04813191220164299, "policy_loss": -0.0011834128178570325, "dist_entropy": 0.9795553803443908, "actor_grad_norm": 0.17575909197330475, "critic_grad_norm": 0.23685073852539062, "ratio": 0.9996994137763977, "entropy": 0.9795553803443908, "incre_win_rate": 0.6, "step": 358}
{"time": 1767332806.0826037, "phase": "train", "update": 359, "total_env_steps": 1148800, "episode_reward": 0.17818708717823029, "value_loss": 0.024849336966872214, "policy_loss": -0.0011723952944048932, "dist_entropy": 0.9619468212127685, "actor_grad_norm": 0.11455567181110382, "critic_grad_norm": 0.20627887547016144, "ratio": 1.000010371208191, "entropy": 0.9619468212127685, "incre_win_rate": 0.5483870967741935, "step": 359}
{"time": 1767332810.1268318, "phase": "train", "update": 360, "total_env_steps": 1152000, "episode_reward": 0.18797029554843903, "value_loss": 0.025618110969662666, "policy_loss": -0.001186925882575629, "dist_entropy": 0.9556410551071167, "actor_grad_norm": 0.14981205761432648, "critic_grad_norm": 0.12595124542713165, "ratio": 1.0000978708267212, "entropy": 0.9556410551071167, "incre_win_rate": 0.5833333333333334, "step": 360}
{"time": 1767332814.1516905, "phase": "train", "update": 361, "total_env_steps": 1155200, "episode_reward": 0.19097940623760223, "value_loss": 0.029495498910546303, "policy_loss": -0.0009906703055250431, "dist_entropy": 0.9368567585945129, "actor_grad_norm": 0.10466235876083374, "critic_grad_norm": 0.08637363463640213, "ratio": 1.0000877380371094, "entropy": 0.9368567585945129, "incre_win_rate": 0.6666666666666666, "step": 361}
{"time": 1767332818.1807923, "phase": "train", "update": 362, "total_env_steps": 1158400, "episode_reward": 0.1776236593723297, "value_loss": 0.037236275523900984, "policy_loss": -0.0010285132993558932, "dist_entropy": 0.9612868189811706, "actor_grad_norm": 0.10239755362272263, "critic_grad_norm": 0.1343916952610016, "ratio": 1.0000946521759033, "entropy": 0.9612868189811706, "incre_win_rate": 0.4594594594594595, "step": 362}
{"time": 1767332822.1941319, "phase": "train", "update": 363, "total_env_steps": 1161600, "episode_reward": 0.17805515229701996, "value_loss": 0.027510646730661392, "policy_loss": -0.0013882286513918984, "dist_entropy": 0.9855978608131408, "actor_grad_norm": 0.11516956239938736, "critic_grad_norm": 0.12078877538442612, "ratio": 0.9999122023582458, "entropy": 0.9855978608131408, "incre_win_rate": 0.42424242424242425, "step": 363}
{"time": 1767332826.3248732, "phase": "train", "update": 364, "total_env_steps": 1164800, "episode_reward": 0.18169546127319336, "value_loss": 0.029269877448678018, "policy_loss": -0.001296654494647953, "dist_entropy": 0.9966413974761963, "actor_grad_norm": 0.1304120123386383, "critic_grad_norm": 0.11713776737451553, "ratio": 0.999955952167511, "entropy": 0.9966413974761963, "incre_win_rate": 0.4444444444444444, "step": 364}
{"time": 1767332830.453711, "phase": "train", "update": 365, "total_env_steps": 1168000, "episode_reward": 0.1876707226037979, "value_loss": 0.02672303356230259, "policy_loss": -0.0016851215628808092, "dist_entropy": 0.9945096135139465, "actor_grad_norm": 0.1350165754556656, "critic_grad_norm": 0.09781409054994583, "ratio": 0.9998052716255188, "entropy": 0.9945096135139465, "incre_win_rate": 0.5277777777777778, "step": 365}
{"time": 1767332834.470321, "phase": "train", "update": 366, "total_env_steps": 1171200, "episode_reward": 0.17606323957443237, "value_loss": 0.02261875048279762, "policy_loss": -0.001490484920060453, "dist_entropy": 0.9666383028030395, "actor_grad_norm": 0.13181252777576447, "critic_grad_norm": 0.07399032264947891, "ratio": 0.9993662238121033, "entropy": 0.9666383028030395, "incre_win_rate": 0.35294117647058826, "step": 366}
{"time": 1767332838.506999, "phase": "train", "update": 367, "total_env_steps": 1174400, "episode_reward": 0.1788705587387085, "value_loss": 0.025548181682825088, "policy_loss": -0.0010456053704338331, "dist_entropy": 0.9490273833274842, "actor_grad_norm": 0.09764581173658371, "critic_grad_norm": 0.05791635438799858, "ratio": 0.9994571805000305, "entropy": 0.9490273833274842, "incre_win_rate": 0.5142857142857142, "step": 367}
{"time": 1767332842.5437105, "phase": "train", "update": 368, "total_env_steps": 1177600, "episode_reward": 0.18281352519989014, "value_loss": 0.02278251051902771, "policy_loss": -0.00130875976731204, "dist_entropy": 0.9489053726196289, "actor_grad_norm": 0.12427599728107452, "critic_grad_norm": 0.10864203423261642, "ratio": 0.9996883273124695, "entropy": 0.9489053726196289, "incre_win_rate": 0.47058823529411764, "step": 368}
{"time": 1767332846.5731258, "phase": "train", "update": 369, "total_env_steps": 1180800, "episode_reward": 0.17926271259784698, "value_loss": 0.025038519874215126, "policy_loss": -0.0010007821706409458, "dist_entropy": 0.9499146103858948, "actor_grad_norm": 0.08789344877004623, "critic_grad_norm": 0.18262334167957306, "ratio": 1.0000907182693481, "entropy": 0.9499146103858948, "incre_win_rate": 0.4166666666666667, "step": 369}
{"time": 1767332850.578688, "phase": "train", "update": 370, "total_env_steps": 1184000, "episode_reward": 0.17787925899028778, "value_loss": 0.027789244428277016, "policy_loss": -0.0018984211720265876, "dist_entropy": 0.9574295997619628, "actor_grad_norm": 0.08848115056753159, "critic_grad_norm": 0.14165358245372772, "ratio": 1.0002714395523071, "entropy": 0.9574295997619628, "incre_win_rate": 0.45714285714285713, "step": 370}
{"time": 1767332854.6054842, "phase": "train", "update": 371, "total_env_steps": 1187200, "episode_reward": 0.17786993086338043, "value_loss": 0.024214315786957742, "policy_loss": -0.0014137385129224355, "dist_entropy": 0.9362945318222046, "actor_grad_norm": 0.11600615829229355, "critic_grad_norm": 0.1390989124774933, "ratio": 0.9999701380729675, "entropy": 0.9362945318222046, "incre_win_rate": 0.45714285714285713, "step": 371}
{"time": 1767332858.6908126, "phase": "train", "update": 372, "total_env_steps": 1190400, "episode_reward": 0.18762367963790894, "value_loss": 0.02712269052863121, "policy_loss": -0.001264750632249223, "dist_entropy": 0.9373246550559997, "actor_grad_norm": 0.1495514214038849, "critic_grad_norm": 0.08653097599744797, "ratio": 1.0004379749298096, "entropy": 0.9373246550559997, "incre_win_rate": 0.5833333333333334, "step": 372}
{"time": 1767332862.7182863, "phase": "train", "update": 373, "total_env_steps": 1193600, "episode_reward": 0.17798840999603271, "value_loss": 0.02445569112896919, "policy_loss": -0.0015089595787600274, "dist_entropy": 0.9190518617630005, "actor_grad_norm": 0.1655130386352539, "critic_grad_norm": 0.08579492568969727, "ratio": 0.9997596144676208, "entropy": 0.9190518617630005, "incre_win_rate": 0.5454545454545454, "step": 373}
{"time": 1767332866.7474153, "phase": "train", "update": 374, "total_env_steps": 1196800, "episode_reward": 0.19736133515834808, "value_loss": 0.02491772174835205, "policy_loss": -0.0011400046249336881, "dist_entropy": 0.9342714071273803, "actor_grad_norm": 0.09057822078466415, "critic_grad_norm": 0.11676700413227081, "ratio": 0.9999440312385559, "entropy": 0.9342714071273803, "incre_win_rate": 0.78125, "step": 374}
{"time": 1767332870.7760663, "phase": "train", "update": 375, "total_env_steps": 1200000, "episode_reward": 0.18948985636234283, "value_loss": 0.026012330129742623, "policy_loss": -0.001342899519023888, "dist_entropy": 0.9492788910865784, "actor_grad_norm": 0.08051487058401108, "critic_grad_norm": 0.11210811138153076, "ratio": 1.0001108646392822, "entropy": 0.9492788910865784, "incre_win_rate": 0.7058823529411765, "step": 375}
{"time": 1767332874.7923808, "phase": "train", "update": 376, "total_env_steps": 1203200, "episode_reward": 0.19224441051483154, "value_loss": 0.024993466585874556, "policy_loss": -0.0014015499057570934, "dist_entropy": 0.9463566064834594, "actor_grad_norm": 0.11730634421110153, "critic_grad_norm": 0.0812167152762413, "ratio": 1.0000016689300537, "entropy": 0.9463566064834594, "incre_win_rate": 0.6111111111111112, "step": 376}
{"time": 1767332888.2308831, "phase": "eval", "update": 376, "total_env_steps": 1203200, "eval_win_rate": 0.84375, "eval_episode_reward": 19.152059188741717, "step": 376}
{"time": 1767332892.2465043, "phase": "train", "update": 377, "total_env_steps": 1206400, "episode_reward": 0.1788860708475113, "value_loss": 0.022318444028496743, "policy_loss": -0.001425270452430194, "dist_entropy": 0.958864688873291, "actor_grad_norm": 0.14023548364639282, "critic_grad_norm": 0.07430770248174667, "ratio": 1.0000652074813843, "entropy": 0.958864688873291, "incre_win_rate": 0.5161290322580645, "step": 377}
{"time": 1767332896.3186967, "phase": "train", "update": 378, "total_env_steps": 1209600, "episode_reward": 0.19113929569721222, "value_loss": 0.03392289131879807, "policy_loss": -0.001292587111722332, "dist_entropy": 0.9376253366470337, "actor_grad_norm": 0.1018838882446289, "critic_grad_norm": 0.0628461241722107, "ratio": 1.0001978874206543, "entropy": 0.9376253366470337, "incre_win_rate": 0.6216216216216216, "step": 378}
{"time": 1767332900.342223, "phase": "train", "update": 379, "total_env_steps": 1212800, "episode_reward": 0.1869112253189087, "value_loss": 0.02521192952990532, "policy_loss": -0.0015582677375235222, "dist_entropy": 0.9486109137535095, "actor_grad_norm": 0.09844816476106644, "critic_grad_norm": 0.0738389641046524, "ratio": 0.9997043013572693, "entropy": 0.9486109137535095, "incre_win_rate": 0.5454545454545454, "step": 379}
{"time": 1767332904.3061466, "phase": "train", "update": 380, "total_env_steps": 1216000, "episode_reward": 0.1798126995563507, "value_loss": 0.023205403611063956, "policy_loss": -0.0013747179566276913, "dist_entropy": 0.9226411938667297, "actor_grad_norm": 0.08779790252447128, "critic_grad_norm": 0.10936440527439117, "ratio": 0.9998089671134949, "entropy": 0.9226411938667297, "incre_win_rate": 0.5454545454545454, "step": 380}
{"time": 1767332908.3493707, "phase": "train", "update": 381, "total_env_steps": 1219200, "episode_reward": 0.1933247148990631, "value_loss": 0.02327526770532131, "policy_loss": -0.0009465280797911646, "dist_entropy": 0.9206714987754822, "actor_grad_norm": 0.0846342071890831, "critic_grad_norm": 0.1214364543557167, "ratio": 1.0002949237823486, "entropy": 0.9206714987754822, "incre_win_rate": 0.5641025641025641, "step": 381}
{"time": 1767332912.396357, "phase": "train", "update": 382, "total_env_steps": 1222400, "episode_reward": 0.19222372770309448, "value_loss": 0.024638189747929574, "policy_loss": -0.0012412089594171505, "dist_entropy": 0.9066296339035034, "actor_grad_norm": 0.11493387073278427, "critic_grad_norm": 0.14206579327583313, "ratio": 0.9997557997703552, "entropy": 0.9066296339035034, "incre_win_rate": 0.5294117647058824, "step": 382}
{"time": 1767332916.4255426, "phase": "train", "update": 383, "total_env_steps": 1225600, "episode_reward": 0.1911247819662094, "value_loss": 0.024768517911434175, "policy_loss": -0.0011665026485335518, "dist_entropy": 0.9034246683120728, "actor_grad_norm": 0.09862890839576721, "critic_grad_norm": 0.08580300956964493, "ratio": 1.0000206232070923, "entropy": 0.9034246683120728, "incre_win_rate": 0.6666666666666666, "step": 383}
{"time": 1767332920.490097, "phase": "train", "update": 384, "total_env_steps": 1228800, "episode_reward": 0.18162718415260315, "value_loss": 0.03670934811234474, "policy_loss": -0.0008326822380370303, "dist_entropy": 0.9052722811698913, "actor_grad_norm": 0.09289845079183578, "critic_grad_norm": 0.1341378539800644, "ratio": 1.0001429319381714, "entropy": 0.9052722811698913, "incre_win_rate": 0.5135135135135135, "step": 384}
{"time": 1767332924.5107574, "phase": "train", "update": 385, "total_env_steps": 1232000, "episode_reward": 0.19854512810707092, "value_loss": 0.02428526245057583, "policy_loss": -0.0009348721448716902, "dist_entropy": 0.8965453147888184, "actor_grad_norm": 0.11670847237110138, "critic_grad_norm": 0.17572163045406342, "ratio": 1.0000509023666382, "entropy": 0.8965453147888184, "incre_win_rate": 0.6571428571428571, "step": 385}
{"time": 1767332928.5470145, "phase": "train", "update": 386, "total_env_steps": 1235200, "episode_reward": 0.20729771256446838, "value_loss": 0.021303023025393487, "policy_loss": -0.001214316088984546, "dist_entropy": 0.8861937165260315, "actor_grad_norm": 0.097409687936306, "critic_grad_norm": 0.14410434663295746, "ratio": 1.0001046657562256, "entropy": 0.8861937165260315, "incre_win_rate": 0.8285714285714286, "step": 386}
{"time": 1767332932.5660324, "phase": "train", "update": 387, "total_env_steps": 1238400, "episode_reward": 0.18714094161987305, "value_loss": 0.022352495044469834, "policy_loss": -0.0011113137089845183, "dist_entropy": 0.9089402079582214, "actor_grad_norm": 0.12011760473251343, "critic_grad_norm": 0.08860030025243759, "ratio": 0.9999208450317383, "entropy": 0.9089402079582214, "incre_win_rate": 0.5428571428571428, "step": 387}
{"time": 1767332936.597312, "phase": "train", "update": 388, "total_env_steps": 1241600, "episode_reward": 0.18330711126327515, "value_loss": 0.029532423987984658, "policy_loss": -0.0007027949972937319, "dist_entropy": 0.905755615234375, "actor_grad_norm": 0.09924478828907013, "critic_grad_norm": 0.2401978075504303, "ratio": 0.999981701374054, "entropy": 0.905755615234375, "incre_win_rate": 0.5142857142857142, "step": 388}
{"time": 1767332940.5981853, "phase": "train", "update": 389, "total_env_steps": 1244800, "episode_reward": 0.18837696313858032, "value_loss": 0.02319898083806038, "policy_loss": -0.0010888872359814173, "dist_entropy": 0.8942442655563354, "actor_grad_norm": 0.1240200325846672, "critic_grad_norm": 0.1569414585828781, "ratio": 0.9998946189880371, "entropy": 0.8942442655563354, "incre_win_rate": 0.5714285714285714, "step": 389}
{"time": 1767332944.60071, "phase": "train", "update": 390, "total_env_steps": 1248000, "episode_reward": 0.19103944301605225, "value_loss": 0.020193301513791083, "policy_loss": -0.0012303706427232441, "dist_entropy": 0.9011829614639282, "actor_grad_norm": 0.0872054323554039, "critic_grad_norm": 0.12644481658935547, "ratio": 0.9999901056289673, "entropy": 0.9011829614639282, "incre_win_rate": 0.78125, "step": 390}
{"time": 1767332948.666162, "phase": "train", "update": 391, "total_env_steps": 1251200, "episode_reward": 0.19358135759830475, "value_loss": 0.019766011089086533, "policy_loss": -0.0008987839976754231, "dist_entropy": 0.887145745754242, "actor_grad_norm": 0.0898100882768631, "critic_grad_norm": 0.11242230236530304, "ratio": 1.0002635717391968, "entropy": 0.887145745754242, "incre_win_rate": 0.6666666666666666, "step": 391}
{"time": 1767332952.7850442, "phase": "train", "update": 392, "total_env_steps": 1254400, "episode_reward": 0.18295790255069733, "value_loss": 0.0239267211407423, "policy_loss": -0.0011704026218154694, "dist_entropy": 0.9191380143165588, "actor_grad_norm": 0.09416528046131134, "critic_grad_norm": 0.13418856263160706, "ratio": 0.9997393488883972, "entropy": 0.9191380143165588, "incre_win_rate": 0.5, "step": 392}
{"time": 1767332956.837851, "phase": "train", "update": 393, "total_env_steps": 1257600, "episode_reward": 0.18421563506126404, "value_loss": 0.028065222874283792, "policy_loss": -0.0012540320549980777, "dist_entropy": 0.9247338533401489, "actor_grad_norm": 0.08693947643041611, "critic_grad_norm": 0.20162005722522736, "ratio": 0.9997679591178894, "entropy": 0.9247338533401489, "incre_win_rate": 0.47368421052631576, "step": 393}
{"time": 1767332960.8673258, "phase": "train", "update": 394, "total_env_steps": 1260800, "episode_reward": 0.1943051517009735, "value_loss": 0.02163144387304783, "policy_loss": -0.0012387557867121757, "dist_entropy": 0.8992403507232666, "actor_grad_norm": 0.08233322948217392, "critic_grad_norm": 0.14630158245563507, "ratio": 1.0000286102294922, "entropy": 0.8992403507232666, "incre_win_rate": 0.5714285714285714, "step": 394}
{"time": 1767332964.8972673, "phase": "train", "update": 395, "total_env_steps": 1264000, "episode_reward": 0.18644505739212036, "value_loss": 0.025528373196721077, "policy_loss": -0.0009410379146274295, "dist_entropy": 0.8883389592170715, "actor_grad_norm": 0.08635907620191574, "critic_grad_norm": 0.11213113367557526, "ratio": 1.0000056028366089, "entropy": 0.8883389592170715, "incre_win_rate": 0.5142857142857142, "step": 395}
{"time": 1767332968.9362032, "phase": "train", "update": 396, "total_env_steps": 1267200, "episode_reward": 0.1886439472436905, "value_loss": 0.025245721265673638, "policy_loss": -0.0014312516445777134, "dist_entropy": 0.8959652066230774, "actor_grad_norm": 0.11592157930135727, "critic_grad_norm": 0.12593211233615875, "ratio": 0.9999811053276062, "entropy": 0.8959652066230774, "incre_win_rate": 0.5555555555555556, "step": 396}
{"time": 1767332972.9788983, "phase": "train", "update": 397, "total_env_steps": 1270400, "episode_reward": 0.17976407706737518, "value_loss": 0.028598908334970474, "policy_loss": -0.0012871512420552732, "dist_entropy": 0.9039962649345398, "actor_grad_norm": 0.09408576786518097, "critic_grad_norm": 0.08347831666469574, "ratio": 0.9996431469917297, "entropy": 0.9039962649345398, "incre_win_rate": 0.40540540540540543, "step": 397}
{"time": 1767332977.0367854, "phase": "train", "update": 398, "total_env_steps": 1273600, "episode_reward": 0.19750206172466278, "value_loss": 0.021126195788383484, "policy_loss": -0.0015338807424850388, "dist_entropy": 0.9182746291160584, "actor_grad_norm": 0.09628842025995255, "critic_grad_norm": 0.053298499435186386, "ratio": 0.9998739361763, "entropy": 0.9182746291160584, "incre_win_rate": 0.6, "step": 398}
{"time": 1767332981.0931168, "phase": "train", "update": 399, "total_env_steps": 1276800, "episode_reward": 0.1873742640018463, "value_loss": 0.022242166846990586, "policy_loss": -0.0011864887637592857, "dist_entropy": 0.916888439655304, "actor_grad_norm": 0.11955007165670395, "critic_grad_norm": 0.052586015313863754, "ratio": 0.999788761138916, "entropy": 0.916888439655304, "incre_win_rate": 0.6, "step": 399}
{"time": 1767332985.1011088, "phase": "train", "update": 400, "total_env_steps": 1280000, "episode_reward": 0.18615169823169708, "value_loss": 0.02597217485308647, "policy_loss": -0.0012668172783428134, "dist_entropy": 0.9181908130645752, "actor_grad_norm": 0.10859286040067673, "critic_grad_norm": 0.0916043370962143, "ratio": 0.999978244304657, "entropy": 0.9181908130645752, "incre_win_rate": 0.5142857142857142, "step": 400}
{"time": 1767332989.14714, "phase": "train", "update": 401, "total_env_steps": 1283200, "episode_reward": 0.193207785487175, "value_loss": 0.022581068426370622, "policy_loss": -0.0014021411876598221, "dist_entropy": 0.9402351021766663, "actor_grad_norm": 0.18532700836658478, "critic_grad_norm": 0.07635761052370071, "ratio": 1.00023353099823, "entropy": 0.9402351021766663, "incre_win_rate": 0.6571428571428571, "step": 401}
{"time": 1767333001.4042828, "phase": "eval", "update": 401, "total_env_steps": 1283200, "eval_win_rate": 0.8125, "eval_episode_reward": 18.83247102649007, "step": 401}
{"time": 1767333005.454205, "phase": "train", "update": 402, "total_env_steps": 1286400, "episode_reward": 0.19851045310497284, "value_loss": 0.02096288204193115, "policy_loss": -0.0010655099885797715, "dist_entropy": 0.9262918949127197, "actor_grad_norm": 0.08791130781173706, "critic_grad_norm": 0.09642854332923889, "ratio": 1.0000145435333252, "entropy": 0.9262918949127197, "incre_win_rate": 0.6388888888888888, "step": 402}
{"time": 1767333009.5010414, "phase": "train", "update": 403, "total_env_steps": 1289600, "episode_reward": 0.19398489594459534, "value_loss": 0.01810130514204502, "policy_loss": -0.0011842686003141977, "dist_entropy": 0.9397736191749573, "actor_grad_norm": 0.10002537071704865, "critic_grad_norm": 0.08578293770551682, "ratio": 1.0000418424606323, "entropy": 0.9397736191749573, "incre_win_rate": 0.6666666666666666, "step": 403}
{"time": 1767333013.5480855, "phase": "train", "update": 404, "total_env_steps": 1292800, "episode_reward": 0.19513039290905, "value_loss": 0.020561589300632475, "policy_loss": -0.0012822920560617845, "dist_entropy": 0.9396614670753479, "actor_grad_norm": 0.16563008725643158, "critic_grad_norm": 0.06358130276203156, "ratio": 1.000114917755127, "entropy": 0.9396614670753479, "incre_win_rate": 0.7142857142857143, "step": 404}
{"time": 1767333017.5463324, "phase": "train", "update": 405, "total_env_steps": 1296000, "episode_reward": 0.19342662394046783, "value_loss": 0.021584482118487357, "policy_loss": -0.0012136122988628984, "dist_entropy": 0.9363227844238281, "actor_grad_norm": 0.11809892952442169, "critic_grad_norm": 0.05567679554224014, "ratio": 0.9998015761375427, "entropy": 0.9363227844238281, "incre_win_rate": 0.6764705882352942, "step": 405}
{"time": 1767333021.5633364, "phase": "train", "update": 406, "total_env_steps": 1299200, "episode_reward": 0.19502072036266327, "value_loss": 0.02533358410000801, "policy_loss": -0.0012471103264110272, "dist_entropy": 0.9521169066429138, "actor_grad_norm": 0.12217964977025986, "critic_grad_norm": 0.08117365092039108, "ratio": 0.9999999403953552, "entropy": 0.9521169066429138, "incre_win_rate": 0.631578947368421, "step": 406}
{"time": 1767333025.5740163, "phase": "train", "update": 407, "total_env_steps": 1302400, "episode_reward": 0.2001272737979889, "value_loss": 0.02216276004910469, "policy_loss": -0.0013044425662045, "dist_entropy": 0.9681739807128906, "actor_grad_norm": 0.13162671029567719, "critic_grad_norm": 0.09126243740320206, "ratio": 1.000204086303711, "entropy": 0.9681739807128906, "incre_win_rate": 0.7352941176470589, "step": 407}
{"time": 1767333029.5841446, "phase": "train", "update": 408, "total_env_steps": 1305600, "episode_reward": 0.1820431500673294, "value_loss": 0.022477700561285018, "policy_loss": -0.0014064681405727697, "dist_entropy": 0.9588487386703491, "actor_grad_norm": 0.12624035775661469, "critic_grad_norm": 0.1047709733247757, "ratio": 0.9998481869697571, "entropy": 0.9588487386703491, "incre_win_rate": 0.4594594594594595, "step": 408}
{"time": 1767333033.6397665, "phase": "train", "update": 409, "total_env_steps": 1308800, "episode_reward": 0.19731271266937256, "value_loss": 0.019230561703443526, "policy_loss": -0.0010322215769143384, "dist_entropy": 0.9527076005935669, "actor_grad_norm": 0.11669053882360458, "critic_grad_norm": 0.09002356976270676, "ratio": 0.9999942183494568, "entropy": 0.9527076005935669, "incre_win_rate": 0.5833333333333334, "step": 409}
{"time": 1767333037.7135923, "phase": "train", "update": 410, "total_env_steps": 1312000, "episode_reward": 0.20632398128509521, "value_loss": 0.02076145224273205, "policy_loss": -0.00117975496457845, "dist_entropy": 0.9285808682441712, "actor_grad_norm": 0.13081473112106323, "critic_grad_norm": 0.09622030705213547, "ratio": 1.0000240802764893, "entropy": 0.9285808682441712, "incre_win_rate": 0.7027027027027027, "step": 410}
{"time": 1767333041.7331696, "phase": "train", "update": 411, "total_env_steps": 1315200, "episode_reward": 0.18209747970104218, "value_loss": 0.02328582517802715, "policy_loss": -0.0011859800685424915, "dist_entropy": 0.9432766318321228, "actor_grad_norm": 0.09407740086317062, "critic_grad_norm": 0.17666155099868774, "ratio": 0.9997038245201111, "entropy": 0.9432766318321228, "incre_win_rate": 0.4444444444444444, "step": 411}
{"time": 1767333045.780314, "phase": "train", "update": 412, "total_env_steps": 1318400, "episode_reward": 0.19545944035053253, "value_loss": 0.018522532656788826, "policy_loss": -0.001573970163637739, "dist_entropy": 0.9193298816680908, "actor_grad_norm": 0.1263984590768814, "critic_grad_norm": 0.12775087356567383, "ratio": 1.0000202655792236, "entropy": 0.9193298816680908, "incre_win_rate": 0.5833333333333334, "step": 412}
{"time": 1767333049.8289359, "phase": "train", "update": 413, "total_env_steps": 1321600, "episode_reward": 0.21161319315433502, "value_loss": 0.019321104511618614, "policy_loss": -0.0014174413651716123, "dist_entropy": 0.9437173247337342, "actor_grad_norm": 0.08243340253829956, "critic_grad_norm": 0.1418590545654297, "ratio": 1.0002802610397339, "entropy": 0.9437173247337342, "incre_win_rate": 0.7941176470588235, "step": 413}
{"time": 1767333053.8641436, "phase": "train", "update": 414, "total_env_steps": 1324800, "episode_reward": 0.18745239078998566, "value_loss": 0.03675333932042122, "policy_loss": -0.0015687042854704459, "dist_entropy": 0.887316906452179, "actor_grad_norm": 0.11851727962493896, "critic_grad_norm": 0.1682579666376114, "ratio": 0.9997650384902954, "entropy": 0.887316906452179, "incre_win_rate": 0.631578947368421, "step": 414}
{"time": 1767333057.8874724, "phase": "train", "update": 415, "total_env_steps": 1328000, "episode_reward": 0.19931240379810333, "value_loss": 0.02262306325137615, "policy_loss": -0.0010668188778808485, "dist_entropy": 0.8940000295639038, "actor_grad_norm": 0.10554099082946777, "critic_grad_norm": 0.11468010395765305, "ratio": 0.9997478723526001, "entropy": 0.8940000295639038, "incre_win_rate": 0.6764705882352942, "step": 415}
{"time": 1767333061.9240928, "phase": "train", "update": 416, "total_env_steps": 1331200, "episode_reward": 0.18992497026920319, "value_loss": 0.026993860304355622, "policy_loss": -0.001348916102112696, "dist_entropy": 0.9369121670722962, "actor_grad_norm": 0.13307009637355804, "critic_grad_norm": 0.15988585352897644, "ratio": 1.0004338026046753, "entropy": 0.9369121670722962, "incre_win_rate": 0.5555555555555556, "step": 416}
{"time": 1767333066.0048232, "phase": "train", "update": 417, "total_env_steps": 1334400, "episode_reward": 0.17008483409881592, "value_loss": 0.032594770193099976, "policy_loss": -0.0009438475442472338, "dist_entropy": 0.901694142818451, "actor_grad_norm": 0.129703089594841, "critic_grad_norm": 0.29609325528144836, "ratio": 1.000184416770935, "entropy": 0.901694142818451, "incre_win_rate": 0.4411764705882353, "step": 417}
{"time": 1767333070.0476673, "phase": "train", "update": 418, "total_env_steps": 1337600, "episode_reward": 0.18952037394046783, "value_loss": 0.02758890576660633, "policy_loss": -0.0011321070831257884, "dist_entropy": 0.9025666236877441, "actor_grad_norm": 0.09166514128446579, "critic_grad_norm": 0.18499557673931122, "ratio": 1.0002321004867554, "entropy": 0.9025666236877441, "incre_win_rate": 0.6, "step": 418}
{"time": 1767333074.0634577, "phase": "train", "update": 419, "total_env_steps": 1340800, "episode_reward": 0.19273696839809418, "value_loss": 0.02615378759801388, "policy_loss": -0.0013607193522531702, "dist_entropy": 0.9435632824897766, "actor_grad_norm": 0.16970805823802948, "critic_grad_norm": 0.1773749440908432, "ratio": 1.0001895427703857, "entropy": 0.9435632824897766, "incre_win_rate": 0.6571428571428571, "step": 419}
{"time": 1767333078.0636766, "phase": "train", "update": 420, "total_env_steps": 1344000, "episode_reward": 0.18375569581985474, "value_loss": 0.03310698494315147, "policy_loss": -0.0013230316520576936, "dist_entropy": 0.8900069475173951, "actor_grad_norm": 0.13863706588745117, "critic_grad_norm": 0.16793592274188995, "ratio": 0.9998507499694824, "entropy": 0.8900069475173951, "incre_win_rate": 0.6571428571428571, "step": 420}
{"time": 1767333082.084378, "phase": "train", "update": 421, "total_env_steps": 1347200, "episode_reward": 0.19827091693878174, "value_loss": 0.023040809854865073, "policy_loss": -0.0013145777182661078, "dist_entropy": 0.9211994290351868, "actor_grad_norm": 0.1436365395784378, "critic_grad_norm": 0.12365978956222534, "ratio": 1.0001986026763916, "entropy": 0.9211994290351868, "incre_win_rate": 0.5714285714285714, "step": 421}
{"time": 1767333086.1665044, "phase": "train", "update": 422, "total_env_steps": 1350400, "episode_reward": 0.19472061097621918, "value_loss": 0.02533845417201519, "policy_loss": -0.0014152809759096386, "dist_entropy": 0.9250932335853577, "actor_grad_norm": 0.11824088543653488, "critic_grad_norm": 0.10092663764953613, "ratio": 0.9997065663337708, "entropy": 0.9250932335853577, "incre_win_rate": 0.5405405405405406, "step": 422}
{"time": 1767333090.2727573, "phase": "train", "update": 423, "total_env_steps": 1353600, "episode_reward": 0.1956431269645691, "value_loss": 0.026352785155177118, "policy_loss": -0.0014416636716944708, "dist_entropy": 0.9259017825126648, "actor_grad_norm": 0.09574951976537704, "critic_grad_norm": 0.0858391746878624, "ratio": 0.9999109506607056, "entropy": 0.9259017825126648, "incre_win_rate": 0.5714285714285714, "step": 423}
{"time": 1767333094.3545651, "phase": "train", "update": 424, "total_env_steps": 1356800, "episode_reward": 0.18449348211288452, "value_loss": 0.026571166515350342, "policy_loss": -0.001000029103939326, "dist_entropy": 0.9166226506233215, "actor_grad_norm": 0.10370073467493057, "critic_grad_norm": 0.07924636453390121, "ratio": 1.000006079673767, "entropy": 0.9166226506233215, "incre_win_rate": 0.4864864864864865, "step": 424}
{"time": 1767333098.4057052, "phase": "train", "update": 425, "total_env_steps": 1360000, "episode_reward": 0.20314723253250122, "value_loss": 0.02060670256614685, "policy_loss": -0.0011886382656385308, "dist_entropy": 0.8815806388854981, "actor_grad_norm": 0.14898255467414856, "critic_grad_norm": 0.0561724491417408, "ratio": 1.0003076791763306, "entropy": 0.8815806388854981, "incre_win_rate": 0.6756756756756757, "step": 425}
{"time": 1767333102.4014904, "phase": "train", "update": 426, "total_env_steps": 1363200, "episode_reward": 0.18276283144950867, "value_loss": 0.035621944814920425, "policy_loss": -0.001148931702736561, "dist_entropy": 0.887468135356903, "actor_grad_norm": 0.08059396594762802, "critic_grad_norm": 0.1473480463027954, "ratio": 1.000356912612915, "entropy": 0.887468135356903, "incre_win_rate": 0.6363636363636364, "step": 426}
{"time": 1767333116.086276, "phase": "eval", "update": 426, "total_env_steps": 1363200, "eval_win_rate": 0.71875, "eval_episode_reward": 17.50434602649007, "step": 426}
{"time": 1767333120.1125026, "phase": "train", "update": 427, "total_env_steps": 1366400, "episode_reward": 0.1862386167049408, "value_loss": 0.03501232713460922, "policy_loss": -0.0011039012710014617, "dist_entropy": 0.894465970993042, "actor_grad_norm": 0.1675761342048645, "critic_grad_norm": 0.0878426656126976, "ratio": 1.0001614093780518, "entropy": 0.894465970993042, "incre_win_rate": 0.6388888888888888, "step": 427}
{"time": 1767333124.3315325, "phase": "train", "update": 428, "total_env_steps": 1369600, "episode_reward": 0.19861909747123718, "value_loss": 0.029134076088666916, "policy_loss": -0.00107095388942966, "dist_entropy": 0.9105390667915344, "actor_grad_norm": 0.12118083238601685, "critic_grad_norm": 0.11438305675983429, "ratio": 1.0003567934036255, "entropy": 0.9105390667915344, "incre_win_rate": 0.7352941176470589, "step": 428}
{"time": 1767333128.3761997, "phase": "train", "update": 429, "total_env_steps": 1372800, "episode_reward": 0.18926584720611572, "value_loss": 0.02496907003223896, "policy_loss": -0.001671261854167483, "dist_entropy": 0.9351710081100464, "actor_grad_norm": 0.09636487811803818, "critic_grad_norm": 0.07274996489286423, "ratio": 0.9998777508735657, "entropy": 0.9351710081100464, "incre_win_rate": 0.5135135135135135, "step": 429}
{"time": 1767333132.3933156, "phase": "train", "update": 430, "total_env_steps": 1376000, "episode_reward": 0.19179479777812958, "value_loss": 0.023750656843185426, "policy_loss": -0.00092633275693359, "dist_entropy": 0.9657431602478027, "actor_grad_norm": 0.12723013758659363, "critic_grad_norm": 0.07383840531110764, "ratio": 1.0004264116287231, "entropy": 0.9657431602478027, "incre_win_rate": 0.6363636363636364, "step": 430}
{"time": 1767333136.398905, "phase": "train", "update": 431, "total_env_steps": 1379200, "episode_reward": 0.18371689319610596, "value_loss": 0.029366370663046835, "policy_loss": -0.00105535575833251, "dist_entropy": 0.9330192089080811, "actor_grad_norm": 0.1120101734995842, "critic_grad_norm": 0.057138122618198395, "ratio": 1.0004596710205078, "entropy": 0.9330192089080811, "incre_win_rate": 0.5, "step": 431}
{"time": 1767333140.4541695, "phase": "train", "update": 432, "total_env_steps": 1382400, "episode_reward": 0.19225630164146423, "value_loss": 0.026292885839939117, "policy_loss": -0.0013584627847933461, "dist_entropy": 0.9789120316505432, "actor_grad_norm": 0.09381895512342453, "critic_grad_norm": 0.10503893345594406, "ratio": 1.00022554397583, "entropy": 0.9789120316505432, "incre_win_rate": 0.5526315789473685, "step": 432}
{"time": 1767333144.5264373, "phase": "train", "update": 433, "total_env_steps": 1385600, "episode_reward": 0.1862722635269165, "value_loss": 0.027781524136662482, "policy_loss": -0.0012615328134415904, "dist_entropy": 0.949942660331726, "actor_grad_norm": 0.10154476016759872, "critic_grad_norm": 0.07382745295763016, "ratio": 0.9998502135276794, "entropy": 0.949942660331726, "incre_win_rate": 0.4722222222222222, "step": 433}
{"time": 1767333148.5823367, "phase": "train", "update": 434, "total_env_steps": 1388800, "episode_reward": 0.20326057076454163, "value_loss": 0.024286888539791107, "policy_loss": -0.000969263128818909, "dist_entropy": 0.9360311388969421, "actor_grad_norm": 0.10817592591047287, "critic_grad_norm": 0.1987934112548828, "ratio": 1.0003420114517212, "entropy": 0.9360311388969421, "incre_win_rate": 0.7142857142857143, "step": 434}
{"time": 1767333153.1771195, "phase": "train", "update": 435, "total_env_steps": 1392000, "episode_reward": 0.1884690523147583, "value_loss": 0.022600002586841583, "policy_loss": -0.0010495113123127453, "dist_entropy": 0.9574771046638488, "actor_grad_norm": 0.10180526226758957, "critic_grad_norm": 0.1271974742412567, "ratio": 0.9999613165855408, "entropy": 0.9574771046638488, "incre_win_rate": 0.4857142857142857, "step": 435}
{"time": 1767333157.786129, "phase": "train", "update": 436, "total_env_steps": 1395200, "episode_reward": 0.18046201765537262, "value_loss": 0.025647590681910516, "policy_loss": -0.0013727435339497163, "dist_entropy": 0.9740484237670899, "actor_grad_norm": 0.16058075428009033, "critic_grad_norm": 0.17864952981472015, "ratio": 0.9994587898254395, "entropy": 0.9740484237670899, "incre_win_rate": 0.3888888888888889, "step": 436}
{"time": 1767333162.248592, "phase": "train", "update": 437, "total_env_steps": 1398400, "episode_reward": 0.1854635775089264, "value_loss": 0.02728492356836796, "policy_loss": -0.0010406407065733704, "dist_entropy": 0.936688244342804, "actor_grad_norm": 0.10214682668447495, "critic_grad_norm": 0.11028274148702621, "ratio": 0.9999813437461853, "entropy": 0.936688244342804, "incre_win_rate": 0.4857142857142857, "step": 437}
{"time": 1767333166.9480798, "phase": "train", "update": 438, "total_env_steps": 1401600, "episode_reward": 0.1822066307067871, "value_loss": 0.02264552041888237, "policy_loss": -0.0010844884727470472, "dist_entropy": 0.957626211643219, "actor_grad_norm": 0.13229404389858246, "critic_grad_norm": 0.07288367301225662, "ratio": 0.9999002814292908, "entropy": 0.957626211643219, "incre_win_rate": 0.3783783783783784, "step": 438}
{"time": 1767333171.2004166, "phase": "train", "update": 439, "total_env_steps": 1404800, "episode_reward": 0.1883247196674347, "value_loss": 0.021893169730901718, "policy_loss": -0.0016768262576690063, "dist_entropy": 0.9584725856781006, "actor_grad_norm": 0.16496436297893524, "critic_grad_norm": 0.09241887181997299, "ratio": 0.9997574687004089, "entropy": 0.9584725856781006, "incre_win_rate": 0.5405405405405406, "step": 439}
{"time": 1767333175.44205, "phase": "train", "update": 440, "total_env_steps": 1408000, "episode_reward": 0.19524990022182465, "value_loss": 0.021007903665304185, "policy_loss": -0.0008453801633912406, "dist_entropy": 0.95861337184906, "actor_grad_norm": 0.09681104868650436, "critic_grad_norm": 0.07966824620962143, "ratio": 0.9999015927314758, "entropy": 0.95861337184906, "incre_win_rate": 0.5428571428571428, "step": 440}
{"time": 1767333179.867315, "phase": "train", "update": 441, "total_env_steps": 1411200, "episode_reward": 0.1930127590894699, "value_loss": 0.021099590882658958, "policy_loss": -0.0013161318972333192, "dist_entropy": 0.9693992972373963, "actor_grad_norm": 0.1224089041352272, "critic_grad_norm": 0.057607538998126984, "ratio": 0.9997440576553345, "entropy": 0.9693992972373963, "incre_win_rate": 0.5588235294117647, "step": 441}
{"time": 1767333184.1757271, "phase": "train", "update": 442, "total_env_steps": 1414400, "episode_reward": 0.19181756675243378, "value_loss": 0.027497101202607156, "policy_loss": -0.0009967404361489684, "dist_entropy": 0.9757037878036499, "actor_grad_norm": 0.1040765792131424, "critic_grad_norm": 0.08865534514188766, "ratio": 1.00022292137146, "entropy": 0.9757037878036499, "incre_win_rate": 0.5526315789473685, "step": 442}
{"time": 1767333188.4124205, "phase": "train", "update": 443, "total_env_steps": 1417600, "episode_reward": 0.19653403759002686, "value_loss": 0.02084779553115368, "policy_loss": -0.0011746337716907363, "dist_entropy": 0.9664101123809814, "actor_grad_norm": 0.1793939769268036, "critic_grad_norm": 0.06409638375043869, "ratio": 0.999934196472168, "entropy": 0.9664101123809814, "incre_win_rate": 0.5789473684210527, "step": 443}
{"time": 1767333192.5209906, "phase": "train", "update": 444, "total_env_steps": 1420800, "episode_reward": 0.18704625964164734, "value_loss": 0.02517995461821556, "policy_loss": -0.0012490243329750684, "dist_entropy": 0.9895834445953369, "actor_grad_norm": 0.13229307532310486, "critic_grad_norm": 0.08613944798707962, "ratio": 1.000010371208191, "entropy": 0.9895834445953369, "incre_win_rate": 0.43243243243243246, "step": 444}
{"time": 1767333196.8183062, "phase": "train", "update": 445, "total_env_steps": 1424000, "episode_reward": 0.20636484026908875, "value_loss": 0.021645284816622735, "policy_loss": -0.0010520412212198238, "dist_entropy": 0.9712409973144531, "actor_grad_norm": 0.11088254302740097, "critic_grad_norm": 0.10584449023008347, "ratio": 0.9995157122612, "entropy": 0.9712409973144531, "incre_win_rate": 0.6571428571428571, "step": 445}
{"time": 1767333201.1036415, "phase": "train", "update": 446, "total_env_steps": 1427200, "episode_reward": 0.18443189561367035, "value_loss": 0.039452700316905974, "policy_loss": -0.0012927795245985863, "dist_entropy": 0.9549391269683838, "actor_grad_norm": 0.10825999826192856, "critic_grad_norm": 0.23971576988697052, "ratio": 0.9998388290405273, "entropy": 0.9549391269683838, "incre_win_rate": 0.5945945945945946, "step": 446}
{"time": 1767333205.2797935, "phase": "train", "update": 447, "total_env_steps": 1430400, "episode_reward": 0.2042653113603592, "value_loss": 0.02198276072740555, "policy_loss": -0.0012092806708045244, "dist_entropy": 0.966508436203003, "actor_grad_norm": 0.14219723641872406, "critic_grad_norm": 0.16678494215011597, "ratio": 0.9998897910118103, "entropy": 0.966508436203003, "incre_win_rate": 0.6944444444444444, "step": 447}
{"time": 1767333209.3733358, "phase": "train", "update": 448, "total_env_steps": 1433600, "episode_reward": 0.19888918101787567, "value_loss": 0.026083625480532648, "policy_loss": -0.0013870882438354216, "dist_entropy": 0.9577061057090759, "actor_grad_norm": 0.1490580141544342, "critic_grad_norm": 0.12026231735944748, "ratio": 1.0001379251480103, "entropy": 0.9577061057090759, "incre_win_rate": 0.6857142857142857, "step": 448}
{"time": 1767333213.542998, "phase": "train", "update": 449, "total_env_steps": 1436800, "episode_reward": 0.19274887442588806, "value_loss": 0.027696483582258225, "policy_loss": -0.0014763840664123507, "dist_entropy": 0.950839900970459, "actor_grad_norm": 0.1690988838672638, "critic_grad_norm": 0.09478110820055008, "ratio": 0.9997785687446594, "entropy": 0.950839900970459, "incre_win_rate": 0.5945945945945946, "step": 449}
{"time": 1767333217.9956017, "phase": "train", "update": 450, "total_env_steps": 1440000, "episode_reward": 0.18063172698020935, "value_loss": 0.020227765664458275, "policy_loss": -0.0012378565753436988, "dist_entropy": 0.950234305858612, "actor_grad_norm": 0.11866458505392075, "critic_grad_norm": 0.07778871804475784, "ratio": 1.0000311136245728, "entropy": 0.950234305858612, "incre_win_rate": 0.5294117647058824, "step": 450}
{"time": 1767333222.1155758, "phase": "train", "update": 451, "total_env_steps": 1443200, "episode_reward": 0.18627846240997314, "value_loss": 0.02263561636209488, "policy_loss": -0.0011136843246468686, "dist_entropy": 0.9654470086097717, "actor_grad_norm": 0.09736152738332748, "critic_grad_norm": 0.07080584764480591, "ratio": 1.0000152587890625, "entropy": 0.9654470086097717, "incre_win_rate": 0.65625, "step": 451}
{"time": 1767333235.98662, "phase": "eval", "update": 451, "total_env_steps": 1443200, "eval_win_rate": 0.625, "eval_episode_reward": 16.8658940397351, "step": 451}
{"time": 1767333240.2415, "phase": "train", "update": 452, "total_env_steps": 1446400, "episode_reward": 0.198648601770401, "value_loss": 0.01800454705953598, "policy_loss": -0.0007571889771714524, "dist_entropy": 0.9543670415878296, "actor_grad_norm": 0.10139413923025131, "critic_grad_norm": 0.061783622950315475, "ratio": 1.0001256465911865, "entropy": 0.9543670415878296, "incre_win_rate": 0.7428571428571429, "step": 452}
{"time": 1767333244.663785, "phase": "train", "update": 453, "total_env_steps": 1449600, "episode_reward": 0.1844107061624527, "value_loss": 0.0354643389582634, "policy_loss": -0.0015294196450772902, "dist_entropy": 0.9722406983375549, "actor_grad_norm": 0.12137991189956665, "critic_grad_norm": 0.17574524879455566, "ratio": 0.9997901320457458, "entropy": 0.9722406983375549, "incre_win_rate": 0.6, "step": 453}
{"time": 1767333249.1153557, "phase": "train", "update": 454, "total_env_steps": 1452800, "episode_reward": 0.19800756871700287, "value_loss": 0.020431282743811608, "policy_loss": -0.0013845888481021974, "dist_entropy": 0.9866023063659668, "actor_grad_norm": 0.09654010832309723, "critic_grad_norm": 0.12316184490919113, "ratio": 1.000166893005371, "entropy": 0.9866023063659668, "incre_win_rate": 0.5555555555555556, "step": 454}
{"time": 1767333253.3235183, "phase": "train", "update": 455, "total_env_steps": 1456000, "episode_reward": 0.1861703246831894, "value_loss": 0.0208411131054163, "policy_loss": -0.001236422050460817, "dist_entropy": 0.9574254274368286, "actor_grad_norm": 0.09631174802780151, "critic_grad_norm": 0.11409769207239151, "ratio": 1.0002332925796509, "entropy": 0.9574254274368286, "incre_win_rate": 0.5428571428571428, "step": 455}
{"time": 1767333257.5178878, "phase": "train", "update": 456, "total_env_steps": 1459200, "episode_reward": 0.1984059363603592, "value_loss": 0.02332381680607796, "policy_loss": -0.001007364399680455, "dist_entropy": 0.9702087640762329, "actor_grad_norm": 0.0798027440905571, "critic_grad_norm": 0.13938255608081818, "ratio": 1.0001596212387085, "entropy": 0.9702087640762329, "incre_win_rate": 0.5945945945945946, "step": 456}
{"time": 1767333261.6527696, "phase": "train", "update": 457, "total_env_steps": 1462400, "episode_reward": 0.183791384100914, "value_loss": 0.029513369500637054, "policy_loss": -0.0015351880087948189, "dist_entropy": 0.9856155633926391, "actor_grad_norm": 0.08542700856924057, "critic_grad_norm": 0.10976286232471466, "ratio": 0.9998441934585571, "entropy": 0.9856155633926391, "incre_win_rate": 0.4722222222222222, "step": 457}
{"time": 1767333265.8510487, "phase": "train", "update": 458, "total_env_steps": 1465600, "episode_reward": 0.19039735198020935, "value_loss": 0.028403444588184355, "policy_loss": -0.00107490493037794, "dist_entropy": 0.990535569190979, "actor_grad_norm": 0.08169136941432953, "critic_grad_norm": 0.09161050617694855, "ratio": 0.9997033476829529, "entropy": 0.990535569190979, "incre_win_rate": 0.5405405405405406, "step": 458}
{"time": 1767333271.7899163, "phase": "train", "update": 459, "total_env_steps": 1468800, "episode_reward": 0.1889248639345169, "value_loss": 0.028697485476732253, "policy_loss": -0.0013809922652001205, "dist_entropy": 0.9826231241226197, "actor_grad_norm": 0.12599214911460876, "critic_grad_norm": 0.08826621621847153, "ratio": 1.0004370212554932, "entropy": 0.9826231241226197, "incre_win_rate": 0.5714285714285714, "step": 459}
{"time": 1767333276.0331647, "phase": "train", "update": 460, "total_env_steps": 1472000, "episode_reward": 0.1927100569009781, "value_loss": 0.030877737700939177, "policy_loss": -0.001175968218108636, "dist_entropy": 0.9882217407226562, "actor_grad_norm": 0.09763190895318985, "critic_grad_norm": 0.1513068675994873, "ratio": 1.0000425577163696, "entropy": 0.9882217407226562, "incre_win_rate": 0.5555555555555556, "step": 460}
{"time": 1767333280.1896822, "phase": "train", "update": 461, "total_env_steps": 1475200, "episode_reward": 0.1900460422039032, "value_loss": 0.02891974076628685, "policy_loss": -0.0012098501321787581, "dist_entropy": 0.9764464378356934, "actor_grad_norm": 0.1318187713623047, "critic_grad_norm": 0.15455476939678192, "ratio": 0.9995817542076111, "entropy": 0.9764464378356934, "incre_win_rate": 0.5135135135135135, "step": 461}
{"time": 1767333284.344052, "phase": "train", "update": 462, "total_env_steps": 1478400, "episode_reward": 0.1939823180437088, "value_loss": 0.028371481969952584, "policy_loss": -0.0010497482308196027, "dist_entropy": 0.9683950662612915, "actor_grad_norm": 0.1313251107931137, "critic_grad_norm": 0.11251965910196304, "ratio": 0.9998674392700195, "entropy": 0.9683950662612915, "incre_win_rate": 0.5, "step": 462}
{"time": 1767333288.4326987, "phase": "train", "update": 463, "total_env_steps": 1481600, "episode_reward": 0.1947123408317566, "value_loss": 0.025927498191595077, "policy_loss": -0.0012631585373717336, "dist_entropy": 0.9836271405220032, "actor_grad_norm": 0.16027504205703735, "critic_grad_norm": 0.12582780420780182, "ratio": 0.9999027252197266, "entropy": 0.9836271405220032, "incre_win_rate": 0.6, "step": 463}
{"time": 1767333292.5577023, "phase": "train", "update": 464, "total_env_steps": 1484800, "episode_reward": 0.19605082273483276, "value_loss": 0.02433794066309929, "policy_loss": -0.0013709100243872285, "dist_entropy": 0.9792810201644897, "actor_grad_norm": 0.10520640760660172, "critic_grad_norm": 0.049281030893325806, "ratio": 0.99952232837677, "entropy": 0.9792810201644897, "incre_win_rate": 0.5641025641025641, "step": 464}
{"time": 1767333296.6457465, "phase": "train", "update": 465, "total_env_steps": 1488000, "episode_reward": 0.197075754404068, "value_loss": 0.022810273990035056, "policy_loss": -0.0013573533251122426, "dist_entropy": 0.9646725177764892, "actor_grad_norm": 0.17223785817623138, "critic_grad_norm": 0.04768683388829231, "ratio": 1.0001100301742554, "entropy": 0.9646725177764892, "incre_win_rate": 0.6363636363636364, "step": 465}
{"time": 1767333300.7986455, "phase": "train", "update": 466, "total_env_steps": 1491200, "episode_reward": 0.21072643995285034, "value_loss": 0.015109741501510144, "policy_loss": -0.0012735053604714607, "dist_entropy": 0.9490545392036438, "actor_grad_norm": 0.13346163928508759, "critic_grad_norm": 0.13851217925548553, "ratio": 0.9998036623001099, "entropy": 0.9490545392036438, "incre_win_rate": 0.7631578947368421, "step": 466}
{"time": 1767333305.0203874, "phase": "train", "update": 467, "total_env_steps": 1494400, "episode_reward": 0.20365272462368011, "value_loss": 0.02680121026933193, "policy_loss": -0.0016069985529654218, "dist_entropy": 0.9435287714004517, "actor_grad_norm": 0.10245772451162338, "critic_grad_norm": 0.13868452608585358, "ratio": 0.9996433258056641, "entropy": 0.9435287714004517, "incre_win_rate": 0.5789473684210527, "step": 467}
{"time": 1767333309.1582792, "phase": "train", "update": 468, "total_env_steps": 1497600, "episode_reward": 0.2047475278377533, "value_loss": 0.025355782359838486, "policy_loss": -0.0015452752752377562, "dist_entropy": 0.9298787117004395, "actor_grad_norm": 0.16491515934467316, "critic_grad_norm": 0.14390598237514496, "ratio": 1.0000180006027222, "entropy": 0.9298787117004395, "incre_win_rate": 0.7142857142857143, "step": 468}
{"time": 1767333313.2820609, "phase": "train", "update": 469, "total_env_steps": 1500800, "episode_reward": 0.1909685581922531, "value_loss": 0.03469036966562271, "policy_loss": -0.0009986575550030353, "dist_entropy": 0.9375374674797058, "actor_grad_norm": 0.10463161766529083, "critic_grad_norm": 0.1546637862920761, "ratio": 1.000290870666504, "entropy": 0.9375374674797058, "incre_win_rate": 0.5833333333333334, "step": 469}
{"time": 1767333317.3981395, "phase": "train", "update": 470, "total_env_steps": 1504000, "episode_reward": 0.20410026609897614, "value_loss": 0.02123415619134903, "policy_loss": -0.0011155708354253946, "dist_entropy": 0.9419668793678284, "actor_grad_norm": 0.13858680427074432, "critic_grad_norm": 0.13172011077404022, "ratio": 0.9998689889907837, "entropy": 0.9419668793678284, "incre_win_rate": 0.6666666666666666, "step": 470}
{"time": 1767333321.4778655, "phase": "train", "update": 471, "total_env_steps": 1507200, "episode_reward": 0.1997237354516983, "value_loss": 0.01861151084303856, "policy_loss": -0.0016460732893211372, "dist_entropy": 0.9245079755783081, "actor_grad_norm": 0.12825845181941986, "critic_grad_norm": 0.0858200341463089, "ratio": 0.999630868434906, "entropy": 0.9245079755783081, "incre_win_rate": 0.6666666666666666, "step": 471}
{"time": 1767333325.5913453, "phase": "train", "update": 472, "total_env_steps": 1510400, "episode_reward": 0.20814001560211182, "value_loss": 0.02053556628525257, "policy_loss": -0.0009464059550005288, "dist_entropy": 0.9319940686225892, "actor_grad_norm": 0.13950105011463165, "critic_grad_norm": 0.10096924751996994, "ratio": 0.9998451471328735, "entropy": 0.9319940686225892, "incre_win_rate": 0.6756756756756757, "step": 472}
{"time": 1767333329.709607, "phase": "train", "update": 473, "total_env_steps": 1513600, "episode_reward": 0.19873087108135223, "value_loss": 0.018638147786259652, "policy_loss": -0.001050549303994508, "dist_entropy": 0.9256170392036438, "actor_grad_norm": 0.1105692982673645, "critic_grad_norm": 0.08966677635908127, "ratio": 0.9997424483299255, "entropy": 0.9256170392036438, "incre_win_rate": 0.6388888888888888, "step": 473}
{"time": 1767333333.8307981, "phase": "train", "update": 474, "total_env_steps": 1516800, "episode_reward": 0.2019350230693817, "value_loss": 0.024952152743935585, "policy_loss": -0.0012286722881199807, "dist_entropy": 0.9555523633956909, "actor_grad_norm": 0.12504176795482635, "critic_grad_norm": 0.11809047311544418, "ratio": 0.9999596476554871, "entropy": 0.9555523633956909, "incre_win_rate": 0.6857142857142857, "step": 474}
{"time": 1767333337.9995165, "phase": "train", "update": 475, "total_env_steps": 1520000, "episode_reward": 0.20009365677833557, "value_loss": 0.025026766955852507, "policy_loss": -0.0012664453283917966, "dist_entropy": 0.9492746114730835, "actor_grad_norm": 0.11002341657876968, "critic_grad_norm": 0.1453476995229721, "ratio": 1.0000879764556885, "entropy": 0.9492746114730835, "incre_win_rate": 0.6052631578947368, "step": 475}
{"time": 1767333342.1344109, "phase": "train", "update": 476, "total_env_steps": 1523200, "episode_reward": 0.2089269459247589, "value_loss": 0.02306494638323784, "policy_loss": -0.001085338071666797, "dist_entropy": 0.9354205131530762, "actor_grad_norm": 0.08608527481555939, "critic_grad_norm": 0.10034691542387009, "ratio": 0.9996881484985352, "entropy": 0.9354205131530762, "incre_win_rate": 0.5897435897435898, "step": 476}
{"time": 1767333353.1649647, "phase": "eval", "update": 476, "total_env_steps": 1523200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.395126241721854, "step": 476}
{"time": 1767333357.290211, "phase": "train", "update": 477, "total_env_steps": 1526400, "episode_reward": 0.1922920048236847, "value_loss": 0.03514153137803078, "policy_loss": -0.0010798368084522282, "dist_entropy": 0.9431454539299011, "actor_grad_norm": 0.09180236607789993, "critic_grad_norm": 0.1342921108007431, "ratio": 0.9999405741691589, "entropy": 0.9431454539299011, "incre_win_rate": 0.4166666666666667, "step": 477}
{"time": 1767333361.4455981, "phase": "train", "update": 478, "total_env_steps": 1529600, "episode_reward": 0.1975921094417572, "value_loss": 0.025022029504179956, "policy_loss": -0.0016577712902737574, "dist_entropy": 0.9068851232528686, "actor_grad_norm": 0.13935786485671997, "critic_grad_norm": 0.10694252699613571, "ratio": 1.000062346458435, "entropy": 0.9068851232528686, "incre_win_rate": 0.5526315789473685, "step": 478}
{"time": 1767333365.5948908, "phase": "train", "update": 479, "total_env_steps": 1532800, "episode_reward": 0.21826158463954926, "value_loss": 0.02633819654583931, "policy_loss": -0.0007076151997516434, "dist_entropy": 0.9194888114929199, "actor_grad_norm": 0.14760372042655945, "critic_grad_norm": 0.14810790121555328, "ratio": 0.999910831451416, "entropy": 0.9194888114929199, "incre_win_rate": 0.775, "step": 479}
{"time": 1767333369.7249548, "phase": "train", "update": 480, "total_env_steps": 1536000, "episode_reward": 0.2155509889125824, "value_loss": 0.020062947273254396, "policy_loss": -0.0012364974722828491, "dist_entropy": 0.9046503186225892, "actor_grad_norm": 0.11886663734912872, "critic_grad_norm": 0.11523240804672241, "ratio": 0.9999255537986755, "entropy": 0.9046503186225892, "incre_win_rate": 0.7777777777777778, "step": 480}
{"time": 1767333373.8447168, "phase": "train", "update": 481, "total_env_steps": 1539200, "episode_reward": 0.22243686020374298, "value_loss": 0.01745983026921749, "policy_loss": -0.001302115048818564, "dist_entropy": 0.8969486355781555, "actor_grad_norm": 0.12536406517028809, "critic_grad_norm": 0.10904917865991592, "ratio": 0.9993950128555298, "entropy": 0.8969486355781555, "incre_win_rate": 0.8947368421052632, "step": 481}
{"time": 1767333377.917268, "phase": "train", "update": 482, "total_env_steps": 1542400, "episode_reward": 0.19267332553863525, "value_loss": 0.03250597938895226, "policy_loss": -0.0015114775817359316, "dist_entropy": 0.8978342056274414, "actor_grad_norm": 0.15262305736541748, "critic_grad_norm": 0.2004464864730835, "ratio": 0.9998272061347961, "entropy": 0.8978342056274414, "incre_win_rate": 0.5714285714285714, "step": 482}
{"time": 1767333382.0702574, "phase": "train", "update": 483, "total_env_steps": 1545600, "episode_reward": 0.19843801856040955, "value_loss": 0.031489374488592146, "policy_loss": -0.0013430829093437069, "dist_entropy": 0.8985186100006104, "actor_grad_norm": 0.17089347541332245, "critic_grad_norm": 0.14185558259487152, "ratio": 0.9997313618659973, "entropy": 0.8985186100006104, "incre_win_rate": 0.6666666666666666, "step": 483}
{"time": 1767333386.2012322, "phase": "train", "update": 484, "total_env_steps": 1548800, "episode_reward": 0.20824399590492249, "value_loss": 0.018934774026274682, "policy_loss": -0.0012078195084070486, "dist_entropy": 0.901928985118866, "actor_grad_norm": 0.15431633591651917, "critic_grad_norm": 0.057079799473285675, "ratio": 0.9999317526817322, "entropy": 0.901928985118866, "incre_win_rate": 0.7352941176470589, "step": 484}
{"time": 1767333390.3456132, "phase": "train", "update": 485, "total_env_steps": 1552000, "episode_reward": 0.2027488499879837, "value_loss": 0.021253296732902528, "policy_loss": -0.0009444416085905516, "dist_entropy": 0.8773530840873718, "actor_grad_norm": 0.12387166172266006, "critic_grad_norm": 0.06715767830610275, "ratio": 1.00011146068573, "entropy": 0.8773530840873718, "incre_win_rate": 0.6410256410256411, "step": 485}
{"time": 1767333394.4666471, "phase": "train", "update": 486, "total_env_steps": 1555200, "episode_reward": 0.20482616126537323, "value_loss": 0.026521133631467818, "policy_loss": -0.0008195456113043065, "dist_entropy": 0.8952226996421814, "actor_grad_norm": 0.11101000756025314, "critic_grad_norm": 0.10739243030548096, "ratio": 1.0002774000167847, "entropy": 0.8952226996421814, "incre_win_rate": 0.6756756756756757, "step": 486}
{"time": 1767333398.737566, "phase": "train", "update": 487, "total_env_steps": 1558400, "episode_reward": 0.2152193784713745, "value_loss": 0.026388011500239374, "policy_loss": -0.0013013696543850983, "dist_entropy": 0.9468625307083129, "actor_grad_norm": 0.10183105617761612, "critic_grad_norm": 0.19109688699245453, "ratio": 0.9997749328613281, "entropy": 0.9468625307083129, "incre_win_rate": 0.7352941176470589, "step": 487}
{"time": 1767333402.927471, "phase": "train", "update": 488, "total_env_steps": 1561600, "episode_reward": 0.21168874204158783, "value_loss": 0.021647687628865243, "policy_loss": -0.0014105168240213573, "dist_entropy": 0.9391496658325196, "actor_grad_norm": 0.1358327567577362, "critic_grad_norm": 0.13050737977027893, "ratio": 0.9998577237129211, "entropy": 0.9391496658325196, "incre_win_rate": 0.725, "step": 488}
{"time": 1767333407.0695834, "phase": "train", "update": 489, "total_env_steps": 1564800, "episode_reward": 0.20463474094867706, "value_loss": 0.01848365515470505, "policy_loss": -0.0010891546283417596, "dist_entropy": 0.9629145741462708, "actor_grad_norm": 0.1515350192785263, "critic_grad_norm": 0.11001014709472656, "ratio": 0.9997996687889099, "entropy": 0.9629145741462708, "incre_win_rate": 0.5789473684210527, "step": 489}
{"time": 1767333411.1867993, "phase": "train", "update": 490, "total_env_steps": 1568000, "episode_reward": 0.2064346820116043, "value_loss": 0.02532305531203747, "policy_loss": -0.0013282526175387942, "dist_entropy": 0.9442539215087891, "actor_grad_norm": 0.1147037073969841, "critic_grad_norm": 0.09691589325666428, "ratio": 0.9999918341636658, "entropy": 0.9442539215087891, "incre_win_rate": 0.6486486486486487, "step": 490}
{"time": 1767333449.3736362, "phase": "train", "update": 491, "total_env_steps": 1571200, "episode_reward": 0.18917889893054962, "value_loss": 0.1047914132475853, "policy_loss": -0.0012973554490365302, "dist_entropy": 0.9068869233131409, "actor_grad_norm": 0.1250777691602707, "critic_grad_norm": 0.319344699382782, "ratio": 0.9995481371879578, "entropy": 0.9068869233131409, "incre_win_rate": 0.6176470588235294, "step": 491}
{"time": 1767333453.444036, "phase": "train", "update": 492, "total_env_steps": 1574400, "episode_reward": 0.2012251615524292, "value_loss": 0.02259562388062477, "policy_loss": -0.0010554974583840248, "dist_entropy": 0.9379251956939697, "actor_grad_norm": 0.11959882080554962, "critic_grad_norm": 0.24204280972480774, "ratio": 1.0000689029693604, "entropy": 0.9379251956939697, "incre_win_rate": 0.6111111111111112, "step": 492}
{"time": 1767333457.5337584, "phase": "train", "update": 493, "total_env_steps": 1577600, "episode_reward": 0.19351303577423096, "value_loss": 0.03449104726314545, "policy_loss": -0.0014747078440905171, "dist_entropy": 0.957345712184906, "actor_grad_norm": 0.1330484002828598, "critic_grad_norm": 0.2032802402973175, "ratio": 1.00003182888031, "entropy": 0.957345712184906, "incre_win_rate": 0.5526315789473685, "step": 493}
{"time": 1767333461.5972037, "phase": "train", "update": 494, "total_env_steps": 1580800, "episode_reward": 0.2056218981742859, "value_loss": 0.020559026673436166, "policy_loss": -0.0012492797849196434, "dist_entropy": 0.9245189428329468, "actor_grad_norm": 0.113844133913517, "critic_grad_norm": 0.14077535271644592, "ratio": 0.9996097683906555, "entropy": 0.9245189428329468, "incre_win_rate": 0.6388888888888888, "step": 494}
{"time": 1767333465.6796455, "phase": "train", "update": 495, "total_env_steps": 1584000, "episode_reward": 0.18186412751674652, "value_loss": 0.0552014984190464, "policy_loss": -0.0012039949084403645, "dist_entropy": 0.9085767388343811, "actor_grad_norm": 0.12619848549365997, "critic_grad_norm": 0.4190342128276825, "ratio": 0.999546229839325, "entropy": 0.9085767388343811, "incre_win_rate": 0.5, "step": 495}
{"time": 1767333469.7467306, "phase": "train", "update": 496, "total_env_steps": 1587200, "episode_reward": 0.2019045054912567, "value_loss": 0.024450230598449706, "policy_loss": -0.001152475704166278, "dist_entropy": 0.9212854266166687, "actor_grad_norm": 0.09992371499538422, "critic_grad_norm": 0.22163057327270508, "ratio": 1.000163197517395, "entropy": 0.9212854266166687, "incre_win_rate": 0.5945945945945946, "step": 496}
{"time": 1767333473.7996833, "phase": "train", "update": 497, "total_env_steps": 1590400, "episode_reward": 0.19944226741790771, "value_loss": 0.022797936201095582, "policy_loss": -0.0007577489512414104, "dist_entropy": 0.9046768307685852, "actor_grad_norm": 0.09959237277507782, "critic_grad_norm": 0.17520339787006378, "ratio": 1.0003740787506104, "entropy": 0.9046768307685852, "incre_win_rate": 0.6666666666666666, "step": 497}
{"time": 1767333477.8584976, "phase": "train", "update": 498, "total_env_steps": 1593600, "episode_reward": 0.19808049499988556, "value_loss": 0.020309003069996834, "policy_loss": -0.0008380349224331951, "dist_entropy": 0.9068540453910827, "actor_grad_norm": 0.08721832931041718, "critic_grad_norm": 0.16871535778045654, "ratio": 0.9999679923057556, "entropy": 0.9068540453910827, "incre_win_rate": 0.5833333333333334, "step": 498}
{"time": 1767333481.9540942, "phase": "train", "update": 499, "total_env_steps": 1596800, "episode_reward": 0.21124224364757538, "value_loss": 0.018001673743128777, "policy_loss": -0.0009747876211378071, "dist_entropy": 0.9102770447731018, "actor_grad_norm": 0.11597175896167755, "critic_grad_norm": 0.12729889154434204, "ratio": 1.0001953840255737, "entropy": 0.9102770447731018, "incre_win_rate": 0.6944444444444444, "step": 499}
{"time": 1767333486.0167096, "phase": "train", "update": 500, "total_env_steps": 1600000, "episode_reward": 0.19672289490699768, "value_loss": 0.01903450898826122, "policy_loss": -0.0010332947233294477, "dist_entropy": 0.8788851976394654, "actor_grad_norm": 0.08410405367612839, "critic_grad_norm": 0.09431060403585434, "ratio": 0.9999354481697083, "entropy": 0.8788851976394654, "incre_win_rate": 0.6666666666666666, "step": 500}
{"time": 1767333490.076624, "phase": "train", "update": 501, "total_env_steps": 1603200, "episode_reward": 0.22597269713878632, "value_loss": 0.012434790283441544, "policy_loss": -0.0012445205324198127, "dist_entropy": 0.886967408657074, "actor_grad_norm": 0.12076412886381149, "critic_grad_norm": 0.08554842323064804, "ratio": 1.0001710653305054, "entropy": 0.886967408657074, "incre_win_rate": 0.8974358974358975, "step": 501}
{"time": 1767333501.8724642, "phase": "eval", "update": 501, "total_env_steps": 1603200, "eval_win_rate": 0.875, "eval_episode_reward": 19.33278145695364, "step": 501}
{"time": 1767333505.9252253, "phase": "train", "update": 502, "total_env_steps": 1606400, "episode_reward": 0.20111392438411713, "value_loss": 0.016779562830924986, "policy_loss": -0.0015057300324393453, "dist_entropy": 0.8612210035324097, "actor_grad_norm": 0.1009007915854454, "critic_grad_norm": 0.08918751031160355, "ratio": 0.9999307990074158, "entropy": 0.8612210035324097, "incre_win_rate": 0.6176470588235294, "step": 502}
{"time": 1767333510.0120227, "phase": "train", "update": 503, "total_env_steps": 1609600, "episode_reward": 0.19274887442588806, "value_loss": 0.024585749208927154, "policy_loss": -0.0010580815191026717, "dist_entropy": 0.8811943531036377, "actor_grad_norm": 0.11254329979419708, "critic_grad_norm": 0.14873407781124115, "ratio": 0.9993915557861328, "entropy": 0.8811943531036377, "incre_win_rate": 0.5277777777777778, "step": 503}
{"time": 1767333514.201364, "phase": "train", "update": 504, "total_env_steps": 1612800, "episode_reward": 0.19965852797031403, "value_loss": 0.022235579788684845, "policy_loss": -0.00134125351571015, "dist_entropy": 0.8757794260978699, "actor_grad_norm": 0.10297540575265884, "critic_grad_norm": 0.073404960334301, "ratio": 0.9998550415039062, "entropy": 0.8757794260978699, "incre_win_rate": 0.5789473684210527, "step": 504}
{"time": 1767333518.280187, "phase": "train", "update": 505, "total_env_steps": 1616000, "episode_reward": 0.22083453834056854, "value_loss": 0.01875557638704777, "policy_loss": -0.0009387898915441895, "dist_entropy": 0.8850750088691711, "actor_grad_norm": 0.11996372044086456, "critic_grad_norm": 0.21993212401866913, "ratio": 1.0002752542495728, "entropy": 0.8850750088691711, "incre_win_rate": 0.8333333333333334, "step": 505}
{"time": 1767333522.3795912, "phase": "train", "update": 506, "total_env_steps": 1619200, "episode_reward": 0.22263814508914948, "value_loss": 0.016865570843219758, "policy_loss": -0.0007742279428818222, "dist_entropy": 0.8711495041847229, "actor_grad_norm": 0.07674658298492432, "critic_grad_norm": 0.12122438102960587, "ratio": 0.9995079040527344, "entropy": 0.8711495041847229, "incre_win_rate": 0.8055555555555556, "step": 506}
{"time": 1767333526.4437053, "phase": "train", "update": 507, "total_env_steps": 1622400, "episode_reward": 0.200654998421669, "value_loss": 0.01622987538576126, "policy_loss": -0.0012571844707650825, "dist_entropy": 0.881992244720459, "actor_grad_norm": 0.11083061993122101, "critic_grad_norm": 0.08433781564235687, "ratio": 1.0000003576278687, "entropy": 0.881992244720459, "incre_win_rate": 0.7297297297297297, "step": 507}
{"time": 1767333530.519395, "phase": "train", "update": 508, "total_env_steps": 1625600, "episode_reward": 0.21423272788524628, "value_loss": 0.017142587155103684, "policy_loss": -0.0013746306984337765, "dist_entropy": 0.8718925714492798, "actor_grad_norm": 0.13112221658229828, "critic_grad_norm": 0.10628265142440796, "ratio": 0.9999780654907227, "entropy": 0.8718925714492798, "incre_win_rate": 0.7222222222222222, "step": 508}
{"time": 1767333534.5545042, "phase": "train", "update": 509, "total_env_steps": 1628800, "episode_reward": 0.19893521070480347, "value_loss": 0.02131129093468189, "policy_loss": -0.0009788684987668717, "dist_entropy": 0.842011547088623, "actor_grad_norm": 0.17213104665279388, "critic_grad_norm": 0.10044191032648087, "ratio": 0.9999614953994751, "entropy": 0.842011547088623, "incre_win_rate": 0.6944444444444444, "step": 509}
{"time": 1767333538.5763736, "phase": "train", "update": 510, "total_env_steps": 1632000, "episode_reward": 0.19704367220401764, "value_loss": 0.020961466431617736, "policy_loss": -0.0011381490284801288, "dist_entropy": 0.8356588959693909, "actor_grad_norm": 0.15590150654315948, "critic_grad_norm": 0.07646476477384567, "ratio": 0.9998517036437988, "entropy": 0.8356588959693909, "incre_win_rate": 0.5882352941176471, "step": 510}
{"time": 1767333542.6524808, "phase": "train", "update": 511, "total_env_steps": 1635200, "episode_reward": 0.20089145004749298, "value_loss": 0.02124246396124363, "policy_loss": -0.0007592063139469473, "dist_entropy": 0.8469109535217285, "actor_grad_norm": 0.11470457166433334, "critic_grad_norm": 0.12409581989049911, "ratio": 0.999992847442627, "entropy": 0.8469109535217285, "incre_win_rate": 0.5945945945945946, "step": 511}
{"time": 1767333546.8031373, "phase": "train", "update": 512, "total_env_steps": 1638400, "episode_reward": 0.22212697565555573, "value_loss": 0.02067567817866802, "policy_loss": -0.0012124250118738188, "dist_entropy": 0.8500377655029296, "actor_grad_norm": 0.11723281443119049, "critic_grad_norm": 0.16171956062316895, "ratio": 1.0000452995300293, "entropy": 0.8500377655029296, "incre_win_rate": 0.775, "step": 512}
{"time": 1767333550.9028308, "phase": "train", "update": 513, "total_env_steps": 1641600, "episode_reward": 0.20950227975845337, "value_loss": 0.018803283199667932, "policy_loss": -0.001034542696482532, "dist_entropy": 0.8786441683769226, "actor_grad_norm": 0.09233145415782928, "critic_grad_norm": 0.08686261624097824, "ratio": 1.000260353088379, "entropy": 0.8786441683769226, "incre_win_rate": 0.6842105263157895, "step": 513}
{"time": 1767333555.0419092, "phase": "train", "update": 514, "total_env_steps": 1644800, "episode_reward": 0.20282232761383057, "value_loss": 0.023019877821207048, "policy_loss": -0.0013605557624586594, "dist_entropy": 0.8819995999336243, "actor_grad_norm": 0.1084975004196167, "critic_grad_norm": 0.20178759098052979, "ratio": 0.9999292492866516, "entropy": 0.8819995999336243, "incre_win_rate": 0.6176470588235294, "step": 514}
{"time": 1767333559.0459511, "phase": "train", "update": 515, "total_env_steps": 1648000, "episode_reward": 0.21096748113632202, "value_loss": 0.019329697266221045, "policy_loss": -0.0008920769470257995, "dist_entropy": 0.8892936825752258, "actor_grad_norm": 0.10368607193231583, "critic_grad_norm": 0.09742068499326706, "ratio": 0.9997827410697937, "entropy": 0.8892936825752258, "incre_win_rate": 0.7894736842105263, "step": 515}
{"time": 1767333563.0355911, "phase": "train", "update": 516, "total_env_steps": 1651200, "episode_reward": 0.20008020102977753, "value_loss": 0.02200140878558159, "policy_loss": -0.0015755800784493345, "dist_entropy": 0.8953421235084533, "actor_grad_norm": 0.13956426084041595, "critic_grad_norm": 0.102096788585186, "ratio": 0.999792754650116, "entropy": 0.8953421235084533, "incre_win_rate": 0.6578947368421053, "step": 516}
{"time": 1767333567.0549746, "phase": "train", "update": 517, "total_env_steps": 1654400, "episode_reward": 0.20682378113269806, "value_loss": 0.01764550358057022, "policy_loss": -0.001209045194942604, "dist_entropy": 0.8831849098205566, "actor_grad_norm": 0.1264084428548813, "critic_grad_norm": 0.12129876762628555, "ratio": 1.000181794166565, "entropy": 0.8831849098205566, "incre_win_rate": 0.6764705882352942, "step": 517}
{"time": 1767333571.0605798, "phase": "train", "update": 518, "total_env_steps": 1657600, "episode_reward": 0.2044355422258377, "value_loss": 0.018707549944519997, "policy_loss": -0.0012557775306873964, "dist_entropy": 0.8947381138801574, "actor_grad_norm": 0.09797403961420059, "critic_grad_norm": 0.08789826184511185, "ratio": 0.9999791383743286, "entropy": 0.8947381138801574, "incre_win_rate": 0.7058823529411765, "step": 518}
{"time": 1767333575.1256585, "phase": "train", "update": 519, "total_env_steps": 1660800, "episode_reward": 0.20775558054447174, "value_loss": 0.015200310945510864, "policy_loss": -0.001152929959441451, "dist_entropy": 0.8748711705207824, "actor_grad_norm": 0.11818094551563263, "critic_grad_norm": 0.07296399772167206, "ratio": 1.0004836320877075, "entropy": 0.8748711705207824, "incre_win_rate": 0.6666666666666666, "step": 519}
{"time": 1767333579.159678, "phase": "train", "update": 520, "total_env_steps": 1664000, "episode_reward": 0.203132763504982, "value_loss": 0.019078992307186127, "policy_loss": -0.0008510333678074744, "dist_entropy": 0.8862009048461914, "actor_grad_norm": 0.10450514405965805, "critic_grad_norm": 0.07209821045398712, "ratio": 1.0001174211502075, "entropy": 0.8862009048461914, "incre_win_rate": 0.6666666666666666, "step": 520}
{"time": 1767333583.1859596, "phase": "train", "update": 521, "total_env_steps": 1667200, "episode_reward": 0.20283372700214386, "value_loss": 0.019507938250899314, "policy_loss": -0.0010863397184916578, "dist_entropy": 0.871752655506134, "actor_grad_norm": 0.13678710162639618, "critic_grad_norm": 0.05596015602350235, "ratio": 0.9994974136352539, "entropy": 0.871752655506134, "incre_win_rate": 0.7142857142857143, "step": 521}
{"time": 1767333587.1956913, "phase": "train", "update": 522, "total_env_steps": 1670400, "episode_reward": 0.204143226146698, "value_loss": 0.018299875408411027, "policy_loss": -0.0012383012804640715, "dist_entropy": 0.873910641670227, "actor_grad_norm": 0.1462840735912323, "critic_grad_norm": 0.061952996999025345, "ratio": 1.0000507831573486, "entropy": 0.873910641670227, "incre_win_rate": 0.6052631578947368, "step": 522}
{"time": 1767333591.2215466, "phase": "train", "update": 523, "total_env_steps": 1673600, "episode_reward": 0.19413389265537262, "value_loss": 0.021421954035758972, "policy_loss": -0.0010341235829635308, "dist_entropy": 0.8780488729476928, "actor_grad_norm": 0.08365678042173386, "critic_grad_norm": 0.1292610615491867, "ratio": 0.9997777938842773, "entropy": 0.8780488729476928, "incre_win_rate": 0.5555555555555556, "step": 523}
{"time": 1767333595.2895393, "phase": "train", "update": 524, "total_env_steps": 1676800, "episode_reward": 0.21935014426708221, "value_loss": 0.01601107567548752, "policy_loss": -0.0012150004586299445, "dist_entropy": 0.8809929490089417, "actor_grad_norm": 0.11509567499160767, "critic_grad_norm": 0.14259961247444153, "ratio": 1.0001108646392822, "entropy": 0.8809929490089417, "incre_win_rate": 0.7948717948717948, "step": 524}
{"time": 1767333599.3524625, "phase": "train", "update": 525, "total_env_steps": 1680000, "episode_reward": 0.22949813306331635, "value_loss": 0.013299275375902652, "policy_loss": -0.0010847496159669845, "dist_entropy": 0.9088370680809021, "actor_grad_norm": 0.10626421123743057, "critic_grad_norm": 0.09148357063531876, "ratio": 0.999909520149231, "entropy": 0.9088370680809021, "incre_win_rate": 0.9166666666666666, "step": 525}
{"time": 1767333603.3780982, "phase": "train", "update": 526, "total_env_steps": 1683200, "episode_reward": 0.1960756480693817, "value_loss": 0.019825740531086922, "policy_loss": -0.0009528821852093472, "dist_entropy": 0.8876493096351623, "actor_grad_norm": 0.15914498269557953, "critic_grad_norm": 0.09506265074014664, "ratio": 1.0000524520874023, "entropy": 0.8876493096351623, "incre_win_rate": 0.5789473684210527, "step": 526}
{"time": 1767333614.9033015, "phase": "eval", "update": 526, "total_env_steps": 1683200, "eval_win_rate": 0.84375, "eval_episode_reward": 19.03673427152318, "step": 526}
{"time": 1767333618.968251, "phase": "train", "update": 527, "total_env_steps": 1686400, "episode_reward": 0.21601665019989014, "value_loss": 0.01793680265545845, "policy_loss": -0.0009091709808778603, "dist_entropy": 0.9147392868995666, "actor_grad_norm": 0.11464221775531769, "critic_grad_norm": 0.03794896975159645, "ratio": 0.9999715685844421, "entropy": 0.9147392868995666, "incre_win_rate": 0.75, "step": 527}
{"time": 1767333623.0085263, "phase": "train", "update": 528, "total_env_steps": 1689600, "episode_reward": 0.19435690343379974, "value_loss": 0.022451937943696976, "policy_loss": -0.0014278384393563216, "dist_entropy": 0.8864524602890015, "actor_grad_norm": 0.14335200190544128, "critic_grad_norm": 0.058873631060123444, "ratio": 1.0001598596572876, "entropy": 0.8864524602890015, "incre_win_rate": 0.6857142857142857, "step": 528}
{"time": 1767333627.0712867, "phase": "train", "update": 529, "total_env_steps": 1692800, "episode_reward": 0.2101929783821106, "value_loss": 0.01632290370762348, "policy_loss": -0.0012148181282872982, "dist_entropy": 0.8961731672286988, "actor_grad_norm": 0.13622181117534637, "critic_grad_norm": 0.07152020186185837, "ratio": 0.9999051094055176, "entropy": 0.8961731672286988, "incre_win_rate": 0.6571428571428571, "step": 529}
{"time": 1767333631.119499, "phase": "train", "update": 530, "total_env_steps": 1696000, "episode_reward": 0.19674617052078247, "value_loss": 0.0194528441876173, "policy_loss": -0.001015040540906753, "dist_entropy": 0.9085476160049438, "actor_grad_norm": 0.08489551395177841, "critic_grad_norm": 0.05800900608301163, "ratio": 0.9999534487724304, "entropy": 0.9085476160049438, "incre_win_rate": 0.6111111111111112, "step": 530}
{"time": 1767333635.2203245, "phase": "train", "update": 531, "total_env_steps": 1699200, "episode_reward": 0.2141028642654419, "value_loss": 0.015233020484447479, "policy_loss": -0.0006247050717545832, "dist_entropy": 0.9197139024734498, "actor_grad_norm": 0.08271347731351852, "critic_grad_norm": 0.0670388862490654, "ratio": 0.9998534321784973, "entropy": 0.9197139024734498, "incre_win_rate": 0.7894736842105263, "step": 531}
{"time": 1767333639.2506657, "phase": "train", "update": 532, "total_env_steps": 1702400, "episode_reward": 0.21375519037246704, "value_loss": 0.015108487755060195, "policy_loss": -0.0012078980216658763, "dist_entropy": 0.922853696346283, "actor_grad_norm": 0.10150015354156494, "critic_grad_norm": 0.056970108300447464, "ratio": 0.9996386766433716, "entropy": 0.922853696346283, "incre_win_rate": 0.7222222222222222, "step": 532}
{"time": 1767333643.280644, "phase": "train", "update": 533, "total_env_steps": 1705600, "episode_reward": 0.20497514307498932, "value_loss": 0.019822222366929054, "policy_loss": -0.001391232664955311, "dist_entropy": 0.889439070224762, "actor_grad_norm": 0.09436897188425064, "critic_grad_norm": 0.13770867884159088, "ratio": 0.9998920559883118, "entropy": 0.889439070224762, "incre_win_rate": 0.7428571428571429, "step": 533}
{"time": 1767333647.34503, "phase": "train", "update": 534, "total_env_steps": 1708800, "episode_reward": 0.2029884159564972, "value_loss": 0.02238233983516693, "policy_loss": -0.0010776494870391672, "dist_entropy": 0.9284487247467041, "actor_grad_norm": 0.11564679443836212, "critic_grad_norm": 0.08801007270812988, "ratio": 1.000335693359375, "entropy": 0.9284487247467041, "incre_win_rate": 0.6578947368421053, "step": 534}
{"time": 1767333651.357072, "phase": "train", "update": 535, "total_env_steps": 1712000, "episode_reward": 0.20329523086547852, "value_loss": 0.02268756367266178, "policy_loss": -0.0010536207290100298, "dist_entropy": 0.9272642135620117, "actor_grad_norm": 0.14934788644313812, "critic_grad_norm": 0.07977276295423508, "ratio": 1.0000132322311401, "entropy": 0.9272642135620117, "incre_win_rate": 0.6842105263157895, "step": 535}
{"time": 1767333655.3870118, "phase": "train", "update": 536, "total_env_steps": 1715200, "episode_reward": 0.21199968457221985, "value_loss": 0.01686793565750122, "policy_loss": -0.001183140856268494, "dist_entropy": 0.920171320438385, "actor_grad_norm": 0.11226184666156769, "critic_grad_norm": 0.10941486805677414, "ratio": 0.9999475479125977, "entropy": 0.920171320438385, "incre_win_rate": 0.7647058823529411, "step": 536}
{"time": 1767333659.4223711, "phase": "train", "update": 537, "total_env_steps": 1718400, "episode_reward": 0.20154337584972382, "value_loss": 0.019260282814502715, "policy_loss": -0.0010811411559689787, "dist_entropy": 0.9619803786277771, "actor_grad_norm": 0.10723259299993515, "critic_grad_norm": 0.11429176479578018, "ratio": 0.9995986819267273, "entropy": 0.9619803786277771, "incre_win_rate": 0.6944444444444444, "step": 537}
{"time": 1767333663.5068326, "phase": "train", "update": 538, "total_env_steps": 1721600, "episode_reward": 0.1971818208694458, "value_loss": 0.024949877336621285, "policy_loss": -0.0011680017371727303, "dist_entropy": 0.9500596165657044, "actor_grad_norm": 0.10878755897283554, "critic_grad_norm": 0.18522420525550842, "ratio": 0.9999880194664001, "entropy": 0.9500596165657044, "incre_win_rate": 0.5757575757575758, "step": 538}
{"time": 1767333667.6352975, "phase": "train", "update": 539, "total_env_steps": 1724800, "episode_reward": 0.19762831926345825, "value_loss": 0.018932731077075004, "policy_loss": -0.0016355291431963792, "dist_entropy": 0.9411227107048035, "actor_grad_norm": 0.1355598419904709, "critic_grad_norm": 0.06603797525167465, "ratio": 0.9997348785400391, "entropy": 0.9411227107048035, "incre_win_rate": 0.6153846153846154, "step": 539}
{"time": 1767333671.8407638, "phase": "train", "update": 540, "total_env_steps": 1728000, "episode_reward": 0.20986081659793854, "value_loss": 0.016136036440730094, "policy_loss": -0.0013258834970173439, "dist_entropy": 0.9521163105964661, "actor_grad_norm": 0.12312334030866623, "critic_grad_norm": 0.13194340467453003, "ratio": 0.9999015927314758, "entropy": 0.9521163105964661, "incre_win_rate": 0.6756756756756757, "step": 540}
{"time": 1767333675.961702, "phase": "train", "update": 541, "total_env_steps": 1731200, "episode_reward": 0.19901800155639648, "value_loss": 0.03202183209359646, "policy_loss": -0.0009317253124699221, "dist_entropy": 0.9547021269798279, "actor_grad_norm": 0.12618255615234375, "critic_grad_norm": 0.14872418344020844, "ratio": 0.9995765089988708, "entropy": 0.9547021269798279, "incre_win_rate": 0.7058823529411765, "step": 541}
{"time": 1767333680.0487037, "phase": "train", "update": 542, "total_env_steps": 1734400, "episode_reward": 0.19652368128299713, "value_loss": 0.022772856429219245, "policy_loss": -0.001334274335301444, "dist_entropy": 0.942816960811615, "actor_grad_norm": 0.1375916451215744, "critic_grad_norm": 0.11444801092147827, "ratio": 1.00017249584198, "entropy": 0.942816960811615, "incre_win_rate": 0.6388888888888888, "step": 542}
{"time": 1767333684.1275132, "phase": "train", "update": 543, "total_env_steps": 1737600, "episode_reward": 0.20548011362552643, "value_loss": 0.020475025847554208, "policy_loss": -0.0009919003179102326, "dist_entropy": 0.940324604511261, "actor_grad_norm": 0.13181160390377045, "critic_grad_norm": 0.12035908550024033, "ratio": 1.0000776052474976, "entropy": 0.940324604511261, "incre_win_rate": 0.7297297297297297, "step": 543}
{"time": 1767333688.2122793, "phase": "train", "update": 544, "total_env_steps": 1740800, "episode_reward": 0.21362271904945374, "value_loss": 0.020096462219953537, "policy_loss": -0.001444875949999158, "dist_entropy": 0.9477609515190124, "actor_grad_norm": 0.12178043276071548, "critic_grad_norm": 0.0600830614566803, "ratio": 1.0000003576278687, "entropy": 0.9477609515190124, "incre_win_rate": 0.7297297297297297, "step": 544}
{"time": 1767333692.3352199, "phase": "train", "update": 545, "total_env_steps": 1744000, "episode_reward": 0.2075408697128296, "value_loss": 0.01871736943721771, "policy_loss": -0.0010780146535722679, "dist_entropy": 0.9186237812042236, "actor_grad_norm": 0.08480033278465271, "critic_grad_norm": 0.051610108464956284, "ratio": 0.9999756217002869, "entropy": 0.9186237812042236, "incre_win_rate": 0.7297297297297297, "step": 545}
{"time": 1767333696.4185355, "phase": "train", "update": 546, "total_env_steps": 1747200, "episode_reward": 0.20735307037830353, "value_loss": 0.014733251929283143, "policy_loss": -0.0014428757613288213, "dist_entropy": 0.9203017830848694, "actor_grad_norm": 0.10586811602115631, "critic_grad_norm": 0.05488404259085655, "ratio": 0.9996267557144165, "entropy": 0.9203017830848694, "incre_win_rate": 0.6842105263157895, "step": 546}
{"time": 1767333700.4998963, "phase": "train", "update": 547, "total_env_steps": 1750400, "episode_reward": 0.2207559049129486, "value_loss": 0.01615840047597885, "policy_loss": -0.0010919653782266892, "dist_entropy": 0.9587804079055786, "actor_grad_norm": 0.11246281862258911, "critic_grad_norm": 0.09019982069730759, "ratio": 0.9997919201850891, "entropy": 0.9587804079055786, "incre_win_rate": 0.8, "step": 547}
{"time": 1767333704.5865815, "phase": "train", "update": 548, "total_env_steps": 1753600, "episode_reward": 0.2044282853603363, "value_loss": 0.015680037252604962, "policy_loss": -0.0010450300902578036, "dist_entropy": 0.9334401845932007, "actor_grad_norm": 0.1098184809088707, "critic_grad_norm": 0.049262456595897675, "ratio": 1.0001018047332764, "entropy": 0.9334401845932007, "incre_win_rate": 0.6756756756756757, "step": 548}
{"time": 1767333708.7123163, "phase": "train", "update": 549, "total_env_steps": 1756800, "episode_reward": 0.2078218013048172, "value_loss": 0.015640775486826897, "policy_loss": -0.0010167738489921696, "dist_entropy": 0.9490285515785217, "actor_grad_norm": 0.10680031031370163, "critic_grad_norm": 0.07464196532964706, "ratio": 1.0004055500030518, "entropy": 0.9490285515785217, "incre_win_rate": 0.7027027027027027, "step": 549}
{"time": 1767333712.7807734, "phase": "train", "update": 550, "total_env_steps": 1760000, "episode_reward": 0.19859427213668823, "value_loss": 0.02090921252965927, "policy_loss": -0.0010023930065884202, "dist_entropy": 0.9241984963417054, "actor_grad_norm": 0.0970592200756073, "critic_grad_norm": 0.10020359605550766, "ratio": 0.9997965097427368, "entropy": 0.9241984963417054, "incre_win_rate": 0.5833333333333334, "step": 550}
{"time": 1767333716.8765473, "phase": "train", "update": 551, "total_env_steps": 1763200, "episode_reward": 0.20698729157447815, "value_loss": 0.01767100691795349, "policy_loss": -0.0015430753652125873, "dist_entropy": 0.9336475849151611, "actor_grad_norm": 0.1488272100687027, "critic_grad_norm": 0.04449332877993584, "ratio": 1.0002968311309814, "entropy": 0.9336475849151611, "incre_win_rate": 0.6486486486486487, "step": 551}
{"time": 1767333735.42306, "phase": "eval", "update": 551, "total_env_steps": 1763200, "eval_win_rate": 0.8125, "eval_episode_reward": 18.603114652317878, "step": 551}
{"time": 1767333739.5056763, "phase": "train", "update": 552, "total_env_steps": 1766400, "episode_reward": 0.2170208990573883, "value_loss": 0.015455892868340015, "policy_loss": -0.0010489611376520713, "dist_entropy": 0.9367995500564575, "actor_grad_norm": 0.1779177486896515, "critic_grad_norm": 0.10806401818990707, "ratio": 1.000346064567566, "entropy": 0.9367995500564575, "incre_win_rate": 0.7631578947368421, "step": 552}
{"time": 1767333743.600539, "phase": "train", "update": 553, "total_env_steps": 1769600, "episode_reward": 0.2113519310951233, "value_loss": 0.019072237610816955, "policy_loss": -0.0016374322300961807, "dist_entropy": 0.9425870656967164, "actor_grad_norm": 0.13833379745483398, "critic_grad_norm": 0.09623254090547562, "ratio": 1.000023603439331, "entropy": 0.9425870656967164, "incre_win_rate": 0.7428571428571429, "step": 553}
{"time": 1767333747.7085505, "phase": "train", "update": 554, "total_env_steps": 1772800, "episode_reward": 0.21843492984771729, "value_loss": 0.014950516074895859, "policy_loss": -0.0009844259682850521, "dist_entropy": 0.9419950723648072, "actor_grad_norm": 0.10079868137836456, "critic_grad_norm": 0.06988883763551712, "ratio": 1.0003700256347656, "entropy": 0.9419950723648072, "incre_win_rate": 0.8157894736842105, "step": 554}
{"time": 1767333751.794939, "phase": "train", "update": 555, "total_env_steps": 1776000, "episode_reward": 0.22411632537841797, "value_loss": 0.011470356024801731, "policy_loss": -0.001220852964081942, "dist_entropy": 0.9278011918067932, "actor_grad_norm": 0.14878271520137787, "critic_grad_norm": 0.04251439496874809, "ratio": 1.0001047849655151, "entropy": 0.9278011918067932, "incre_win_rate": 0.8333333333333334, "step": 555}
{"time": 1767333755.9381008, "phase": "train", "update": 556, "total_env_steps": 1779200, "episode_reward": 0.20630691945552826, "value_loss": 0.019123341515660287, "policy_loss": -0.00121520929787593, "dist_entropy": 0.9280008196830749, "actor_grad_norm": 0.10109321027994156, "critic_grad_norm": 0.13352958858013153, "ratio": 0.9998424649238586, "entropy": 0.9280008196830749, "incre_win_rate": 0.7, "step": 556}
{"time": 1767333760.1047747, "phase": "train", "update": 557, "total_env_steps": 1782400, "episode_reward": 0.22547081112861633, "value_loss": 0.01584747713059187, "policy_loss": -0.0009956282472813882, "dist_entropy": 0.9295670747756958, "actor_grad_norm": 0.07540769129991531, "critic_grad_norm": 0.08452294021844864, "ratio": 1.000051736831665, "entropy": 0.9295670747756958, "incre_win_rate": 0.8529411764705882, "step": 557}
{"time": 1767333764.1955683, "phase": "train", "update": 558, "total_env_steps": 1785600, "episode_reward": 0.21174773573875427, "value_loss": 0.019917242974042893, "policy_loss": -0.001145019573131023, "dist_entropy": 0.9018806934356689, "actor_grad_norm": 0.12256689369678497, "critic_grad_norm": 0.06029289588332176, "ratio": 0.9999025464057922, "entropy": 0.9018806934356689, "incre_win_rate": 0.717948717948718, "step": 558}
{"time": 1767333768.2874591, "phase": "train", "update": 559, "total_env_steps": 1788800, "episode_reward": 0.20898646116256714, "value_loss": 0.01665007881820202, "policy_loss": -0.0011877706109697072, "dist_entropy": 0.9208324551582336, "actor_grad_norm": 0.0938124880194664, "critic_grad_norm": 0.0636131688952446, "ratio": 0.9999963641166687, "entropy": 0.9208324551582336, "incre_win_rate": 0.7222222222222222, "step": 559}
{"time": 1767333772.3463306, "phase": "train", "update": 560, "total_env_steps": 1792000, "episode_reward": 0.19108030200004578, "value_loss": 0.021499206870794298, "policy_loss": -0.0015170295483414975, "dist_entropy": 0.9401714682579041, "actor_grad_norm": 0.13495700061321259, "critic_grad_norm": 0.15524046123027802, "ratio": 0.9997479319572449, "entropy": 0.9401714682579041, "incre_win_rate": 0.5428571428571428, "step": 560}
{"time": 1767333776.4070654, "phase": "train", "update": 561, "total_env_steps": 1795200, "episode_reward": 0.209204763174057, "value_loss": 0.018388953432440756, "policy_loss": -0.0008070518529507354, "dist_entropy": 0.9313011884689331, "actor_grad_norm": 0.11427879333496094, "critic_grad_norm": 0.08663014322519302, "ratio": 1.0001038312911987, "entropy": 0.9313011884689331, "incre_win_rate": 0.6666666666666666, "step": 561}
{"time": 1767333780.4936178, "phase": "train", "update": 562, "total_env_steps": 1798400, "episode_reward": 0.20377637445926666, "value_loss": 0.021335412189364432, "policy_loss": -0.001296204776794241, "dist_entropy": 0.9384473085403442, "actor_grad_norm": 0.10024756193161011, "critic_grad_norm": 0.07827221602201462, "ratio": 0.9997729659080505, "entropy": 0.9384473085403442, "incre_win_rate": 0.6, "step": 562}
{"time": 1767333784.5972323, "phase": "train", "update": 563, "total_env_steps": 1801600, "episode_reward": 0.20184189081192017, "value_loss": 0.020156459137797355, "policy_loss": -0.0011770496658549234, "dist_entropy": 0.923631739616394, "actor_grad_norm": 0.10945870727300644, "critic_grad_norm": 0.09595021605491638, "ratio": 1.0000795125961304, "entropy": 0.923631739616394, "incre_win_rate": 0.575, "step": 563}
{"time": 1767333788.72473, "phase": "train", "update": 564, "total_env_steps": 1804800, "episode_reward": 0.21316847205162048, "value_loss": 0.02166200280189514, "policy_loss": -0.000922080532251357, "dist_entropy": 0.9177560806274414, "actor_grad_norm": 0.10648038238286972, "critic_grad_norm": 0.11880698055028915, "ratio": 1.000573992729187, "entropy": 0.9177560806274414, "incre_win_rate": 0.6923076923076923, "step": 564}
{"time": 1767333792.8342848, "phase": "train", "update": 565, "total_env_steps": 1808000, "episode_reward": 0.22596752643585205, "value_loss": 0.018924887478351592, "policy_loss": -0.0014790294248831159, "dist_entropy": 0.9100598096847534, "actor_grad_norm": 0.09633346647024155, "critic_grad_norm": 0.03697570785880089, "ratio": 0.9998273253440857, "entropy": 0.9100598096847534, "incre_win_rate": 0.7567567567567568, "step": 565}
{"time": 1767333796.913483, "phase": "train", "update": 566, "total_env_steps": 1811200, "episode_reward": 0.20815294981002808, "value_loss": 0.016150561347603797, "policy_loss": -0.0014585802853218865, "dist_entropy": 0.8987860202789306, "actor_grad_norm": 0.11092860996723175, "critic_grad_norm": 0.062437206506729126, "ratio": 0.9997636675834656, "entropy": 0.8987860202789306, "incre_win_rate": 0.7222222222222222, "step": 566}
{"time": 1767333801.0289187, "phase": "train", "update": 567, "total_env_steps": 1814400, "episode_reward": 0.20898489654064178, "value_loss": 0.01833902932703495, "policy_loss": -0.0012763869764398806, "dist_entropy": 0.9011061310768127, "actor_grad_norm": 0.10456625372171402, "critic_grad_norm": 0.08456507325172424, "ratio": 0.99996417760849, "entropy": 0.9011061310768127, "incre_win_rate": 0.6923076923076923, "step": 567}
{"time": 1767333805.36026, "phase": "train", "update": 568, "total_env_steps": 1817600, "episode_reward": 0.21057532727718353, "value_loss": 0.016363805532455443, "policy_loss": -0.0013422844194671767, "dist_entropy": 0.9034727454185486, "actor_grad_norm": 0.11412639915943146, "critic_grad_norm": 0.04372198134660721, "ratio": 0.9996317028999329, "entropy": 0.9034727454185486, "incre_win_rate": 0.6578947368421053, "step": 568}
{"time": 1767333809.4519112, "phase": "train", "update": 569, "total_env_steps": 1820800, "episode_reward": 0.2132864147424698, "value_loss": 0.016555164381861685, "policy_loss": -0.0013885048326670812, "dist_entropy": 0.8990537047386169, "actor_grad_norm": 0.08656515926122665, "critic_grad_norm": 0.056153226643800735, "ratio": 1.0002259016036987, "entropy": 0.8990537047386169, "incre_win_rate": 0.7222222222222222, "step": 569}
{"time": 1767333813.5313594, "phase": "train", "update": 570, "total_env_steps": 1824000, "episode_reward": 0.22416804730892181, "value_loss": 0.012144873104989528, "policy_loss": -0.0014746705707310071, "dist_entropy": 0.8918210029602051, "actor_grad_norm": 0.16537737846374512, "critic_grad_norm": 0.08089304715394974, "ratio": 1.0007498264312744, "entropy": 0.8918210029602051, "incre_win_rate": 0.8421052631578947, "step": 570}
{"time": 1767333817.6455975, "phase": "train", "update": 571, "total_env_steps": 1827200, "episode_reward": 0.22198832035064697, "value_loss": 0.013878680020570754, "policy_loss": -0.0010747517011118646, "dist_entropy": 0.8982379317283631, "actor_grad_norm": 0.09626593440771103, "critic_grad_norm": 0.030998069792985916, "ratio": 0.9999520182609558, "entropy": 0.8982379317283631, "incre_win_rate": 0.8378378378378378, "step": 571}
{"time": 1767333821.6923501, "phase": "train", "update": 572, "total_env_steps": 1830400, "episode_reward": 0.21149471402168274, "value_loss": 0.017119023576378824, "policy_loss": -0.0009688706548246273, "dist_entropy": 0.9121009349822998, "actor_grad_norm": 0.1586480438709259, "critic_grad_norm": 0.08154645562171936, "ratio": 0.9992846846580505, "entropy": 0.9121009349822998, "incre_win_rate": 0.7567567567567568, "step": 572}
{"time": 1767333825.7450204, "phase": "train", "update": 573, "total_env_steps": 1833600, "episode_reward": 0.21185173094272614, "value_loss": 0.017440925166010857, "policy_loss": -0.0015003127122302118, "dist_entropy": 0.9032026529312134, "actor_grad_norm": 0.15940968692302704, "critic_grad_norm": 0.05001714453101158, "ratio": 0.9999365210533142, "entropy": 0.9032026529312134, "incre_win_rate": 0.6756756756756757, "step": 573}
{"time": 1767333829.8008645, "phase": "train", "update": 574, "total_env_steps": 1836800, "episode_reward": 0.21123343706130981, "value_loss": 0.015586713701486588, "policy_loss": -0.0012800449351568544, "dist_entropy": 0.9004443407058715, "actor_grad_norm": 0.14774073660373688, "critic_grad_norm": 0.080541230738163, "ratio": 1.000244140625, "entropy": 0.9004443407058715, "incre_win_rate": 0.8285714285714286, "step": 574}
{"time": 1767333833.876174, "phase": "train", "update": 575, "total_env_steps": 1840000, "episode_reward": 0.2010161429643631, "value_loss": 0.020723744481801986, "policy_loss": -0.0013891501232933478, "dist_entropy": 0.8593016147613526, "actor_grad_norm": 0.11463069170713425, "critic_grad_norm": 0.08982306718826294, "ratio": 1.0001133680343628, "entropy": 0.8593016147613526, "incre_win_rate": 0.7105263157894737, "step": 575}
{"time": 1767333837.957113, "phase": "train", "update": 576, "total_env_steps": 1843200, "episode_reward": 0.21267487108707428, "value_loss": 0.01351131834089756, "policy_loss": -0.001458573676752195, "dist_entropy": 0.882168459892273, "actor_grad_norm": 0.13659098744392395, "critic_grad_norm": 0.10941225290298462, "ratio": 1.0000394582748413, "entropy": 0.882168459892273, "incre_win_rate": 0.6944444444444444, "step": 576}
{"time": 1767333849.7130227, "phase": "eval", "update": 576, "total_env_steps": 1843200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.48592715231788, "step": 576}
{"time": 1767333853.7844164, "phase": "train", "update": 577, "total_env_steps": 1846400, "episode_reward": 0.21580247581005096, "value_loss": 0.014668368734419346, "policy_loss": -0.0008398848447281893, "dist_entropy": 0.8774534225463867, "actor_grad_norm": 0.11760149151086807, "critic_grad_norm": 0.061846692115068436, "ratio": 1.0000476837158203, "entropy": 0.8774534225463867, "incre_win_rate": 0.7368421052631579, "step": 577}
{"time": 1767333857.8838263, "phase": "train", "update": 578, "total_env_steps": 1849600, "episode_reward": 0.21376295387744904, "value_loss": 0.017289892211556433, "policy_loss": -0.0014985260085936148, "dist_entropy": 0.8849610686302185, "actor_grad_norm": 0.14326468110084534, "critic_grad_norm": 0.07582739740610123, "ratio": 1.0003966093063354, "entropy": 0.8849610686302185, "incre_win_rate": 0.8571428571428571, "step": 578}
{"time": 1767333861.9836175, "phase": "train", "update": 579, "total_env_steps": 1852800, "episode_reward": 0.216781884431839, "value_loss": 0.012926079891622066, "policy_loss": -0.0010773725848171266, "dist_entropy": 0.8704880595207214, "actor_grad_norm": 0.13449756801128387, "critic_grad_norm": 0.03420906886458397, "ratio": 1.0001989603042603, "entropy": 0.8704880595207214, "incre_win_rate": 0.7894736842105263, "step": 579}
{"time": 1767333866.0371778, "phase": "train", "update": 580, "total_env_steps": 1856000, "episode_reward": 0.21346645057201385, "value_loss": 0.01407665405422449, "policy_loss": -0.0010638841145354406, "dist_entropy": 0.8774559736251831, "actor_grad_norm": 0.1067822203040123, "critic_grad_norm": 0.06540001183748245, "ratio": 0.9999383091926575, "entropy": 0.8774559736251831, "incre_win_rate": 0.7428571428571429, "step": 580}
{"time": 1767333870.095771, "phase": "train", "update": 581, "total_env_steps": 1859200, "episode_reward": 0.20324194431304932, "value_loss": 0.015831887535750867, "policy_loss": -0.001332684633422332, "dist_entropy": 0.8768904566764831, "actor_grad_norm": 0.09094519168138504, "critic_grad_norm": 0.046958208084106445, "ratio": 0.999836266040802, "entropy": 0.8768904566764831, "incre_win_rate": 0.6216216216216216, "step": 581}
{"time": 1767333874.1779323, "phase": "train", "update": 582, "total_env_steps": 1862400, "episode_reward": 0.22169288992881775, "value_loss": 0.010927660949528217, "policy_loss": -0.0010735453993291344, "dist_entropy": 0.9158668637275695, "actor_grad_norm": 0.13137996196746826, "critic_grad_norm": 0.09654019773006439, "ratio": 0.9997455477714539, "entropy": 0.9158668637275695, "incre_win_rate": 0.868421052631579, "step": 582}
{"time": 1767333878.2625828, "phase": "train", "update": 583, "total_env_steps": 1865600, "episode_reward": 0.20328332483768463, "value_loss": 0.015102418698370456, "policy_loss": -0.0008779266991913559, "dist_entropy": 0.9212465643882751, "actor_grad_norm": 0.14743483066558838, "critic_grad_norm": 0.11834730207920074, "ratio": 1.0001598596572876, "entropy": 0.9212465643882751, "incre_win_rate": 0.6764705882352942, "step": 583}
{"time": 1767333882.2847507, "phase": "train", "update": 584, "total_env_steps": 1868800, "episode_reward": 0.20258277654647827, "value_loss": 0.016277942061424255, "policy_loss": -0.0013890881108821417, "dist_entropy": 0.9112871408462524, "actor_grad_norm": 0.09838496893644333, "critic_grad_norm": 0.15028662979602814, "ratio": 1.0000351667404175, "entropy": 0.9112871408462524, "incre_win_rate": 0.7297297297297297, "step": 584}
{"time": 1767333886.3307, "phase": "train", "update": 585, "total_env_steps": 1872000, "episode_reward": 0.21689826250076294, "value_loss": 0.012895380146801472, "policy_loss": -0.0011135711765231093, "dist_entropy": 0.93746098279953, "actor_grad_norm": 0.09928679466247559, "critic_grad_norm": 0.07276307046413422, "ratio": 1.0000768899917603, "entropy": 0.93746098279953, "incre_win_rate": 0.8285714285714286, "step": 585}
{"time": 1767333890.3768044, "phase": "train", "update": 586, "total_env_steps": 1875200, "episode_reward": 0.20780733227729797, "value_loss": 0.012021932937204837, "policy_loss": -0.0011929319627490998, "dist_entropy": 0.9273390173912048, "actor_grad_norm": 0.08814439177513123, "critic_grad_norm": 0.04980332404375076, "ratio": 0.9998907446861267, "entropy": 0.9273390173912048, "incre_win_rate": 0.7837837837837838, "step": 586}
{"time": 1767333894.4014516, "phase": "train", "update": 587, "total_env_steps": 1878400, "episode_reward": 0.20577193796634674, "value_loss": 0.014644611440598965, "policy_loss": -0.0017369819330419034, "dist_entropy": 0.941213846206665, "actor_grad_norm": 0.13265763223171234, "critic_grad_norm": 0.06575323641300201, "ratio": 1.0005513429641724, "entropy": 0.941213846206665, "incre_win_rate": 0.6470588235294118, "step": 587}
{"time": 1767333898.4559805, "phase": "train", "update": 588, "total_env_steps": 1881600, "episode_reward": 0.20761537551879883, "value_loss": 0.017478152364492416, "policy_loss": -0.0014251163725777615, "dist_entropy": 0.9188128352165222, "actor_grad_norm": 0.12621214985847473, "critic_grad_norm": 0.0833936259150505, "ratio": 0.9998529553413391, "entropy": 0.9188128352165222, "incre_win_rate": 0.7368421052631579, "step": 588}
{"time": 1767333902.5578032, "phase": "train", "update": 589, "total_env_steps": 1884800, "episode_reward": 0.21088680624961853, "value_loss": 0.0164378821849823, "policy_loss": -0.0012813845552436475, "dist_entropy": 0.9035834908485413, "actor_grad_norm": 0.132557213306427, "critic_grad_norm": 0.06143781542778015, "ratio": 0.9998766183853149, "entropy": 0.9035834908485413, "incre_win_rate": 0.6666666666666666, "step": 589}
{"time": 1767333906.6303225, "phase": "train", "update": 590, "total_env_steps": 1888000, "episode_reward": 0.20828485488891602, "value_loss": 0.018790656700730324, "policy_loss": -0.0017833194696329712, "dist_entropy": 0.8995305299758911, "actor_grad_norm": 0.12130240350961685, "critic_grad_norm": 0.04028911516070366, "ratio": 0.9997445940971375, "entropy": 0.8995305299758911, "incre_win_rate": 0.6216216216216216, "step": 590}
{"time": 1767333910.6733272, "phase": "train", "update": 591, "total_env_steps": 1891200, "episode_reward": 0.20524421334266663, "value_loss": 0.019081521406769754, "policy_loss": -0.000979904720771252, "dist_entropy": 0.8782084941864013, "actor_grad_norm": 0.10798075050115585, "critic_grad_norm": 0.034693486988544464, "ratio": 1.000131607055664, "entropy": 0.8782084941864013, "incre_win_rate": 0.7777777777777778, "step": 591}
{"time": 1767333914.778212, "phase": "train", "update": 592, "total_env_steps": 1894400, "episode_reward": 0.2205478996038437, "value_loss": 0.011477908492088318, "policy_loss": -0.0011843798668154104, "dist_entropy": 0.8826033592224121, "actor_grad_norm": 0.09372541308403015, "critic_grad_norm": 0.10932209342718124, "ratio": 0.9999322891235352, "entropy": 0.8826033592224121, "incre_win_rate": 0.8333333333333334, "step": 592}
{"time": 1767333918.843893, "phase": "train", "update": 593, "total_env_steps": 1897600, "episode_reward": 0.21065035462379456, "value_loss": 0.017440199851989746, "policy_loss": -0.001332113809728952, "dist_entropy": 0.8771148443222045, "actor_grad_norm": 0.1236267015337944, "critic_grad_norm": 0.10069823265075684, "ratio": 0.9997966885566711, "entropy": 0.8771148443222045, "incre_win_rate": 0.7894736842105263, "step": 593}
{"time": 1767333922.8804975, "phase": "train", "update": 594, "total_env_steps": 1900800, "episode_reward": 0.2126060426235199, "value_loss": 0.014036433771252632, "policy_loss": -0.0013150727963605392, "dist_entropy": 0.8783761739730835, "actor_grad_norm": 0.10393750667572021, "critic_grad_norm": 0.05694815516471863, "ratio": 1.000040054321289, "entropy": 0.8783761739730835, "incre_win_rate": 0.6764705882352942, "step": 594}
{"time": 1767333926.9690952, "phase": "train", "update": 595, "total_env_steps": 1904000, "episode_reward": 0.2230318784713745, "value_loss": 0.015250113606452943, "policy_loss": -0.0015319121205926932, "dist_entropy": 0.8471160531044006, "actor_grad_norm": 0.11958678066730499, "critic_grad_norm": 0.0388956256210804, "ratio": 1.0000580549240112, "entropy": 0.8471160531044006, "incre_win_rate": 0.8205128205128205, "step": 595}
{"time": 1767333931.0240695, "phase": "train", "update": 596, "total_env_steps": 1907200, "episode_reward": 0.2184230238199234, "value_loss": 0.01159998420625925, "policy_loss": -0.0010659632652121331, "dist_entropy": 0.8531596541404725, "actor_grad_norm": 0.12365291267633438, "critic_grad_norm": 0.0546090193092823, "ratio": 1.0002115964889526, "entropy": 0.8531596541404725, "incre_win_rate": 0.8157894736842105, "step": 596}
{"time": 1767333935.092743, "phase": "train", "update": 597, "total_env_steps": 1910400, "episode_reward": 0.214106485247612, "value_loss": 0.013519888557493687, "policy_loss": -0.0011993128770058092, "dist_entropy": 0.8417330861091614, "actor_grad_norm": 0.12334416061639786, "critic_grad_norm": 0.04431961849331856, "ratio": 1.0001806020736694, "entropy": 0.8417330861091614, "incre_win_rate": 0.7027027027027027, "step": 597}
{"time": 1767333939.1726828, "phase": "train", "update": 598, "total_env_steps": 1913600, "episode_reward": 0.22191639244556427, "value_loss": 0.015274572558701039, "policy_loss": -0.0009572292787005665, "dist_entropy": 0.8523014783859253, "actor_grad_norm": 0.1658569723367691, "critic_grad_norm": 0.06973589956760406, "ratio": 0.9996234178543091, "entropy": 0.8523014783859253, "incre_win_rate": 0.8857142857142857, "step": 598}
{"time": 1767333943.2335858, "phase": "train", "update": 599, "total_env_steps": 1916800, "episode_reward": 0.21749122440814972, "value_loss": 0.011818318627774715, "policy_loss": -0.0008485586724635396, "dist_entropy": 0.8417171835899353, "actor_grad_norm": 0.14855597913265228, "critic_grad_norm": 0.04485393688082695, "ratio": 0.9993506669998169, "entropy": 0.8417171835899353, "incre_win_rate": 0.8157894736842105, "step": 599}
{"time": 1767333947.2988505, "phase": "train", "update": 600, "total_env_steps": 1920000, "episode_reward": 0.2216002643108368, "value_loss": 0.012549466453492641, "policy_loss": -0.0008684892982813608, "dist_entropy": 0.8471739649772644, "actor_grad_norm": 0.17193901538848877, "critic_grad_norm": 0.039231736212968826, "ratio": 0.999609649181366, "entropy": 0.8471739649772644, "incre_win_rate": 0.8918918918918919, "step": 600}
{"time": 1767333951.3134964, "phase": "train", "update": 601, "total_env_steps": 1923200, "episode_reward": 0.21426324546337128, "value_loss": 0.01086117811501026, "policy_loss": -0.0010423426505610678, "dist_entropy": 0.8208995699882508, "actor_grad_norm": 0.17270241677761078, "critic_grad_norm": 0.06396026164293289, "ratio": 0.9996033906936646, "entropy": 0.8208995699882508, "incre_win_rate": 0.7567567567567568, "step": 601}
{"time": 1767333963.366171, "phase": "eval", "update": 601, "total_env_steps": 1923200, "eval_win_rate": 0.84375, "eval_episode_reward": 18.426686672185433, "step": 601}
{"time": 1767333967.459994, "phase": "train", "update": 602, "total_env_steps": 1926400, "episode_reward": 0.20997518301010132, "value_loss": 0.013019097223877906, "policy_loss": -0.0009698740772947189, "dist_entropy": 0.8179934024810791, "actor_grad_norm": 0.18040770292282104, "critic_grad_norm": 0.07357784360647202, "ratio": 1.0000866651535034, "entropy": 0.8179934024810791, "incre_win_rate": 0.7222222222222222, "step": 602}
{"time": 1767333971.4987025, "phase": "train", "update": 603, "total_env_steps": 1929600, "episode_reward": 0.19670426845550537, "value_loss": 0.017986809089779853, "policy_loss": -0.0009602251120329087, "dist_entropy": 0.8088472127914429, "actor_grad_norm": 0.14483116567134857, "critic_grad_norm": 0.11385568231344223, "ratio": 0.9999346733093262, "entropy": 0.8088472127914429, "incre_win_rate": 0.6944444444444444, "step": 603}
{"time": 1767333975.5785275, "phase": "train", "update": 604, "total_env_steps": 1932800, "episode_reward": 0.2046026587486267, "value_loss": 0.03143648207187653, "policy_loss": -0.0009171075416707808, "dist_entropy": 0.8400530934333801, "actor_grad_norm": 0.17367196083068848, "critic_grad_norm": 0.06437622755765915, "ratio": 0.9997264742851257, "entropy": 0.8400530934333801, "incre_win_rate": 0.7647058823529411, "step": 604}
{"time": 1767333979.5877264, "phase": "train", "update": 605, "total_env_steps": 1936000, "episode_reward": 0.20001709461212158, "value_loss": 0.02339732348918915, "policy_loss": -0.0014112060437567742, "dist_entropy": 0.8328222274780274, "actor_grad_norm": 0.1445777863264084, "critic_grad_norm": 0.04032255336642265, "ratio": 0.9999839067459106, "entropy": 0.8328222274780274, "incre_win_rate": 0.75, "step": 605}
{"time": 1767333983.6328874, "phase": "train", "update": 606, "total_env_steps": 1939200, "episode_reward": 0.2104470282793045, "value_loss": 0.014130718261003494, "policy_loss": -0.00133674720806507, "dist_entropy": 0.879067850112915, "actor_grad_norm": 0.12828229367733002, "critic_grad_norm": 0.08730102330446243, "ratio": 1.0001312494277954, "entropy": 0.879067850112915, "incre_win_rate": 0.7647058823529411, "step": 606}
{"time": 1767333987.6824296, "phase": "train", "update": 607, "total_env_steps": 1942400, "episode_reward": 0.19926221668720245, "value_loss": 0.014528371579945087, "policy_loss": -0.001189918613641794, "dist_entropy": 0.8495183467864991, "actor_grad_norm": 0.12037773430347443, "critic_grad_norm": 0.06659267097711563, "ratio": 0.9997002482414246, "entropy": 0.8495183467864991, "incre_win_rate": 0.6666666666666666, "step": 607}
{"time": 1767333991.7404892, "phase": "train", "update": 608, "total_env_steps": 1945600, "episode_reward": 0.20118272304534912, "value_loss": 0.01710650809109211, "policy_loss": -0.0014949432905808635, "dist_entropy": 0.8510388612747193, "actor_grad_norm": 0.13404317200183868, "critic_grad_norm": 0.05712486431002617, "ratio": 0.9997352957725525, "entropy": 0.8510388612747193, "incre_win_rate": 0.7222222222222222, "step": 608}
{"time": 1767333995.8286011, "phase": "train", "update": 609, "total_env_steps": 1948800, "episode_reward": 0.21157078444957733, "value_loss": 0.015192399546504021, "policy_loss": -0.0014907660794424515, "dist_entropy": 0.8683997392654419, "actor_grad_norm": 0.17077086865901947, "critic_grad_norm": 0.053201157599687576, "ratio": 0.9998359084129333, "entropy": 0.8683997392654419, "incre_win_rate": 0.7222222222222222, "step": 609}
{"time": 1767333999.8801403, "phase": "train", "update": 610, "total_env_steps": 1952000, "episode_reward": 0.2032657265663147, "value_loss": 0.013802986592054367, "policy_loss": -0.0009837156621980369, "dist_entropy": 0.8672844409942627, "actor_grad_norm": 0.11091981083154678, "critic_grad_norm": 0.06575307995080948, "ratio": 0.9997024536132812, "entropy": 0.8672844409942627, "incre_win_rate": 0.7714285714285715, "step": 610}
{"time": 1767334003.9327872, "phase": "train", "update": 611, "total_env_steps": 1955200, "episode_reward": 0.20396988093852997, "value_loss": 0.016412122920155526, "policy_loss": -0.0013835323979815683, "dist_entropy": 0.8778751850128174, "actor_grad_norm": 0.11620578914880753, "critic_grad_norm": 0.06672439724206924, "ratio": 0.9998626708984375, "entropy": 0.8778751850128174, "incre_win_rate": 0.6410256410256411, "step": 611}
{"time": 1767334008.022154, "phase": "train", "update": 612, "total_env_steps": 1958400, "episode_reward": 0.22010503709316254, "value_loss": 0.011668931692838669, "policy_loss": -0.0013673669435263491, "dist_entropy": 0.8892483115196228, "actor_grad_norm": 0.12166353315114975, "critic_grad_norm": 0.05016948655247688, "ratio": 1.0001989603042603, "entropy": 0.8892483115196228, "incre_win_rate": 0.8285714285714286, "step": 612}
{"time": 1767334012.1025932, "phase": "train", "update": 613, "total_env_steps": 1961600, "episode_reward": 0.20409353077411652, "value_loss": 0.018383248522877694, "policy_loss": -0.0015389748790312296, "dist_entropy": 0.8872301459312439, "actor_grad_norm": 0.13010452687740326, "critic_grad_norm": 0.16354888677597046, "ratio": 1.0001323223114014, "entropy": 0.8872301459312439, "incre_win_rate": 0.6666666666666666, "step": 613}
{"time": 1767334016.1656702, "phase": "train", "update": 614, "total_env_steps": 1964800, "episode_reward": 0.2001153826713562, "value_loss": 0.01663288287818432, "policy_loss": -0.0016382794708217573, "dist_entropy": 0.8961135506629944, "actor_grad_norm": 0.14263755083084106, "critic_grad_norm": 0.12294544279575348, "ratio": 0.9998987317085266, "entropy": 0.8961135506629944, "incre_win_rate": 0.6571428571428571, "step": 614}
{"time": 1767334020.1697085, "phase": "train", "update": 615, "total_env_steps": 1968000, "episode_reward": 0.1936020404100418, "value_loss": 0.01724979281425476, "policy_loss": -0.0015383833263697966, "dist_entropy": 0.8714978694915771, "actor_grad_norm": 0.09517936408519745, "critic_grad_norm": 0.07117917388677597, "ratio": 0.9999066591262817, "entropy": 0.8714978694915771, "incre_win_rate": 0.6388888888888888, "step": 615}
{"time": 1767334024.2091997, "phase": "train", "update": 616, "total_env_steps": 1971200, "episode_reward": 0.1971518099308014, "value_loss": 0.014492442645132542, "policy_loss": -0.0021420759988657776, "dist_entropy": 0.894000244140625, "actor_grad_norm": 0.19251368939876556, "critic_grad_norm": 0.08153138309717178, "ratio": 1.000178575515747, "entropy": 0.894000244140625, "incre_win_rate": 0.696969696969697, "step": 616}
{"time": 1767334028.3076484, "phase": "train", "update": 617, "total_env_steps": 1974400, "episode_reward": 0.19466577470302582, "value_loss": 0.015816397964954376, "policy_loss": -0.0010943497028243598, "dist_entropy": 0.9012302875518798, "actor_grad_norm": 0.12463157624006271, "critic_grad_norm": 0.04764634743332863, "ratio": 1.0000098943710327, "entropy": 0.9012302875518798, "incre_win_rate": 0.6571428571428571, "step": 617}
{"time": 1767334032.380882, "phase": "train", "update": 618, "total_env_steps": 1977600, "episode_reward": 0.20553651452064514, "value_loss": 0.012916845083236695, "policy_loss": -0.0016235056200329724, "dist_entropy": 0.8874404430389404, "actor_grad_norm": 0.18034628033638, "critic_grad_norm": 0.048961907625198364, "ratio": 0.9997953772544861, "entropy": 0.8874404430389404, "incre_win_rate": 0.7352941176470589, "step": 618}
{"time": 1767334036.4541264, "phase": "train", "update": 619, "total_env_steps": 1980800, "episode_reward": 0.20877379179000854, "value_loss": 0.014880605787038804, "policy_loss": -0.0014714646954291587, "dist_entropy": 0.8902790307998657, "actor_grad_norm": 0.10197704285383224, "critic_grad_norm": 0.08268848806619644, "ratio": 1.0000077486038208, "entropy": 0.8902790307998657, "incre_win_rate": 0.75, "step": 619}
{"time": 1767334040.522312, "phase": "train", "update": 620, "total_env_steps": 1984000, "episode_reward": 0.20615428686141968, "value_loss": 0.01383607555180788, "policy_loss": -0.0016725352568002449, "dist_entropy": 0.8836477160453796, "actor_grad_norm": 0.09250452369451523, "critic_grad_norm": 0.08272819966077805, "ratio": 1.0000269412994385, "entropy": 0.8836477160453796, "incre_win_rate": 0.7105263157894737, "step": 620}
{"time": 1767334044.5714188, "phase": "train", "update": 621, "total_env_steps": 1987200, "episode_reward": 0.20080919563770294, "value_loss": 0.01767544448375702, "policy_loss": -0.0010980203239787656, "dist_entropy": 0.9085425019264222, "actor_grad_norm": 0.12944363057613373, "critic_grad_norm": 0.06132146716117859, "ratio": 1.000466227531433, "entropy": 0.9085425019264222, "incre_win_rate": 0.6470588235294118, "step": 621}
{"time": 1767334048.6295907, "phase": "train", "update": 622, "total_env_steps": 1990400, "episode_reward": 0.19690914452075958, "value_loss": 0.016045229509472847, "policy_loss": -0.0013309579792277315, "dist_entropy": 0.8876314282417297, "actor_grad_norm": 0.13268700242042542, "critic_grad_norm": 0.045239925384521484, "ratio": 0.9996854066848755, "entropy": 0.8876314282417297, "incre_win_rate": 0.6285714285714286, "step": 622}
{"time": 1767334052.661491, "phase": "train", "update": 623, "total_env_steps": 1993600, "episode_reward": 0.19964714348316193, "value_loss": 0.015073823556303979, "policy_loss": -0.001339143142118715, "dist_entropy": 0.9038636088371277, "actor_grad_norm": 0.126810222864151, "critic_grad_norm": 0.03755679354071617, "ratio": 0.9997628331184387, "entropy": 0.9038636088371277, "incre_win_rate": 0.6388888888888888, "step": 623}
{"time": 1767334056.7288232, "phase": "train", "update": 624, "total_env_steps": 1996800, "episode_reward": 0.18688224256038666, "value_loss": 0.01629032250493765, "policy_loss": -0.0010475925380347916, "dist_entropy": 0.8783656835556031, "actor_grad_norm": 0.1405249536037445, "critic_grad_norm": 0.07957937568426132, "ratio": 0.9997914433479309, "entropy": 0.8783656835556031, "incre_win_rate": 0.6666666666666666, "step": 624}
{"time": 1767334060.7773054, "phase": "train", "update": 625, "total_env_steps": 2000000, "episode_reward": 0.1942409873008728, "value_loss": 0.026993408799171448, "policy_loss": -0.0009583796699160985, "dist_entropy": 0.8946794033050537, "actor_grad_norm": 0.1401437669992447, "critic_grad_norm": 0.11013241112232208, "ratio": 0.9999275207519531, "entropy": 0.8946794033050537, "incre_win_rate": 0.5833333333333334, "step": 625}
{"time": 1767334064.813159, "phase": "train", "update": 626, "total_env_steps": 2003200, "episode_reward": 0.19470714032649994, "value_loss": 0.017195051163434984, "policy_loss": -0.001286036258284895, "dist_entropy": 0.8994374394416809, "actor_grad_norm": 0.10862403362989426, "critic_grad_norm": 0.05994843319058418, "ratio": 0.9999074339866638, "entropy": 0.8994374394416809, "incre_win_rate": 0.6111111111111112, "step": 626}
{"time": 1767334077.7425272, "phase": "eval", "update": 626, "total_env_steps": 2003200, "eval_win_rate": 0.75, "eval_episode_reward": 18.84406043046358, "step": 626}
{"time": 1767334081.8023577, "phase": "train", "update": 627, "total_env_steps": 2006400, "episode_reward": 0.20108497142791748, "value_loss": 0.016777310892939566, "policy_loss": -0.0013656004062710281, "dist_entropy": 0.8884450316429138, "actor_grad_norm": 0.11027585715055466, "critic_grad_norm": 0.17027556896209717, "ratio": 0.9994975328445435, "entropy": 0.8884450316429138, "incre_win_rate": 0.7647058823529411, "step": 627}
{"time": 1767334085.8547657, "phase": "train", "update": 628, "total_env_steps": 2009600, "episode_reward": 0.19353683292865753, "value_loss": 0.018619972094893456, "policy_loss": -0.0011596693209774856, "dist_entropy": 0.8916658878326416, "actor_grad_norm": 0.10850652307271957, "critic_grad_norm": 0.09952846169471741, "ratio": 1.0006412267684937, "entropy": 0.8916658878326416, "incre_win_rate": 0.5714285714285714, "step": 628}
{"time": 1767334089.983309, "phase": "train", "update": 629, "total_env_steps": 2012800, "episode_reward": 0.20073054730892181, "value_loss": 0.014947901479899883, "policy_loss": -0.0011424900862294861, "dist_entropy": 0.8914944171905518, "actor_grad_norm": 0.09877479076385498, "critic_grad_norm": 0.04943041130900383, "ratio": 0.9998423457145691, "entropy": 0.8914944171905518, "incre_win_rate": 0.6486486486486487, "step": 629}
{"time": 1767334094.0157368, "phase": "train", "update": 630, "total_env_steps": 2016000, "episode_reward": 0.20395074784755707, "value_loss": 0.012972101010382176, "policy_loss": -0.0013827398315545913, "dist_entropy": 0.9178415298461914, "actor_grad_norm": 0.09201466292142868, "critic_grad_norm": 0.045385878533124924, "ratio": 1.0000814199447632, "entropy": 0.9178415298461914, "incre_win_rate": 0.6764705882352942, "step": 630}
{"time": 1767334098.0656986, "phase": "train", "update": 631, "total_env_steps": 2019200, "episode_reward": 0.2131105363368988, "value_loss": 0.011764578334987164, "policy_loss": -0.0010191121600442443, "dist_entropy": 0.9365223050117493, "actor_grad_norm": 0.14307820796966553, "critic_grad_norm": 0.04696449264883995, "ratio": 0.9999185800552368, "entropy": 0.9365223050117493, "incre_win_rate": 0.7894736842105263, "step": 631}
{"time": 1767334102.1181815, "phase": "train", "update": 632, "total_env_steps": 2022400, "episode_reward": 0.2035089135169983, "value_loss": 0.015987246483564376, "policy_loss": -0.001232877048556702, "dist_entropy": 0.9271224975585938, "actor_grad_norm": 0.10267625004053116, "critic_grad_norm": 0.07170597463846207, "ratio": 0.9994205832481384, "entropy": 0.9271224975585938, "incre_win_rate": 0.6571428571428571, "step": 632}
{"time": 1767334106.1952019, "phase": "train", "update": 633, "total_env_steps": 2025600, "episode_reward": 0.20798376202583313, "value_loss": 0.014245264977216721, "policy_loss": -0.0014759795789281327, "dist_entropy": 0.9243533492088318, "actor_grad_norm": 0.10092367976903915, "critic_grad_norm": 0.0933777466416359, "ratio": 0.9999826550483704, "entropy": 0.9243533492088318, "incre_win_rate": 0.7027027027027027, "step": 633}
{"time": 1767334110.2887201, "phase": "train", "update": 634, "total_env_steps": 2028800, "episode_reward": 0.21283113956451416, "value_loss": 0.013160174340009689, "policy_loss": -0.001466897134272216, "dist_entropy": 0.9492465853691101, "actor_grad_norm": 0.11092301458120346, "critic_grad_norm": 0.12957124412059784, "ratio": 1.0002130270004272, "entropy": 0.9492465853691101, "incre_win_rate": 0.75, "step": 634}
{"time": 1767334114.3653028, "phase": "train", "update": 635, "total_env_steps": 2032000, "episode_reward": 0.20823001861572266, "value_loss": 0.012281219474971294, "policy_loss": -0.0014279106254580399, "dist_entropy": 0.9488629102706909, "actor_grad_norm": 0.09290976822376251, "critic_grad_norm": 0.04687534272670746, "ratio": 0.9999755024909973, "entropy": 0.9488629102706909, "incre_win_rate": 0.6666666666666666, "step": 635}
{"time": 1767334118.4342446, "phase": "train", "update": 636, "total_env_steps": 2035200, "episode_reward": 0.2159954458475113, "value_loss": 0.013144062459468841, "policy_loss": -0.0017186313049106338, "dist_entropy": 0.9189172506332397, "actor_grad_norm": 0.0996994897723198, "critic_grad_norm": 0.031836435198783875, "ratio": 0.9997709393501282, "entropy": 0.9189172506332397, "incre_win_rate": 0.7692307692307693, "step": 636}
{"time": 1767334122.5039668, "phase": "train", "update": 637, "total_env_steps": 2038400, "episode_reward": 0.21697485446929932, "value_loss": 0.011143738217651845, "policy_loss": -0.0010603570820748587, "dist_entropy": 0.9059157371520996, "actor_grad_norm": 0.09103601425886154, "critic_grad_norm": 0.03485431894659996, "ratio": 1.0000485181808472, "entropy": 0.9059157371520996, "incre_win_rate": 0.7428571428571429, "step": 637}
{"time": 1767334126.5547373, "phase": "train", "update": 638, "total_env_steps": 2041600, "episode_reward": 0.2187044769525528, "value_loss": 0.013386455923318863, "policy_loss": -0.0015342435186543213, "dist_entropy": 0.8834816694259644, "actor_grad_norm": 0.09699093550443649, "critic_grad_norm": 0.06998281925916672, "ratio": 0.9999702572822571, "entropy": 0.8834816694259644, "incre_win_rate": 0.8378378378378378, "step": 638}
{"time": 1767334130.6780536, "phase": "train", "update": 639, "total_env_steps": 2044800, "episode_reward": 0.22373655438423157, "value_loss": 0.011883997544646262, "policy_loss": -0.0012222026956123955, "dist_entropy": 0.8752545833587646, "actor_grad_norm": 0.10204624384641647, "critic_grad_norm": 0.08131986111402512, "ratio": 1.0000240802764893, "entropy": 0.8752545833587646, "incre_win_rate": 0.8974358974358975, "step": 639}
{"time": 1767334134.7149262, "phase": "train", "update": 640, "total_env_steps": 2048000, "episode_reward": 0.20130328834056854, "value_loss": 0.018953194469213487, "policy_loss": -0.0015509567537730362, "dist_entropy": 0.9125339150428772, "actor_grad_norm": 0.1840042769908905, "critic_grad_norm": 0.1522594690322876, "ratio": 1.0002187490463257, "entropy": 0.9125339150428772, "incre_win_rate": 0.696969696969697, "step": 640}
{"time": 1767334138.7748325, "phase": "train", "update": 641, "total_env_steps": 2051200, "episode_reward": 0.204348623752594, "value_loss": 0.019265757128596305, "policy_loss": -0.0012705475609692484, "dist_entropy": 0.875824773311615, "actor_grad_norm": 0.12807399034500122, "critic_grad_norm": 0.09241574257612228, "ratio": 0.9998618364334106, "entropy": 0.875824773311615, "incre_win_rate": 0.8333333333333334, "step": 641}
{"time": 1767334142.8676145, "phase": "train", "update": 642, "total_env_steps": 2054400, "episode_reward": 0.2255256474018097, "value_loss": 0.01009693518280983, "policy_loss": -0.001229683833889439, "dist_entropy": 0.899863862991333, "actor_grad_norm": 0.09658705443143845, "critic_grad_norm": 0.10076979547739029, "ratio": 1.0001522302627563, "entropy": 0.899863862991333, "incre_win_rate": 0.8918918918918919, "step": 642}
{"time": 1767334146.9287887, "phase": "train", "update": 643, "total_env_steps": 2057600, "episode_reward": 0.20018626749515533, "value_loss": 0.01647593080997467, "policy_loss": -0.0015526072615116959, "dist_entropy": 0.8732674479484558, "actor_grad_norm": 0.09735225886106491, "critic_grad_norm": 0.11015017330646515, "ratio": 1.000044345855713, "entropy": 0.8732674479484558, "incre_win_rate": 0.7058823529411765, "step": 643}
{"time": 1767334151.0240536, "phase": "train", "update": 644, "total_env_steps": 2060800, "episode_reward": 0.20593804121017456, "value_loss": 0.018031947687268256, "policy_loss": -0.001072982043201165, "dist_entropy": 0.8704210877418518, "actor_grad_norm": 0.15070022642612457, "critic_grad_norm": 0.16722217202186584, "ratio": 0.9993986487388611, "entropy": 0.8704210877418518, "incre_win_rate": 0.7777777777777778, "step": 644}
{"time": 1767334155.199761, "phase": "train", "update": 645, "total_env_steps": 2064000, "episode_reward": 0.22390159964561462, "value_loss": 0.013337009586393833, "policy_loss": -0.001066399216441738, "dist_entropy": 0.9001394391059876, "actor_grad_norm": 0.1755988448858261, "critic_grad_norm": 0.14107196033000946, "ratio": 1.0001763105392456, "entropy": 0.9001394391059876, "incre_win_rate": 0.8378378378378378, "step": 645}
{"time": 1767334159.2735922, "phase": "train", "update": 646, "total_env_steps": 2067200, "episode_reward": 0.2148168534040451, "value_loss": 0.01565253920853138, "policy_loss": -0.0011901718608202216, "dist_entropy": 0.8694809436798095, "actor_grad_norm": 0.10786081850528717, "critic_grad_norm": 0.12990741431713104, "ratio": 1.0000180006027222, "entropy": 0.8694809436798095, "incre_win_rate": 0.75, "step": 646}
{"time": 1767334163.339232, "phase": "train", "update": 647, "total_env_steps": 2070400, "episode_reward": 0.2074684351682663, "value_loss": 0.013126265816390514, "policy_loss": -0.0013473143889129347, "dist_entropy": 0.8564806342124939, "actor_grad_norm": 0.13162504136562347, "critic_grad_norm": 0.05915484577417374, "ratio": 0.9999244809150696, "entropy": 0.8564806342124939, "incre_win_rate": 0.7027027027027027, "step": 647}
{"time": 1767334167.4423072, "phase": "train", "update": 648, "total_env_steps": 2073600, "episode_reward": 0.2278735488653183, "value_loss": 0.00959168877452612, "policy_loss": -0.0013166018566117543, "dist_entropy": 0.8785580039024353, "actor_grad_norm": 0.10466625541448593, "critic_grad_norm": 0.06354893743991852, "ratio": 0.9998447299003601, "entropy": 0.8785580039024353, "incre_win_rate": 0.8918918918918919, "step": 648}
{"time": 1767334171.5150456, "phase": "train", "update": 649, "total_env_steps": 2076800, "episode_reward": 0.21625050902366638, "value_loss": 0.013081235252320767, "policy_loss": -0.0013755388398784874, "dist_entropy": 0.8615818500518799, "actor_grad_norm": 0.10892899334430695, "critic_grad_norm": 0.13111865520477295, "ratio": 1.000009536743164, "entropy": 0.8615818500518799, "incre_win_rate": 0.75, "step": 649}
{"time": 1767334175.5726326, "phase": "train", "update": 650, "total_env_steps": 2080000, "episode_reward": 0.20965799689292908, "value_loss": 0.014751138910651208, "policy_loss": -0.0011307354058697427, "dist_entropy": 0.8759629487991333, "actor_grad_norm": 0.09522642940282822, "critic_grad_norm": 0.13260476291179657, "ratio": 0.9997166991233826, "entropy": 0.8759629487991333, "incre_win_rate": 0.7435897435897436, "step": 650}
{"time": 1767334179.6666944, "phase": "train", "update": 651, "total_env_steps": 2083200, "episode_reward": 0.20193657279014587, "value_loss": 0.025935221835970877, "policy_loss": -0.0018488657214206228, "dist_entropy": 0.8899098992347717, "actor_grad_norm": 0.0971248671412468, "critic_grad_norm": 0.11394491046667099, "ratio": 1.0003389120101929, "entropy": 0.8899098992347717, "incre_win_rate": 0.7222222222222222, "step": 651}
{"time": 1767334191.2314725, "phase": "eval", "update": 651, "total_env_steps": 2083200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.602079884105958, "step": 651}
{"time": 1767334195.290941, "phase": "train", "update": 652, "total_env_steps": 2086400, "episode_reward": 0.2126360684633255, "value_loss": 0.016646578907966614, "policy_loss": -0.0011509067565583565, "dist_entropy": 0.8947559356689453, "actor_grad_norm": 0.09125911444425583, "critic_grad_norm": 0.13261263072490692, "ratio": 1.0004247426986694, "entropy": 0.8947559356689453, "incre_win_rate": 0.8235294117647058, "step": 652}
{"time": 1767334199.3860443, "phase": "train", "update": 653, "total_env_steps": 2089600, "episode_reward": 0.21693295240402222, "value_loss": 0.011800410784780979, "policy_loss": -0.0012483012211667698, "dist_entropy": 0.8981207251548767, "actor_grad_norm": 0.08626922219991684, "critic_grad_norm": 0.1181064173579216, "ratio": 1.0002375841140747, "entropy": 0.8981207251548767, "incre_win_rate": 0.8055555555555556, "step": 653}
{"time": 1767334232.8375647, "phase": "train", "update": 654, "total_env_steps": 2092800, "episode_reward": 0.20072588324546814, "value_loss": 0.1032489463686943, "policy_loss": -0.0013457988757508588, "dist_entropy": 0.8822044968605042, "actor_grad_norm": 0.13110192120075226, "critic_grad_norm": 0.4348083436489105, "ratio": 0.9998390078544617, "entropy": 0.8822044968605042, "incre_win_rate": 0.7647058823529411, "step": 654}
{"time": 1767334236.912908, "phase": "train", "update": 655, "total_env_steps": 2096000, "episode_reward": 0.2190800905227661, "value_loss": 0.015098639391362667, "policy_loss": -0.001168790553481358, "dist_entropy": 0.9098003745079041, "actor_grad_norm": 0.08485396951436996, "critic_grad_norm": 0.27597078680992126, "ratio": 1.0001167058944702, "entropy": 0.9098003745079041, "incre_win_rate": 0.8108108108108109, "step": 655}
{"time": 1767334241.01197, "phase": "train", "update": 656, "total_env_steps": 2099200, "episode_reward": 0.22441381216049194, "value_loss": 0.014217621646821499, "policy_loss": -0.001155256828618434, "dist_entropy": 0.9114988088607788, "actor_grad_norm": 0.10501686483621597, "critic_grad_norm": 0.21128427982330322, "ratio": 0.999687671661377, "entropy": 0.9114988088607788, "incre_win_rate": 0.7894736842105263, "step": 656}
{"time": 1767334245.0609684, "phase": "train", "update": 657, "total_env_steps": 2102400, "episode_reward": 0.21391557157039642, "value_loss": 0.013400453515350819, "policy_loss": -0.0009851049308831961, "dist_entropy": 0.8949414134025574, "actor_grad_norm": 0.10148363560438156, "critic_grad_norm": 0.14963801205158234, "ratio": 1.00014328956604, "entropy": 0.8949414134025574, "incre_win_rate": 0.7631578947368421, "step": 657}
{"time": 1767334249.1029093, "phase": "train", "update": 658, "total_env_steps": 2105600, "episode_reward": 0.19229821860790253, "value_loss": 0.03097965642809868, "policy_loss": -0.0011018542011186129, "dist_entropy": 0.8871636271476746, "actor_grad_norm": 0.11374039947986603, "critic_grad_norm": 0.2758142352104187, "ratio": 1.0000736713409424, "entropy": 0.8871636271476746, "incre_win_rate": 0.5714285714285714, "step": 658}
{"time": 1767334253.1536689, "phase": "train", "update": 659, "total_env_steps": 2108800, "episode_reward": 0.21353735029697418, "value_loss": 0.02569049708545208, "policy_loss": -0.0008585038997928507, "dist_entropy": 0.9018450975418091, "actor_grad_norm": 0.07798408716917038, "critic_grad_norm": 0.15172238647937775, "ratio": 0.9995678067207336, "entropy": 0.9018450975418091, "incre_win_rate": 0.7631578947368421, "step": 659}
{"time": 1767334257.217268, "phase": "train", "update": 660, "total_env_steps": 2112000, "episode_reward": 0.20975321531295776, "value_loss": 0.015142304264009, "policy_loss": -0.0011372256937182356, "dist_entropy": 0.8973711252212524, "actor_grad_norm": 0.10512904077768326, "critic_grad_norm": 0.11437548696994781, "ratio": 0.999808132648468, "entropy": 0.8973711252212524, "incre_win_rate": 0.6944444444444444, "step": 660}
{"time": 1767334261.2967973, "phase": "train", "update": 661, "total_env_steps": 2115200, "episode_reward": 0.20988929271697998, "value_loss": 0.017423174157738686, "policy_loss": -0.001425270283374047, "dist_entropy": 0.9068231582641602, "actor_grad_norm": 0.10741674900054932, "critic_grad_norm": 0.08655785769224167, "ratio": 0.9998360872268677, "entropy": 0.9068231582641602, "incre_win_rate": 0.6486486486486487, "step": 661}
{"time": 1767334265.3513064, "phase": "train", "update": 662, "total_env_steps": 2118400, "episode_reward": 0.21327504515647888, "value_loss": 0.016268030181527136, "policy_loss": -0.0014265033136673822, "dist_entropy": 0.9038946866989136, "actor_grad_norm": 0.17331354320049286, "critic_grad_norm": 0.05296693369746208, "ratio": 0.99983149766922, "entropy": 0.9038946866989136, "incre_win_rate": 0.7027027027027027, "step": 662}
{"time": 1767334269.4077594, "phase": "train", "update": 663, "total_env_steps": 2121600, "episode_reward": 0.21040406823158264, "value_loss": 0.01323751825839281, "policy_loss": -0.0013828210699820432, "dist_entropy": 0.8733128547668457, "actor_grad_norm": 0.08853417634963989, "critic_grad_norm": 0.06346134096384048, "ratio": 1.0001262426376343, "entropy": 0.8733128547668457, "incre_win_rate": 0.7567567567567568, "step": 663}
{"time": 1767334273.47709, "phase": "train", "update": 664, "total_env_steps": 2124800, "episode_reward": 0.22723975777626038, "value_loss": 0.01303231567144394, "policy_loss": -0.0013044894549977925, "dist_entropy": 0.8638270974159241, "actor_grad_norm": 0.12009070068597794, "critic_grad_norm": 0.08058806508779526, "ratio": 1.0001211166381836, "entropy": 0.8638270974159241, "incre_win_rate": 0.7948717948717948, "step": 664}
{"time": 1767334277.554404, "phase": "train", "update": 665, "total_env_steps": 2128000, "episode_reward": 0.22588680684566498, "value_loss": 0.010481312498450279, "policy_loss": -0.001096386277002992, "dist_entropy": 0.8818497776985168, "actor_grad_norm": 0.11176703125238419, "critic_grad_norm": 0.036981046199798584, "ratio": 1.00058913230896, "entropy": 0.8818497776985168, "incre_win_rate": 0.8888888888888888, "step": 665}
{"time": 1767334281.6105564, "phase": "train", "update": 666, "total_env_steps": 2131200, "episode_reward": 0.21250413358211517, "value_loss": 0.02477690577507019, "policy_loss": -0.0010674161213319877, "dist_entropy": 0.8635683298110962, "actor_grad_norm": 0.17174354195594788, "critic_grad_norm": 0.1930961012840271, "ratio": 1.0000488758087158, "entropy": 0.8635683298110962, "incre_win_rate": 0.8378378378378378, "step": 666}
{"time": 1767334285.664517, "phase": "train", "update": 667, "total_env_steps": 2134400, "episode_reward": 0.22707471251487732, "value_loss": 0.01199599951505661, "policy_loss": -0.0010096043014677035, "dist_entropy": 0.8747124195098877, "actor_grad_norm": 0.09185720980167389, "critic_grad_norm": 0.08759334683418274, "ratio": 1.000004529953003, "entropy": 0.8747124195098877, "incre_win_rate": 0.7692307692307693, "step": 667}
{"time": 1767334289.732398, "phase": "train", "update": 668, "total_env_steps": 2137600, "episode_reward": 0.22116619348526, "value_loss": 0.016585580818355084, "policy_loss": -0.0010425425175778712, "dist_entropy": 0.8601727247238159, "actor_grad_norm": 0.1045231968164444, "critic_grad_norm": 0.06002488359808922, "ratio": 1.000400424003601, "entropy": 0.8601727247238159, "incre_win_rate": 0.7297297297297297, "step": 668}
{"time": 1767334293.8063948, "phase": "train", "update": 669, "total_env_steps": 2140800, "episode_reward": 0.2282155454158783, "value_loss": 0.016773365065455438, "policy_loss": -0.0011965122909892046, "dist_entropy": 0.8598192214965821, "actor_grad_norm": 0.09783939272165298, "critic_grad_norm": 0.05758213996887207, "ratio": 0.9998826384544373, "entropy": 0.8598192214965821, "incre_win_rate": 0.85, "step": 669}
{"time": 1767334297.8376489, "phase": "train", "update": 670, "total_env_steps": 2144000, "episode_reward": 0.20912200212478638, "value_loss": 0.017683250829577446, "policy_loss": -0.0018009285430435895, "dist_entropy": 0.8381249785423279, "actor_grad_norm": 0.13014227151870728, "critic_grad_norm": 0.05164360627532005, "ratio": 0.9999680519104004, "entropy": 0.8381249785423279, "incre_win_rate": 0.6052631578947368, "step": 670}
{"time": 1767334301.9341526, "phase": "train", "update": 671, "total_env_steps": 2147200, "episode_reward": 0.2281394898891449, "value_loss": 0.012033861875534058, "policy_loss": -0.0013289341504014729, "dist_entropy": 0.8483510851860047, "actor_grad_norm": 0.09001852571964264, "critic_grad_norm": 0.04596447944641113, "ratio": 1.000308871269226, "entropy": 0.8483510851860047, "incre_win_rate": 0.8, "step": 671}
{"time": 1767334306.0203936, "phase": "train", "update": 672, "total_env_steps": 2150400, "episode_reward": 0.22889485955238342, "value_loss": 0.012862747721374034, "policy_loss": -0.0012715892914805238, "dist_entropy": 0.8481048941612244, "actor_grad_norm": 0.12153513729572296, "critic_grad_norm": 0.06235795095562935, "ratio": 1.0000170469284058, "entropy": 0.8481048941612244, "incre_win_rate": 0.8157894736842105, "step": 672}
{"time": 1767334310.0554395, "phase": "train", "update": 673, "total_env_steps": 2153600, "episode_reward": 0.2164202183485031, "value_loss": 0.013634330406785012, "policy_loss": -0.0011962836327185755, "dist_entropy": 0.8443474531173706, "actor_grad_norm": 0.13242585957050323, "critic_grad_norm": 0.06096489354968071, "ratio": 0.999829888343811, "entropy": 0.8443474531173706, "incre_win_rate": 0.7837837837837838, "step": 673}
{"time": 1767334314.110455, "phase": "train", "update": 674, "total_env_steps": 2156800, "episode_reward": 0.2233133316040039, "value_loss": 0.011274073272943497, "policy_loss": -0.0012075138119019614, "dist_entropy": 0.8594139695167542, "actor_grad_norm": 0.13365299999713898, "critic_grad_norm": 0.055355072021484375, "ratio": 1.0003037452697754, "entropy": 0.8594139695167542, "incre_win_rate": 0.8378378378378378, "step": 674}
{"time": 1767334318.1550815, "phase": "train", "update": 675, "total_env_steps": 2160000, "episode_reward": 0.21195052564144135, "value_loss": 0.010128197632730008, "policy_loss": -0.0013829359616913451, "dist_entropy": 0.847760796546936, "actor_grad_norm": 0.1385551542043686, "critic_grad_norm": 0.03778892382979393, "ratio": 0.9999467730522156, "entropy": 0.847760796546936, "incre_win_rate": 0.8333333333333334, "step": 675}
{"time": 1767334322.2276323, "phase": "train", "update": 676, "total_env_steps": 2163200, "episode_reward": 0.21292218565940857, "value_loss": 0.012939164228737355, "policy_loss": -0.0006583562531027098, "dist_entropy": 0.8747683882713317, "actor_grad_norm": 0.1264229416847229, "critic_grad_norm": 0.054373014718294144, "ratio": 1.0004037618637085, "entropy": 0.8747683882713317, "incre_win_rate": 0.7105263157894737, "step": 676}
{"time": 1767334333.2819161, "phase": "eval", "update": 676, "total_env_steps": 2163200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.89528145695364, "step": 676}
{"time": 1767334337.3168755, "phase": "train", "update": 677, "total_env_steps": 2166400, "episode_reward": 0.21761539578437805, "value_loss": 0.013991244696080684, "policy_loss": -0.001205503526724172, "dist_entropy": 0.8561107993125916, "actor_grad_norm": 0.1036333367228508, "critic_grad_norm": 0.06943734735250473, "ratio": 0.9998313784599304, "entropy": 0.8561107993125916, "incre_win_rate": 0.7837837837837838, "step": 677}
{"time": 1767334341.351977, "phase": "train", "update": 678, "total_env_steps": 2169600, "episode_reward": 0.19923686981201172, "value_loss": 0.023898236081004144, "policy_loss": -0.001016767954448028, "dist_entropy": 0.8793696641921998, "actor_grad_norm": 0.08267921209335327, "critic_grad_norm": 0.13662070035934448, "ratio": 1.0001856088638306, "entropy": 0.8793696641921998, "incre_win_rate": 0.6388888888888888, "step": 678}
{"time": 1767334345.3540258, "phase": "train", "update": 679, "total_env_steps": 2172800, "episode_reward": 0.21669960021972656, "value_loss": 0.018140433728694914, "policy_loss": -0.0015548470863006258, "dist_entropy": 0.8745453000068665, "actor_grad_norm": 0.1424691379070282, "critic_grad_norm": 0.12088221311569214, "ratio": 0.9999884963035583, "entropy": 0.8745453000068665, "incre_win_rate": 0.8, "step": 679}
{"time": 1767334349.3985038, "phase": "train", "update": 680, "total_env_steps": 2176000, "episode_reward": 0.21710315346717834, "value_loss": 0.015462284348905087, "policy_loss": -0.0012161317558494033, "dist_entropy": 0.8705039858818054, "actor_grad_norm": 0.10629111528396606, "critic_grad_norm": 0.07347255945205688, "ratio": 1.0000945329666138, "entropy": 0.8705039858818054, "incre_win_rate": 0.7631578947368421, "step": 680}
{"time": 1767334353.4748082, "phase": "train", "update": 681, "total_env_steps": 2179200, "episode_reward": 0.21815863251686096, "value_loss": 0.013087781518697739, "policy_loss": -0.0011260684608046744, "dist_entropy": 0.8657903552055359, "actor_grad_norm": 0.11543510109186172, "critic_grad_norm": 0.04539396986365318, "ratio": 1.000108003616333, "entropy": 0.8657903552055359, "incre_win_rate": 0.8205128205128205, "step": 681}
{"time": 1767334357.5249798, "phase": "train", "update": 682, "total_env_steps": 2182400, "episode_reward": 0.21533113718032837, "value_loss": 0.01687518022954464, "policy_loss": -0.001761374272033045, "dist_entropy": 0.8842106819152832, "actor_grad_norm": 0.15628103911876678, "critic_grad_norm": 0.059109706431627274, "ratio": 1.0002012252807617, "entropy": 0.8842106819152832, "incre_win_rate": 0.7142857142857143, "step": 682}
{"time": 1767334361.5956411, "phase": "train", "update": 683, "total_env_steps": 2185600, "episode_reward": 0.21293771266937256, "value_loss": 0.01463462933897972, "policy_loss": -0.0011880772002221818, "dist_entropy": 0.8577880859375, "actor_grad_norm": 0.09772119671106339, "critic_grad_norm": 0.04282427579164505, "ratio": 0.9999014139175415, "entropy": 0.8577880859375, "incre_win_rate": 0.7435897435897436, "step": 683}
{"time": 1767334365.632225, "phase": "train", "update": 684, "total_env_steps": 2188800, "episode_reward": 0.20823675394058228, "value_loss": 0.014983649551868438, "policy_loss": -0.0015138808337393783, "dist_entropy": 0.8764777660369873, "actor_grad_norm": 0.13478223979473114, "critic_grad_norm": 0.050249554216861725, "ratio": 0.9998902678489685, "entropy": 0.8764777660369873, "incre_win_rate": 0.7222222222222222, "step": 684}
{"time": 1767334369.6668615, "phase": "train", "update": 685, "total_env_steps": 2192000, "episode_reward": 0.20972424745559692, "value_loss": 0.01464492604136467, "policy_loss": -0.001035272644367069, "dist_entropy": 0.8670822739601135, "actor_grad_norm": 0.09227251261472702, "critic_grad_norm": 0.08516018837690353, "ratio": 0.9994630813598633, "entropy": 0.8670822739601135, "incre_win_rate": 0.7567567567567568, "step": 685}
{"time": 1767334373.7002814, "phase": "train", "update": 686, "total_env_steps": 2195200, "episode_reward": 0.21671617031097412, "value_loss": 0.012183652445673942, "policy_loss": -0.0012464365364259322, "dist_entropy": 0.8697336912155151, "actor_grad_norm": 0.10116197913885117, "critic_grad_norm": 0.05442289263010025, "ratio": 0.9995384216308594, "entropy": 0.8697336912155151, "incre_win_rate": 0.8055555555555556, "step": 686}
{"time": 1767334377.7886145, "phase": "train", "update": 687, "total_env_steps": 2198400, "episode_reward": 0.2288617342710495, "value_loss": 0.00794580914080143, "policy_loss": -0.001318032627231247, "dist_entropy": 0.8719574093818665, "actor_grad_norm": 0.09693524986505508, "critic_grad_norm": 0.05925768241286278, "ratio": 0.9999157786369324, "entropy": 0.8719574093818665, "incre_win_rate": 0.8157894736842105, "step": 687}
{"time": 1767334381.8652418, "phase": "train", "update": 688, "total_env_steps": 2201600, "episode_reward": 0.20702867209911346, "value_loss": 0.01284870933741331, "policy_loss": -0.0010723582355943507, "dist_entropy": 0.8682641506195068, "actor_grad_norm": 0.10982759296894073, "critic_grad_norm": 0.12137836217880249, "ratio": 0.9994811415672302, "entropy": 0.8682641506195068, "incre_win_rate": 0.7567567567567568, "step": 688}
{"time": 1767334385.876717, "phase": "train", "update": 689, "total_env_steps": 2204800, "episode_reward": 0.2125522792339325, "value_loss": 0.01112600564956665, "policy_loss": -0.001509650766701043, "dist_entropy": 0.8797971606254578, "actor_grad_norm": 0.13540057837963104, "critic_grad_norm": 0.05356321483850479, "ratio": 0.9998351335525513, "entropy": 0.8797971606254578, "incre_win_rate": 0.7777777777777778, "step": 689}
{"time": 1767334389.9563098, "phase": "train", "update": 690, "total_env_steps": 2208000, "episode_reward": 0.21939879655838013, "value_loss": 0.011826449260115623, "policy_loss": -0.0009404636936629629, "dist_entropy": 0.8842228174209594, "actor_grad_norm": 0.1764453947544098, "critic_grad_norm": 0.06783632189035416, "ratio": 0.9997215270996094, "entropy": 0.8842228174209594, "incre_win_rate": 0.8055555555555556, "step": 690}
{"time": 1767334394.015186, "phase": "train", "update": 691, "total_env_steps": 2211200, "episode_reward": 0.21707263588905334, "value_loss": 0.010068511217832565, "policy_loss": -0.0012553371022121951, "dist_entropy": 0.8952117919921875, "actor_grad_norm": 0.11024986952543259, "critic_grad_norm": 0.04916150122880936, "ratio": 0.9996952414512634, "entropy": 0.8952117919921875, "incre_win_rate": 0.8108108108108109, "step": 691}
{"time": 1767334398.0366392, "phase": "train", "update": 692, "total_env_steps": 2214400, "episode_reward": 0.2021331787109375, "value_loss": 0.009468462504446506, "policy_loss": -0.0016815142667571336, "dist_entropy": 0.899565601348877, "actor_grad_norm": 0.11891498416662216, "critic_grad_norm": 0.0718591958284378, "ratio": 1.000051736831665, "entropy": 0.899565601348877, "incre_win_rate": 0.7352941176470589, "step": 692}
{"time": 1767334402.1347082, "phase": "train", "update": 693, "total_env_steps": 2217600, "episode_reward": 0.2301691770553589, "value_loss": 0.009755207225680351, "policy_loss": -0.0010711925479792938, "dist_entropy": 0.8841552972793579, "actor_grad_norm": 0.08360495418310165, "critic_grad_norm": 0.05467377230525017, "ratio": 0.9997957348823547, "entropy": 0.8841552972793579, "incre_win_rate": 0.8461538461538461, "step": 693}
{"time": 1767334406.2160192, "phase": "train", "update": 694, "total_env_steps": 2220800, "episode_reward": 0.22521059215068817, "value_loss": 0.011465392820537091, "policy_loss": -0.0015898026138799538, "dist_entropy": 0.8687371134757995, "actor_grad_norm": 0.11658580601215363, "critic_grad_norm": 0.05878331884741783, "ratio": 1.0000990629196167, "entropy": 0.8687371134757995, "incre_win_rate": 0.75, "step": 694}
{"time": 1767334410.2916436, "phase": "train", "update": 695, "total_env_steps": 2224000, "episode_reward": 0.22472164034843445, "value_loss": 0.01243321169167757, "policy_loss": -0.0011452483816213998, "dist_entropy": 0.8486502528190613, "actor_grad_norm": 0.09949646145105362, "critic_grad_norm": 0.05023114010691643, "ratio": 0.9998956918716431, "entropy": 0.8486502528190613, "incre_win_rate": 0.8, "step": 695}
{"time": 1767334414.3732386, "phase": "train", "update": 696, "total_env_steps": 2227200, "episode_reward": 0.2262427657842636, "value_loss": 0.015022576786577702, "policy_loss": -0.0013413226559134018, "dist_entropy": 0.8604713559150696, "actor_grad_norm": 0.14281868934631348, "critic_grad_norm": 0.0539795458316803, "ratio": 1.0000660419464111, "entropy": 0.8604713559150696, "incre_win_rate": 0.75, "step": 696}
{"time": 1767334418.4329739, "phase": "train", "update": 697, "total_env_steps": 2230400, "episode_reward": 0.2263876348733902, "value_loss": 0.01237067934125662, "policy_loss": -0.0012518701513670294, "dist_entropy": 0.8401173949241638, "actor_grad_norm": 0.1275237798690796, "critic_grad_norm": 0.05773378163576126, "ratio": 0.9996883273124695, "entropy": 0.8401173949241638, "incre_win_rate": 0.8205128205128205, "step": 697}
{"time": 1767334422.5341907, "phase": "train", "update": 698, "total_env_steps": 2233600, "episode_reward": 0.239155113697052, "value_loss": 0.009771684184670448, "policy_loss": -0.001359272467421846, "dist_entropy": 0.8449273824691772, "actor_grad_norm": 0.10267259180545807, "critic_grad_norm": 0.06124584749341011, "ratio": 0.9999334216117859, "entropy": 0.8449273824691772, "incre_win_rate": 0.972972972972973, "step": 698}
{"time": 1767334426.5747883, "phase": "train", "update": 699, "total_env_steps": 2236800, "episode_reward": 0.21678704023361206, "value_loss": 0.011806618049740791, "policy_loss": -0.001155399591621986, "dist_entropy": 0.8166892051696777, "actor_grad_norm": 0.10384237766265869, "critic_grad_norm": 0.0819336473941803, "ratio": 1.0002020597457886, "entropy": 0.8166892051696777, "incre_win_rate": 0.6923076923076923, "step": 699}
{"time": 1767334430.6332278, "phase": "train", "update": 700, "total_env_steps": 2240000, "episode_reward": 0.21758121252059937, "value_loss": 0.010456780530512333, "policy_loss": -0.0009565846026486468, "dist_entropy": 0.8107686161994934, "actor_grad_norm": 0.10890372097492218, "critic_grad_norm": 0.054736316204071045, "ratio": 0.999516487121582, "entropy": 0.8107686161994934, "incre_win_rate": 0.6578947368421053, "step": 700}
{"time": 1767334434.6654878, "phase": "train", "update": 701, "total_env_steps": 2243200, "episode_reward": 0.2266835719347, "value_loss": 0.01383579932153225, "policy_loss": -0.0011494590618738698, "dist_entropy": 0.795875895023346, "actor_grad_norm": 0.11598793417215347, "critic_grad_norm": 0.06919438391923904, "ratio": 1.0001534223556519, "entropy": 0.795875895023346, "incre_win_rate": 0.8461538461538461, "step": 701}
{"time": 1767334445.3657675, "phase": "eval", "update": 701, "total_env_steps": 2243200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.893418874172184, "step": 701}
{"time": 1767334449.7968144, "phase": "train", "update": 702, "total_env_steps": 2246400, "episode_reward": 0.22918666899204254, "value_loss": 0.012034141644835471, "policy_loss": -0.0011141061434813081, "dist_entropy": 0.833221161365509, "actor_grad_norm": 0.12585905194282532, "critic_grad_norm": 0.0487370565533638, "ratio": 1.000239372253418, "entropy": 0.833221161365509, "incre_win_rate": 0.8378378378378378, "step": 702}
{"time": 1767334454.0807593, "phase": "train", "update": 703, "total_env_steps": 2249600, "episode_reward": 0.21725372970104218, "value_loss": 0.01757034324109554, "policy_loss": -0.001140971722261952, "dist_entropy": 0.8152924418449402, "actor_grad_norm": 0.12899957597255707, "critic_grad_norm": 0.040248967707157135, "ratio": 1.0000661611557007, "entropy": 0.8152924418449402, "incre_win_rate": 0.6842105263157895, "step": 703}
{"time": 1767334458.1962316, "phase": "train", "update": 704, "total_env_steps": 2252800, "episode_reward": 0.22781871259212494, "value_loss": 0.011589857004582881, "policy_loss": -0.000875684832165291, "dist_entropy": 0.8276441812515258, "actor_grad_norm": 0.12441220134496689, "critic_grad_norm": 0.05070297047495842, "ratio": 0.9997169375419617, "entropy": 0.8276441812515258, "incre_win_rate": 0.8461538461538461, "step": 704}
{"time": 1767334462.268249, "phase": "train", "update": 705, "total_env_steps": 2256000, "episode_reward": 0.22590801119804382, "value_loss": 0.014088339731097221, "policy_loss": -0.0010375410119980444, "dist_entropy": 0.8290515899658203, "actor_grad_norm": 0.11534736305475235, "critic_grad_norm": 0.036579545587301254, "ratio": 1.0001312494277954, "entropy": 0.8290515899658203, "incre_win_rate": 0.75, "step": 705}
{"time": 1767334466.2749505, "phase": "train", "update": 706, "total_env_steps": 2259200, "episode_reward": 0.2196771651506424, "value_loss": 0.014984348602592946, "policy_loss": -0.0008199505338339463, "dist_entropy": 0.8247868895530701, "actor_grad_norm": 0.12199723720550537, "critic_grad_norm": 0.09820329397916794, "ratio": 0.9998936653137207, "entropy": 0.8247868895530701, "incre_win_rate": 0.7631578947368421, "step": 706}
{"time": 1767334470.3627772, "phase": "train", "update": 707, "total_env_steps": 2262400, "episode_reward": 0.2301200032234192, "value_loss": 0.010782572627067565, "policy_loss": -0.0010084092550435742, "dist_entropy": 0.8363563060760498, "actor_grad_norm": 0.10329335182905197, "critic_grad_norm": 0.05104607343673706, "ratio": 1.0000708103179932, "entropy": 0.8363563060760498, "incre_win_rate": 0.8421052631578947, "step": 707}
{"time": 1767334474.410847, "phase": "train", "update": 708, "total_env_steps": 2265600, "episode_reward": 0.2197568267583847, "value_loss": 0.013423180766403675, "policy_loss": -0.0010082624288678232, "dist_entropy": 0.8113052725791932, "actor_grad_norm": 0.12065887451171875, "critic_grad_norm": 0.04791240766644478, "ratio": 1.0001957416534424, "entropy": 0.8113052725791932, "incre_win_rate": 0.7368421052631579, "step": 708}
{"time": 1767334478.4312563, "phase": "train", "update": 709, "total_env_steps": 2268800, "episode_reward": 0.23166805505752563, "value_loss": 0.010263440385460853, "policy_loss": -0.0011725147280500891, "dist_entropy": 0.8199981689453125, "actor_grad_norm": 0.09136687964200974, "critic_grad_norm": 0.0846036747097969, "ratio": 0.9999901056289673, "entropy": 0.8199981689453125, "incre_win_rate": 0.8947368421052632, "step": 709}
{"time": 1767334482.5136144, "phase": "train", "update": 710, "total_env_steps": 2272000, "episode_reward": 0.22052410244941711, "value_loss": 0.01314797978848219, "policy_loss": -0.0012751109697248352, "dist_entropy": 0.8215835094451904, "actor_grad_norm": 0.11947102844715118, "critic_grad_norm": 0.08047454804182053, "ratio": 0.9996523857116699, "entropy": 0.8215835094451904, "incre_win_rate": 0.8157894736842105, "step": 710}
{"time": 1767334486.5854537, "phase": "train", "update": 711, "total_env_steps": 2275200, "episode_reward": 0.2351153939962387, "value_loss": 0.011804052256047725, "policy_loss": -0.0011718615120038579, "dist_entropy": 0.8088037610054016, "actor_grad_norm": 0.13900454342365265, "critic_grad_norm": 0.0700262188911438, "ratio": 1.0002506971359253, "entropy": 0.8088037610054016, "incre_win_rate": 0.8292682926829268, "step": 711}
{"time": 1767334490.6733265, "phase": "train", "update": 712, "total_env_steps": 2278400, "episode_reward": 0.23964352905750275, "value_loss": 0.012513495236635207, "policy_loss": -0.0013009431672244887, "dist_entropy": 0.7926427006721497, "actor_grad_norm": 0.1638396829366684, "critic_grad_norm": 0.060621827840805054, "ratio": 0.9998185038566589, "entropy": 0.7926427006721497, "incre_win_rate": 0.8974358974358975, "step": 712}
{"time": 1767334494.7303083, "phase": "train", "update": 713, "total_env_steps": 2281600, "episode_reward": 0.2239362746477127, "value_loss": 0.024186105653643607, "policy_loss": -0.0011240741441991275, "dist_entropy": 0.8113975405693055, "actor_grad_norm": 0.10423383861780167, "critic_grad_norm": 0.10480672121047974, "ratio": 1.0001221895217896, "entropy": 0.8113975405693055, "incre_win_rate": 0.7948717948717948, "step": 713}
{"time": 1767334498.7998333, "phase": "train", "update": 714, "total_env_steps": 2284800, "episode_reward": 0.22077040374279022, "value_loss": 0.014962645992636681, "policy_loss": -0.0014002696659174418, "dist_entropy": 0.8189624190330506, "actor_grad_norm": 0.14594332873821259, "critic_grad_norm": 0.06261195242404938, "ratio": 0.9999314546585083, "entropy": 0.8189624190330506, "incre_win_rate": 0.7631578947368421, "step": 714}
{"time": 1767334502.880718, "phase": "train", "update": 715, "total_env_steps": 2288000, "episode_reward": 0.21740326285362244, "value_loss": 0.017137979343533515, "policy_loss": -0.0015193101076050653, "dist_entropy": 0.8131580710411072, "actor_grad_norm": 0.101392462849617, "critic_grad_norm": 0.07827342301607132, "ratio": 0.9996776580810547, "entropy": 0.8131580710411072, "incre_win_rate": 0.7368421052631579, "step": 715}
{"time": 1767334506.9236553, "phase": "train", "update": 716, "total_env_steps": 2291200, "episode_reward": 0.2345234900712967, "value_loss": 0.010324733890593052, "policy_loss": -0.0012596148868752265, "dist_entropy": 0.7801981568336487, "actor_grad_norm": 0.12504911422729492, "critic_grad_norm": 0.10917134582996368, "ratio": 0.9998241662979126, "entropy": 0.7801981568336487, "incre_win_rate": 0.918918918918919, "step": 716}
{"time": 1767334511.0775828, "phase": "train", "update": 717, "total_env_steps": 2294400, "episode_reward": 0.2402649074792862, "value_loss": 0.0070400327444076535, "policy_loss": -0.0012602631801819086, "dist_entropy": 0.8031602025032043, "actor_grad_norm": 0.11819728463888168, "critic_grad_norm": 0.08005302399396896, "ratio": 1.0000014305114746, "entropy": 0.8031602025032043, "incre_win_rate": 0.925, "step": 717}
{"time": 1767334515.1754248, "phase": "train", "update": 718, "total_env_steps": 2297600, "episode_reward": 0.23404905200004578, "value_loss": 0.00954930130392313, "policy_loss": -0.001145756845979662, "dist_entropy": 0.8045872569084167, "actor_grad_norm": 0.09569564461708069, "critic_grad_norm": 0.05303345248103142, "ratio": 0.9999416470527649, "entropy": 0.8045872569084167, "incre_win_rate": 0.8461538461538461, "step": 718}
{"time": 1767334519.2330792, "phase": "train", "update": 719, "total_env_steps": 2300800, "episode_reward": 0.2267259955406189, "value_loss": 0.013412871770560742, "policy_loss": -0.0010060127110850913, "dist_entropy": 0.8034970164299011, "actor_grad_norm": 0.08734413236379623, "critic_grad_norm": 0.11334413290023804, "ratio": 0.9997441172599792, "entropy": 0.8034970164299011, "incre_win_rate": 0.7894736842105263, "step": 719}
{"time": 1767334523.295976, "phase": "train", "update": 720, "total_env_steps": 2304000, "episode_reward": 0.2353518307209015, "value_loss": 0.011722126044332981, "policy_loss": -0.0012179436492658624, "dist_entropy": 0.7919796347618103, "actor_grad_norm": 0.14033348858356476, "critic_grad_norm": 0.07653672248125076, "ratio": 0.999817967414856, "entropy": 0.7919796347618103, "incre_win_rate": 0.8974358974358975, "step": 720}
{"time": 1767334527.30101, "phase": "train", "update": 721, "total_env_steps": 2307200, "episode_reward": 0.22807273268699646, "value_loss": 0.009271179884672165, "policy_loss": -0.0009495575767374476, "dist_entropy": 0.7977785229682922, "actor_grad_norm": 0.07580862939357758, "critic_grad_norm": 0.07483352720737457, "ratio": 0.9999198317527771, "entropy": 0.7977785229682922, "incre_win_rate": 0.875, "step": 721}
{"time": 1767334531.2638154, "phase": "train", "update": 722, "total_env_steps": 2310400, "episode_reward": 0.21865737438201904, "value_loss": 0.012098445743322372, "policy_loss": -0.001553348639884078, "dist_entropy": 0.7549019813537597, "actor_grad_norm": 0.12408196926116943, "critic_grad_norm": 0.08899243921041489, "ratio": 0.9996253252029419, "entropy": 0.7549019813537597, "incre_win_rate": 0.7777777777777778, "step": 722}
{"time": 1767334535.2757802, "phase": "train", "update": 723, "total_env_steps": 2313600, "episode_reward": 0.22109997272491455, "value_loss": 0.011077922955155372, "policy_loss": -0.0016557360022826373, "dist_entropy": 0.7932923913002015, "actor_grad_norm": 0.10536245256662369, "critic_grad_norm": 0.10557474941015244, "ratio": 0.999952495098114, "entropy": 0.7932923913002015, "incre_win_rate": 0.8108108108108109, "step": 723}
{"time": 1767334539.2912705, "phase": "train", "update": 724, "total_env_steps": 2316800, "episode_reward": 0.2276950478553772, "value_loss": 0.012244389764964581, "policy_loss": -0.0011411712159400621, "dist_entropy": 0.8078395247459411, "actor_grad_norm": 0.08621329069137573, "critic_grad_norm": 0.08232278376817703, "ratio": 1.000221610069275, "entropy": 0.8078395247459411, "incre_win_rate": 0.8648648648648649, "step": 724}
{"time": 1767334543.3721654, "phase": "train", "update": 725, "total_env_steps": 2320000, "episode_reward": 0.24319276213645935, "value_loss": 0.009393197856843472, "policy_loss": -0.0013151228918573566, "dist_entropy": 0.8190763711929321, "actor_grad_norm": 0.12930917739868164, "critic_grad_norm": 0.10597642511129379, "ratio": 1.0001554489135742, "entropy": 0.8190763711929321, "incre_win_rate": 0.9487179487179487, "step": 725}
{"time": 1767334547.451204, "phase": "train", "update": 726, "total_env_steps": 2323200, "episode_reward": 0.23401956260204315, "value_loss": 0.010557100921869279, "policy_loss": -0.0011906635358172935, "dist_entropy": 0.8134375095367432, "actor_grad_norm": 0.08846426010131836, "critic_grad_norm": 0.0600079670548439, "ratio": 1.000226378440857, "entropy": 0.8134375095367432, "incre_win_rate": 0.8947368421052632, "step": 726}
{"time": 1767334558.3859553, "phase": "eval", "update": 726, "total_env_steps": 2323200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.4739755794702, "step": 726}
{"time": 1767334562.464271, "phase": "train", "update": 727, "total_env_steps": 2326400, "episode_reward": 0.22629967331886292, "value_loss": 0.014100238867104053, "policy_loss": -0.0011812611061063905, "dist_entropy": 0.796263575553894, "actor_grad_norm": 0.15205931663513184, "critic_grad_norm": 0.06419777125120163, "ratio": 1.0002962350845337, "entropy": 0.796263575553894, "incre_win_rate": 0.8, "step": 727}
{"time": 1767334566.572333, "phase": "train", "update": 728, "total_env_steps": 2329600, "episode_reward": 0.2322806417942047, "value_loss": 0.010882370546460152, "policy_loss": -0.0012384200674418367, "dist_entropy": 0.782373046875, "actor_grad_norm": 0.09488996863365173, "critic_grad_norm": 0.03915560990571976, "ratio": 1.0001276731491089, "entropy": 0.782373046875, "incre_win_rate": 0.8717948717948718, "step": 728}
{"time": 1767334570.6942732, "phase": "train", "update": 729, "total_env_steps": 2332800, "episode_reward": 0.2323303073644638, "value_loss": 0.014733856730163097, "policy_loss": -0.001066530961931278, "dist_entropy": 0.7993426084518432, "actor_grad_norm": 0.1052851602435112, "critic_grad_norm": 0.10913874208927155, "ratio": 1.0001906156539917, "entropy": 0.7993426084518432, "incre_win_rate": 0.7692307692307693, "step": 729}
{"time": 1767334574.7936924, "phase": "train", "update": 730, "total_env_steps": 2336000, "episode_reward": 0.23207472264766693, "value_loss": 0.013288356177508832, "policy_loss": -0.00104978847389674, "dist_entropy": 0.8104054570198059, "actor_grad_norm": 0.10122082382440567, "critic_grad_norm": 0.07284893840551376, "ratio": 0.9998810887336731, "entropy": 0.8104054570198059, "incre_win_rate": 0.7948717948717948, "step": 730}
{"time": 1767334578.856751, "phase": "train", "update": 731, "total_env_steps": 2339200, "episode_reward": 0.2354842722415924, "value_loss": 0.010051672533154487, "policy_loss": -0.0010320653857512241, "dist_entropy": 0.8030820727348328, "actor_grad_norm": 0.10589343309402466, "critic_grad_norm": 0.036341384053230286, "ratio": 0.9999851584434509, "entropy": 0.8030820727348328, "incre_win_rate": 0.8918918918918919, "step": 731}
{"time": 1767334582.9336119, "phase": "train", "update": 732, "total_env_steps": 2342400, "episode_reward": 0.23873862624168396, "value_loss": 0.006502101663500071, "policy_loss": -0.001075980063704307, "dist_entropy": 0.8151447772979736, "actor_grad_norm": 0.10006598383188248, "critic_grad_norm": 0.09330492466688156, "ratio": 1.0002716779708862, "entropy": 0.8151447772979736, "incre_win_rate": 0.926829268292683, "step": 732}
{"time": 1767334587.018939, "phase": "train", "update": 733, "total_env_steps": 2345600, "episode_reward": 0.23308983445167542, "value_loss": 0.006805068720132113, "policy_loss": -0.001138633200898198, "dist_entropy": 0.824175238609314, "actor_grad_norm": 0.10519929230213165, "critic_grad_norm": 0.04303578659892082, "ratio": 1.0001988410949707, "entropy": 0.824175238609314, "incre_win_rate": 0.9230769230769231, "step": 733}
{"time": 1767334591.1220477, "phase": "train", "update": 734, "total_env_steps": 2348800, "episode_reward": 0.2331327646970749, "value_loss": 0.009680075198411941, "policy_loss": -0.0012351596625364892, "dist_entropy": 0.8352888941764831, "actor_grad_norm": 0.08991385251283646, "critic_grad_norm": 0.04608270525932312, "ratio": 0.9999530911445618, "entropy": 0.8352888941764831, "incre_win_rate": 0.8648648648648649, "step": 734}
{"time": 1767334595.1974216, "phase": "train", "update": 735, "total_env_steps": 2352000, "episode_reward": 0.2273447960615158, "value_loss": 0.007849535439163446, "policy_loss": -0.0011697954392870357, "dist_entropy": 0.8414209604263305, "actor_grad_norm": 0.11728794872760773, "critic_grad_norm": 0.03562706708908081, "ratio": 0.9997904896736145, "entropy": 0.8414209604263305, "incre_win_rate": 0.8717948717948718, "step": 735}
{"time": 1767334599.2516077, "phase": "train", "update": 736, "total_env_steps": 2355200, "episode_reward": 0.2292523980140686, "value_loss": 0.009221743047237396, "policy_loss": -0.0012700381366315128, "dist_entropy": 0.825508177280426, "actor_grad_norm": 0.08984740823507309, "critic_grad_norm": 0.057590316981077194, "ratio": 1.000278353691101, "entropy": 0.825508177280426, "incre_win_rate": 0.8421052631578947, "step": 736}
{"time": 1767334603.3695996, "phase": "train", "update": 737, "total_env_steps": 2358400, "episode_reward": 0.23903970420360565, "value_loss": 0.005225311871618033, "policy_loss": -0.0014244072246725637, "dist_entropy": 0.8449016451835633, "actor_grad_norm": 0.09627056121826172, "critic_grad_norm": 0.03376203402876854, "ratio": 0.9999241828918457, "entropy": 0.8449016451835633, "incre_win_rate": 0.9736842105263158, "step": 737}
{"time": 1767334607.4351072, "phase": "train", "update": 738, "total_env_steps": 2361600, "episode_reward": 0.24061258137226105, "value_loss": 0.006743822898715735, "policy_loss": -0.0012129279280835626, "dist_entropy": 0.8540421247482299, "actor_grad_norm": 0.14528892934322357, "critic_grad_norm": 0.030045494437217712, "ratio": 0.9998855590820312, "entropy": 0.8540421247482299, "incre_win_rate": 0.9487179487179487, "step": 738}
{"time": 1767334611.66925, "phase": "train", "update": 739, "total_env_steps": 2364800, "episode_reward": 0.22846855223178864, "value_loss": 0.006359295174479485, "policy_loss": -0.000982750338570071, "dist_entropy": 0.8482691407203674, "actor_grad_norm": 0.10498211532831192, "critic_grad_norm": 0.03175167366862297, "ratio": 0.999788761138916, "entropy": 0.8482691407203674, "incre_win_rate": 0.8918918918918919, "step": 739}
{"time": 1767334615.7421663, "phase": "train", "update": 740, "total_env_steps": 2368000, "episode_reward": 0.22894039750099182, "value_loss": 0.00729145910590887, "policy_loss": -0.0014827787167146056, "dist_entropy": 0.872878623008728, "actor_grad_norm": 0.14796873927116394, "critic_grad_norm": 0.02956477366387844, "ratio": 0.9998621940612793, "entropy": 0.872878623008728, "incre_win_rate": 0.8157894736842105, "step": 740}
{"time": 1767334619.7925622, "phase": "train", "update": 741, "total_env_steps": 2371200, "episode_reward": 0.22652630507946014, "value_loss": 0.0071612270548939705, "policy_loss": -0.0011641880631182212, "dist_entropy": 0.8532514691352844, "actor_grad_norm": 0.10651098936796188, "critic_grad_norm": 0.03712668642401695, "ratio": 0.9998723864555359, "entropy": 0.8532514691352844, "incre_win_rate": 0.9230769230769231, "step": 741}
{"time": 1767334623.897555, "phase": "train", "update": 742, "total_env_steps": 2374400, "episode_reward": 0.22666753828525543, "value_loss": 0.009796652756631375, "policy_loss": -0.001241098164224752, "dist_entropy": 0.8738495230674743, "actor_grad_norm": 0.08655858784914017, "critic_grad_norm": 0.042423296719789505, "ratio": 0.9997269511222839, "entropy": 0.8738495230674743, "incre_win_rate": 0.8611111111111112, "step": 742}
{"time": 1767334628.0013034, "phase": "train", "update": 743, "total_env_steps": 2377600, "episode_reward": 0.23370860517024994, "value_loss": 0.007306497544050217, "policy_loss": -0.0010138925892114515, "dist_entropy": 0.8373360991477966, "actor_grad_norm": 0.08269146084785461, "critic_grad_norm": 0.06331276148557663, "ratio": 1.0000709295272827, "entropy": 0.8373360991477966, "incre_win_rate": 0.9, "step": 743}
{"time": 1767334632.1560802, "phase": "train", "update": 744, "total_env_steps": 2380800, "episode_reward": 0.2379014939069748, "value_loss": 0.008968568034470081, "policy_loss": -0.0016249396332412402, "dist_entropy": 0.853137981891632, "actor_grad_norm": 0.10627488046884537, "critic_grad_norm": 0.04285215958952904, "ratio": 0.9997817873954773, "entropy": 0.853137981891632, "incre_win_rate": 0.8974358974358975, "step": 744}
{"time": 1767334636.2105901, "phase": "train", "update": 745, "total_env_steps": 2384000, "episode_reward": 0.2301076054573059, "value_loss": 0.006082776002585888, "policy_loss": -0.001817454416817199, "dist_entropy": 0.8642667293548584, "actor_grad_norm": 0.1105344295501709, "critic_grad_norm": 0.03340042382478714, "ratio": 1.0002498626708984, "entropy": 0.8642667293548584, "incre_win_rate": 0.8888888888888888, "step": 745}
{"time": 1767334640.2528734, "phase": "train", "update": 746, "total_env_steps": 2387200, "episode_reward": 0.2302597463130951, "value_loss": 0.006681906990706921, "policy_loss": -0.0013793236304951329, "dist_entropy": 0.8499539256095886, "actor_grad_norm": 0.1381111890077591, "critic_grad_norm": 0.02445269748568535, "ratio": 1.0000184774398804, "entropy": 0.8499539256095886, "incre_win_rate": 0.8947368421052632, "step": 746}
{"time": 1767334644.3395386, "phase": "train", "update": 747, "total_env_steps": 2390400, "episode_reward": 0.23058775067329407, "value_loss": 0.0175824549049139, "policy_loss": -0.0012315585545650265, "dist_entropy": 0.8596946716308593, "actor_grad_norm": 0.11055272817611694, "critic_grad_norm": 0.07211478054523468, "ratio": 1.0001453161239624, "entropy": 0.8596946716308593, "incre_win_rate": 0.8974358974358975, "step": 747}
{"time": 1767334648.4319406, "phase": "train", "update": 748, "total_env_steps": 2393600, "episode_reward": 0.21781975030899048, "value_loss": 0.014110294170677662, "policy_loss": -0.0012654081491305647, "dist_entropy": 0.880542254447937, "actor_grad_norm": 0.1565706878900528, "critic_grad_norm": 0.06811467558145523, "ratio": 0.9997861981391907, "entropy": 0.880542254447937, "incre_win_rate": 0.7837837837837838, "step": 748}
{"time": 1767334652.4998446, "phase": "train", "update": 749, "total_env_steps": 2396800, "episode_reward": 0.21348406374454498, "value_loss": 0.013696265593171119, "policy_loss": -0.0014784786787579661, "dist_entropy": 0.8896215200424195, "actor_grad_norm": 0.13612893223762512, "critic_grad_norm": 0.0524410605430603, "ratio": 1.0001789331436157, "entropy": 0.8896215200424195, "incre_win_rate": 0.717948717948718, "step": 749}
{"time": 1767334656.5970917, "phase": "train", "update": 750, "total_env_steps": 2400000, "episode_reward": 0.21722112596035004, "value_loss": 0.013587021082639695, "policy_loss": -0.0014738424489010526, "dist_entropy": 0.8973000407218933, "actor_grad_norm": 0.11855590343475342, "critic_grad_norm": 0.050229497253894806, "ratio": 1.0001730918884277, "entropy": 0.8973000407218933, "incre_win_rate": 0.7777777777777778, "step": 750}
{"time": 1767334660.6663015, "phase": "train", "update": 751, "total_env_steps": 2403200, "episode_reward": 0.22244206070899963, "value_loss": 0.01218509916216135, "policy_loss": -0.0016177787786610053, "dist_entropy": 0.8817272186279297, "actor_grad_norm": 0.12278993427753448, "critic_grad_norm": 0.047878723591566086, "ratio": 1.0004558563232422, "entropy": 0.8817272186279297, "incre_win_rate": 0.8055555555555556, "step": 751}
{"time": 1767334672.0856466, "phase": "eval", "update": 751, "total_env_steps": 2403200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.876655629139073, "step": 751}
{"time": 1767334676.1651363, "phase": "train", "update": 752, "total_env_steps": 2406400, "episode_reward": 0.222815603017807, "value_loss": 0.012741691246628762, "policy_loss": -0.001671932709783519, "dist_entropy": 0.8697778582572937, "actor_grad_norm": 0.09976328909397125, "critic_grad_norm": 0.047793854027986526, "ratio": 1.000030279159546, "entropy": 0.8697778582572937, "incre_win_rate": 0.8205128205128205, "step": 752}
{"time": 1767334680.2173543, "phase": "train", "update": 753, "total_env_steps": 2409600, "episode_reward": 0.2179408222436905, "value_loss": 0.01205109003931284, "policy_loss": -0.0010966225382283313, "dist_entropy": 0.873057734966278, "actor_grad_norm": 0.08844257891178131, "critic_grad_norm": 0.046703387051820755, "ratio": 0.9998875856399536, "entropy": 0.873057734966278, "incre_win_rate": 0.8055555555555556, "step": 753}
{"time": 1767334684.3491442, "phase": "train", "update": 754, "total_env_steps": 2412800, "episode_reward": 0.2346140444278717, "value_loss": 0.010059117153286935, "policy_loss": -0.0014812119751837828, "dist_entropy": 0.88318350315094, "actor_grad_norm": 0.09146352857351303, "critic_grad_norm": 0.11254885047674179, "ratio": 1.0002316236495972, "entropy": 0.88318350315094, "incre_win_rate": 0.8947368421052632, "step": 754}
{"time": 1767334688.3771284, "phase": "train", "update": 755, "total_env_steps": 2416000, "episode_reward": 0.20671409368515015, "value_loss": 0.01636652573943138, "policy_loss": -0.0012650982794909283, "dist_entropy": 0.8654197216033935, "actor_grad_norm": 0.09323815256357193, "critic_grad_norm": 0.08487962931394577, "ratio": 0.9998556971549988, "entropy": 0.8654197216033935, "incre_win_rate": 0.631578947368421, "step": 755}
{"time": 1767334692.5168629, "phase": "train", "update": 756, "total_env_steps": 2419200, "episode_reward": 0.2160787582397461, "value_loss": 0.010645974427461624, "policy_loss": -0.0017146525114156929, "dist_entropy": 0.9003435134887695, "actor_grad_norm": 0.12934564054012299, "critic_grad_norm": 0.06609233468770981, "ratio": 0.9999160170555115, "entropy": 0.9003435134887695, "incre_win_rate": 0.7631578947368421, "step": 756}
{"time": 1767334696.6026287, "phase": "train", "update": 757, "total_env_steps": 2422400, "episode_reward": 0.22643211483955383, "value_loss": 0.009435908123850822, "policy_loss": -0.001196317974948613, "dist_entropy": 0.9130900979042054, "actor_grad_norm": 0.10512863844633102, "critic_grad_norm": 0.057900410145521164, "ratio": 1.0001734495162964, "entropy": 0.9130900979042054, "incre_win_rate": 0.7777777777777778, "step": 757}
{"time": 1767334700.694505, "phase": "train", "update": 758, "total_env_steps": 2425600, "episode_reward": 0.23204006254673004, "value_loss": 0.009472852014005185, "policy_loss": -0.001655879705828056, "dist_entropy": 0.9076074719429016, "actor_grad_norm": 0.10237544029951096, "critic_grad_norm": 0.03501975163817406, "ratio": 1.000038743019104, "entropy": 0.9076074719429016, "incre_win_rate": 0.85, "step": 758}
{"time": 1767334704.7887015, "phase": "train", "update": 759, "total_env_steps": 2428800, "episode_reward": 0.23136642575263977, "value_loss": 0.008223232068121433, "policy_loss": -0.0013755183076085587, "dist_entropy": 0.9067212700843811, "actor_grad_norm": 0.10736086219549179, "critic_grad_norm": 0.0485665500164032, "ratio": 0.9997413754463196, "entropy": 0.9067212700843811, "incre_win_rate": 0.8421052631578947, "step": 759}
{"time": 1767334708.8238728, "phase": "train", "update": 760, "total_env_steps": 2432000, "episode_reward": 0.22211144864559174, "value_loss": 0.01344557125121355, "policy_loss": -0.0011617403914208069, "dist_entropy": 0.8958261489868165, "actor_grad_norm": 0.1024598628282547, "critic_grad_norm": 0.09702206403017044, "ratio": 1.0000675916671753, "entropy": 0.8958261489868165, "incre_win_rate": 0.7692307692307693, "step": 760}
{"time": 1767334712.9137614, "phase": "train", "update": 761, "total_env_steps": 2435200, "episode_reward": 0.22460108995437622, "value_loss": 0.011218632571399212, "policy_loss": -0.0015818555722944439, "dist_entropy": 0.8743611454963685, "actor_grad_norm": 0.09944430738687515, "critic_grad_norm": 0.04187709838151932, "ratio": 0.9996795058250427, "entropy": 0.8743611454963685, "incre_win_rate": 0.7837837837837838, "step": 761}
{"time": 1767334717.0214925, "phase": "train", "update": 762, "total_env_steps": 2438400, "episode_reward": 0.2323271930217743, "value_loss": 0.007932328805327415, "policy_loss": -0.0012973594525355736, "dist_entropy": 0.8917596578598023, "actor_grad_norm": 0.11032252758741379, "critic_grad_norm": 0.12163256853818893, "ratio": 0.9999818801879883, "entropy": 0.8917596578598023, "incre_win_rate": 0.8717948717948718, "step": 762}
{"time": 1767334721.1043308, "phase": "train", "update": 763, "total_env_steps": 2441600, "episode_reward": 0.23129655420780182, "value_loss": 0.012000624276697635, "policy_loss": -0.001646336550700056, "dist_entropy": 0.8668172836303711, "actor_grad_norm": 0.12140172719955444, "critic_grad_norm": 0.060801733285188675, "ratio": 1.0000534057617188, "entropy": 0.8668172836303711, "incre_win_rate": 0.7948717948717948, "step": 763}
{"time": 1767334725.2318778, "phase": "train", "update": 764, "total_env_steps": 2444800, "episode_reward": 0.23214665055274963, "value_loss": 0.008024770300835371, "policy_loss": -0.0009032213526921851, "dist_entropy": 0.8928386807441712, "actor_grad_norm": 0.10415979474782944, "critic_grad_norm": 0.03806762024760246, "ratio": 0.9999176859855652, "entropy": 0.8928386807441712, "incre_win_rate": 0.7948717948717948, "step": 764}
{"time": 1767334729.289626, "phase": "train", "update": 765, "total_env_steps": 2448000, "episode_reward": 0.22378259897232056, "value_loss": 0.011535710841417312, "policy_loss": -0.0013471567805105166, "dist_entropy": 0.8771644234657288, "actor_grad_norm": 0.09556284546852112, "critic_grad_norm": 0.1371835321187973, "ratio": 0.9996538162231445, "entropy": 0.8771644234657288, "incre_win_rate": 0.7837837837837838, "step": 765}
{"time": 1767334733.3464017, "phase": "train", "update": 766, "total_env_steps": 2451200, "episode_reward": 0.22707366943359375, "value_loss": 0.012530788406729698, "policy_loss": -0.0017321530704073496, "dist_entropy": 0.896779990196228, "actor_grad_norm": 0.11270218342542648, "critic_grad_norm": 0.07548736035823822, "ratio": 0.9999966621398926, "entropy": 0.896779990196228, "incre_win_rate": 0.8421052631578947, "step": 766}
{"time": 1767334737.433363, "phase": "train", "update": 767, "total_env_steps": 2454400, "episode_reward": 0.2286216765642166, "value_loss": 0.007679916825145483, "policy_loss": -0.0013013284992858588, "dist_entropy": 0.9116706252098083, "actor_grad_norm": 0.09126540273427963, "critic_grad_norm": 0.062423110008239746, "ratio": 0.9997877478599548, "entropy": 0.9116706252098083, "incre_win_rate": 0.8918918918918919, "step": 767}
{"time": 1767334741.5025153, "phase": "train", "update": 768, "total_env_steps": 2457600, "episode_reward": 0.2222909778356552, "value_loss": 0.010625482350587846, "policy_loss": -0.0013521787975996347, "dist_entropy": 0.8923518896102905, "actor_grad_norm": 0.10437092930078506, "critic_grad_norm": 0.061218567192554474, "ratio": 0.9994961023330688, "entropy": 0.8923518896102905, "incre_win_rate": 0.8461538461538461, "step": 768}
{"time": 1767334745.5825207, "phase": "train", "update": 769, "total_env_steps": 2460800, "episode_reward": 0.2344205230474472, "value_loss": 0.009542564675211907, "policy_loss": -0.0012814066621174903, "dist_entropy": 0.882097041606903, "actor_grad_norm": 0.09201712161302567, "critic_grad_norm": 0.07020837813615799, "ratio": 0.9999295473098755, "entropy": 0.882097041606903, "incre_win_rate": 0.8947368421052632, "step": 769}
{"time": 1767334749.726714, "phase": "train", "update": 770, "total_env_steps": 2464000, "episode_reward": 0.22569018602371216, "value_loss": 0.009351622685790062, "policy_loss": -0.0012359168720273317, "dist_entropy": 0.87213613986969, "actor_grad_norm": 0.10447113960981369, "critic_grad_norm": 0.11005984991788864, "ratio": 1.0001412630081177, "entropy": 0.87213613986969, "incre_win_rate": 0.775, "step": 770}
{"time": 1767334753.8543012, "phase": "train", "update": 771, "total_env_steps": 2467200, "episode_reward": 0.23343801498413086, "value_loss": 0.012471028231084346, "policy_loss": -0.001316098141695221, "dist_entropy": 0.9051852107048035, "actor_grad_norm": 0.14899007976055145, "critic_grad_norm": 0.09535776823759079, "ratio": 0.999898374080658, "entropy": 0.9051852107048035, "incre_win_rate": 0.868421052631579, "step": 771}
{"time": 1767334757.9143083, "phase": "train", "update": 772, "total_env_steps": 2470400, "episode_reward": 0.2288690060377121, "value_loss": 0.012888135947287082, "policy_loss": -0.0010931935332710197, "dist_entropy": 0.8981640696525574, "actor_grad_norm": 0.08540287613868713, "critic_grad_norm": 0.061894357204437256, "ratio": 1.0001682043075562, "entropy": 0.8981640696525574, "incre_win_rate": 0.8947368421052632, "step": 772}
{"time": 1767334761.990233, "phase": "train", "update": 773, "total_env_steps": 2473600, "episode_reward": 0.23021315038204193, "value_loss": 0.011584333330392837, "policy_loss": -0.0014211296254060812, "dist_entropy": 0.8894300937652588, "actor_grad_norm": 0.09010934084653854, "critic_grad_norm": 0.04747247323393822, "ratio": 0.9998084306716919, "entropy": 0.8894300937652588, "incre_win_rate": 0.8421052631578947, "step": 773}
{"time": 1767334766.0426972, "phase": "train", "update": 774, "total_env_steps": 2476800, "episode_reward": 0.2229563593864441, "value_loss": 0.00981158297508955, "policy_loss": -0.0014529041243065421, "dist_entropy": 0.8872737884521484, "actor_grad_norm": 0.09413649886846542, "critic_grad_norm": 0.0716278925538063, "ratio": 0.9999251365661621, "entropy": 0.8872737884521484, "incre_win_rate": 0.8157894736842105, "step": 774}
{"time": 1767334770.1605833, "phase": "train", "update": 775, "total_env_steps": 2480000, "episode_reward": 0.23452091217041016, "value_loss": 0.009398461133241654, "policy_loss": -0.001430081584154408, "dist_entropy": 0.886592960357666, "actor_grad_norm": 0.09051423519849777, "critic_grad_norm": 0.06093964725732803, "ratio": 1.000078797340393, "entropy": 0.886592960357666, "incre_win_rate": 0.8717948717948718, "step": 775}
{"time": 1767334774.2779577, "phase": "train", "update": 776, "total_env_steps": 2483200, "episode_reward": 0.2331550270318985, "value_loss": 0.007053220365196467, "policy_loss": -0.0010421426791708654, "dist_entropy": 0.8887069463729859, "actor_grad_norm": 0.09144275635480881, "critic_grad_norm": 0.02680685557425022, "ratio": 1.000150203704834, "entropy": 0.8887069463729859, "incre_win_rate": 0.8717948717948718, "step": 776}
{"time": 1767334785.752629, "phase": "eval", "update": 776, "total_env_steps": 2483200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.597061258278146, "step": 776}
{"time": 1767334789.82067, "phase": "train", "update": 777, "total_env_steps": 2486400, "episode_reward": 0.22065965831279755, "value_loss": 0.012231728434562683, "policy_loss": -0.0011222338510407325, "dist_entropy": 0.8779058337211609, "actor_grad_norm": 0.09622159600257874, "critic_grad_norm": 0.15046091377735138, "ratio": 1.0000221729278564, "entropy": 0.8779058337211609, "incre_win_rate": 0.717948717948718, "step": 777}
{"time": 1767334793.8947499, "phase": "train", "update": 778, "total_env_steps": 2489600, "episode_reward": 0.23335832357406616, "value_loss": 0.011069605313241481, "policy_loss": -0.0009389443719200585, "dist_entropy": 0.9077123761177063, "actor_grad_norm": 0.09033438563346863, "critic_grad_norm": 0.11073336750268936, "ratio": 0.9999275207519531, "entropy": 0.9077123761177063, "incre_win_rate": 0.8157894736842105, "step": 778}
{"time": 1767334797.9926891, "phase": "train", "update": 779, "total_env_steps": 2492800, "episode_reward": 0.23737996816635132, "value_loss": 0.008893956802785397, "policy_loss": -0.0014848031198127388, "dist_entropy": 0.8825279712677002, "actor_grad_norm": 0.14994695782661438, "critic_grad_norm": 0.08569607138633728, "ratio": 1.0000489950180054, "entropy": 0.8825279712677002, "incre_win_rate": 0.8974358974358975, "step": 779}
{"time": 1767334802.03577, "phase": "train", "update": 780, "total_env_steps": 2496000, "episode_reward": 0.22387313842773438, "value_loss": 0.00986027754843235, "policy_loss": -0.0012900735364070215, "dist_entropy": 0.8877522945404053, "actor_grad_norm": 0.15481871366500854, "critic_grad_norm": 0.05027400329709053, "ratio": 0.9999929666519165, "entropy": 0.8877522945404053, "incre_win_rate": 0.8108108108108109, "step": 780}
{"time": 1767334806.0892081, "phase": "train", "update": 781, "total_env_steps": 2499200, "episode_reward": 0.23106683790683746, "value_loss": 0.008689998649060726, "policy_loss": -0.0016664619647404066, "dist_entropy": 0.8860671401023865, "actor_grad_norm": 0.08965054899454117, "critic_grad_norm": 0.033485617488622665, "ratio": 1.0000301599502563, "entropy": 0.8860671401023865, "incre_win_rate": 0.8717948717948718, "step": 781}
{"time": 1767334810.1867487, "phase": "train", "update": 782, "total_env_steps": 2502400, "episode_reward": 0.22352804243564606, "value_loss": 0.011843642406165599, "policy_loss": -0.0014880677673750676, "dist_entropy": 0.8611722350120544, "actor_grad_norm": 0.08646100759506226, "critic_grad_norm": 0.056222882121801376, "ratio": 0.999963104724884, "entropy": 0.8611722350120544, "incre_win_rate": 0.775, "step": 782}
{"time": 1767334814.2577307, "phase": "train", "update": 783, "total_env_steps": 2505600, "episode_reward": 0.22403766214847565, "value_loss": 0.008679580874741077, "policy_loss": -0.0013384837890171753, "dist_entropy": 0.8615539073944092, "actor_grad_norm": 0.10061488300561905, "critic_grad_norm": 0.033204492181539536, "ratio": 0.9998793005943298, "entropy": 0.8615539073944092, "incre_win_rate": 0.8108108108108109, "step": 783}
{"time": 1767334818.332296, "phase": "train", "update": 784, "total_env_steps": 2508800, "episode_reward": 0.2348996102809906, "value_loss": 0.008120084553956986, "policy_loss": -0.0015488629928080756, "dist_entropy": 0.8667400479316711, "actor_grad_norm": 0.09465856850147247, "critic_grad_norm": 0.029461894184350967, "ratio": 1.0000461339950562, "entropy": 0.8667400479316711, "incre_win_rate": 0.8648648648648649, "step": 784}
{"time": 1767334822.3919713, "phase": "train", "update": 785, "total_env_steps": 2512000, "episode_reward": 0.23346441984176636, "value_loss": 0.007998271845281124, "policy_loss": -0.001163443229808081, "dist_entropy": 0.8720890641212463, "actor_grad_norm": 0.11489802598953247, "critic_grad_norm": 0.023219039663672447, "ratio": 0.9995025992393494, "entropy": 0.8720890641212463, "incre_win_rate": 0.8947368421052632, "step": 785}
{"time": 1767334826.482074, "phase": "train", "update": 786, "total_env_steps": 2515200, "episode_reward": 0.2342425286769867, "value_loss": 0.008056031540036201, "policy_loss": -0.0013665624792154496, "dist_entropy": 0.8786850571632385, "actor_grad_norm": 0.15709730982780457, "critic_grad_norm": 0.017412293702363968, "ratio": 0.9999419450759888, "entropy": 0.8786850571632385, "incre_win_rate": 0.9230769230769231, "step": 786}
{"time": 1767334830.4925158, "phase": "train", "update": 787, "total_env_steps": 2518400, "episode_reward": 0.2115148901939392, "value_loss": 0.011688659712672234, "policy_loss": -0.0018709252563170243, "dist_entropy": 0.8879575252532959, "actor_grad_norm": 0.1941232532262802, "critic_grad_norm": 0.06450328975915909, "ratio": 0.9999252557754517, "entropy": 0.8879575252532959, "incre_win_rate": 0.8108108108108109, "step": 787}
{"time": 1767334834.5499341, "phase": "train", "update": 788, "total_env_steps": 2521600, "episode_reward": 0.22887727618217468, "value_loss": 0.008827447891235352, "policy_loss": -0.0013654668734748299, "dist_entropy": 0.8886963844299316, "actor_grad_norm": 0.15283958613872528, "critic_grad_norm": 0.03238336369395256, "ratio": 0.999640166759491, "entropy": 0.8886963844299316, "incre_win_rate": 0.8157894736842105, "step": 788}
{"time": 1767334838.5929484, "phase": "train", "update": 789, "total_env_steps": 2524800, "episode_reward": 0.2307119369506836, "value_loss": 0.008614279516041278, "policy_loss": -0.0011339804218849282, "dist_entropy": 0.9061973810195922, "actor_grad_norm": 0.14647184312343597, "critic_grad_norm": 0.029614070430397987, "ratio": 0.9998092651367188, "entropy": 0.9061973810195922, "incre_win_rate": 0.8333333333333334, "step": 789}
{"time": 1767334842.611083, "phase": "train", "update": 790, "total_env_steps": 2528000, "episode_reward": 0.21557016670703888, "value_loss": 0.014594138786196708, "policy_loss": -0.0013641358430596996, "dist_entropy": 0.8907781600952148, "actor_grad_norm": 0.11692916601896286, "critic_grad_norm": 0.0688946396112442, "ratio": 1.000230073928833, "entropy": 0.8907781600952148, "incre_win_rate": 0.7317073170731707, "step": 790}
{"time": 1767334846.5989227, "phase": "train", "update": 791, "total_env_steps": 2531200, "episode_reward": 0.21483546495437622, "value_loss": 0.011069215275347233, "policy_loss": -0.0011293524884429472, "dist_entropy": 0.909555983543396, "actor_grad_norm": 0.10475554317235947, "critic_grad_norm": 0.09093192219734192, "ratio": 1.0000803470611572, "entropy": 0.909555983543396, "incre_win_rate": 0.8, "step": 791}
{"time": 1767334850.6209216, "phase": "train", "update": 792, "total_env_steps": 2534400, "episode_reward": 0.21891090273857117, "value_loss": 0.011495107598602772, "policy_loss": -0.0016516078611289232, "dist_entropy": 0.9129324913024902, "actor_grad_norm": 0.10373250395059586, "critic_grad_norm": 0.07361654192209244, "ratio": 0.999893844127655, "entropy": 0.9129324913024902, "incre_win_rate": 0.8108108108108109, "step": 792}
{"time": 1767334854.6224174, "phase": "train", "update": 793, "total_env_steps": 2537600, "episode_reward": 0.20972423255443573, "value_loss": 0.015717169642448424, "policy_loss": -0.001683600615628933, "dist_entropy": 0.8947674393653869, "actor_grad_norm": 0.10274827480316162, "critic_grad_norm": 0.13635413348674774, "ratio": 0.9996976256370544, "entropy": 0.8947674393653869, "incre_win_rate": 0.6153846153846154, "step": 793}
{"time": 1767334858.640007, "phase": "train", "update": 794, "total_env_steps": 2540800, "episode_reward": 0.2119365632534027, "value_loss": 0.01195057574659586, "policy_loss": -0.0015207330627504234, "dist_entropy": 0.9037906050682067, "actor_grad_norm": 0.09350837767124176, "critic_grad_norm": 0.08701670914888382, "ratio": 0.9999327659606934, "entropy": 0.9037906050682067, "incre_win_rate": 0.7027027027027027, "step": 794}
{"time": 1767334862.6637123, "phase": "train", "update": 795, "total_env_steps": 2544000, "episode_reward": 0.2234623283147812, "value_loss": 0.01260573472827673, "policy_loss": -0.0017253120648552667, "dist_entropy": 0.912390124797821, "actor_grad_norm": 0.10907884687185287, "critic_grad_norm": 0.08045925945043564, "ratio": 1.0001792907714844, "entropy": 0.912390124797821, "incre_win_rate": 0.8108108108108109, "step": 795}
{"time": 1767334866.660505, "phase": "train", "update": 796, "total_env_steps": 2547200, "episode_reward": 0.21739031374454498, "value_loss": 0.012380684725940228, "policy_loss": -0.001471809979818306, "dist_entropy": 0.912166428565979, "actor_grad_norm": 0.0989965945482254, "critic_grad_norm": 0.056750427931547165, "ratio": 0.999915599822998, "entropy": 0.912166428565979, "incre_win_rate": 0.6842105263157895, "step": 796}
{"time": 1767334870.7028494, "phase": "train", "update": 797, "total_env_steps": 2550400, "episode_reward": 0.22470922768115997, "value_loss": 0.010411049425601959, "policy_loss": -0.0018651714415412358, "dist_entropy": 0.9173928022384643, "actor_grad_norm": 0.12437929213047028, "critic_grad_norm": 0.04747306928038597, "ratio": 0.9992753267288208, "entropy": 0.9173928022384643, "incre_win_rate": 0.7948717948717948, "step": 797}
{"time": 1767334874.7264516, "phase": "train", "update": 798, "total_env_steps": 2553600, "episode_reward": 0.22640468180179596, "value_loss": 0.008649748750030994, "policy_loss": -0.0012062488376194836, "dist_entropy": 0.9028650999069214, "actor_grad_norm": 0.11490793526172638, "critic_grad_norm": 0.04479924961924553, "ratio": 0.9996035695075989, "entropy": 0.9028650999069214, "incre_win_rate": 0.8378378378378378, "step": 798}
{"time": 1767334878.7974362, "phase": "train", "update": 799, "total_env_steps": 2556800, "episode_reward": 0.23067881166934967, "value_loss": 0.012108741328120232, "policy_loss": -0.0013689796030917022, "dist_entropy": 0.8861332893371582, "actor_grad_norm": 0.11043351888656616, "critic_grad_norm": 0.05889853462576866, "ratio": 1.0000755786895752, "entropy": 0.8861332893371582, "incre_win_rate": 0.825, "step": 799}
{"time": 1767334882.828395, "phase": "train", "update": 800, "total_env_steps": 2560000, "episode_reward": 0.23190397024154663, "value_loss": 0.009562142565846444, "policy_loss": -0.0014875060065103417, "dist_entropy": 0.8546156048774719, "actor_grad_norm": 0.10135944187641144, "critic_grad_norm": 0.05559581145644188, "ratio": 1.000196933746338, "entropy": 0.8546156048774719, "incre_win_rate": 0.8421052631578947, "step": 800}
{"time": 1767334886.8966203, "phase": "train", "update": 801, "total_env_steps": 2563200, "episode_reward": 0.2376769483089447, "value_loss": 0.008515815064311028, "policy_loss": -0.0016078499591756668, "dist_entropy": 0.8584578037261963, "actor_grad_norm": 0.11298558861017227, "critic_grad_norm": 0.05421685799956322, "ratio": 1.0001877546310425, "entropy": 0.8584578037261963, "incre_win_rate": 0.8292682926829268, "step": 801}
{"time": 1767334897.7395792, "phase": "eval", "update": 801, "total_env_steps": 2563200, "eval_win_rate": 1.0, "eval_episode_reward": 20.0, "step": 801}
{"time": 1767334901.9170187, "phase": "train", "update": 802, "total_env_steps": 2566400, "episode_reward": 0.2237810343503952, "value_loss": 0.01371826808899641, "policy_loss": -0.0012879291047884322, "dist_entropy": 0.8324176907539368, "actor_grad_norm": 0.13776734471321106, "critic_grad_norm": 0.11551256477832794, "ratio": 0.9997026324272156, "entropy": 0.8324176907539368, "incre_win_rate": 0.7631578947368421, "step": 802}
{"time": 1767334906.1719964, "phase": "train", "update": 803, "total_env_steps": 2569600, "episode_reward": 0.210451140999794, "value_loss": 0.014827480725944042, "policy_loss": -0.001071466635069984, "dist_entropy": 0.8175576567649842, "actor_grad_norm": 0.11050476133823395, "critic_grad_norm": 0.0829671174287796, "ratio": 0.9996600151062012, "entropy": 0.8175576567649842, "incre_win_rate": 0.6756756756756757, "step": 803}
{"time": 1767334910.6532397, "phase": "train", "update": 804, "total_env_steps": 2572800, "episode_reward": 0.2048887461423874, "value_loss": 0.016797729209065436, "policy_loss": -0.0010425726516189115, "dist_entropy": 0.7989762902259827, "actor_grad_norm": 0.13348285853862762, "critic_grad_norm": 0.042774032801389694, "ratio": 0.999811589717865, "entropy": 0.7989762902259827, "incre_win_rate": 0.5945945945945946, "step": 804}
{"time": 1767334915.289567, "phase": "train", "update": 805, "total_env_steps": 2576000, "episode_reward": 0.24185535311698914, "value_loss": 0.010883713886141778, "policy_loss": -0.001445323353674155, "dist_entropy": 0.8176074981689453, "actor_grad_norm": 0.1221025213599205, "critic_grad_norm": 0.13465793430805206, "ratio": 1.0003201961517334, "entropy": 0.8176074981689453, "incre_win_rate": 0.9285714285714286, "step": 805}
{"time": 1767334919.3350368, "phase": "train", "update": 806, "total_env_steps": 2579200, "episode_reward": 0.22884728014469147, "value_loss": 0.010521851107478141, "policy_loss": -0.0013637793072994952, "dist_entropy": 0.8380261898040772, "actor_grad_norm": 0.1287379264831543, "critic_grad_norm": 0.06256046146154404, "ratio": 1.0002129077911377, "entropy": 0.8380261898040772, "incre_win_rate": 0.7894736842105263, "step": 806}
{"time": 1767334923.4229538, "phase": "train", "update": 807, "total_env_steps": 2582400, "episode_reward": 0.23637831211090088, "value_loss": 0.008660719357430935, "policy_loss": -0.0010289964445874488, "dist_entropy": 0.853644871711731, "actor_grad_norm": 0.09999237954616547, "critic_grad_norm": 0.052641838788986206, "ratio": 0.9999561309814453, "entropy": 0.853644871711731, "incre_win_rate": 0.868421052631579, "step": 807}
{"time": 1767334927.499685, "phase": "train", "update": 808, "total_env_steps": 2585600, "episode_reward": 0.2300015389919281, "value_loss": 0.012349201552569865, "policy_loss": -0.0011881025816919077, "dist_entropy": 0.8305811166763306, "actor_grad_norm": 0.10014346987009048, "critic_grad_norm": 0.05371881276369095, "ratio": 0.999681293964386, "entropy": 0.8305811166763306, "incre_win_rate": 0.8974358974358975, "step": 808}
{"time": 1767334931.6277726, "phase": "train", "update": 809, "total_env_steps": 2588800, "episode_reward": 0.22515316307544708, "value_loss": 0.011827981285750865, "policy_loss": -0.0011005749134801236, "dist_entropy": 0.8350135207176208, "actor_grad_norm": 0.0933070033788681, "critic_grad_norm": 0.05573919042944908, "ratio": 0.9999608993530273, "entropy": 0.8350135207176208, "incre_win_rate": 0.7631578947368421, "step": 809}
{"time": 1767334935.7237642, "phase": "train", "update": 810, "total_env_steps": 2592000, "episode_reward": 0.22531352937221527, "value_loss": 0.010939738899469375, "policy_loss": -0.0012506746727019903, "dist_entropy": 0.8342901229858398, "actor_grad_norm": 0.1095142513513565, "critic_grad_norm": 0.11199849843978882, "ratio": 0.9999489784240723, "entropy": 0.8342901229858398, "incre_win_rate": 0.8421052631578947, "step": 810}
{"time": 1767334939.805626, "phase": "train", "update": 811, "total_env_steps": 2595200, "episode_reward": 0.2395695298910141, "value_loss": 0.006565108615905047, "policy_loss": -0.0013465474389896316, "dist_entropy": 0.8455491900444031, "actor_grad_norm": 0.14040544629096985, "critic_grad_norm": 0.09117823094129562, "ratio": 0.9997709393501282, "entropy": 0.8455491900444031, "incre_win_rate": 0.9487179487179487, "step": 811}
{"time": 1767334943.8367484, "phase": "train", "update": 812, "total_env_steps": 2598400, "episode_reward": 0.23486341536045074, "value_loss": 0.006697291508316994, "policy_loss": -0.0015026221226129622, "dist_entropy": 0.8660431981086731, "actor_grad_norm": 0.1305435746908188, "critic_grad_norm": 0.037760037928819656, "ratio": 0.9997658133506775, "entropy": 0.8660431981086731, "incre_win_rate": 0.9487179487179487, "step": 812}
{"time": 1767334947.8886538, "phase": "train", "update": 813, "total_env_steps": 2601600, "episode_reward": 0.23297236859798431, "value_loss": 0.0067732658237218855, "policy_loss": -0.0017555153015550219, "dist_entropy": 0.9135909795761108, "actor_grad_norm": 0.12778638303279877, "critic_grad_norm": 0.0473746657371521, "ratio": 0.9998981356620789, "entropy": 0.9135909795761108, "incre_win_rate": 0.8947368421052632, "step": 813}
{"time": 1767334951.9988847, "phase": "train", "update": 814, "total_env_steps": 2604800, "episode_reward": 0.23862117528915405, "value_loss": 0.006320912670344114, "policy_loss": -0.0011095573335705212, "dist_entropy": 0.9012095928192139, "actor_grad_norm": 0.1067158579826355, "critic_grad_norm": 0.05024629831314087, "ratio": 1.0000337362289429, "entropy": 0.9012095928192139, "incre_win_rate": 0.8974358974358975, "step": 814}
{"time": 1767334956.1198423, "phase": "train", "update": 815, "total_env_steps": 2608000, "episode_reward": 0.22022764384746552, "value_loss": 0.011870935373008252, "policy_loss": -0.001181851645100096, "dist_entropy": 0.9225164651870728, "actor_grad_norm": 0.07852180302143097, "critic_grad_norm": 0.09984614700078964, "ratio": 1.0000823736190796, "entropy": 0.9225164651870728, "incre_win_rate": 0.7368421052631579, "step": 815}
{"time": 1767334960.2068915, "phase": "train", "update": 816, "total_env_steps": 2611200, "episode_reward": 0.23061001300811768, "value_loss": 0.01061190403997898, "policy_loss": -0.0014076091964767556, "dist_entropy": 0.9208973050117493, "actor_grad_norm": 0.10611792653799057, "critic_grad_norm": 0.12511208653450012, "ratio": 0.9999691843986511, "entropy": 0.9208973050117493, "incre_win_rate": 0.8648648648648649, "step": 816}
{"time": 1767334993.3770478, "phase": "train", "update": 817, "total_env_steps": 2614400, "episode_reward": 0.20863410830497742, "value_loss": 0.08003282696008682, "policy_loss": -0.0012927499910825979, "dist_entropy": 0.8627387523651123, "actor_grad_norm": 0.14244744181632996, "critic_grad_norm": 0.32479390501976013, "ratio": 1.0000147819519043, "entropy": 0.8627387523651123, "incre_win_rate": 0.6666666666666666, "step": 817}
{"time": 1767334997.4376502, "phase": "train", "update": 818, "total_env_steps": 2617600, "episode_reward": 0.22855909168720245, "value_loss": 0.01234473343938589, "policy_loss": -0.0015035207579141563, "dist_entropy": 0.8466090321540832, "actor_grad_norm": 0.15790480375289917, "critic_grad_norm": 0.1807893067598343, "ratio": 0.999972939491272, "entropy": 0.8466090321540832, "incre_win_rate": 0.8, "step": 818}
{"time": 1767335001.5304756, "phase": "train", "update": 819, "total_env_steps": 2620800, "episode_reward": 0.22709178924560547, "value_loss": 0.008252943679690362, "policy_loss": -0.0014595612346948172, "dist_entropy": 0.8913359403610229, "actor_grad_norm": 0.08433663845062256, "critic_grad_norm": 0.1343664973974228, "ratio": 1.0002838373184204, "entropy": 0.8913359403610229, "incre_win_rate": 0.8, "step": 819}
{"time": 1767335005.6175067, "phase": "train", "update": 820, "total_env_steps": 2624000, "episode_reward": 0.22656303644180298, "value_loss": 0.014185666665434837, "policy_loss": -0.001281061216114665, "dist_entropy": 0.869013512134552, "actor_grad_norm": 0.10638570040464401, "critic_grad_norm": 0.11012303084135056, "ratio": 0.9999019503593445, "entropy": 0.869013512134552, "incre_win_rate": 0.8205128205128205, "step": 820}
{"time": 1767335009.6891525, "phase": "train", "update": 821, "total_env_steps": 2627200, "episode_reward": 0.22428083419799805, "value_loss": 0.014843597263097762, "policy_loss": -0.0015935816300430617, "dist_entropy": 0.8709983468055725, "actor_grad_norm": 0.11048020422458649, "critic_grad_norm": 0.06501643359661102, "ratio": 0.9997524619102478, "entropy": 0.8709983468055725, "incre_win_rate": 0.7435897435897436, "step": 821}
{"time": 1767335013.7158976, "phase": "train", "update": 822, "total_env_steps": 2630400, "episode_reward": 0.2194003462791443, "value_loss": 0.012665391713380814, "policy_loss": -0.0015953779908157272, "dist_entropy": 0.8650483250617981, "actor_grad_norm": 0.14150340855121613, "critic_grad_norm": 0.037206221371889114, "ratio": 0.999890923500061, "entropy": 0.8650483250617981, "incre_win_rate": 0.7631578947368421, "step": 822}
{"time": 1767335017.8233438, "phase": "train", "update": 823, "total_env_steps": 2633600, "episode_reward": 0.24019764363765717, "value_loss": 0.0061162193305790424, "policy_loss": -0.001963269382684274, "dist_entropy": 0.84533851146698, "actor_grad_norm": 0.11871109157800674, "critic_grad_norm": 0.09518170356750488, "ratio": 0.999633252620697, "entropy": 0.84533851146698, "incre_win_rate": 0.9736842105263158, "step": 823}
{"time": 1767335021.9139178, "phase": "train", "update": 824, "total_env_steps": 2636800, "episode_reward": 0.24278973042964935, "value_loss": 0.006709981523454189, "policy_loss": -0.0014920645469615578, "dist_entropy": 0.8446033239364624, "actor_grad_norm": 0.08698111027479172, "critic_grad_norm": 0.042910948395729065, "ratio": 0.9996642470359802, "entropy": 0.8446033239364624, "incre_win_rate": 0.9487179487179487, "step": 824}
{"time": 1767335026.0612152, "phase": "train", "update": 825, "total_env_steps": 2640000, "episode_reward": 0.2344619333744049, "value_loss": 0.005850078258663416, "policy_loss": -0.001564296985091218, "dist_entropy": 0.8579053401947021, "actor_grad_norm": 0.08823200315237045, "critic_grad_norm": 0.02721373178064823, "ratio": 0.9997571110725403, "entropy": 0.8579053401947021, "incre_win_rate": 0.9473684210526315, "step": 825}
{"time": 1767335030.1413722, "phase": "train", "update": 826, "total_env_steps": 2643200, "episode_reward": 0.22786422073841095, "value_loss": 0.008130704797804356, "policy_loss": -0.0013908642176858165, "dist_entropy": 0.8600519895553589, "actor_grad_norm": 0.15115197002887726, "critic_grad_norm": 0.04865771532058716, "ratio": 0.9998430609703064, "entropy": 0.8600519895553589, "incre_win_rate": 0.868421052631579, "step": 826}
{"time": 1767335041.3559585, "phase": "eval", "update": 826, "total_env_steps": 2643200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.909250827814567, "step": 826}
{"time": 1767335045.4129086, "phase": "train", "update": 827, "total_env_steps": 2646400, "episode_reward": 0.21442881226539612, "value_loss": 0.010782761685550212, "policy_loss": -0.0018654163470181117, "dist_entropy": 0.8497477531433105, "actor_grad_norm": 0.10382198542356491, "critic_grad_norm": 0.08031263202428818, "ratio": 1.0000721216201782, "entropy": 0.8497477531433105, "incre_win_rate": 0.7368421052631579, "step": 827}
{"time": 1767335049.5314443, "phase": "train", "update": 828, "total_env_steps": 2649600, "episode_reward": 0.2304195910692215, "value_loss": 0.00847594439983368, "policy_loss": -0.0011142575375366448, "dist_entropy": 0.8648386001586914, "actor_grad_norm": 0.09078939259052277, "critic_grad_norm": 0.042959947139024734, "ratio": 0.999823272228241, "entropy": 0.8648386001586914, "incre_win_rate": 0.8918918918918919, "step": 828}
{"time": 1767335053.624543, "phase": "train", "update": 829, "total_env_steps": 2652800, "episode_reward": 0.23100581765174866, "value_loss": 0.013023335859179497, "policy_loss": -0.0013490962667990658, "dist_entropy": 0.8485270738601685, "actor_grad_norm": 0.08561026304960251, "critic_grad_norm": 0.07828456163406372, "ratio": 0.9999601244926453, "entropy": 0.8485270738601685, "incre_win_rate": 0.9210526315789473, "step": 829}
{"time": 1767335057.7016346, "phase": "train", "update": 830, "total_env_steps": 2656000, "episode_reward": 0.2269231230020523, "value_loss": 0.008132395707070828, "policy_loss": -0.0014482911324030568, "dist_entropy": 0.8481674432754517, "actor_grad_norm": 0.16963449120521545, "critic_grad_norm": 0.06749545782804489, "ratio": 1.0001505613327026, "entropy": 0.8481674432754517, "incre_win_rate": 0.8648648648648649, "step": 830}
{"time": 1767335061.7487302, "phase": "train", "update": 831, "total_env_steps": 2659200, "episode_reward": 0.21796460449695587, "value_loss": 0.010229087062180042, "policy_loss": -0.0012664981199408843, "dist_entropy": 0.8464760661125184, "actor_grad_norm": 0.08209538459777832, "critic_grad_norm": 0.03586803004145622, "ratio": 1.0000182390213013, "entropy": 0.8464760661125184, "incre_win_rate": 0.8108108108108109, "step": 831}
{"time": 1767335065.8557131, "phase": "train", "update": 832, "total_env_steps": 2662400, "episode_reward": 0.22879813611507416, "value_loss": 0.0075296488590538505, "policy_loss": -0.0015988814221437053, "dist_entropy": 0.8554432153701782, "actor_grad_norm": 0.09652473777532578, "critic_grad_norm": 0.02987225167453289, "ratio": 1.0002121925354004, "entropy": 0.8554432153701782, "incre_win_rate": 0.8461538461538461, "step": 832}
{"time": 1767335069.965154, "phase": "train", "update": 833, "total_env_steps": 2665600, "episode_reward": 0.21623395383358002, "value_loss": 0.008831248432397843, "policy_loss": -0.0011150102698609166, "dist_entropy": 0.875466501712799, "actor_grad_norm": 0.10326850414276123, "critic_grad_norm": 0.051317404955625534, "ratio": 1.0001219511032104, "entropy": 0.875466501712799, "incre_win_rate": 0.8571428571428571, "step": 833}
{"time": 1767335074.0539281, "phase": "train", "update": 834, "total_env_steps": 2668800, "episode_reward": 0.2188565880060196, "value_loss": 0.008684901893138886, "policy_loss": -0.001976772732215437, "dist_entropy": 0.8848726868629455, "actor_grad_norm": 0.11680008471012115, "critic_grad_norm": 0.023466987535357475, "ratio": 0.9998490214347839, "entropy": 0.8848726868629455, "incre_win_rate": 0.8205128205128205, "step": 834}
{"time": 1767335078.1141753, "phase": "train", "update": 835, "total_env_steps": 2672000, "episode_reward": 0.2176293581724167, "value_loss": 0.008625775761902332, "policy_loss": -0.0014265626118286079, "dist_entropy": 0.8720036625862122, "actor_grad_norm": 0.11727364361286163, "critic_grad_norm": 0.023629743605852127, "ratio": 0.9998507499694824, "entropy": 0.8720036625862122, "incre_win_rate": 0.7297297297297297, "step": 835}
{"time": 1767335082.2096999, "phase": "train", "update": 836, "total_env_steps": 2675200, "episode_reward": 0.22470973432064056, "value_loss": 0.012458754889667033, "policy_loss": -0.0017716117036092882, "dist_entropy": 0.8816688060760498, "actor_grad_norm": 0.10346820205450058, "critic_grad_norm": 0.04098040983080864, "ratio": 1.0003328323364258, "entropy": 0.8816688060760498, "incre_win_rate": 0.8205128205128205, "step": 836}
{"time": 1767335086.314382, "phase": "train", "update": 837, "total_env_steps": 2678400, "episode_reward": 0.22983857989311218, "value_loss": 0.007922285795211792, "policy_loss": -0.0015766655912835327, "dist_entropy": 0.8942595481872558, "actor_grad_norm": 0.10454404354095459, "critic_grad_norm": 0.05667906999588013, "ratio": 1.0000040531158447, "entropy": 0.8942595481872558, "incre_win_rate": 0.8918918918918919, "step": 837}
{"time": 1767335090.3899632, "phase": "train", "update": 838, "total_env_steps": 2681600, "episode_reward": 0.22998085618019104, "value_loss": 0.009010124765336514, "policy_loss": -0.0015963327230466007, "dist_entropy": 0.8775291323661805, "actor_grad_norm": 0.09629248827695847, "critic_grad_norm": 0.04667805880308151, "ratio": 1.0003547668457031, "entropy": 0.8775291323661805, "incre_win_rate": 0.8888888888888888, "step": 838}
{"time": 1767335094.4319263, "phase": "train", "update": 839, "total_env_steps": 2684800, "episode_reward": 0.2046409249305725, "value_loss": 0.01494288183748722, "policy_loss": -0.001242489420119597, "dist_entropy": 0.8479500770568847, "actor_grad_norm": 0.15235769748687744, "critic_grad_norm": 0.1155080571770668, "ratio": 0.9999750256538391, "entropy": 0.8479500770568847, "incre_win_rate": 0.631578947368421, "step": 839}
{"time": 1767335098.5555174, "phase": "train", "update": 840, "total_env_steps": 2688000, "episode_reward": 0.23811618983745575, "value_loss": 0.006418932788074016, "policy_loss": -0.001643149260154786, "dist_entropy": 0.8869861006736756, "actor_grad_norm": 0.12273327261209488, "critic_grad_norm": 0.11560016870498657, "ratio": 1.0000532865524292, "entropy": 0.8869861006736756, "incre_win_rate": 0.95, "step": 840}
{"time": 1767335102.6313329, "phase": "train", "update": 841, "total_env_steps": 2691200, "episode_reward": 0.22368793189525604, "value_loss": 0.01050958726555109, "policy_loss": -0.0017520053722453355, "dist_entropy": 0.8664831638336181, "actor_grad_norm": 0.11265422403812408, "critic_grad_norm": 0.0880153477191925, "ratio": 0.9998686909675598, "entropy": 0.8664831638336181, "incre_win_rate": 0.8648648648648649, "step": 841}
{"time": 1767335106.7515728, "phase": "train", "update": 842, "total_env_steps": 2694400, "episode_reward": 0.2351422756910324, "value_loss": 0.0063201279379427435, "policy_loss": -0.0011943571318095091, "dist_entropy": 0.8734826803207397, "actor_grad_norm": 0.09105449169874191, "critic_grad_norm": 0.06477736681699753, "ratio": 0.9998284578323364, "entropy": 0.8734826803207397, "incre_win_rate": 0.9230769230769231, "step": 842}
{"time": 1767335110.8732388, "phase": "train", "update": 843, "total_env_steps": 2697600, "episode_reward": 0.22440658509731293, "value_loss": 0.009766541421413422, "policy_loss": -0.001873926820322458, "dist_entropy": 0.8718597650527954, "actor_grad_norm": 0.11909782886505127, "critic_grad_norm": 0.0902918204665184, "ratio": 1.000178575515747, "entropy": 0.8718597650527954, "incre_win_rate": 0.8157894736842105, "step": 843}
{"time": 1767335114.9299753, "phase": "train", "update": 844, "total_env_steps": 2700800, "episode_reward": 0.22905835509300232, "value_loss": 0.008757833577692508, "policy_loss": -0.0009638303460462794, "dist_entropy": 0.8237898230552674, "actor_grad_norm": 0.09085625410079956, "critic_grad_norm": 0.10221761465072632, "ratio": 1.0003379583358765, "entropy": 0.8237898230552674, "incre_win_rate": 0.8611111111111112, "step": 844}
{"time": 1767335119.0501802, "phase": "train", "update": 845, "total_env_steps": 2704000, "episode_reward": 0.23260919749736786, "value_loss": 0.013057746924459934, "policy_loss": -0.001482261413842423, "dist_entropy": 0.8193686604499817, "actor_grad_norm": 0.1217021718621254, "critic_grad_norm": 0.060856401920318604, "ratio": 0.9997631311416626, "entropy": 0.8193686604499817, "incre_win_rate": 0.8536585365853658, "step": 845}
{"time": 1767335123.1405058, "phase": "train", "update": 846, "total_env_steps": 2707200, "episode_reward": 0.2411615401506424, "value_loss": 0.009467128477990628, "policy_loss": -0.0008642497755730006, "dist_entropy": 0.8397607445716858, "actor_grad_norm": 0.14158599078655243, "critic_grad_norm": 0.07454913854598999, "ratio": 1.0000499486923218, "entropy": 0.8397607445716858, "incre_win_rate": 0.875, "step": 846}
{"time": 1767335127.233561, "phase": "train", "update": 847, "total_env_steps": 2710400, "episode_reward": 0.23489755392074585, "value_loss": 0.009277689643204213, "policy_loss": -0.001588802079992746, "dist_entropy": 0.8253247618675232, "actor_grad_norm": 0.11283786594867706, "critic_grad_norm": 0.08479832857847214, "ratio": 0.99974125623703, "entropy": 0.8253247618675232, "incre_win_rate": 0.8461538461538461, "step": 847}
{"time": 1767335131.355142, "phase": "train", "update": 848, "total_env_steps": 2713600, "episode_reward": 0.23555049300193787, "value_loss": 0.012158663757145406, "policy_loss": -0.0011638158579124537, "dist_entropy": 0.8144740343093873, "actor_grad_norm": 0.10238726437091827, "critic_grad_norm": 0.07474812865257263, "ratio": 0.9997718930244446, "entropy": 0.8144740343093873, "incre_win_rate": 0.868421052631579, "step": 848}
{"time": 1767335135.4931254, "phase": "train", "update": 849, "total_env_steps": 2716800, "episode_reward": 0.23737169802188873, "value_loss": 0.007157075591385365, "policy_loss": -0.0014420600412719865, "dist_entropy": 0.8282990217208862, "actor_grad_norm": 0.08635485172271729, "critic_grad_norm": 0.04398799315094948, "ratio": 1.0000766515731812, "entropy": 0.8282990217208862, "incre_win_rate": 0.9230769230769231, "step": 849}
{"time": 1767335139.6314101, "phase": "train", "update": 850, "total_env_steps": 2720000, "episode_reward": 0.24552980065345764, "value_loss": 0.005242486111819744, "policy_loss": -0.0013296684341156605, "dist_entropy": 0.8434986233711242, "actor_grad_norm": 0.1219780221581459, "critic_grad_norm": 0.06416594237089157, "ratio": 0.9993929266929626, "entropy": 0.8434986233711242, "incre_win_rate": 0.975, "step": 850}
{"time": 1767335143.7056866, "phase": "train", "update": 851, "total_env_steps": 2723200, "episode_reward": 0.22954626381397247, "value_loss": 0.01146635003387928, "policy_loss": -0.0011276423631748854, "dist_entropy": 0.8259771227836609, "actor_grad_norm": 0.113411545753479, "critic_grad_norm": 0.06821519136428833, "ratio": 1.0000245571136475, "entropy": 0.8259771227836609, "incre_win_rate": 0.8157894736842105, "step": 851}
{"time": 1767335154.5597565, "phase": "eval", "update": 851, "total_env_steps": 2723200, "eval_win_rate": 1.0, "eval_episode_reward": 20.001655629139073, "step": 851}
{"time": 1767335158.6646755, "phase": "train", "update": 852, "total_env_steps": 2726400, "episode_reward": 0.22754967212677002, "value_loss": 0.007474617753177881, "policy_loss": -0.0015176814069604917, "dist_entropy": 0.8324913024902344, "actor_grad_norm": 0.1249026283621788, "critic_grad_norm": 0.06143546104431152, "ratio": 0.9999309778213501, "entropy": 0.8324913024902344, "incre_win_rate": 0.868421052631579, "step": 852}
{"time": 1767335162.7631142, "phase": "train", "update": 853, "total_env_steps": 2729600, "episode_reward": 0.22366774082183838, "value_loss": 0.009829134494066239, "policy_loss": -0.0018182841458527221, "dist_entropy": 0.8385331153869628, "actor_grad_norm": 0.09827118366956711, "critic_grad_norm": 0.06950593739748001, "ratio": 0.9995939135551453, "entropy": 0.8385331153869628, "incre_win_rate": 0.8205128205128205, "step": 853}
{"time": 1767335166.8443322, "phase": "train", "update": 854, "total_env_steps": 2732800, "episode_reward": 0.22436155378818512, "value_loss": 0.007780418824404478, "policy_loss": -0.00178803498529021, "dist_entropy": 0.8542473316192627, "actor_grad_norm": 0.10023393481969833, "critic_grad_norm": 0.04033958911895752, "ratio": 0.9999570846557617, "entropy": 0.8542473316192627, "incre_win_rate": 0.8378378378378378, "step": 854}
{"time": 1767335170.9426336, "phase": "train", "update": 855, "total_env_steps": 2736000, "episode_reward": 0.22718802094459534, "value_loss": 0.007794219255447388, "policy_loss": -0.0017951297639797303, "dist_entropy": 0.8781534314155579, "actor_grad_norm": 0.13846896588802338, "critic_grad_norm": 0.040882449597120285, "ratio": 0.9999625086784363, "entropy": 0.8781534314155579, "incre_win_rate": 0.8648648648648649, "step": 855}
{"time": 1767335175.012439, "phase": "train", "update": 856, "total_env_steps": 2739200, "episode_reward": 0.23053550720214844, "value_loss": 0.010740426927804947, "policy_loss": -0.0011214441454836077, "dist_entropy": 0.8550660014152527, "actor_grad_norm": 0.09474547952413559, "critic_grad_norm": 0.06479064375162125, "ratio": 0.9998327493667603, "entropy": 0.8550660014152527, "incre_win_rate": 0.7894736842105263, "step": 856}
{"time": 1767335179.1061885, "phase": "train", "update": 857, "total_env_steps": 2742400, "episode_reward": 0.24022197723388672, "value_loss": 0.008325457386672497, "policy_loss": -0.0016455265576951206, "dist_entropy": 0.8779429078102112, "actor_grad_norm": 0.14958445727825165, "critic_grad_norm": 0.07130076736211777, "ratio": 1.000231146812439, "entropy": 0.8779429078102112, "incre_win_rate": 0.925, "step": 857}
{"time": 1767335183.222957, "phase": "train", "update": 858, "total_env_steps": 2745600, "episode_reward": 0.21821865439414978, "value_loss": 0.013548302836716175, "policy_loss": -0.0016182931475510643, "dist_entropy": 0.8431015610694885, "actor_grad_norm": 0.12222683429718018, "critic_grad_norm": 0.09612633287906647, "ratio": 0.9996253252029419, "entropy": 0.8431015610694885, "incre_win_rate": 0.6923076923076923, "step": 858}
{"time": 1767335187.363161, "phase": "train", "update": 859, "total_env_steps": 2748800, "episode_reward": 0.2381249964237213, "value_loss": 0.007739918772131205, "policy_loss": -0.0013443279110632034, "dist_entropy": 0.8782009720802307, "actor_grad_norm": 0.0897267684340477, "critic_grad_norm": 0.04598486050963402, "ratio": 0.9996725916862488, "entropy": 0.8782009720802307, "incre_win_rate": 0.8717948717948718, "step": 859}
{"time": 1767335191.4599817, "phase": "train", "update": 860, "total_env_steps": 2752000, "episode_reward": 0.23588937520980835, "value_loss": 0.0060846623964607716, "policy_loss": -0.0012508290709300595, "dist_entropy": 0.8790730357170105, "actor_grad_norm": 0.09884856641292572, "critic_grad_norm": 0.04029536247253418, "ratio": 0.999738335609436, "entropy": 0.8790730357170105, "incre_win_rate": 0.8974358974358975, "step": 860}
{"time": 1767335195.6143336, "phase": "train", "update": 861, "total_env_steps": 2755200, "episode_reward": 0.24495860934257507, "value_loss": 0.005967130046337843, "policy_loss": -0.0012895077659472066, "dist_entropy": 0.892664623260498, "actor_grad_norm": 0.13529576361179352, "critic_grad_norm": 0.04179546982049942, "ratio": 0.9993531107902527, "entropy": 0.892664623260498, "incre_win_rate": 0.95, "step": 861}
{"time": 1767335199.7393043, "phase": "train", "update": 862, "total_env_steps": 2758400, "episode_reward": 0.23540978133678436, "value_loss": 0.008128187526017428, "policy_loss": -0.0015716201782677076, "dist_entropy": 0.8784376978874207, "actor_grad_norm": 0.10448183864355087, "critic_grad_norm": 0.05319037660956383, "ratio": 0.9997509121894836, "entropy": 0.8784376978874207, "incre_win_rate": 0.9210526315789473, "step": 862}
{"time": 1767335203.8720944, "phase": "train", "update": 863, "total_env_steps": 2761600, "episode_reward": 0.24175339937210083, "value_loss": 0.009562074951827527, "policy_loss": -0.0011042375347761536, "dist_entropy": 0.8710008859634399, "actor_grad_norm": 0.11291545629501343, "critic_grad_norm": 0.06799840182065964, "ratio": 1.000267505645752, "entropy": 0.8710008859634399, "incre_win_rate": 0.9, "step": 863}
{"time": 1767335208.0599234, "phase": "train", "update": 864, "total_env_steps": 2764800, "episode_reward": 0.24186673760414124, "value_loss": 0.008322019875049592, "policy_loss": -0.0012319982074487257, "dist_entropy": 0.8623889565467835, "actor_grad_norm": 0.11102988570928574, "critic_grad_norm": 0.05454796180129051, "ratio": 1.000004768371582, "entropy": 0.8623889565467835, "incre_win_rate": 0.875, "step": 864}
{"time": 1767335212.2115238, "phase": "train", "update": 865, "total_env_steps": 2768000, "episode_reward": 0.24349337816238403, "value_loss": 0.007695121318101883, "policy_loss": -0.0010434721432190485, "dist_entropy": 0.8393021583557129, "actor_grad_norm": 0.12510310113430023, "critic_grad_norm": 0.03384332358837128, "ratio": 0.9999955296516418, "entropy": 0.8393021583557129, "incre_win_rate": 0.926829268292683, "step": 865}
{"time": 1767335216.354649, "phase": "train", "update": 866, "total_env_steps": 2771200, "episode_reward": 0.25127899646759033, "value_loss": 0.00597181860357523, "policy_loss": -0.0014704020705636367, "dist_entropy": 0.8453295826911926, "actor_grad_norm": 0.11171569675207138, "critic_grad_norm": 0.035662613809108734, "ratio": 0.9996862411499023, "entropy": 0.8453295826911926, "incre_win_rate": 0.975, "step": 866}
{"time": 1767335220.464459, "phase": "train", "update": 867, "total_env_steps": 2774400, "episode_reward": 0.24181602895259857, "value_loss": 0.007121132593601942, "policy_loss": -0.0011802142940165795, "dist_entropy": 0.8525485038757324, "actor_grad_norm": 0.10132332891225815, "critic_grad_norm": 0.05195873603224754, "ratio": 0.9997460246086121, "entropy": 0.8525485038757324, "incre_win_rate": 0.8974358974358975, "step": 867}
{"time": 1767335224.5728579, "phase": "train", "update": 868, "total_env_steps": 2777600, "episode_reward": 0.24170738458633423, "value_loss": 0.005367377586662769, "policy_loss": -0.001406793251008054, "dist_entropy": 0.8557499766349792, "actor_grad_norm": 0.12498655170202255, "critic_grad_norm": 0.037233736366033554, "ratio": 0.9996829032897949, "entropy": 0.8557499766349792, "incre_win_rate": 0.925, "step": 868}
{"time": 1767335228.7030294, "phase": "train", "update": 869, "total_env_steps": 2780800, "episode_reward": 0.23024319112300873, "value_loss": 0.008460909686982631, "policy_loss": -0.0011241069022631222, "dist_entropy": 0.8512981057167053, "actor_grad_norm": 0.11383838951587677, "critic_grad_norm": 0.049865107983350754, "ratio": 0.9999859929084778, "entropy": 0.8512981057167053, "incre_win_rate": 0.8461538461538461, "step": 869}
{"time": 1767335232.86541, "phase": "train", "update": 870, "total_env_steps": 2784000, "episode_reward": 0.2419934868812561, "value_loss": 0.007411474641412496, "policy_loss": -0.0014705682841295697, "dist_entropy": 0.8520583271980285, "actor_grad_norm": 0.10769368708133698, "critic_grad_norm": 0.03726577386260033, "ratio": 1.0005521774291992, "entropy": 0.8520583271980285, "incre_win_rate": 0.9, "step": 870}
{"time": 1767335236.9863987, "phase": "train", "update": 871, "total_env_steps": 2787200, "episode_reward": 0.23628881573677063, "value_loss": 0.0109850550070405, "policy_loss": -0.0015550927973251305, "dist_entropy": 0.8486051797866822, "actor_grad_norm": 0.10092462599277496, "critic_grad_norm": 0.05962061882019043, "ratio": 1.0002415180206299, "entropy": 0.8486051797866822, "incre_win_rate": 0.8, "step": 871}
{"time": 1767335241.079242, "phase": "train", "update": 872, "total_env_steps": 2790400, "episode_reward": 0.2296212762594223, "value_loss": 0.01165852677077055, "policy_loss": -0.001345978961948946, "dist_entropy": 0.8404253005981446, "actor_grad_norm": 0.08685268461704254, "critic_grad_norm": 0.04910893365740776, "ratio": 0.99980229139328, "entropy": 0.8404253005981446, "incre_win_rate": 0.8, "step": 872}
{"time": 1767335245.179897, "phase": "train", "update": 873, "total_env_steps": 2793600, "episode_reward": 0.2354547679424286, "value_loss": 0.014602356962859631, "policy_loss": -0.0013255886456050802, "dist_entropy": 0.8500946402549744, "actor_grad_norm": 0.09765511751174927, "critic_grad_norm": 0.04123775288462639, "ratio": 0.9997332692146301, "entropy": 0.8500946402549744, "incre_win_rate": 0.8461538461538461, "step": 873}
{"time": 1767335249.290582, "phase": "train", "update": 874, "total_env_steps": 2796800, "episode_reward": 0.22835522890090942, "value_loss": 0.012696437537670135, "policy_loss": -0.0008994176959191691, "dist_entropy": 0.8500513553619384, "actor_grad_norm": 0.07473167032003403, "critic_grad_norm": 0.031423188745975494, "ratio": 0.9999880194664001, "entropy": 0.8500513553619384, "incre_win_rate": 0.7894736842105263, "step": 874}
{"time": 1767335253.3634126, "phase": "train", "update": 875, "total_env_steps": 2800000, "episode_reward": 0.22494100034236908, "value_loss": 0.011986758001148701, "policy_loss": -0.0014540153139812162, "dist_entropy": 0.8309011340141297, "actor_grad_norm": 0.14261659979820251, "critic_grad_norm": 0.04566207528114319, "ratio": 1.0001877546310425, "entropy": 0.8309011340141297, "incre_win_rate": 0.7948717948717948, "step": 875}
{"time": 1767335257.540292, "phase": "train", "update": 876, "total_env_steps": 2803200, "episode_reward": 0.24372929334640503, "value_loss": 0.006491256132721901, "policy_loss": -0.0012271322690800446, "dist_entropy": 0.8307129263877868, "actor_grad_norm": 0.1097772866487503, "critic_grad_norm": 0.09802337735891342, "ratio": 1.0002192258834839, "entropy": 0.8307129263877868, "incre_win_rate": 0.9512195121951219, "step": 876}
{"time": 1767335269.1132503, "phase": "eval", "update": 876, "total_env_steps": 2803200, "eval_win_rate": 0.875, "eval_episode_reward": 19.293356788079468, "step": 876}
{"time": 1767335273.2055995, "phase": "train", "update": 877, "total_env_steps": 2806400, "episode_reward": 0.23457419872283936, "value_loss": 0.0057123685255646706, "policy_loss": -0.0016625204249632653, "dist_entropy": 0.8201262831687928, "actor_grad_norm": 0.1063755676150322, "critic_grad_norm": 0.05864531919360161, "ratio": 0.9998127818107605, "entropy": 0.8201262831687928, "incre_win_rate": 0.9459459459459459, "step": 877}
{"time": 1767335277.3084848, "phase": "train", "update": 878, "total_env_steps": 2809600, "episode_reward": 0.22143316268920898, "value_loss": 0.009359613433480263, "policy_loss": -0.0013218449835576962, "dist_entropy": 0.8026371002197266, "actor_grad_norm": 0.08851005882024765, "critic_grad_norm": 0.0758250281214714, "ratio": 0.9999577403068542, "entropy": 0.8026371002197266, "incre_win_rate": 0.7837837837837838, "step": 878}
{"time": 1767335281.4085584, "phase": "train", "update": 879, "total_env_steps": 2812800, "episode_reward": 0.24066224694252014, "value_loss": 0.0074363998137414455, "policy_loss": -0.0010711131345701118, "dist_entropy": 0.8295200943946839, "actor_grad_norm": 0.08497067540884018, "critic_grad_norm": 0.04561041668057442, "ratio": 1.0001033544540405, "entropy": 0.8295200943946839, "incre_win_rate": 0.9230769230769231, "step": 879}
{"time": 1767335285.4487867, "phase": "train", "update": 880, "total_env_steps": 2816000, "episode_reward": 0.22439414262771606, "value_loss": 0.009040181711316108, "policy_loss": -0.0011502582897900738, "dist_entropy": 0.8064737558364868, "actor_grad_norm": 0.09587933123111725, "critic_grad_norm": 0.031159086152911186, "ratio": 1.0000866651535034, "entropy": 0.8064737558364868, "incre_win_rate": 0.7837837837837838, "step": 880}
{"time": 1767335289.5786498, "phase": "train", "update": 881, "total_env_steps": 2819200, "episode_reward": 0.23783424496650696, "value_loss": 0.009901545196771621, "policy_loss": -0.0009693307693588338, "dist_entropy": 0.8404429078102111, "actor_grad_norm": 0.0889580026268959, "critic_grad_norm": 0.03276006877422333, "ratio": 1.0000532865524292, "entropy": 0.8404429078102111, "incre_win_rate": 0.875, "step": 881}
{"time": 1767335293.7133584, "phase": "train", "update": 882, "total_env_steps": 2822400, "episode_reward": 0.24019092321395874, "value_loss": 0.008754340559244156, "policy_loss": -0.00110321583735562, "dist_entropy": 0.8381585240364074, "actor_grad_norm": 0.12486529350280762, "critic_grad_norm": 0.03842475637793541, "ratio": 1.0003541707992554, "entropy": 0.8381585240364074, "incre_win_rate": 0.8536585365853658, "step": 882}
{"time": 1767335297.760553, "phase": "train", "update": 883, "total_env_steps": 2825600, "episode_reward": 0.22124172747135162, "value_loss": 0.009427052550017833, "policy_loss": -0.0010681696638691562, "dist_entropy": 0.8152903556823731, "actor_grad_norm": 0.10872983187437057, "critic_grad_norm": 0.09246077388525009, "ratio": 1.0001194477081299, "entropy": 0.8152903556823731, "incre_win_rate": 0.7222222222222222, "step": 883}
{"time": 1767335301.8492656, "phase": "train", "update": 884, "total_env_steps": 2828800, "episode_reward": 0.23455245792865753, "value_loss": 0.008254206273704767, "policy_loss": -0.0010156130991628488, "dist_entropy": 0.8268256068229676, "actor_grad_norm": 0.11355210840702057, "critic_grad_norm": 0.06506075710058212, "ratio": 1.0002796649932861, "entropy": 0.8268256068229676, "incre_win_rate": 0.8974358974358975, "step": 884}
{"time": 1767335305.9095023, "phase": "train", "update": 885, "total_env_steps": 2832000, "episode_reward": 0.23569327592849731, "value_loss": 0.007654762268066407, "policy_loss": -0.001342727777949193, "dist_entropy": 0.823052728176117, "actor_grad_norm": 0.11595859378576279, "critic_grad_norm": 0.08251702040433884, "ratio": 0.9996961951255798, "entropy": 0.823052728176117, "incre_win_rate": 0.85, "step": 885}
{"time": 1767335310.0003104, "phase": "train", "update": 886, "total_env_steps": 2835200, "episode_reward": 0.24019506573677063, "value_loss": 0.008412855863571166, "policy_loss": -0.0010118976905388877, "dist_entropy": 0.8506058692932129, "actor_grad_norm": 0.06740476936101913, "critic_grad_norm": 0.06351923197507858, "ratio": 1.000166893005371, "entropy": 0.8506058692932129, "incre_win_rate": 0.8536585365853658, "step": 886}
{"time": 1767335314.1242983, "phase": "train", "update": 887, "total_env_steps": 2838400, "episode_reward": 0.2314109057188034, "value_loss": 0.01022556535899639, "policy_loss": -0.001485213548637887, "dist_entropy": 0.8525725483894349, "actor_grad_norm": 0.09614687412977219, "critic_grad_norm": 0.03114350698888302, "ratio": 1.0000017881393433, "entropy": 0.8525725483894349, "incre_win_rate": 0.8918918918918919, "step": 887}
{"time": 1767335318.245575, "phase": "train", "update": 888, "total_env_steps": 2841600, "episode_reward": 0.24066847562789917, "value_loss": 0.005457991827279329, "policy_loss": -0.0014035161096600745, "dist_entropy": 0.8245827913284302, "actor_grad_norm": 0.14861814677715302, "critic_grad_norm": 0.060382165014743805, "ratio": 1.0000228881835938, "entropy": 0.8245827913284302, "incre_win_rate": 0.9, "step": 888}
{"time": 1767335322.3687496, "phase": "train", "update": 889, "total_env_steps": 2844800, "episode_reward": 0.24336713552474976, "value_loss": 0.005434728041291237, "policy_loss": -0.0011920085336640796, "dist_entropy": 0.8226749181747437, "actor_grad_norm": 0.08611490577459335, "critic_grad_norm": 0.03578561171889305, "ratio": 0.9998340606689453, "entropy": 0.8226749181747437, "incre_win_rate": 0.926829268292683, "step": 889}
{"time": 1767335326.4771485, "phase": "train", "update": 890, "total_env_steps": 2848000, "episode_reward": 0.24456022679805756, "value_loss": 0.004877992812544108, "policy_loss": -0.0014079955605492244, "dist_entropy": 0.8182733416557312, "actor_grad_norm": 0.11061909049749374, "critic_grad_norm": 0.019231025129556656, "ratio": 0.999931275844574, "entropy": 0.8182733416557312, "incre_win_rate": 0.925, "step": 890}
{"time": 1767335330.5472515, "phase": "train", "update": 891, "total_env_steps": 2851200, "episode_reward": 0.23371276259422302, "value_loss": 0.010003788582980632, "policy_loss": -0.0010692072236992089, "dist_entropy": 0.8087174773216248, "actor_grad_norm": 0.08058705180883408, "critic_grad_norm": 0.05636030435562134, "ratio": 1.0000181198120117, "entropy": 0.8087174773216248, "incre_win_rate": 0.8421052631578947, "step": 891}
{"time": 1767335334.626127, "phase": "train", "update": 892, "total_env_steps": 2854400, "episode_reward": 0.23447486758232117, "value_loss": 0.007948827557265758, "policy_loss": -0.0019284344742864334, "dist_entropy": 0.7979186773300171, "actor_grad_norm": 0.14104478061199188, "critic_grad_norm": 0.055588867515325546, "ratio": 0.9999069571495056, "entropy": 0.7979186773300171, "incre_win_rate": 0.868421052631579, "step": 892}
{"time": 1767335338.7466195, "phase": "train", "update": 893, "total_env_steps": 2857600, "episode_reward": 0.24446192383766174, "value_loss": 0.0050392596051096914, "policy_loss": -0.0013093314725766358, "dist_entropy": 0.8161569356918335, "actor_grad_norm": 0.10906936228275299, "critic_grad_norm": 0.03775078430771828, "ratio": 1.0000938177108765, "entropy": 0.8161569356918335, "incre_win_rate": 0.926829268292683, "step": 893}
{"time": 1767335342.8744993, "phase": "train", "update": 894, "total_env_steps": 2860800, "episode_reward": 0.23775404691696167, "value_loss": 0.009261129982769489, "policy_loss": -0.0011262780253957771, "dist_entropy": 0.8271525502204895, "actor_grad_norm": 0.1043320819735527, "critic_grad_norm": 0.06772488355636597, "ratio": 1.0001283884048462, "entropy": 0.8271525502204895, "incre_win_rate": 0.8205128205128205, "step": 894}
{"time": 1767335347.0315638, "phase": "train", "update": 895, "total_env_steps": 2864000, "episode_reward": 0.24130795896053314, "value_loss": 0.006833412125706673, "policy_loss": -0.0011122464985611202, "dist_entropy": 0.8171102643013001, "actor_grad_norm": 0.08067276328802109, "critic_grad_norm": 0.03958003968000412, "ratio": 1.000033974647522, "entropy": 0.8171102643013001, "incre_win_rate": 0.875, "step": 895}
{"time": 1767335351.158582, "phase": "train", "update": 896, "total_env_steps": 2867200, "episode_reward": 0.23798790574073792, "value_loss": 0.011301254108548164, "policy_loss": -0.001339954438885238, "dist_entropy": 0.8186029434204102, "actor_grad_norm": 0.12077627331018448, "critic_grad_norm": 0.047911692410707474, "ratio": 1.000321388244629, "entropy": 0.8186029434204102, "incre_win_rate": 0.8461538461538461, "step": 896}
{"time": 1767335355.2541265, "phase": "train", "update": 897, "total_env_steps": 2870400, "episode_reward": 0.24532748758792877, "value_loss": 0.0077625088393688205, "policy_loss": -0.0014364231807221018, "dist_entropy": 0.7974768280982971, "actor_grad_norm": 0.10515832901000977, "critic_grad_norm": 0.0771065354347229, "ratio": 1.0000600814819336, "entropy": 0.7974768280982971, "incre_win_rate": 0.926829268292683, "step": 897}
{"time": 1767335359.404248, "phase": "train", "update": 898, "total_env_steps": 2873600, "episode_reward": 0.23967301845550537, "value_loss": 0.006036954745650291, "policy_loss": -0.0012511044282746298, "dist_entropy": 0.7662100076675415, "actor_grad_norm": 0.08647646009922028, "critic_grad_norm": 0.05080033466219902, "ratio": 0.9999493956565857, "entropy": 0.7662100076675415, "incre_win_rate": 0.9024390243902439, "step": 898}
{"time": 1767335363.5251548, "phase": "train", "update": 899, "total_env_steps": 2876800, "episode_reward": 0.24401956796646118, "value_loss": 0.00819284152239561, "policy_loss": -0.0009041363597862784, "dist_entropy": 0.759183919429779, "actor_grad_norm": 0.09055978059768677, "critic_grad_norm": 0.03863219544291496, "ratio": 0.9997751116752625, "entropy": 0.759183919429779, "incre_win_rate": 0.9473684210526315, "step": 899}
{"time": 1767335367.6343079, "phase": "train", "update": 900, "total_env_steps": 2880000, "episode_reward": 0.24491308629512787, "value_loss": 0.005391571018844843, "policy_loss": -0.0012343134065858409, "dist_entropy": 0.7687305808067322, "actor_grad_norm": 0.10059104114770889, "critic_grad_norm": 0.03437723591923714, "ratio": 0.9999963641166687, "entropy": 0.7687305808067322, "incre_win_rate": 0.926829268292683, "step": 900}
{"time": 1767335371.7356238, "phase": "train", "update": 901, "total_env_steps": 2883200, "episode_reward": 0.24154388904571533, "value_loss": 0.005799871031194925, "policy_loss": -0.001591815683285347, "dist_entropy": 0.7938389778137207, "actor_grad_norm": 0.12594102323055267, "critic_grad_norm": 0.024523334577679634, "ratio": 1.0000020265579224, "entropy": 0.7938389778137207, "incre_win_rate": 0.918918918918919, "step": 901}
{"time": 1767335382.3234692, "phase": "eval", "update": 901, "total_env_steps": 2883200, "eval_win_rate": 1.0, "eval_episode_reward": 20.001862582781456, "step": 901}
{"time": 1767335386.4098384, "phase": "train", "update": 902, "total_env_steps": 2886400, "episode_reward": 0.24712282419204712, "value_loss": 0.005639230366796255, "policy_loss": -0.0011936113914929436, "dist_entropy": 0.7834296226501465, "actor_grad_norm": 0.0887957513332367, "critic_grad_norm": 0.04029473289847374, "ratio": 0.9999690055847168, "entropy": 0.7834296226501465, "incre_win_rate": 0.975609756097561, "step": 902}
{"time": 1767335390.5764484, "phase": "train", "update": 903, "total_env_steps": 2889600, "episode_reward": 0.23926325142383575, "value_loss": 0.004628349281847477, "policy_loss": -0.001188421249813576, "dist_entropy": 0.8018617272377014, "actor_grad_norm": 0.07137202471494675, "critic_grad_norm": 0.025056034326553345, "ratio": 1.0002716779708862, "entropy": 0.8018617272377014, "incre_win_rate": 0.9230769230769231, "step": 903}
{"time": 1767335394.6596067, "phase": "train", "update": 904, "total_env_steps": 2892800, "episode_reward": 0.2315402626991272, "value_loss": 0.007528422027826309, "policy_loss": -0.000961871280892268, "dist_entropy": 0.7803917169570923, "actor_grad_norm": 0.08079668134450912, "critic_grad_norm": 0.03290063142776489, "ratio": 1.0002163648605347, "entropy": 0.7803917169570923, "incre_win_rate": 0.8947368421052632, "step": 904}
{"time": 1767335398.783192, "phase": "train", "update": 905, "total_env_steps": 2896000, "episode_reward": 0.23310533165931702, "value_loss": 0.00829775705933571, "policy_loss": -0.0012563288051129716, "dist_entropy": 0.771217405796051, "actor_grad_norm": 0.0886339321732521, "critic_grad_norm": 0.059292055666446686, "ratio": 1.0001486539840698, "entropy": 0.771217405796051, "incre_win_rate": 0.9, "step": 905}
{"time": 1767335402.8311086, "phase": "train", "update": 906, "total_env_steps": 2899200, "episode_reward": 0.23668046295642853, "value_loss": 0.006690641026943922, "policy_loss": -0.0013026045773273155, "dist_entropy": 0.7960698246955872, "actor_grad_norm": 0.10630974918603897, "critic_grad_norm": 0.03720119595527649, "ratio": 1.0001381635665894, "entropy": 0.7960698246955872, "incre_win_rate": 0.9166666666666666, "step": 906}
{"time": 1767335406.9186506, "phase": "train", "update": 907, "total_env_steps": 2902400, "episode_reward": 0.23236289620399475, "value_loss": 0.009244385920464993, "policy_loss": -0.001381722345319325, "dist_entropy": 0.8091771125793457, "actor_grad_norm": 0.13385950028896332, "critic_grad_norm": 0.047997985035181046, "ratio": 1.0001405477523804, "entropy": 0.8091771125793457, "incre_win_rate": 0.85, "step": 907}
{"time": 1767335411.0262663, "phase": "train", "update": 908, "total_env_steps": 2905600, "episode_reward": 0.22709490358829498, "value_loss": 0.008309351839125156, "policy_loss": -0.001573659023134688, "dist_entropy": 0.785261356830597, "actor_grad_norm": 0.08659908920526505, "critic_grad_norm": 0.06928160041570663, "ratio": 1.0002155303955078, "entropy": 0.785261356830597, "incre_win_rate": 0.8421052631578947, "step": 908}
{"time": 1767335415.1361482, "phase": "train", "update": 909, "total_env_steps": 2908800, "episode_reward": 0.236122727394104, "value_loss": 0.008075898420065642, "policy_loss": -0.0010529582911877667, "dist_entropy": 0.8004687547683715, "actor_grad_norm": 0.08571507781744003, "critic_grad_norm": 0.10608231276273727, "ratio": 0.9995889067649841, "entropy": 0.8004687547683715, "incre_win_rate": 0.9210526315789473, "step": 909}
{"time": 1767335419.2526815, "phase": "train", "update": 910, "total_env_steps": 2912000, "episode_reward": 0.23364394903182983, "value_loss": 0.00922934915870428, "policy_loss": -0.0012040168127171568, "dist_entropy": 0.7976441144943237, "actor_grad_norm": 0.10727296024560928, "critic_grad_norm": 0.07973852008581161, "ratio": 0.9995331764221191, "entropy": 0.7976441144943237, "incre_win_rate": 0.8461538461538461, "step": 910}
{"time": 1767335423.342678, "phase": "train", "update": 911, "total_env_steps": 2915200, "episode_reward": 0.23581281304359436, "value_loss": 0.009210505709052085, "policy_loss": -0.0012166280497639902, "dist_entropy": 0.8221587181091309, "actor_grad_norm": 0.11752881854772568, "critic_grad_norm": 0.05377197265625, "ratio": 1.000102162361145, "entropy": 0.8221587181091309, "incre_win_rate": 0.875, "step": 911}
{"time": 1767335427.4599142, "phase": "train", "update": 912, "total_env_steps": 2918400, "episode_reward": 0.24217766523361206, "value_loss": 0.008144565485417843, "policy_loss": -0.0008289529227607062, "dist_entropy": 0.822739577293396, "actor_grad_norm": 0.12950865924358368, "critic_grad_norm": 0.03733929991722107, "ratio": 0.9996434450149536, "entropy": 0.822739577293396, "incre_win_rate": 0.9024390243902439, "step": 912}
{"time": 1767335431.6125383, "phase": "train", "update": 913, "total_env_steps": 2921600, "episode_reward": 0.2420317828655243, "value_loss": 0.006838389206677675, "policy_loss": -0.0011886819390340975, "dist_entropy": 0.8333342432975769, "actor_grad_norm": 0.11022956669330597, "critic_grad_norm": 0.03292830288410187, "ratio": 0.9997677206993103, "entropy": 0.8333342432975769, "incre_win_rate": 0.9473684210526315, "step": 913}
{"time": 1767335435.720253, "phase": "train", "update": 914, "total_env_steps": 2924800, "episode_reward": 0.2363695204257965, "value_loss": 0.0042979509569704534, "policy_loss": -0.0012394041612976635, "dist_entropy": 0.852371084690094, "actor_grad_norm": 0.10680543631315231, "critic_grad_norm": 0.02838440239429474, "ratio": 1.0003080368041992, "entropy": 0.852371084690094, "incre_win_rate": 0.9473684210526315, "step": 914}
{"time": 1767335439.854813, "phase": "train", "update": 915, "total_env_steps": 2928000, "episode_reward": 0.24163027107715607, "value_loss": 0.0042527875863015655, "policy_loss": -0.0011257071327587908, "dist_entropy": 0.8334261536598205, "actor_grad_norm": 0.10380206257104874, "critic_grad_norm": 0.038820184767246246, "ratio": 0.9999961853027344, "entropy": 0.8334261536598205, "incre_win_rate": 0.975, "step": 915}
{"time": 1767335443.9771934, "phase": "train", "update": 916, "total_env_steps": 2931200, "episode_reward": 0.23909352719783783, "value_loss": 0.004107547923922539, "policy_loss": -0.0013280930096236433, "dist_entropy": 0.8688116431236267, "actor_grad_norm": 0.12383506447076797, "critic_grad_norm": 0.02233436144888401, "ratio": 0.9999077916145325, "entropy": 0.8688116431236267, "incre_win_rate": 0.9487179487179487, "step": 916}
{"time": 1767335448.0805972, "phase": "train", "update": 917, "total_env_steps": 2934400, "episode_reward": 0.22945261001586914, "value_loss": 0.010438157059252263, "policy_loss": -0.0013167647394476845, "dist_entropy": 0.8336520552635193, "actor_grad_norm": 0.08518370240926743, "critic_grad_norm": 0.11899299919605255, "ratio": 0.9996790885925293, "entropy": 0.8336520552635193, "incre_win_rate": 0.7692307692307693, "step": 917}
{"time": 1767335452.221298, "phase": "train", "update": 918, "total_env_steps": 2937600, "episode_reward": 0.22586971521377563, "value_loss": 0.0088064044713974, "policy_loss": -0.001247730614240794, "dist_entropy": 0.8513076186180115, "actor_grad_norm": 0.09628033638000488, "critic_grad_norm": 0.05291309580206871, "ratio": 0.9998776316642761, "entropy": 0.8513076186180115, "incre_win_rate": 0.8648648648648649, "step": 918}
{"time": 1767335456.2644045, "phase": "train", "update": 919, "total_env_steps": 2940800, "episode_reward": 0.22828644514083862, "value_loss": 0.008484286814928054, "policy_loss": -0.001416441127067003, "dist_entropy": 0.8455300331115723, "actor_grad_norm": 0.10903065651655197, "critic_grad_norm": 0.03510630130767822, "ratio": 1.000303030014038, "entropy": 0.8455300331115723, "incre_win_rate": 0.8974358974358975, "step": 919}
{"time": 1767335460.3600962, "phase": "train", "update": 920, "total_env_steps": 2944000, "episode_reward": 0.23802980780601501, "value_loss": 0.006718770135194063, "policy_loss": -0.0016190735155531932, "dist_entropy": 0.835778534412384, "actor_grad_norm": 0.11763457208871841, "critic_grad_norm": 0.03410835191607475, "ratio": 1.000150203704834, "entropy": 0.835778534412384, "incre_win_rate": 0.918918918918919, "step": 920}
{"time": 1767335464.4614506, "phase": "train", "update": 921, "total_env_steps": 2947200, "episode_reward": 0.23043979704380035, "value_loss": 0.008519862964749336, "policy_loss": -0.001177673899969278, "dist_entropy": 0.8185625195503234, "actor_grad_norm": 0.11943487077951431, "critic_grad_norm": 0.03009500913321972, "ratio": 1.0000412464141846, "entropy": 0.8185625195503234, "incre_win_rate": 0.825, "step": 921}
{"time": 1767335468.5669084, "phase": "train", "update": 922, "total_env_steps": 2950400, "episode_reward": 0.23885193467140198, "value_loss": 0.007341173849999905, "policy_loss": -0.0012274935223793193, "dist_entropy": 0.8175786375999451, "actor_grad_norm": 0.12857110798358917, "critic_grad_norm": 0.06422276049852371, "ratio": 0.9997976422309875, "entropy": 0.8175786375999451, "incre_win_rate": 0.9230769230769231, "step": 922}
{"time": 1767335472.7551355, "phase": "train", "update": 923, "total_env_steps": 2953600, "episode_reward": 0.24797183275222778, "value_loss": 0.00465762298554182, "policy_loss": -0.0013819323633802228, "dist_entropy": 0.8429296493530274, "actor_grad_norm": 0.09389772266149521, "critic_grad_norm": 0.046238481998443604, "ratio": 1.0003820657730103, "entropy": 0.8429296493530274, "incre_win_rate": 0.95, "step": 923}
{"time": 1767335476.8716793, "phase": "train", "update": 924, "total_env_steps": 2956800, "episode_reward": 0.2258324772119522, "value_loss": 0.008405296877026559, "policy_loss": -0.0011508762540287875, "dist_entropy": 0.8575261116027832, "actor_grad_norm": 0.10956541448831558, "critic_grad_norm": 0.08767471462488174, "ratio": 0.9998126029968262, "entropy": 0.8575261116027832, "incre_win_rate": 0.9210526315789473, "step": 924}
{"time": 1767335480.9849162, "phase": "train", "update": 925, "total_env_steps": 2960000, "episode_reward": 0.23821710050106049, "value_loss": 0.007090182974934578, "policy_loss": -0.0014460535392572637, "dist_entropy": 0.846583890914917, "actor_grad_norm": 0.09423726052045822, "critic_grad_norm": 0.030053112655878067, "ratio": 0.9996824264526367, "entropy": 0.846583890914917, "incre_win_rate": 0.8947368421052632, "step": 925}
{"time": 1767335485.071819, "phase": "train", "update": 926, "total_env_steps": 2963200, "episode_reward": 0.23429790139198303, "value_loss": 0.008131694607436657, "policy_loss": -0.0011994013617879773, "dist_entropy": 0.85441654920578, "actor_grad_norm": 0.07490431517362595, "critic_grad_norm": 0.02299513667821884, "ratio": 0.999940037727356, "entropy": 0.85441654920578, "incre_win_rate": 0.8648648648648649, "step": 926}
{"time": 1767335495.5890572, "phase": "eval", "update": 926, "total_env_steps": 2963200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.888348509933774, "step": 926}
{"time": 1767335499.6929336, "phase": "train", "update": 927, "total_env_steps": 2966400, "episode_reward": 0.23372620344161987, "value_loss": 0.008699568174779414, "policy_loss": -0.0013271094311761544, "dist_entropy": 0.8270285964012146, "actor_grad_norm": 0.09209110587835312, "critic_grad_norm": 0.026177698746323586, "ratio": 0.9998494386672974, "entropy": 0.8270285964012146, "incre_win_rate": 0.875, "step": 927}
{"time": 1767335503.8136072, "phase": "train", "update": 928, "total_env_steps": 2969600, "episode_reward": 0.23889073729515076, "value_loss": 0.005970663018524646, "policy_loss": -0.0012408426826652885, "dist_entropy": 0.8510496497154236, "actor_grad_norm": 0.0917246863245964, "critic_grad_norm": 0.06037352234125137, "ratio": 1.0001157522201538, "entropy": 0.8510496497154236, "incre_win_rate": 0.8918918918918919, "step": 928}
{"time": 1767335507.9119124, "phase": "train", "update": 929, "total_env_steps": 2972800, "episode_reward": 0.23168925940990448, "value_loss": 0.009440013952553273, "policy_loss": -0.0012154342508040373, "dist_entropy": 0.8577164649963379, "actor_grad_norm": 0.11379418522119522, "critic_grad_norm": 0.036787889897823334, "ratio": 0.9995875358581543, "entropy": 0.8577164649963379, "incre_win_rate": 0.8205128205128205, "step": 929}
{"time": 1767335511.9682178, "phase": "train", "update": 930, "total_env_steps": 2976000, "episode_reward": 0.2303052544593811, "value_loss": 0.006981470994651318, "policy_loss": -0.0013320541042865842, "dist_entropy": 0.8308294177055359, "actor_grad_norm": 0.11480380594730377, "critic_grad_norm": 0.020070472732186317, "ratio": 0.9997480511665344, "entropy": 0.8308294177055359, "incre_win_rate": 0.825, "step": 930}
{"time": 1767335516.0478096, "phase": "train", "update": 931, "total_env_steps": 2979200, "episode_reward": 0.23641298711299896, "value_loss": 0.007485131546854973, "policy_loss": -0.001657594435530285, "dist_entropy": 0.8625229358673095, "actor_grad_norm": 0.09422772377729416, "critic_grad_norm": 0.0395716093480587, "ratio": 0.999781608581543, "entropy": 0.8625229358673095, "incre_win_rate": 0.8717948717948718, "step": 931}
{"time": 1767335520.1133611, "phase": "train", "update": 932, "total_env_steps": 2982400, "episode_reward": 0.23338006436824799, "value_loss": 0.005154521390795708, "policy_loss": -0.0011944121285068833, "dist_entropy": 0.8269641757011413, "actor_grad_norm": 0.094325952231884, "critic_grad_norm": 0.02899818681180477, "ratio": 0.9999682307243347, "entropy": 0.8269641757011413, "incre_win_rate": 0.8947368421052632, "step": 932}
{"time": 1767335524.1598651, "phase": "train", "update": 933, "total_env_steps": 2985600, "episode_reward": 0.23461973667144775, "value_loss": 0.0064687375910580155, "policy_loss": -0.0011242726853623708, "dist_entropy": 0.8257523536682129, "actor_grad_norm": 0.09591473639011383, "critic_grad_norm": 0.024289995431900024, "ratio": 1.000040054321289, "entropy": 0.8257523536682129, "incre_win_rate": 0.8974358974358975, "step": 933}
{"time": 1767335528.2802315, "phase": "train", "update": 934, "total_env_steps": 2988800, "episode_reward": 0.23984375596046448, "value_loss": 0.007717022392898798, "policy_loss": -0.001419647518616518, "dist_entropy": 0.8234675765037537, "actor_grad_norm": 0.12468993663787842, "critic_grad_norm": 0.02672685496509075, "ratio": 1.0000518560409546, "entropy": 0.8234675765037537, "incre_win_rate": 0.875, "step": 934}
{"time": 1767335532.428164, "phase": "train", "update": 935, "total_env_steps": 2992000, "episode_reward": 0.2409105896949768, "value_loss": 0.006918470282107592, "policy_loss": -0.0014833063745619767, "dist_entropy": 0.8112282276153564, "actor_grad_norm": 0.12069638818502426, "critic_grad_norm": 0.04041460156440735, "ratio": 1.0001640319824219, "entropy": 0.8112282276153564, "incre_win_rate": 0.9230769230769231, "step": 935}
{"time": 1767335536.4838483, "phase": "train", "update": 936, "total_env_steps": 2995200, "episode_reward": 0.23351770639419556, "value_loss": 0.005589692760258913, "policy_loss": -0.00094117726078764, "dist_entropy": 0.8287053227424621, "actor_grad_norm": 0.0998409241437912, "critic_grad_norm": 0.023339224979281425, "ratio": 0.9998915791511536, "entropy": 0.8287053227424621, "incre_win_rate": 0.9230769230769231, "step": 936}
{"time": 1767335540.5793564, "phase": "train", "update": 937, "total_env_steps": 2998400, "episode_reward": 0.22939777374267578, "value_loss": 0.008870167657732964, "policy_loss": -0.0013348444365504975, "dist_entropy": 0.8326706647872925, "actor_grad_norm": 0.10951105505228043, "critic_grad_norm": 0.07516655325889587, "ratio": 1.0001376867294312, "entropy": 0.8326706647872925, "incre_win_rate": 0.8378378378378378, "step": 937}
{"time": 1767335544.6626122, "phase": "train", "update": 938, "total_env_steps": 3001600, "episode_reward": 0.23455141484737396, "value_loss": 0.009287386573851109, "policy_loss": -0.001199837563328998, "dist_entropy": 0.8524917364120483, "actor_grad_norm": 0.11288907378911972, "critic_grad_norm": 0.05226407200098038, "ratio": 0.9999329447746277, "entropy": 0.8524917364120483, "incre_win_rate": 0.825, "step": 938}
{"time": 1767335548.7688158, "phase": "train", "update": 939, "total_env_steps": 3004800, "episode_reward": 0.23475271463394165, "value_loss": 0.009780487790703774, "policy_loss": -0.0009876574345369705, "dist_entropy": 0.8603652358055115, "actor_grad_norm": 0.09185297787189484, "critic_grad_norm": 0.04450012370944023, "ratio": 0.9996615648269653, "entropy": 0.8603652358055115, "incre_win_rate": 0.9230769230769231, "step": 939}
{"time": 1767335552.8521051, "phase": "train", "update": 940, "total_env_steps": 3008000, "episode_reward": 0.2269991934299469, "value_loss": 0.009671477228403091, "policy_loss": -0.0011222121965452914, "dist_entropy": 0.8765057325363159, "actor_grad_norm": 0.08134573698043823, "critic_grad_norm": 0.042281873524188995, "ratio": 1.0002381801605225, "entropy": 0.8765057325363159, "incre_win_rate": 0.8157894736842105, "step": 940}
{"time": 1767335556.9177105, "phase": "train", "update": 941, "total_env_steps": 3011200, "episode_reward": 0.22185584902763367, "value_loss": 0.009556337259709835, "policy_loss": -0.0014766633899718328, "dist_entropy": 0.8957033753395081, "actor_grad_norm": 0.09503892064094543, "critic_grad_norm": 0.022551260888576508, "ratio": 0.9998588562011719, "entropy": 0.8957033753395081, "incre_win_rate": 0.868421052631579, "step": 941}
{"time": 1767335560.9879527, "phase": "train", "update": 942, "total_env_steps": 3014400, "episode_reward": 0.22409921884536743, "value_loss": 0.012021610140800476, "policy_loss": -0.0014655663222768566, "dist_entropy": 0.8662229776382446, "actor_grad_norm": 0.10983574390411377, "critic_grad_norm": 0.03361739218235016, "ratio": 0.9995548129081726, "entropy": 0.8662229776382446, "incre_win_rate": 0.7435897435897436, "step": 942}
{"time": 1767335565.0332537, "phase": "train", "update": 943, "total_env_steps": 3017600, "episode_reward": 0.2202586978673935, "value_loss": 0.015115218050777913, "policy_loss": -0.0011476439811474392, "dist_entropy": 0.8698115348815918, "actor_grad_norm": 0.09480663388967514, "critic_grad_norm": 0.04871074855327606, "ratio": 0.9999856352806091, "entropy": 0.8698115348815918, "incre_win_rate": 0.7435897435897436, "step": 943}
{"time": 1767335569.1246376, "phase": "train", "update": 944, "total_env_steps": 3020800, "episode_reward": 0.23028406500816345, "value_loss": 0.010536609403789043, "policy_loss": -0.0012849369567542012, "dist_entropy": 0.8699225068092347, "actor_grad_norm": 0.11045024544000626, "critic_grad_norm": 0.05157160758972168, "ratio": 0.9996867179870605, "entropy": 0.8699225068092347, "incre_win_rate": 0.8888888888888888, "step": 944}
{"time": 1767335573.2048228, "phase": "train", "update": 945, "total_env_steps": 3024000, "episode_reward": 0.23407180607318878, "value_loss": 0.007178162969648838, "policy_loss": -0.0017479116896303992, "dist_entropy": 0.8954222679138184, "actor_grad_norm": 0.11439740657806396, "critic_grad_norm": 0.12722466886043549, "ratio": 0.9991376996040344, "entropy": 0.8954222679138184, "incre_win_rate": 0.9210526315789473, "step": 945}
{"time": 1767335577.2312489, "phase": "train", "update": 946, "total_env_steps": 3027200, "episode_reward": 0.2192399799823761, "value_loss": 0.011805403605103492, "policy_loss": -0.0013052012745918163, "dist_entropy": 0.8744166374206543, "actor_grad_norm": 0.09041240066289902, "critic_grad_norm": 0.10333063453435898, "ratio": 0.9999917149543762, "entropy": 0.8744166374206543, "incre_win_rate": 0.8, "step": 946}
{"time": 1767335581.3025897, "phase": "train", "update": 947, "total_env_steps": 3030400, "episode_reward": 0.23810845613479614, "value_loss": 0.00792608167976141, "policy_loss": -0.0014899437214516808, "dist_entropy": 0.8969957113265992, "actor_grad_norm": 0.11480440944433212, "critic_grad_norm": 0.08080265671014786, "ratio": 0.9998975992202759, "entropy": 0.8969957113265992, "incre_win_rate": 0.9166666666666666, "step": 947}
{"time": 1767335585.3499293, "phase": "train", "update": 948, "total_env_steps": 3033600, "episode_reward": 0.22802774608135223, "value_loss": 0.006315286923199892, "policy_loss": -0.0013830105329571297, "dist_entropy": 0.9107039093971252, "actor_grad_norm": 0.10944097489118576, "critic_grad_norm": 0.05950913578271866, "ratio": 0.999811589717865, "entropy": 0.9107039093971252, "incre_win_rate": 0.9210526315789473, "step": 948}
{"time": 1767335589.4155111, "phase": "train", "update": 949, "total_env_steps": 3036800, "episode_reward": 0.2296936959028244, "value_loss": 0.00723307803273201, "policy_loss": -0.0014989169370792864, "dist_entropy": 0.8872589230537414, "actor_grad_norm": 0.0943531021475792, "critic_grad_norm": 0.05517232418060303, "ratio": 0.9997988939285278, "entropy": 0.8872589230537414, "incre_win_rate": 0.8205128205128205, "step": 949}
{"time": 1767335593.5323195, "phase": "train", "update": 950, "total_env_steps": 3040000, "episode_reward": 0.24341991543769836, "value_loss": 0.007658936455845833, "policy_loss": -0.0013980164206671476, "dist_entropy": 0.8795238971710205, "actor_grad_norm": 0.11470475047826767, "critic_grad_norm": 0.06521753966808319, "ratio": 1.0000582933425903, "entropy": 0.8795238971710205, "incre_win_rate": 0.9230769230769231, "step": 950}
{"time": 1767335597.6052544, "phase": "train", "update": 951, "total_env_steps": 3043200, "episode_reward": 0.23090438544750214, "value_loss": 0.009921034798026085, "policy_loss": -0.0009589752385963379, "dist_entropy": 0.8750337719917297, "actor_grad_norm": 0.10343080759048462, "critic_grad_norm": 0.07125880569219589, "ratio": 1.0003036260604858, "entropy": 0.8750337719917297, "incre_win_rate": 0.8, "step": 951}
{"time": 1767335608.658996, "phase": "eval", "update": 951, "total_env_steps": 3043200, "eval_win_rate": 0.875, "eval_episode_reward": 19.442363410596027, "step": 951}
{"time": 1767335612.722823, "phase": "train", "update": 952, "total_env_steps": 3046400, "episode_reward": 0.240219384431839, "value_loss": 0.006125559564679861, "policy_loss": -0.0010955432733048553, "dist_entropy": 0.9027045130729675, "actor_grad_norm": 0.10195743292570114, "critic_grad_norm": 0.02239058166742325, "ratio": 1.0002844333648682, "entropy": 0.9027045130729675, "incre_win_rate": 0.9, "step": 952}
{"time": 1767335616.7643611, "phase": "train", "update": 953, "total_env_steps": 3049600, "episode_reward": 0.229967400431633, "value_loss": 0.012645946815609932, "policy_loss": -0.0013420275928076818, "dist_entropy": 0.8866878747940063, "actor_grad_norm": 0.09934208542108536, "critic_grad_norm": 0.08799970895051956, "ratio": 1.0001091957092285, "entropy": 0.8866878747940063, "incre_win_rate": 0.7894736842105263, "step": 953}
{"time": 1767335620.8172245, "phase": "train", "update": 954, "total_env_steps": 3052800, "episode_reward": 0.22769194841384888, "value_loss": 0.01164568103849888, "policy_loss": -0.0012359670120801526, "dist_entropy": 0.8890851378440857, "actor_grad_norm": 0.10974782705307007, "critic_grad_norm": 0.058287858963012695, "ratio": 0.9997722506523132, "entropy": 0.8890851378440857, "incre_win_rate": 0.8157894736842105, "step": 954}
{"time": 1767335624.8692324, "phase": "train", "update": 955, "total_env_steps": 3056000, "episode_reward": 0.22116981446743011, "value_loss": 0.01095571331679821, "policy_loss": -0.0014879222163749263, "dist_entropy": 0.8777214765548706, "actor_grad_norm": 0.10901270061731339, "critic_grad_norm": 0.0431557297706604, "ratio": 1.0003445148468018, "entropy": 0.8777214765548706, "incre_win_rate": 0.7, "step": 955}
{"time": 1767335628.888728, "phase": "train", "update": 956, "total_env_steps": 3059200, "episode_reward": 0.22339557111263275, "value_loss": 0.009232834726572037, "policy_loss": -0.0017729322690636096, "dist_entropy": 0.8482466101646423, "actor_grad_norm": 0.0928453877568245, "critic_grad_norm": 0.07076413929462433, "ratio": 0.9999967813491821, "entropy": 0.8482466101646423, "incre_win_rate": 0.7941176470588235, "step": 956}
{"time": 1767335632.986291, "phase": "train", "update": 957, "total_env_steps": 3062400, "episode_reward": 0.22976459562778473, "value_loss": 0.011982288770377636, "policy_loss": -0.001376096512388969, "dist_entropy": 0.8172877669334412, "actor_grad_norm": 0.10144052654504776, "critic_grad_norm": 0.07846876233816147, "ratio": 1.0002936124801636, "entropy": 0.8172877669334412, "incre_win_rate": 0.8048780487804879, "step": 957}
{"time": 1767335637.0587976, "phase": "train", "update": 958, "total_env_steps": 3065600, "episode_reward": 0.22862686216831207, "value_loss": 0.011962463520467282, "policy_loss": -0.0010454217510045716, "dist_entropy": 0.8214434623718262, "actor_grad_norm": 0.08705585449934006, "critic_grad_norm": 0.08849195390939713, "ratio": 0.9999737739562988, "entropy": 0.8214434623718262, "incre_win_rate": 0.7948717948717948, "step": 958}
{"time": 1767335641.1482038, "phase": "train", "update": 959, "total_env_steps": 3068800, "episode_reward": 0.2289791852235794, "value_loss": 0.012794079817831516, "policy_loss": -0.0011742359431092808, "dist_entropy": 0.7967909455299378, "actor_grad_norm": 0.08396218717098236, "critic_grad_norm": 0.0736786350607872, "ratio": 0.9998607635498047, "entropy": 0.7967909455299378, "incre_win_rate": 0.7948717948717948, "step": 959}
{"time": 1767335645.249769, "phase": "train", "update": 960, "total_env_steps": 3072000, "episode_reward": 0.24933671951293945, "value_loss": 0.006658748723566532, "policy_loss": -0.0011528486865550747, "dist_entropy": 0.8503332734107971, "actor_grad_norm": 0.08603281527757645, "critic_grad_norm": 0.12057469040155411, "ratio": 1.000428318977356, "entropy": 0.8503332734107971, "incre_win_rate": 0.9, "step": 960}
{"time": 1767335649.329032, "phase": "train", "update": 961, "total_env_steps": 3075200, "episode_reward": 0.23976925015449524, "value_loss": 0.009078583493828774, "policy_loss": -0.0011868287523221, "dist_entropy": 0.8276286005973816, "actor_grad_norm": 0.09355007112026215, "critic_grad_norm": 0.090829998254776, "ratio": 1.0002716779708862, "entropy": 0.8276286005973816, "incre_win_rate": 0.875, "step": 961}
{"time": 1767335653.4812577, "phase": "train", "update": 962, "total_env_steps": 3078400, "episode_reward": 0.23903614282608032, "value_loss": 0.008465592749416828, "policy_loss": -0.00142115202775841, "dist_entropy": 0.821453309059143, "actor_grad_norm": 0.09961090981960297, "critic_grad_norm": 0.0725247710943222, "ratio": 0.9996687173843384, "entropy": 0.821453309059143, "incre_win_rate": 0.85, "step": 962}
{"time": 1767335657.5891767, "phase": "train", "update": 963, "total_env_steps": 3081600, "episode_reward": 0.23888036608695984, "value_loss": 0.010044729895889759, "policy_loss": -0.0011741987169941125, "dist_entropy": 0.8269060254096985, "actor_grad_norm": 0.08250030875205994, "critic_grad_norm": 0.07010689377784729, "ratio": 1.000067114830017, "entropy": 0.8269060254096985, "incre_win_rate": 0.825, "step": 963}
{"time": 1767335661.6836824, "phase": "train", "update": 964, "total_env_steps": 3084800, "episode_reward": 0.23924566805362701, "value_loss": 0.011014130339026451, "policy_loss": -0.001216114345809416, "dist_entropy": 0.827780020236969, "actor_grad_norm": 0.07728590071201324, "critic_grad_norm": 0.06122769042849541, "ratio": 0.9998165965080261, "entropy": 0.827780020236969, "incre_win_rate": 0.8, "step": 964}
{"time": 1767335665.7856367, "phase": "train", "update": 965, "total_env_steps": 3088000, "episode_reward": 0.23752537369728088, "value_loss": 0.012560606747865678, "policy_loss": -0.001176032276838157, "dist_entropy": 0.8453463435173034, "actor_grad_norm": 0.10905414819717407, "critic_grad_norm": 0.04564814269542694, "ratio": 1.0001782178878784, "entropy": 0.8453463435173034, "incre_win_rate": 0.825, "step": 965}
{"time": 1767335669.8522148, "phase": "train", "update": 966, "total_env_steps": 3091200, "episode_reward": 0.2406301647424698, "value_loss": 0.010967716947197914, "policy_loss": -0.0016729375681663328, "dist_entropy": 0.8271791338920593, "actor_grad_norm": 0.11123842000961304, "critic_grad_norm": 0.02937554381787777, "ratio": 0.9997852444648743, "entropy": 0.8271791338920593, "incre_win_rate": 0.8571428571428571, "step": 966}
{"time": 1767335673.9680665, "phase": "train", "update": 967, "total_env_steps": 3094400, "episode_reward": 0.24699607491493225, "value_loss": 0.009912715665996075, "policy_loss": -0.0012680851670575422, "dist_entropy": 0.7878577828407287, "actor_grad_norm": 0.09647645056247711, "critic_grad_norm": 0.03306714817881584, "ratio": 1.000045657157898, "entropy": 0.7878577828407287, "incre_win_rate": 0.8536585365853658, "step": 967}
{"time": 1767335678.0860767, "phase": "train", "update": 968, "total_env_steps": 3097600, "episode_reward": 0.2440650910139084, "value_loss": 0.007349543739110231, "policy_loss": -0.0008779423240156348, "dist_entropy": 0.786908757686615, "actor_grad_norm": 0.08844789117574692, "critic_grad_norm": 0.021960586309432983, "ratio": 0.9993367195129395, "entropy": 0.786908757686615, "incre_win_rate": 0.9, "step": 968}
{"time": 1767335682.1966338, "phase": "train", "update": 969, "total_env_steps": 3100800, "episode_reward": 0.246816024184227, "value_loss": 0.006859920825809241, "policy_loss": -0.0010718642063345385, "dist_entropy": 0.7974740624427795, "actor_grad_norm": 0.08805369585752487, "critic_grad_norm": 0.0513688325881958, "ratio": 0.9997696280479431, "entropy": 0.7974740624427795, "incre_win_rate": 0.8780487804878049, "step": 969}
{"time": 1767335686.2646194, "phase": "train", "update": 970, "total_env_steps": 3104000, "episode_reward": 0.2426055520772934, "value_loss": 0.009698281250894069, "policy_loss": -0.001823587820487127, "dist_entropy": 0.7990297555923462, "actor_grad_norm": 0.10107354074716568, "critic_grad_norm": 0.031004954129457474, "ratio": 0.9997923970222473, "entropy": 0.7990297555923462, "incre_win_rate": 0.8717948717948718, "step": 970}
{"time": 1767335690.3444505, "phase": "train", "update": 971, "total_env_steps": 3107200, "episode_reward": 0.23380380868911743, "value_loss": 0.010248767398297786, "policy_loss": -0.0014417024183918103, "dist_entropy": 0.8032938241958618, "actor_grad_norm": 0.10036315768957138, "critic_grad_norm": 0.044682037085294724, "ratio": 1.0005704164505005, "entropy": 0.8032938241958618, "incre_win_rate": 0.8292682926829268, "step": 971}
{"time": 1767335694.401115, "phase": "train", "update": 972, "total_env_steps": 3110400, "episode_reward": 0.22698469460010529, "value_loss": 0.011238253489136697, "policy_loss": -0.0016127358598403418, "dist_entropy": 0.8000282406806946, "actor_grad_norm": 0.10615447908639908, "critic_grad_norm": 0.025518236681818962, "ratio": 0.9996734857559204, "entropy": 0.8000282406806946, "incre_win_rate": 0.717948717948718, "step": 972}
{"time": 1767335698.4283419, "phase": "train", "update": 973, "total_env_steps": 3113600, "episode_reward": 0.21982616186141968, "value_loss": 0.012939845211803913, "policy_loss": -0.001436924141742324, "dist_entropy": 0.7714842081069946, "actor_grad_norm": 0.09489252418279648, "critic_grad_norm": 0.0848003700375557, "ratio": 0.999860942363739, "entropy": 0.7714842081069946, "incre_win_rate": 0.717948717948718, "step": 973}
{"time": 1767335702.519454, "phase": "train", "update": 974, "total_env_steps": 3116800, "episode_reward": 0.2186361849308014, "value_loss": 0.011288545653223991, "policy_loss": -0.001453080982270194, "dist_entropy": 0.7857141017913818, "actor_grad_norm": 0.11942016333341599, "critic_grad_norm": 0.08189600706100464, "ratio": 1.000221848487854, "entropy": 0.7857141017913818, "incre_win_rate": 0.7567567567567568, "step": 974}
{"time": 1767335706.5972047, "phase": "train", "update": 975, "total_env_steps": 3120000, "episode_reward": 0.2349373996257782, "value_loss": 0.010796444304287434, "policy_loss": -0.0014198070177114275, "dist_entropy": 0.7966667890548706, "actor_grad_norm": 0.11936306953430176, "critic_grad_norm": 0.06175509840250015, "ratio": 0.9996946454048157, "entropy": 0.7966667890548706, "incre_win_rate": 0.8421052631578947, "step": 975}
{"time": 1767335710.6465518, "phase": "train", "update": 976, "total_env_steps": 3123200, "episode_reward": 0.2264559417963028, "value_loss": 0.011609980091452598, "policy_loss": -0.0013756234856089123, "dist_entropy": 0.7829717874526978, "actor_grad_norm": 0.13465118408203125, "critic_grad_norm": 0.0547303631901741, "ratio": 1.0001651048660278, "entropy": 0.7829717874526978, "incre_win_rate": 0.7948717948717948, "step": 976}
{"time": 1767335721.0705807, "phase": "eval", "update": 976, "total_env_steps": 3123200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.66887417218543, "step": 976}
{"time": 1767335725.0935605, "phase": "train", "update": 977, "total_env_steps": 3126400, "episode_reward": 0.2296823263168335, "value_loss": 0.009917114116251468, "policy_loss": -0.0015323035408034257, "dist_entropy": 0.7710716009140015, "actor_grad_norm": 0.11606524139642715, "critic_grad_norm": 0.08749502897262573, "ratio": 0.9999379515647888, "entropy": 0.7710716009140015, "incre_win_rate": 0.8157894736842105, "step": 977}
{"time": 1767335729.1920297, "phase": "train", "update": 978, "total_env_steps": 3129600, "episode_reward": 0.2434561401605606, "value_loss": 0.008442441746592522, "policy_loss": -0.001354181164086299, "dist_entropy": 0.8009842514991761, "actor_grad_norm": 0.08593696355819702, "critic_grad_norm": 0.053755927830934525, "ratio": 1.0002812147140503, "entropy": 0.8009842514991761, "incre_win_rate": 0.8780487804878049, "step": 978}
{"time": 1767335733.3107402, "phase": "train", "update": 979, "total_env_steps": 3132800, "episode_reward": 0.24337075650691986, "value_loss": 0.009518893994390964, "policy_loss": -0.001141277108679617, "dist_entropy": 0.7992025494575501, "actor_grad_norm": 0.08256649971008301, "critic_grad_norm": 0.05942096188664436, "ratio": 1.000239610671997, "entropy": 0.7992025494575501, "incre_win_rate": 0.8717948717948718, "step": 979}
{"time": 1767335737.389323, "phase": "train", "update": 980, "total_env_steps": 3136000, "episode_reward": 0.23479251563549042, "value_loss": 0.012174983508884907, "policy_loss": -0.0011551453500587173, "dist_entropy": 0.7774865508079529, "actor_grad_norm": 0.0936858132481575, "critic_grad_norm": 0.07216890901327133, "ratio": 0.9999322891235352, "entropy": 0.7774865508079529, "incre_win_rate": 0.8048780487804879, "step": 980}
{"time": 1767335770.6189866, "phase": "train", "update": 981, "total_env_steps": 3139200, "episode_reward": 0.22165563702583313, "value_loss": 0.057326199114322664, "policy_loss": -0.000625372089761278, "dist_entropy": 0.7978586792945862, "actor_grad_norm": 0.07887912541627884, "critic_grad_norm": 0.21667344868183136, "ratio": 1.000252604484558, "entropy": 0.7978586792945862, "incre_win_rate": 0.8055555555555556, "step": 981}
{"time": 1767335774.7375655, "phase": "train", "update": 982, "total_env_steps": 3142400, "episode_reward": 0.23849493265151978, "value_loss": 0.008564615063369274, "policy_loss": -0.0011709791500418732, "dist_entropy": 0.8140079259872437, "actor_grad_norm": 0.09234952926635742, "critic_grad_norm": 0.1157657653093338, "ratio": 1.0000295639038086, "entropy": 0.8140079259872437, "incre_win_rate": 0.8205128205128205, "step": 982}
{"time": 1767335778.7496395, "phase": "train", "update": 983, "total_env_steps": 3145600, "episode_reward": 0.2328321486711502, "value_loss": 0.00803478928282857, "policy_loss": -0.001563812227200856, "dist_entropy": 0.7875691533088685, "actor_grad_norm": 0.08010685443878174, "critic_grad_norm": 0.08454760164022446, "ratio": 0.9997879266738892, "entropy": 0.7875691533088685, "incre_win_rate": 0.868421052631579, "step": 983}
{"time": 1767335782.8825247, "phase": "train", "update": 984, "total_env_steps": 3148800, "episode_reward": 0.23867550492286682, "value_loss": 0.007093733362853527, "policy_loss": -0.0012375903296501178, "dist_entropy": 0.801779854297638, "actor_grad_norm": 0.07918524742126465, "critic_grad_norm": 0.07996681332588196, "ratio": 0.9998378157615662, "entropy": 0.801779854297638, "incre_win_rate": 0.9, "step": 984}
{"time": 1767335786.886815, "phase": "train", "update": 985, "total_env_steps": 3152000, "episode_reward": 0.23482461273670197, "value_loss": 0.009768140129745006, "policy_loss": -0.001087083596337024, "dist_entropy": 0.776513421535492, "actor_grad_norm": 0.0958179235458374, "critic_grad_norm": 0.08521213382482529, "ratio": 0.9998027086257935, "entropy": 0.776513421535492, "incre_win_rate": 0.8157894736842105, "step": 985}
{"time": 1767335790.9503403, "phase": "train", "update": 986, "total_env_steps": 3155200, "episode_reward": 0.22598354518413544, "value_loss": 0.011519827134907245, "policy_loss": -0.001053913928874195, "dist_entropy": 0.782100522518158, "actor_grad_norm": 0.1177033931016922, "critic_grad_norm": 0.08129560947418213, "ratio": 1.0000137090682983, "entropy": 0.782100522518158, "incre_win_rate": 0.7560975609756098, "step": 986}
{"time": 1767335794.9660015, "phase": "train", "update": 987, "total_env_steps": 3158400, "episode_reward": 0.22065812349319458, "value_loss": 0.014250032417476178, "policy_loss": -0.0008548819139136299, "dist_entropy": 0.7663234591484069, "actor_grad_norm": 0.11850389093160629, "critic_grad_norm": 0.0634959265589714, "ratio": 0.9997936487197876, "entropy": 0.7663234591484069, "incre_win_rate": 0.7105263157894737, "step": 987}
{"time": 1767335799.0626287, "phase": "train", "update": 988, "total_env_steps": 3161600, "episode_reward": 0.23046770691871643, "value_loss": 0.013351458869874478, "policy_loss": -0.0015368465979690882, "dist_entropy": 0.7970032811164856, "actor_grad_norm": 0.14077983796596527, "critic_grad_norm": 0.0659683346748352, "ratio": 0.9995512366294861, "entropy": 0.7970032811164856, "incre_win_rate": 0.7948717948717948, "step": 988}
{"time": 1767335803.140875, "phase": "train", "update": 989, "total_env_steps": 3164800, "episode_reward": 0.22525610029697418, "value_loss": 0.010492940805852414, "policy_loss": -0.0016655444427595256, "dist_entropy": 0.7999960899353027, "actor_grad_norm": 0.09187978506088257, "critic_grad_norm": 0.06743601709604263, "ratio": 1.000150442123413, "entropy": 0.7999960899353027, "incre_win_rate": 0.7948717948717948, "step": 989}
{"time": 1767335807.1884437, "phase": "train", "update": 990, "total_env_steps": 3168000, "episode_reward": 0.2391323447227478, "value_loss": 0.008293377608060837, "policy_loss": -0.0012725228806857558, "dist_entropy": 0.7838862895965576, "actor_grad_norm": 0.07619240134954453, "critic_grad_norm": 0.02346050553023815, "ratio": 1.0002813339233398, "entropy": 0.7838862895965576, "incre_win_rate": 0.8717948717948718, "step": 990}
{"time": 1767335811.211, "phase": "train", "update": 991, "total_env_steps": 3171200, "episode_reward": 0.23098872601985931, "value_loss": 0.009127439558506012, "policy_loss": -0.0010633514690107759, "dist_entropy": 0.807026469707489, "actor_grad_norm": 0.07902991026639938, "critic_grad_norm": 0.0429600365459919, "ratio": 0.9998840689659119, "entropy": 0.807026469707489, "incre_win_rate": 0.8, "step": 991}
{"time": 1767335815.2850296, "phase": "train", "update": 992, "total_env_steps": 3174400, "episode_reward": 0.2437913864850998, "value_loss": 0.010999475605785847, "policy_loss": -0.001449270782799772, "dist_entropy": 0.8072276592254639, "actor_grad_norm": 0.09507163614034653, "critic_grad_norm": 0.03758886083960533, "ratio": 1.0001569986343384, "entropy": 0.8072276592254639, "incre_win_rate": 0.85, "step": 992}
{"time": 1767335819.3522696, "phase": "train", "update": 993, "total_env_steps": 3177600, "episode_reward": 0.24825745820999146, "value_loss": 0.010148299299180508, "policy_loss": -0.0012948278860044128, "dist_entropy": 0.8018161654472351, "actor_grad_norm": 0.09237487614154816, "critic_grad_norm": 0.062489379197359085, "ratio": 0.9996873140335083, "entropy": 0.8018161654472351, "incre_win_rate": 0.9285714285714286, "step": 993}
{"time": 1767335823.4828906, "phase": "train", "update": 994, "total_env_steps": 3180800, "episode_reward": 0.24435016512870789, "value_loss": 0.008903577737510205, "policy_loss": -0.000931693311107118, "dist_entropy": 0.7908995389938355, "actor_grad_norm": 0.09665980190038681, "critic_grad_norm": 0.04082931950688362, "ratio": 0.9999513030052185, "entropy": 0.7908995389938355, "incre_win_rate": 0.85, "step": 994}
{"time": 1767335827.5580778, "phase": "train", "update": 995, "total_env_steps": 3184000, "episode_reward": 0.2298603057861328, "value_loss": 0.010111282579600811, "policy_loss": -0.00112668611673854, "dist_entropy": 0.7693212151527404, "actor_grad_norm": 0.10072783380746841, "critic_grad_norm": 0.06011411175131798, "ratio": 0.9998144507408142, "entropy": 0.7693212151527404, "incre_win_rate": 0.725, "step": 995}
{"time": 1767335831.621345, "phase": "train", "update": 996, "total_env_steps": 3187200, "episode_reward": 0.2337934672832489, "value_loss": 0.00962226651608944, "policy_loss": -0.0010774025156152333, "dist_entropy": 0.788968312740326, "actor_grad_norm": 0.08899585157632828, "critic_grad_norm": 0.07462410628795624, "ratio": 1.000205159187317, "entropy": 0.788968312740326, "incre_win_rate": 0.775, "step": 996}
{"time": 1767335835.707123, "phase": "train", "update": 997, "total_env_steps": 3190400, "episode_reward": 0.2355039417743683, "value_loss": 0.009873051568865776, "policy_loss": -0.0012152647989935872, "dist_entropy": 0.7803624272346497, "actor_grad_norm": 0.09590867906808853, "critic_grad_norm": 0.054933495819568634, "ratio": 1.0002644062042236, "entropy": 0.7803624272346497, "incre_win_rate": 0.7435897435897436, "step": 997}
{"time": 1767335839.8047464, "phase": "train", "update": 998, "total_env_steps": 3193600, "episode_reward": 0.24957315623760223, "value_loss": 0.009779877588152885, "policy_loss": -0.0012935599930684384, "dist_entropy": 0.7985944986343384, "actor_grad_norm": 0.09196930378675461, "critic_grad_norm": 0.06675698608160019, "ratio": 0.9999589323997498, "entropy": 0.7985944986343384, "incre_win_rate": 0.926829268292683, "step": 998}
{"time": 1767335843.8628633, "phase": "train", "update": 999, "total_env_steps": 3196800, "episode_reward": 0.2413969486951828, "value_loss": 0.00806621704250574, "policy_loss": -0.001188289537251741, "dist_entropy": 0.8129140496253967, "actor_grad_norm": 0.12369457632303238, "critic_grad_norm": 0.05628805235028267, "ratio": 1.0001171827316284, "entropy": 0.8129140496253967, "incre_win_rate": 0.9, "step": 999}
{"time": 1767335847.93623, "phase": "train", "update": 1000, "total_env_steps": 3200000, "episode_reward": 0.2367456555366516, "value_loss": 0.010787232220172882, "policy_loss": -0.0010714751912725973, "dist_entropy": 0.799615204334259, "actor_grad_norm": 0.10034418106079102, "critic_grad_norm": 0.07138139754533768, "ratio": 1.0001176595687866, "entropy": 0.799615204334259, "incre_win_rate": 0.8421052631578947, "step": 1000}
{"time": 1767335852.01754, "phase": "train", "update": 1001, "total_env_steps": 3203200, "episode_reward": 0.22318241000175476, "value_loss": 0.014176624082028865, "policy_loss": -0.0012446579063954744, "dist_entropy": 0.7959484338760376, "actor_grad_norm": 0.09438770264387131, "critic_grad_norm": 0.12570832669734955, "ratio": 1.000091791152954, "entropy": 0.7959484338760376, "incre_win_rate": 0.6097560975609756, "step": 1001}
{"time": 1767335862.8720856, "phase": "eval", "update": 1001, "total_env_steps": 3203200, "eval_win_rate": 0.8125, "eval_episode_reward": 18.92084023178808, "step": 1001}
{"time": 1767335866.905507, "phase": "train", "update": 1002, "total_env_steps": 3206400, "episode_reward": 0.22518211603164673, "value_loss": 0.011725814454257489, "policy_loss": -0.0014730101400985518, "dist_entropy": 0.808570659160614, "actor_grad_norm": 0.10402541607618332, "critic_grad_norm": 0.08917059749364853, "ratio": 0.999663770198822, "entropy": 0.808570659160614, "incre_win_rate": 0.7631578947368421, "step": 1002}
{"time": 1767335870.9354515, "phase": "train", "update": 1003, "total_env_steps": 3209600, "episode_reward": 0.22495239973068237, "value_loss": 0.011413491144776345, "policy_loss": -0.001390089182545573, "dist_entropy": 0.8364368319511414, "actor_grad_norm": 0.10108835995197296, "critic_grad_norm": 0.057110048830509186, "ratio": 1.000645399093628, "entropy": 0.8364368319511414, "incre_win_rate": 0.7948717948717948, "step": 1003}
{"time": 1767335874.9675581, "phase": "train", "update": 1004, "total_env_steps": 3212800, "episode_reward": 0.22905991971492767, "value_loss": 0.009236563555896282, "policy_loss": -0.0014301010550543225, "dist_entropy": 0.8201168656349183, "actor_grad_norm": 0.1342623084783554, "critic_grad_norm": 0.08638760447502136, "ratio": 0.9998087882995605, "entropy": 0.8201168656349183, "incre_win_rate": 0.8205128205128205, "step": 1004}
{"time": 1767335879.0029972, "phase": "train", "update": 1005, "total_env_steps": 3216000, "episode_reward": 0.22580662369728088, "value_loss": 0.010841157101094723, "policy_loss": -0.00117768863740082, "dist_entropy": 0.8297931313514709, "actor_grad_norm": 0.11351173371076584, "critic_grad_norm": 0.06671791523694992, "ratio": 0.9998778700828552, "entropy": 0.8297931313514709, "incre_win_rate": 0.7631578947368421, "step": 1005}
{"time": 1767335883.0712888, "phase": "train", "update": 1006, "total_env_steps": 3219200, "episode_reward": 0.21740740537643433, "value_loss": 0.011557902209460735, "policy_loss": -0.001174370413876602, "dist_entropy": 0.8211095213890076, "actor_grad_norm": 0.09027249366044998, "critic_grad_norm": 0.07462502270936966, "ratio": 0.9998920559883118, "entropy": 0.8211095213890076, "incre_win_rate": 0.6666666666666666, "step": 1006}
{"time": 1767335887.1639044, "phase": "train", "update": 1007, "total_env_steps": 3222400, "episode_reward": 0.22915512323379517, "value_loss": 0.007565024122595787, "policy_loss": -0.0015236772382686281, "dist_entropy": 0.840583074092865, "actor_grad_norm": 0.097358338534832, "critic_grad_norm": 0.032378073781728745, "ratio": 0.9998877644538879, "entropy": 0.840583074092865, "incre_win_rate": 0.8157894736842105, "step": 1007}
{"time": 1767335891.220004, "phase": "train", "update": 1008, "total_env_steps": 3225600, "episode_reward": 0.24321605265140533, "value_loss": 0.007855392713099717, "policy_loss": -0.0013935981296528065, "dist_entropy": 0.7888170838356018, "actor_grad_norm": 0.07669228315353394, "critic_grad_norm": 0.05274488404393196, "ratio": 1.0000463724136353, "entropy": 0.7888170838356018, "incre_win_rate": 0.95, "step": 1008}
{"time": 1767335895.3173573, "phase": "train", "update": 1009, "total_env_steps": 3228800, "episode_reward": 0.24435481429100037, "value_loss": 0.008837034739553929, "policy_loss": -0.0013068011852595874, "dist_entropy": 0.7951695322990417, "actor_grad_norm": 0.08008934557437897, "critic_grad_norm": 0.07222265005111694, "ratio": 1.0000156164169312, "entropy": 0.7951695322990417, "incre_win_rate": 0.9230769230769231, "step": 1009}
{"time": 1767335899.3564708, "phase": "train", "update": 1010, "total_env_steps": 3232000, "episode_reward": 0.24079057574272156, "value_loss": 0.006463855877518654, "policy_loss": -0.001177161782666758, "dist_entropy": 0.7723792195320129, "actor_grad_norm": 0.08569236099720001, "critic_grad_norm": 0.04561386629939079, "ratio": 0.9997355341911316, "entropy": 0.7723792195320129, "incre_win_rate": 0.9210526315789473, "step": 1010}
{"time": 1767335903.4538555, "phase": "train", "update": 1011, "total_env_steps": 3235200, "episode_reward": 0.24685068428516388, "value_loss": 0.005187858268618584, "policy_loss": -0.0015222851278679172, "dist_entropy": 0.8118391394615173, "actor_grad_norm": 0.08121655881404877, "critic_grad_norm": 0.03573964536190033, "ratio": 1.0001959800720215, "entropy": 0.8118391394615173, "incre_win_rate": 0.9285714285714286, "step": 1011}
{"time": 1767335907.5294418, "phase": "train", "update": 1012, "total_env_steps": 3238400, "episode_reward": 0.23812085390090942, "value_loss": 0.007579115591943264, "policy_loss": -0.0011404392012353882, "dist_entropy": 0.8273481011390686, "actor_grad_norm": 0.08218713104724884, "critic_grad_norm": 0.07016025483608246, "ratio": 0.9998661279678345, "entropy": 0.8273481011390686, "incre_win_rate": 0.8717948717948718, "step": 1012}
{"time": 1767335911.6276507, "phase": "train", "update": 1013, "total_env_steps": 3241600, "episode_reward": 0.24139074981212616, "value_loss": 0.008567634597420692, "policy_loss": -0.0011582976646955956, "dist_entropy": 0.8364846587181092, "actor_grad_norm": 0.1205783262848854, "critic_grad_norm": 0.04166678339242935, "ratio": 0.9997121095657349, "entropy": 0.8364846587181092, "incre_win_rate": 0.85, "step": 1013}
{"time": 1767335915.7099822, "phase": "train", "update": 1014, "total_env_steps": 3244800, "episode_reward": 0.2315780222415924, "value_loss": 0.011313288286328316, "policy_loss": -0.0012556275775580162, "dist_entropy": 0.865254032611847, "actor_grad_norm": 0.10742544382810593, "critic_grad_norm": 0.053161878138780594, "ratio": 0.9997346997261047, "entropy": 0.865254032611847, "incre_win_rate": 0.8974358974358975, "step": 1014}
{"time": 1767335919.7747347, "phase": "train", "update": 1015, "total_env_steps": 3248000, "episode_reward": 0.2453145831823349, "value_loss": 0.00812322050333023, "policy_loss": -0.0012214693988875426, "dist_entropy": 0.8437374353408813, "actor_grad_norm": 0.10003755241632462, "critic_grad_norm": 0.06125400587916374, "ratio": 0.9995471835136414, "entropy": 0.8437374353408813, "incre_win_rate": 0.925, "step": 1015}
{"time": 1767335923.8346703, "phase": "train", "update": 1016, "total_env_steps": 3251200, "episode_reward": 0.25064417719841003, "value_loss": 0.005628920532763005, "policy_loss": -0.0009727886623469573, "dist_entropy": 0.8212210297584533, "actor_grad_norm": 0.1191924586892128, "critic_grad_norm": 0.033326610922813416, "ratio": 1.000056266784668, "entropy": 0.8212210297584533, "incre_win_rate": 0.95, "step": 1016}
{"time": 1767335927.9138587, "phase": "train", "update": 1017, "total_env_steps": 3254400, "episode_reward": 0.2576862573623657, "value_loss": 0.003007487067952752, "policy_loss": -0.0010753762871683393, "dist_entropy": 0.847090482711792, "actor_grad_norm": 0.10674351453781128, "critic_grad_norm": 0.03214612603187561, "ratio": 1.0001460313796997, "entropy": 0.847090482711792, "incre_win_rate": 0.9761904761904762, "step": 1017}
{"time": 1767335932.0218332, "phase": "train", "update": 1018, "total_env_steps": 3257600, "episode_reward": 0.2460182160139084, "value_loss": 0.003999593853950501, "policy_loss": -0.00117433511519911, "dist_entropy": 0.8497617602348327, "actor_grad_norm": 0.11483805626630783, "critic_grad_norm": 0.014511133544147015, "ratio": 0.9999793171882629, "entropy": 0.8497617602348327, "incre_win_rate": 0.9743589743589743, "step": 1018}
{"time": 1767335936.09792, "phase": "train", "update": 1019, "total_env_steps": 3260800, "episode_reward": 0.2450025975704193, "value_loss": 0.007911863271147013, "policy_loss": -0.0012239072625646942, "dist_entropy": 0.8224359273910522, "actor_grad_norm": 0.09253689646720886, "critic_grad_norm": 0.0348772332072258, "ratio": 0.9995021820068359, "entropy": 0.8224359273910522, "incre_win_rate": 0.9047619047619048, "step": 1019}
{"time": 1767335940.191654, "phase": "train", "update": 1020, "total_env_steps": 3264000, "episode_reward": 0.231509730219841, "value_loss": 0.009144576638936997, "policy_loss": -0.001183097025727875, "dist_entropy": 0.840611743927002, "actor_grad_norm": 0.08937917649745941, "critic_grad_norm": 0.08871147781610489, "ratio": 1.0003318786621094, "entropy": 0.840611743927002, "incre_win_rate": 0.8205128205128205, "step": 1020}
{"time": 1767335944.2572424, "phase": "train", "update": 1021, "total_env_steps": 3267200, "episode_reward": 0.23095302283763885, "value_loss": 0.011357738636434078, "policy_loss": -0.0015815295777972694, "dist_entropy": 0.8376076102256775, "actor_grad_norm": 0.12994550168514252, "critic_grad_norm": 0.08932247012853622, "ratio": 0.999954879283905, "entropy": 0.8376076102256775, "incre_win_rate": 0.7317073170731707, "step": 1021}
{"time": 1767335948.341702, "phase": "train", "update": 1022, "total_env_steps": 3270400, "episode_reward": 0.24385866522789001, "value_loss": 0.010899579524993897, "policy_loss": -0.0015196505128631799, "dist_entropy": 0.8079031586647034, "actor_grad_norm": 0.09783919900655746, "critic_grad_norm": 0.05562508851289749, "ratio": 1.0003480911254883, "entropy": 0.8079031586647034, "incre_win_rate": 0.825, "step": 1022}
{"time": 1767335952.4059827, "phase": "train", "update": 1023, "total_env_steps": 3273600, "episode_reward": 0.24124588072299957, "value_loss": 0.009767143614590168, "policy_loss": -0.0012786124118321141, "dist_entropy": 0.8206639051437378, "actor_grad_norm": 0.0882815420627594, "critic_grad_norm": 0.050981055945158005, "ratio": 0.9998096823692322, "entropy": 0.8206639051437378, "incre_win_rate": 0.8536585365853658, "step": 1023}
{"time": 1767335956.4158208, "phase": "train", "update": 1024, "total_env_steps": 3276800, "episode_reward": 0.23651646077632904, "value_loss": 0.009211725927889347, "policy_loss": -0.0016005097509506072, "dist_entropy": 0.8087918043136597, "actor_grad_norm": 0.09165017306804657, "critic_grad_norm": 0.047566309571266174, "ratio": 0.9999937415122986, "entropy": 0.8087918043136597, "incre_win_rate": 0.8421052631578947, "step": 1024}
{"time": 1767335960.551909, "phase": "train", "update": 1025, "total_env_steps": 3280000, "episode_reward": 0.24806703627109528, "value_loss": 0.0065664017572999, "policy_loss": -0.0016478400723265452, "dist_entropy": 0.8202310919761657, "actor_grad_norm": 0.11236866563558578, "critic_grad_norm": 0.042156416922807693, "ratio": 0.9996953010559082, "entropy": 0.8202310919761657, "incre_win_rate": 0.9047619047619048, "step": 1025}
{"time": 1767335964.6844897, "phase": "train", "update": 1026, "total_env_steps": 3283200, "episode_reward": 0.2600812315940857, "value_loss": 0.004269461706280708, "policy_loss": -0.00109616966571906, "dist_entropy": 0.7989116668701172, "actor_grad_norm": 0.10091779381036758, "critic_grad_norm": 0.08004331588745117, "ratio": 1.0001896619796753, "entropy": 0.7989116668701172, "incre_win_rate": 0.975609756097561, "step": 1026}
{"time": 1767335975.202696, "phase": "eval", "update": 1026, "total_env_steps": 3283200, "eval_win_rate": 0.84375, "eval_episode_reward": 19.19883071192053, "step": 1026}
{"time": 1767335979.2466722, "phase": "train", "update": 1027, "total_env_steps": 3286400, "episode_reward": 0.2517337501049042, "value_loss": 0.007148319203406572, "policy_loss": -0.0007974463591576608, "dist_entropy": 0.8003365755081177, "actor_grad_norm": 0.07387864589691162, "critic_grad_norm": 0.04267972335219383, "ratio": 0.9999105334281921, "entropy": 0.8003365755081177, "incre_win_rate": 0.9230769230769231, "step": 1027}
{"time": 1767335983.3029604, "phase": "train", "update": 1028, "total_env_steps": 3289600, "episode_reward": 0.2438058853149414, "value_loss": 0.005254599172621966, "policy_loss": -0.0013507707602878228, "dist_entropy": 0.8033553123474121, "actor_grad_norm": 0.10565745830535889, "critic_grad_norm": 0.034567538648843765, "ratio": 1.0004380941390991, "entropy": 0.8033553123474121, "incre_win_rate": 0.926829268292683, "step": 1028}
{"time": 1767335987.360579, "phase": "train", "update": 1029, "total_env_steps": 3292800, "episode_reward": 0.2518170475959778, "value_loss": 0.003998205903917551, "policy_loss": -0.0010526296631764964, "dist_entropy": 0.8055234909057617, "actor_grad_norm": 0.09360849112272263, "critic_grad_norm": 0.03066851571202278, "ratio": 0.9999330639839172, "entropy": 0.8055234909057617, "incre_win_rate": 0.9523809523809523, "step": 1029}
{"time": 1767335991.405124, "phase": "train", "update": 1030, "total_env_steps": 3296000, "episode_reward": 0.23384156823158264, "value_loss": 0.007136892806738615, "policy_loss": -0.0014533634052273925, "dist_entropy": 0.7485714435577393, "actor_grad_norm": 0.08545513451099396, "critic_grad_norm": 0.07046562433242798, "ratio": 1.0000100135803223, "entropy": 0.7485714435577393, "incre_win_rate": 0.7948717948717948, "step": 1030}
{"time": 1767335995.417254, "phase": "train", "update": 1031, "total_env_steps": 3299200, "episode_reward": 0.22551323473453522, "value_loss": 0.009684903547167778, "policy_loss": -0.0014320574854252755, "dist_entropy": 0.7400937795639038, "actor_grad_norm": 0.10262506455183029, "critic_grad_norm": 0.07208739966154099, "ratio": 1.0001848936080933, "entropy": 0.7400937795639038, "incre_win_rate": 0.8378378378378378, "step": 1031}
{"time": 1767335999.4668903, "phase": "train", "update": 1032, "total_env_steps": 3302400, "episode_reward": 0.24078643321990967, "value_loss": 0.009080458991229534, "policy_loss": -0.0009842544667293396, "dist_entropy": 0.7673097729682923, "actor_grad_norm": 0.11899731308221817, "critic_grad_norm": 0.06126396730542183, "ratio": 0.9997811317443848, "entropy": 0.7673097729682923, "incre_win_rate": 0.8461538461538461, "step": 1032}
{"time": 1767336003.5352108, "phase": "train", "update": 1033, "total_env_steps": 3305600, "episode_reward": 0.24163077771663666, "value_loss": 0.005662462953478098, "policy_loss": -0.0014883578798709606, "dist_entropy": 0.7701517343521118, "actor_grad_norm": 0.09834976494312286, "critic_grad_norm": 0.05627806857228279, "ratio": 0.9999639391899109, "entropy": 0.7701517343521118, "incre_win_rate": 0.8780487804878049, "step": 1033}
{"time": 1767336007.593701, "phase": "train", "update": 1034, "total_env_steps": 3308800, "episode_reward": 0.24376602470874786, "value_loss": 0.006611751113086939, "policy_loss": -0.0013778099658203757, "dist_entropy": 0.7684421062469482, "actor_grad_norm": 0.09366004914045334, "critic_grad_norm": 0.033894166350364685, "ratio": 1.0003283023834229, "entropy": 0.7684421062469482, "incre_win_rate": 0.9024390243902439, "step": 1034}
{"time": 1767336011.6675575, "phase": "train", "update": 1035, "total_env_steps": 3312000, "episode_reward": 0.2352147102355957, "value_loss": 0.011623037606477737, "policy_loss": -0.0011949855866602022, "dist_entropy": 0.7534798979759216, "actor_grad_norm": 0.09752964973449707, "critic_grad_norm": 0.09990089386701584, "ratio": 0.9999599456787109, "entropy": 0.7534798979759216, "incre_win_rate": 0.75, "step": 1035}
{"time": 1767336015.6849256, "phase": "train", "update": 1036, "total_env_steps": 3315200, "episode_reward": 0.22642694413661957, "value_loss": 0.011854554712772369, "policy_loss": -0.0013239033910785736, "dist_entropy": 0.7445733070373535, "actor_grad_norm": 0.08733724802732468, "critic_grad_norm": 0.11751840263605118, "ratio": 1.0001357793807983, "entropy": 0.7445733070373535, "incre_win_rate": 0.6585365853658537, "step": 1036}
{"time": 1767336019.7328198, "phase": "train", "update": 1037, "total_env_steps": 3318400, "episode_reward": 0.23934343457221985, "value_loss": 0.009481900185346604, "policy_loss": -0.0008232304178335426, "dist_entropy": 0.7635316371917724, "actor_grad_norm": 0.10268666595220566, "critic_grad_norm": 0.05693577602505684, "ratio": 1.0001341104507446, "entropy": 0.7635316371917724, "incre_win_rate": 0.8, "step": 1037}
{"time": 1767336023.8278713, "phase": "train", "update": 1038, "total_env_steps": 3321600, "episode_reward": 0.2307238131761551, "value_loss": 0.014508354663848876, "policy_loss": -0.0014404973688073141, "dist_entropy": 0.7602846145629882, "actor_grad_norm": 0.11229868233203888, "critic_grad_norm": 0.07223431766033173, "ratio": 0.9998250007629395, "entropy": 0.7602846145629882, "incre_win_rate": 0.7948717948717948, "step": 1038}
{"time": 1767336027.8630917, "phase": "train", "update": 1039, "total_env_steps": 3324800, "episode_reward": 0.23137053847312927, "value_loss": 0.011799465864896774, "policy_loss": -0.0012403170512005346, "dist_entropy": 0.7553241491317749, "actor_grad_norm": 0.12065470218658447, "critic_grad_norm": 0.05099223181605339, "ratio": 0.9995271563529968, "entropy": 0.7553241491317749, "incre_win_rate": 0.75, "step": 1039}
{"time": 1767336031.8676949, "phase": "train", "update": 1040, "total_env_steps": 3328000, "episode_reward": 0.23547597229480743, "value_loss": 0.007895104680210352, "policy_loss": -0.0012815806703107668, "dist_entropy": 0.7564723372459412, "actor_grad_norm": 0.12574531137943268, "critic_grad_norm": 0.07243853807449341, "ratio": 1.0005806684494019, "entropy": 0.7564723372459412, "incre_win_rate": 0.868421052631579, "step": 1040}
{"time": 1767336035.9244068, "phase": "train", "update": 1041, "total_env_steps": 3331200, "episode_reward": 0.240743488073349, "value_loss": 0.005872105713933706, "policy_loss": -0.0011406628754485836, "dist_entropy": 0.74935964345932, "actor_grad_norm": 0.10683325678110123, "critic_grad_norm": 0.055419374257326126, "ratio": 1.0000361204147339, "entropy": 0.74935964345932, "incre_win_rate": 0.8974358974358975, "step": 1041}
{"time": 1767336039.9661102, "phase": "train", "update": 1042, "total_env_steps": 3334400, "episode_reward": 0.23537614941596985, "value_loss": 0.007465041801333427, "policy_loss": -0.0018379025988132015, "dist_entropy": 0.7561377882957458, "actor_grad_norm": 0.11130175739526749, "critic_grad_norm": 0.04358349367976189, "ratio": 1.0001808404922485, "entropy": 0.7561377882957458, "incre_win_rate": 0.8421052631578947, "step": 1042}
{"time": 1767336044.0559206, "phase": "train", "update": 1043, "total_env_steps": 3337600, "episode_reward": 0.25480133295059204, "value_loss": 0.006870997976511717, "policy_loss": -0.001505112062329772, "dist_entropy": 0.7711321830749511, "actor_grad_norm": 0.1295391172170639, "critic_grad_norm": 0.03899776190519333, "ratio": 1.0001503229141235, "entropy": 0.7711321830749511, "incre_win_rate": 0.9285714285714286, "step": 1043}
{"time": 1767336048.1284077, "phase": "train", "update": 1044, "total_env_steps": 3340800, "episode_reward": 0.2376355528831482, "value_loss": 0.007995197176933288, "policy_loss": -0.0012653229622603846, "dist_entropy": 0.7687802076339721, "actor_grad_norm": 0.1115143895149231, "critic_grad_norm": 0.03295380622148514, "ratio": 1.0002498626708984, "entropy": 0.7687802076339721, "incre_win_rate": 0.875, "step": 1044}
{"time": 1767336052.209396, "phase": "train", "update": 1045, "total_env_steps": 3344000, "episode_reward": 0.24228891730308533, "value_loss": 0.007125985436141491, "policy_loss": -0.0010896691658933478, "dist_entropy": 0.7562335848808288, "actor_grad_norm": 0.09985407441854477, "critic_grad_norm": 0.048987384885549545, "ratio": 1.0001076459884644, "entropy": 0.7562335848808288, "incre_win_rate": 0.9024390243902439, "step": 1045}
{"time": 1767336056.2781627, "phase": "train", "update": 1046, "total_env_steps": 3347200, "episode_reward": 0.25007036328315735, "value_loss": 0.005098934005945921, "policy_loss": -0.0012306682807100345, "dist_entropy": 0.7738954067230225, "actor_grad_norm": 0.11754083633422852, "critic_grad_norm": 0.04904397949576378, "ratio": 0.9996311068534851, "entropy": 0.7738954067230225, "incre_win_rate": 1.0, "step": 1046}
{"time": 1767336060.353191, "phase": "train", "update": 1047, "total_env_steps": 3350400, "episode_reward": 0.24638865888118744, "value_loss": 0.007197053357958794, "policy_loss": -0.0013455923848498586, "dist_entropy": 0.7715288758277893, "actor_grad_norm": 0.12510085105895996, "critic_grad_norm": 0.059614717960357666, "ratio": 1.0002707242965698, "entropy": 0.7715288758277893, "incre_win_rate": 0.9047619047619048, "step": 1047}
{"time": 1767336064.4514165, "phase": "train", "update": 1048, "total_env_steps": 3353600, "episode_reward": 0.2429320216178894, "value_loss": 0.007079418748617172, "policy_loss": -0.0008434835507582505, "dist_entropy": 0.7354431390762329, "actor_grad_norm": 0.08588632196187973, "critic_grad_norm": 0.04682214930653572, "ratio": 0.999965488910675, "entropy": 0.7354431390762329, "incre_win_rate": 0.8974358974358975, "step": 1048}
{"time": 1767336068.585924, "phase": "train", "update": 1049, "total_env_steps": 3356800, "episode_reward": 0.2516308128833771, "value_loss": 0.007901715394109488, "policy_loss": -0.001177014919301378, "dist_entropy": 0.7937386631965637, "actor_grad_norm": 0.09927438944578171, "critic_grad_norm": 0.053858187049627304, "ratio": 0.9998236894607544, "entropy": 0.7937386631965637, "incre_win_rate": 0.926829268292683, "step": 1049}
{"time": 1767336072.652879, "phase": "train", "update": 1050, "total_env_steps": 3360000, "episode_reward": 0.2419629693031311, "value_loss": 0.00960138365626335, "policy_loss": -0.0016410274877401321, "dist_entropy": 0.7830695986747742, "actor_grad_norm": 0.09845685958862305, "critic_grad_norm": 0.0881035253405571, "ratio": 0.9997054934501648, "entropy": 0.7830695986747742, "incre_win_rate": 0.8333333333333334, "step": 1050}
{"time": 1767336076.7355742, "phase": "train", "update": 1051, "total_env_steps": 3363200, "episode_reward": 0.25114238262176514, "value_loss": 0.0051580237224698065, "policy_loss": -0.0009498822918452277, "dist_entropy": 0.8074488878250122, "actor_grad_norm": 0.09011487662792206, "critic_grad_norm": 0.08707047998905182, "ratio": 1.0002137422561646, "entropy": 0.8074488878250122, "incre_win_rate": 0.9487179487179487, "step": 1051}
{"time": 1767336086.897418, "phase": "eval", "update": 1051, "total_env_steps": 3363200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.653559602649004, "step": 1051}
{"time": 1767336090.9462707, "phase": "train", "update": 1052, "total_env_steps": 3366400, "episode_reward": 0.23999327421188354, "value_loss": 0.006313642021268606, "policy_loss": -0.0010829351430267308, "dist_entropy": 0.7780453562736511, "actor_grad_norm": 0.09849220514297485, "critic_grad_norm": 0.06108641251921654, "ratio": 0.9998309016227722, "entropy": 0.7780453562736511, "incre_win_rate": 0.8536585365853658, "step": 1052}
{"time": 1767336095.106521, "phase": "train", "update": 1053, "total_env_steps": 3369600, "episode_reward": 0.2583899199962616, "value_loss": 0.003926532668992877, "policy_loss": -0.0011360270653014482, "dist_entropy": 0.7895869255065918, "actor_grad_norm": 0.10498445481061935, "critic_grad_norm": 0.05411149188876152, "ratio": 1.0002435445785522, "entropy": 0.7895869255065918, "incre_win_rate": 0.975, "step": 1053}
{"time": 1767336099.163979, "phase": "train", "update": 1054, "total_env_steps": 3372800, "episode_reward": 0.23583559691905975, "value_loss": 0.00864618718624115, "policy_loss": -0.0013349381633211976, "dist_entropy": 0.796818470954895, "actor_grad_norm": 0.09650664776563644, "critic_grad_norm": 0.11663039028644562, "ratio": 1.0001095533370972, "entropy": 0.796818470954895, "incre_win_rate": 0.825, "step": 1054}
{"time": 1767336103.20575, "phase": "train", "update": 1055, "total_env_steps": 3376000, "episode_reward": 0.24491310119628906, "value_loss": 0.006882010307163, "policy_loss": -0.0010353729456163308, "dist_entropy": 0.8096936345100403, "actor_grad_norm": 0.09542898088693619, "critic_grad_norm": 0.0612221360206604, "ratio": 1.00026535987854, "entropy": 0.8096936345100403, "incre_win_rate": 0.9285714285714286, "step": 1055}
{"time": 1767336107.2356489, "phase": "train", "update": 1056, "total_env_steps": 3379200, "episode_reward": 0.24605806171894073, "value_loss": 0.0067765661515295506, "policy_loss": -0.0011871470922976356, "dist_entropy": 0.8142381072044372, "actor_grad_norm": 0.09782975912094116, "critic_grad_norm": 0.04440704360604286, "ratio": 0.9999961256980896, "entropy": 0.8142381072044372, "incre_win_rate": 0.875, "step": 1056}
{"time": 1767336111.2781537, "phase": "train", "update": 1057, "total_env_steps": 3382400, "episode_reward": 0.2436310052871704, "value_loss": 0.007120030559599399, "policy_loss": -0.0011906078025589295, "dist_entropy": 0.8076313853263855, "actor_grad_norm": 0.08627127856016159, "critic_grad_norm": 0.028263313695788383, "ratio": 0.9999243021011353, "entropy": 0.8076313853263855, "incre_win_rate": 0.8717948717948718, "step": 1057}
{"time": 1767336115.3774326, "phase": "train", "update": 1058, "total_env_steps": 3385600, "episode_reward": 0.24644505977630615, "value_loss": 0.006158160232007504, "policy_loss": -0.001337391988957748, "dist_entropy": 0.8102917790412902, "actor_grad_norm": 0.09051027148962021, "critic_grad_norm": 0.05167127400636673, "ratio": 0.9996528029441833, "entropy": 0.8102917790412902, "incre_win_rate": 0.95, "step": 1058}
{"time": 1767336119.3852863, "phase": "train", "update": 1059, "total_env_steps": 3388800, "episode_reward": 0.23986341059207916, "value_loss": 0.009265798516571522, "policy_loss": -0.0013877499990314845, "dist_entropy": 0.7905723690986634, "actor_grad_norm": 0.10322093218564987, "critic_grad_norm": 0.05579886585474014, "ratio": 1.0000262260437012, "entropy": 0.7905723690986634, "incre_win_rate": 0.925, "step": 1059}
{"time": 1767336123.4473112, "phase": "train", "update": 1060, "total_env_steps": 3392000, "episode_reward": 0.25349336862564087, "value_loss": 0.007700435630977154, "policy_loss": -0.0012012727037131298, "dist_entropy": 0.7839620113372803, "actor_grad_norm": 0.12398933619260788, "critic_grad_norm": 0.03910461813211441, "ratio": 0.9996838569641113, "entropy": 0.7839620113372803, "incre_win_rate": 0.9024390243902439, "step": 1060}
{"time": 1767336127.4963148, "phase": "train", "update": 1061, "total_env_steps": 3395200, "episode_reward": 0.2553507685661316, "value_loss": 0.005186623707413673, "policy_loss": -0.0011761192397136354, "dist_entropy": 0.7884410738945007, "actor_grad_norm": 0.10151763260364532, "critic_grad_norm": 0.039233144372701645, "ratio": 1.0002237558364868, "entropy": 0.7884410738945007, "incre_win_rate": 0.9285714285714286, "step": 1061}
{"time": 1767336131.5607731, "phase": "train", "update": 1062, "total_env_steps": 3398400, "episode_reward": 0.23951314389705658, "value_loss": 0.008561880514025687, "policy_loss": -0.0014347911639063682, "dist_entropy": 0.7772424578666687, "actor_grad_norm": 0.10055839270353317, "critic_grad_norm": 0.06519212573766708, "ratio": 1.0002514123916626, "entropy": 0.7772424578666687, "incre_win_rate": 0.8, "step": 1062}
{"time": 1767336135.7196681, "phase": "train", "update": 1063, "total_env_steps": 3401600, "episode_reward": 0.25930875539779663, "value_loss": 0.005424319952726364, "policy_loss": -0.001366448341200055, "dist_entropy": 0.8044091105461121, "actor_grad_norm": 0.12028656154870987, "critic_grad_norm": 0.09845762699842453, "ratio": 0.9998399615287781, "entropy": 0.8044091105461121, "incre_win_rate": 1.0, "step": 1063}
{"time": 1767336139.800884, "phase": "train", "update": 1064, "total_env_steps": 3404800, "episode_reward": 0.24537460505962372, "value_loss": 0.008185015711933374, "policy_loss": -0.001151105979621292, "dist_entropy": 0.7595010161399841, "actor_grad_norm": 0.10333269089460373, "critic_grad_norm": 0.07557230442762375, "ratio": 0.9999880790710449, "entropy": 0.7595010161399841, "incre_win_rate": 0.8571428571428571, "step": 1064}
{"time": 1767336143.9018502, "phase": "train", "update": 1065, "total_env_steps": 3408000, "episode_reward": 0.25778716802597046, "value_loss": 0.005908620543777943, "policy_loss": -0.0011727976561417108, "dist_entropy": 0.7757141351699829, "actor_grad_norm": 0.11762141436338425, "critic_grad_norm": 0.048103876411914825, "ratio": 1.0001475811004639, "entropy": 0.7757141351699829, "incre_win_rate": 0.9024390243902439, "step": 1065}
{"time": 1767336147.9938865, "phase": "train", "update": 1066, "total_env_steps": 3411200, "episode_reward": 0.26059603691101074, "value_loss": 0.005074441339820624, "policy_loss": -0.0012231014641876925, "dist_entropy": 0.7450634360313415, "actor_grad_norm": 0.12404896318912506, "critic_grad_norm": 0.060568489134311676, "ratio": 1.0000231266021729, "entropy": 0.7450634360313415, "incre_win_rate": 1.0, "step": 1066}
{"time": 1767336152.0732572, "phase": "train", "update": 1067, "total_env_steps": 3414400, "episode_reward": 0.24981166422367096, "value_loss": 0.005502254702150822, "policy_loss": -0.001250331524202153, "dist_entropy": 0.736001443862915, "actor_grad_norm": 0.09540796279907227, "critic_grad_norm": 0.04769207909703255, "ratio": 0.9999307990074158, "entropy": 0.736001443862915, "incre_win_rate": 0.875, "step": 1067}
{"time": 1767336156.1635547, "phase": "train", "update": 1068, "total_env_steps": 3417600, "episode_reward": 0.2517032325267792, "value_loss": 0.005576449353247881, "policy_loss": -0.0014467222405471602, "dist_entropy": 0.7563066244125366, "actor_grad_norm": 0.08873994648456573, "critic_grad_norm": 0.04042484983801842, "ratio": 0.9999563097953796, "entropy": 0.7563066244125366, "incre_win_rate": 0.9512195121951219, "step": 1068}
{"time": 1767336160.2311692, "phase": "train", "update": 1069, "total_env_steps": 3420800, "episode_reward": 0.2457703799009323, "value_loss": 0.010118315368890763, "policy_loss": -0.001058097068280972, "dist_entropy": 0.723922598361969, "actor_grad_norm": 0.07076460123062134, "critic_grad_norm": 0.030931705608963966, "ratio": 1.000130534172058, "entropy": 0.723922598361969, "incre_win_rate": 0.8837209302325582, "step": 1069}
{"time": 1767336164.322792, "phase": "train", "update": 1070, "total_env_steps": 3424000, "episode_reward": 0.24886846542358398, "value_loss": 0.005208931397646666, "policy_loss": -0.0010275503780007966, "dist_entropy": 0.7092501521110535, "actor_grad_norm": 0.07977378368377686, "critic_grad_norm": 0.02877766266465187, "ratio": 1.0001509189605713, "entropy": 0.7092501521110535, "incre_win_rate": 0.925, "step": 1070}
{"time": 1767336168.3459074, "phase": "train", "update": 1071, "total_env_steps": 3427200, "episode_reward": 0.24263659119606018, "value_loss": 0.007432482484728098, "policy_loss": -0.0010308960304037495, "dist_entropy": 0.7079168319702148, "actor_grad_norm": 0.10977522283792496, "critic_grad_norm": 0.07025018334388733, "ratio": 0.999805748462677, "entropy": 0.7079168319702148, "incre_win_rate": 0.9, "step": 1071}
{"time": 1767336172.4093773, "phase": "train", "update": 1072, "total_env_steps": 3430400, "episode_reward": 0.25481268763542175, "value_loss": 0.00438012471422553, "policy_loss": -0.0013073689885516383, "dist_entropy": 0.7330788135528564, "actor_grad_norm": 0.11090368032455444, "critic_grad_norm": 0.03630494698882103, "ratio": 0.9997755885124207, "entropy": 0.7330788135528564, "incre_win_rate": 0.975, "step": 1072}
{"time": 1767336176.4975827, "phase": "train", "update": 1073, "total_env_steps": 3433600, "episode_reward": 0.25876137614250183, "value_loss": 0.0042695640586316586, "policy_loss": -0.0010927221682301535, "dist_entropy": 0.7247385025024414, "actor_grad_norm": 0.09102171659469604, "critic_grad_norm": 0.05300167202949524, "ratio": 0.9999263882637024, "entropy": 0.7247385025024414, "incre_win_rate": 0.975, "step": 1073}
{"time": 1767336180.562845, "phase": "train", "update": 1074, "total_env_steps": 3436800, "episode_reward": 0.25298428535461426, "value_loss": 0.008051118440926075, "policy_loss": -0.0011396767980905054, "dist_entropy": 0.7250871539115906, "actor_grad_norm": 0.07846879214048386, "critic_grad_norm": 0.03968512639403343, "ratio": 0.9998847246170044, "entropy": 0.7250871539115906, "incre_win_rate": 0.9333333333333333, "step": 1074}
{"time": 1767336184.6318917, "phase": "train", "update": 1075, "total_env_steps": 3440000, "episode_reward": 0.2471274882555008, "value_loss": 0.0058455104939639565, "policy_loss": -0.0010230679650121033, "dist_entropy": 0.7271047592163086, "actor_grad_norm": 0.08112578094005585, "critic_grad_norm": 0.02663571946322918, "ratio": 1.0001307725906372, "entropy": 0.7271047592163086, "incre_win_rate": 0.925, "step": 1075}
{"time": 1767336188.7086809, "phase": "train", "update": 1076, "total_env_steps": 3443200, "episode_reward": 0.2517715394496918, "value_loss": 0.007504342868924141, "policy_loss": -0.0011465166035307562, "dist_entropy": 0.7477754831314087, "actor_grad_norm": 0.0872592106461525, "critic_grad_norm": 0.051888562738895416, "ratio": 0.9999281167984009, "entropy": 0.7477754831314087, "incre_win_rate": 0.8974358974358975, "step": 1076}
{"time": 1767336199.067945, "phase": "eval", "update": 1076, "total_env_steps": 3443200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.847578642384107, "step": 1076}
{"time": 1767336203.1390963, "phase": "train", "update": 1077, "total_env_steps": 3446400, "episode_reward": 0.25947535037994385, "value_loss": 0.005133729614317417, "policy_loss": -0.0012359892355576108, "dist_entropy": 0.7731386661529541, "actor_grad_norm": 0.07986646890640259, "critic_grad_norm": 0.04587328061461449, "ratio": 1.0003098249435425, "entropy": 0.7731386661529541, "incre_win_rate": 0.9534883720930233, "step": 1077}
{"time": 1767336207.2363582, "phase": "train", "update": 1078, "total_env_steps": 3449600, "episode_reward": 0.24698418378829956, "value_loss": 0.007152298931032419, "policy_loss": -0.0015909622751371978, "dist_entropy": 0.7826006650924683, "actor_grad_norm": 0.08979903906583786, "critic_grad_norm": 0.04712755233049393, "ratio": 1.000144362449646, "entropy": 0.7826006650924683, "incre_win_rate": 0.926829268292683, "step": 1078}
{"time": 1767336211.314057, "phase": "train", "update": 1079, "total_env_steps": 3452800, "episode_reward": 0.2436884343624115, "value_loss": 0.00895498190075159, "policy_loss": -0.0008902813598979265, "dist_entropy": 0.7372832655906677, "actor_grad_norm": 0.0800616443157196, "critic_grad_norm": 0.03692338615655899, "ratio": 1.0001055002212524, "entropy": 0.7372832655906677, "incre_win_rate": 0.9, "step": 1079}
{"time": 1767336215.452256, "phase": "train", "update": 1080, "total_env_steps": 3456000, "episode_reward": 0.26003727316856384, "value_loss": 0.0060362257063388824, "policy_loss": -0.0013195222052075906, "dist_entropy": 0.7467171907424927, "actor_grad_norm": 0.07799848169088364, "critic_grad_norm": 0.11026892811059952, "ratio": 1.0001267194747925, "entropy": 0.7467171907424927, "incre_win_rate": 0.9767441860465116, "step": 1080}
{"time": 1767336219.5260546, "phase": "train", "update": 1081, "total_env_steps": 3459200, "episode_reward": 0.24154232442378998, "value_loss": 0.008805825747549534, "policy_loss": -0.0016556950974646156, "dist_entropy": 0.7593682885169983, "actor_grad_norm": 0.09461678564548492, "critic_grad_norm": 0.07614018768072128, "ratio": 0.9999570846557617, "entropy": 0.7593682885169983, "incre_win_rate": 0.8205128205128205, "step": 1081}
{"time": 1767336223.6448596, "phase": "train", "update": 1082, "total_env_steps": 3462400, "episode_reward": 0.25132864713668823, "value_loss": 0.006527078151702881, "policy_loss": -0.0013246608120184079, "dist_entropy": 0.7691917419433594, "actor_grad_norm": 0.11204316467046738, "critic_grad_norm": 0.04976914823055267, "ratio": 1.0003077983856201, "entropy": 0.7691917419433594, "incre_win_rate": 0.9024390243902439, "step": 1082}
{"time": 1767336227.730827, "phase": "train", "update": 1083, "total_env_steps": 3465600, "episode_reward": 0.24391087889671326, "value_loss": 0.008037204388529062, "policy_loss": -0.0013818029452906445, "dist_entropy": 0.7507201075553894, "actor_grad_norm": 0.09428928792476654, "critic_grad_norm": 0.07107459753751755, "ratio": 0.9998189806938171, "entropy": 0.7507201075553894, "incre_win_rate": 0.8974358974358975, "step": 1083}
{"time": 1767336231.8276274, "phase": "train", "update": 1084, "total_env_steps": 3468800, "episode_reward": 0.2572687268257141, "value_loss": 0.007684297394007444, "policy_loss": -0.0011835871300956314, "dist_entropy": 0.7395641803741455, "actor_grad_norm": 0.08292125165462494, "critic_grad_norm": 0.04055257514119148, "ratio": 0.9998877644538879, "entropy": 0.7395641803741455, "incre_win_rate": 0.9534883720930233, "step": 1084}
{"time": 1767336235.9380808, "phase": "train", "update": 1085, "total_env_steps": 3472000, "episode_reward": 0.2528456449508667, "value_loss": 0.006623288057744503, "policy_loss": -0.0011251465494382274, "dist_entropy": 0.7280561447143554, "actor_grad_norm": 0.11522196978330612, "critic_grad_norm": 0.04275062307715416, "ratio": 1.0000355243682861, "entropy": 0.7280561447143554, "incre_win_rate": 0.8571428571428571, "step": 1085}
{"time": 1767336240.039618, "phase": "train", "update": 1086, "total_env_steps": 3475200, "episode_reward": 0.26023125648498535, "value_loss": 0.00603401567786932, "policy_loss": -0.0013867602424051384, "dist_entropy": 0.7363363265991211, "actor_grad_norm": 0.09853928536176682, "critic_grad_norm": 0.03327368199825287, "ratio": 0.9999732971191406, "entropy": 0.7363363265991211, "incre_win_rate": 0.9285714285714286, "step": 1086}
{"time": 1767336244.1344159, "phase": "train", "update": 1087, "total_env_steps": 3478400, "episode_reward": 0.2540278434753418, "value_loss": 0.00425553023815155, "policy_loss": -0.0017408235009352068, "dist_entropy": 0.7523590087890625, "actor_grad_norm": 0.0911833718419075, "critic_grad_norm": 0.026228902861475945, "ratio": 0.9999347925186157, "entropy": 0.7523590087890625, "incre_win_rate": 0.9487179487179487, "step": 1087}
{"time": 1767336248.1830978, "phase": "train", "update": 1088, "total_env_steps": 3481600, "episode_reward": 0.24136537313461304, "value_loss": 0.0065748939290642735, "policy_loss": -0.0014681245983304337, "dist_entropy": 0.7384294033050537, "actor_grad_norm": 0.09294505417346954, "critic_grad_norm": 0.03038485161960125, "ratio": 0.9999620318412781, "entropy": 0.7384294033050537, "incre_win_rate": 0.8809523809523809, "step": 1088}
{"time": 1767336252.298908, "phase": "train", "update": 1089, "total_env_steps": 3484800, "episode_reward": 0.2501034736633301, "value_loss": 0.00697436248883605, "policy_loss": -0.001386840080776608, "dist_entropy": 0.7491217374801635, "actor_grad_norm": 0.10629117488861084, "critic_grad_norm": 0.014478257857263088, "ratio": 0.9999117851257324, "entropy": 0.7491217374801635, "incre_win_rate": 0.8809523809523809, "step": 1089}
{"time": 1767336256.4171135, "phase": "train", "update": 1090, "total_env_steps": 3488000, "episode_reward": 0.25165149569511414, "value_loss": 0.00789462924003601, "policy_loss": -0.0011075658174138693, "dist_entropy": 0.7402300357818603, "actor_grad_norm": 0.10077065229415894, "critic_grad_norm": 0.039915867149829865, "ratio": 0.9998661875724792, "entropy": 0.7402300357818603, "incre_win_rate": 0.8536585365853658, "step": 1090}
{"time": 1767336260.4944148, "phase": "train", "update": 1091, "total_env_steps": 3491200, "episode_reward": 0.2506420910358429, "value_loss": 0.007446739729493857, "policy_loss": -0.0013760087943190057, "dist_entropy": 0.7544546723365784, "actor_grad_norm": 0.09793298691511154, "critic_grad_norm": 0.03785082697868347, "ratio": 1.000030517578125, "entropy": 0.7544546723365784, "incre_win_rate": 0.9024390243902439, "step": 1091}
{"time": 1767336264.5751586, "phase": "train", "update": 1092, "total_env_steps": 3494400, "episode_reward": 0.24435430765151978, "value_loss": 0.006681874301284552, "policy_loss": -0.0012552796036629844, "dist_entropy": 0.7606978058815003, "actor_grad_norm": 0.08133996278047562, "critic_grad_norm": 0.031805042177438736, "ratio": 1.0003994703292847, "entropy": 0.7606978058815003, "incre_win_rate": 0.8780487804878049, "step": 1092}
{"time": 1767336268.6709125, "phase": "train", "update": 1093, "total_env_steps": 3497600, "episode_reward": 0.25486651062965393, "value_loss": 0.005739989131689072, "policy_loss": -0.0009488707569516919, "dist_entropy": 0.7623027801513672, "actor_grad_norm": 0.07917718589305878, "critic_grad_norm": 0.04166610911488533, "ratio": 1.0001440048217773, "entropy": 0.7623027801513672, "incre_win_rate": 0.8809523809523809, "step": 1093}
{"time": 1767336272.7580202, "phase": "train", "update": 1094, "total_env_steps": 3500800, "episode_reward": 0.2554977238178253, "value_loss": 0.006303600594401359, "policy_loss": -0.0012146385143410043, "dist_entropy": 0.7716488242149353, "actor_grad_norm": 0.11985142529010773, "critic_grad_norm": 0.03985781595110893, "ratio": 1.0003494024276733, "entropy": 0.7716488242149353, "incre_win_rate": 0.975, "step": 1094}
{"time": 1767336276.8076618, "phase": "train", "update": 1095, "total_env_steps": 3504000, "episode_reward": 0.25074300169944763, "value_loss": 0.004190453607589006, "policy_loss": -0.0014608479489524484, "dist_entropy": 0.7588083982467652, "actor_grad_norm": 0.12239743769168854, "critic_grad_norm": 0.03152114897966385, "ratio": 1.0000501871109009, "entropy": 0.7588083982467652, "incre_win_rate": 0.9090909090909091, "step": 1095}
{"time": 1767336280.841321, "phase": "train", "update": 1096, "total_env_steps": 3507200, "episode_reward": 0.26500001549720764, "value_loss": 0.003200427116826177, "policy_loss": -0.0012321322244829957, "dist_entropy": 0.7571326613426208, "actor_grad_norm": 0.08940105140209198, "critic_grad_norm": 0.06252347677946091, "ratio": 0.9999364018440247, "entropy": 0.7571326613426208, "incre_win_rate": 1.0, "step": 1096}
{"time": 1767336284.9008577, "phase": "train", "update": 1097, "total_env_steps": 3510400, "episode_reward": 0.25711920857429504, "value_loss": 0.005916141718626022, "policy_loss": -0.0015157974801823571, "dist_entropy": 0.7761870980262756, "actor_grad_norm": 0.08294530212879181, "critic_grad_norm": 0.04320172965526581, "ratio": 1.00019109249115, "entropy": 0.7761870980262756, "incre_win_rate": 0.925, "step": 1097}
{"time": 1767336288.979152, "phase": "train", "update": 1098, "total_env_steps": 3513600, "episode_reward": 0.24843543767929077, "value_loss": 0.007324628345668316, "policy_loss": -0.0015147745023966763, "dist_entropy": 0.7559261560440064, "actor_grad_norm": 0.09343825280666351, "critic_grad_norm": 0.03975678235292435, "ratio": 0.9993664026260376, "entropy": 0.7559261560440064, "incre_win_rate": 0.9024390243902439, "step": 1098}
{"time": 1767336293.0734496, "phase": "train", "update": 1099, "total_env_steps": 3516800, "episode_reward": 0.2507031559944153, "value_loss": 0.006613240297883749, "policy_loss": -0.0011001044330479991, "dist_entropy": 0.7564377307891845, "actor_grad_norm": 0.10483721643686295, "critic_grad_norm": 0.049129124730825424, "ratio": 1.000038743019104, "entropy": 0.7564377307891845, "incre_win_rate": 0.8888888888888888, "step": 1099}
{"time": 1767336297.1356504, "phase": "train", "update": 1100, "total_env_steps": 3520000, "episode_reward": 0.2532879710197449, "value_loss": 0.010111270472407341, "policy_loss": -0.001277369766697234, "dist_entropy": 0.7617946028709411, "actor_grad_norm": 0.08362468332052231, "critic_grad_norm": 0.04162972792983055, "ratio": 0.9999248385429382, "entropy": 0.7617946028709411, "incre_win_rate": 0.925, "step": 1100}
{"time": 1767336301.179906, "phase": "train", "update": 1101, "total_env_steps": 3523200, "episode_reward": 0.2579387426376343, "value_loss": 0.005251147411763668, "policy_loss": -0.0014720536889925029, "dist_entropy": 0.7606461882591248, "actor_grad_norm": 0.0939425528049469, "critic_grad_norm": 0.04753826558589935, "ratio": 0.9997521638870239, "entropy": 0.7606461882591248, "incre_win_rate": 0.9534883720930233, "step": 1101}
{"time": 1767336311.5422192, "phase": "eval", "update": 1101, "total_env_steps": 3523200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.878156043046353, "step": 1101}
{"time": 1767336315.6478703, "phase": "train", "update": 1102, "total_env_steps": 3526400, "episode_reward": 0.25307536125183105, "value_loss": 0.006173926685005426, "policy_loss": -0.0009205673521321955, "dist_entropy": 0.7648008823394775, "actor_grad_norm": 0.08992984145879745, "critic_grad_norm": 0.038654908537864685, "ratio": 0.9998623728752136, "entropy": 0.7648008823394775, "incre_win_rate": 0.8809523809523809, "step": 1102}
{"time": 1767336319.7198749, "phase": "train", "update": 1103, "total_env_steps": 3529600, "episode_reward": 0.25351354479789734, "value_loss": 0.005918733868747949, "policy_loss": -0.0011434584631444978, "dist_entropy": 0.7914919376373291, "actor_grad_norm": 0.10341037809848785, "critic_grad_norm": 0.03525807335972786, "ratio": 1.0001325607299805, "entropy": 0.7914919376373291, "incre_win_rate": 0.925, "step": 1103}
{"time": 1767336323.807984, "phase": "train", "update": 1104, "total_env_steps": 3532800, "episode_reward": 0.2569490075111389, "value_loss": 0.004820653144270182, "policy_loss": -0.001286070494639091, "dist_entropy": 0.7514867305755615, "actor_grad_norm": 0.1201212927699089, "critic_grad_norm": 0.029811447486281395, "ratio": 0.9995953440666199, "entropy": 0.7514867305755615, "incre_win_rate": 0.9512195121951219, "step": 1104}
{"time": 1767336327.8577535, "phase": "train", "update": 1105, "total_env_steps": 3536000, "episode_reward": 0.2512955367565155, "value_loss": 0.005676748137921095, "policy_loss": -0.0015058884121575745, "dist_entropy": 0.7669533967971802, "actor_grad_norm": 0.14764262735843658, "critic_grad_norm": 0.051690537482500076, "ratio": 1.0003494024276733, "entropy": 0.7669533967971802, "incre_win_rate": 0.925, "step": 1105}
{"time": 1767336331.9247036, "phase": "train", "update": 1106, "total_env_steps": 3539200, "episode_reward": 0.2572764754295349, "value_loss": 0.005620790924876928, "policy_loss": -0.001498449853704642, "dist_entropy": 0.7683232426643372, "actor_grad_norm": 0.13869069516658783, "critic_grad_norm": 0.02868746593594551, "ratio": 0.9999697804450989, "entropy": 0.7683232426643372, "incre_win_rate": 0.9523809523809523, "step": 1106}
{"time": 1767336336.0176692, "phase": "train", "update": 1107, "total_env_steps": 3542400, "episode_reward": 0.2477473020553589, "value_loss": 0.007686134986579418, "policy_loss": -0.001229082270175752, "dist_entropy": 0.7589362382888794, "actor_grad_norm": 0.08834357559680939, "critic_grad_norm": 0.0551501028239727, "ratio": 1.000055193901062, "entropy": 0.7589362382888794, "incre_win_rate": 0.9285714285714286, "step": 1107}
{"time": 1767336340.0637283, "phase": "train", "update": 1108, "total_env_steps": 3545600, "episode_reward": 0.23521989583969116, "value_loss": 0.006494474597275257, "policy_loss": -0.0013218914825664286, "dist_entropy": 0.7538657307624816, "actor_grad_norm": 0.10041745007038116, "critic_grad_norm": 0.05612076446413994, "ratio": 0.9998283386230469, "entropy": 0.7538657307624816, "incre_win_rate": 0.8157894736842105, "step": 1108}
{"time": 1767336344.1075354, "phase": "train", "update": 1109, "total_env_steps": 3548800, "episode_reward": 0.2439926564693451, "value_loss": 0.00675903856754303, "policy_loss": -0.0011876948012025323, "dist_entropy": 0.7555608630180359, "actor_grad_norm": 0.0807228609919548, "critic_grad_norm": 0.04766688868403435, "ratio": 0.9995865821838379, "entropy": 0.7555608630180359, "incre_win_rate": 0.926829268292683, "step": 1109}
{"time": 1767336348.1027586, "phase": "train", "update": 1110, "total_env_steps": 3552000, "episode_reward": 0.2327747344970703, "value_loss": 0.009019332937896252, "policy_loss": -0.0011551039142598362, "dist_entropy": 0.7571063041687012, "actor_grad_norm": 0.10560419410467148, "critic_grad_norm": 0.042398884892463684, "ratio": 1.0000205039978027, "entropy": 0.7571063041687012, "incre_win_rate": 0.8974358974358975, "step": 1110}
{"time": 1767336352.1262393, "phase": "train", "update": 1111, "total_env_steps": 3555200, "episode_reward": 0.2521440386772156, "value_loss": 0.006912003364413976, "policy_loss": -0.0011737633201896358, "dist_entropy": 0.7514617800712585, "actor_grad_norm": 0.1148890033364296, "critic_grad_norm": 0.0805811658501625, "ratio": 0.9998655319213867, "entropy": 0.7514617800712585, "incre_win_rate": 0.9047619047619048, "step": 1111}
{"time": 1767336356.1582358, "phase": "train", "update": 1112, "total_env_steps": 3558400, "episode_reward": 0.2493005245923996, "value_loss": 0.005013836082071066, "policy_loss": -0.0010560636477457308, "dist_entropy": 0.7676899313926697, "actor_grad_norm": 0.08820875734090805, "critic_grad_norm": 0.05233578011393547, "ratio": 0.9996387362480164, "entropy": 0.7676899313926697, "incre_win_rate": 0.9230769230769231, "step": 1112}
{"time": 1767336360.1920946, "phase": "train", "update": 1113, "total_env_steps": 3561600, "episode_reward": 0.23805047571659088, "value_loss": 0.010619691014289856, "policy_loss": -0.001413318832481991, "dist_entropy": 0.7603118658065796, "actor_grad_norm": 0.11258409172296524, "critic_grad_norm": 0.09580286592245102, "ratio": 1.0003106594085693, "entropy": 0.7603118658065796, "incre_win_rate": 0.7857142857142857, "step": 1113}
{"time": 1767336364.2179928, "phase": "train", "update": 1114, "total_env_steps": 3564800, "episode_reward": 0.24727387726306915, "value_loss": 0.012521804682910443, "policy_loss": -0.0011972523681911262, "dist_entropy": 0.7757228255271912, "actor_grad_norm": 0.10730896145105362, "critic_grad_norm": 0.05445863679051399, "ratio": 0.9999640583992004, "entropy": 0.7757228255271912, "incre_win_rate": 0.85, "step": 1114}
{"time": 1767336368.2985826, "phase": "train", "update": 1115, "total_env_steps": 3568000, "episode_reward": 0.2324254959821701, "value_loss": 0.01375216394662857, "policy_loss": -0.001336881787442934, "dist_entropy": 0.7578003287315369, "actor_grad_norm": 0.1095857247710228, "critic_grad_norm": 0.03960598632693291, "ratio": 0.9998589754104614, "entropy": 0.7578003287315369, "incre_win_rate": 0.7692307692307693, "step": 1115}
{"time": 1767336372.3774452, "phase": "train", "update": 1116, "total_env_steps": 3571200, "episode_reward": 0.2444981336593628, "value_loss": 0.007839077338576316, "policy_loss": -0.0009010117909241444, "dist_entropy": 0.7661435842514038, "actor_grad_norm": 0.1179027333855629, "critic_grad_norm": 0.07928553968667984, "ratio": 1.0001009702682495, "entropy": 0.7661435842514038, "incre_win_rate": 0.926829268292683, "step": 1116}
{"time": 1767336376.4895287, "phase": "train", "update": 1117, "total_env_steps": 3574400, "episode_reward": 0.2552732229232788, "value_loss": 0.003672505775466561, "policy_loss": -0.0010715223035504095, "dist_entropy": 0.7612892031669617, "actor_grad_norm": 0.07587318867444992, "critic_grad_norm": 0.0653858408331871, "ratio": 1.0000308752059937, "entropy": 0.7612892031669617, "incre_win_rate": 0.9767441860465116, "step": 1117}
{"time": 1767336380.544382, "phase": "train", "update": 1118, "total_env_steps": 3577600, "episode_reward": 0.2436118721961975, "value_loss": 0.005629240442067385, "policy_loss": -0.0012037398919943598, "dist_entropy": 0.7764101505279541, "actor_grad_norm": 0.08298810571432114, "critic_grad_norm": 0.035551268607378006, "ratio": 0.9997846484184265, "entropy": 0.7764101505279541, "incre_win_rate": 0.8974358974358975, "step": 1118}
{"time": 1767336384.6050143, "phase": "train", "update": 1119, "total_env_steps": 3580800, "episode_reward": 0.2455960214138031, "value_loss": 0.006745740491896868, "policy_loss": -0.0013269601207611004, "dist_entropy": 0.7867289185523987, "actor_grad_norm": 0.09131445735692978, "critic_grad_norm": 0.046213340014219284, "ratio": 0.9999197125434875, "entropy": 0.7867289185523987, "incre_win_rate": 0.875, "step": 1119}
{"time": 1767336388.7230825, "phase": "train", "update": 1120, "total_env_steps": 3584000, "episode_reward": 0.2486056536436081, "value_loss": 0.006706699915230274, "policy_loss": -0.0014417465057633195, "dist_entropy": 0.825252091884613, "actor_grad_norm": 0.09191925823688507, "critic_grad_norm": 0.026232758536934853, "ratio": 1.000365138053894, "entropy": 0.825252091884613, "incre_win_rate": 0.9024390243902439, "step": 1120}
{"time": 1767336392.7648842, "phase": "train", "update": 1121, "total_env_steps": 3587200, "episode_reward": 0.2502323091030121, "value_loss": 0.008978085592389107, "policy_loss": -0.0014618820147401124, "dist_entropy": 0.7777239203453064, "actor_grad_norm": 0.12238388508558273, "critic_grad_norm": 0.0377829484641552, "ratio": 0.9998719096183777, "entropy": 0.7777239203453064, "incre_win_rate": 0.8780487804878049, "step": 1121}
{"time": 1767336396.9105606, "phase": "train", "update": 1122, "total_env_steps": 3590400, "episode_reward": 0.2566240727901459, "value_loss": 0.008135748468339444, "policy_loss": -0.0018370357861250853, "dist_entropy": 0.7597745418548584, "actor_grad_norm": 0.1060425266623497, "critic_grad_norm": 0.025167230516672134, "ratio": 0.9995953440666199, "entropy": 0.7597745418548584, "incre_win_rate": 0.9047619047619048, "step": 1122}
{"time": 1767336400.977691, "phase": "train", "update": 1123, "total_env_steps": 3593600, "episode_reward": 0.25604769587516785, "value_loss": 0.0061643383465707306, "policy_loss": -0.0011242020981015344, "dist_entropy": 0.7324585318565369, "actor_grad_norm": 0.08271536976099014, "critic_grad_norm": 0.036746252328157425, "ratio": 1.0001192092895508, "entropy": 0.7324585318565369, "incre_win_rate": 0.926829268292683, "step": 1123}
{"time": 1767336405.042403, "phase": "train", "update": 1124, "total_env_steps": 3596800, "episode_reward": 0.2514517903327942, "value_loss": 0.007322615385055542, "policy_loss": -0.0012213906907007298, "dist_entropy": 0.7348070621490479, "actor_grad_norm": 0.10112924873828888, "critic_grad_norm": 0.029152540490031242, "ratio": 1.0003507137298584, "entropy": 0.7348070621490479, "incre_win_rate": 0.9047619047619048, "step": 1124}
{"time": 1767336409.102231, "phase": "train", "update": 1125, "total_env_steps": 3600000, "episode_reward": 0.25243687629699707, "value_loss": 0.007086375635117293, "policy_loss": -0.0011673810461807932, "dist_entropy": 0.7304324388504029, "actor_grad_norm": 0.12325054407119751, "critic_grad_norm": 0.043712206184864044, "ratio": 0.9994605183601379, "entropy": 0.7304324388504029, "incre_win_rate": 0.9285714285714286, "step": 1125}
{"time": 1767336413.143894, "phase": "train", "update": 1126, "total_env_steps": 3603200, "episode_reward": 0.2459374964237213, "value_loss": 0.008897058106958866, "policy_loss": -0.00110987288668305, "dist_entropy": 0.714931321144104, "actor_grad_norm": 0.10919284075498581, "critic_grad_norm": 0.042648233473300934, "ratio": 0.999696671962738, "entropy": 0.714931321144104, "incre_win_rate": 0.8292682926829268, "step": 1126}
{"time": 1767336423.1627934, "phase": "eval", "update": 1126, "total_env_steps": 3603200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.91375206953642, "step": 1126}
{"time": 1767336427.2443187, "phase": "train", "update": 1127, "total_env_steps": 3606400, "episode_reward": 0.24502897262573242, "value_loss": 0.007363218814134598, "policy_loss": -0.0011740606482476324, "dist_entropy": 0.7333066821098327, "actor_grad_norm": 0.12002646178007126, "critic_grad_norm": 0.03231526166200638, "ratio": 0.9997542500495911, "entropy": 0.7333066821098327, "incre_win_rate": 0.9, "step": 1127}
{"time": 1767336431.3836343, "phase": "train", "update": 1128, "total_env_steps": 3609600, "episode_reward": 0.2532802224159241, "value_loss": 0.005093355197459459, "policy_loss": -0.0011293850444122455, "dist_entropy": 0.7436218023300171, "actor_grad_norm": 0.09652812033891678, "critic_grad_norm": 0.03170473873615265, "ratio": 0.9997645616531372, "entropy": 0.7436218023300171, "incre_win_rate": 0.9512195121951219, "step": 1128}
{"time": 1767336435.4811866, "phase": "train", "update": 1129, "total_env_steps": 3612800, "episode_reward": 0.254734069108963, "value_loss": 0.004543142672628164, "policy_loss": -0.0012918340754481505, "dist_entropy": 0.7471774935722351, "actor_grad_norm": 0.08524298667907715, "critic_grad_norm": 0.023692259564995766, "ratio": 1.0000618696212769, "entropy": 0.7471774935722351, "incre_win_rate": 0.925, "step": 1129}
{"time": 1767336439.5021775, "phase": "train", "update": 1130, "total_env_steps": 3616000, "episode_reward": 0.25528663396835327, "value_loss": 0.004005095409229398, "policy_loss": -0.0009452713765531584, "dist_entropy": 0.7628527402877807, "actor_grad_norm": 0.07603447884321213, "critic_grad_norm": 0.031722985208034515, "ratio": 0.9999329447746277, "entropy": 0.7628527402877807, "incre_win_rate": 0.975609756097561, "step": 1130}
{"time": 1767336443.55415, "phase": "train", "update": 1131, "total_env_steps": 3619200, "episode_reward": 0.2462308704853058, "value_loss": 0.008651600778102874, "policy_loss": -0.0009901283421584139, "dist_entropy": 0.7459837198257446, "actor_grad_norm": 0.08976656198501587, "critic_grad_norm": 0.04136401414871216, "ratio": 1.0002613067626953, "entropy": 0.7459837198257446, "incre_win_rate": 0.8571428571428571, "step": 1131}
{"time": 1767336447.6682293, "phase": "train", "update": 1132, "total_env_steps": 3622400, "episode_reward": 0.24395383894443512, "value_loss": 0.009800588898360729, "policy_loss": -0.0012398310396591228, "dist_entropy": 0.7629260540008544, "actor_grad_norm": 0.08671390265226364, "critic_grad_norm": 0.05030955746769905, "ratio": 1.0000337362289429, "entropy": 0.7629260540008544, "incre_win_rate": 0.8292682926829268, "step": 1132}
{"time": 1767336451.733625, "phase": "train", "update": 1133, "total_env_steps": 3625600, "episode_reward": 0.24791650474071503, "value_loss": 0.01081100683659315, "policy_loss": -0.0011518829457607183, "dist_entropy": 0.7573345899581909, "actor_grad_norm": 0.09005264937877655, "critic_grad_norm": 0.04529137536883354, "ratio": 0.9997087717056274, "entropy": 0.7573345899581909, "incre_win_rate": 0.9, "step": 1133}
{"time": 1767336455.8472407, "phase": "train", "update": 1134, "total_env_steps": 3628800, "episode_reward": 0.2466023564338684, "value_loss": 0.011432006768882275, "policy_loss": -0.0012143569283487921, "dist_entropy": 0.7697367429733276, "actor_grad_norm": 0.0975906252861023, "critic_grad_norm": 0.031155740842223167, "ratio": 0.9999964833259583, "entropy": 0.7697367429733276, "incre_win_rate": 0.8536585365853658, "step": 1134}
{"time": 1767336459.9061406, "phase": "train", "update": 1135, "total_env_steps": 3632000, "episode_reward": 0.2530587911605835, "value_loss": 0.008338767290115356, "policy_loss": -0.0012318194084500079, "dist_entropy": 0.7604577779769898, "actor_grad_norm": 0.09780720621347427, "critic_grad_norm": 0.03117082454264164, "ratio": 0.999474048614502, "entropy": 0.7604577779769898, "incre_win_rate": 0.9090909090909091, "step": 1135}
{"time": 1767336463.95485, "phase": "train", "update": 1136, "total_env_steps": 3635200, "episode_reward": 0.2456369251012802, "value_loss": 0.006302103865891695, "policy_loss": -0.0009008264109134246, "dist_entropy": 0.8012146711349487, "actor_grad_norm": 0.08906801789999008, "critic_grad_norm": 0.041148968040943146, "ratio": 0.9996833801269531, "entropy": 0.8012146711349487, "incre_win_rate": 0.85, "step": 1136}
{"time": 1767336468.0531852, "phase": "train", "update": 1137, "total_env_steps": 3638400, "episode_reward": 0.24698469042778015, "value_loss": 0.006417580135166645, "policy_loss": -0.0010752773941907988, "dist_entropy": 0.7979466915130615, "actor_grad_norm": 0.08185636252164841, "critic_grad_norm": 0.02549557201564312, "ratio": 0.9998138546943665, "entropy": 0.7979466915130615, "incre_win_rate": 0.8571428571428571, "step": 1137}
{"time": 1767336472.186822, "phase": "train", "update": 1138, "total_env_steps": 3641600, "episode_reward": 0.25841525197029114, "value_loss": 0.005130108166486025, "policy_loss": -0.0016085302364178488, "dist_entropy": 0.808271610736847, "actor_grad_norm": 0.08908742666244507, "critic_grad_norm": 0.02499622292816639, "ratio": 0.999726414680481, "entropy": 0.808271610736847, "incre_win_rate": 0.9, "step": 1138}
{"time": 1767336476.266642, "phase": "train", "update": 1139, "total_env_steps": 3644800, "episode_reward": 0.24611550569534302, "value_loss": 0.010857131518423557, "policy_loss": -0.0014691724514520389, "dist_entropy": 0.7909479022026062, "actor_grad_norm": 0.10002956539392471, "critic_grad_norm": 0.07971111685037613, "ratio": 0.9997210502624512, "entropy": 0.7909479022026062, "incre_win_rate": 0.8536585365853658, "step": 1139}
{"time": 1767336480.339255, "phase": "train", "update": 1140, "total_env_steps": 3648000, "episode_reward": 0.2533515989780426, "value_loss": 0.006417761836200952, "policy_loss": -0.001673443817903797, "dist_entropy": 0.746264636516571, "actor_grad_norm": 0.10883962363004684, "critic_grad_norm": 0.05498666316270828, "ratio": 0.9998998045921326, "entropy": 0.746264636516571, "incre_win_rate": 0.926829268292683, "step": 1140}
{"time": 1767336484.3846695, "phase": "train", "update": 1141, "total_env_steps": 3651200, "episode_reward": 0.24934864044189453, "value_loss": 0.007578298263251781, "policy_loss": -0.001149368518917626, "dist_entropy": 0.7522863268852233, "actor_grad_norm": 0.1013166680932045, "critic_grad_norm": 0.046849172562360764, "ratio": 0.9993961453437805, "entropy": 0.7522863268852233, "incre_win_rate": 0.8809523809523809, "step": 1141}
{"time": 1767336488.511314, "phase": "train", "update": 1142, "total_env_steps": 3654400, "episode_reward": 0.25159716606140137, "value_loss": 0.008226916380226611, "policy_loss": -0.0012713223094891646, "dist_entropy": 0.7651620268821716, "actor_grad_norm": 0.09030982106924057, "critic_grad_norm": 0.05327364429831505, "ratio": 0.9997991919517517, "entropy": 0.7651620268821716, "incre_win_rate": 0.8604651162790697, "step": 1142}
{"time": 1767336492.6253119, "phase": "train", "update": 1143, "total_env_steps": 3657600, "episode_reward": 0.2571895718574524, "value_loss": 0.005522929225116968, "policy_loss": -0.001400335287640786, "dist_entropy": 0.7712883353233337, "actor_grad_norm": 0.10607903450727463, "critic_grad_norm": 0.05052681639790535, "ratio": 0.9999892115592957, "entropy": 0.7712883353233337, "incre_win_rate": 0.9761904761904762, "step": 1143}
{"time": 1767336521.2174416, "phase": "train", "update": 1144, "total_env_steps": 3660800, "episode_reward": 0.24048428237438202, "value_loss": 0.05909515842795372, "policy_loss": -0.0005164759115288576, "dist_entropy": 0.7732847452163696, "actor_grad_norm": 0.08168282359838486, "critic_grad_norm": 0.2275632917881012, "ratio": 0.999927818775177, "entropy": 0.7732847452163696, "incre_win_rate": 0.8611111111111112, "step": 1144}
{"time": 1767336525.240072, "phase": "train", "update": 1145, "total_env_steps": 3664000, "episode_reward": 0.25431808829307556, "value_loss": 0.006647117715328932, "policy_loss": -0.0012329390129472984, "dist_entropy": 0.7695437788963317, "actor_grad_norm": 0.10660742968320847, "critic_grad_norm": 0.18319112062454224, "ratio": 0.9999791383743286, "entropy": 0.7695437788963317, "incre_win_rate": 0.925, "step": 1145}
{"time": 1767336529.3140342, "phase": "train", "update": 1146, "total_env_steps": 3667200, "episode_reward": 0.2559887170791626, "value_loss": 0.00542389452457428, "policy_loss": -0.001132974847509871, "dist_entropy": 0.7525827765464783, "actor_grad_norm": 0.09559114277362823, "critic_grad_norm": 0.1436491161584854, "ratio": 1.0002626180648804, "entropy": 0.7525827765464783, "incre_win_rate": 0.9302325581395349, "step": 1146}
{"time": 1767336533.3327208, "phase": "train", "update": 1147, "total_env_steps": 3670400, "episode_reward": 0.25169238448143005, "value_loss": 0.006476031802594662, "policy_loss": -0.0011862743968933387, "dist_entropy": 0.7622558116912842, "actor_grad_norm": 0.090239979326725, "critic_grad_norm": 0.09470085799694061, "ratio": 1.0000942945480347, "entropy": 0.7622558116912842, "incre_win_rate": 0.8837209302325582, "step": 1147}
{"time": 1767336537.4738207, "phase": "train", "update": 1148, "total_env_steps": 3673600, "episode_reward": 0.24237428605556488, "value_loss": 0.009273382276296616, "policy_loss": -0.0012616139013784887, "dist_entropy": 0.7706008315086365, "actor_grad_norm": 0.08371885865926743, "critic_grad_norm": 0.13001835346221924, "ratio": 0.9998159408569336, "entropy": 0.7706008315086365, "incre_win_rate": 0.825, "step": 1148}
{"time": 1767336541.5124028, "phase": "train", "update": 1149, "total_env_steps": 3676800, "episode_reward": 0.23690396547317505, "value_loss": 0.014569842070341111, "policy_loss": -0.001538012134388822, "dist_entropy": 0.7359984874725342, "actor_grad_norm": 0.12900708615779877, "critic_grad_norm": 0.10147207230329514, "ratio": 0.9996344447135925, "entropy": 0.7359984874725342, "incre_win_rate": 0.7804878048780488, "step": 1149}
{"time": 1767336545.5752182, "phase": "train", "update": 1150, "total_env_steps": 3680000, "episode_reward": 0.24385452270507812, "value_loss": 0.007665791362524032, "policy_loss": -0.0011089148848391517, "dist_entropy": 0.7638707995414734, "actor_grad_norm": 0.12025723606348038, "critic_grad_norm": 0.055269885808229446, "ratio": 1.0000046491622925, "entropy": 0.7638707995414734, "incre_win_rate": 0.8974358974358975, "step": 1150}
{"time": 1767336549.6798449, "phase": "train", "update": 1151, "total_env_steps": 3683200, "episode_reward": 0.24902784824371338, "value_loss": 0.005417838972061872, "policy_loss": -0.0011866305910878338, "dist_entropy": 0.795036232471466, "actor_grad_norm": 0.11135776340961456, "critic_grad_norm": 0.039858877658843994, "ratio": 0.9998777508735657, "entropy": 0.795036232471466, "incre_win_rate": 0.926829268292683, "step": 1151}
{"time": 1767336559.8705797, "phase": "eval", "update": 1151, "total_env_steps": 3683200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.706539735099337, "step": 1151}
{"time": 1767336563.912325, "phase": "train", "update": 1152, "total_env_steps": 3686400, "episode_reward": 0.25029388070106506, "value_loss": 0.0053999838419258595, "policy_loss": -0.0011300431348058027, "dist_entropy": 0.7740209341049195, "actor_grad_norm": 0.12221379578113556, "critic_grad_norm": 0.04675034433603287, "ratio": 1.0001516342163086, "entropy": 0.7740209341049195, "incre_win_rate": 0.8809523809523809, "step": 1152}
{"time": 1767336567.981483, "phase": "train", "update": 1153, "total_env_steps": 3689600, "episode_reward": 0.2523892819881439, "value_loss": 0.004854724742472172, "policy_loss": -0.0011776423681723713, "dist_entropy": 0.7816523432731628, "actor_grad_norm": 0.09561712294816971, "critic_grad_norm": 0.04911157861351967, "ratio": 0.9998638033866882, "entropy": 0.7816523432731628, "incre_win_rate": 0.925, "step": 1153}
{"time": 1767336572.0721667, "phase": "train", "update": 1154, "total_env_steps": 3692800, "episode_reward": 0.2539859414100647, "value_loss": 0.005858489125967026, "policy_loss": -0.0008624371130521169, "dist_entropy": 0.779776108264923, "actor_grad_norm": 0.09708648175001144, "critic_grad_norm": 0.03268522769212723, "ratio": 1.0000275373458862, "entropy": 0.779776108264923, "incre_win_rate": 0.9523809523809523, "step": 1154}
{"time": 1767336576.1194706, "phase": "train", "update": 1155, "total_env_steps": 3696000, "episode_reward": 0.23720508813858032, "value_loss": 0.009577188082039357, "policy_loss": -0.0012992085920092932, "dist_entropy": 0.7552263379096985, "actor_grad_norm": 0.10261781513690948, "critic_grad_norm": 0.08786385506391525, "ratio": 1.000186800956726, "entropy": 0.7552263379096985, "incre_win_rate": 0.8717948717948718, "step": 1155}
{"time": 1767336580.1923416, "phase": "train", "update": 1156, "total_env_steps": 3699200, "episode_reward": 0.24622568488121033, "value_loss": 0.005921043921262026, "policy_loss": -0.0013105893244143019, "dist_entropy": 0.7585108995437622, "actor_grad_norm": 0.08883217722177505, "critic_grad_norm": 0.041155509650707245, "ratio": 0.9999033808708191, "entropy": 0.7585108995437622, "incre_win_rate": 0.875, "step": 1156}
{"time": 1767336584.2063344, "phase": "train", "update": 1157, "total_env_steps": 3702400, "episode_reward": 0.24375568330287933, "value_loss": 0.0056809400208294395, "policy_loss": -0.0012384405540565523, "dist_entropy": 0.7395374417304993, "actor_grad_norm": 0.08468981832265854, "critic_grad_norm": 0.03944939002394676, "ratio": 0.9999119639396667, "entropy": 0.7395374417304993, "incre_win_rate": 0.8717948717948718, "step": 1157}
{"time": 1767336588.2833838, "phase": "train", "update": 1158, "total_env_steps": 3705600, "episode_reward": 0.25015830993652344, "value_loss": 0.00493171950802207, "policy_loss": -0.001343500277311449, "dist_entropy": 0.7518407106399536, "actor_grad_norm": 0.09409984946250916, "critic_grad_norm": 0.0476408377289772, "ratio": 0.9999460577964783, "entropy": 0.7518407106399536, "incre_win_rate": 0.8780487804878049, "step": 1158}
{"time": 1767336592.340811, "phase": "train", "update": 1159, "total_env_steps": 3708800, "episode_reward": 0.24315398931503296, "value_loss": 0.005263379123061895, "policy_loss": -0.0010165663612911047, "dist_entropy": 0.7044901728630066, "actor_grad_norm": 0.09425418078899384, "critic_grad_norm": 0.03411422297358513, "ratio": 1.0000007152557373, "entropy": 0.7044901728630066, "incre_win_rate": 0.9024390243902439, "step": 1159}
{"time": 1767336596.4211462, "phase": "train", "update": 1160, "total_env_steps": 3712000, "episode_reward": 0.25235408544540405, "value_loss": 0.0046933812089264395, "policy_loss": -0.00085591430252272, "dist_entropy": 0.7147424221038818, "actor_grad_norm": 0.07502307742834091, "critic_grad_norm": 0.02325494773685932, "ratio": 0.9999853372573853, "entropy": 0.7147424221038818, "incre_win_rate": 0.926829268292683, "step": 1160}
{"time": 1767336600.4830155, "phase": "train", "update": 1161, "total_env_steps": 3715200, "episode_reward": 0.24602803587913513, "value_loss": 0.008838748559355736, "policy_loss": -0.001106533569966217, "dist_entropy": 0.7111850857734681, "actor_grad_norm": 0.09087551385164261, "critic_grad_norm": 0.06312844902276993, "ratio": 1.000011920928955, "entropy": 0.7111850857734681, "incre_win_rate": 0.9047619047619048, "step": 1161}
{"time": 1767336604.5885594, "phase": "train", "update": 1162, "total_env_steps": 3718400, "episode_reward": 0.2591845989227295, "value_loss": 0.004770760983228683, "policy_loss": -0.0010457424014486349, "dist_entropy": 0.7150267601013184, "actor_grad_norm": 0.09998123347759247, "critic_grad_norm": 0.04525667056441307, "ratio": 0.9998939633369446, "entropy": 0.7150267601013184, "incre_win_rate": 0.975, "step": 1162}
{"time": 1767336608.7003787, "phase": "train", "update": 1163, "total_env_steps": 3721600, "episode_reward": 0.25855860114097595, "value_loss": 0.004008141625672579, "policy_loss": -0.0009308392194483872, "dist_entropy": 0.7156434059143066, "actor_grad_norm": 0.10353042930364609, "critic_grad_norm": 0.047849394381046295, "ratio": 1.0000402927398682, "entropy": 0.7156434059143066, "incre_win_rate": 0.9534883720930233, "step": 1163}
{"time": 1767336612.7532935, "phase": "train", "update": 1164, "total_env_steps": 3724800, "episode_reward": 0.24301739037036896, "value_loss": 0.00769474720582366, "policy_loss": -0.0010708847239914831, "dist_entropy": 0.7069907546043396, "actor_grad_norm": 0.09472580999135971, "critic_grad_norm": 0.05605868622660637, "ratio": 1.0000826120376587, "entropy": 0.7069907546043396, "incre_win_rate": 0.85, "step": 1164}
{"time": 1767336616.8133714, "phase": "train", "update": 1165, "total_env_steps": 3728000, "episode_reward": 0.24320882558822632, "value_loss": 0.007998274825513362, "policy_loss": -0.0011606762416088046, "dist_entropy": 0.7142171859741211, "actor_grad_norm": 0.09694813936948776, "critic_grad_norm": 0.04565036669373512, "ratio": 0.9999614953994751, "entropy": 0.7142171859741211, "incre_win_rate": 0.8333333333333334, "step": 1165}
{"time": 1767336620.842563, "phase": "train", "update": 1166, "total_env_steps": 3731200, "episode_reward": 0.24377742409706116, "value_loss": 0.008855736628174782, "policy_loss": -0.0009733289971023851, "dist_entropy": 0.6948824286460876, "actor_grad_norm": 0.0821467712521553, "critic_grad_norm": 0.03675167262554169, "ratio": 0.9998441934585571, "entropy": 0.6948824286460876, "incre_win_rate": 0.8461538461538461, "step": 1166}
{"time": 1767336624.9389963, "phase": "train", "update": 1167, "total_env_steps": 3734400, "episode_reward": 0.2437303364276886, "value_loss": 0.008326882123947143, "policy_loss": -0.0012393470992538625, "dist_entropy": 0.6919481754302979, "actor_grad_norm": 0.11099635809659958, "critic_grad_norm": 0.03400803729891777, "ratio": 1.0000969171524048, "entropy": 0.6919481754302979, "incre_win_rate": 0.825, "step": 1167}
{"time": 1767336628.974654, "phase": "train", "update": 1168, "total_env_steps": 3737600, "episode_reward": 0.2302638590335846, "value_loss": 0.009685074351727963, "policy_loss": -0.0009797342959801726, "dist_entropy": 0.6908776879310607, "actor_grad_norm": 0.09296800941228867, "critic_grad_norm": 0.04441488906741142, "ratio": 0.999734103679657, "entropy": 0.6908776879310607, "incre_win_rate": 0.8461538461538461, "step": 1168}
{"time": 1767336633.0162575, "phase": "train", "update": 1169, "total_env_steps": 3740800, "episode_reward": 0.24470457434654236, "value_loss": 0.0071370556019246575, "policy_loss": -0.0012626382444555161, "dist_entropy": 0.6898338079452515, "actor_grad_norm": 0.11645916849374771, "critic_grad_norm": 0.03882206603884697, "ratio": 1.0003231763839722, "entropy": 0.6898338079452515, "incre_win_rate": 0.9, "step": 1169}
{"time": 1767336637.096548, "phase": "train", "update": 1170, "total_env_steps": 3744000, "episode_reward": 0.24658061563968658, "value_loss": 0.008197061717510223, "policy_loss": -0.0009140402543970083, "dist_entropy": 0.6879338979721069, "actor_grad_norm": 0.07518433779478073, "critic_grad_norm": 0.05056063085794449, "ratio": 1.0000152587890625, "entropy": 0.6879338979721069, "incre_win_rate": 0.8048780487804879, "step": 1170}
{"time": 1767336641.1092775, "phase": "train", "update": 1171, "total_env_steps": 3747200, "episode_reward": 0.25164785981178284, "value_loss": 0.0063426242209970955, "policy_loss": -0.001030579107111862, "dist_entropy": 0.7217171311378479, "actor_grad_norm": 0.09208301454782486, "critic_grad_norm": 0.020702799782156944, "ratio": 0.9999255537986755, "entropy": 0.7217171311378479, "incre_win_rate": 0.926829268292683, "step": 1171}
{"time": 1767336645.1414838, "phase": "train", "update": 1172, "total_env_steps": 3750400, "episode_reward": 0.25177979469299316, "value_loss": 0.0062608084641397, "policy_loss": -0.0013945304708677497, "dist_entropy": 0.728384268283844, "actor_grad_norm": 0.08640354871749878, "critic_grad_norm": 0.01872563734650612, "ratio": 0.9999366998672485, "entropy": 0.728384268283844, "incre_win_rate": 0.8666666666666667, "step": 1172}
{"time": 1767336649.2262306, "phase": "train", "update": 1173, "total_env_steps": 3753600, "episode_reward": 0.2452726811170578, "value_loss": 0.009266283176839352, "policy_loss": -0.0012698689756035718, "dist_entropy": 0.7267249584197998, "actor_grad_norm": 0.10211461037397385, "critic_grad_norm": 0.051182668656110764, "ratio": 0.9999080896377563, "entropy": 0.7267249584197998, "incre_win_rate": 0.8205128205128205, "step": 1173}
{"time": 1767336653.3038075, "phase": "train", "update": 1174, "total_env_steps": 3756800, "episode_reward": 0.24446605145931244, "value_loss": 0.008050707168877125, "policy_loss": -0.0012111491323686606, "dist_entropy": 0.736292016506195, "actor_grad_norm": 0.08267234265804291, "critic_grad_norm": 0.030559053644537926, "ratio": 1.0000693798065186, "entropy": 0.736292016506195, "incre_win_rate": 0.8292682926829268, "step": 1174}
{"time": 1767336657.408059, "phase": "train", "update": 1175, "total_env_steps": 3760000, "episode_reward": 0.252888023853302, "value_loss": 0.006287946738302708, "policy_loss": -0.0013511986337178428, "dist_entropy": 0.7712057828903198, "actor_grad_norm": 0.11825455725193024, "critic_grad_norm": 0.06250648945569992, "ratio": 0.9998795390129089, "entropy": 0.7712057828903198, "incre_win_rate": 0.875, "step": 1175}
{"time": 1767336661.4371328, "phase": "train", "update": 1176, "total_env_steps": 3763200, "episode_reward": 0.23355959355831146, "value_loss": 0.008301672711968421, "policy_loss": -0.0013253388551373035, "dist_entropy": 0.759122908115387, "actor_grad_norm": 0.10750379413366318, "critic_grad_norm": 0.08315261453390121, "ratio": 0.9997337460517883, "entropy": 0.759122908115387, "incre_win_rate": 0.7804878048780488, "step": 1176}
{"time": 1767336677.2034805, "phase": "eval", "update": 1176, "total_env_steps": 3763200, "eval_win_rate": 0.78125, "eval_episode_reward": 18.90728476821192, "step": 1176}
{"time": 1767336681.1942763, "phase": "train", "update": 1177, "total_env_steps": 3766400, "episode_reward": 0.2379050999879837, "value_loss": 0.008477121032774449, "policy_loss": -0.0015170330731900882, "dist_entropy": 0.7562076330184937, "actor_grad_norm": 0.08780442923307419, "critic_grad_norm": 0.07277943938970566, "ratio": 0.9998982548713684, "entropy": 0.7562076330184937, "incre_win_rate": 0.75, "step": 1177}
{"time": 1767336685.2351954, "phase": "train", "update": 1178, "total_env_steps": 3769600, "episode_reward": 0.24052152037620544, "value_loss": 0.010344362445175647, "policy_loss": -0.001337244333059573, "dist_entropy": 0.752801525592804, "actor_grad_norm": 0.08457516878843307, "critic_grad_norm": 0.02096540667116642, "ratio": 0.9998340606689453, "entropy": 0.752801525592804, "incre_win_rate": 0.85, "step": 1178}
{"time": 1767336689.328266, "phase": "train", "update": 1179, "total_env_steps": 3772800, "episode_reward": 0.24598926305770874, "value_loss": 0.009406771510839462, "policy_loss": -0.001113544868577243, "dist_entropy": 0.7549860000610351, "actor_grad_norm": 0.08606932312250137, "critic_grad_norm": 0.02621050551533699, "ratio": 1.0000265836715698, "entropy": 0.7549860000610351, "incre_win_rate": 0.8048780487804879, "step": 1179}
{"time": 1767336693.3659766, "phase": "train", "update": 1180, "total_env_steps": 3776000, "episode_reward": 0.2466597706079483, "value_loss": 0.007806568685919046, "policy_loss": -0.0013289200973567005, "dist_entropy": 0.7597267866134644, "actor_grad_norm": 0.09897857904434204, "critic_grad_norm": 0.04397490248084068, "ratio": 0.9998818635940552, "entropy": 0.7597267866134644, "incre_win_rate": 0.8095238095238095, "step": 1180}
{"time": 1767336697.4583032, "phase": "train", "update": 1181, "total_env_steps": 3779200, "episode_reward": 0.253510981798172, "value_loss": 0.008388183638453483, "policy_loss": -0.0012332279935861833, "dist_entropy": 0.7535114884376526, "actor_grad_norm": 0.12763166427612305, "critic_grad_norm": 0.02831416204571724, "ratio": 0.999821126461029, "entropy": 0.7535114884376526, "incre_win_rate": 0.8809523809523809, "step": 1181}
{"time": 1767336701.5287685, "phase": "train", "update": 1182, "total_env_steps": 3782400, "episode_reward": 0.25747981667518616, "value_loss": 0.008763205632567406, "policy_loss": -0.0010774684322058191, "dist_entropy": 0.7655723214149475, "actor_grad_norm": 0.08923475444316864, "critic_grad_norm": 0.0542452298104763, "ratio": 0.9992284774780273, "entropy": 0.7655723214149475, "incre_win_rate": 0.9069767441860465, "step": 1182}
{"time": 1767336705.5882752, "phase": "train", "update": 1183, "total_env_steps": 3785600, "episode_reward": 0.2381638139486313, "value_loss": 0.010402042232453824, "policy_loss": -0.0013623912944325412, "dist_entropy": 0.7398389101028442, "actor_grad_norm": 0.08219171315431595, "critic_grad_norm": 0.04064743593335152, "ratio": 0.9997068643569946, "entropy": 0.7398389101028442, "incre_win_rate": 0.8205128205128205, "step": 1183}
{"time": 1767336709.6683571, "phase": "train", "update": 1184, "total_env_steps": 3788800, "episode_reward": 0.2495928257703781, "value_loss": 0.008380470983684062, "policy_loss": -0.0011543414406162355, "dist_entropy": 0.7863736867904663, "actor_grad_norm": 0.09552496671676636, "critic_grad_norm": 0.09500648826360703, "ratio": 1.0003066062927246, "entropy": 0.7863736867904663, "incre_win_rate": 0.8571428571428571, "step": 1184}
{"time": 1767336713.6778514, "phase": "train", "update": 1185, "total_env_steps": 3792000, "episode_reward": 0.24454469978809357, "value_loss": 0.008445501700043679, "policy_loss": -0.0011432069007327073, "dist_entropy": 0.7556612014770507, "actor_grad_norm": 0.11879437416791916, "critic_grad_norm": 0.09180565178394318, "ratio": 1.0000743865966797, "entropy": 0.7556612014770507, "incre_win_rate": 0.8, "step": 1185}
{"time": 1767336717.7590067, "phase": "train", "update": 1186, "total_env_steps": 3795200, "episode_reward": 0.2629035711288452, "value_loss": 0.004605305287986994, "policy_loss": -0.001017945206587001, "dist_entropy": 0.7861978054046631, "actor_grad_norm": 0.07827247679233551, "critic_grad_norm": 0.06509565562009811, "ratio": 1.0000213384628296, "entropy": 0.7861978054046631, "incre_win_rate": 0.9767441860465116, "step": 1186}
{"time": 1767336721.8109171, "phase": "train", "update": 1187, "total_env_steps": 3798400, "episode_reward": 0.2543993294239044, "value_loss": 0.0057096129283308985, "policy_loss": -0.0012469343850185055, "dist_entropy": 0.7780951738357544, "actor_grad_norm": 0.10642478615045547, "critic_grad_norm": 0.047426216304302216, "ratio": 0.9996644854545593, "entropy": 0.7780951738357544, "incre_win_rate": 0.9285714285714286, "step": 1187}
{"time": 1767336725.8773947, "phase": "train", "update": 1188, "total_env_steps": 3801600, "episode_reward": 0.24420996010303497, "value_loss": 0.007015661709010601, "policy_loss": -0.000736657464889845, "dist_entropy": 0.7688825488090515, "actor_grad_norm": 0.09363378584384918, "critic_grad_norm": 0.04944790527224541, "ratio": 1.0000147819519043, "entropy": 0.7688825488090515, "incre_win_rate": 0.8292682926829268, "step": 1188}
{"time": 1767336729.9476032, "phase": "train", "update": 1189, "total_env_steps": 3804800, "episode_reward": 0.2441556304693222, "value_loss": 0.00737201813608408, "policy_loss": -0.0013181625658535978, "dist_entropy": 0.7587216854095459, "actor_grad_norm": 0.09148817509412766, "critic_grad_norm": 0.046147238463163376, "ratio": 0.9998354911804199, "entropy": 0.7587216854095459, "incre_win_rate": 0.8717948717948718, "step": 1189}
{"time": 1767336734.0230544, "phase": "train", "update": 1190, "total_env_steps": 3808000, "episode_reward": 0.2593129277229309, "value_loss": 0.007952276151627302, "policy_loss": -0.0009913084579423526, "dist_entropy": 0.7568900227546692, "actor_grad_norm": 0.11098726093769073, "critic_grad_norm": 0.02337619476020336, "ratio": 0.9999697804450989, "entropy": 0.7568900227546692, "incre_win_rate": 0.9302325581395349, "step": 1190}
{"time": 1767336738.0848248, "phase": "train", "update": 1191, "total_env_steps": 3811200, "episode_reward": 0.24998342990875244, "value_loss": 0.008144314214587212, "policy_loss": -0.0016451837244712663, "dist_entropy": 0.7664817452430726, "actor_grad_norm": 0.11244799196720123, "critic_grad_norm": 0.026384038850665092, "ratio": 0.9995848536491394, "entropy": 0.7664817452430726, "incre_win_rate": 0.9024390243902439, "step": 1191}
{"time": 1767336742.1361885, "phase": "train", "update": 1192, "total_env_steps": 3814400, "episode_reward": 0.23851871490478516, "value_loss": 0.009523103199899196, "policy_loss": -0.0013480771696151805, "dist_entropy": 0.7517350077629089, "actor_grad_norm": 0.10999609529972076, "critic_grad_norm": 0.07645442336797714, "ratio": 1.0003716945648193, "entropy": 0.7517350077629089, "incre_win_rate": 0.7804878048780488, "step": 1192}
{"time": 1767336746.228437, "phase": "train", "update": 1193, "total_env_steps": 3817600, "episode_reward": 0.256580114364624, "value_loss": 0.010090774483978748, "policy_loss": -0.0016383947696711587, "dist_entropy": 0.7489511847496033, "actor_grad_norm": 0.12476952373981476, "critic_grad_norm": 0.04476045072078705, "ratio": 0.9996724128723145, "entropy": 0.7489511847496033, "incre_win_rate": 0.9069767441860465, "step": 1193}
{"time": 1767336750.3370223, "phase": "train", "update": 1194, "total_env_steps": 3820800, "episode_reward": 0.2443382889032364, "value_loss": 0.01124099288135767, "policy_loss": -0.0012912913966950158, "dist_entropy": 0.7605173468589783, "actor_grad_norm": 0.12521935999393463, "critic_grad_norm": 0.03242924436926842, "ratio": 0.9998432993888855, "entropy": 0.7605173468589783, "incre_win_rate": 0.7804878048780488, "step": 1194}
{"time": 1767336754.4094071, "phase": "train", "update": 1195, "total_env_steps": 3824000, "episode_reward": 0.2533402144908905, "value_loss": 0.005524737294763327, "policy_loss": -0.001550997772319107, "dist_entropy": 0.774493956565857, "actor_grad_norm": 0.10450337082147598, "critic_grad_norm": 0.0737622082233429, "ratio": 1.0000065565109253, "entropy": 0.774493956565857, "incre_win_rate": 0.926829268292683, "step": 1195}
{"time": 1767336758.4820786, "phase": "train", "update": 1196, "total_env_steps": 3827200, "episode_reward": 0.25373345613479614, "value_loss": 0.005391847994178534, "policy_loss": -0.001449710461369058, "dist_entropy": 0.7521780848503112, "actor_grad_norm": 0.09459344297647476, "critic_grad_norm": 0.035524334758520126, "ratio": 0.9997864961624146, "entropy": 0.7521780848503112, "incre_win_rate": 0.9523809523809523, "step": 1196}
{"time": 1767336762.5451438, "phase": "train", "update": 1197, "total_env_steps": 3830400, "episode_reward": 0.25382453203201294, "value_loss": 0.00634688725695014, "policy_loss": -0.001053995190076762, "dist_entropy": 0.7267024278640747, "actor_grad_norm": 0.10138892382383347, "critic_grad_norm": 0.028609169647097588, "ratio": 0.9998975992202759, "entropy": 0.7267024278640747, "incre_win_rate": 0.9047619047619048, "step": 1197}
{"time": 1767336766.6566577, "phase": "train", "update": 1198, "total_env_steps": 3833600, "episode_reward": 0.2579387426376343, "value_loss": 0.0060612943954765795, "policy_loss": -0.0010321439600403438, "dist_entropy": 0.7126996517181396, "actor_grad_norm": 0.10278313606977463, "critic_grad_norm": 0.031678128987550735, "ratio": 0.9998462796211243, "entropy": 0.7126996517181396, "incre_win_rate": 0.926829268292683, "step": 1198}
{"time": 1767336770.7221317, "phase": "train", "update": 1199, "total_env_steps": 3836800, "episode_reward": 0.24954883754253387, "value_loss": 0.005494905542582274, "policy_loss": -0.001042827498977772, "dist_entropy": 0.7237207889556885, "actor_grad_norm": 0.1102009043097496, "critic_grad_norm": 0.0161582138389349, "ratio": 0.9995383620262146, "entropy": 0.7237207889556885, "incre_win_rate": 0.925, "step": 1199}
{"time": 1767336774.7706861, "phase": "train", "update": 1200, "total_env_steps": 3840000, "episode_reward": 0.24628311395645142, "value_loss": 0.006897907797247171, "policy_loss": -0.000713370231936139, "dist_entropy": 0.7281060457229614, "actor_grad_norm": 0.07230817526578903, "critic_grad_norm": 0.03690442442893982, "ratio": 1.0003072023391724, "entropy": 0.7281060457229614, "incre_win_rate": 0.8809523809523809, "step": 1200}
{"time": 1767336778.8364644, "phase": "train", "update": 1201, "total_env_steps": 3843200, "episode_reward": 0.2439776360988617, "value_loss": 0.009858575835824012, "policy_loss": -0.0014151789345591582, "dist_entropy": 0.7327949404716492, "actor_grad_norm": 0.09911119192838669, "critic_grad_norm": 0.05356192588806152, "ratio": 0.9996834993362427, "entropy": 0.7327949404716492, "incre_win_rate": 0.8571428571428571, "step": 1201}
{"time": 1767336789.3011389, "phase": "eval", "update": 1201, "total_env_steps": 3843200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.45322847682119, "step": 1201}
{"time": 1767336793.397949, "phase": "train", "update": 1202, "total_env_steps": 3846400, "episode_reward": 0.2524994909763336, "value_loss": 0.009181058779358865, "policy_loss": -0.0008996015641940857, "dist_entropy": 0.7482197642326355, "actor_grad_norm": 0.07574597746133804, "critic_grad_norm": 0.03421442583203316, "ratio": 0.999881386756897, "entropy": 0.7482197642326355, "incre_win_rate": 0.9047619047619048, "step": 1202}
{"time": 1767336797.478906, "phase": "train", "update": 1203, "total_env_steps": 3849600, "episode_reward": 0.25628724694252014, "value_loss": 0.004922907147556543, "policy_loss": -0.0010448893407129845, "dist_entropy": 0.7359262704849243, "actor_grad_norm": 0.09387891739606857, "critic_grad_norm": 0.05837481841444969, "ratio": 0.9995588660240173, "entropy": 0.7359262704849243, "incre_win_rate": 0.9512195121951219, "step": 1203}
{"time": 1767336801.5660949, "phase": "train", "update": 1204, "total_env_steps": 3852800, "episode_reward": 0.2546440362930298, "value_loss": 0.006365062855184078, "policy_loss": -0.0011210069845532188, "dist_entropy": 0.7362109780311584, "actor_grad_norm": 0.07544668018817902, "critic_grad_norm": 0.03200555592775345, "ratio": 0.9999871253967285, "entropy": 0.7362109780311584, "incre_win_rate": 0.925, "step": 1204}
{"time": 1767336805.6295016, "phase": "train", "update": 1205, "total_env_steps": 3856000, "episode_reward": 0.256254106760025, "value_loss": 0.006620489992201328, "policy_loss": -0.0012906975424289869, "dist_entropy": 0.7687379002571106, "actor_grad_norm": 0.12486499547958374, "critic_grad_norm": 0.03743287920951843, "ratio": 1.000027060508728, "entropy": 0.7687379002571106, "incre_win_rate": 0.9523809523809523, "step": 1205}
{"time": 1767336809.7316992, "phase": "train", "update": 1206, "total_env_steps": 3859200, "episode_reward": 0.25395023822784424, "value_loss": 0.006217567343264818, "policy_loss": -0.001333370355262531, "dist_entropy": 0.7402425646781922, "actor_grad_norm": 0.09651179611682892, "critic_grad_norm": 0.03556736931204796, "ratio": 1.0003823041915894, "entropy": 0.7402425646781922, "incre_win_rate": 0.8809523809523809, "step": 1206}
{"time": 1767336813.7902415, "phase": "train", "update": 1207, "total_env_steps": 3862400, "episode_reward": 0.24877071380615234, "value_loss": 0.007594626862555742, "policy_loss": -0.001256712414660921, "dist_entropy": 0.7465975284576416, "actor_grad_norm": 0.08788364380598068, "critic_grad_norm": 0.03451697155833244, "ratio": 0.999883770942688, "entropy": 0.7465975284576416, "incre_win_rate": 0.9024390243902439, "step": 1207}
{"time": 1767336817.8555453, "phase": "train", "update": 1208, "total_env_steps": 3865600, "episode_reward": 0.24427875876426697, "value_loss": 0.008617313764989375, "policy_loss": -0.0009606651624380902, "dist_entropy": 0.7298973798751831, "actor_grad_norm": 0.09615706652402878, "critic_grad_norm": 0.03443828225135803, "ratio": 1.0001646280288696, "entropy": 0.7298973798751831, "incre_win_rate": 0.8717948717948718, "step": 1208}
{"time": 1767336821.959979, "phase": "train", "update": 1209, "total_env_steps": 3868800, "episode_reward": 0.2581208646297455, "value_loss": 0.0046984761022031305, "policy_loss": -0.0013956957664462255, "dist_entropy": 0.7429397583007813, "actor_grad_norm": 0.09073572605848312, "critic_grad_norm": 0.08427023887634277, "ratio": 1.0000067949295044, "entropy": 0.7429397583007813, "incre_win_rate": 0.9761904761904762, "step": 1209}
{"time": 1767336826.0268748, "phase": "train", "update": 1210, "total_env_steps": 3872000, "episode_reward": 0.25361186265945435, "value_loss": 0.005676672514528036, "policy_loss": -0.0014752123366672976, "dist_entropy": 0.7452654242515564, "actor_grad_norm": 0.12836115062236786, "critic_grad_norm": 0.048959050327539444, "ratio": 1.0001283884048462, "entropy": 0.7452654242515564, "incre_win_rate": 0.8809523809523809, "step": 1210}
{"time": 1767336830.1608803, "phase": "train", "update": 1211, "total_env_steps": 3875200, "episode_reward": 0.2495597004890442, "value_loss": 0.0053950540721416475, "policy_loss": -0.0013601915459140912, "dist_entropy": 0.7457021474838257, "actor_grad_norm": 0.09809178858995438, "critic_grad_norm": 0.04521101340651512, "ratio": 0.9996391534805298, "entropy": 0.7457021474838257, "incre_win_rate": 0.9285714285714286, "step": 1211}
{"time": 1767336834.2109387, "phase": "train", "update": 1212, "total_env_steps": 3878400, "episode_reward": 0.2547682225704193, "value_loss": 0.005858924146741629, "policy_loss": -0.0013549416954994342, "dist_entropy": 0.7504897832870483, "actor_grad_norm": 0.12402855604887009, "critic_grad_norm": 0.018351441249251366, "ratio": 0.9998594522476196, "entropy": 0.7504897832870483, "incre_win_rate": 0.9285714285714286, "step": 1212}
{"time": 1767336838.3229303, "phase": "train", "update": 1213, "total_env_steps": 3881600, "episode_reward": 0.2613043189048767, "value_loss": 0.006993536371737719, "policy_loss": -0.0012745863793794498, "dist_entropy": 0.7364886283874512, "actor_grad_norm": 0.10247989743947983, "critic_grad_norm": 0.014635388739407063, "ratio": 1.0004547834396362, "entropy": 0.7364886283874512, "incre_win_rate": 0.95, "step": 1213}
{"time": 1767336842.414074, "phase": "train", "update": 1214, "total_env_steps": 3884800, "episode_reward": 0.24433566629886627, "value_loss": 0.0070509593933820724, "policy_loss": -0.0012008591159418103, "dist_entropy": 0.7480891585350037, "actor_grad_norm": 0.12646155059337616, "critic_grad_norm": 0.03462553769350052, "ratio": 1.000075340270996, "entropy": 0.7480891585350037, "incre_win_rate": 0.8717948717948718, "step": 1214}
{"time": 1767336846.543037, "phase": "train", "update": 1215, "total_env_steps": 3888000, "episode_reward": 0.2615025043487549, "value_loss": 0.003091723471879959, "policy_loss": -0.0012451754539526405, "dist_entropy": 0.7416350245475769, "actor_grad_norm": 0.10173733532428741, "critic_grad_norm": 0.03178975731134415, "ratio": 0.9999658465385437, "entropy": 0.7416350245475769, "incre_win_rate": 0.9772727272727273, "step": 1215}
{"time": 1767336850.6465104, "phase": "train", "update": 1216, "total_env_steps": 3891200, "episode_reward": 0.25395023822784424, "value_loss": 0.004890540614724159, "policy_loss": -0.0010806044951067405, "dist_entropy": 0.7205228447914124, "actor_grad_norm": 0.08238506317138672, "critic_grad_norm": 0.02710263431072235, "ratio": 1.000346064567566, "entropy": 0.7205228447914124, "incre_win_rate": 0.9047619047619048, "step": 1216}
{"time": 1767336854.6872451, "phase": "train", "update": 1217, "total_env_steps": 3894400, "episode_reward": 0.24461093544960022, "value_loss": 0.006735186744481325, "policy_loss": -0.001768723950037554, "dist_entropy": 0.7227158188819885, "actor_grad_norm": 0.12143919616937637, "critic_grad_norm": 0.04304922744631767, "ratio": 1.0000368356704712, "entropy": 0.7227158188819885, "incre_win_rate": 0.8974358974358975, "step": 1217}
{"time": 1767336858.7358105, "phase": "train", "update": 1218, "total_env_steps": 3897600, "episode_reward": 0.23401802778244019, "value_loss": 0.00821423288434744, "policy_loss": -0.001256450245329077, "dist_entropy": 0.7254763007164001, "actor_grad_norm": 0.11120662838220596, "critic_grad_norm": 0.03404252231121063, "ratio": 0.9998379945755005, "entropy": 0.7254763007164001, "incre_win_rate": 0.7948717948717948, "step": 1218}
{"time": 1767336862.7921731, "phase": "train", "update": 1219, "total_env_steps": 3900800, "episode_reward": 0.24491310119628906, "value_loss": 0.007711739372462034, "policy_loss": -0.0013897060110004134, "dist_entropy": 0.7394341468811035, "actor_grad_norm": 0.0981094092130661, "critic_grad_norm": 0.03884422034025192, "ratio": 0.9998963475227356, "entropy": 0.7394341468811035, "incre_win_rate": 0.8571428571428571, "step": 1219}
{"time": 1767336866.881618, "phase": "train", "update": 1220, "total_env_steps": 3904000, "episode_reward": 0.26424670219421387, "value_loss": 0.004494656529277563, "policy_loss": -0.0012727968738934059, "dist_entropy": 0.7460221886634827, "actor_grad_norm": 0.11346369981765747, "critic_grad_norm": 0.05894850566983223, "ratio": 1.0001280307769775, "entropy": 0.7460221886634827, "incre_win_rate": 1.0, "step": 1220}
{"time": 1767336870.9949827, "phase": "train", "update": 1221, "total_env_steps": 3907200, "episode_reward": 0.2555939555168152, "value_loss": 0.006066070031374693, "policy_loss": -0.0010231646410950646, "dist_entropy": 0.726565706729889, "actor_grad_norm": 0.07341095060110092, "critic_grad_norm": 0.03189849108457565, "ratio": 1.0004686117172241, "entropy": 0.726565706729889, "incre_win_rate": 0.8571428571428571, "step": 1221}
{"time": 1767336875.0757844, "phase": "train", "update": 1222, "total_env_steps": 3910400, "episode_reward": 0.2602897584438324, "value_loss": 0.006702135503292084, "policy_loss": -0.0014508159964868206, "dist_entropy": 0.7362454652786254, "actor_grad_norm": 0.08950997143983841, "critic_grad_norm": 0.035031672567129135, "ratio": 1.0002096891403198, "entropy": 0.7362454652786254, "incre_win_rate": 0.9545454545454546, "step": 1222}
{"time": 1767336879.1914463, "phase": "train", "update": 1223, "total_env_steps": 3913600, "episode_reward": 0.25447848439216614, "value_loss": 0.005029972828924656, "policy_loss": -0.0008511220067489944, "dist_entropy": 0.733668327331543, "actor_grad_norm": 0.09051083028316498, "critic_grad_norm": 0.03531081601977348, "ratio": 1.0001167058944702, "entropy": 0.733668327331543, "incre_win_rate": 0.926829268292683, "step": 1223}
{"time": 1767336883.2571054, "phase": "train", "update": 1224, "total_env_steps": 3916800, "episode_reward": 0.2475372701883316, "value_loss": 0.007735473662614822, "policy_loss": -0.001303298058297031, "dist_entropy": 0.7548189759254456, "actor_grad_norm": 0.07792257517576218, "critic_grad_norm": 0.045081645250320435, "ratio": 0.9998158812522888, "entropy": 0.7548189759254456, "incre_win_rate": 0.85, "step": 1224}
{"time": 1767336887.3372912, "phase": "train", "update": 1225, "total_env_steps": 3920000, "episode_reward": 0.23988306522369385, "value_loss": 0.009555705450475216, "policy_loss": -0.0011839714443965476, "dist_entropy": 0.7402380108833313, "actor_grad_norm": 0.09331075102090836, "critic_grad_norm": 0.07319707423448563, "ratio": 1.0001449584960938, "entropy": 0.7402380108833313, "incre_win_rate": 0.8048780487804879, "step": 1225}
{"time": 1767336891.4186935, "phase": "train", "update": 1226, "total_env_steps": 3923200, "episode_reward": 0.2547413110733032, "value_loss": 0.005963471811264753, "policy_loss": -0.001617690880976852, "dist_entropy": 0.7305616497993469, "actor_grad_norm": 0.09748613089323044, "critic_grad_norm": 0.044885724782943726, "ratio": 1.0000056028366089, "entropy": 0.7305616497993469, "incre_win_rate": 0.9047619047619048, "step": 1226}
{"time": 1767336901.8526764, "phase": "eval", "update": 1226, "total_env_steps": 3923200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.812551738410598, "step": 1226}
{"time": 1767336905.9637234, "phase": "train", "update": 1227, "total_env_steps": 3926400, "episode_reward": 0.2609323561191559, "value_loss": 0.006863821018487215, "policy_loss": -0.001345965438673602, "dist_entropy": 0.7422396302223205, "actor_grad_norm": 0.09193216264247894, "critic_grad_norm": 0.0409785620868206, "ratio": 1.0000859498977661, "entropy": 0.7422396302223205, "incre_win_rate": 0.9761904761904762, "step": 1227}
{"time": 1767336910.0598335, "phase": "train", "update": 1228, "total_env_steps": 3929600, "episode_reward": 0.25637418031692505, "value_loss": 0.00816113892942667, "policy_loss": -0.001178005786796632, "dist_entropy": 0.7279274702072144, "actor_grad_norm": 0.08405854552984238, "critic_grad_norm": 0.07020625472068787, "ratio": 0.9999883770942688, "entropy": 0.7279274702072144, "incre_win_rate": 0.9285714285714286, "step": 1228}
{"time": 1767336914.1276274, "phase": "train", "update": 1229, "total_env_steps": 3932800, "episode_reward": 0.2516002655029297, "value_loss": 0.009859024919569493, "policy_loss": -0.0012086319297931248, "dist_entropy": 0.7220799446105957, "actor_grad_norm": 0.09558982402086258, "critic_grad_norm": 0.05768300220370293, "ratio": 0.9998820424079895, "entropy": 0.7220799446105957, "incre_win_rate": 0.8604651162790697, "step": 1229}
{"time": 1767336918.196854, "phase": "train", "update": 1230, "total_env_steps": 3936000, "episode_reward": 0.2534312903881073, "value_loss": 0.006835066806524992, "policy_loss": -0.0014483862870655173, "dist_entropy": 0.7084414005279541, "actor_grad_norm": 0.13797537982463837, "critic_grad_norm": 0.04179856553673744, "ratio": 0.9998866319656372, "entropy": 0.7084414005279541, "incre_win_rate": 0.925, "step": 1230}
{"time": 1767336922.2771564, "phase": "train", "update": 1231, "total_env_steps": 3939200, "episode_reward": 0.2526702284812927, "value_loss": 0.008888785727322102, "policy_loss": -0.00117819010742366, "dist_entropy": 0.6908360600471497, "actor_grad_norm": 0.09172066301107407, "critic_grad_norm": 0.06994428485631943, "ratio": 0.9997696876525879, "entropy": 0.6908360600471497, "incre_win_rate": 0.8604651162790697, "step": 1231}
{"time": 1767336926.3925407, "phase": "train", "update": 1232, "total_env_steps": 3942400, "episode_reward": 0.2555474042892456, "value_loss": 0.007036267500370741, "policy_loss": -0.0012958831457723363, "dist_entropy": 0.6922332525253296, "actor_grad_norm": 0.1228056475520134, "critic_grad_norm": 0.044516656547784805, "ratio": 1.0002810955047607, "entropy": 0.6922332525253296, "incre_win_rate": 0.9, "step": 1232}
{"time": 1767336930.5315924, "phase": "train", "update": 1233, "total_env_steps": 3945600, "episode_reward": 0.2714652419090271, "value_loss": 0.006014934275299311, "policy_loss": -0.0010830978797761403, "dist_entropy": 0.6946436285972595, "actor_grad_norm": 0.102580726146698, "critic_grad_norm": 0.10381723940372467, "ratio": 1.000254511833191, "entropy": 0.6946436285972595, "incre_win_rate": 0.9777777777777777, "step": 1233}
{"time": 1767336934.639083, "phase": "train", "update": 1234, "total_env_steps": 3948800, "episode_reward": 0.2577856183052063, "value_loss": 0.008670933730900287, "policy_loss": -0.00077178436994636, "dist_entropy": 0.6848989367485047, "actor_grad_norm": 0.06758158653974533, "critic_grad_norm": 0.06004693731665611, "ratio": 1.000046968460083, "entropy": 0.6848989367485047, "incre_win_rate": 0.8809523809523809, "step": 1234}
{"time": 1767336938.7076697, "phase": "train", "update": 1235, "total_env_steps": 3952000, "episode_reward": 0.24947695434093475, "value_loss": 0.005860841553658247, "policy_loss": -0.0013723842420372279, "dist_entropy": 0.6913567066192627, "actor_grad_norm": 0.09902193397283554, "critic_grad_norm": 0.04684838652610779, "ratio": 1.0001368522644043, "entropy": 0.6913567066192627, "incre_win_rate": 0.926829268292683, "step": 1235}
{"time": 1767336942.8193326, "phase": "train", "update": 1236, "total_env_steps": 3955200, "episode_reward": 0.2681746780872345, "value_loss": 0.004511096328496933, "policy_loss": -0.0012160607287139413, "dist_entropy": 0.7051121234893799, "actor_grad_norm": 0.09041759371757507, "critic_grad_norm": 0.040454741567373276, "ratio": 1.0001330375671387, "entropy": 0.7051121234893799, "incre_win_rate": 1.0, "step": 1236}
{"time": 1767336946.910665, "phase": "train", "update": 1237, "total_env_steps": 3958400, "episode_reward": 0.25798478722572327, "value_loss": 0.0047183863818645476, "policy_loss": -0.0010189170805308123, "dist_entropy": 0.7035070538520813, "actor_grad_norm": 0.11454974859952927, "critic_grad_norm": 0.03755100443959236, "ratio": 1.0002739429473877, "entropy": 0.7035070538520813, "incre_win_rate": 0.9047619047619048, "step": 1237}
{"time": 1767336951.033186, "phase": "train", "update": 1238, "total_env_steps": 3961600, "episode_reward": 0.2576903998851776, "value_loss": 0.005223546549677849, "policy_loss": -0.0011335987526312151, "dist_entropy": 0.6836231231689454, "actor_grad_norm": 0.08873558789491653, "critic_grad_norm": 0.04636669158935547, "ratio": 1.0001460313796997, "entropy": 0.6836231231689454, "incre_win_rate": 0.9534883720930233, "step": 1238}
{"time": 1767336955.1219761, "phase": "train", "update": 1239, "total_env_steps": 3964800, "episode_reward": 0.25703227519989014, "value_loss": 0.01026255264878273, "policy_loss": -0.001257751312375177, "dist_entropy": 0.6737738251686096, "actor_grad_norm": 0.07376384735107422, "critic_grad_norm": 0.04923021048307419, "ratio": 0.9998237490653992, "entropy": 0.6737738251686096, "incre_win_rate": 0.8780487804878049, "step": 1239}
{"time": 1767336959.2661016, "phase": "train", "update": 1240, "total_env_steps": 3968000, "episode_reward": 0.2574896514415741, "value_loss": 0.006254689954221249, "policy_loss": -0.0011944455632189488, "dist_entropy": 0.6663784861564637, "actor_grad_norm": 0.09345915168523788, "critic_grad_norm": 0.0606158971786499, "ratio": 1.000020146369934, "entropy": 0.6663784861564637, "incre_win_rate": 0.8636363636363636, "step": 1240}
{"time": 1767336963.3407388, "phase": "train", "update": 1241, "total_env_steps": 3971200, "episode_reward": 0.2636382579803467, "value_loss": 0.004223545268177986, "policy_loss": -0.001027119920672792, "dist_entropy": 0.6661141395568848, "actor_grad_norm": 0.08630713075399399, "critic_grad_norm": 0.035290367901325226, "ratio": 0.9999208450317383, "entropy": 0.6661141395568848, "incre_win_rate": 0.9285714285714286, "step": 1241}
{"time": 1767336967.4614532, "phase": "train", "update": 1242, "total_env_steps": 3974400, "episode_reward": 0.2642684280872345, "value_loss": 0.004490248300135136, "policy_loss": -0.0010927506876413418, "dist_entropy": 0.6826058745384216, "actor_grad_norm": 0.08566418290138245, "critic_grad_norm": 0.02480413392186165, "ratio": 0.9997121691703796, "entropy": 0.6826058745384216, "incre_win_rate": 0.9534883720930233, "step": 1242}
{"time": 1767336971.5644825, "phase": "train", "update": 1243, "total_env_steps": 3977600, "episode_reward": 0.2632885277271271, "value_loss": 0.004505166318267584, "policy_loss": -0.0012039581219495331, "dist_entropy": 0.6841503858566285, "actor_grad_norm": 0.12307467311620712, "critic_grad_norm": 0.04013695940375328, "ratio": 1.0001535415649414, "entropy": 0.6841503858566285, "incre_win_rate": 0.9545454545454546, "step": 1243}
{"time": 1767336975.6083229, "phase": "train", "update": 1244, "total_env_steps": 3980800, "episode_reward": 0.2517099678516388, "value_loss": 0.007231038063764572, "policy_loss": -0.0006221929097712575, "dist_entropy": 0.6533004879951477, "actor_grad_norm": 0.100899837911129, "critic_grad_norm": 0.03763033077120781, "ratio": 0.9998914003372192, "entropy": 0.6533004879951477, "incre_win_rate": 0.9069767441860465, "step": 1244}
{"time": 1767336979.7018096, "phase": "train", "update": 1245, "total_env_steps": 3984000, "episode_reward": 0.2579294443130493, "value_loss": 0.0079668328166008, "policy_loss": -0.0010439373615326985, "dist_entropy": 0.6744093060493469, "actor_grad_norm": 0.08796431124210358, "critic_grad_norm": 0.03448698669672012, "ratio": 0.9998769760131836, "entropy": 0.6744093060493469, "incre_win_rate": 0.9, "step": 1245}
{"time": 1767336983.8203068, "phase": "train", "update": 1246, "total_env_steps": 3987200, "episode_reward": 0.2616432309150696, "value_loss": 0.006854997389018536, "policy_loss": -0.0012885238548751231, "dist_entropy": 0.6669568896293641, "actor_grad_norm": 0.10318298637866974, "critic_grad_norm": 0.03427369147539139, "ratio": 0.9996536374092102, "entropy": 0.6669568896293641, "incre_win_rate": 0.9047619047619048, "step": 1246}
{"time": 1767336987.8964608, "phase": "train", "update": 1247, "total_env_steps": 3990400, "episode_reward": 0.2603766620159149, "value_loss": 0.00662820553407073, "policy_loss": -0.0012626264912316554, "dist_entropy": 0.6543630123138428, "actor_grad_norm": 0.09940643608570099, "critic_grad_norm": 0.02880638837814331, "ratio": 0.9995228052139282, "entropy": 0.6543630123138428, "incre_win_rate": 0.9534883720930233, "step": 1247}
{"time": 1767336992.0397494, "phase": "train", "update": 1248, "total_env_steps": 3993600, "episode_reward": 0.2583474814891815, "value_loss": 0.007426799274981022, "policy_loss": -0.0012767882558405662, "dist_entropy": 0.6707562446594239, "actor_grad_norm": 0.11179456859827042, "critic_grad_norm": 0.04818692430853844, "ratio": 1.0000039339065552, "entropy": 0.6707562446594239, "incre_win_rate": 0.9302325581395349, "step": 1248}
{"time": 1767336996.3344545, "phase": "train", "update": 1249, "total_env_steps": 3996800, "episode_reward": 0.27176737785339355, "value_loss": 0.0031809297390282152, "policy_loss": -0.0011260162214014712, "dist_entropy": 0.640964412689209, "actor_grad_norm": 0.10224492847919464, "critic_grad_norm": 0.034784186631441116, "ratio": 1.0003238916397095, "entropy": 0.640964412689209, "incre_win_rate": 0.9772727272727273, "step": 1249}
{"time": 1767337000.940636, "phase": "train", "update": 1250, "total_env_steps": 4000000, "episode_reward": 0.26715850830078125, "value_loss": 0.004277035314589739, "policy_loss": -0.0009679785491840676, "dist_entropy": 0.638126266002655, "actor_grad_norm": 0.10842613130807877, "critic_grad_norm": 0.04078197851777077, "ratio": 1.0001220703125, "entropy": 0.638126266002655, "incre_win_rate": 0.9534883720930233, "step": 1250}
{"time": 1767337005.0775452, "phase": "train", "update": 1251, "total_env_steps": 4003200, "episode_reward": 0.24863462150096893, "value_loss": 0.007871057372540236, "policy_loss": -0.0010692027841297858, "dist_entropy": 0.6245726466178894, "actor_grad_norm": 0.09295586496591568, "critic_grad_norm": 0.052222657948732376, "ratio": 0.9997520446777344, "entropy": 0.6245726466178894, "incre_win_rate": 0.825, "step": 1251}
{"time": 1767337016.1089435, "phase": "eval", "update": 1251, "total_env_steps": 4003200, "eval_win_rate": 0.84375, "eval_episode_reward": 19.435689155629138, "step": 1251}
{"time": 1767337020.2315855, "phase": "train", "update": 1252, "total_env_steps": 4006400, "episode_reward": 0.2633153796195984, "value_loss": 0.004697081446647644, "policy_loss": -0.0012846028272377908, "dist_entropy": 0.6327661275863647, "actor_grad_norm": 0.1044795885682106, "critic_grad_norm": 0.03697516396641731, "ratio": 0.9997410178184509, "entropy": 0.6327661275863647, "incre_win_rate": 0.9772727272727273, "step": 1252}
{"time": 1767337024.292055, "phase": "train", "update": 1253, "total_env_steps": 4009600, "episode_reward": 0.250067800283432, "value_loss": 0.006081718113273382, "policy_loss": -0.001350581225789682, "dist_entropy": 0.6479734539985657, "actor_grad_norm": 0.08676514029502869, "critic_grad_norm": 0.06668926775455475, "ratio": 0.9997137188911438, "entropy": 0.6479734539985657, "incre_win_rate": 0.9, "step": 1253}
{"time": 1767337028.416367, "phase": "train", "update": 1254, "total_env_steps": 4012800, "episode_reward": 0.2579594552516937, "value_loss": 0.004924410581588745, "policy_loss": -0.0011462945135747304, "dist_entropy": 0.6612972140312194, "actor_grad_norm": 0.08420617133378983, "critic_grad_norm": 0.04644027352333069, "ratio": 1.0001674890518188, "entropy": 0.6612972140312194, "incre_win_rate": 0.9523809523809523, "step": 1254}
{"time": 1767337032.5160165, "phase": "train", "update": 1255, "total_env_steps": 4016000, "episode_reward": 0.2639900743961334, "value_loss": 0.005696952249854803, "policy_loss": -0.0014416940793913647, "dist_entropy": 0.6548368096351623, "actor_grad_norm": 0.07234295457601547, "critic_grad_norm": 0.06935694068670273, "ratio": 0.9998701214790344, "entropy": 0.6548368096351623, "incre_win_rate": 0.9534883720930233, "step": 1255}
{"time": 1767337036.5895898, "phase": "train", "update": 1256, "total_env_steps": 4019200, "episode_reward": 0.25733909010887146, "value_loss": 0.004358754120767116, "policy_loss": -0.001468131683213869, "dist_entropy": 0.6686601758003234, "actor_grad_norm": 0.1224420815706253, "critic_grad_norm": 0.04032113030552864, "ratio": 0.99964839220047, "entropy": 0.6686601758003234, "incre_win_rate": 0.975, "step": 1256}
{"time": 1767337040.703175, "phase": "train", "update": 1257, "total_env_steps": 4022400, "episode_reward": 0.2614222764968872, "value_loss": 0.004473994858562947, "policy_loss": -0.001415933072900799, "dist_entropy": 0.6694865345954895, "actor_grad_norm": 0.13458657264709473, "critic_grad_norm": 0.03032856620848179, "ratio": 1.0006029605865479, "entropy": 0.6694865345954895, "incre_win_rate": 0.9545454545454546, "step": 1257}
{"time": 1767337044.7725863, "phase": "train", "update": 1258, "total_env_steps": 4025600, "episode_reward": 0.26703643798828125, "value_loss": 0.0036541718523949384, "policy_loss": -0.0011150094276221266, "dist_entropy": 0.6619015812873841, "actor_grad_norm": 0.08372419327497482, "critic_grad_norm": 0.05197814106941223, "ratio": 0.9996684193611145, "entropy": 0.6619015812873841, "incre_win_rate": 1.0, "step": 1258}
{"time": 1767337048.8725135, "phase": "train", "update": 1259, "total_env_steps": 4028800, "episode_reward": 0.25057119131088257, "value_loss": 0.019569776952266693, "policy_loss": -0.0011492021265905096, "dist_entropy": 0.6855528354644775, "actor_grad_norm": 0.07663925737142563, "critic_grad_norm": 0.16706576943397522, "ratio": 0.9995571970939636, "entropy": 0.6855528354644775, "incre_win_rate": 0.9285714285714286, "step": 1259}
{"time": 1767337052.9900928, "phase": "train", "update": 1260, "total_env_steps": 4032000, "episode_reward": 0.25621846318244934, "value_loss": 0.009383515082299709, "policy_loss": -0.0011994181701872719, "dist_entropy": 0.65618417263031, "actor_grad_norm": 0.0774644985795021, "critic_grad_norm": 0.09337937086820602, "ratio": 1.0000059604644775, "entropy": 0.65618417263031, "incre_win_rate": 0.9047619047619048, "step": 1260}
{"time": 1767337057.095946, "phase": "train", "update": 1261, "total_env_steps": 4035200, "episode_reward": 0.26601821184158325, "value_loss": 0.005545227322727442, "policy_loss": -0.0011311109675284925, "dist_entropy": 0.6624643445014954, "actor_grad_norm": 0.07233569025993347, "critic_grad_norm": 0.05569860339164734, "ratio": 0.9998175501823425, "entropy": 0.6624643445014954, "incre_win_rate": 0.9512195121951219, "step": 1261}
{"time": 1767337061.2128172, "phase": "train", "update": 1262, "total_env_steps": 4038400, "episode_reward": 0.25902315974235535, "value_loss": 0.006318875681608915, "policy_loss": -0.0011472250013980557, "dist_entropy": 0.6400092840194702, "actor_grad_norm": 0.0870281383395195, "critic_grad_norm": 0.05012078210711479, "ratio": 0.9996431469917297, "entropy": 0.6400092840194702, "incre_win_rate": 0.9148936170212766, "step": 1262}
{"time": 1767337065.2741623, "phase": "train", "update": 1263, "total_env_steps": 4041600, "episode_reward": 0.25824451446533203, "value_loss": 0.00794925382360816, "policy_loss": -0.0011846758636551158, "dist_entropy": 0.6521857380867004, "actor_grad_norm": 0.09313397854566574, "critic_grad_norm": 0.07330625504255295, "ratio": 0.9998192191123962, "entropy": 0.6521857380867004, "incre_win_rate": 0.875, "step": 1263}
{"time": 1767337069.3340383, "phase": "train", "update": 1264, "total_env_steps": 4044800, "episode_reward": 0.2504708170890808, "value_loss": 0.008028817921876907, "policy_loss": -0.0012342963705570752, "dist_entropy": 0.6667051315307617, "actor_grad_norm": 0.09669702500104904, "critic_grad_norm": 0.041562728583812714, "ratio": 1.0001739263534546, "entropy": 0.6667051315307617, "incre_win_rate": 0.8292682926829268, "step": 1264}
{"time": 1767337073.4046876, "phase": "train", "update": 1265, "total_env_steps": 4048000, "episode_reward": 0.2529796361923218, "value_loss": 0.007930632494390012, "policy_loss": -0.0009991530615316435, "dist_entropy": 0.6689821124076843, "actor_grad_norm": 0.08531153202056885, "critic_grad_norm": 0.06358128041028976, "ratio": 0.999755859375, "entropy": 0.6689821124076843, "incre_win_rate": 0.9512195121951219, "step": 1265}
{"time": 1767337077.440693, "phase": "train", "update": 1266, "total_env_steps": 4051200, "episode_reward": 0.23709282279014587, "value_loss": 0.008374795131385327, "policy_loss": -0.0011512693973635302, "dist_entropy": 0.6579629063606263, "actor_grad_norm": 0.1144748330116272, "critic_grad_norm": 0.03820137679576874, "ratio": 0.9999231696128845, "entropy": 0.6579629063606263, "incre_win_rate": 0.75, "step": 1266}
{"time": 1767337081.534841, "phase": "train", "update": 1267, "total_env_steps": 4054400, "episode_reward": 0.25165149569511414, "value_loss": 0.011423973366618156, "policy_loss": -0.0009651698797355834, "dist_entropy": 0.6761092185974121, "actor_grad_norm": 0.10103213787078857, "critic_grad_norm": 0.03146573156118393, "ratio": 1.0001415014266968, "entropy": 0.6761092185974121, "incre_win_rate": 0.8636363636363636, "step": 1267}
{"time": 1767337085.6477742, "phase": "train", "update": 1268, "total_env_steps": 4057600, "episode_reward": 0.2704428732395172, "value_loss": 0.004592638276517391, "policy_loss": -0.001275809801437333, "dist_entropy": 0.7046503186225891, "actor_grad_norm": 0.10403186082839966, "critic_grad_norm": 0.023844698444008827, "ratio": 0.9999765753746033, "entropy": 0.7046503186225891, "incre_win_rate": 1.0, "step": 1268}
{"time": 1767337089.7422123, "phase": "train", "update": 1269, "total_env_steps": 4060800, "episode_reward": 0.2632005512714386, "value_loss": 0.005311710666865111, "policy_loss": -0.0014910042554589608, "dist_entropy": 0.7052022099494935, "actor_grad_norm": 0.09826689213514328, "critic_grad_norm": 0.017072288319468498, "ratio": 0.999727725982666, "entropy": 0.7052022099494935, "incre_win_rate": 0.9069767441860465, "step": 1269}
{"time": 1767337093.8214974, "phase": "train", "update": 1270, "total_env_steps": 4064000, "episode_reward": 0.25166597962379456, "value_loss": 0.005532050970941782, "policy_loss": -0.0010397625794841049, "dist_entropy": 0.6895589828491211, "actor_grad_norm": 0.10950056463479996, "critic_grad_norm": 0.020055189728736877, "ratio": 0.9995438456535339, "entropy": 0.6895589828491211, "incre_win_rate": 0.9, "step": 1270}
{"time": 1767337097.8963346, "phase": "train", "update": 1271, "total_env_steps": 4067200, "episode_reward": 0.2541908323764801, "value_loss": 0.007973697781562806, "policy_loss": -0.0008730887782675723, "dist_entropy": 0.667244553565979, "actor_grad_norm": 0.08582841604948044, "critic_grad_norm": 0.03440963104367256, "ratio": 0.9999174475669861, "entropy": 0.667244553565979, "incre_win_rate": 0.8409090909090909, "step": 1271}
{"time": 1767337101.984551, "phase": "train", "update": 1272, "total_env_steps": 4070400, "episode_reward": 0.25500208139419556, "value_loss": 0.008178013190627099, "policy_loss": -0.001363453760698441, "dist_entropy": 0.6799628973007202, "actor_grad_norm": 0.08378700166940689, "critic_grad_norm": 0.029009712859988213, "ratio": 1.000108003616333, "entropy": 0.6799628973007202, "incre_win_rate": 0.9047619047619048, "step": 1272}
{"time": 1767337106.0654795, "phase": "train", "update": 1273, "total_env_steps": 4073600, "episode_reward": 0.2469298541545868, "value_loss": 0.011606871895492078, "policy_loss": -0.001558323417609131, "dist_entropy": 0.6447372794151306, "actor_grad_norm": 0.10211290419101715, "critic_grad_norm": 0.07464506477117538, "ratio": 0.9998624920845032, "entropy": 0.6447372794151306, "incre_win_rate": 0.7674418604651163, "step": 1273}
{"time": 1767337110.1415167, "phase": "train", "update": 1274, "total_env_steps": 4076800, "episode_reward": 0.2640138864517212, "value_loss": 0.004806411173194647, "policy_loss": -0.001188157079355534, "dist_entropy": 0.6665866613388062, "actor_grad_norm": 0.14779677987098694, "critic_grad_norm": 0.07029452174901962, "ratio": 0.999976634979248, "entropy": 0.6665866613388062, "incre_win_rate": 0.975609756097561, "step": 1274}
{"time": 1767337114.2537193, "phase": "train", "update": 1275, "total_env_steps": 4080000, "episode_reward": 0.2702690362930298, "value_loss": 0.004378875624388457, "policy_loss": -0.0007209709872732617, "dist_entropy": 0.6727851510047913, "actor_grad_norm": 0.07419829815626144, "critic_grad_norm": 0.04759683832526207, "ratio": 0.9999012351036072, "entropy": 0.6727851510047913, "incre_win_rate": 0.9777777777777777, "step": 1275}
{"time": 1767337118.393197, "phase": "train", "update": 1276, "total_env_steps": 4083200, "episode_reward": 0.2590257525444031, "value_loss": 0.00519518069922924, "policy_loss": -0.0012392347031806139, "dist_entropy": 0.6710646986961365, "actor_grad_norm": 0.09650354087352753, "critic_grad_norm": 0.047127172350883484, "ratio": 0.9996652603149414, "entropy": 0.6710646986961365, "incre_win_rate": 0.9285714285714286, "step": 1276}
{"time": 1767337128.8628833, "phase": "eval", "update": 1276, "total_env_steps": 4083200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.819536423841058, "step": 1276}
{"time": 1767337132.9905195, "phase": "train", "update": 1277, "total_env_steps": 4086400, "episode_reward": 0.2631787955760956, "value_loss": 0.005015202611684799, "policy_loss": -0.000909557692890317, "dist_entropy": 0.6809806942939758, "actor_grad_norm": 0.09745617210865021, "critic_grad_norm": 0.04646943137049675, "ratio": 1.0001835823059082, "entropy": 0.6809806942939758, "incre_win_rate": 0.9047619047619048, "step": 1277}
{"time": 1767337137.0727127, "phase": "train", "update": 1278, "total_env_steps": 4089600, "episode_reward": 0.2511920630931854, "value_loss": 0.008747086115181445, "policy_loss": -0.0012001831694316678, "dist_entropy": 0.6591662645339966, "actor_grad_norm": 0.10503923892974854, "critic_grad_norm": 0.061839353293180466, "ratio": 0.9998539090156555, "entropy": 0.6591662645339966, "incre_win_rate": 0.8809523809523809, "step": 1278}
{"time": 1767337141.2184203, "phase": "train", "update": 1279, "total_env_steps": 4092800, "episode_reward": 0.2692756950855255, "value_loss": 0.004701808653771877, "policy_loss": -0.0009819978064633972, "dist_entropy": 0.6779230237007141, "actor_grad_norm": 0.09368359297513962, "critic_grad_norm": 0.041765935719013214, "ratio": 0.9999718070030212, "entropy": 0.6779230237007141, "incre_win_rate": 1.0, "step": 1279}
{"time": 1767337145.2908475, "phase": "train", "update": 1280, "total_env_steps": 4096000, "episode_reward": 0.2570266127586365, "value_loss": 0.005239777453243733, "policy_loss": -0.0009930519277759231, "dist_entropy": 0.658776319026947, "actor_grad_norm": 0.09594225138425827, "critic_grad_norm": 0.06899309903383255, "ratio": 0.9999492764472961, "entropy": 0.658776319026947, "incre_win_rate": 0.875, "step": 1280}
{"time": 1767337149.3860974, "phase": "train", "update": 1281, "total_env_steps": 4099200, "episode_reward": 0.262813538312912, "value_loss": 0.004452417232096195, "policy_loss": -0.0011038772192719648, "dist_entropy": 0.6732323050498963, "actor_grad_norm": 0.09196903556585312, "critic_grad_norm": 0.0464804470539093, "ratio": 1.000016212463379, "entropy": 0.6732323050498963, "incre_win_rate": 0.9545454545454546, "step": 1281}
{"time": 1767337153.5668764, "phase": "train", "update": 1282, "total_env_steps": 4102400, "episode_reward": 0.2707740068435669, "value_loss": 0.0038899275474250316, "policy_loss": -0.0012200806621990522, "dist_entropy": 0.6875652194023132, "actor_grad_norm": 0.09648595005273819, "critic_grad_norm": 0.04346923157572746, "ratio": 1.000019907951355, "entropy": 0.6875652194023132, "incre_win_rate": 0.9545454545454546, "step": 1282}
{"time": 1767337157.6783235, "phase": "train", "update": 1283, "total_env_steps": 4105600, "episode_reward": 0.2628368139266968, "value_loss": 0.007030402403324842, "policy_loss": -0.0013784943073709144, "dist_entropy": 0.6753849625587464, "actor_grad_norm": 0.11294864863157272, "critic_grad_norm": 0.031941235065460205, "ratio": 1.0001685619354248, "entropy": 0.6753849625587464, "incre_win_rate": 0.8863636363636364, "step": 1283}
{"time": 1767337161.784888, "phase": "train", "update": 1284, "total_env_steps": 4108800, "episode_reward": 0.2568506896495819, "value_loss": 0.006014321837574244, "policy_loss": -0.0013312889835589204, "dist_entropy": 0.6872123122215271, "actor_grad_norm": 0.10703183710575104, "critic_grad_norm": 0.038178931921720505, "ratio": 0.9999570846557617, "entropy": 0.6872123122215271, "incre_win_rate": 0.975, "step": 1284}
{"time": 1767337165.8699768, "phase": "train", "update": 1285, "total_env_steps": 4112000, "episode_reward": 0.2626489996910095, "value_loss": 0.0059376852586865425, "policy_loss": -0.0007226516079377632, "dist_entropy": 0.7036398530006409, "actor_grad_norm": 0.11266851425170898, "critic_grad_norm": 0.03252475708723068, "ratio": 0.9999818801879883, "entropy": 0.7036398530006409, "incre_win_rate": 0.9318181818181818, "step": 1285}
{"time": 1767337169.9812531, "phase": "train", "update": 1286, "total_env_steps": 4115200, "episode_reward": 0.2648225426673889, "value_loss": 0.005687751621007919, "policy_loss": -0.001233077331479171, "dist_entropy": 0.707712197303772, "actor_grad_norm": 0.09896916151046753, "critic_grad_norm": 0.023629385977983475, "ratio": 0.9998292326927185, "entropy": 0.707712197303772, "incre_win_rate": 0.9285714285714286, "step": 1286}
{"time": 1767337174.0762484, "phase": "train", "update": 1287, "total_env_steps": 4118400, "episode_reward": 0.25768420100212097, "value_loss": 0.005711892433464527, "policy_loss": -0.0008685378742061545, "dist_entropy": 0.7039054036140442, "actor_grad_norm": 0.08332609385251999, "critic_grad_norm": 0.026591261848807335, "ratio": 0.9998031854629517, "entropy": 0.7039054036140442, "incre_win_rate": 0.9069767441860465, "step": 1287}
{"time": 1767337178.1607158, "phase": "train", "update": 1288, "total_env_steps": 4121600, "episode_reward": 0.25306135416030884, "value_loss": 0.006958763115108013, "policy_loss": -0.001001741070554374, "dist_entropy": 0.6963313460350037, "actor_grad_norm": 0.09565788507461548, "critic_grad_norm": 0.0480463020503521, "ratio": 0.9997909665107727, "entropy": 0.6963313460350037, "incre_win_rate": 0.9024390243902439, "step": 1288}
{"time": 1767337182.28876, "phase": "train", "update": 1289, "total_env_steps": 4124800, "episode_reward": 0.25183773040771484, "value_loss": 0.021150995418429373, "policy_loss": -0.0008775969302163844, "dist_entropy": 0.7088211894035339, "actor_grad_norm": 0.08259475976228714, "critic_grad_norm": 0.10631904751062393, "ratio": 1.0000033378601074, "entropy": 0.7088211894035339, "incre_win_rate": 0.9302325581395349, "step": 1289}
{"time": 1767337186.4159791, "phase": "train", "update": 1290, "total_env_steps": 4128000, "episode_reward": 0.2702069580554962, "value_loss": 0.005753707978874445, "policy_loss": -0.001314850647707999, "dist_entropy": 0.7046438813209533, "actor_grad_norm": 0.11588449776172638, "critic_grad_norm": 0.12243516743183136, "ratio": 0.9999764561653137, "entropy": 0.7046438813209533, "incre_win_rate": 1.0, "step": 1290}
{"time": 1767337190.5283551, "phase": "train", "update": 1291, "total_env_steps": 4131200, "episode_reward": 0.2650206983089447, "value_loss": 0.005975424125790596, "policy_loss": -0.0014785910445496598, "dist_entropy": 0.7164554953575134, "actor_grad_norm": 0.10145360231399536, "critic_grad_norm": 0.07670377939939499, "ratio": 0.9995229840278625, "entropy": 0.7164554953575134, "incre_win_rate": 0.9302325581395349, "step": 1291}
{"time": 1767337194.6248703, "phase": "train", "update": 1292, "total_env_steps": 4134400, "episode_reward": 0.2648509740829468, "value_loss": 0.004567461274564266, "policy_loss": -0.0015795627254725276, "dist_entropy": 0.7212366700172425, "actor_grad_norm": 0.11169973760843277, "critic_grad_norm": 0.045564670115709305, "ratio": 0.9997900128364563, "entropy": 0.7212366700172425, "incre_win_rate": 1.0, "step": 1292}
{"time": 1767337198.7146192, "phase": "train", "update": 1293, "total_env_steps": 4137600, "episode_reward": 0.2656705379486084, "value_loss": 0.0035696299746632576, "policy_loss": -0.0012419662886946625, "dist_entropy": 0.7259867191314697, "actor_grad_norm": 0.14447417855262756, "critic_grad_norm": 0.039482153952121735, "ratio": 0.9997151494026184, "entropy": 0.7259867191314697, "incre_win_rate": 0.975609756097561, "step": 1293}
{"time": 1767337202.809152, "phase": "train", "update": 1294, "total_env_steps": 4140800, "episode_reward": 0.258990079164505, "value_loss": 0.005225684493780136, "policy_loss": -0.0016050899718230483, "dist_entropy": 0.7212827205657959, "actor_grad_norm": 0.10806597769260406, "critic_grad_norm": 0.03831592574715614, "ratio": 0.9995771646499634, "entropy": 0.7212827205657959, "incre_win_rate": 0.9318181818181818, "step": 1294}
{"time": 1767337206.936293, "phase": "train", "update": 1295, "total_env_steps": 4144000, "episode_reward": 0.2613658905029297, "value_loss": 0.005600815545767546, "policy_loss": -0.0011134023366849988, "dist_entropy": 0.7374805569648742, "actor_grad_norm": 0.09338252991437912, "critic_grad_norm": 0.036742132157087326, "ratio": 1.000425934791565, "entropy": 0.7374805569648742, "incre_win_rate": 0.926829268292683, "step": 1295}
{"time": 1767337211.0522375, "phase": "train", "update": 1296, "total_env_steps": 4147200, "episode_reward": 0.26113978028297424, "value_loss": 0.007260153722018004, "policy_loss": -0.0014247657002812275, "dist_entropy": 0.7119153141975403, "actor_grad_norm": 0.0968904048204422, "critic_grad_norm": 0.052554428577423096, "ratio": 1.0002001523971558, "entropy": 0.7119153141975403, "incre_win_rate": 0.8863636363636364, "step": 1296}
{"time": 1767337215.182345, "phase": "train", "update": 1297, "total_env_steps": 4150400, "episode_reward": 0.26395177841186523, "value_loss": 0.0060986332595348355, "policy_loss": -0.001088826324982506, "dist_entropy": 0.7330784320831298, "actor_grad_norm": 0.11841044574975967, "critic_grad_norm": 0.04078567400574684, "ratio": 0.9997388124465942, "entropy": 0.7330784320831298, "incre_win_rate": 0.8863636363636364, "step": 1297}
{"time": 1767337219.241465, "phase": "train", "update": 1298, "total_env_steps": 4153600, "episode_reward": 0.24608442187309265, "value_loss": 0.011975358054041863, "policy_loss": -0.0016275129603602779, "dist_entropy": 0.7454409599304199, "actor_grad_norm": 0.09651177376508713, "critic_grad_norm": 0.08954598754644394, "ratio": 1.0000485181808472, "entropy": 0.7454409599304199, "incre_win_rate": 0.925, "step": 1298}
{"time": 1767337223.3539052, "phase": "train", "update": 1299, "total_env_steps": 4156800, "episode_reward": 0.26064568758010864, "value_loss": 0.0057380272075533865, "policy_loss": -0.0013977178347509777, "dist_entropy": 0.7485366344451905, "actor_grad_norm": 0.08101270347833633, "critic_grad_norm": 0.04145747423171997, "ratio": 1.0002344846725464, "entropy": 0.7485366344451905, "incre_win_rate": 0.9761904761904762, "step": 1299}
{"time": 1767337227.4177165, "phase": "train", "update": 1300, "total_env_steps": 4160000, "episode_reward": 0.2481456995010376, "value_loss": 0.007295280601829291, "policy_loss": -0.0013185246880738077, "dist_entropy": 0.7463542461395264, "actor_grad_norm": 0.10513480752706528, "critic_grad_norm": 0.03561551868915558, "ratio": 0.9995477795600891, "entropy": 0.7463542461395264, "incre_win_rate": 0.925, "step": 1300}
{"time": 1767337231.5147116, "phase": "train", "update": 1301, "total_env_steps": 4163200, "episode_reward": 0.2324177324771881, "value_loss": 0.010442649945616722, "policy_loss": -0.0014032209051904943, "dist_entropy": 0.7398951888084412, "actor_grad_norm": 0.13083118200302124, "critic_grad_norm": 0.07011321932077408, "ratio": 0.9997345209121704, "entropy": 0.7398951888084412, "incre_win_rate": 0.7317073170731707, "step": 1301}
{"time": 1767337241.6342735, "phase": "eval", "update": 1301, "total_env_steps": 4163200, "eval_win_rate": 1.0, "eval_episode_reward": 20.001655629139073, "step": 1301}
{"time": 1767337245.715538, "phase": "train", "update": 1302, "total_env_steps": 4166400, "episode_reward": 0.25342094898223877, "value_loss": 0.008100450411438942, "policy_loss": -0.0012507479960994772, "dist_entropy": 0.731125557422638, "actor_grad_norm": 0.10028471797704697, "critic_grad_norm": 0.07164653390645981, "ratio": 1.0001741647720337, "entropy": 0.731125557422638, "incre_win_rate": 0.9285714285714286, "step": 1302}
{"time": 1767337249.7730577, "phase": "train", "update": 1303, "total_env_steps": 4169600, "episode_reward": 0.24564309418201447, "value_loss": 0.010483640246093273, "policy_loss": -0.0017790055603072118, "dist_entropy": 0.7358575105667114, "actor_grad_norm": 0.10208342224359512, "critic_grad_norm": 0.10101770609617233, "ratio": 0.9998070597648621, "entropy": 0.7358575105667114, "incre_win_rate": 0.8, "step": 1303}
{"time": 1767337253.869549, "phase": "train", "update": 1304, "total_env_steps": 4172800, "episode_reward": 0.25396108627319336, "value_loss": 0.009793784841895104, "policy_loss": -0.0007878409737649861, "dist_entropy": 0.7408710598945618, "actor_grad_norm": 0.08464663475751877, "critic_grad_norm": 0.08143811672925949, "ratio": 1.0005406141281128, "entropy": 0.7408710598945618, "incre_win_rate": 0.8604651162790697, "step": 1304}
{"time": 1767337257.9346964, "phase": "train", "update": 1305, "total_env_steps": 4176000, "episode_reward": 0.25475165247917175, "value_loss": 0.007324548624455929, "policy_loss": -0.0012866514268623063, "dist_entropy": 0.7560548782348633, "actor_grad_norm": 0.11641909927129745, "critic_grad_norm": 0.04080953076481819, "ratio": 1.0000121593475342, "entropy": 0.7560548782348633, "incre_win_rate": 0.925, "step": 1305}
{"time": 1767337262.0715947, "phase": "train", "update": 1306, "total_env_steps": 4179200, "episode_reward": 0.2538162171840668, "value_loss": 0.005289988499134779, "policy_loss": -0.0015144908598443863, "dist_entropy": 0.7648293495178222, "actor_grad_norm": 0.09520002454519272, "critic_grad_norm": 0.06731811165809631, "ratio": 1.0004106760025024, "entropy": 0.7648293495178222, "incre_win_rate": 0.9285714285714286, "step": 1306}
{"time": 1767337290.7459698, "phase": "train", "update": 1307, "total_env_steps": 4182400, "episode_reward": 0.2467932254076004, "value_loss": 0.08832835257053376, "policy_loss": -0.0013041217911840875, "dist_entropy": 0.7716443419456482, "actor_grad_norm": 0.09052575379610062, "critic_grad_norm": 0.31262993812561035, "ratio": 0.9998067021369934, "entropy": 0.7716443419456482, "incre_win_rate": 0.8974358974358975, "step": 1307}
{"time": 1767337294.8733933, "phase": "train", "update": 1308, "total_env_steps": 4185600, "episode_reward": 0.24194692075252533, "value_loss": 0.014859971031546593, "policy_loss": -0.00085855352132711, "dist_entropy": 0.7727534532546997, "actor_grad_norm": 0.12456227838993073, "critic_grad_norm": 0.19571344554424286, "ratio": 1.000032901763916, "entropy": 0.7727534532546997, "incre_win_rate": 0.8571428571428571, "step": 1308}
{"time": 1767337298.9885411, "phase": "train", "update": 1309, "total_env_steps": 4188800, "episode_reward": 0.24210679531097412, "value_loss": 0.01086030937731266, "policy_loss": -0.0013730729209093795, "dist_entropy": 0.802938175201416, "actor_grad_norm": 0.08552511781454086, "critic_grad_norm": 0.14165090024471283, "ratio": 0.9996801614761353, "entropy": 0.802938175201416, "incre_win_rate": 0.825, "step": 1309}
{"time": 1767337303.0412884, "phase": "train", "update": 1310, "total_env_steps": 4192000, "episode_reward": 0.24306292831897736, "value_loss": 0.010520895384252072, "policy_loss": -0.001411776879570148, "dist_entropy": 0.7992471814155578, "actor_grad_norm": 0.0937572717666626, "critic_grad_norm": 0.09559979289770126, "ratio": 1.0001959800720215, "entropy": 0.7992471814155578, "incre_win_rate": 0.8, "step": 1310}
{"time": 1767337307.0985246, "phase": "train", "update": 1311, "total_env_steps": 4195200, "episode_reward": 0.2519122362136841, "value_loss": 0.00801753904670477, "policy_loss": -0.0009925190435410513, "dist_entropy": 0.7960062026977539, "actor_grad_norm": 0.09436185657978058, "critic_grad_norm": 0.035313576459884644, "ratio": 0.9999942779541016, "entropy": 0.7960062026977539, "incre_win_rate": 0.8604651162790697, "step": 1311}
{"time": 1767337311.1617494, "phase": "train", "update": 1312, "total_env_steps": 4198400, "episode_reward": 0.25585681200027466, "value_loss": 0.006739270128309727, "policy_loss": -0.0007723781938587138, "dist_entropy": 0.8041258692741394, "actor_grad_norm": 0.08745275437831879, "critic_grad_norm": 0.03652411326766014, "ratio": 0.9995713233947754, "entropy": 0.8041258692741394, "incre_win_rate": 0.9024390243902439, "step": 1312}
{"time": 1767337315.2623367, "phase": "train", "update": 1313, "total_env_steps": 4201600, "episode_reward": 0.24843129515647888, "value_loss": 0.008312450721859932, "policy_loss": -0.0014457530734667047, "dist_entropy": 0.81301429271698, "actor_grad_norm": 0.10004176199436188, "critic_grad_norm": 0.0293330829590559, "ratio": 0.9997758269309998, "entropy": 0.81301429271698, "incre_win_rate": 0.8604651162790697, "step": 1313}
{"time": 1767337319.333726, "phase": "train", "update": 1314, "total_env_steps": 4204800, "episode_reward": 0.2534436881542206, "value_loss": 0.00749699892476201, "policy_loss": -0.001246369294827332, "dist_entropy": 0.8081235885620117, "actor_grad_norm": 0.09498810768127441, "critic_grad_norm": 0.030187388882040977, "ratio": 1.0001641511917114, "entropy": 0.8081235885620117, "incre_win_rate": 0.8809523809523809, "step": 1314}
{"time": 1767337323.4204676, "phase": "train", "update": 1315, "total_env_steps": 4208000, "episode_reward": 0.2412106841802597, "value_loss": 0.012138250283896923, "policy_loss": -0.0013794738804364215, "dist_entropy": 0.8201161861419678, "actor_grad_norm": 0.09924951940774918, "critic_grad_norm": 0.053305573761463165, "ratio": 1.0003546476364136, "entropy": 0.8201161861419678, "incre_win_rate": 0.85, "step": 1315}
{"time": 1767337327.508576, "phase": "train", "update": 1316, "total_env_steps": 4211200, "episode_reward": 0.24799256026744843, "value_loss": 0.00891264770179987, "policy_loss": -0.0010710351065398526, "dist_entropy": 0.7783572912216187, "actor_grad_norm": 0.09719289839267731, "critic_grad_norm": 0.036604687571525574, "ratio": 0.9994231462478638, "entropy": 0.7783572912216187, "incre_win_rate": 0.8571428571428571, "step": 1316}
{"time": 1767337331.6018977, "phase": "train", "update": 1317, "total_env_steps": 4214400, "episode_reward": 0.2581503689289093, "value_loss": 0.008799594081938266, "policy_loss": -0.0007894814898754988, "dist_entropy": 0.780483090877533, "actor_grad_norm": 0.07676909863948822, "critic_grad_norm": 0.02279229834675789, "ratio": 0.9999424815177917, "entropy": 0.780483090877533, "incre_win_rate": 0.8780487804878049, "step": 1317}
{"time": 1767337335.6950405, "phase": "train", "update": 1318, "total_env_steps": 4217600, "episode_reward": 0.2511811852455139, "value_loss": 0.0069392483681440355, "policy_loss": -0.001495633122647888, "dist_entropy": 0.7604617476463318, "actor_grad_norm": 0.10798259824514389, "critic_grad_norm": 0.039099182933568954, "ratio": 1.00011146068573, "entropy": 0.7604617476463318, "incre_win_rate": 0.8780487804878049, "step": 1318}
{"time": 1767337339.841471, "phase": "train", "update": 1319, "total_env_steps": 4220800, "episode_reward": 0.25938329100608826, "value_loss": 0.004170706868171692, "policy_loss": -0.0013114319874269142, "dist_entropy": 0.7636408567428589, "actor_grad_norm": 0.11911529302597046, "critic_grad_norm": 0.03920041024684906, "ratio": 1.0002275705337524, "entropy": 0.7636408567428589, "incre_win_rate": 0.9523809523809523, "step": 1319}
{"time": 1767337343.929978, "phase": "train", "update": 1320, "total_env_steps": 4224000, "episode_reward": 0.25689467787742615, "value_loss": 0.007006142660975457, "policy_loss": -0.0009347347814674834, "dist_entropy": 0.7422797560691834, "actor_grad_norm": 0.09527405351400375, "critic_grad_norm": 0.03146550431847572, "ratio": 0.9999825358390808, "entropy": 0.7422797560691834, "incre_win_rate": 0.8837209302325582, "step": 1320}
{"time": 1767337348.0044918, "phase": "train", "update": 1321, "total_env_steps": 4227200, "episode_reward": 0.255586713552475, "value_loss": 0.0038316278252750633, "policy_loss": -0.0010781393614313294, "dist_entropy": 0.7451815605163574, "actor_grad_norm": 0.07887053489685059, "critic_grad_norm": 0.020680321380496025, "ratio": 1.0001705884933472, "entropy": 0.7451815605163574, "incre_win_rate": 0.9761904761904762, "step": 1321}
{"time": 1767337352.0837405, "phase": "train", "update": 1322, "total_env_steps": 4230400, "episode_reward": 0.2623603045940399, "value_loss": 0.005766096618026495, "policy_loss": -0.0009385255942912174, "dist_entropy": 0.7325809717178344, "actor_grad_norm": 0.09480664134025574, "critic_grad_norm": 0.02056186832487583, "ratio": 0.9996628761291504, "entropy": 0.7325809717178344, "incre_win_rate": 0.9302325581395349, "step": 1322}
{"time": 1767337356.2214134, "phase": "train", "update": 1323, "total_env_steps": 4233600, "episode_reward": 0.26361966133117676, "value_loss": 0.005632406380027532, "policy_loss": -0.0011846649537602615, "dist_entropy": 0.7365681767463684, "actor_grad_norm": 0.12856054306030273, "critic_grad_norm": 0.04742338880896568, "ratio": 0.9998369216918945, "entropy": 0.7365681767463684, "incre_win_rate": 0.9761904761904762, "step": 1323}
{"time": 1767337360.3192735, "phase": "train", "update": 1324, "total_env_steps": 4236800, "episode_reward": 0.26111340522766113, "value_loss": 0.006699891202151776, "policy_loss": -0.0010217570518051388, "dist_entropy": 0.7000767230987549, "actor_grad_norm": 0.11649928241968155, "critic_grad_norm": 0.039994996041059494, "ratio": 0.9997476935386658, "entropy": 0.7000767230987549, "incre_win_rate": 0.9534883720930233, "step": 1324}
{"time": 1767337364.3801794, "phase": "train", "update": 1325, "total_env_steps": 4240000, "episode_reward": 0.2590852677822113, "value_loss": 0.006652771960943937, "policy_loss": -0.0009119861311404521, "dist_entropy": 0.7341225504875183, "actor_grad_norm": 0.07642124593257904, "critic_grad_norm": 0.028835326433181763, "ratio": 0.9999165534973145, "entropy": 0.7341225504875183, "incre_win_rate": 0.925, "step": 1325}
{"time": 1767337368.4483223, "phase": "train", "update": 1326, "total_env_steps": 4243200, "episode_reward": 0.25787150859832764, "value_loss": 0.007443638518452644, "policy_loss": -0.001465657845726298, "dist_entropy": 0.7385372638702392, "actor_grad_norm": 0.12131696939468384, "critic_grad_norm": 0.04940934106707573, "ratio": 1.0004913806915283, "entropy": 0.7385372638702392, "incre_win_rate": 0.9534883720930233, "step": 1326}
{"time": 1767337379.4148414, "phase": "eval", "update": 1326, "total_env_steps": 4243200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.73183981788079, "step": 1326}
{"time": 1767337383.4879997, "phase": "train", "update": 1327, "total_env_steps": 4246400, "episode_reward": 0.261301726102829, "value_loss": 0.005506746377795935, "policy_loss": -0.0012287170299018157, "dist_entropy": 0.7625159740447998, "actor_grad_norm": 0.11921612173318863, "critic_grad_norm": 0.02966744638979435, "ratio": 0.999583899974823, "entropy": 0.7625159740447998, "incre_win_rate": 0.8809523809523809, "step": 1327}
{"time": 1767337387.5494003, "phase": "train", "update": 1328, "total_env_steps": 4249600, "episode_reward": 0.25275248289108276, "value_loss": 0.008503548242151738, "policy_loss": -0.0010109523319755454, "dist_entropy": 0.7582879662513733, "actor_grad_norm": 0.09802301228046417, "critic_grad_norm": 0.029508013278245926, "ratio": 0.9998270869255066, "entropy": 0.7582879662513733, "incre_win_rate": 0.8636363636363636, "step": 1328}
{"time": 1767337391.5772226, "phase": "train", "update": 1329, "total_env_steps": 4252800, "episode_reward": 0.2503300905227661, "value_loss": 0.0068093881011009215, "policy_loss": -0.0020706299572935904, "dist_entropy": 0.7537322521209717, "actor_grad_norm": 0.11246500164270401, "critic_grad_norm": 0.04416752979159355, "ratio": 1.000487208366394, "entropy": 0.7537322521209717, "incre_win_rate": 0.875, "step": 1329}
{"time": 1767337395.6267648, "phase": "train", "update": 1330, "total_env_steps": 4256000, "episode_reward": 0.25110098719596863, "value_loss": 0.00831325761973858, "policy_loss": -0.0007696944183820164, "dist_entropy": 0.7538602471351623, "actor_grad_norm": 0.09337422996759415, "critic_grad_norm": 0.07899194210767746, "ratio": 1.0001072883605957, "entropy": 0.7538602471351623, "incre_win_rate": 0.8780487804878049, "step": 1330}
{"time": 1767337399.6855383, "phase": "train", "update": 1331, "total_env_steps": 4259200, "episode_reward": 0.26355546712875366, "value_loss": 0.006960460264235735, "policy_loss": -0.001155397133874203, "dist_entropy": 0.7565950274467468, "actor_grad_norm": 0.08740963041782379, "critic_grad_norm": 0.052304308861494064, "ratio": 0.9998331069946289, "entropy": 0.7565950274467468, "incre_win_rate": 0.9333333333333333, "step": 1331}
{"time": 1767337403.8055146, "phase": "train", "update": 1332, "total_env_steps": 4262400, "episode_reward": 0.26760348677635193, "value_loss": 0.006304362788796425, "policy_loss": -0.001533965315173802, "dist_entropy": 0.7602271437644958, "actor_grad_norm": 0.0956825464963913, "critic_grad_norm": 0.05488675832748413, "ratio": 0.999824047088623, "entropy": 0.7602271437644958, "incre_win_rate": 0.9523809523809523, "step": 1332}
{"time": 1767337407.9022748, "phase": "train", "update": 1333, "total_env_steps": 4265600, "episode_reward": 0.2683148682117462, "value_loss": 0.0038286000024527313, "policy_loss": -0.0011660973977811295, "dist_entropy": 0.7880029320716858, "actor_grad_norm": 0.11958332359790802, "critic_grad_norm": 0.056203629821538925, "ratio": 0.9996885657310486, "entropy": 0.7880029320716858, "incre_win_rate": 0.9767441860465116, "step": 1333}
{"time": 1767337411.9888203, "phase": "train", "update": 1334, "total_env_steps": 4268800, "episode_reward": 0.2631787955760956, "value_loss": 0.006338808964937925, "policy_loss": -0.0013156908356133812, "dist_entropy": 0.7788858771324157, "actor_grad_norm": 0.10318126529455185, "critic_grad_norm": 0.05902466922998428, "ratio": 1.0002646446228027, "entropy": 0.7788858771324157, "incre_win_rate": 0.9523809523809523, "step": 1334}
{"time": 1767337416.092973, "phase": "train", "update": 1335, "total_env_steps": 4272000, "episode_reward": 0.25252074003219604, "value_loss": 0.00739089185371995, "policy_loss": -0.001638473192949874, "dist_entropy": 0.7737172365188598, "actor_grad_norm": 0.13775736093521118, "critic_grad_norm": 0.06426426023244858, "ratio": 0.999735951423645, "entropy": 0.7737172365188598, "incre_win_rate": 0.8604651162790697, "step": 1335}
{"time": 1767337420.153299, "phase": "train", "update": 1336, "total_env_steps": 4275200, "episode_reward": 0.24268315732479095, "value_loss": 0.009628490544855595, "policy_loss": -0.0015797609002497382, "dist_entropy": 0.7980443716049195, "actor_grad_norm": 0.11415868997573853, "critic_grad_norm": 0.10873105376958847, "ratio": 0.9997410774230957, "entropy": 0.7980443716049195, "incre_win_rate": 0.725, "step": 1336}
{"time": 1767337424.2635098, "phase": "train", "update": 1337, "total_env_steps": 4278400, "episode_reward": 0.25963473320007324, "value_loss": 0.008735980466008186, "policy_loss": -0.0015886276151821032, "dist_entropy": 0.7946669697761536, "actor_grad_norm": 0.11498422920703888, "critic_grad_norm": 0.061060529202222824, "ratio": 1.0002963542938232, "entropy": 0.7946669697761536, "incre_win_rate": 0.9090909090909091, "step": 1337}
{"time": 1767337428.3222735, "phase": "train", "update": 1338, "total_env_steps": 4281600, "episode_reward": 0.24654075503349304, "value_loss": 0.008810553513467313, "policy_loss": -0.0015358681589333401, "dist_entropy": 0.7823321342468261, "actor_grad_norm": 0.11245623975992203, "critic_grad_norm": 0.059728898108005524, "ratio": 1.0003374814987183, "entropy": 0.7823321342468261, "incre_win_rate": 0.8095238095238095, "step": 1338}
{"time": 1767337432.4338937, "phase": "train", "update": 1339, "total_env_steps": 4284800, "episode_reward": 0.26378312706947327, "value_loss": 0.007656434644013643, "policy_loss": -0.0013747283378663156, "dist_entropy": 0.7448752164840698, "actor_grad_norm": 0.12481682747602463, "critic_grad_norm": 0.14421585202217102, "ratio": 0.9998632669448853, "entropy": 0.7448752164840698, "incre_win_rate": 0.9090909090909091, "step": 1339}
{"time": 1767337436.5010161, "phase": "train", "update": 1340, "total_env_steps": 4288000, "episode_reward": 0.262715220451355, "value_loss": 0.006746951211243868, "policy_loss": -0.0010764345991017166, "dist_entropy": 0.7499232411384582, "actor_grad_norm": 0.10119616240262985, "critic_grad_norm": 0.10282426327466965, "ratio": 1.0003502368927002, "entropy": 0.7499232411384582, "incre_win_rate": 0.9024390243902439, "step": 1340}
{"time": 1767337440.5790768, "phase": "train", "update": 1341, "total_env_steps": 4291200, "episode_reward": 0.26086458563804626, "value_loss": 0.009187216684222222, "policy_loss": -0.001334902749267186, "dist_entropy": 0.7478043556213378, "actor_grad_norm": 0.11007660627365112, "critic_grad_norm": 0.0680784210562706, "ratio": 0.9998825192451477, "entropy": 0.7478043556213378, "incre_win_rate": 0.8666666666666667, "step": 1341}
{"time": 1767337444.6823788, "phase": "train", "update": 1342, "total_env_steps": 4294400, "episode_reward": 0.2658485174179077, "value_loss": 0.004820917453616858, "policy_loss": -0.0010971429624351714, "dist_entropy": 0.7551969170570374, "actor_grad_norm": 0.10702713578939438, "critic_grad_norm": 0.05648119002580643, "ratio": 0.99990314245224, "entropy": 0.7551969170570374, "incre_win_rate": 0.9767441860465116, "step": 1342}
{"time": 1767337448.7479138, "phase": "train", "update": 1343, "total_env_steps": 4297600, "episode_reward": 0.25161218643188477, "value_loss": 0.00699461493641138, "policy_loss": -0.0012209105137021225, "dist_entropy": 0.7797061920166015, "actor_grad_norm": 0.07694794982671738, "critic_grad_norm": 0.07295985519886017, "ratio": 0.9999791979789734, "entropy": 0.7797061920166015, "incre_win_rate": 0.9069767441860465, "step": 1343}
{"time": 1767337452.8542402, "phase": "train", "update": 1344, "total_env_steps": 4300800, "episode_reward": 0.2674172520637512, "value_loss": 0.004999390244483948, "policy_loss": -0.0011707588552226865, "dist_entropy": 0.7724957704544068, "actor_grad_norm": 0.0874142274260521, "critic_grad_norm": 0.10036702454090118, "ratio": 1.0002254247665405, "entropy": 0.7724957704544068, "incre_win_rate": 0.975609756097561, "step": 1344}
{"time": 1767337456.9088457, "phase": "train", "update": 1345, "total_env_steps": 4304000, "episode_reward": 0.25850579142570496, "value_loss": 0.007583398837596178, "policy_loss": -0.0017878343991014844, "dist_entropy": 0.7666325211524964, "actor_grad_norm": 0.09845753759145737, "critic_grad_norm": 0.05829678848385811, "ratio": 0.999659538269043, "entropy": 0.7666325211524964, "incre_win_rate": 0.8863636363636364, "step": 1345}
{"time": 1767337461.0489876, "phase": "train", "update": 1346, "total_env_steps": 4307200, "episode_reward": 0.25885865092277527, "value_loss": 0.007432690262794495, "policy_loss": -0.0010623421016781264, "dist_entropy": 0.7758749723434448, "actor_grad_norm": 0.11121779680252075, "critic_grad_norm": 0.04347681626677513, "ratio": 1.0001994371414185, "entropy": 0.7758749723434448, "incre_win_rate": 0.9047619047619048, "step": 1346}
{"time": 1767337465.1216948, "phase": "train", "update": 1347, "total_env_steps": 4310400, "episode_reward": 0.25604304671287537, "value_loss": 0.006985793635249138, "policy_loss": -0.001539872489013172, "dist_entropy": 0.7811129570007325, "actor_grad_norm": 0.09828480333089828, "critic_grad_norm": 0.058223575353622437, "ratio": 0.9997586607933044, "entropy": 0.7811129570007325, "incre_win_rate": 0.9512195121951219, "step": 1347}
{"time": 1767337469.215965, "phase": "train", "update": 1348, "total_env_steps": 4313600, "episode_reward": 0.25184860825538635, "value_loss": 0.007352437451481819, "policy_loss": -0.0013127751251921893, "dist_entropy": 0.775636613368988, "actor_grad_norm": 0.10742920637130737, "critic_grad_norm": 0.03370699658989906, "ratio": 0.9996212124824524, "entropy": 0.775636613368988, "incre_win_rate": 0.9047619047619048, "step": 1348}
{"time": 1767337473.2983806, "phase": "train", "update": 1349, "total_env_steps": 4316800, "episode_reward": 0.2506125867366791, "value_loss": 0.0072662304155528545, "policy_loss": -0.0015765289959823292, "dist_entropy": 0.750171673297882, "actor_grad_norm": 0.1261417418718338, "critic_grad_norm": 0.040771227329969406, "ratio": 0.9994004368782043, "entropy": 0.750171673297882, "incre_win_rate": 0.8837209302325582, "step": 1349}
{"time": 1767337477.361581, "phase": "train", "update": 1350, "total_env_steps": 4320000, "episode_reward": 0.2502400875091553, "value_loss": 0.004699908848851919, "policy_loss": -0.0014380960169617651, "dist_entropy": 0.7689698100090027, "actor_grad_norm": 0.12136638164520264, "critic_grad_norm": 0.06191868707537651, "ratio": 1.0000733137130737, "entropy": 0.7689698100090027, "incre_win_rate": 0.9210526315789473, "step": 1350}
{"time": 1767337481.43715, "phase": "train", "update": 1351, "total_env_steps": 4323200, "episode_reward": 0.26933053135871887, "value_loss": 0.004895837604999542, "policy_loss": -0.0013396724298132766, "dist_entropy": 0.7712860107421875, "actor_grad_norm": 0.10196846723556519, "critic_grad_norm": 0.03887421637773514, "ratio": 1.0000903606414795, "entropy": 0.7712860107421875, "incre_win_rate": 0.9347826086956522, "step": 1351}
{"time": 1767337491.473113, "phase": "eval", "update": 1351, "total_env_steps": 4323200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.5338886589404, "step": 1351}
{"time": 1767337495.5379794, "phase": "train", "update": 1352, "total_env_steps": 4326400, "episode_reward": 0.2633914649486542, "value_loss": 0.005436332989484071, "policy_loss": -0.0012852755464265897, "dist_entropy": 0.7691944479942322, "actor_grad_norm": 0.10431603342294693, "critic_grad_norm": 0.06656204909086227, "ratio": 0.9997467398643494, "entropy": 0.7691944479942322, "incre_win_rate": 0.9523809523809523, "step": 1352}
{"time": 1767337499.6667082, "phase": "train", "update": 1353, "total_env_steps": 4329600, "episode_reward": 0.26513245701789856, "value_loss": 0.005875250231474638, "policy_loss": -0.0010940987430764436, "dist_entropy": 0.7689653635025024, "actor_grad_norm": 0.08346665650606155, "critic_grad_norm": 0.05046125873923302, "ratio": 0.999775230884552, "entropy": 0.7689653635025024, "incre_win_rate": 0.9302325581395349, "step": 1353}
{"time": 1767337503.768664, "phase": "train", "update": 1354, "total_env_steps": 4332800, "episode_reward": 0.2516991198062897, "value_loss": 0.009098574332892895, "policy_loss": -0.0017211202737604126, "dist_entropy": 0.7762331962585449, "actor_grad_norm": 0.12867413461208344, "critic_grad_norm": 0.0350462831556797, "ratio": 0.9990793466567993, "entropy": 0.7762331962585449, "incre_win_rate": 0.8636363636363636, "step": 1354}
{"time": 1767337507.823358, "phase": "train", "update": 1355, "total_env_steps": 4336000, "episode_reward": 0.25610771775245667, "value_loss": 0.01191143449395895, "policy_loss": -0.0014578061075269488, "dist_entropy": 0.7774090647697449, "actor_grad_norm": 0.11824163049459457, "critic_grad_norm": 0.06602120399475098, "ratio": 1.0000709295272827, "entropy": 0.7774090647697449, "incre_win_rate": 0.9, "step": 1355}
{"time": 1767337511.8887262, "phase": "train", "update": 1356, "total_env_steps": 4339200, "episode_reward": 0.25622931122779846, "value_loss": 0.010908210836350917, "policy_loss": -0.0015867879999031942, "dist_entropy": 0.7814978241920472, "actor_grad_norm": 0.0967208668589592, "critic_grad_norm": 0.045200277119874954, "ratio": 0.9997817277908325, "entropy": 0.7814978241920472, "incre_win_rate": 0.8372093023255814, "step": 1356}
{"time": 1767337515.9976044, "phase": "train", "update": 1357, "total_env_steps": 4342400, "episode_reward": 0.2653176784515381, "value_loss": 0.006456661596894264, "policy_loss": -0.0012859225203182944, "dist_entropy": 0.7759778261184692, "actor_grad_norm": 0.09863679856061935, "critic_grad_norm": 0.045836858451366425, "ratio": 1.0002235174179077, "entropy": 0.7759778261184692, "incre_win_rate": 0.9302325581395349, "step": 1357}
{"time": 1767337520.1210237, "phase": "train", "update": 1358, "total_env_steps": 4345600, "episode_reward": 0.26503413915634155, "value_loss": 0.005931076873093843, "policy_loss": -0.0010788717409326409, "dist_entropy": 0.7917110085487366, "actor_grad_norm": 0.09605780243873596, "critic_grad_norm": 0.07316720485687256, "ratio": 0.9996213316917419, "entropy": 0.7917110085487366, "incre_win_rate": 0.9090909090909091, "step": 1358}
{"time": 1767337524.2421837, "phase": "train", "update": 1359, "total_env_steps": 4348800, "episode_reward": 0.26232874393463135, "value_loss": 0.0091940987855196, "policy_loss": -0.00128191420940027, "dist_entropy": 0.7774925589561462, "actor_grad_norm": 0.09916438907384872, "critic_grad_norm": 0.07809905707836151, "ratio": 0.9997381567955017, "entropy": 0.7774925589561462, "incre_win_rate": 0.8837209302325582, "step": 1359}
{"time": 1767337528.3622963, "phase": "train", "update": 1360, "total_env_steps": 4352000, "episode_reward": 0.27496689558029175, "value_loss": 0.005048082210123539, "policy_loss": -0.001147875558432787, "dist_entropy": 0.7840337753295898, "actor_grad_norm": 0.10660294443368912, "critic_grad_norm": 0.10089907795190811, "ratio": 1.0000296831130981, "entropy": 0.7840337753295898, "incre_win_rate": 0.9761904761904762, "step": 1360}
{"time": 1767337532.4143221, "phase": "train", "update": 1361, "total_env_steps": 4355200, "episode_reward": 0.2575356960296631, "value_loss": 0.007271466217935086, "policy_loss": -0.0008269953492288096, "dist_entropy": 0.7686428666114807, "actor_grad_norm": 0.09375550597906113, "critic_grad_norm": 0.056035496294498444, "ratio": 1.0000172853469849, "entropy": 0.7686428666114807, "incre_win_rate": 0.9318181818181818, "step": 1361}
{"time": 1767337536.522559, "phase": "train", "update": 1362, "total_env_steps": 4358400, "episode_reward": 0.25667375326156616, "value_loss": 0.00903923399746418, "policy_loss": -0.0014208947437522213, "dist_entropy": 0.7487685561180115, "actor_grad_norm": 0.11864735931158066, "critic_grad_norm": 0.04399433732032776, "ratio": 0.9999207854270935, "entropy": 0.7487685561180115, "incre_win_rate": 0.8837209302325582, "step": 1362}
{"time": 1767337540.6087828, "phase": "train", "update": 1363, "total_env_steps": 4361600, "episode_reward": 0.2668449878692627, "value_loss": 0.007357217557728291, "policy_loss": -0.0014231782406596948, "dist_entropy": 0.7459638833999633, "actor_grad_norm": 0.08879724889993668, "critic_grad_norm": 0.07105856388807297, "ratio": 0.9997805953025818, "entropy": 0.7459638833999633, "incre_win_rate": 0.9302325581395349, "step": 1363}
{"time": 1767337544.6902645, "phase": "train", "update": 1364, "total_env_steps": 4364800, "episode_reward": 0.26448675990104675, "value_loss": 0.008820660319179297, "policy_loss": -0.0011669505890353094, "dist_entropy": 0.7365165233612061, "actor_grad_norm": 0.08422394096851349, "critic_grad_norm": 0.08961442857980728, "ratio": 0.9998487830162048, "entropy": 0.7365165233612061, "incre_win_rate": 0.9512195121951219, "step": 1364}
{"time": 1767337548.7548995, "phase": "train", "update": 1365, "total_env_steps": 4368000, "episode_reward": 0.25451934337615967, "value_loss": 0.008666611649096012, "policy_loss": -0.0014332696795690935, "dist_entropy": 0.757309353351593, "actor_grad_norm": 0.12937675416469574, "critic_grad_norm": 0.06710648536682129, "ratio": 0.9999819993972778, "entropy": 0.757309353351593, "incre_win_rate": 0.8478260869565217, "step": 1365}
{"time": 1767337552.8189352, "phase": "train", "update": 1366, "total_env_steps": 4371200, "episode_reward": 0.25569796562194824, "value_loss": 0.007194881699979306, "policy_loss": -0.001080021210623272, "dist_entropy": 0.7512257695198059, "actor_grad_norm": 0.08332231640815735, "critic_grad_norm": 0.07473006099462509, "ratio": 1.0000734329223633, "entropy": 0.7512257695198059, "incre_win_rate": 0.9024390243902439, "step": 1366}
{"time": 1767337556.9026117, "phase": "train", "update": 1367, "total_env_steps": 4374400, "episode_reward": 0.2595110833644867, "value_loss": 0.009035502560436726, "policy_loss": -0.0013161894064440461, "dist_entropy": 0.7627647161483765, "actor_grad_norm": 0.10527598857879639, "critic_grad_norm": 0.04738857224583626, "ratio": 0.9997601509094238, "entropy": 0.7627647161483765, "incre_win_rate": 0.8780487804878049, "step": 1367}
{"time": 1767337561.006164, "phase": "train", "update": 1368, "total_env_steps": 4377600, "episode_reward": 0.255972683429718, "value_loss": 0.011592169106006623, "policy_loss": -0.0013981074965339958, "dist_entropy": 0.7552377700805664, "actor_grad_norm": 0.08810628205537796, "critic_grad_norm": 0.051496367901563644, "ratio": 1.0004156827926636, "entropy": 0.7552377700805664, "incre_win_rate": 0.8222222222222222, "step": 1368}
{"time": 1767337565.1487665, "phase": "train", "update": 1369, "total_env_steps": 4380800, "episode_reward": 0.25288286805152893, "value_loss": 0.008488027192652226, "policy_loss": -0.0016710817052449033, "dist_entropy": 0.760247266292572, "actor_grad_norm": 0.10980470478534698, "critic_grad_norm": 0.07753125578165054, "ratio": 1.0004326105117798, "entropy": 0.760247266292572, "incre_win_rate": 0.7674418604651163, "step": 1369}
{"time": 1767337569.2643378, "phase": "train", "update": 1370, "total_env_steps": 4384000, "episode_reward": 0.26555877923965454, "value_loss": 0.008703636936843395, "policy_loss": -0.0012301782028181663, "dist_entropy": 0.7528236150741577, "actor_grad_norm": 0.09525364637374878, "critic_grad_norm": 0.08460714668035507, "ratio": 0.9998898506164551, "entropy": 0.7528236150741577, "incre_win_rate": 0.9534883720930233, "step": 1370}
{"time": 1767337573.3504179, "phase": "train", "update": 1371, "total_env_steps": 4387200, "episode_reward": 0.25669804215431213, "value_loss": 0.009054972790181637, "policy_loss": -0.0015920031201886787, "dist_entropy": 0.7635099172592164, "actor_grad_norm": 0.10883241146802902, "critic_grad_norm": 0.06891553848981857, "ratio": 0.9998776316642761, "entropy": 0.7635099172592164, "incre_win_rate": 0.8837209302325582, "step": 1371}
{"time": 1767337577.416796, "phase": "train", "update": 1372, "total_env_steps": 4390400, "episode_reward": 0.23796512186527252, "value_loss": 0.010134581290185452, "policy_loss": -0.001444800014021297, "dist_entropy": 0.7359767436981202, "actor_grad_norm": 0.09462087601423264, "critic_grad_norm": 0.06512033194303513, "ratio": 0.999951183795929, "entropy": 0.7359767436981202, "incre_win_rate": 0.725, "step": 1372}
{"time": 1767337581.5577188, "phase": "train", "update": 1373, "total_env_steps": 4393600, "episode_reward": 0.2578202486038208, "value_loss": 0.007192569971084595, "policy_loss": -0.0008969356033816211, "dist_entropy": 0.7537891030311584, "actor_grad_norm": 0.09794964641332626, "critic_grad_norm": 0.05164789780974388, "ratio": 0.9997836947441101, "entropy": 0.7537891030311584, "incre_win_rate": 0.9069767441860465, "step": 1373}
{"time": 1767337585.6431384, "phase": "train", "update": 1374, "total_env_steps": 4396800, "episode_reward": 0.2595234811306, "value_loss": 0.006645311135798693, "policy_loss": -0.0013487269427404636, "dist_entropy": 0.7737519025802613, "actor_grad_norm": 0.10444114357233047, "critic_grad_norm": 0.029661817476153374, "ratio": 1.0000594854354858, "entropy": 0.7737519025802613, "incre_win_rate": 0.9024390243902439, "step": 1374}
{"time": 1767337589.704562, "phase": "train", "update": 1375, "total_env_steps": 4400000, "episode_reward": 0.253928005695343, "value_loss": 0.006764480471611023, "policy_loss": -0.0011161303271151723, "dist_entropy": 0.7586704850196838, "actor_grad_norm": 0.08397240936756134, "critic_grad_norm": 0.04687545821070671, "ratio": 1.0001672506332397, "entropy": 0.7586704850196838, "incre_win_rate": 0.8780487804878049, "step": 1375}
{"time": 1767337593.729513, "phase": "train", "update": 1376, "total_env_steps": 4403200, "episode_reward": 0.23772715032100677, "value_loss": 0.013697988726198674, "policy_loss": -0.0015658315967572278, "dist_entropy": 0.7356451630592347, "actor_grad_norm": 0.11643385142087936, "critic_grad_norm": 0.09184224158525467, "ratio": 0.99965900182724, "entropy": 0.7356451630592347, "incre_win_rate": 0.7727272727272727, "step": 1376}
{"time": 1767337604.0717623, "phase": "eval", "update": 1376, "total_env_steps": 4403200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.419495033112582, "step": 1376}
{"time": 1767337608.1253748, "phase": "train", "update": 1377, "total_env_steps": 4406400, "episode_reward": 0.24001654982566833, "value_loss": 0.011804149113595485, "policy_loss": -0.0012981682520191383, "dist_entropy": 0.7372097373008728, "actor_grad_norm": 0.09908926486968994, "critic_grad_norm": 0.08450136333703995, "ratio": 0.9998363852500916, "entropy": 0.7372097373008728, "incre_win_rate": 0.8048780487804879, "step": 1377}
{"time": 1767337612.2174046, "phase": "train", "update": 1378, "total_env_steps": 4409600, "episode_reward": 0.2582983076572418, "value_loss": 0.0052649094723165035, "policy_loss": -0.0016319355152727866, "dist_entropy": 0.7340970396995544, "actor_grad_norm": 0.1221168041229248, "critic_grad_norm": 0.056466709822416306, "ratio": 1.0000076293945312, "entropy": 0.7340970396995544, "incre_win_rate": 0.9047619047619048, "step": 1378}
{"time": 1767337616.2856274, "phase": "train", "update": 1379, "total_env_steps": 4412800, "episode_reward": 0.25978684425354004, "value_loss": 0.006289125606417656, "policy_loss": -0.0013624065682790842, "dist_entropy": 0.7307397365570069, "actor_grad_norm": 0.10588959604501724, "critic_grad_norm": 0.06773758679628372, "ratio": 1.0001988410949707, "entropy": 0.7307397365570069, "incre_win_rate": 0.9285714285714286, "step": 1379}
{"time": 1767337620.3709767, "phase": "train", "update": 1380, "total_env_steps": 4416000, "episode_reward": 0.24802567064762115, "value_loss": 0.008419790863990783, "policy_loss": -0.0010816305064992094, "dist_entropy": 0.7157338261604309, "actor_grad_norm": 0.09134328365325928, "critic_grad_norm": 0.04436187446117401, "ratio": 1.0001322031021118, "entropy": 0.7157338261604309, "incre_win_rate": 0.8536585365853658, "step": 1380}
{"time": 1767337624.4172802, "phase": "train", "update": 1381, "total_env_steps": 4419200, "episode_reward": 0.24993844330310822, "value_loss": 0.006158824916929007, "policy_loss": -0.0007844069441183876, "dist_entropy": 0.7324422836303711, "actor_grad_norm": 0.09308739006519318, "critic_grad_norm": 0.03327484056353569, "ratio": 1.0001323223114014, "entropy": 0.7324422836303711, "incre_win_rate": 0.8536585365853658, "step": 1381}
{"time": 1767337628.5012958, "phase": "train", "update": 1382, "total_env_steps": 4422400, "episode_reward": 0.25753986835479736, "value_loss": 0.008637434057891368, "policy_loss": -0.001005015385749175, "dist_entropy": 0.7346823215484619, "actor_grad_norm": 0.11622495949268341, "critic_grad_norm": 0.03540217876434326, "ratio": 1.0002487897872925, "entropy": 0.7346823215484619, "incre_win_rate": 0.9302325581395349, "step": 1382}
{"time": 1767337632.6163323, "phase": "train", "update": 1383, "total_env_steps": 4425600, "episode_reward": 0.24979668855667114, "value_loss": 0.008492721989750863, "policy_loss": -0.0011522762725519442, "dist_entropy": 0.7351912975311279, "actor_grad_norm": 0.11965743452310562, "critic_grad_norm": 0.024196621030569077, "ratio": 1.0003321170806885, "entropy": 0.7351912975311279, "incre_win_rate": 0.8809523809523809, "step": 1383}
{"time": 1767337636.730537, "phase": "train", "update": 1384, "total_env_steps": 4428800, "episode_reward": 0.2580225467681885, "value_loss": 0.010643831454217434, "policy_loss": -0.0007657517236815181, "dist_entropy": 0.7271019220352173, "actor_grad_norm": 0.12244688719511032, "critic_grad_norm": 0.042007215321063995, "ratio": 1.0000466108322144, "entropy": 0.7271019220352173, "incre_win_rate": 0.8571428571428571, "step": 1384}
{"time": 1767337640.8134654, "phase": "train", "update": 1385, "total_env_steps": 4432000, "episode_reward": 0.25247931480407715, "value_loss": 0.009185882657766343, "policy_loss": -0.00113476544509723, "dist_entropy": 0.7725934982299805, "actor_grad_norm": 0.11328859627246857, "critic_grad_norm": 0.03438790887594223, "ratio": 0.9997302889823914, "entropy": 0.7725934982299805, "incre_win_rate": 0.8571428571428571, "step": 1385}
{"time": 1767337644.9248314, "phase": "train", "update": 1386, "total_env_steps": 4435200, "episode_reward": 0.2584737539291382, "value_loss": 0.01072296816855669, "policy_loss": -0.001220723626950182, "dist_entropy": 0.7681058764457702, "actor_grad_norm": 0.10757162421941757, "critic_grad_norm": 0.022863244637846947, "ratio": 0.9997712969779968, "entropy": 0.7681058764457702, "incre_win_rate": 0.8666666666666667, "step": 1386}
{"time": 1767337649.0045512, "phase": "train", "update": 1387, "total_env_steps": 4438400, "episode_reward": 0.25152266025543213, "value_loss": 0.009334343299269677, "policy_loss": -0.0014784587336791333, "dist_entropy": 0.7629106760025024, "actor_grad_norm": 0.09267403930425644, "critic_grad_norm": 0.025588784366846085, "ratio": 0.9999517798423767, "entropy": 0.7629106760025024, "incre_win_rate": 0.8809523809523809, "step": 1387}
{"time": 1767337653.0987163, "phase": "train", "update": 1388, "total_env_steps": 4441600, "episode_reward": 0.24525247514247894, "value_loss": 0.009124297462403775, "policy_loss": -0.0015382102369940753, "dist_entropy": 0.7790120840072632, "actor_grad_norm": 0.12328390032052994, "critic_grad_norm": 0.02684544026851654, "ratio": 1.0001370906829834, "entropy": 0.7790120840072632, "incre_win_rate": 0.85, "step": 1388}
{"time": 1767337657.2134829, "phase": "train", "update": 1389, "total_env_steps": 4444800, "episode_reward": 0.24709539115428925, "value_loss": 0.005994090996682644, "policy_loss": -0.0014244965494019546, "dist_entropy": 0.810380733013153, "actor_grad_norm": 0.09118730574846268, "critic_grad_norm": 0.02359999343752861, "ratio": 1.000459909439087, "entropy": 0.810380733013153, "incre_win_rate": 0.875, "step": 1389}
{"time": 1767337661.3192103, "phase": "train", "update": 1390, "total_env_steps": 4448000, "episode_reward": 0.2539145350456238, "value_loss": 0.006598377320915461, "policy_loss": -0.0013162776092457307, "dist_entropy": 0.7927924275398255, "actor_grad_norm": 0.09361741691827774, "critic_grad_norm": 0.028935803100466728, "ratio": 0.9998918771743774, "entropy": 0.7927924275398255, "incre_win_rate": 0.8837209302325582, "step": 1390}
{"time": 1767337665.4369478, "phase": "train", "update": 1391, "total_env_steps": 4451200, "episode_reward": 0.2623220384120941, "value_loss": 0.0050278231501579285, "policy_loss": -0.0013169516624774503, "dist_entropy": 0.8025346040725708, "actor_grad_norm": 0.10107530653476715, "critic_grad_norm": 0.03469115495681763, "ratio": 0.9998539090156555, "entropy": 0.8025346040725708, "incre_win_rate": 0.9069767441860465, "step": 1391}
{"time": 1767337669.4887211, "phase": "train", "update": 1392, "total_env_steps": 4454400, "episode_reward": 0.25456541776657104, "value_loss": 0.00505617493763566, "policy_loss": -0.0015805121425103152, "dist_entropy": 0.7875803112983704, "actor_grad_norm": 0.09738140553236008, "critic_grad_norm": 0.019409997388720512, "ratio": 1.0001721382141113, "entropy": 0.7875803112983704, "incre_win_rate": 0.925, "step": 1392}
{"time": 1767337673.5420759, "phase": "train", "update": 1393, "total_env_steps": 4457600, "episode_reward": 0.2589114308357239, "value_loss": 0.005999497417360544, "policy_loss": -0.001143570767586155, "dist_entropy": 0.7953715324401855, "actor_grad_norm": 0.08807633817195892, "critic_grad_norm": 0.04447149857878685, "ratio": 1.0001239776611328, "entropy": 0.7953715324401855, "incre_win_rate": 0.8809523809523809, "step": 1393}
{"time": 1767337677.6289158, "phase": "train", "update": 1394, "total_env_steps": 4460800, "episode_reward": 0.25083765387535095, "value_loss": 0.00774016622453928, "policy_loss": -0.001445147689795334, "dist_entropy": 0.7905717372894288, "actor_grad_norm": 0.09787150472402573, "critic_grad_norm": 0.039094846695661545, "ratio": 1.0003174543380737, "entropy": 0.7905717372894288, "incre_win_rate": 0.9069767441860465, "step": 1394}
{"time": 1767337681.7550747, "phase": "train", "update": 1395, "total_env_steps": 4464000, "episode_reward": 0.2517710030078888, "value_loss": 0.00590432183817029, "policy_loss": -0.0012171343198531305, "dist_entropy": 0.7931125521659851, "actor_grad_norm": 0.10804802179336548, "critic_grad_norm": 0.01607426255941391, "ratio": 0.9998359680175781, "entropy": 0.7931125521659851, "incre_win_rate": 0.8780487804878049, "step": 1395}
{"time": 1767337685.899894, "phase": "train", "update": 1396, "total_env_steps": 4467200, "episode_reward": 0.2642342746257782, "value_loss": 0.006488209590315819, "policy_loss": -0.0012792755444340997, "dist_entropy": 0.8107577323913574, "actor_grad_norm": 0.10380039364099503, "critic_grad_norm": 0.05632391199469566, "ratio": 0.9997591972351074, "entropy": 0.8107577323913574, "incre_win_rate": 0.9761904761904762, "step": 1396}
{"time": 1767337689.999269, "phase": "train", "update": 1397, "total_env_steps": 4470400, "episode_reward": 0.2602483332157135, "value_loss": 0.005663806758821011, "policy_loss": -0.001137099903247929, "dist_entropy": 0.7774519205093384, "actor_grad_norm": 0.08282562345266342, "critic_grad_norm": 0.025290561839938164, "ratio": 1.0003092288970947, "entropy": 0.7774519205093384, "incre_win_rate": 0.9069767441860465, "step": 1397}
{"time": 1767337694.0769713, "phase": "train", "update": 1398, "total_env_steps": 4473600, "episode_reward": 0.25948211550712585, "value_loss": 0.005500292405486107, "policy_loss": -0.0015558232326878141, "dist_entropy": 0.7773359894752503, "actor_grad_norm": 0.0805513858795166, "critic_grad_norm": 0.030497727915644646, "ratio": 1.0000139474868774, "entropy": 0.7773359894752503, "incre_win_rate": 0.8809523809523809, "step": 1398}
{"time": 1767337698.1730368, "phase": "train", "update": 1399, "total_env_steps": 4476800, "episode_reward": 0.254507452249527, "value_loss": 0.00615395288914442, "policy_loss": -0.0012304936368096263, "dist_entropy": 0.777283227443695, "actor_grad_norm": 0.09479784220457077, "critic_grad_norm": 0.02437693439424038, "ratio": 0.9999960064888, "entropy": 0.777283227443695, "incre_win_rate": 0.9285714285714286, "step": 1399}
{"time": 1767337702.2805102, "phase": "train", "update": 1400, "total_env_steps": 4480000, "episode_reward": 0.2539362609386444, "value_loss": 0.006352560035884381, "policy_loss": -0.001545024371745285, "dist_entropy": 0.7978633284568787, "actor_grad_norm": 0.0932847186923027, "critic_grad_norm": 0.037722669541835785, "ratio": 0.9997333884239197, "entropy": 0.7978633284568787, "incre_win_rate": 0.8780487804878049, "step": 1400}
{"time": 1767337706.4272668, "phase": "train", "update": 1401, "total_env_steps": 4483200, "episode_reward": 0.2520783245563507, "value_loss": 0.007944683078676462, "policy_loss": -0.0016273552358114785, "dist_entropy": 0.7767078280448914, "actor_grad_norm": 0.14580343663692474, "critic_grad_norm": 0.04812338203191757, "ratio": 1.0002315044403076, "entropy": 0.7767078280448914, "incre_win_rate": 0.8372093023255814, "step": 1401}
{"time": 1767337716.617286, "phase": "eval", "update": 1401, "total_env_steps": 4483200, "eval_win_rate": 1.0, "eval_episode_reward": 20.0, "step": 1401}
{"time": 1767337720.707902, "phase": "train", "update": 1402, "total_env_steps": 4486400, "episode_reward": 0.26342716813087463, "value_loss": 0.006851924117654562, "policy_loss": -0.0009967009032411766, "dist_entropy": 0.7744409680366516, "actor_grad_norm": 0.08994103968143463, "critic_grad_norm": 0.054558731615543365, "ratio": 0.9999884963035583, "entropy": 0.7744409680366516, "incre_win_rate": 0.9285714285714286, "step": 1402}
{"time": 1767337724.7956111, "phase": "train", "update": 1403, "total_env_steps": 4489600, "episode_reward": 0.24975012242794037, "value_loss": 0.009967325814068317, "policy_loss": -0.0012841076474838786, "dist_entropy": 0.7713267803192139, "actor_grad_norm": 0.106356181204319, "critic_grad_norm": 0.05375748872756958, "ratio": 0.9999446272850037, "entropy": 0.7713267803192139, "incre_win_rate": 0.8604651162790697, "step": 1403}
{"time": 1767337728.881641, "phase": "train", "update": 1404, "total_env_steps": 4492800, "episode_reward": 0.25144970417022705, "value_loss": 0.0075651672668755054, "policy_loss": -0.0015479959120597187, "dist_entropy": 0.7791787147521972, "actor_grad_norm": 0.11969353258609772, "critic_grad_norm": 0.04652785882353783, "ratio": 0.9998266100883484, "entropy": 0.7791787147521972, "incre_win_rate": 0.8837209302325582, "step": 1404}
{"time": 1767337732.9235864, "phase": "train", "update": 1405, "total_env_steps": 4496000, "episode_reward": 0.2502804100513458, "value_loss": 0.007158403843641281, "policy_loss": -0.0008246666688052073, "dist_entropy": 0.7868839383125306, "actor_grad_norm": 0.08216790854930878, "critic_grad_norm": 0.04090172052383423, "ratio": 1.0001293420791626, "entropy": 0.7868839383125306, "incre_win_rate": 0.8205128205128205, "step": 1405}
{"time": 1767337737.0146613, "phase": "train", "update": 1406, "total_env_steps": 4499200, "episode_reward": 0.24253104627132416, "value_loss": 0.010992954671382903, "policy_loss": -0.0014935155128071643, "dist_entropy": 0.7571717977523804, "actor_grad_norm": 0.11724168062210083, "critic_grad_norm": 0.04721099138259888, "ratio": 0.9999231696128845, "entropy": 0.7571717977523804, "incre_win_rate": 0.7441860465116279, "step": 1406}
{"time": 1767337741.068257, "phase": "train", "update": 1407, "total_env_steps": 4502400, "episode_reward": 0.259072870016098, "value_loss": 0.006026084907352925, "policy_loss": -0.0010152646786586671, "dist_entropy": 0.7678834795951843, "actor_grad_norm": 0.07622773200273514, "critic_grad_norm": 0.03751757740974426, "ratio": 1.0001462697982788, "entropy": 0.7678834795951843, "incre_win_rate": 0.926829268292683, "step": 1407}
{"time": 1767337745.192946, "phase": "train", "update": 1408, "total_env_steps": 4505600, "episode_reward": 0.25939154624938965, "value_loss": 0.00579273821786046, "policy_loss": -0.0011794694357206482, "dist_entropy": 0.7652806639671326, "actor_grad_norm": 0.10343537479639053, "critic_grad_norm": 0.039196524769067764, "ratio": 0.9999021887779236, "entropy": 0.7652806639671326, "incre_win_rate": 0.9285714285714286, "step": 1408}
{"time": 1767337749.2766817, "phase": "train", "update": 1409, "total_env_steps": 4508800, "episode_reward": 0.25624120235443115, "value_loss": 0.005759831424802542, "policy_loss": -0.0011933654153239103, "dist_entropy": 0.7626210212707519, "actor_grad_norm": 0.11629146337509155, "critic_grad_norm": 0.034401748329401016, "ratio": 1.0006377696990967, "entropy": 0.7626210212707519, "incre_win_rate": 0.8863636363636364, "step": 1409}
{"time": 1767337753.406443, "phase": "train", "update": 1410, "total_env_steps": 4512000, "episode_reward": 0.24687500298023224, "value_loss": 0.007968709152191878, "policy_loss": -0.0016171308796465666, "dist_entropy": 0.7448090791702271, "actor_grad_norm": 0.12660439312458038, "critic_grad_norm": 0.05966266617178917, "ratio": 1.0002011060714722, "entropy": 0.7448090791702271, "incre_win_rate": 0.825, "step": 1410}
{"time": 1767337757.495529, "phase": "train", "update": 1411, "total_env_steps": 4515200, "episode_reward": 0.26222267746925354, "value_loss": 0.004921661131083966, "policy_loss": -0.0009258032017790185, "dist_entropy": 0.7533373355865478, "actor_grad_norm": 0.14746759831905365, "critic_grad_norm": 0.06199006363749504, "ratio": 0.9998611807823181, "entropy": 0.7533373355865478, "incre_win_rate": 0.9761904761904762, "step": 1411}
{"time": 1767337761.6210098, "phase": "train", "update": 1412, "total_env_steps": 4518400, "episode_reward": 0.2668708562850952, "value_loss": 0.004375538881868124, "policy_loss": -0.001258300638571086, "dist_entropy": 0.7645476460456848, "actor_grad_norm": 0.09604093432426453, "critic_grad_norm": 0.053646039217710495, "ratio": 1.000054955482483, "entropy": 0.7645476460456848, "incre_win_rate": 0.9545454545454546, "step": 1412}
{"time": 1767337765.7172453, "phase": "train", "update": 1413, "total_env_steps": 4521600, "episode_reward": 0.2604263424873352, "value_loss": 0.003927011694759131, "policy_loss": -0.0013519102818037253, "dist_entropy": 0.7490013241767883, "actor_grad_norm": 0.09942277520895004, "critic_grad_norm": 0.043219346553087234, "ratio": 1.000308632850647, "entropy": 0.7490013241767883, "incre_win_rate": 0.9761904761904762, "step": 1413}
{"time": 1767337769.8174841, "phase": "train", "update": 1414, "total_env_steps": 4524800, "episode_reward": 0.2593853771686554, "value_loss": 0.005022759642452001, "policy_loss": -0.0012888575174116567, "dist_entropy": 0.7551024913787842, "actor_grad_norm": 0.0943913385272026, "critic_grad_norm": 0.02292686700820923, "ratio": 1.0000132322311401, "entropy": 0.7551024913787842, "incre_win_rate": 0.926829268292683, "step": 1414}
{"time": 1767337773.8856215, "phase": "train", "update": 1415, "total_env_steps": 4528000, "episode_reward": 0.26301220059394836, "value_loss": 0.003939097141847014, "policy_loss": -0.0009436840072821085, "dist_entropy": 0.7567158937454224, "actor_grad_norm": 0.10156714916229248, "critic_grad_norm": 0.0527338944375515, "ratio": 0.9999813437461853, "entropy": 0.7567158937454224, "incre_win_rate": 0.9534883720930233, "step": 1415}
{"time": 1767337778.0171614, "phase": "train", "update": 1416, "total_env_steps": 4531200, "episode_reward": 0.25856631994247437, "value_loss": 0.004069982003420592, "policy_loss": -0.0011587624882565706, "dist_entropy": 0.7460864067077637, "actor_grad_norm": 0.1104658842086792, "critic_grad_norm": 0.04356004297733307, "ratio": 1.0000221729278564, "entropy": 0.7460864067077637, "incre_win_rate": 0.9512195121951219, "step": 1416}
{"time": 1767337782.085217, "phase": "train", "update": 1417, "total_env_steps": 4534400, "episode_reward": 0.2616349458694458, "value_loss": 0.0049083871766924855, "policy_loss": -0.0012889637161213941, "dist_entropy": 0.7414949774742127, "actor_grad_norm": 0.0975029468536377, "critic_grad_norm": 0.04779471084475517, "ratio": 1.0004297494888306, "entropy": 0.7414949774742127, "incre_win_rate": 0.9318181818181818, "step": 1417}
{"time": 1767337786.1915312, "phase": "train", "update": 1418, "total_env_steps": 4537600, "episode_reward": 0.25726407766342163, "value_loss": 0.008415746875107289, "policy_loss": -0.00132552860749513, "dist_entropy": 0.7235387325286865, "actor_grad_norm": 0.09818713366985321, "critic_grad_norm": 0.04002896323800087, "ratio": 0.9998554587364197, "entropy": 0.7235387325286865, "incre_win_rate": 0.8604651162790697, "step": 1418}
{"time": 1767337790.2672048, "phase": "train", "update": 1419, "total_env_steps": 4540800, "episode_reward": 0.26614293456077576, "value_loss": 0.004966460354626179, "policy_loss": -0.0011639935108981093, "dist_entropy": 0.7369669675827026, "actor_grad_norm": 0.09105473756790161, "critic_grad_norm": 0.031936753541231155, "ratio": 0.9997881054878235, "entropy": 0.7369669675827026, "incre_win_rate": 0.9523809523809523, "step": 1419}
{"time": 1767337794.3128195, "phase": "train", "update": 1420, "total_env_steps": 4544000, "episode_reward": 0.261771023273468, "value_loss": 0.005616533849388361, "policy_loss": -0.0011512218214337455, "dist_entropy": 0.729377555847168, "actor_grad_norm": 0.09907195717096329, "critic_grad_norm": 0.022531190887093544, "ratio": 0.999809205532074, "entropy": 0.729377555847168, "incre_win_rate": 0.9318181818181818, "step": 1420}
{"time": 1767337798.4148388, "phase": "train", "update": 1421, "total_env_steps": 4547200, "episode_reward": 0.25632864236831665, "value_loss": 0.006362536363303662, "policy_loss": -0.001180955772126424, "dist_entropy": 0.7314859986305237, "actor_grad_norm": 0.09593439847230911, "critic_grad_norm": 0.023794258013367653, "ratio": 0.9998507499694824, "entropy": 0.7314859986305237, "incre_win_rate": 0.9047619047619048, "step": 1421}
{"time": 1767337802.4642105, "phase": "train", "update": 1422, "total_env_steps": 4550400, "episode_reward": 0.2587127387523651, "value_loss": 0.006598948594182729, "policy_loss": -0.0009524150917911811, "dist_entropy": 0.7167925834655762, "actor_grad_norm": 0.09294097870588303, "critic_grad_norm": 0.017613762989640236, "ratio": 1.000134825706482, "entropy": 0.7167925834655762, "incre_win_rate": 0.926829268292683, "step": 1422}
{"time": 1767337806.7622352, "phase": "train", "update": 1423, "total_env_steps": 4553600, "episode_reward": 0.2656787931919098, "value_loss": 0.0038948166649788616, "policy_loss": -0.0011502730757527503, "dist_entropy": 0.7426603555679321, "actor_grad_norm": 0.10195779800415039, "critic_grad_norm": 0.03486400842666626, "ratio": 0.9998669028282166, "entropy": 0.7426603555679321, "incre_win_rate": 0.9545454545454546, "step": 1423}
{"time": 1767337810.8196254, "phase": "train", "update": 1424, "total_env_steps": 4556800, "episode_reward": 0.2522904574871063, "value_loss": 0.005879089701920748, "policy_loss": -0.0013285206493584667, "dist_entropy": 0.7341989994049072, "actor_grad_norm": 0.1040230542421341, "critic_grad_norm": 0.054382920265197754, "ratio": 0.9997603297233582, "entropy": 0.7341989994049072, "incre_win_rate": 0.8604651162790697, "step": 1424}
{"time": 1767337814.8398771, "phase": "train", "update": 1425, "total_env_steps": 4560000, "episode_reward": 0.2508407533168793, "value_loss": 0.009012066572904587, "policy_loss": -0.0009874431669008032, "dist_entropy": 0.7384154319763183, "actor_grad_norm": 0.09184303134679794, "critic_grad_norm": 0.035890739411115646, "ratio": 0.999914824962616, "entropy": 0.7384154319763183, "incre_win_rate": 0.875, "step": 1425}
{"time": 1767337818.9218917, "phase": "train", "update": 1426, "total_env_steps": 4563200, "episode_reward": 0.2698882520198822, "value_loss": 0.005024143401533366, "policy_loss": -0.0013083581068348948, "dist_entropy": 0.7428664565086365, "actor_grad_norm": 0.10707669705152512, "critic_grad_norm": 0.04799587279558182, "ratio": 1.0005295276641846, "entropy": 0.7428664565086365, "incre_win_rate": 0.9555555555555556, "step": 1426}
{"time": 1767337828.6662078, "phase": "eval", "update": 1426, "total_env_steps": 4563200, "eval_win_rate": 1.0, "eval_episode_reward": 20.0, "step": 1426}
{"time": 1767337832.735877, "phase": "train", "update": 1427, "total_env_steps": 4566400, "episode_reward": 0.262623131275177, "value_loss": 0.004473998304456472, "policy_loss": -0.0015724158073751938, "dist_entropy": 0.7500493168830872, "actor_grad_norm": 0.1060202345252037, "critic_grad_norm": 0.022404242306947708, "ratio": 0.9996986389160156, "entropy": 0.7500493168830872, "incre_win_rate": 0.9047619047619048, "step": 1427}
{"time": 1767337836.8576703, "phase": "train", "update": 1428, "total_env_steps": 4569600, "episode_reward": 0.26107046008110046, "value_loss": 0.005421457253396511, "policy_loss": -0.0010295815526220053, "dist_entropy": 0.7572676181793213, "actor_grad_norm": 0.09408970177173615, "critic_grad_norm": 0.03596958890557289, "ratio": 1.0000946521759033, "entropy": 0.7572676181793213, "incre_win_rate": 0.926829268292683, "step": 1428}
{"time": 1767337840.9799416, "phase": "train", "update": 1429, "total_env_steps": 4572800, "episode_reward": 0.26477131247520447, "value_loss": 0.005321631114929915, "policy_loss": -0.0009408456429355283, "dist_entropy": 0.7548303246498108, "actor_grad_norm": 0.10355210304260254, "critic_grad_norm": 0.023806964978575706, "ratio": 0.9998354315757751, "entropy": 0.7548303246498108, "incre_win_rate": 0.9565217391304348, "step": 1429}
{"time": 1767337845.0463011, "phase": "train", "update": 1430, "total_env_steps": 4576000, "episode_reward": 0.25925910472869873, "value_loss": 0.008205178938806058, "policy_loss": -0.0011803453802677667, "dist_entropy": 0.7554543137550354, "actor_grad_norm": 0.10398703068494797, "critic_grad_norm": 0.018530255183577538, "ratio": 1.0003856420516968, "entropy": 0.7554543137550354, "incre_win_rate": 0.8780487804878049, "step": 1430}
{"time": 1767337849.1445704, "phase": "train", "update": 1431, "total_env_steps": 4579200, "episode_reward": 0.2644991874694824, "value_loss": 0.006297757104039192, "policy_loss": -0.0013332647518275564, "dist_entropy": 0.7546497344970703, "actor_grad_norm": 0.09693878144025803, "critic_grad_norm": 0.01882755570113659, "ratio": 1.0003703832626343, "entropy": 0.7546497344970703, "incre_win_rate": 0.9534883720930233, "step": 1431}
{"time": 1767337853.2487013, "phase": "train", "update": 1432, "total_env_steps": 4582400, "episode_reward": 0.2697433829307556, "value_loss": 0.0036059945356100797, "policy_loss": -0.0015718595974332672, "dist_entropy": 0.7607687950134278, "actor_grad_norm": 0.1334141343832016, "critic_grad_norm": 0.03235480561852455, "ratio": 0.9996352195739746, "entropy": 0.7607687950134278, "incre_win_rate": 0.9767441860465116, "step": 1432}
{"time": 1767337857.4088047, "phase": "train", "update": 1433, "total_env_steps": 4585600, "episode_reward": 0.2689988613128662, "value_loss": 0.005236464459449053, "policy_loss": -0.0008843683263330959, "dist_entropy": 0.7502399563789368, "actor_grad_norm": 0.1032257005572319, "critic_grad_norm": 0.02767826057970524, "ratio": 0.9998289346694946, "entropy": 0.7502399563789368, "incre_win_rate": 0.9333333333333333, "step": 1433}
{"time": 1767337861.5412087, "phase": "train", "update": 1434, "total_env_steps": 4588800, "episode_reward": 0.26340800523757935, "value_loss": 0.00500805089250207, "policy_loss": -0.0008949439907560474, "dist_entropy": 0.7465567827224732, "actor_grad_norm": 0.10003715008497238, "critic_grad_norm": 0.029391905292868614, "ratio": 0.9997744560241699, "entropy": 0.7465567827224732, "incre_win_rate": 0.9024390243902439, "step": 1434}
{"time": 1767337865.627573, "phase": "train", "update": 1435, "total_env_steps": 4592000, "episode_reward": 0.2536434233188629, "value_loss": 0.006129578873515129, "policy_loss": -0.0015831460692695032, "dist_entropy": 0.7534316182136536, "actor_grad_norm": 0.09426268190145493, "critic_grad_norm": 0.0568634532392025, "ratio": 1.000105857849121, "entropy": 0.7534316182136536, "incre_win_rate": 0.8837209302325582, "step": 1435}
{"time": 1767337869.7524374, "phase": "train", "update": 1436, "total_env_steps": 4595200, "episode_reward": 0.26917633414268494, "value_loss": 0.003426655242219567, "policy_loss": -0.0012999133991471012, "dist_entropy": 0.7574769258499146, "actor_grad_norm": 0.11919760704040527, "critic_grad_norm": 0.04146478697657585, "ratio": 0.999599277973175, "entropy": 0.7574769258499146, "incre_win_rate": 0.9772727272727273, "step": 1436}
{"time": 1767337873.8571389, "phase": "train", "update": 1437, "total_env_steps": 4598400, "episode_reward": 0.2630298137664795, "value_loss": 0.004755136277526617, "policy_loss": -0.0012771314060877614, "dist_entropy": 0.7617477059364319, "actor_grad_norm": 0.09965819865465164, "critic_grad_norm": 0.040421728044748306, "ratio": 0.9999478459358215, "entropy": 0.7617477059364319, "incre_win_rate": 1.0, "step": 1437}
{"time": 1767337877.9774692, "phase": "train", "update": 1438, "total_env_steps": 4601600, "episode_reward": 0.2595033347606659, "value_loss": 0.005830708425492048, "policy_loss": -0.0014159859998642333, "dist_entropy": 0.780137574672699, "actor_grad_norm": 0.08981180191040039, "critic_grad_norm": 0.03769459202885628, "ratio": 0.9996431469917297, "entropy": 0.780137574672699, "incre_win_rate": 0.9024390243902439, "step": 1438}
{"time": 1767337882.0835028, "phase": "train", "update": 1439, "total_env_steps": 4604800, "episode_reward": 0.25982409715652466, "value_loss": 0.0065071254037320616, "policy_loss": -0.0014212030548724109, "dist_entropy": 0.7755179405212402, "actor_grad_norm": 0.116111159324646, "critic_grad_norm": 0.0563172772526741, "ratio": 1.0001863241195679, "entropy": 0.7755179405212402, "incre_win_rate": 0.9024390243902439, "step": 1439}
{"time": 1767337886.1863902, "phase": "train", "update": 1440, "total_env_steps": 4608000, "episode_reward": 0.25836607813835144, "value_loss": 0.007245681714266539, "policy_loss": -0.001723197044373137, "dist_entropy": 0.7811781406402588, "actor_grad_norm": 0.11108163744211197, "critic_grad_norm": 0.062137503176927567, "ratio": 0.9998359084129333, "entropy": 0.7811781406402588, "incre_win_rate": 0.9318181818181818, "step": 1440}
{"time": 1767337890.270169, "phase": "train", "update": 1441, "total_env_steps": 4611200, "episode_reward": 0.2580562233924866, "value_loss": 0.008521589823067189, "policy_loss": -0.0011088731461949663, "dist_entropy": 0.7817499876022339, "actor_grad_norm": 0.11279052495956421, "critic_grad_norm": 0.03903856500983238, "ratio": 0.9997663497924805, "entropy": 0.7817499876022339, "incre_win_rate": 0.9523809523809523, "step": 1441}
{"time": 1767337894.4010992, "phase": "train", "update": 1442, "total_env_steps": 4614400, "episode_reward": 0.250205397605896, "value_loss": 0.006196771934628487, "policy_loss": -0.0014631045226501272, "dist_entropy": 0.7721037983894348, "actor_grad_norm": 0.12675772607326508, "critic_grad_norm": 0.03980642184615135, "ratio": 0.9997936487197876, "entropy": 0.7721037983894348, "incre_win_rate": 0.8571428571428571, "step": 1442}
{"time": 1767337898.552216, "phase": "train", "update": 1443, "total_env_steps": 4617600, "episode_reward": 0.2697475254535675, "value_loss": 0.003055818285793066, "policy_loss": -0.0015139026008924362, "dist_entropy": 0.8260496735572815, "actor_grad_norm": 0.11481942981481552, "critic_grad_norm": 0.06097278743982315, "ratio": 1.000223159790039, "entropy": 0.8260496735572815, "incre_win_rate": 1.0, "step": 1443}
{"time": 1767337902.6680741, "phase": "train", "update": 1444, "total_env_steps": 4620800, "episode_reward": 0.26004138588905334, "value_loss": 0.005040947161614895, "policy_loss": -0.0013752834817406523, "dist_entropy": 0.7966980934143066, "actor_grad_norm": 0.10136119276285172, "critic_grad_norm": 0.038397565484046936, "ratio": 1.0000423192977905, "entropy": 0.7966980934143066, "incre_win_rate": 0.8974358974358975, "step": 1444}
{"time": 1767337906.798954, "phase": "train", "update": 1445, "total_env_steps": 4624000, "episode_reward": 0.26327812671661377, "value_loss": 0.0046060214750468734, "policy_loss": -0.0010628093982816722, "dist_entropy": 0.8141626119613647, "actor_grad_norm": 0.09263920783996582, "critic_grad_norm": 0.03445803374052048, "ratio": 0.9997450113296509, "entropy": 0.8141626119613647, "incre_win_rate": 0.9545454545454546, "step": 1445}
{"time": 1767337910.870027, "phase": "train", "update": 1446, "total_env_steps": 4627200, "episode_reward": 0.25489291548728943, "value_loss": 0.007361689023673535, "policy_loss": -0.0009567230196225295, "dist_entropy": 0.7934212565422059, "actor_grad_norm": 0.08429576456546783, "critic_grad_norm": 0.06864750385284424, "ratio": 0.9995861053466797, "entropy": 0.7934212565422059, "incre_win_rate": 0.8604651162790697, "step": 1446}
{"time": 1767337914.9542813, "phase": "train", "update": 1447, "total_env_steps": 4630400, "episode_reward": 0.26346853375434875, "value_loss": 0.005460389424115419, "policy_loss": -0.0013615506318778614, "dist_entropy": 0.8198049902915955, "actor_grad_norm": 0.08591645210981369, "critic_grad_norm": 0.053575851023197174, "ratio": 0.9998525977134705, "entropy": 0.8198049902915955, "incre_win_rate": 0.8837209302325582, "step": 1447}
{"time": 1767337919.0791414, "phase": "train", "update": 1448, "total_env_steps": 4633600, "episode_reward": 0.2578812837600708, "value_loss": 0.006466474663466215, "policy_loss": -0.0012163372516859282, "dist_entropy": 0.797160804271698, "actor_grad_norm": 0.09701833128929138, "critic_grad_norm": 0.03070840612053871, "ratio": 1.0000067949295044, "entropy": 0.797160804271698, "incre_win_rate": 0.9047619047619048, "step": 1448}
{"time": 1767337923.1818306, "phase": "train", "update": 1449, "total_env_steps": 4636800, "episode_reward": 0.25567829608917236, "value_loss": 0.007143055088818073, "policy_loss": -0.0014080208617279766, "dist_entropy": 0.7916505455970764, "actor_grad_norm": 0.11220667511224747, "critic_grad_norm": 0.02444985881447792, "ratio": 0.9998311996459961, "entropy": 0.7916505455970764, "incre_win_rate": 0.8837209302325582, "step": 1449}
{"time": 1767337927.2644846, "phase": "train", "update": 1450, "total_env_steps": 4640000, "episode_reward": 0.2638038098812103, "value_loss": 0.006408349610865116, "policy_loss": -0.0012333089193036883, "dist_entropy": 0.7954207301139832, "actor_grad_norm": 0.11473081260919571, "critic_grad_norm": 0.0385931096971035, "ratio": 0.9997755289077759, "entropy": 0.7954207301139832, "incre_win_rate": 0.9523809523809523, "step": 1450}
{"time": 1767337931.3676636, "phase": "train", "update": 1451, "total_env_steps": 4643200, "episode_reward": 0.26669391989707947, "value_loss": 0.0035840604919940232, "policy_loss": -0.0012069082935099117, "dist_entropy": 0.7842807054519654, "actor_grad_norm": 0.09938236325979233, "critic_grad_norm": 0.01486169546842575, "ratio": 1.0002508163452148, "entropy": 0.7842807054519654, "incre_win_rate": 0.9333333333333333, "step": 1451}
{"time": 1767337940.8871627, "phase": "eval", "update": 1451, "total_env_steps": 4643200, "eval_win_rate": 1.0, "eval_episode_reward": 20.001655629139073, "step": 1451}
{"time": 1767337944.9483879, "phase": "train", "update": 1452, "total_env_steps": 4646400, "episode_reward": 0.2685699462890625, "value_loss": 0.005044626910239458, "policy_loss": -0.0009838077211696827, "dist_entropy": 0.77120121717453, "actor_grad_norm": 0.09486424177885056, "critic_grad_norm": 0.011764885857701302, "ratio": 1.0000202655792236, "entropy": 0.77120121717453, "incre_win_rate": 0.9523809523809523, "step": 1452}
{"time": 1767337949.0333884, "phase": "train", "update": 1453, "total_env_steps": 4649600, "episode_reward": 0.2636733949184418, "value_loss": 0.006179238576442004, "policy_loss": -0.0008354183904344837, "dist_entropy": 0.7690456986427308, "actor_grad_norm": 0.08051445335149765, "critic_grad_norm": 0.016120541840791702, "ratio": 0.999779999256134, "entropy": 0.7690456986427308, "incre_win_rate": 0.9069767441860465, "step": 1453}
{"time": 1767337953.0787323, "phase": "train", "update": 1454, "total_env_steps": 4652800, "episode_reward": 0.24888762831687927, "value_loss": 0.00813207533210516, "policy_loss": -0.001633874753393627, "dist_entropy": 0.7579539895057679, "actor_grad_norm": 0.10772986710071564, "critic_grad_norm": 0.015743352472782135, "ratio": 0.999971330165863, "entropy": 0.7579539895057679, "incre_win_rate": 0.9069767441860465, "step": 1454}
{"time": 1767337957.1297998, "phase": "train", "update": 1455, "total_env_steps": 4656000, "episode_reward": 0.25725114345550537, "value_loss": 0.006043605692684651, "policy_loss": -0.0010890098026735018, "dist_entropy": 0.7667002320289612, "actor_grad_norm": 0.10113426297903061, "critic_grad_norm": 0.014757058583199978, "ratio": 0.9995203018188477, "entropy": 0.7667002320289612, "incre_win_rate": 0.8780487804878049, "step": 1455}
{"time": 1767337961.206699, "phase": "train", "update": 1456, "total_env_steps": 4659200, "episode_reward": 0.27329057455062866, "value_loss": 0.0029516845010221005, "policy_loss": -0.0009290904460655724, "dist_entropy": 0.7742265939712525, "actor_grad_norm": 0.09599649161100388, "critic_grad_norm": 0.05761898681521416, "ratio": 1.0001076459884644, "entropy": 0.7742265939712525, "incre_win_rate": 1.0, "step": 1456}
{"time": 1767337965.297698, "phase": "train", "update": 1457, "total_env_steps": 4662400, "episode_reward": 0.268133282661438, "value_loss": 0.0036498384084552526, "policy_loss": -0.0012058798265975668, "dist_entropy": 0.7746370434761047, "actor_grad_norm": 0.08757894486188889, "critic_grad_norm": 0.03203817829489708, "ratio": 1.0000252723693848, "entropy": 0.7746370434761047, "incre_win_rate": 0.9772727272727273, "step": 1457}
{"time": 1767337969.3839283, "phase": "train", "update": 1458, "total_env_steps": 4665600, "episode_reward": 0.26207107305526733, "value_loss": 0.005559167545288801, "policy_loss": -0.0012190534770521566, "dist_entropy": 0.7728044748306274, "actor_grad_norm": 0.09468790143728256, "critic_grad_norm": 0.03908763453364372, "ratio": 1.0003514289855957, "entropy": 0.7728044748306274, "incre_win_rate": 0.8837209302325582, "step": 1458}
{"time": 1767337973.4852881, "phase": "train", "update": 1459, "total_env_steps": 4668800, "episode_reward": 0.2676950693130493, "value_loss": 0.005057019367814064, "policy_loss": -0.000973065220704683, "dist_entropy": 0.7777383208274842, "actor_grad_norm": 0.08124929666519165, "critic_grad_norm": 0.0408407561480999, "ratio": 0.9995986223220825, "entropy": 0.7777383208274842, "incre_win_rate": 0.9285714285714286, "step": 1459}
{"time": 1767337977.6038768, "phase": "train", "update": 1460, "total_env_steps": 4672000, "episode_reward": 0.2618129253387451, "value_loss": 0.007100595347583294, "policy_loss": -0.0015559984948069427, "dist_entropy": 0.774233877658844, "actor_grad_norm": 0.10435731709003448, "critic_grad_norm": 0.049520161002874374, "ratio": 0.9995046854019165, "entropy": 0.774233877658844, "incre_win_rate": 0.8888888888888888, "step": 1460}
{"time": 1767337981.6920242, "phase": "train", "update": 1461, "total_env_steps": 4675200, "episode_reward": 0.27064982056617737, "value_loss": 0.0052413782104849815, "policy_loss": -0.0008044704354780663, "dist_entropy": 0.7797817826271057, "actor_grad_norm": 0.08755695074796677, "critic_grad_norm": 0.060831040143966675, "ratio": 0.9993728995323181, "entropy": 0.7797817826271057, "incre_win_rate": 0.9761904761904762, "step": 1461}
{"time": 1767337985.7692566, "phase": "train", "update": 1462, "total_env_steps": 4678400, "episode_reward": 0.26161423325538635, "value_loss": 0.006373690720647573, "policy_loss": -0.0010079510454222174, "dist_entropy": 0.77491694688797, "actor_grad_norm": 0.11419433355331421, "critic_grad_norm": 0.048014476895332336, "ratio": 1.0001002550125122, "entropy": 0.77491694688797, "incre_win_rate": 0.9545454545454546, "step": 1462}
{"time": 1767337989.8798494, "phase": "train", "update": 1463, "total_env_steps": 4681600, "episode_reward": 0.2609313130378723, "value_loss": 0.007250087708234787, "policy_loss": -0.0010012183562963628, "dist_entropy": 0.7691758632659912, "actor_grad_norm": 0.09825742244720459, "critic_grad_norm": 0.05217183753848076, "ratio": 0.999872624874115, "entropy": 0.7691758632659912, "incre_win_rate": 0.8863636363636364, "step": 1463}
{"time": 1767337993.9549937, "phase": "train", "update": 1464, "total_env_steps": 4684800, "episode_reward": 0.25906044244766235, "value_loss": 0.006348629202693701, "policy_loss": -0.0008351135390203268, "dist_entropy": 0.7665748238563538, "actor_grad_norm": 0.0879426822066307, "critic_grad_norm": 0.03876909241080284, "ratio": 0.9999160766601562, "entropy": 0.7665748238563538, "incre_win_rate": 0.9024390243902439, "step": 1464}
{"time": 1767337998.0554743, "phase": "train", "update": 1465, "total_env_steps": 4688000, "episode_reward": 0.26167941093444824, "value_loss": 0.005589265469461679, "policy_loss": -0.0011757066941669337, "dist_entropy": 0.7792868137359619, "actor_grad_norm": 0.07916561514139175, "critic_grad_norm": 0.06379133462905884, "ratio": 0.9998189806938171, "entropy": 0.7792868137359619, "incre_win_rate": 0.8837209302325582, "step": 1465}
{"time": 1767338002.1441953, "phase": "train", "update": 1466, "total_env_steps": 4691200, "episode_reward": 0.27881932258605957, "value_loss": 0.0031077171210199595, "policy_loss": -0.0014738193406500955, "dist_entropy": 0.7988155126571655, "actor_grad_norm": 0.10359565168619156, "critic_grad_norm": 0.04534311220049858, "ratio": 0.9999023675918579, "entropy": 0.7988155126571655, "incre_win_rate": 0.9767441860465116, "step": 1466}
{"time": 1767338006.2029448, "phase": "train", "update": 1467, "total_env_steps": 4694400, "episode_reward": 0.2564367949962616, "value_loss": 0.007982633262872695, "policy_loss": -0.0011796289721345942, "dist_entropy": 0.7947734951972961, "actor_grad_norm": 0.08789809793233871, "critic_grad_norm": 0.05394367128610611, "ratio": 1.0000216960906982, "entropy": 0.7947734951972961, "incre_win_rate": 0.8444444444444444, "step": 1467}
{"time": 1767338010.3263857, "phase": "train", "update": 1468, "total_env_steps": 4697600, "episode_reward": 0.27085888385772705, "value_loss": 0.00511739831417799, "policy_loss": -0.0017769682021210541, "dist_entropy": 0.8038980841636658, "actor_grad_norm": 0.10312896966934204, "critic_grad_norm": 0.07605207711458206, "ratio": 0.9998701214790344, "entropy": 0.8038980841636658, "incre_win_rate": 0.9534883720930233, "step": 1468}
{"time": 1767338014.406269, "phase": "train", "update": 1469, "total_env_steps": 4700800, "episode_reward": 0.2580106556415558, "value_loss": 0.008725282177329064, "policy_loss": -0.0013904938788691368, "dist_entropy": 0.8004820585250855, "actor_grad_norm": 0.07982179522514343, "critic_grad_norm": 0.0831245705485344, "ratio": 1.0000736713409424, "entropy": 0.8004820585250855, "incre_win_rate": 0.9090909090909091, "step": 1469}
{"time": 1767338018.532013, "phase": "train", "update": 1470, "total_env_steps": 4704000, "episode_reward": 0.26077502965927124, "value_loss": 0.008960109762847423, "policy_loss": -0.0012380597072354504, "dist_entropy": 0.7751848816871643, "actor_grad_norm": 0.08709631115198135, "critic_grad_norm": 0.06805957853794098, "ratio": 1.00039803981781, "entropy": 0.7751848816871643, "incre_win_rate": 0.9285714285714286, "step": 1470}
{"time": 1767338047.1222813, "phase": "train", "update": 1471, "total_env_steps": 4707200, "episode_reward": 0.23505742847919464, "value_loss": 0.06932558864355087, "policy_loss": -0.001459276653582009, "dist_entropy": 0.7825783014297485, "actor_grad_norm": 0.13287346065044403, "critic_grad_norm": 0.22803449630737305, "ratio": 1.0000861883163452, "entropy": 0.7825783014297485, "incre_win_rate": 0.6216216216216216, "step": 1471}
{"time": 1767338051.2752411, "phase": "train", "update": 1472, "total_env_steps": 4710400, "episode_reward": 0.2638203799724579, "value_loss": 0.006437033601105213, "policy_loss": -0.0009366242616252407, "dist_entropy": 0.7914001941680908, "actor_grad_norm": 0.09870444983243942, "critic_grad_norm": 0.09897255152463913, "ratio": 0.9997140765190125, "entropy": 0.7914001941680908, "incre_win_rate": 0.9130434782608695, "step": 1472}
{"time": 1767338055.3984475, "phase": "train", "update": 1473, "total_env_steps": 4713600, "episode_reward": 0.26394814252853394, "value_loss": 0.006205023173242808, "policy_loss": -0.0010950597359716597, "dist_entropy": 0.7749511957168579, "actor_grad_norm": 0.09147530049085617, "critic_grad_norm": 0.08743163198232651, "ratio": 0.9999533891677856, "entropy": 0.7749511957168579, "incre_win_rate": 0.9047619047619048, "step": 1473}
{"time": 1767338059.5448186, "phase": "train", "update": 1474, "total_env_steps": 4716800, "episode_reward": 0.2649456858634949, "value_loss": 0.0038469970226287843, "policy_loss": -0.0015392708985388025, "dist_entropy": 0.7935863494873047, "actor_grad_norm": 0.10812532901763916, "critic_grad_norm": 0.02202913910150528, "ratio": 1.0000050067901611, "entropy": 0.7935863494873047, "incre_win_rate": 0.9534883720930233, "step": 1474}
{"time": 1767338064.1111436, "phase": "train", "update": 1475, "total_env_steps": 4720000, "episode_reward": 0.2672971785068512, "value_loss": 0.0031138857826590537, "policy_loss": -0.0012878012525838756, "dist_entropy": 0.7929039120674133, "actor_grad_norm": 0.0978245660662651, "critic_grad_norm": 0.038003675639629364, "ratio": 1.0001250505447388, "entropy": 0.7929039120674133, "incre_win_rate": 0.9767441860465116, "step": 1475}
{"time": 1767338068.2925603, "phase": "train", "update": 1476, "total_env_steps": 4723200, "episode_reward": 0.25925081968307495, "value_loss": 0.004068091418594122, "policy_loss": -0.001202642039030266, "dist_entropy": 0.8029008269309997, "actor_grad_norm": 0.09306780248880386, "critic_grad_norm": 0.04402395337820053, "ratio": 1.000404715538025, "entropy": 0.8029008269309997, "incre_win_rate": 0.9302325581395349, "step": 1476}
{"time": 1767338078.222504, "phase": "eval", "update": 1476, "total_env_steps": 4723200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.415976821192054, "step": 1476}
{"time": 1767338082.3578637, "phase": "train", "update": 1477, "total_env_steps": 4726400, "episode_reward": 0.2573670446872711, "value_loss": 0.005945878941565752, "policy_loss": -0.0014169948099571172, "dist_entropy": 0.7758189558982849, "actor_grad_norm": 0.10981869697570801, "critic_grad_norm": 0.024014299735426903, "ratio": 0.9997801184654236, "entropy": 0.7758189558982849, "incre_win_rate": 0.9024390243902439, "step": 1477}
{"time": 1767338086.4655576, "phase": "train", "update": 1478, "total_env_steps": 4729600, "episode_reward": 0.26726406812667847, "value_loss": 0.0052776125259697436, "policy_loss": -0.0010599876849653356, "dist_entropy": 0.7922755956649781, "actor_grad_norm": 0.1022825762629509, "critic_grad_norm": 0.053859710693359375, "ratio": 0.9999788403511047, "entropy": 0.7922755956649781, "incre_win_rate": 0.9318181818181818, "step": 1478}
{"time": 1767338090.6132824, "phase": "train", "update": 1479, "total_env_steps": 4732800, "episode_reward": 0.2689321041107178, "value_loss": 0.005829581990838051, "policy_loss": -0.001333492649766299, "dist_entropy": 0.8064728140830993, "actor_grad_norm": 0.10000108927488327, "critic_grad_norm": 0.0364367812871933, "ratio": 1.0001188516616821, "entropy": 0.8064728140830993, "incre_win_rate": 0.9772727272727273, "step": 1479}
{"time": 1767338094.6796534, "phase": "train", "update": 1480, "total_env_steps": 4736000, "episode_reward": 0.25638142228126526, "value_loss": 0.0059644864872097966, "policy_loss": -0.0012132008469073695, "dist_entropy": 0.7989497780799866, "actor_grad_norm": 0.07750427722930908, "critic_grad_norm": 0.07859785854816437, "ratio": 0.9997649192810059, "entropy": 0.7989497780799866, "incre_win_rate": 0.9024390243902439, "step": 1480}
{"time": 1767338098.7936695, "phase": "train", "update": 1481, "total_env_steps": 4739200, "episode_reward": 0.2603518068790436, "value_loss": 0.004540901910513639, "policy_loss": -0.0014319020913362123, "dist_entropy": 0.8022975206375123, "actor_grad_norm": 0.08339103311300278, "critic_grad_norm": 0.039322562515735626, "ratio": 0.999864399433136, "entropy": 0.8022975206375123, "incre_win_rate": 0.9318181818181818, "step": 1481}
{"time": 1767338102.9042199, "phase": "train", "update": 1482, "total_env_steps": 4742400, "episode_reward": 0.26746636629104614, "value_loss": 0.0031605159398168325, "policy_loss": -0.001033403447623016, "dist_entropy": 0.7944369554519654, "actor_grad_norm": 0.09381869435310364, "critic_grad_norm": 0.04224449023604393, "ratio": 0.9996852874755859, "entropy": 0.7944369554519654, "incre_win_rate": 0.975609756097561, "step": 1482}
{"time": 1767338107.00181, "phase": "train", "update": 1483, "total_env_steps": 4745600, "episode_reward": 0.25977855920791626, "value_loss": 0.004706696141511202, "policy_loss": -0.0012652762653539763, "dist_entropy": 0.7767727375030518, "actor_grad_norm": 0.09523975849151611, "critic_grad_norm": 0.03689585253596306, "ratio": 0.9997984766960144, "entropy": 0.7767727375030518, "incre_win_rate": 0.926829268292683, "step": 1483}
{"time": 1767338111.1318052, "phase": "train", "update": 1484, "total_env_steps": 4748800, "episode_reward": 0.26280009746551514, "value_loss": 0.004553665686398744, "policy_loss": -0.0012359852153146279, "dist_entropy": 0.7811574220657349, "actor_grad_norm": 0.10969360917806625, "critic_grad_norm": 0.020595304667949677, "ratio": 0.9997751116752625, "entropy": 0.7811574220657349, "incre_win_rate": 0.9555555555555556, "step": 1484}
{"time": 1767338115.2349362, "phase": "train", "update": 1485, "total_env_steps": 4752000, "episode_reward": 0.26882243156433105, "value_loss": 0.004954364150762558, "policy_loss": -0.0017053524292899524, "dist_entropy": 0.8055513978004456, "actor_grad_norm": 0.09077693521976471, "critic_grad_norm": 0.03260880336165428, "ratio": 0.9998046159744263, "entropy": 0.8055513978004456, "incre_win_rate": 0.926829268292683, "step": 1485}
{"time": 1767338119.327292, "phase": "train", "update": 1486, "total_env_steps": 4755200, "episode_reward": 0.2633609175682068, "value_loss": 0.0036071843933314085, "policy_loss": -0.001141721382517602, "dist_entropy": 0.7927886486053467, "actor_grad_norm": 0.07504073530435562, "critic_grad_norm": 0.0325310193002224, "ratio": 0.9999675750732422, "entropy": 0.7927886486053467, "incre_win_rate": 0.9782608695652174, "step": 1486}
{"time": 1767338123.4623735, "phase": "train", "update": 1487, "total_env_steps": 4758400, "episode_reward": 0.2673882246017456, "value_loss": 0.0037026994861662386, "policy_loss": -0.001119311001459522, "dist_entropy": 0.7997020483016968, "actor_grad_norm": 0.08223694562911987, "critic_grad_norm": 0.02950071170926094, "ratio": 0.9999529123306274, "entropy": 0.7997020483016968, "incre_win_rate": 0.9761904761904762, "step": 1487}
{"time": 1767338127.549662, "phase": "train", "update": 1488, "total_env_steps": 4761600, "episode_reward": 0.2539626359939575, "value_loss": 0.006820409093052149, "policy_loss": -0.0009984286706085754, "dist_entropy": 0.7948503375053406, "actor_grad_norm": 0.07946479320526123, "critic_grad_norm": 0.03649400919675827, "ratio": 0.9997534155845642, "entropy": 0.7948503375053406, "incre_win_rate": 0.8571428571428571, "step": 1488}
{"time": 1767338131.6728396, "phase": "train", "update": 1489, "total_env_steps": 4764800, "episode_reward": 0.2659064531326294, "value_loss": 0.005140386521816254, "policy_loss": -0.0012121910742003195, "dist_entropy": 0.78261958360672, "actor_grad_norm": 0.09235885739326477, "critic_grad_norm": 0.0740402340888977, "ratio": 0.9999498724937439, "entropy": 0.78261958360672, "incre_win_rate": 0.9761904761904762, "step": 1489}
{"time": 1767338135.7627842, "phase": "train", "update": 1490, "total_env_steps": 4768000, "episode_reward": 0.2571181654930115, "value_loss": 0.005541836563497782, "policy_loss": -0.0013234816738005861, "dist_entropy": 0.7774219870567322, "actor_grad_norm": 0.0958477184176445, "critic_grad_norm": 0.054516058415174484, "ratio": 1.0003410577774048, "entropy": 0.7774219870567322, "incre_win_rate": 0.9318181818181818, "step": 1490}
{"time": 1767338139.8785183, "phase": "train", "update": 1491, "total_env_steps": 4771200, "episode_reward": 0.25738152861595154, "value_loss": 0.0042270060628652574, "policy_loss": -0.001356335560693722, "dist_entropy": 0.7564350247383118, "actor_grad_norm": 0.08812636137008667, "critic_grad_norm": 0.040112435817718506, "ratio": 0.9998534321784973, "entropy": 0.7564350247383118, "incre_win_rate": 0.926829268292683, "step": 1491}
{"time": 1767338143.9389036, "phase": "train", "update": 1492, "total_env_steps": 4774400, "episode_reward": 0.2613452076911926, "value_loss": 0.005653939303010702, "policy_loss": -0.0019067159826789749, "dist_entropy": 0.7883599281311036, "actor_grad_norm": 0.09363896399736404, "critic_grad_norm": 0.032395582646131516, "ratio": 1.000205636024475, "entropy": 0.7883599281311036, "incre_win_rate": 0.9512195121951219, "step": 1492}
{"time": 1767338148.0495787, "phase": "train", "update": 1493, "total_env_steps": 4777600, "episode_reward": 0.256003737449646, "value_loss": 0.006194443814456463, "policy_loss": -0.0015759505706718357, "dist_entropy": 0.7624145030975342, "actor_grad_norm": 0.08437111973762512, "critic_grad_norm": 0.04610133171081543, "ratio": 0.999943196773529, "entropy": 0.7624145030975342, "incre_win_rate": 0.8837209302325582, "step": 1493}
{"time": 1767338152.1417053, "phase": "train", "update": 1494, "total_env_steps": 4780800, "episode_reward": 0.26665976643562317, "value_loss": 0.0067570052109658715, "policy_loss": -0.0015614926198999513, "dist_entropy": 0.7394007086753845, "actor_grad_norm": 0.08814744651317596, "critic_grad_norm": 0.05348843336105347, "ratio": 0.9997926950454712, "entropy": 0.7394007086753845, "incre_win_rate": 0.9545454545454546, "step": 1494}
{"time": 1767338156.2171931, "phase": "train", "update": 1495, "total_env_steps": 4784000, "episode_reward": 0.26042476296424866, "value_loss": 0.005689345858991146, "policy_loss": -0.001288793806140731, "dist_entropy": 0.7492759108543396, "actor_grad_norm": 0.09478862583637238, "critic_grad_norm": 0.04139437526464462, "ratio": 1.0005913972854614, "entropy": 0.7492759108543396, "incre_win_rate": 0.8837209302325582, "step": 1495}
{"time": 1767338160.3480117, "phase": "train", "update": 1496, "total_env_steps": 4787200, "episode_reward": 0.2730753421783447, "value_loss": 0.003756889468058944, "policy_loss": -0.001229553682378537, "dist_entropy": 0.7714429497718811, "actor_grad_norm": 0.08334595710039139, "critic_grad_norm": 0.05094604566693306, "ratio": 0.9999595880508423, "entropy": 0.7714429497718811, "incre_win_rate": 1.0, "step": 1496}
{"time": 1767338164.4525752, "phase": "train", "update": 1497, "total_env_steps": 4790400, "episode_reward": 0.2577162981033325, "value_loss": 0.007075479254126549, "policy_loss": -0.0009541200498510705, "dist_entropy": 0.7642552733421326, "actor_grad_norm": 0.07148543745279312, "critic_grad_norm": 0.11199243366718292, "ratio": 1.000226616859436, "entropy": 0.7642552733421326, "incre_win_rate": 0.8809523809523809, "step": 1497}
{"time": 1767338168.57312, "phase": "train", "update": 1498, "total_env_steps": 4793600, "episode_reward": 0.25971028208732605, "value_loss": 0.009322702698409558, "policy_loss": -0.0010416933328080801, "dist_entropy": 0.7636334657669067, "actor_grad_norm": 0.10015869140625, "critic_grad_norm": 0.07834392786026001, "ratio": 1.00053071975708, "entropy": 0.7636334657669067, "incre_win_rate": 0.8536585365853658, "step": 1498}
{"time": 1767338172.705264, "phase": "train", "update": 1499, "total_env_steps": 4796800, "episode_reward": 0.25511330366134644, "value_loss": 0.008339479751884937, "policy_loss": -0.0014207474866012148, "dist_entropy": 0.775557029247284, "actor_grad_norm": 0.12011431902647018, "critic_grad_norm": 0.07282053679227829, "ratio": 0.9998754858970642, "entropy": 0.775557029247284, "incre_win_rate": 0.8409090909090909, "step": 1499}
{"time": 1767338176.80471, "phase": "train", "update": 1500, "total_env_steps": 4800000, "episode_reward": 0.26680877804756165, "value_loss": 0.0069430812261998655, "policy_loss": -0.0012635673549842962, "dist_entropy": 0.7625176787376404, "actor_grad_norm": 0.09720323979854584, "critic_grad_norm": 0.05004986748099327, "ratio": 1.00006902217865, "entropy": 0.7625176787376404, "incre_win_rate": 0.9534883720930233, "step": 1500}
{"time": 1767338180.955573, "phase": "train", "update": 1501, "total_env_steps": 4803200, "episode_reward": 0.2576831579208374, "value_loss": 0.00965962205082178, "policy_loss": -0.0013002685775973077, "dist_entropy": 0.7866150617599488, "actor_grad_norm": 0.0876212865114212, "critic_grad_norm": 0.10723884403705597, "ratio": 1.0001357793807983, "entropy": 0.7866150617599488, "incre_win_rate": 0.8409090909090909, "step": 1501}
{"time": 1767338191.2508113, "phase": "eval", "update": 1501, "total_env_steps": 4803200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.291856374172184, "step": 1501}
{"time": 1767338195.3264568, "phase": "train", "update": 1502, "total_env_steps": 4806400, "episode_reward": 0.2511806786060333, "value_loss": 0.007121592015028, "policy_loss": -0.0016393300697842505, "dist_entropy": 0.8037240266799927, "actor_grad_norm": 0.09918924421072006, "critic_grad_norm": 0.07088535279035568, "ratio": 0.9999241232872009, "entropy": 0.8037240266799927, "incre_win_rate": 0.8780487804878049, "step": 1502}
{"time": 1767338199.4382606, "phase": "train", "update": 1503, "total_env_steps": 4809600, "episode_reward": 0.2505173981189728, "value_loss": 0.010531850159168243, "policy_loss": -0.0011907391833190673, "dist_entropy": 0.8083130359649658, "actor_grad_norm": 0.10700418800115585, "critic_grad_norm": 0.030839944258332253, "ratio": 0.9998378753662109, "entropy": 0.8083130359649658, "incre_win_rate": 0.8837209302325582, "step": 1503}
{"time": 1767338203.5195067, "phase": "train", "update": 1504, "total_env_steps": 4812800, "episode_reward": 0.2414574772119522, "value_loss": 0.012581983394920827, "policy_loss": -0.0017214863942641046, "dist_entropy": 0.7994446396827698, "actor_grad_norm": 0.09905677288770676, "critic_grad_norm": 0.04770930856466293, "ratio": 1.0000981092453003, "entropy": 0.7994446396827698, "incre_win_rate": 0.75, "step": 1504}
{"time": 1767338207.6456904, "phase": "train", "update": 1505, "total_env_steps": 4816000, "episode_reward": 0.25543564558029175, "value_loss": 0.008434202708303928, "policy_loss": -0.0017025911457437815, "dist_entropy": 0.8129727959632873, "actor_grad_norm": 0.11273825168609619, "critic_grad_norm": 0.07948607951402664, "ratio": 0.9999716877937317, "entropy": 0.8129727959632873, "incre_win_rate": 0.8571428571428571, "step": 1505}
{"time": 1767338211.8247614, "phase": "train", "update": 1506, "total_env_steps": 4819200, "episode_reward": 0.24537044763565063, "value_loss": 0.009215367026627064, "policy_loss": -0.001381451265403655, "dist_entropy": 0.7996757507324219, "actor_grad_norm": 0.10494609922170639, "critic_grad_norm": 0.05508297681808472, "ratio": 0.9999813437461853, "entropy": 0.7996757507324219, "incre_win_rate": 0.8974358974358975, "step": 1506}
{"time": 1767338215.9198444, "phase": "train", "update": 1507, "total_env_steps": 4822400, "episode_reward": 0.26152732968330383, "value_loss": 0.004651653114706278, "policy_loss": -0.001721279924385044, "dist_entropy": 0.8059812545776367, "actor_grad_norm": 0.09057251363992691, "critic_grad_norm": 0.05802839994430542, "ratio": 0.9998195767402649, "entropy": 0.8059812545776367, "incre_win_rate": 0.9772727272727273, "step": 1507}
{"time": 1767338219.970075, "phase": "train", "update": 1508, "total_env_steps": 4825600, "episode_reward": 0.24481788277626038, "value_loss": 0.0050515376031398775, "policy_loss": -0.0009469318030944862, "dist_entropy": 0.7946560859680176, "actor_grad_norm": 0.08686643093824387, "critic_grad_norm": 0.03456766530871391, "ratio": 1.0002344846725464, "entropy": 0.7946560859680176, "incre_win_rate": 0.8974358974358975, "step": 1508}
{"time": 1767338224.0790029, "phase": "train", "update": 1509, "total_env_steps": 4828800, "episode_reward": 0.2541044354438782, "value_loss": 0.004993678070604801, "policy_loss": -0.0015181938381822135, "dist_entropy": 0.7951119780540467, "actor_grad_norm": 0.11593925207853317, "critic_grad_norm": 0.03928843513131142, "ratio": 0.9997798800468445, "entropy": 0.7951119780540467, "incre_win_rate": 0.9512195121951219, "step": 1509}
{"time": 1767338228.1306677, "phase": "train", "update": 1510, "total_env_steps": 4832000, "episode_reward": 0.2424001544713974, "value_loss": 0.006565344892442227, "policy_loss": -0.001281475650199404, "dist_entropy": 0.795876657962799, "actor_grad_norm": 0.11232586205005646, "critic_grad_norm": 0.026338830590248108, "ratio": 1.0001822710037231, "entropy": 0.795876657962799, "incre_win_rate": 0.9, "step": 1510}
{"time": 1767338232.2653942, "phase": "train", "update": 1511, "total_env_steps": 4835200, "episode_reward": 0.2620146870613098, "value_loss": 0.003939456306397915, "policy_loss": -0.001294483999808449, "dist_entropy": 0.7830681324005127, "actor_grad_norm": 0.0946669653058052, "critic_grad_norm": 0.07438259571790695, "ratio": 1.0001152753829956, "entropy": 0.7830681324005127, "incre_win_rate": 0.9767441860465116, "step": 1511}
{"time": 1767338236.3425493, "phase": "train", "update": 1512, "total_env_steps": 4838400, "episode_reward": 0.25595974922180176, "value_loss": 0.006381844822317362, "policy_loss": -0.0012058570162089665, "dist_entropy": 0.7917495727539062, "actor_grad_norm": 0.0923856720328331, "critic_grad_norm": 0.0506276898086071, "ratio": 1.0000178813934326, "entropy": 0.7917495727539062, "incre_win_rate": 0.8837209302325582, "step": 1512}
{"time": 1767338240.4427342, "phase": "train", "update": 1513, "total_env_steps": 4841600, "episode_reward": 0.2551024556159973, "value_loss": 0.00645905826240778, "policy_loss": -0.000936193540723096, "dist_entropy": 0.7838746070861816, "actor_grad_norm": 0.09554555267095566, "critic_grad_norm": 0.08703102916479111, "ratio": 0.9998049736022949, "entropy": 0.7838746070861816, "incre_win_rate": 0.9285714285714286, "step": 1513}
{"time": 1767338244.5099218, "phase": "train", "update": 1514, "total_env_steps": 4844800, "episode_reward": 0.2554263472557068, "value_loss": 0.007139699812978506, "policy_loss": -0.0013793755619715853, "dist_entropy": 0.7779565930366517, "actor_grad_norm": 0.09501134604215622, "critic_grad_norm": 0.05937831476330757, "ratio": 0.9998021125793457, "entropy": 0.7779565930366517, "incre_win_rate": 0.9743589743589743, "step": 1514}
{"time": 1767338248.6150937, "phase": "train", "update": 1515, "total_env_steps": 4848000, "episode_reward": 0.26672133803367615, "value_loss": 0.0040009614080190655, "policy_loss": -0.0011029279720446538, "dist_entropy": 0.7928495883941651, "actor_grad_norm": 0.1009269505739212, "critic_grad_norm": 0.08918356150388718, "ratio": 0.999527096748352, "entropy": 0.7928495883941651, "incre_win_rate": 0.9767441860465116, "step": 1515}
{"time": 1767338252.6920788, "phase": "train", "update": 1516, "total_env_steps": 4851200, "episode_reward": 0.24653251469135284, "value_loss": 0.00848446525633335, "policy_loss": -0.0011588444946042387, "dist_entropy": 0.8011370062828064, "actor_grad_norm": 0.11827158182859421, "critic_grad_norm": 0.06442224234342575, "ratio": 0.9998060464859009, "entropy": 0.8011370062828064, "incre_win_rate": 0.8292682926829268, "step": 1516}
{"time": 1767338256.796052, "phase": "train", "update": 1517, "total_env_steps": 4854400, "episode_reward": 0.24209022521972656, "value_loss": 0.024157265946269036, "policy_loss": -0.0010620105492890274, "dist_entropy": 0.8191946744918823, "actor_grad_norm": 0.24578356742858887, "critic_grad_norm": 0.16782556474208832, "ratio": 1.0001919269561768, "entropy": 0.8191946744918823, "incre_win_rate": 0.926829268292683, "step": 1517}
{"time": 1767338260.8843956, "phase": "train", "update": 1518, "total_env_steps": 4857600, "episode_reward": 0.24985305964946747, "value_loss": 0.006920821871608496, "policy_loss": -0.0011688326903548153, "dist_entropy": 0.829607355594635, "actor_grad_norm": 0.15424972772598267, "critic_grad_norm": 0.11935194581747055, "ratio": 1.0002013444900513, "entropy": 0.829607355594635, "incre_win_rate": 0.9, "step": 1518}
{"time": 1767338264.9779615, "phase": "train", "update": 1519, "total_env_steps": 4860800, "episode_reward": 0.25680410861968994, "value_loss": 0.0062095895409584045, "policy_loss": -0.0014571312791396452, "dist_entropy": 0.8154974460601807, "actor_grad_norm": 0.0935811921954155, "critic_grad_norm": 0.11519689857959747, "ratio": 0.9999260902404785, "entropy": 0.8154974460601807, "incre_win_rate": 0.9302325581395349, "step": 1519}
{"time": 1767338269.066551, "phase": "train", "update": 1520, "total_env_steps": 4864000, "episode_reward": 0.25490841269493103, "value_loss": 0.007675625011324882, "policy_loss": -0.0013477100740750814, "dist_entropy": 0.7935619473457336, "actor_grad_norm": 0.0805811882019043, "critic_grad_norm": 0.08483570069074631, "ratio": 1.0000107288360596, "entropy": 0.7935619473457336, "incre_win_rate": 0.8536585365853658, "step": 1520}
{"time": 1767338273.1308916, "phase": "train", "update": 1521, "total_env_steps": 4867200, "episode_reward": 0.24979357421398163, "value_loss": 0.007600134704262018, "policy_loss": -0.0012318191186594164, "dist_entropy": 0.795940363407135, "actor_grad_norm": 0.06794197112321854, "critic_grad_norm": 0.07298927754163742, "ratio": 0.9998953938484192, "entropy": 0.795940363407135, "incre_win_rate": 0.8780487804878049, "step": 1521}
{"time": 1767338277.2070863, "phase": "train", "update": 1522, "total_env_steps": 4870400, "episode_reward": 0.25806188583374023, "value_loss": 0.006260654143989086, "policy_loss": -0.0013258897291706262, "dist_entropy": 0.8000867962837219, "actor_grad_norm": 0.08332519233226776, "critic_grad_norm": 0.06165085360407829, "ratio": 1.0000498294830322, "entropy": 0.8000867962837219, "incre_win_rate": 0.9302325581395349, "step": 1522}
{"time": 1767338281.3580167, "phase": "train", "update": 1523, "total_env_steps": 4873600, "episode_reward": 0.25846439599990845, "value_loss": 0.005250803008675575, "policy_loss": -0.001224106456348295, "dist_entropy": 0.7846322655677795, "actor_grad_norm": 0.08719959110021591, "critic_grad_norm": 0.051180191338062286, "ratio": 1.0001002550125122, "entropy": 0.7846322655677795, "incre_win_rate": 0.95, "step": 1523}
{"time": 1767338285.4535413, "phase": "train", "update": 1524, "total_env_steps": 4876800, "episode_reward": 0.2556963860988617, "value_loss": 0.0058664469048380855, "policy_loss": -0.001113955762092189, "dist_entropy": 0.7788270354270935, "actor_grad_norm": 0.1049671396613121, "critic_grad_norm": 0.06122952699661255, "ratio": 0.9994345903396606, "entropy": 0.7788270354270935, "incre_win_rate": 0.8636363636363636, "step": 1524}
{"time": 1767338289.543956, "phase": "train", "update": 1525, "total_env_steps": 4880000, "episode_reward": 0.254862904548645, "value_loss": 0.006637866888195276, "policy_loss": -0.0010258989103148152, "dist_entropy": 0.744440221786499, "actor_grad_norm": 0.09646645933389664, "critic_grad_norm": 0.0726904422044754, "ratio": 1.0002135038375854, "entropy": 0.744440221786499, "incre_win_rate": 0.8780487804878049, "step": 1525}
{"time": 1767338293.6597679, "phase": "train", "update": 1526, "total_env_steps": 4883200, "episode_reward": 0.2569313943386078, "value_loss": 0.00627889484167099, "policy_loss": -0.0009716886780999801, "dist_entropy": 0.7471497178077697, "actor_grad_norm": 0.07624258100986481, "critic_grad_norm": 0.06768911331892014, "ratio": 0.9998855590820312, "entropy": 0.7471497178077697, "incre_win_rate": 0.8604651162790697, "step": 1526}
{"time": 1767338303.795119, "phase": "eval", "update": 1526, "total_env_steps": 4883200, "eval_win_rate": 0.875, "eval_episode_reward": 19.421512831125828, "step": 1526}
{"time": 1767338307.8516204, "phase": "train", "update": 1527, "total_env_steps": 4886400, "episode_reward": 0.2557864487171173, "value_loss": 0.007309870701283217, "policy_loss": -0.0014597292999985357, "dist_entropy": 0.7557068586349487, "actor_grad_norm": 0.12697327136993408, "critic_grad_norm": 0.06188319995999336, "ratio": 0.9997398257255554, "entropy": 0.7557068586349487, "incre_win_rate": 0.9767441860465116, "step": 1527}
{"time": 1767338311.9556892, "phase": "train", "update": 1528, "total_env_steps": 4889600, "episode_reward": 0.2687670886516571, "value_loss": 0.005173516552895307, "policy_loss": -0.0009721243734752249, "dist_entropy": 0.7574373602867126, "actor_grad_norm": 0.10752840340137482, "critic_grad_norm": 0.053535401821136475, "ratio": 1.000133752822876, "entropy": 0.7574373602867126, "incre_win_rate": 0.9512195121951219, "step": 1528}
{"time": 1767338316.0578792, "phase": "train", "update": 1529, "total_env_steps": 4892800, "episode_reward": 0.26779595017433167, "value_loss": 0.004395202826708555, "policy_loss": -0.001035104904696027, "dist_entropy": 0.7642441391944885, "actor_grad_norm": 0.10947360843420029, "critic_grad_norm": 0.07073193788528442, "ratio": 1.000227451324463, "entropy": 0.7642441391944885, "incre_win_rate": 0.9772727272727273, "step": 1529}
{"time": 1767338320.1740546, "phase": "train", "update": 1530, "total_env_steps": 4896000, "episode_reward": 0.2674461603164673, "value_loss": 0.004216271452605724, "policy_loss": -0.0009472250284019879, "dist_entropy": 0.7652187466621398, "actor_grad_norm": 0.0746709555387497, "critic_grad_norm": 0.07518366724252701, "ratio": 1.0001685619354248, "entropy": 0.7652187466621398, "incre_win_rate": 0.9545454545454546, "step": 1530}
{"time": 1767338324.2441962, "phase": "train", "update": 1531, "total_env_steps": 4899200, "episode_reward": 0.2649337947368622, "value_loss": 0.004284757701680064, "policy_loss": -0.0014434442925491454, "dist_entropy": 0.7724070191383362, "actor_grad_norm": 0.10455789417028427, "critic_grad_norm": 0.033622898161411285, "ratio": 0.9993773698806763, "entropy": 0.7724070191383362, "incre_win_rate": 0.9024390243902439, "step": 1531}
{"time": 1767338328.3308032, "phase": "train", "update": 1532, "total_env_steps": 4902400, "episode_reward": 0.2606746554374695, "value_loss": 0.006134691089391709, "policy_loss": -0.0013449236353165971, "dist_entropy": 0.7933815360069275, "actor_grad_norm": 0.09802445024251938, "critic_grad_norm": 0.05048149824142456, "ratio": 0.9997901916503906, "entropy": 0.7933815360069275, "incre_win_rate": 0.9285714285714286, "step": 1532}
{"time": 1767338332.444863, "phase": "train", "update": 1533, "total_env_steps": 4905600, "episode_reward": 0.255942165851593, "value_loss": 0.011043943651020526, "policy_loss": -0.0012926014653556806, "dist_entropy": 0.7571385502815247, "actor_grad_norm": 0.099091537296772, "critic_grad_norm": 0.04455650597810745, "ratio": 0.9999774098396301, "entropy": 0.7571385502815247, "incre_win_rate": 0.8181818181818182, "step": 1533}
{"time": 1767338336.5450156, "phase": "train", "update": 1534, "total_env_steps": 4908800, "episode_reward": 0.2534002363681793, "value_loss": 0.008410139009356499, "policy_loss": -0.0011339819621788648, "dist_entropy": 0.7437551140785217, "actor_grad_norm": 0.11849703639745712, "critic_grad_norm": 0.0403125062584877, "ratio": 1.0001001358032227, "entropy": 0.7437551140785217, "incre_win_rate": 0.8604651162790697, "step": 1534}
{"time": 1767338340.6969867, "phase": "train", "update": 1535, "total_env_steps": 4912000, "episode_reward": 0.25947123765945435, "value_loss": 0.005928894691169262, "policy_loss": -0.001169054678743464, "dist_entropy": 0.7547517657279968, "actor_grad_norm": 0.09484674036502838, "critic_grad_norm": 0.030643699690699577, "ratio": 1.0001384019851685, "entropy": 0.7547517657279968, "incre_win_rate": 0.9069767441860465, "step": 1535}
{"time": 1767338344.7500677, "phase": "train", "update": 1536, "total_env_steps": 4915200, "episode_reward": 0.25306448340415955, "value_loss": 0.011855652555823326, "policy_loss": -0.0007937520114424501, "dist_entropy": 0.7150363087654114, "actor_grad_norm": 0.07603221386671066, "critic_grad_norm": 0.09318964928388596, "ratio": 1.0001401901245117, "entropy": 0.7150363087654114, "incre_win_rate": 0.7906976744186046, "step": 1536}
{"time": 1767338348.811192, "phase": "train", "update": 1537, "total_env_steps": 4918400, "episode_reward": 0.25473925471305847, "value_loss": 0.008830454759299755, "policy_loss": -0.0015031997345467119, "dist_entropy": 0.7148854851722717, "actor_grad_norm": 0.08401277661323547, "critic_grad_norm": 0.05134535953402519, "ratio": 0.9997026324272156, "entropy": 0.7148854851722717, "incre_win_rate": 0.9047619047619048, "step": 1537}
{"time": 1767338352.9571168, "phase": "train", "update": 1538, "total_env_steps": 4921600, "episode_reward": 0.26267123222351074, "value_loss": 0.007456823252141476, "policy_loss": -0.0013404503616055053, "dist_entropy": 0.7282895565032959, "actor_grad_norm": 0.0889158621430397, "critic_grad_norm": 0.060466088354587555, "ratio": 0.9996532797813416, "entropy": 0.7282895565032959, "incre_win_rate": 0.8604651162790697, "step": 1538}
{"time": 1767338357.0515974, "phase": "train", "update": 1539, "total_env_steps": 4924800, "episode_reward": 0.25948622822761536, "value_loss": 0.007270218338817358, "policy_loss": -0.001454997155815363, "dist_entropy": 0.7233152031898499, "actor_grad_norm": 0.10642456263303757, "critic_grad_norm": 0.05556102469563484, "ratio": 1.0001405477523804, "entropy": 0.7233152031898499, "incre_win_rate": 0.9024390243902439, "step": 1539}
{"time": 1767338361.2183273, "phase": "train", "update": 1540, "total_env_steps": 4928000, "episode_reward": 0.2597009539604187, "value_loss": 0.0076261571608483795, "policy_loss": -0.0015925992133573707, "dist_entropy": 0.7067151188850402, "actor_grad_norm": 0.10975807160139084, "critic_grad_norm": 0.04122477397322655, "ratio": 1.000106692314148, "entropy": 0.7067151188850402, "incre_win_rate": 0.9069767441860465, "step": 1540}
{"time": 1767338365.3219352, "phase": "train", "update": 1541, "total_env_steps": 4931200, "episode_reward": 0.2605980932712555, "value_loss": 0.006023824959993362, "policy_loss": -0.0012710658291408272, "dist_entropy": 0.6927533626556397, "actor_grad_norm": 0.08771941810846329, "critic_grad_norm": 0.035232748836278915, "ratio": 0.9999855160713196, "entropy": 0.6927533626556397, "incre_win_rate": 0.9090909090909091, "step": 1541}
{"time": 1767338369.4115245, "phase": "train", "update": 1542, "total_env_steps": 4934400, "episode_reward": 0.26680463552474976, "value_loss": 0.004056864231824875, "policy_loss": -0.0014662360111600491, "dist_entropy": 0.7160362839698792, "actor_grad_norm": 0.10018340498209, "critic_grad_norm": 0.028457865118980408, "ratio": 0.999856173992157, "entropy": 0.7160362839698792, "incre_win_rate": 0.975609756097561, "step": 1542}
{"time": 1767338373.5105064, "phase": "train", "update": 1543, "total_env_steps": 4937600, "episode_reward": 0.25975167751312256, "value_loss": 0.0056955933570861815, "policy_loss": -0.0013541189213626126, "dist_entropy": 0.696711802482605, "actor_grad_norm": 0.08182241767644882, "critic_grad_norm": 0.03071385994553566, "ratio": 1.0004217624664307, "entropy": 0.696711802482605, "incre_win_rate": 0.9090909090909091, "step": 1543}
{"time": 1767338377.6311715, "phase": "train", "update": 1544, "total_env_steps": 4940800, "episode_reward": 0.2685099244117737, "value_loss": 0.0034779388457536697, "policy_loss": -0.001043157857132826, "dist_entropy": 0.6928822517395019, "actor_grad_norm": 0.08565134555101395, "critic_grad_norm": 0.06482920795679092, "ratio": 1.0002628564834595, "entropy": 0.6928822517395019, "incre_win_rate": 0.9761904761904762, "step": 1544}
{"time": 1767338381.7709923, "phase": "train", "update": 1545, "total_env_steps": 4944000, "episode_reward": 0.26026439666748047, "value_loss": 0.008146940357983112, "policy_loss": -0.0011880930086327623, "dist_entropy": 0.6801125288009644, "actor_grad_norm": 0.08195340633392334, "critic_grad_norm": 0.04944799095392227, "ratio": 1.0005137920379639, "entropy": 0.6801125288009644, "incre_win_rate": 0.8837209302325582, "step": 1545}
{"time": 1767338385.8582983, "phase": "train", "update": 1546, "total_env_steps": 4947200, "episode_reward": 0.2673758268356323, "value_loss": 0.004129967652261257, "policy_loss": -0.00126545891398564, "dist_entropy": 0.6761492252349853, "actor_grad_norm": 0.08505766838788986, "critic_grad_norm": 0.039058685302734375, "ratio": 0.9997578859329224, "entropy": 0.6761492252349853, "incre_win_rate": 0.9069767441860465, "step": 1546}
{"time": 1767338389.9713202, "phase": "train", "update": 1547, "total_env_steps": 4950400, "episode_reward": 0.27255794405937195, "value_loss": 0.0033566759433597327, "policy_loss": -0.0011249344116841086, "dist_entropy": 0.6939619898796081, "actor_grad_norm": 0.07838191837072372, "critic_grad_norm": 0.06734830141067505, "ratio": 1.0001049041748047, "entropy": 0.6939619898796081, "incre_win_rate": 0.9777777777777777, "step": 1547}
{"time": 1767338394.0873501, "phase": "train", "update": 1548, "total_env_steps": 4953600, "episode_reward": 0.27040770649909973, "value_loss": 0.003229592088609934, "policy_loss": -0.0014786254866081094, "dist_entropy": 0.6849352598190308, "actor_grad_norm": 0.09950540214776993, "critic_grad_norm": 0.0542462058365345, "ratio": 0.9997279047966003, "entropy": 0.6849352598190308, "incre_win_rate": 0.9772727272727273, "step": 1548}
{"time": 1767338398.158633, "phase": "train", "update": 1549, "total_env_steps": 4956800, "episode_reward": 0.2638493478298187, "value_loss": 0.0034335779957473276, "policy_loss": -0.001126007289367692, "dist_entropy": 0.6767963647842408, "actor_grad_norm": 0.07947959750890732, "critic_grad_norm": 0.027247577905654907, "ratio": 0.9998440146446228, "entropy": 0.6767963647842408, "incre_win_rate": 0.9523809523809523, "step": 1549}
{"time": 1767338402.3100193, "phase": "train", "update": 1550, "total_env_steps": 4960000, "episode_reward": 0.27015677094459534, "value_loss": 0.004132369346916675, "policy_loss": -0.0015960280899889768, "dist_entropy": 0.6637423992156982, "actor_grad_norm": 0.0864301547408104, "critic_grad_norm": 0.05854097753763199, "ratio": 1.000207543373108, "entropy": 0.6637423992156982, "incre_win_rate": 0.9545454545454546, "step": 1550}
{"time": 1767338406.4024096, "phase": "train", "update": 1551, "total_env_steps": 4963200, "episode_reward": 0.26569536328315735, "value_loss": 0.005922289658337831, "policy_loss": -0.0017495081112642197, "dist_entropy": 0.670437467098236, "actor_grad_norm": 0.11591266840696335, "critic_grad_norm": 0.030340811237692833, "ratio": 1.0003408193588257, "entropy": 0.670437467098236, "incre_win_rate": 0.9512195121951219, "step": 1551}
{"time": 1767338416.004951, "phase": "eval", "update": 1551, "total_env_steps": 4963200, "eval_win_rate": 1.0, "eval_episode_reward": 20.0, "step": 1551}
{"time": 1767338420.1116006, "phase": "train", "update": 1552, "total_env_steps": 4966400, "episode_reward": 0.26779696345329285, "value_loss": 0.004701847489923239, "policy_loss": -0.000996282687238903, "dist_entropy": 0.6582223057746888, "actor_grad_norm": 0.09020305424928665, "critic_grad_norm": 0.04574722424149513, "ratio": 0.9999467730522156, "entropy": 0.6582223057746888, "incre_win_rate": 0.9555555555555556, "step": 1552}
{"time": 1767338424.2663307, "phase": "train", "update": 1553, "total_env_steps": 4969600, "episode_reward": 0.273468554019928, "value_loss": 0.004350562766194344, "policy_loss": -0.0016581603725100535, "dist_entropy": 0.6662065744400024, "actor_grad_norm": 0.07813548296689987, "critic_grad_norm": 0.056590378284454346, "ratio": 0.9998133778572083, "entropy": 0.6662065744400024, "incre_win_rate": 0.9767441860465116, "step": 1553}
{"time": 1767338428.334006, "phase": "train", "update": 1554, "total_env_steps": 4972800, "episode_reward": 0.2619732916355133, "value_loss": 0.008178225252777338, "policy_loss": -0.000901196585546149, "dist_entropy": 0.6691008806228638, "actor_grad_norm": 0.07448380440473557, "critic_grad_norm": 0.06274823844432831, "ratio": 0.9996808171272278, "entropy": 0.6691008806228638, "incre_win_rate": 0.9302325581395349, "step": 1554}
{"time": 1767338432.4025404, "phase": "train", "update": 1555, "total_env_steps": 4976000, "episode_reward": 0.253572016954422, "value_loss": 0.007362153939902782, "policy_loss": -0.0017039654080562628, "dist_entropy": 0.6623734712600708, "actor_grad_norm": 0.09797661751508713, "critic_grad_norm": 0.04823779687285423, "ratio": 0.9996485710144043, "entropy": 0.6623734712600708, "incre_win_rate": 0.9285714285714286, "step": 1555}
{"time": 1767338436.4836037, "phase": "train", "update": 1556, "total_env_steps": 4979200, "episode_reward": 0.2660922110080719, "value_loss": 0.007101274840533733, "policy_loss": -0.0011217741043850538, "dist_entropy": 0.6565140843391418, "actor_grad_norm": 0.09177473932504654, "critic_grad_norm": 0.08786561340093613, "ratio": 1.0002719163894653, "entropy": 0.6565140843391418, "incre_win_rate": 0.9318181818181818, "step": 1556}
{"time": 1767338440.5859585, "phase": "train", "update": 1557, "total_env_steps": 4982400, "episode_reward": 0.26008692383766174, "value_loss": 0.006398497708141803, "policy_loss": -0.0008694631105313988, "dist_entropy": 0.6635068893432617, "actor_grad_norm": 0.09472157806158066, "critic_grad_norm": 0.047075871378183365, "ratio": 1.000481128692627, "entropy": 0.6635068893432617, "incre_win_rate": 0.9069767441860465, "step": 1557}
{"time": 1767338444.6892052, "phase": "train", "update": 1558, "total_env_steps": 4985600, "episode_reward": 0.26483237743377686, "value_loss": 0.0060079660266637806, "policy_loss": -0.000933935200909275, "dist_entropy": 0.6611911296844483, "actor_grad_norm": 0.10336392372846603, "critic_grad_norm": 0.035295139998197556, "ratio": 0.9997731447219849, "entropy": 0.6611911296844483, "incre_win_rate": 0.9523809523809523, "step": 1558}
{"time": 1767338448.7890472, "phase": "train", "update": 1559, "total_env_steps": 4988800, "episode_reward": 0.2627069652080536, "value_loss": 0.005153667088598013, "policy_loss": -0.0010787486596325556, "dist_entropy": 0.6796577930450439, "actor_grad_norm": 0.09765660017728806, "critic_grad_norm": 0.045926496386528015, "ratio": 0.9998432397842407, "entropy": 0.6796577930450439, "incre_win_rate": 0.9090909090909091, "step": 1559}
{"time": 1767338452.9150717, "phase": "train", "update": 1560, "total_env_steps": 4992000, "episode_reward": 0.2725827693939209, "value_loss": 0.003267284668982029, "policy_loss": -0.0011710520789932843, "dist_entropy": 0.6835291028022766, "actor_grad_norm": 0.08715185523033142, "critic_grad_norm": 0.028000876307487488, "ratio": 0.9997989535331726, "entropy": 0.6835291028022766, "incre_win_rate": 0.9545454545454546, "step": 1560}
{"time": 1767338457.017071, "phase": "train", "update": 1561, "total_env_steps": 4995200, "episode_reward": 0.2690066397190094, "value_loss": 0.004442065488547087, "policy_loss": -0.0014053362525114465, "dist_entropy": 0.6810790181159974, "actor_grad_norm": 0.10678305476903915, "critic_grad_norm": 0.041056979447603226, "ratio": 1.000174641609192, "entropy": 0.6810790181159974, "incre_win_rate": 0.9534883720930233, "step": 1561}
{"time": 1767338461.1329277, "phase": "train", "update": 1562, "total_env_steps": 4998400, "episode_reward": 0.2702566385269165, "value_loss": 0.0053008319810032845, "policy_loss": -0.0009899936235512996, "dist_entropy": 0.6855616807937622, "actor_grad_norm": 0.0953226238489151, "critic_grad_norm": 0.04629947617650032, "ratio": 1.000346064567566, "entropy": 0.6855616807937622, "incre_win_rate": 0.9302325581395349, "step": 1562}
{"time": 1767338465.247954, "phase": "train", "update": 1563, "total_env_steps": 5001600, "episode_reward": 0.2684789001941681, "value_loss": 0.0046473205089569095, "policy_loss": -0.001399211587477822, "dist_entropy": 0.6737913370132447, "actor_grad_norm": 0.0934169813990593, "critic_grad_norm": 0.035813089460134506, "ratio": 1.000043511390686, "entropy": 0.6737913370132447, "incre_win_rate": 0.9545454545454546, "step": 1563}
{"time": 1767338469.3359742, "phase": "train", "update": 1564, "total_env_steps": 5004800, "episode_reward": 0.2709685266017914, "value_loss": 0.005905058700591326, "policy_loss": -0.0011854511320883887, "dist_entropy": 0.6977038502693176, "actor_grad_norm": 0.08202408254146576, "critic_grad_norm": 0.08595727384090424, "ratio": 0.9999632239341736, "entropy": 0.6977038502693176, "incre_win_rate": 0.9318181818181818, "step": 1564}
{"time": 1767338473.4669971, "phase": "train", "update": 1565, "total_env_steps": 5008000, "episode_reward": 0.26498186588287354, "value_loss": 0.006427726335823536, "policy_loss": -0.0012790343190008714, "dist_entropy": 0.6640559554100036, "actor_grad_norm": 0.07700445502996445, "critic_grad_norm": 0.04197840392589569, "ratio": 1.0001325607299805, "entropy": 0.6640559554100036, "incre_win_rate": 0.9318181818181818, "step": 1565}
{"time": 1767338477.5646276, "phase": "train", "update": 1566, "total_env_steps": 5011200, "episode_reward": 0.27504193782806396, "value_loss": 0.004614782426506281, "policy_loss": -0.0015158098607958692, "dist_entropy": 0.6947605848312378, "actor_grad_norm": 0.09151892364025116, "critic_grad_norm": 0.06116703897714615, "ratio": 0.9998707175254822, "entropy": 0.6947605848312378, "incre_win_rate": 0.9767441860465116, "step": 1566}
{"time": 1767338481.6789687, "phase": "train", "update": 1567, "total_env_steps": 5014400, "episode_reward": 0.2788213789463043, "value_loss": 0.0033487666863948108, "policy_loss": -0.0011077066154712156, "dist_entropy": 0.6781238317489624, "actor_grad_norm": 0.09890300035476685, "critic_grad_norm": 0.05809326097369194, "ratio": 0.999957263469696, "entropy": 0.6781238317489624, "incre_win_rate": 0.9787234042553191, "step": 1567}
{"time": 1767338485.8060145, "phase": "train", "update": 1568, "total_env_steps": 5017600, "episode_reward": 0.2684478461742401, "value_loss": 0.0029650816693902017, "policy_loss": -0.001192063681230593, "dist_entropy": 0.7046007871627807, "actor_grad_norm": 0.09470533579587936, "critic_grad_norm": 0.033973872661590576, "ratio": 1.0002342462539673, "entropy": 0.7046007871627807, "incre_win_rate": 0.975, "step": 1568}
{"time": 1767338489.8928394, "phase": "train", "update": 1569, "total_env_steps": 5020800, "episode_reward": 0.26745444536209106, "value_loss": 0.0022316206246614455, "policy_loss": -0.00135256423907002, "dist_entropy": 0.680131196975708, "actor_grad_norm": 0.10126888751983643, "critic_grad_norm": 0.03511160612106323, "ratio": 1.000386118888855, "entropy": 0.680131196975708, "incre_win_rate": 0.9777777777777777, "step": 1569}
{"time": 1767338494.0217607, "phase": "train", "update": 1570, "total_env_steps": 5024000, "episode_reward": 0.2708076536655426, "value_loss": 0.0030106694903224707, "policy_loss": -0.0011379615533371635, "dist_entropy": 0.6553872466087342, "actor_grad_norm": 0.11169930547475815, "critic_grad_norm": 0.03101968578994274, "ratio": 0.9997133612632751, "entropy": 0.6553872466087342, "incre_win_rate": 0.9534883720930233, "step": 1570}
{"time": 1767338498.1146772, "phase": "train", "update": 1571, "total_env_steps": 5027200, "episode_reward": 0.26561206579208374, "value_loss": 0.007047055568546057, "policy_loss": -0.0014820266880327892, "dist_entropy": 0.6771205544471741, "actor_grad_norm": 0.11614151298999786, "critic_grad_norm": 0.057652588933706284, "ratio": 1.000034213066101, "entropy": 0.6771205544471741, "incre_win_rate": 0.9333333333333333, "step": 1571}
{"time": 1767338502.2129717, "phase": "train", "update": 1572, "total_env_steps": 5030400, "episode_reward": 0.2735140323638916, "value_loss": 0.004007828095927835, "policy_loss": -0.0014349439473932079, "dist_entropy": 0.6915055871009826, "actor_grad_norm": 0.12789152562618256, "critic_grad_norm": 0.061316538602113724, "ratio": 1.0000966787338257, "entropy": 0.6915055871009826, "incre_win_rate": 0.9767441860465116, "step": 1572}
{"time": 1767338506.2717018, "phase": "train", "update": 1573, "total_env_steps": 5033600, "episode_reward": 0.26218336820602417, "value_loss": 0.005659544374793768, "policy_loss": -0.0011895275317279185, "dist_entropy": 0.7048519015312195, "actor_grad_norm": 0.11645114421844482, "critic_grad_norm": 0.0344047024846077, "ratio": 0.9999022483825684, "entropy": 0.7048519015312195, "incre_win_rate": 0.9047619047619048, "step": 1573}
{"time": 1767338510.3646307, "phase": "train", "update": 1574, "total_env_steps": 5036800, "episode_reward": 0.26689985394477844, "value_loss": 0.0040469921194016935, "policy_loss": -0.001037939366824503, "dist_entropy": 0.6933702945709228, "actor_grad_norm": 0.11430197954177856, "critic_grad_norm": 0.017359396442770958, "ratio": 1.0003293752670288, "entropy": 0.6933702945709228, "incre_win_rate": 0.9772727272727273, "step": 1574}
{"time": 1767338514.5088985, "phase": "train", "update": 1575, "total_env_steps": 5040000, "episode_reward": 0.2639564573764801, "value_loss": 0.00689086252823472, "policy_loss": -0.001293439587826839, "dist_entropy": 0.6902432680130005, "actor_grad_norm": 0.1188693642616272, "critic_grad_norm": 0.03974772244691849, "ratio": 0.999835193157196, "entropy": 0.6902432680130005, "incre_win_rate": 0.9047619047619048, "step": 1575}
{"time": 1767338518.5820105, "phase": "train", "update": 1576, "total_env_steps": 5043200, "episode_reward": 0.26026076078414917, "value_loss": 0.004529800731688738, "policy_loss": -0.0013763886778896505, "dist_entropy": 0.6893749117851258, "actor_grad_norm": 0.09877827018499374, "critic_grad_norm": 0.025647541508078575, "ratio": 1.000105857849121, "entropy": 0.6893749117851258, "incre_win_rate": 0.9302325581395349, "step": 1576}
{"time": 1767338528.3150198, "phase": "eval", "update": 1576, "total_env_steps": 5043200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.899317052980134, "step": 1576}
{"time": 1767338532.415445, "phase": "train", "update": 1577, "total_env_steps": 5046400, "episode_reward": 0.26276490092277527, "value_loss": 0.005254034977406263, "policy_loss": -0.0016405867713583434, "dist_entropy": 0.6647776365280151, "actor_grad_norm": 0.0975177213549614, "critic_grad_norm": 0.019259843975305557, "ratio": 1.000064492225647, "entropy": 0.6647776365280151, "incre_win_rate": 0.9069767441860465, "step": 1577}
{"time": 1767338536.5214348, "phase": "train", "update": 1578, "total_env_steps": 5049600, "episode_reward": 0.2647273540496826, "value_loss": 0.0047321667894721035, "policy_loss": -0.0011905195376453292, "dist_entropy": 0.6394797682762146, "actor_grad_norm": 0.09492164105176926, "critic_grad_norm": 0.033472128212451935, "ratio": 0.999728798866272, "entropy": 0.6394797682762146, "incre_win_rate": 0.9090909090909091, "step": 1578}
{"time": 1767338540.6491725, "phase": "train", "update": 1579, "total_env_steps": 5052800, "episode_reward": 0.2694660723209381, "value_loss": 0.0042947250418365005, "policy_loss": -0.001482034543214894, "dist_entropy": 0.6603206515312194, "actor_grad_norm": 0.08900830894708633, "critic_grad_norm": 0.02617434598505497, "ratio": 0.9999074935913086, "entropy": 0.6603206515312194, "incre_win_rate": 0.9772727272727273, "step": 1579}
{"time": 1767338544.805946, "phase": "train", "update": 1580, "total_env_steps": 5056000, "episode_reward": 0.2766970098018646, "value_loss": 0.003855424979701638, "policy_loss": -0.0013937914190172763, "dist_entropy": 0.6478254675865174, "actor_grad_norm": 0.10411502420902252, "critic_grad_norm": 0.019284406676888466, "ratio": 1.0001634359359741, "entropy": 0.6478254675865174, "incre_win_rate": 0.9534883720930233, "step": 1580}
{"time": 1767338548.8773491, "phase": "train", "update": 1581, "total_env_steps": 5059200, "episode_reward": 0.26301687955856323, "value_loss": 0.007872699573636056, "policy_loss": -0.0011700308027293715, "dist_entropy": 0.656866979598999, "actor_grad_norm": 0.10236787796020508, "critic_grad_norm": 0.06886591017246246, "ratio": 0.9998218417167664, "entropy": 0.656866979598999, "incre_win_rate": 0.8695652173913043, "step": 1581}
{"time": 1767338553.0158083, "phase": "train", "update": 1582, "total_env_steps": 5062400, "episode_reward": 0.2726738452911377, "value_loss": 0.0048129185102880005, "policy_loss": -0.0011946002620256025, "dist_entropy": 0.6679335236549377, "actor_grad_norm": 0.10256727784872055, "critic_grad_norm": 0.08529698848724365, "ratio": 0.9999234080314636, "entropy": 0.6679335236549377, "incre_win_rate": 0.9767441860465116, "step": 1582}
{"time": 1767338557.1383102, "phase": "train", "update": 1583, "total_env_steps": 5065600, "episode_reward": 0.2667880952358246, "value_loss": 0.0061437302269041535, "policy_loss": -0.0013315957562198832, "dist_entropy": 0.6921209335327149, "actor_grad_norm": 0.10816369205713272, "critic_grad_norm": 0.06306985765695572, "ratio": 1.0000828504562378, "entropy": 0.6921209335327149, "incre_win_rate": 0.9302325581395349, "step": 1583}
{"time": 1767338561.2641106, "phase": "train", "update": 1584, "total_env_steps": 5068800, "episode_reward": 0.26965540647506714, "value_loss": 0.0035479496233165263, "policy_loss": -0.0008254097796900339, "dist_entropy": 0.6973015069961548, "actor_grad_norm": 0.09538920968770981, "critic_grad_norm": 0.04120047762989998, "ratio": 1.000372290611267, "entropy": 0.6973015069961548, "incre_win_rate": 0.9772727272727273, "step": 1584}
{"time": 1767338565.3550818, "phase": "train", "update": 1585, "total_env_steps": 5072000, "episode_reward": 0.2630639374256134, "value_loss": 0.006869331281632185, "policy_loss": -0.0009976452326100117, "dist_entropy": 0.6908219337463379, "actor_grad_norm": 0.09577029198408127, "critic_grad_norm": 0.053066592663526535, "ratio": 0.9999539256095886, "entropy": 0.6908219337463379, "incre_win_rate": 0.9302325581395349, "step": 1585}
{"time": 1767338569.4603953, "phase": "train", "update": 1586, "total_env_steps": 5075200, "episode_reward": 0.2684597671031952, "value_loss": 0.005710285808891058, "policy_loss": -0.0012141090614497419, "dist_entropy": 0.6870562911033631, "actor_grad_norm": 0.09373405575752258, "critic_grad_norm": 0.04446505755186081, "ratio": 1.000061273574829, "entropy": 0.6870562911033631, "incre_win_rate": 0.9302325581395349, "step": 1586}
{"time": 1767338573.5872061, "phase": "train", "update": 1587, "total_env_steps": 5078400, "episode_reward": 0.25911372900009155, "value_loss": 0.005921065434813499, "policy_loss": -0.0015580083508645259, "dist_entropy": 0.7125568985939026, "actor_grad_norm": 0.09801110625267029, "critic_grad_norm": 0.03128054365515709, "ratio": 0.999817967414856, "entropy": 0.7125568985939026, "incre_win_rate": 0.9285714285714286, "step": 1587}
{"time": 1767338577.7130713, "phase": "train", "update": 1588, "total_env_steps": 5081600, "episode_reward": 0.25635865330696106, "value_loss": 0.011097057349979877, "policy_loss": -0.0009439021108043732, "dist_entropy": 0.7308268547058105, "actor_grad_norm": 0.09020532667636871, "critic_grad_norm": 0.06122482568025589, "ratio": 0.9998846054077148, "entropy": 0.7308268547058105, "incre_win_rate": 0.9302325581395349, "step": 1588}
{"time": 1767338581.8455746, "phase": "train", "update": 1589, "total_env_steps": 5084800, "episode_reward": 0.2686506509780884, "value_loss": 0.005353063344955444, "policy_loss": -0.0012723436239866826, "dist_entropy": 0.7599907040596008, "actor_grad_norm": 0.1061776652932167, "critic_grad_norm": 0.07359343022108078, "ratio": 1.0000568628311157, "entropy": 0.7599907040596008, "incre_win_rate": 0.9767441860465116, "step": 1589}
{"time": 1767338585.9361742, "phase": "train", "update": 1590, "total_env_steps": 5088000, "episode_reward": 0.2512039244174957, "value_loss": 0.008904604241251945, "policy_loss": -0.0009692414717108022, "dist_entropy": 0.7281526088714599, "actor_grad_norm": 0.08724278211593628, "critic_grad_norm": 0.07798197120428085, "ratio": 0.9999292492866516, "entropy": 0.7281526088714599, "incre_win_rate": 0.8372093023255814, "step": 1590}
{"time": 1767338589.9874976, "phase": "train", "update": 1591, "total_env_steps": 5091200, "episode_reward": 0.2472682148218155, "value_loss": 0.008535364642739296, "policy_loss": -0.0010491732190271107, "dist_entropy": 0.7331366062164306, "actor_grad_norm": 0.08875253051519394, "critic_grad_norm": 0.06477435678243637, "ratio": 1.0000405311584473, "entropy": 0.7331366062164306, "incre_win_rate": 0.8536585365853658, "step": 1591}
{"time": 1767338594.0895982, "phase": "train", "update": 1592, "total_env_steps": 5094400, "episode_reward": 0.2592518627643585, "value_loss": 0.008517367579042912, "policy_loss": -0.0011370540104657322, "dist_entropy": 0.7165017485618591, "actor_grad_norm": 0.08147715777158737, "critic_grad_norm": 0.06657315045595169, "ratio": 0.9999251365661621, "entropy": 0.7165017485618591, "incre_win_rate": 0.9024390243902439, "step": 1592}
{"time": 1767338598.1769586, "phase": "train", "update": 1593, "total_env_steps": 5097600, "episode_reward": 0.2531317472457886, "value_loss": 0.00813639247789979, "policy_loss": -0.0012443608037500554, "dist_entropy": 0.7445803999900817, "actor_grad_norm": 0.09347371011972427, "critic_grad_norm": 0.04669862985610962, "ratio": 0.999493420124054, "entropy": 0.7445803999900817, "incre_win_rate": 0.8372093023255814, "step": 1593}
{"time": 1767338602.4455955, "phase": "train", "update": 1594, "total_env_steps": 5100800, "episode_reward": 0.2500186264514923, "value_loss": 0.006099116522818804, "policy_loss": -0.0015673437728882078, "dist_entropy": 0.7377082109451294, "actor_grad_norm": 0.10782723873853683, "critic_grad_norm": 0.03271360695362091, "ratio": 1.000254511833191, "entropy": 0.7377082109451294, "incre_win_rate": 0.8571428571428571, "step": 1594}
{"time": 1767338606.518756, "phase": "train", "update": 1595, "total_env_steps": 5104000, "episode_reward": 0.25985512137413025, "value_loss": 0.007226978149265051, "policy_loss": -0.0013850802889132652, "dist_entropy": 0.7323781490325928, "actor_grad_norm": 0.10831524431705475, "critic_grad_norm": 0.03759351000189781, "ratio": 1.0000523328781128, "entropy": 0.7323781490325928, "incre_win_rate": 0.926829268292683, "step": 1595}
{"time": 1767338610.5874286, "phase": "train", "update": 1596, "total_env_steps": 5107200, "episode_reward": 0.25928807258605957, "value_loss": 0.005141776241362095, "policy_loss": -0.0008522821605748021, "dist_entropy": 0.7388017416000366, "actor_grad_norm": 0.0916985496878624, "critic_grad_norm": 0.02283722721040249, "ratio": 1.000038981437683, "entropy": 0.7388017416000366, "incre_win_rate": 0.9523809523809523, "step": 1596}
{"time": 1767338614.7103965, "phase": "train", "update": 1597, "total_env_steps": 5110400, "episode_reward": 0.2623302936553955, "value_loss": 0.005931110680103302, "policy_loss": -0.0011675982115946226, "dist_entropy": 0.7527611374855041, "actor_grad_norm": 0.09764697402715683, "critic_grad_norm": 0.030485479161143303, "ratio": 0.9995455145835876, "entropy": 0.7527611374855041, "incre_win_rate": 0.9333333333333333, "step": 1597}
{"time": 1767338618.8354058, "phase": "train", "update": 1598, "total_env_steps": 5113600, "episode_reward": 0.266796350479126, "value_loss": 0.004489312507212162, "policy_loss": -0.001128561885499657, "dist_entropy": 0.7637320280075073, "actor_grad_norm": 0.10248314589262009, "critic_grad_norm": 0.030927414074540138, "ratio": 1.0001102685928345, "entropy": 0.7637320280075073, "incre_win_rate": 0.975609756097561, "step": 1598}
{"time": 1767338622.977379, "phase": "train", "update": 1599, "total_env_steps": 5116800, "episode_reward": 0.261323481798172, "value_loss": 0.003152097435668111, "policy_loss": -0.0010592901539141053, "dist_entropy": 0.7673830628395081, "actor_grad_norm": 0.08612339943647385, "critic_grad_norm": 0.03873145580291748, "ratio": 0.9996744394302368, "entropy": 0.7673830628395081, "incre_win_rate": 1.0, "step": 1599}
{"time": 1767338627.1109242, "phase": "train", "update": 1600, "total_env_steps": 5120000, "episode_reward": 0.25824710726737976, "value_loss": 0.0051611274480819706, "policy_loss": -0.0015317052322403768, "dist_entropy": 0.7769583463668823, "actor_grad_norm": 0.09843188524246216, "critic_grad_norm": 0.030088184401392937, "ratio": 0.9997402429580688, "entropy": 0.7769583463668823, "incre_win_rate": 0.9772727272727273, "step": 1600}
{"time": 1767338631.2087455, "phase": "train", "update": 1601, "total_env_steps": 5123200, "episode_reward": 0.2664714455604553, "value_loss": 0.0028536510188132526, "policy_loss": -0.001722001777706339, "dist_entropy": 0.7541600108146668, "actor_grad_norm": 0.09833728522062302, "critic_grad_norm": 0.027541333809494972, "ratio": 0.9999629855155945, "entropy": 0.7541600108146668, "incre_win_rate": 0.975, "step": 1601}
{"time": 1767338641.0092263, "phase": "eval", "update": 1601, "total_env_steps": 5123200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.82822847682119, "step": 1601}
{"time": 1767338645.0944269, "phase": "train", "update": 1602, "total_env_steps": 5126400, "episode_reward": 0.25209593772888184, "value_loss": 0.004733640793710947, "policy_loss": -0.0015562343646315924, "dist_entropy": 0.7441990852355957, "actor_grad_norm": 0.10613778978586197, "critic_grad_norm": 0.04089852049946785, "ratio": 1.000004768371582, "entropy": 0.7441990852355957, "incre_win_rate": 0.9069767441860465, "step": 1602}
{"time": 1767338649.2037337, "phase": "train", "update": 1603, "total_env_steps": 5129600, "episode_reward": 0.2648603320121765, "value_loss": 0.006020543817430735, "policy_loss": -0.0010741602968703744, "dist_entropy": 0.7607017874717712, "actor_grad_norm": 0.10217179358005524, "critic_grad_norm": 0.05805054306983948, "ratio": 1.0000598430633545, "entropy": 0.7607017874717712, "incre_win_rate": 0.8837209302325582, "step": 1603}
{"time": 1767338653.3137813, "phase": "train", "update": 1604, "total_env_steps": 5132800, "episode_reward": 0.2569991648197174, "value_loss": 0.0041517563164234165, "policy_loss": -0.001549934005507936, "dist_entropy": 0.7459871053695679, "actor_grad_norm": 0.09324678778648376, "critic_grad_norm": 0.042784906923770905, "ratio": 0.9999833106994629, "entropy": 0.7459871053695679, "incre_win_rate": 0.975609756097561, "step": 1604}
{"time": 1767338657.4050648, "phase": "train", "update": 1605, "total_env_steps": 5136000, "episode_reward": 0.26592299342155457, "value_loss": 0.005605678446590901, "policy_loss": -0.0014875914982319216, "dist_entropy": 0.709670877456665, "actor_grad_norm": 0.11982691287994385, "critic_grad_norm": 0.031784169375896454, "ratio": 0.9998981356620789, "entropy": 0.709670877456665, "incre_win_rate": 0.9523809523809523, "step": 1605}
{"time": 1767338661.4507427, "phase": "train", "update": 1606, "total_env_steps": 5139200, "episode_reward": 0.2534348964691162, "value_loss": 0.005015592649579048, "policy_loss": -0.0006471916698039592, "dist_entropy": 0.7042585134506225, "actor_grad_norm": 0.11353309452533722, "critic_grad_norm": 0.02955351211130619, "ratio": 0.9996616244316101, "entropy": 0.7042585134506225, "incre_win_rate": 0.9285714285714286, "step": 1606}
{"time": 1767338665.5593781, "phase": "train", "update": 1607, "total_env_steps": 5142400, "episode_reward": 0.26499587297439575, "value_loss": 0.0064226830378174785, "policy_loss": -0.0009746865936573812, "dist_entropy": 0.6810066342353821, "actor_grad_norm": 0.12160437554121017, "critic_grad_norm": 0.02563820593059063, "ratio": 0.9997097849845886, "entropy": 0.6810066342353821, "incre_win_rate": 0.9318181818181818, "step": 1607}
{"time": 1767338669.6436112, "phase": "train", "update": 1608, "total_env_steps": 5145600, "episode_reward": 0.2646481990814209, "value_loss": 0.004646638408303261, "policy_loss": -0.0009671348572297233, "dist_entropy": 0.7246952891349793, "actor_grad_norm": 0.13345389068126678, "critic_grad_norm": 0.031142914667725563, "ratio": 0.9994277954101562, "entropy": 0.7246952891349793, "incre_win_rate": 0.9285714285714286, "step": 1608}
{"time": 1767338673.76714, "phase": "train", "update": 1609, "total_env_steps": 5148800, "episode_reward": 0.26265573501586914, "value_loss": 0.004965448286384344, "policy_loss": -0.0010348208096857547, "dist_entropy": 0.7150775551795959, "actor_grad_norm": 0.11184792965650558, "critic_grad_norm": 0.0484810508787632, "ratio": 1.0001871585845947, "entropy": 0.7150775551795959, "incre_win_rate": 0.9302325581395349, "step": 1609}
{"time": 1767338677.8863964, "phase": "train", "update": 1610, "total_env_steps": 5152000, "episode_reward": 0.2652297019958496, "value_loss": 0.00512430565431714, "policy_loss": -0.0010775849025847605, "dist_entropy": 0.7188617348670959, "actor_grad_norm": 0.10568542778491974, "critic_grad_norm": 0.021759163588285446, "ratio": 0.999537467956543, "entropy": 0.7188617348670959, "incre_win_rate": 0.9534883720930233, "step": 1610}
{"time": 1767338682.01778, "phase": "train", "update": 1611, "total_env_steps": 5155200, "episode_reward": 0.26660287380218506, "value_loss": 0.004596547782421112, "policy_loss": -0.0010977694679993987, "dist_entropy": 0.6968382835388184, "actor_grad_norm": 0.09865670651197433, "critic_grad_norm": 0.04896632954478264, "ratio": 0.9999537467956543, "entropy": 0.6968382835388184, "incre_win_rate": 0.9090909090909091, "step": 1611}
{"time": 1767338686.1147766, "phase": "train", "update": 1612, "total_env_steps": 5158400, "episode_reward": 0.2599281072616577, "value_loss": 0.007213704660534859, "policy_loss": -0.001308496330103992, "dist_entropy": 0.7065117955207825, "actor_grad_norm": 0.11129998415708542, "critic_grad_norm": 0.03013755939900875, "ratio": 0.9999364018440247, "entropy": 0.7065117955207825, "incre_win_rate": 0.9302325581395349, "step": 1612}
{"time": 1767338690.2410412, "phase": "train", "update": 1613, "total_env_steps": 5161600, "episode_reward": 0.26629140973091125, "value_loss": 0.00812613097950816, "policy_loss": -0.0015501853043986102, "dist_entropy": 0.7249807119369507, "actor_grad_norm": 0.11917421966791153, "critic_grad_norm": 0.03854404762387276, "ratio": 0.9998421669006348, "entropy": 0.7249807119369507, "incre_win_rate": 0.9318181818181818, "step": 1613}
{"time": 1767338694.3537567, "phase": "train", "update": 1614, "total_env_steps": 5164800, "episode_reward": 0.27451056241989136, "value_loss": 0.0065523780882358554, "policy_loss": -0.0012323238348027842, "dist_entropy": 0.7373351335525513, "actor_grad_norm": 0.12424256652593613, "critic_grad_norm": 0.03752708435058594, "ratio": 1.0002754926681519, "entropy": 0.7373351335525513, "incre_win_rate": 1.0, "step": 1614}
{"time": 1767338698.4489307, "phase": "train", "update": 1615, "total_env_steps": 5168000, "episode_reward": 0.26208198070526123, "value_loss": 0.005315548088401556, "policy_loss": -0.0011599913884218437, "dist_entropy": 0.742975401878357, "actor_grad_norm": 0.09683696925640106, "critic_grad_norm": 0.058171819895505905, "ratio": 1.000016212463379, "entropy": 0.742975401878357, "incre_win_rate": 0.9534883720930233, "step": 1615}
{"time": 1767338702.5728602, "phase": "train", "update": 1616, "total_env_steps": 5171200, "episode_reward": 0.2598106265068054, "value_loss": 0.005481872614473105, "policy_loss": -0.0013390306312047074, "dist_entropy": 0.7566929936408997, "actor_grad_norm": 0.11207359284162521, "critic_grad_norm": 0.05947059392929077, "ratio": 0.9999536871910095, "entropy": 0.7566929936408997, "incre_win_rate": 0.8837209302325582, "step": 1616}
{"time": 1767338706.6775444, "phase": "train", "update": 1617, "total_env_steps": 5174400, "episode_reward": 0.26400354504585266, "value_loss": 0.006249439064413309, "policy_loss": -0.00092297244295807, "dist_entropy": 0.7531720519065856, "actor_grad_norm": 0.10373349487781525, "critic_grad_norm": 0.031363844871520996, "ratio": 0.9997269511222839, "entropy": 0.7531720519065856, "incre_win_rate": 0.9069767441860465, "step": 1617}
{"time": 1767338710.8072717, "phase": "train", "update": 1618, "total_env_steps": 5177600, "episode_reward": 0.2675248384475708, "value_loss": 0.006128512602299452, "policy_loss": -0.0009008626511963769, "dist_entropy": 0.7767166495323181, "actor_grad_norm": 0.09943949431180954, "critic_grad_norm": 0.052347492426633835, "ratio": 0.9998793601989746, "entropy": 0.7767166495323181, "incre_win_rate": 0.9523809523809523, "step": 1618}
{"time": 1767338714.9255073, "phase": "train", "update": 1619, "total_env_steps": 5180800, "episode_reward": 0.2575947046279907, "value_loss": 0.005697561241686344, "policy_loss": -0.0008568097870568891, "dist_entropy": 0.7765934109687805, "actor_grad_norm": 0.10705657303333282, "critic_grad_norm": 0.03509625419974327, "ratio": 1.0003012418746948, "entropy": 0.7765934109687805, "incre_win_rate": 0.9534883720930233, "step": 1619}
{"time": 1767338719.0302608, "phase": "train", "update": 1620, "total_env_steps": 5184000, "episode_reward": 0.2595348656177521, "value_loss": 0.005417745187878608, "policy_loss": -0.001035983556914033, "dist_entropy": 0.7942154765129089, "actor_grad_norm": 0.0992872565984726, "critic_grad_norm": 0.041367195546627045, "ratio": 1.0004937648773193, "entropy": 0.7942154765129089, "incre_win_rate": 0.9069767441860465, "step": 1620}
{"time": 1767338723.1675088, "phase": "train", "update": 1621, "total_env_steps": 5187200, "episode_reward": 0.255016028881073, "value_loss": 0.004889693204313516, "policy_loss": -0.001176516899760216, "dist_entropy": 0.7801187753677368, "actor_grad_norm": 0.0905376672744751, "critic_grad_norm": 0.030910996720194817, "ratio": 0.9999775886535645, "entropy": 0.7801187753677368, "incre_win_rate": 0.9024390243902439, "step": 1621}
{"time": 1767338727.248185, "phase": "train", "update": 1622, "total_env_steps": 5190400, "episode_reward": 0.24775302410125732, "value_loss": 0.00932079777121544, "policy_loss": -0.001127270902061639, "dist_entropy": 0.7555801033973694, "actor_grad_norm": 0.09247162938117981, "critic_grad_norm": 0.05928411707282066, "ratio": 0.9998307228088379, "entropy": 0.7555801033973694, "incre_win_rate": 0.7727272727272727, "step": 1622}
{"time": 1767338731.3838391, "phase": "train", "update": 1623, "total_env_steps": 5193600, "episode_reward": 0.26281559467315674, "value_loss": 0.0062947990372776985, "policy_loss": -0.000987367075926926, "dist_entropy": 0.776942777633667, "actor_grad_norm": 0.09780003875494003, "critic_grad_norm": 0.04341993108391762, "ratio": 0.9999163746833801, "entropy": 0.776942777633667, "incre_win_rate": 0.925, "step": 1623}
{"time": 1767338735.5640705, "phase": "train", "update": 1624, "total_env_steps": 5196800, "episode_reward": 0.2621368169784546, "value_loss": 0.007053649611771106, "policy_loss": -0.0012912865568353027, "dist_entropy": 0.7599105119705201, "actor_grad_norm": 0.09930445998907089, "critic_grad_norm": 0.038267310708761215, "ratio": 0.9998540282249451, "entropy": 0.7599105119705201, "incre_win_rate": 0.9318181818181818, "step": 1624}
{"time": 1767338739.697824, "phase": "train", "update": 1625, "total_env_steps": 5200000, "episode_reward": 0.2650744915008545, "value_loss": 0.006457273382693529, "policy_loss": -0.0011509698695931548, "dist_entropy": 0.7572662472724915, "actor_grad_norm": 0.102491594851017, "critic_grad_norm": 0.05139279365539551, "ratio": 0.9999783635139465, "entropy": 0.7572662472724915, "incre_win_rate": 0.8604651162790697, "step": 1625}
{"time": 1767338743.7993736, "phase": "train", "update": 1626, "total_env_steps": 5203200, "episode_reward": 0.25941067934036255, "value_loss": 0.009399671107530594, "policy_loss": -0.0008702645876695669, "dist_entropy": 0.7357093334197998, "actor_grad_norm": 0.10001631081104279, "critic_grad_norm": 0.08857792615890503, "ratio": 0.9997658729553223, "entropy": 0.7357093334197998, "incre_win_rate": 0.8444444444444444, "step": 1626}
{"time": 1767338753.6949797, "phase": "eval", "update": 1626, "total_env_steps": 5203200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.92301324503311, "step": 1626}
{"time": 1767338757.8011563, "phase": "train", "update": 1627, "total_env_steps": 5206400, "episode_reward": 0.27337852120399475, "value_loss": 0.005122439283877611, "policy_loss": -0.0015626461511033085, "dist_entropy": 0.7572338342666626, "actor_grad_norm": 0.10142689198255539, "critic_grad_norm": 0.06167006492614746, "ratio": 1.0000743865966797, "entropy": 0.7572338342666626, "incre_win_rate": 0.9333333333333333, "step": 1627}
{"time": 1767338761.9406545, "phase": "train", "update": 1628, "total_env_steps": 5209600, "episode_reward": 0.2718501687049866, "value_loss": 0.004401099868118763, "policy_loss": -0.001351237339528666, "dist_entropy": 0.76833176612854, "actor_grad_norm": 0.09023826569318771, "critic_grad_norm": 0.05030260607600212, "ratio": 0.9996490478515625, "entropy": 0.76833176612854, "incre_win_rate": 0.926829268292683, "step": 1628}
{"time": 1767338766.0763195, "phase": "train", "update": 1629, "total_env_steps": 5212800, "episode_reward": 0.269182026386261, "value_loss": 0.004665244836360216, "policy_loss": -0.0013485635498092564, "dist_entropy": 0.7690333008766175, "actor_grad_norm": 0.11109597980976105, "critic_grad_norm": 0.04137284308671951, "ratio": 1.000100016593933, "entropy": 0.7690333008766175, "incre_win_rate": 0.9565217391304348, "step": 1629}
{"time": 1767338770.210245, "phase": "train", "update": 1630, "total_env_steps": 5216000, "episode_reward": 0.26974958181381226, "value_loss": 0.0049057619646191595, "policy_loss": -0.0010328854917887043, "dist_entropy": 0.7765032052993774, "actor_grad_norm": 0.1022879034280777, "critic_grad_norm": 0.03280746191740036, "ratio": 0.9999516606330872, "entropy": 0.7765032052993774, "incre_win_rate": 0.926829268292683, "step": 1630}
{"time": 1767338774.3366618, "phase": "train", "update": 1631, "total_env_steps": 5219200, "episode_reward": 0.2681177854537964, "value_loss": 0.003999229008331895, "policy_loss": -0.0008998886398764227, "dist_entropy": 0.7626322865486145, "actor_grad_norm": 0.08034222573041916, "critic_grad_norm": 0.036151137202978134, "ratio": 0.9997329711914062, "entropy": 0.7626322865486145, "incre_win_rate": 0.9777777777777777, "step": 1631}
{"time": 1767338778.4316971, "phase": "train", "update": 1632, "total_env_steps": 5222400, "episode_reward": 0.2726815938949585, "value_loss": 0.004438740760087967, "policy_loss": -0.0014561036343664568, "dist_entropy": 0.7533804059028626, "actor_grad_norm": 0.09340747445821762, "critic_grad_norm": 0.035504501312971115, "ratio": 0.9999025464057922, "entropy": 0.7533804059028626, "incre_win_rate": 0.9767441860465116, "step": 1632}
{"time": 1767338782.5494652, "phase": "train", "update": 1633, "total_env_steps": 5225600, "episode_reward": 0.26718077063560486, "value_loss": 0.004132150486111641, "policy_loss": -0.0011233003254048413, "dist_entropy": 0.738536286354065, "actor_grad_norm": 0.10647433996200562, "critic_grad_norm": 0.038119297474622726, "ratio": 0.9995872378349304, "entropy": 0.738536286354065, "incre_win_rate": 0.9555555555555556, "step": 1633}
{"time": 1767338811.2893982, "phase": "train", "update": 1634, "total_env_steps": 5228800, "episode_reward": 0.26472681760787964, "value_loss": 0.045569700002670285, "policy_loss": -0.0008737606455667901, "dist_entropy": 0.7399497747421264, "actor_grad_norm": 0.09226558357477188, "critic_grad_norm": 0.15392005443572998, "ratio": 0.9998793005943298, "entropy": 0.7399497747421264, "incre_win_rate": 0.9512195121951219, "step": 1634}
{"time": 1767338815.4129362, "phase": "train", "update": 1635, "total_env_steps": 5232000, "episode_reward": 0.268497496843338, "value_loss": 0.005733817163854837, "policy_loss": -0.0010464123653674661, "dist_entropy": 0.730616569519043, "actor_grad_norm": 0.08936340361833572, "critic_grad_norm": 0.1656903326511383, "ratio": 0.9997159838676453, "entropy": 0.730616569519043, "incre_win_rate": 0.9512195121951219, "step": 1635}
{"time": 1767338819.5536923, "phase": "train", "update": 1636, "total_env_steps": 5235200, "episode_reward": 0.27867135405540466, "value_loss": 0.0039715302176773545, "policy_loss": -0.0009705811663664576, "dist_entropy": 0.7469009757041931, "actor_grad_norm": 0.08829248696565628, "critic_grad_norm": 0.1368899643421173, "ratio": 1.0006054639816284, "entropy": 0.7469009757041931, "incre_win_rate": 1.0, "step": 1636}
{"time": 1767338823.6983721, "phase": "train", "update": 1637, "total_env_steps": 5238400, "episode_reward": 0.26898592710494995, "value_loss": 0.007337966188788414, "policy_loss": -0.0012500261119669175, "dist_entropy": 0.7355976343154907, "actor_grad_norm": 0.074099600315094, "critic_grad_norm": 0.05521411448717117, "ratio": 1.0000791549682617, "entropy": 0.7355976343154907, "incre_win_rate": 0.9318181818181818, "step": 1637}
{"time": 1767338827.824842, "phase": "train", "update": 1638, "total_env_steps": 5241600, "episode_reward": 0.264027863740921, "value_loss": 0.012646205350756645, "policy_loss": -0.0017493101425117175, "dist_entropy": 0.7329922318458557, "actor_grad_norm": 0.08747860044240952, "critic_grad_norm": 0.09901686757802963, "ratio": 0.999554455280304, "entropy": 0.7329922318458557, "incre_win_rate": 0.8636363636363636, "step": 1638}
{"time": 1767338831.9552634, "phase": "train", "update": 1639, "total_env_steps": 5244800, "episode_reward": 0.258732408285141, "value_loss": 0.0064114629290997985, "policy_loss": -0.0012371528273444454, "dist_entropy": 0.7413031578063964, "actor_grad_norm": 0.08635465055704117, "critic_grad_norm": 0.05966358259320259, "ratio": 0.9996846318244934, "entropy": 0.7413031578063964, "incre_win_rate": 0.9333333333333333, "step": 1639}
{"time": 1767338836.0899332, "phase": "train", "update": 1640, "total_env_steps": 5248000, "episode_reward": 0.26802462339401245, "value_loss": 0.005887832958251238, "policy_loss": -0.0015233249843696229, "dist_entropy": 0.7423890829086304, "actor_grad_norm": 0.09236893802881241, "critic_grad_norm": 0.04152766615152359, "ratio": 1.000322937965393, "entropy": 0.7423890829086304, "incre_win_rate": 0.926829268292683, "step": 1640}
{"time": 1767338840.2356648, "phase": "train", "update": 1641, "total_env_steps": 5251200, "episode_reward": 0.2643180787563324, "value_loss": 0.009136047959327698, "policy_loss": -0.0016916499597058987, "dist_entropy": 0.7673412084579467, "actor_grad_norm": 0.1223183274269104, "critic_grad_norm": 0.05442031845450401, "ratio": 0.9996876120567322, "entropy": 0.7673412084579467, "incre_win_rate": 0.9090909090909091, "step": 1641}
{"time": 1767338844.349232, "phase": "train", "update": 1642, "total_env_steps": 5254400, "episode_reward": 0.2529403269290924, "value_loss": 0.00721405390650034, "policy_loss": -0.001090434321814726, "dist_entropy": 0.774626100063324, "actor_grad_norm": 0.09506811946630478, "critic_grad_norm": 0.020674755796790123, "ratio": 0.999488353729248, "entropy": 0.774626100063324, "incre_win_rate": 0.8666666666666667, "step": 1642}
{"time": 1767338848.4756026, "phase": "train", "update": 1643, "total_env_steps": 5257600, "episode_reward": 0.2569872736930847, "value_loss": 0.009127936512231826, "policy_loss": -0.0013025429551959179, "dist_entropy": 0.764538586139679, "actor_grad_norm": 0.0926605835556984, "critic_grad_norm": 0.03935645893216133, "ratio": 0.999705970287323, "entropy": 0.764538586139679, "incre_win_rate": 0.8536585365853658, "step": 1643}
{"time": 1767338852.5704834, "phase": "train", "update": 1644, "total_env_steps": 5260800, "episode_reward": 0.25607356429100037, "value_loss": 0.006995448656380176, "policy_loss": -0.0011491148187239952, "dist_entropy": 0.7815426468849183, "actor_grad_norm": 0.10396943241357803, "critic_grad_norm": 0.05003097280859947, "ratio": 1.0004466772079468, "entropy": 0.7815426468849183, "incre_win_rate": 0.8780487804878049, "step": 1644}
{"time": 1767338856.704027, "phase": "train", "update": 1645, "total_env_steps": 5264000, "episode_reward": 0.2541447877883911, "value_loss": 0.012396652065217496, "policy_loss": -0.0010207598760509028, "dist_entropy": 0.7694185853004456, "actor_grad_norm": 0.08606986701488495, "critic_grad_norm": 0.059678591787815094, "ratio": 1.000090479850769, "entropy": 0.7694185853004456, "incre_win_rate": 0.8837209302325582, "step": 1645}
{"time": 1767338860.8468726, "phase": "train", "update": 1646, "total_env_steps": 5267200, "episode_reward": 0.2736072242259979, "value_loss": 0.007529423944652081, "policy_loss": -0.0010119929512690362, "dist_entropy": 0.7688124775886536, "actor_grad_norm": 0.08457846939563751, "critic_grad_norm": 0.08069130778312683, "ratio": 1.000121831893921, "entropy": 0.7688124775886536, "incre_win_rate": 0.9555555555555556, "step": 1646}
{"time": 1767338864.9737692, "phase": "train", "update": 1647, "total_env_steps": 5270400, "episode_reward": 0.260053813457489, "value_loss": 0.005119969882071018, "policy_loss": -0.0013211973107289054, "dist_entropy": 0.7651706814765931, "actor_grad_norm": 0.0821058377623558, "critic_grad_norm": 0.045314181596040726, "ratio": 1.0000077486038208, "entropy": 0.7651706814765931, "incre_win_rate": 0.9047619047619048, "step": 1647}
{"time": 1767338869.089389, "phase": "train", "update": 1648, "total_env_steps": 5273600, "episode_reward": 0.2716520130634308, "value_loss": 0.005202268622815609, "policy_loss": -0.0013244709772095575, "dist_entropy": 0.7437804579734802, "actor_grad_norm": 0.0802498385310173, "critic_grad_norm": 0.02678634598851204, "ratio": 1.0000849962234497, "entropy": 0.7437804579734802, "incre_win_rate": 0.9318181818181818, "step": 1648}
{"time": 1767338873.203625, "phase": "train", "update": 1649, "total_env_steps": 5276800, "episode_reward": 0.2651531398296356, "value_loss": 0.004945340659469366, "policy_loss": -0.0015676344179444634, "dist_entropy": 0.7392011880874634, "actor_grad_norm": 0.10403072834014893, "critic_grad_norm": 0.027360452339053154, "ratio": 0.999516487121582, "entropy": 0.7392011880874634, "incre_win_rate": 0.9534883720930233, "step": 1649}
{"time": 1767338877.3049068, "phase": "train", "update": 1650, "total_env_steps": 5280000, "episode_reward": 0.2684188783168793, "value_loss": 0.0035510768182575704, "policy_loss": -0.0010714376588644825, "dist_entropy": 0.755340039730072, "actor_grad_norm": 0.09887950867414474, "critic_grad_norm": 0.02783098816871643, "ratio": 0.9999746680259705, "entropy": 0.755340039730072, "incre_win_rate": 0.9772727272727273, "step": 1650}
{"time": 1767338881.4371657, "phase": "train", "update": 1651, "total_env_steps": 5283200, "episode_reward": 0.26962336897850037, "value_loss": 0.0027256306260824204, "policy_loss": -0.0014406436313350924, "dist_entropy": 0.7762381076812744, "actor_grad_norm": 0.11306878179311752, "critic_grad_norm": 0.020821407437324524, "ratio": 0.9997918009757996, "entropy": 0.7762381076812744, "incre_win_rate": 0.9767441860465116, "step": 1651}
{"time": 1767338891.2833967, "phase": "eval", "update": 1651, "total_env_steps": 5283200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.855132450331126, "step": 1651}
{"time": 1767338895.3803682, "phase": "train", "update": 1652, "total_env_steps": 5286400, "episode_reward": 0.25234687328338623, "value_loss": 0.0070566973648965355, "policy_loss": -0.0012058664981330126, "dist_entropy": 0.7669956803321838, "actor_grad_norm": 0.09925365447998047, "critic_grad_norm": 0.06300800293684006, "ratio": 1.000022053718567, "entropy": 0.7669956803321838, "incre_win_rate": 0.8095238095238095, "step": 1652}
{"time": 1767338899.458892, "phase": "train", "update": 1653, "total_env_steps": 5289600, "episode_reward": 0.25923067331314087, "value_loss": 0.006543580908328295, "policy_loss": -0.001249939801487443, "dist_entropy": 0.7754289984703064, "actor_grad_norm": 0.10286996513605118, "critic_grad_norm": 0.030858639627695084, "ratio": 0.999782383441925, "entropy": 0.7754289984703064, "incre_win_rate": 0.9024390243902439, "step": 1653}
{"time": 1767338903.5707867, "phase": "train", "update": 1654, "total_env_steps": 5292800, "episode_reward": 0.2576981484889984, "value_loss": 0.006414683163166046, "policy_loss": -0.0011257802644781378, "dist_entropy": 0.7726810812950134, "actor_grad_norm": 0.09911568462848663, "critic_grad_norm": 0.012988762930035591, "ratio": 1.0003689527511597, "entropy": 0.7726810812950134, "incre_win_rate": 0.8571428571428571, "step": 1654}
{"time": 1767338907.674452, "phase": "train", "update": 1655, "total_env_steps": 5296000, "episode_reward": 0.2592798173427582, "value_loss": 0.0053507999517023565, "policy_loss": -0.0008301986083619539, "dist_entropy": 0.7794987797737122, "actor_grad_norm": 0.08666872978210449, "critic_grad_norm": 0.021526364609599113, "ratio": 0.9998131990432739, "entropy": 0.7794987797737122, "incre_win_rate": 0.9333333333333333, "step": 1655}
{"time": 1767338911.7573261, "phase": "train", "update": 1656, "total_env_steps": 5299200, "episode_reward": 0.24944278597831726, "value_loss": 0.012828882224857808, "policy_loss": -0.0017491519847727232, "dist_entropy": 0.761692488193512, "actor_grad_norm": 0.10048641264438629, "critic_grad_norm": 0.10245483368635178, "ratio": 0.9993730783462524, "entropy": 0.761692488193512, "incre_win_rate": 0.7804878048780488, "step": 1656}
{"time": 1767338915.858118, "phase": "train", "update": 1657, "total_env_steps": 5302400, "episode_reward": 0.25039634108543396, "value_loss": 0.00956608485430479, "policy_loss": -0.0007734796071275696, "dist_entropy": 0.7545204281806945, "actor_grad_norm": 0.08045642077922821, "critic_grad_norm": 0.0633569061756134, "ratio": 0.9999111294746399, "entropy": 0.7545204281806945, "incre_win_rate": 0.813953488372093, "step": 1657}
{"time": 1767338919.9500453, "phase": "train", "update": 1658, "total_env_steps": 5305600, "episode_reward": 0.26740479469299316, "value_loss": 0.007629262283444405, "policy_loss": -0.001286797228577541, "dist_entropy": 0.7627423167228699, "actor_grad_norm": 0.0876694992184639, "critic_grad_norm": 0.04144394025206566, "ratio": 1.000054955482483, "entropy": 0.7627423167228699, "incre_win_rate": 0.9767441860465116, "step": 1658}
{"time": 1767338924.0426204, "phase": "train", "update": 1659, "total_env_steps": 5308800, "episode_reward": 0.24981790781021118, "value_loss": 0.009347617998719216, "policy_loss": -0.0012053712171588237, "dist_entropy": 0.761974573135376, "actor_grad_norm": 0.08563078194856644, "critic_grad_norm": 0.0326673649251461, "ratio": 0.9999610781669617, "entropy": 0.761974573135376, "incre_win_rate": 0.813953488372093, "step": 1659}
{"time": 1767338928.1185272, "phase": "train", "update": 1660, "total_env_steps": 5312000, "episode_reward": 0.2599208354949951, "value_loss": 0.00638099005445838, "policy_loss": -0.0010118502085942227, "dist_entropy": 0.7453922986984253, "actor_grad_norm": 0.08900898694992065, "critic_grad_norm": 0.026231730356812477, "ratio": 1.0000261068344116, "entropy": 0.7453922986984253, "incre_win_rate": 0.8571428571428571, "step": 1660}
{"time": 1767338932.2135437, "phase": "train", "update": 1661, "total_env_steps": 5315200, "episode_reward": 0.26452401280403137, "value_loss": 0.0071648889221251014, "policy_loss": -0.0014217615979688959, "dist_entropy": 0.7340900063514709, "actor_grad_norm": 0.10100188106298447, "critic_grad_norm": 0.03640703856945038, "ratio": 0.9998493194580078, "entropy": 0.7340900063514709, "incre_win_rate": 0.9318181818181818, "step": 1661}
{"time": 1767338936.3540552, "phase": "train", "update": 1662, "total_env_steps": 5318400, "episode_reward": 0.2602561116218567, "value_loss": 0.007117218803614378, "policy_loss": -0.0010993825376949928, "dist_entropy": 0.7253857493400574, "actor_grad_norm": 0.10732974112033844, "critic_grad_norm": 0.05004359409213066, "ratio": 1.0003632307052612, "entropy": 0.7253857493400574, "incre_win_rate": 0.9069767441860465, "step": 1662}
{"time": 1767338940.4897573, "phase": "train", "update": 1663, "total_env_steps": 5321600, "episode_reward": 0.2697557806968689, "value_loss": 0.005443772114813328, "policy_loss": -0.000775741040441602, "dist_entropy": 0.7183554410934448, "actor_grad_norm": 0.08236852288246155, "critic_grad_norm": 0.04611220583319664, "ratio": 0.9999060034751892, "entropy": 0.7183554410934448, "incre_win_rate": 0.9302325581395349, "step": 1663}
{"time": 1767338944.62578, "phase": "train", "update": 1664, "total_env_steps": 5324800, "episode_reward": 0.2736967206001282, "value_loss": 0.002923468966037035, "policy_loss": -0.0013230157278453446, "dist_entropy": 0.733275043964386, "actor_grad_norm": 0.0974293202161789, "critic_grad_norm": 0.015679724514484406, "ratio": 0.9997323155403137, "entropy": 0.733275043964386, "incre_win_rate": 0.9767441860465116, "step": 1664}
{"time": 1767338948.7310708, "phase": "train", "update": 1665, "total_env_steps": 5328000, "episode_reward": 0.2606539726257324, "value_loss": 0.005388169828802347, "policy_loss": -0.001019477922867651, "dist_entropy": 0.7367819428443909, "actor_grad_norm": 0.07701288908720016, "critic_grad_norm": 0.05728388950228691, "ratio": 0.9997448325157166, "entropy": 0.7367819428443909, "incre_win_rate": 0.9069767441860465, "step": 1665}
{"time": 1767338952.8878314, "phase": "train", "update": 1666, "total_env_steps": 5331200, "episode_reward": 0.263095498085022, "value_loss": 0.007593766786158085, "policy_loss": -0.0012253843571365052, "dist_entropy": 0.7615324258804321, "actor_grad_norm": 0.07455891370773315, "critic_grad_norm": 0.03717784211039543, "ratio": 1.0000269412994385, "entropy": 0.7615324258804321, "incre_win_rate": 0.8888888888888888, "step": 1666}
{"time": 1767338957.034748, "phase": "train", "update": 1667, "total_env_steps": 5334400, "episode_reward": 0.2544541656970978, "value_loss": 0.00946362130343914, "policy_loss": -0.0011856331484267457, "dist_entropy": 0.7547177672386169, "actor_grad_norm": 0.07419638335704803, "critic_grad_norm": 0.023889299482107162, "ratio": 0.9995515942573547, "entropy": 0.7547177672386169, "incre_win_rate": 0.8333333333333334, "step": 1667}
{"time": 1767338961.120422, "phase": "train", "update": 1668, "total_env_steps": 5337600, "episode_reward": 0.2559856176376343, "value_loss": 0.007189826108515263, "policy_loss": -0.0010549942232369602, "dist_entropy": 0.7502898693084716, "actor_grad_norm": 0.06627126783132553, "critic_grad_norm": 0.02788587473332882, "ratio": 0.9999505877494812, "entropy": 0.7502898693084716, "incre_win_rate": 0.8809523809523809, "step": 1668}
{"time": 1767338965.28837, "phase": "train", "update": 1669, "total_env_steps": 5340800, "episode_reward": 0.2643873989582062, "value_loss": 0.006848239805549383, "policy_loss": -0.0016373683355489278, "dist_entropy": 0.7362241983413697, "actor_grad_norm": 0.09620445221662521, "critic_grad_norm": 0.032880932092666626, "ratio": 1.0003572702407837, "entropy": 0.7362241983413697, "incre_win_rate": 0.8636363636363636, "step": 1669}
{"time": 1767338969.3989594, "phase": "train", "update": 1670, "total_env_steps": 5344000, "episode_reward": 0.2659602761268616, "value_loss": 0.003911022190004587, "policy_loss": -0.0012444114968253928, "dist_entropy": 0.7399648904800415, "actor_grad_norm": 0.10439068078994751, "critic_grad_norm": 0.01879465952515602, "ratio": 0.9999780058860779, "entropy": 0.7399648904800415, "incre_win_rate": 0.9069767441860465, "step": 1670}
{"time": 1767338973.5158749, "phase": "train", "update": 1671, "total_env_steps": 5347200, "episode_reward": 0.2725869119167328, "value_loss": 0.0037765469402074813, "policy_loss": -0.0016585106333337762, "dist_entropy": 0.7191996097564697, "actor_grad_norm": 0.10610198229551315, "critic_grad_norm": 0.02332470938563347, "ratio": 0.9999618530273438, "entropy": 0.7191996097564697, "incre_win_rate": 0.9767441860465116, "step": 1671}
{"time": 1767338977.6390681, "phase": "train", "update": 1672, "total_env_steps": 5350400, "episode_reward": 0.2707279622554779, "value_loss": 0.00442035598680377, "policy_loss": -0.000910598651749961, "dist_entropy": 0.6912295103073121, "actor_grad_norm": 0.08030425012111664, "critic_grad_norm": 0.017285181209445, "ratio": 0.9999845623970032, "entropy": 0.6912295103073121, "incre_win_rate": 0.9545454545454546, "step": 1672}
{"time": 1767338981.718561, "phase": "train", "update": 1673, "total_env_steps": 5353600, "episode_reward": 0.2572609782218933, "value_loss": 0.005734162870794535, "policy_loss": -0.0014512537333477126, "dist_entropy": 0.6632206201553345, "actor_grad_norm": 0.07994696497917175, "critic_grad_norm": 0.021476231515407562, "ratio": 1.0001202821731567, "entropy": 0.6632206201553345, "incre_win_rate": 0.9302325581395349, "step": 1673}
{"time": 1767338985.8280294, "phase": "train", "update": 1674, "total_env_steps": 5356800, "episode_reward": 0.27366310358047485, "value_loss": 0.00565075296908617, "policy_loss": -0.0012895435648662356, "dist_entropy": 0.6649680018424988, "actor_grad_norm": 0.10394861549139023, "critic_grad_norm": 0.029521910473704338, "ratio": 0.9999162554740906, "entropy": 0.6649680018424988, "incre_win_rate": 0.9111111111111111, "step": 1674}
{"time": 1767338989.9344084, "phase": "train", "update": 1675, "total_env_steps": 5360000, "episode_reward": 0.27102237939834595, "value_loss": 0.00786596005782485, "policy_loss": -0.0013047297981297668, "dist_entropy": 0.6604295134544372, "actor_grad_norm": 0.08192814886569977, "critic_grad_norm": 0.027364332228899002, "ratio": 0.9998011589050293, "entropy": 0.6604295134544372, "incre_win_rate": 0.9534883720930233, "step": 1675}
{"time": 1767338994.0161042, "phase": "train", "update": 1676, "total_env_steps": 5363200, "episode_reward": 0.2626489996910095, "value_loss": 0.0064502890221774575, "policy_loss": -0.0012470844401441638, "dist_entropy": 0.6625889301300049, "actor_grad_norm": 0.09882541745901108, "critic_grad_norm": 0.030666841194033623, "ratio": 1.0001730918884277, "entropy": 0.6625889301300049, "incre_win_rate": 0.9318181818181818, "step": 1676}
{"time": 1767339003.7336164, "phase": "eval", "update": 1676, "total_env_steps": 5363200, "eval_win_rate": 1.0, "eval_episode_reward": 20.001655629139073, "step": 1676}
{"time": 1767339007.8402867, "phase": "train", "update": 1677, "total_env_steps": 5366400, "episode_reward": 0.27765312790870667, "value_loss": 0.004073462635278702, "policy_loss": -0.0013918686690139737, "dist_entropy": 0.6808661222457886, "actor_grad_norm": 0.09104909747838974, "critic_grad_norm": 0.030774960294365883, "ratio": 0.9994847178459167, "entropy": 0.6808661222457886, "incre_win_rate": 0.9772727272727273, "step": 1677}
{"time": 1767339011.9448845, "phase": "train", "update": 1678, "total_env_steps": 5369600, "episode_reward": 0.26156872510910034, "value_loss": 0.007428648881614208, "policy_loss": -0.0016149460176752227, "dist_entropy": 0.6773160457611084, "actor_grad_norm": 0.07355604320764542, "critic_grad_norm": 0.03306223824620247, "ratio": 1.00019109249115, "entropy": 0.6773160457611084, "incre_win_rate": 0.8636363636363636, "step": 1678}
{"time": 1767339016.0802696, "phase": "train", "update": 1679, "total_env_steps": 5372800, "episode_reward": 0.27427566051483154, "value_loss": 0.003076124843209982, "policy_loss": -0.001419815760814913, "dist_entropy": 0.6822274208068848, "actor_grad_norm": 0.08892165869474411, "critic_grad_norm": 0.042238205671310425, "ratio": 1.000008463859558, "entropy": 0.6822274208068848, "incre_win_rate": 0.9767441860465116, "step": 1679}
{"time": 1767339020.197963, "phase": "train", "update": 1680, "total_env_steps": 5376000, "episode_reward": 0.26716992259025574, "value_loss": 0.005887307785451412, "policy_loss": -0.001228002956088403, "dist_entropy": 0.6753291010856628, "actor_grad_norm": 0.08191263675689697, "critic_grad_norm": 0.05207003280520439, "ratio": 0.999811589717865, "entropy": 0.6753291010856628, "incre_win_rate": 0.9090909090909091, "step": 1680}
{"time": 1767339024.302949, "phase": "train", "update": 1681, "total_env_steps": 5379200, "episode_reward": 0.27373966574668884, "value_loss": 0.005610096734017134, "policy_loss": -0.0012943523765486021, "dist_entropy": 0.6996994972229004, "actor_grad_norm": 0.09183768182992935, "critic_grad_norm": 0.03821548447012901, "ratio": 0.9995892643928528, "entropy": 0.6996994972229004, "incre_win_rate": 0.9555555555555556, "step": 1681}
{"time": 1767339028.393981, "phase": "train", "update": 1682, "total_env_steps": 5382400, "episode_reward": 0.2662789821624756, "value_loss": 0.004465035814791918, "policy_loss": -0.0011955241788458083, "dist_entropy": 0.699402678012848, "actor_grad_norm": 0.09847928583621979, "critic_grad_norm": 0.021324267610907555, "ratio": 0.9999234080314636, "entropy": 0.699402678012848, "incre_win_rate": 0.9534883720930233, "step": 1682}
{"time": 1767339032.5075989, "phase": "train", "update": 1683, "total_env_steps": 5385600, "episode_reward": 0.26862791180610657, "value_loss": 0.004962062742561102, "policy_loss": -0.0010780189533790008, "dist_entropy": 0.6835366129875183, "actor_grad_norm": 0.09560080617666245, "critic_grad_norm": 0.015530446544289589, "ratio": 0.9998260736465454, "entropy": 0.6835366129875183, "incre_win_rate": 0.9302325581395349, "step": 1683}
{"time": 1767339036.7083564, "phase": "train", "update": 1684, "total_env_steps": 5388800, "episode_reward": 0.27377018332481384, "value_loss": 0.00419703247025609, "policy_loss": -0.001045255264989464, "dist_entropy": 0.6837132811546326, "actor_grad_norm": 0.08301492780447006, "critic_grad_norm": 0.03768337890505791, "ratio": 1.0000206232070923, "entropy": 0.6837132811546326, "incre_win_rate": 0.9090909090909091, "step": 1684}
{"time": 1767339040.8224926, "phase": "train", "update": 1685, "total_env_steps": 5392000, "episode_reward": 0.274379163980484, "value_loss": 0.0035348427947610615, "policy_loss": -0.0010495131956048454, "dist_entropy": 0.6759149193763733, "actor_grad_norm": 0.07917767763137817, "critic_grad_norm": 0.04196447506546974, "ratio": 0.9997448921203613, "entropy": 0.6759149193763733, "incre_win_rate": 1.0, "step": 1685}
{"time": 1767339044.9343398, "phase": "train", "update": 1686, "total_env_steps": 5395200, "episode_reward": 0.27059292793273926, "value_loss": 0.005555162578821183, "policy_loss": -0.0012385631967422484, "dist_entropy": 0.6730394840240479, "actor_grad_norm": 0.0847802683711052, "critic_grad_norm": 0.0394185371696949, "ratio": 0.9995620846748352, "entropy": 0.6730394840240479, "incre_win_rate": 0.9318181818181818, "step": 1686}
{"time": 1767339049.0538723, "phase": "train", "update": 1687, "total_env_steps": 5398400, "episode_reward": 0.2760368585586548, "value_loss": 0.003604229586198926, "policy_loss": -0.0011348215348676582, "dist_entropy": 0.6642347693443298, "actor_grad_norm": 0.07585831731557846, "critic_grad_norm": 0.03654816374182701, "ratio": 0.9999332427978516, "entropy": 0.6642347693443298, "incre_win_rate": 0.9555555555555556, "step": 1687}
{"time": 1767339053.1647792, "phase": "train", "update": 1688, "total_env_steps": 5401600, "episode_reward": 0.27087023854255676, "value_loss": 0.007381322700530291, "policy_loss": -0.0018454790348013006, "dist_entropy": 0.6472100138664245, "actor_grad_norm": 0.09333337098360062, "critic_grad_norm": 0.03502323105931282, "ratio": 0.9999882578849792, "entropy": 0.6472100138664245, "incre_win_rate": 0.9333333333333333, "step": 1688}
{"time": 1767339057.3067727, "phase": "train", "update": 1689, "total_env_steps": 5404800, "episode_reward": 0.2769526243209839, "value_loss": 0.004049601685255766, "policy_loss": -0.001224708153634424, "dist_entropy": 0.6389540553092956, "actor_grad_norm": 0.09202597290277481, "critic_grad_norm": 0.03167710453271866, "ratio": 0.9998833537101746, "entropy": 0.6389540553092956, "incre_win_rate": 0.9545454545454546, "step": 1689}
{"time": 1767339061.4244332, "phase": "train", "update": 1690, "total_env_steps": 5408000, "episode_reward": 0.2774089276790619, "value_loss": 0.0051484408788383005, "policy_loss": -0.0014408597633199349, "dist_entropy": 0.629038667678833, "actor_grad_norm": 0.0967312902212143, "critic_grad_norm": 0.033592429012060165, "ratio": 0.9999585151672363, "entropy": 0.629038667678833, "incre_win_rate": 0.9555555555555556, "step": 1690}
{"time": 1767339065.5554905, "phase": "train", "update": 1691, "total_env_steps": 5411200, "episode_reward": 0.27394869923591614, "value_loss": 0.004789573606103659, "policy_loss": -0.0008519747899802255, "dist_entropy": 0.6476340532302857, "actor_grad_norm": 0.0816337987780571, "critic_grad_norm": 0.04939068481326103, "ratio": 0.9996728897094727, "entropy": 0.6476340532302857, "incre_win_rate": 0.9347826086956522, "step": 1691}
{"time": 1767339069.626223, "phase": "train", "update": 1692, "total_env_steps": 5414400, "episode_reward": 0.2670809328556061, "value_loss": 0.006024231109768153, "policy_loss": -0.0013471986090493715, "dist_entropy": 0.651248300075531, "actor_grad_norm": 0.09537103772163391, "critic_grad_norm": 0.03025408647954464, "ratio": 1.000101923942566, "entropy": 0.651248300075531, "incre_win_rate": 0.9285714285714286, "step": 1692}
{"time": 1767339073.7063498, "phase": "train", "update": 1693, "total_env_steps": 5417600, "episode_reward": 0.27016404271125793, "value_loss": 0.005580250080674887, "policy_loss": -0.0008754197326922508, "dist_entropy": 0.6478780150413513, "actor_grad_norm": 0.07492514699697495, "critic_grad_norm": 0.02087959460914135, "ratio": 0.9997764825820923, "entropy": 0.6478780150413513, "incre_win_rate": 0.9574468085106383, "step": 1693}
{"time": 1767339077.8483965, "phase": "train", "update": 1694, "total_env_steps": 5420800, "episode_reward": 0.26586300134658813, "value_loss": 0.00637424299493432, "policy_loss": -0.0011710759265287861, "dist_entropy": 0.6230021238327026, "actor_grad_norm": 0.08911003917455673, "critic_grad_norm": 0.01905928924679756, "ratio": 1.0000394582748413, "entropy": 0.6230021238327026, "incre_win_rate": 0.9047619047619048, "step": 1694}
{"time": 1767339081.947738, "phase": "train", "update": 1695, "total_env_steps": 5424000, "episode_reward": 0.2736320495605469, "value_loss": 0.005099995993077755, "policy_loss": -0.0010830260376579303, "dist_entropy": 0.6174463033676147, "actor_grad_norm": 0.08239910006523132, "critic_grad_norm": 0.026773011311888695, "ratio": 1.0000394582748413, "entropy": 0.6174463033676147, "incre_win_rate": 0.9302325581395349, "step": 1695}
{"time": 1767339086.1239967, "phase": "train", "update": 1696, "total_env_steps": 5427200, "episode_reward": 0.27817466855049133, "value_loss": 0.004165688622742891, "policy_loss": -0.0009671872265889725, "dist_entropy": 0.6168473839759827, "actor_grad_norm": 0.09040162712335587, "critic_grad_norm": 0.027016937732696533, "ratio": 0.9999387860298157, "entropy": 0.6168473839759827, "incre_win_rate": 0.9782608695652174, "step": 1696}
{"time": 1767339090.218908, "phase": "train", "update": 1697, "total_env_steps": 5430400, "episode_reward": 0.2757284641265869, "value_loss": 0.0041332653723657135, "policy_loss": -0.0010746469199760078, "dist_entropy": 0.6107451319694519, "actor_grad_norm": 0.08575200289487839, "critic_grad_norm": 0.022896867245435715, "ratio": 1.0001482963562012, "entropy": 0.6107451319694519, "incre_win_rate": 0.9777777777777777, "step": 1697}
{"time": 1767339094.3175988, "phase": "train", "update": 1698, "total_env_steps": 5433600, "episode_reward": 0.2724006772041321, "value_loss": 0.004340136982500553, "policy_loss": -0.0013155008059985817, "dist_entropy": 0.6209542632102967, "actor_grad_norm": 0.07691285014152527, "critic_grad_norm": 0.025659803301095963, "ratio": 1.0000797510147095, "entropy": 0.6209542632102967, "incre_win_rate": 0.9069767441860465, "step": 1698}
{"time": 1767339098.423472, "phase": "train", "update": 1699, "total_env_steps": 5436800, "episode_reward": 0.2671942412853241, "value_loss": 0.0042536076158285144, "policy_loss": -0.0012941550173991346, "dist_entropy": 0.6123507022857666, "actor_grad_norm": 0.07412856072187424, "critic_grad_norm": 0.01805412769317627, "ratio": 1.000087022781372, "entropy": 0.6123507022857666, "incre_win_rate": 0.9333333333333333, "step": 1699}
{"time": 1767339102.510149, "phase": "train", "update": 1700, "total_env_steps": 5440000, "episode_reward": 0.274152547121048, "value_loss": 0.0035884713754057882, "policy_loss": -0.0014842028861625778, "dist_entropy": 0.6229823112487793, "actor_grad_norm": 0.09352429956197739, "critic_grad_norm": 0.011631907895207405, "ratio": 0.9998111724853516, "entropy": 0.6229823112487793, "incre_win_rate": 0.9534883720930233, "step": 1700}
{"time": 1767339106.5811176, "phase": "train", "update": 1701, "total_env_steps": 5443200, "episode_reward": 0.26588165760040283, "value_loss": 0.004680299106985331, "policy_loss": -0.001092890333163865, "dist_entropy": 0.6035992503166199, "actor_grad_norm": 0.098355732858181, "critic_grad_norm": 0.022581418976187706, "ratio": 0.9996930360794067, "entropy": 0.6035992503166199, "incre_win_rate": 0.9090909090909091, "step": 1701}
{"time": 1767339117.0941632, "phase": "eval", "update": 1701, "total_env_steps": 5443200, "eval_win_rate": 0.875, "eval_episode_reward": 19.578331953642383, "step": 1701}
{"time": 1767339121.1723762, "phase": "train", "update": 1702, "total_env_steps": 5446400, "episode_reward": 0.2733112573623657, "value_loss": 0.006919677834957838, "policy_loss": -0.0012209858604521173, "dist_entropy": 0.6210691571235657, "actor_grad_norm": 0.0841643437743187, "critic_grad_norm": 0.0177884753793478, "ratio": 1.0000299215316772, "entropy": 0.6210691571235657, "incre_win_rate": 0.9545454545454546, "step": 1702}
{"time": 1767339125.2692165, "phase": "train", "update": 1703, "total_env_steps": 5449600, "episode_reward": 0.2765045464038849, "value_loss": 0.004586301278322935, "policy_loss": -0.0010576695143839742, "dist_entropy": 0.6186896681785583, "actor_grad_norm": 0.06784995645284653, "critic_grad_norm": 0.019643617793917656, "ratio": 1.000258445739746, "entropy": 0.6186896681785583, "incre_win_rate": 0.9347826086956522, "step": 1703}
{"time": 1767339129.3519638, "phase": "train", "update": 1704, "total_env_steps": 5452800, "episode_reward": 0.27246585488319397, "value_loss": 0.0048619072884321215, "policy_loss": -0.001306946494099037, "dist_entropy": 0.6213644027709961, "actor_grad_norm": 0.09145782887935638, "critic_grad_norm": 0.021512405946850777, "ratio": 0.999654233455658, "entropy": 0.6213644027709961, "incre_win_rate": 0.9302325581395349, "step": 1704}
{"time": 1767339133.3506708, "phase": "train", "update": 1705, "total_env_steps": 5456000, "episode_reward": 0.25672394037246704, "value_loss": 0.005444757640361786, "policy_loss": -0.0013234084109797096, "dist_entropy": 0.6301620006561279, "actor_grad_norm": 0.0689481869339943, "critic_grad_norm": 0.02556423656642437, "ratio": 1.0000253915786743, "entropy": 0.6301620006561279, "incre_win_rate": 0.9024390243902439, "step": 1705}
{"time": 1767339137.4332256, "phase": "train", "update": 1706, "total_env_steps": 5459200, "episode_reward": 0.260951966047287, "value_loss": 0.006458442378789187, "policy_loss": -0.0013380274310328844, "dist_entropy": 0.6463338971138001, "actor_grad_norm": 0.0752824991941452, "critic_grad_norm": 0.03582373633980751, "ratio": 0.9998804330825806, "entropy": 0.6463338971138001, "incre_win_rate": 0.9069767441860465, "step": 1706}
{"time": 1767339141.5426497, "phase": "train", "update": 1707, "total_env_steps": 5462400, "episode_reward": 0.26604458689689636, "value_loss": 0.003836588282138109, "policy_loss": -0.0014474630874616423, "dist_entropy": 0.649217963218689, "actor_grad_norm": 0.08409092575311661, "critic_grad_norm": 0.036936793476343155, "ratio": 0.9998164176940918, "entropy": 0.649217963218689, "incre_win_rate": 0.9767441860465116, "step": 1707}
{"time": 1767339145.6778843, "phase": "train", "update": 1708, "total_env_steps": 5465600, "episode_reward": 0.2693336009979248, "value_loss": 0.0033426528330892324, "policy_loss": -0.0010619080785069456, "dist_entropy": 0.6621803641319275, "actor_grad_norm": 0.09456662088632584, "critic_grad_norm": 0.034254610538482666, "ratio": 0.9997699856758118, "entropy": 0.6621803641319275, "incre_win_rate": 0.9302325581395349, "step": 1708}
{"time": 1767339149.7776773, "phase": "train", "update": 1709, "total_env_steps": 5468800, "episode_reward": 0.2616276741027832, "value_loss": 0.005648296233266592, "policy_loss": -0.0009303632675653261, "dist_entropy": 0.6609704852104187, "actor_grad_norm": 0.0803055539727211, "critic_grad_norm": 0.0304159764200449, "ratio": 1.0000427961349487, "entropy": 0.6609704852104187, "incre_win_rate": 0.8636363636363636, "step": 1709}
{"time": 1767339153.8490899, "phase": "train", "update": 1710, "total_env_steps": 5472000, "episode_reward": 0.27645695209503174, "value_loss": 0.006303707789629698, "policy_loss": -0.0012177653010681411, "dist_entropy": 0.6389294981956481, "actor_grad_norm": 0.09439843147993088, "critic_grad_norm": 0.027738718315958977, "ratio": 0.9998985528945923, "entropy": 0.6389294981956481, "incre_win_rate": 0.9555555555555556, "step": 1710}
{"time": 1767339157.9767659, "phase": "train", "update": 1711, "total_env_steps": 5475200, "episode_reward": 0.2760140895843506, "value_loss": 0.0068680793978273865, "policy_loss": -0.0009745970869644794, "dist_entropy": 0.6434504389762878, "actor_grad_norm": 0.08263803273439407, "critic_grad_norm": 0.033395037055015564, "ratio": 1.0003366470336914, "entropy": 0.6434504389762878, "incre_win_rate": 0.9777777777777777, "step": 1711}
{"time": 1767339162.0639002, "phase": "train", "update": 1712, "total_env_steps": 5478400, "episode_reward": 0.27927565574645996, "value_loss": 0.003610818833112717, "policy_loss": -0.0010263291302237576, "dist_entropy": 0.6620105385780335, "actor_grad_norm": 0.09372466802597046, "critic_grad_norm": 0.01582016982138157, "ratio": 0.9998871684074402, "entropy": 0.6620105385780335, "incre_win_rate": 0.9777777777777777, "step": 1712}
{"time": 1767339166.174502, "phase": "train", "update": 1713, "total_env_steps": 5481600, "episode_reward": 0.27921101450920105, "value_loss": 0.003258857550099492, "policy_loss": -0.0010790420983489923, "dist_entropy": 0.6385689377784729, "actor_grad_norm": 0.09314806759357452, "critic_grad_norm": 0.03648874908685684, "ratio": 0.9998094439506531, "entropy": 0.6385689377784729, "incre_win_rate": 0.9767441860465116, "step": 1713}
{"time": 1767339170.2922273, "phase": "train", "update": 1714, "total_env_steps": 5484800, "episode_reward": 0.2731415629386902, "value_loss": 0.0048359761014580725, "policy_loss": -0.0008630058842044707, "dist_entropy": 0.657106876373291, "actor_grad_norm": 0.08021734654903412, "critic_grad_norm": 0.02084607444703579, "ratio": 0.999975323677063, "entropy": 0.657106876373291, "incre_win_rate": 0.9361702127659575, "step": 1714}
{"time": 1767339174.3954194, "phase": "train", "update": 1715, "total_env_steps": 5488000, "episode_reward": 0.2697749435901642, "value_loss": 0.004705917369574308, "policy_loss": -0.0010491350959611623, "dist_entropy": 0.6545685410499573, "actor_grad_norm": 0.08365001529455185, "critic_grad_norm": 0.03792862966656685, "ratio": 1.0000429153442383, "entropy": 0.6545685410499573, "incre_win_rate": 0.9069767441860465, "step": 1715}
{"time": 1767339178.5156453, "phase": "train", "update": 1716, "total_env_steps": 5491200, "episode_reward": 0.2804552912712097, "value_loss": 0.003377541713416576, "policy_loss": -0.0010736773383911214, "dist_entropy": 0.6593868374824524, "actor_grad_norm": 0.08109258860349655, "critic_grad_norm": 0.04054359719157219, "ratio": 0.9999895095825195, "entropy": 0.6593868374824524, "incre_win_rate": 0.9565217391304348, "step": 1716}
{"time": 1767339182.607722, "phase": "train", "update": 1717, "total_env_steps": 5494400, "episode_reward": 0.26685377955436707, "value_loss": 0.0037224949337542057, "policy_loss": -0.0010671838682682732, "dist_entropy": 0.6804445385932922, "actor_grad_norm": 0.087434321641922, "critic_grad_norm": 0.032367218285799026, "ratio": 0.9997312426567078, "entropy": 0.6804445385932922, "incre_win_rate": 0.9069767441860465, "step": 1717}
{"time": 1767339186.7245781, "phase": "train", "update": 1718, "total_env_steps": 5497600, "episode_reward": 0.2600392997264862, "value_loss": 0.008802906796336173, "policy_loss": -0.0011331386963426837, "dist_entropy": 0.6635924577713013, "actor_grad_norm": 0.08671227097511292, "critic_grad_norm": 0.09500111639499664, "ratio": 0.9996384978294373, "entropy": 0.6635924577713013, "incre_win_rate": 0.8181818181818182, "step": 1718}
{"time": 1767339190.82087, "phase": "train", "update": 1719, "total_env_steps": 5500800, "episode_reward": 0.26778095960617065, "value_loss": 0.007592510152608156, "policy_loss": -0.0010586834324314508, "dist_entropy": 0.6728733897209167, "actor_grad_norm": 0.0905420184135437, "critic_grad_norm": 0.060431357473134995, "ratio": 0.9996809363365173, "entropy": 0.6728733897209167, "incre_win_rate": 0.8863636363636364, "step": 1719}
{"time": 1767339194.9220967, "phase": "train", "update": 1720, "total_env_steps": 5504000, "episode_reward": 0.2743915617465973, "value_loss": 0.0046709593385458, "policy_loss": -0.000764091887368501, "dist_entropy": 0.6778113603591919, "actor_grad_norm": 0.07372070103883743, "critic_grad_norm": 0.051354147493839264, "ratio": 0.999995231628418, "entropy": 0.6778113603591919, "incre_win_rate": 0.9761904761904762, "step": 1720}
{"time": 1767339199.0275254, "phase": "train", "update": 1721, "total_env_steps": 5507200, "episode_reward": 0.27112168073654175, "value_loss": 0.004866548534482718, "policy_loss": -0.0012235465215781004, "dist_entropy": 0.6654085040092468, "actor_grad_norm": 0.08755665272474289, "critic_grad_norm": 0.033308010548353195, "ratio": 0.9997852444648743, "entropy": 0.6654085040092468, "incre_win_rate": 0.9787234042553191, "step": 1721}
{"time": 1767339203.1160605, "phase": "train", "update": 1722, "total_env_steps": 5510400, "episode_reward": 0.26909974217414856, "value_loss": 0.006942466367036104, "policy_loss": -0.0011034880356845633, "dist_entropy": 0.668093454837799, "actor_grad_norm": 0.08265914767980576, "critic_grad_norm": 0.02298915386199951, "ratio": 1.0003668069839478, "entropy": 0.668093454837799, "incre_win_rate": 0.8837209302325582, "step": 1722}
{"time": 1767339207.269933, "phase": "train", "update": 1723, "total_env_steps": 5513600, "episode_reward": 0.2691023349761963, "value_loss": 0.008216487802565097, "policy_loss": -0.0010934048623312265, "dist_entropy": 0.6534313201904297, "actor_grad_norm": 0.0786980539560318, "critic_grad_norm": 0.026666302233934402, "ratio": 1.0001561641693115, "entropy": 0.6534313201904297, "incre_win_rate": 0.8666666666666667, "step": 1723}
{"time": 1767339211.370744, "phase": "train", "update": 1724, "total_env_steps": 5516800, "episode_reward": 0.2732905447483063, "value_loss": 0.006838646065443754, "policy_loss": -0.0012420615929785938, "dist_entropy": 0.6538326025009156, "actor_grad_norm": 0.09188827872276306, "critic_grad_norm": 0.028093246743083, "ratio": 0.9999141097068787, "entropy": 0.6538326025009156, "incre_win_rate": 0.9090909090909091, "step": 1724}
{"time": 1767339215.458254, "phase": "train", "update": 1725, "total_env_steps": 5520000, "episode_reward": 0.26852649450302124, "value_loss": 0.004882058966904879, "policy_loss": -0.0008952583416789395, "dist_entropy": 0.6698304414749146, "actor_grad_norm": 0.08879844099283218, "critic_grad_norm": 0.024203840643167496, "ratio": 1.0001152753829956, "entropy": 0.6698304414749146, "incre_win_rate": 0.9347826086956522, "step": 1725}
{"time": 1767339219.5867426, "phase": "train", "update": 1726, "total_env_steps": 5523200, "episode_reward": 0.2828352749347687, "value_loss": 0.00404056329280138, "policy_loss": -0.0015244694532748682, "dist_entropy": 0.6856390118598938, "actor_grad_norm": 0.08783704042434692, "critic_grad_norm": 0.01974802277982235, "ratio": 1.0002292394638062, "entropy": 0.6856390118598938, "incre_win_rate": 0.9767441860465116, "step": 1726}
{"time": 1767339229.2292523, "phase": "eval", "update": 1726, "total_env_steps": 5523200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.76764279801324, "step": 1726}
{"time": 1767339233.3247635, "phase": "train", "update": 1727, "total_env_steps": 5526400, "episode_reward": 0.2630220651626587, "value_loss": 0.0041995210573077205, "policy_loss": -0.0010813350528863452, "dist_entropy": 0.6794281125068664, "actor_grad_norm": 0.08653084933757782, "critic_grad_norm": 0.013075399212539196, "ratio": 0.9999178051948547, "entropy": 0.6794281125068664, "incre_win_rate": 0.8888888888888888, "step": 1727}
{"time": 1767339237.4697335, "phase": "train", "update": 1728, "total_env_steps": 5529600, "episode_reward": 0.27837127447128296, "value_loss": 0.0029067469760775564, "policy_loss": -0.0010454859647687441, "dist_entropy": 0.6873368501663208, "actor_grad_norm": 0.07695382088422775, "critic_grad_norm": 0.03216109797358513, "ratio": 1.0000921487808228, "entropy": 0.6873368501663208, "incre_win_rate": 0.9761904761904762, "step": 1728}
{"time": 1767339241.5826907, "phase": "train", "update": 1729, "total_env_steps": 5532800, "episode_reward": 0.26715749502182007, "value_loss": 0.007524381764233113, "policy_loss": -0.0013266793177237445, "dist_entropy": 0.6714199781417847, "actor_grad_norm": 0.0859747901558876, "critic_grad_norm": 0.0932055115699768, "ratio": 0.9999008178710938, "entropy": 0.6714199781417847, "incre_win_rate": 0.8695652173913043, "step": 1729}
{"time": 1767339245.6836095, "phase": "train", "update": 1730, "total_env_steps": 5536000, "episode_reward": 0.2818087637424469, "value_loss": 0.004349853936582803, "policy_loss": -0.0008575030766383662, "dist_entropy": 0.6729559659957886, "actor_grad_norm": 0.06688117980957031, "critic_grad_norm": 0.07312212884426117, "ratio": 0.9998764395713806, "entropy": 0.6729559659957886, "incre_win_rate": 0.9565217391304348, "step": 1730}
{"time": 1767339249.755911, "phase": "train", "update": 1731, "total_env_steps": 5539200, "episode_reward": 0.264606773853302, "value_loss": 0.00897979512810707, "policy_loss": -0.001143185832588145, "dist_entropy": 0.6571322441101074, "actor_grad_norm": 0.07305484265089035, "critic_grad_norm": 0.10069360584020615, "ratio": 0.9999037981033325, "entropy": 0.6571322441101074, "incre_win_rate": 0.8863636363636364, "step": 1731}
{"time": 1767339253.8675997, "phase": "train", "update": 1732, "total_env_steps": 5542400, "episode_reward": 0.27190810441970825, "value_loss": 0.005524309631437063, "policy_loss": -0.0012526435397120395, "dist_entropy": 0.6651935577392578, "actor_grad_norm": 0.08126460760831833, "critic_grad_norm": 0.07610198110342026, "ratio": 1.000056266784668, "entropy": 0.6651935577392578, "incre_win_rate": 0.9555555555555556, "step": 1732}
{"time": 1767339257.9734888, "phase": "train", "update": 1733, "total_env_steps": 5545600, "episode_reward": 0.2808650732040405, "value_loss": 0.002755624847486615, "policy_loss": -0.0010781860433226598, "dist_entropy": 0.7004359006881714, "actor_grad_norm": 0.08100061863660812, "critic_grad_norm": 0.0788123831152916, "ratio": 1.0000977516174316, "entropy": 0.7004359006881714, "incre_win_rate": 0.9767441860465116, "step": 1733}
{"time": 1767339262.1140144, "phase": "train", "update": 1734, "total_env_steps": 5548800, "episode_reward": 0.26943710446357727, "value_loss": 0.002264425111934543, "policy_loss": -0.0010546153781700318, "dist_entropy": 0.6940833926200867, "actor_grad_norm": 0.08455163985490799, "critic_grad_norm": 0.021760066971182823, "ratio": 1.0001863241195679, "entropy": 0.6940833926200867, "incre_win_rate": 1.0, "step": 1734}
{"time": 1767339266.2719305, "phase": "train", "update": 1735, "total_env_steps": 5552000, "episode_reward": 0.27548840641975403, "value_loss": 0.005590979848057032, "policy_loss": -0.0012414953417987818, "dist_entropy": 0.6992609977722168, "actor_grad_norm": 0.08514862507581711, "critic_grad_norm": 0.026161063462495804, "ratio": 0.9999902844429016, "entropy": 0.6992609977722168, "incre_win_rate": 0.9047619047619048, "step": 1735}
{"time": 1767339270.4111447, "phase": "train", "update": 1736, "total_env_steps": 5555200, "episode_reward": 0.27733391523361206, "value_loss": 0.004270083736628294, "policy_loss": -0.0010910057816062135, "dist_entropy": 0.6791193723678589, "actor_grad_norm": 0.0838533490896225, "critic_grad_norm": 0.023477107286453247, "ratio": 1.0000370740890503, "entropy": 0.6791193723678589, "incre_win_rate": 0.9565217391304348, "step": 1736}
{"time": 1767339274.467004, "phase": "train", "update": 1737, "total_env_steps": 5558400, "episode_reward": 0.27109014987945557, "value_loss": 0.005454383417963981, "policy_loss": -0.0015528382028278554, "dist_entropy": 0.6912817478179931, "actor_grad_norm": 0.0900225043296814, "critic_grad_norm": 0.023659050464630127, "ratio": 1.0001469850540161, "entropy": 0.6912817478179931, "incre_win_rate": 0.9333333333333333, "step": 1737}
{"time": 1767339278.6113567, "phase": "train", "update": 1738, "total_env_steps": 5561600, "episode_reward": 0.2696895897388458, "value_loss": 0.0039899168536067006, "policy_loss": -0.0014728622889706334, "dist_entropy": 0.6908845186233521, "actor_grad_norm": 0.07015851140022278, "critic_grad_norm": 0.017048528417944908, "ratio": 0.9998193979263306, "entropy": 0.6908845186233521, "incre_win_rate": 0.9767441860465116, "step": 1738}
{"time": 1767339282.7183526, "phase": "train", "update": 1739, "total_env_steps": 5564800, "episode_reward": 0.2785927355289459, "value_loss": 0.002913798065856099, "policy_loss": -0.0012327937896117191, "dist_entropy": 0.6744053602218628, "actor_grad_norm": 0.08134884387254715, "critic_grad_norm": 0.03287927433848381, "ratio": 0.9999819993972778, "entropy": 0.6744053602218628, "incre_win_rate": 0.9782608695652174, "step": 1739}
{"time": 1767339286.842097, "phase": "train", "update": 1740, "total_env_steps": 5568000, "episode_reward": 0.27029338479042053, "value_loss": 0.0068203359842300415, "policy_loss": -0.001174335229038892, "dist_entropy": 0.6905268907546998, "actor_grad_norm": 0.078827865421772, "critic_grad_norm": 0.03655534237623215, "ratio": 1.0001133680343628, "entropy": 0.6905268907546998, "incre_win_rate": 0.9285714285714286, "step": 1740}
{"time": 1767339290.91774, "phase": "train", "update": 1741, "total_env_steps": 5571200, "episode_reward": 0.2748841345310211, "value_loss": 0.004764617513865232, "policy_loss": -0.0013244865371461855, "dist_entropy": 0.682534122467041, "actor_grad_norm": 0.0878898873925209, "critic_grad_norm": 0.03003675304353237, "ratio": 0.9998779296875, "entropy": 0.682534122467041, "incre_win_rate": 0.9565217391304348, "step": 1741}
{"time": 1767339294.9620357, "phase": "train", "update": 1742, "total_env_steps": 5574400, "episode_reward": 0.2676464319229126, "value_loss": 0.005587965901941061, "policy_loss": -0.0012501334828272093, "dist_entropy": 0.6927128076553345, "actor_grad_norm": 0.07503658533096313, "critic_grad_norm": 0.0614328496158123, "ratio": 1.000298023223877, "entropy": 0.6927128076553345, "incre_win_rate": 0.9285714285714286, "step": 1742}
{"time": 1767339299.1175063, "phase": "train", "update": 1743, "total_env_steps": 5577600, "episode_reward": 0.26806652545928955, "value_loss": 0.005131303332746029, "policy_loss": -0.0012484851003620179, "dist_entropy": 0.7101505875587464, "actor_grad_norm": 0.07137761265039444, "critic_grad_norm": 0.04725257307291031, "ratio": 0.9997620582580566, "entropy": 0.7101505875587464, "incre_win_rate": 0.8888888888888888, "step": 1743}
{"time": 1767339303.1810472, "phase": "train", "update": 1744, "total_env_steps": 5580800, "episode_reward": 0.26833659410476685, "value_loss": 0.004018607223406434, "policy_loss": -0.001247887232023004, "dist_entropy": 0.733602511882782, "actor_grad_norm": 0.0739947259426117, "critic_grad_norm": 0.04041817784309387, "ratio": 1.0000585317611694, "entropy": 0.733602511882782, "incre_win_rate": 0.9318181818181818, "step": 1744}
{"time": 1767339307.302133, "phase": "train", "update": 1745, "total_env_steps": 5584000, "episode_reward": 0.2698473632335663, "value_loss": 0.006053122691810131, "policy_loss": -0.0013692489822879849, "dist_entropy": 0.7315875649452209, "actor_grad_norm": 0.07913991808891296, "critic_grad_norm": 0.03184276446700096, "ratio": 1.0002769231796265, "entropy": 0.7315875649452209, "incre_win_rate": 0.9545454545454546, "step": 1745}
{"time": 1767339311.4027224, "phase": "train", "update": 1746, "total_env_steps": 5587200, "episode_reward": 0.2678435444831848, "value_loss": 0.006524644978344441, "policy_loss": -0.0016190597414876607, "dist_entropy": 0.7215816259384156, "actor_grad_norm": 0.09020055830478668, "critic_grad_norm": 0.032624226063489914, "ratio": 1.0001881122589111, "entropy": 0.7215816259384156, "incre_win_rate": 0.9302325581395349, "step": 1746}
{"time": 1767339315.5090225, "phase": "train", "update": 1747, "total_env_steps": 5590400, "episode_reward": 0.2724379301071167, "value_loss": 0.0038290762808173896, "policy_loss": -0.0008605211003321678, "dist_entropy": 0.7202240705490113, "actor_grad_norm": 0.07709512859582901, "critic_grad_norm": 0.05152587965130806, "ratio": 1.00017249584198, "entropy": 0.7202240705490113, "incre_win_rate": 0.9565217391304348, "step": 1747}
{"time": 1767339319.6228657, "phase": "train", "update": 1748, "total_env_steps": 5593600, "episode_reward": 0.27044081687927246, "value_loss": 0.006919714156538248, "policy_loss": -0.0010425131607576076, "dist_entropy": 0.7029361486434936, "actor_grad_norm": 0.07804471999406815, "critic_grad_norm": 0.04041445255279541, "ratio": 1.0000509023666382, "entropy": 0.7029361486434936, "incre_win_rate": 0.8780487804878049, "step": 1748}
{"time": 1767339323.733725, "phase": "train", "update": 1749, "total_env_steps": 5596800, "episode_reward": 0.27125826478004456, "value_loss": 0.0023166237864643336, "policy_loss": -0.0014020921763652438, "dist_entropy": 0.7035329103469848, "actor_grad_norm": 0.0944833979010582, "critic_grad_norm": 0.02453562803566456, "ratio": 0.9997979402542114, "entropy": 0.7035329103469848, "incre_win_rate": 0.9782608695652174, "step": 1749}
{"time": 1767339327.8720798, "phase": "train", "update": 1750, "total_env_steps": 5600000, "episode_reward": 0.27530527114868164, "value_loss": 0.005077925510704517, "policy_loss": -0.0012619821281838028, "dist_entropy": 0.6819256901741028, "actor_grad_norm": 0.07192820310592651, "critic_grad_norm": 0.03423548489809036, "ratio": 0.9997841119766235, "entropy": 0.6819256901741028, "incre_win_rate": 0.9333333333333333, "step": 1750}
{"time": 1767339331.993602, "phase": "train", "update": 1751, "total_env_steps": 5603200, "episode_reward": 0.2799343168735504, "value_loss": 0.002030954719521105, "policy_loss": -0.0011614935732708886, "dist_entropy": 0.6793622374534607, "actor_grad_norm": 0.08629756420850754, "critic_grad_norm": 0.045660216361284256, "ratio": 0.9997135400772095, "entropy": 0.6793622374534607, "incre_win_rate": 1.0, "step": 1751}
{"time": 1767339341.4403267, "phase": "eval", "update": 1751, "total_env_steps": 5603200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.85818501655629, "step": 1751}
{"time": 1767339345.530671, "phase": "train", "update": 1752, "total_env_steps": 5606400, "episode_reward": 0.27227962017059326, "value_loss": 0.005301573593169451, "policy_loss": -0.0013224131384880877, "dist_entropy": 0.6764535427093505, "actor_grad_norm": 0.08669473975896835, "critic_grad_norm": 0.03793865442276001, "ratio": 1.0001109838485718, "entropy": 0.6764535427093505, "incre_win_rate": 0.9148936170212766, "step": 1752}
{"time": 1767339349.6686313, "phase": "train", "update": 1753, "total_env_steps": 5609600, "episode_reward": 0.2633800506591797, "value_loss": 0.006177332997322082, "policy_loss": -0.0012612091609167208, "dist_entropy": 0.6732523441314697, "actor_grad_norm": 0.08674946427345276, "critic_grad_norm": 0.030155187472701073, "ratio": 1.0001652240753174, "entropy": 0.6732523441314697, "incre_win_rate": 0.9047619047619048, "step": 1753}
{"time": 1767339353.752959, "phase": "train", "update": 1754, "total_env_steps": 5612800, "episode_reward": 0.26787200570106506, "value_loss": 0.01008410081267357, "policy_loss": -0.001362135112069751, "dist_entropy": 0.6592995166778565, "actor_grad_norm": 0.08516228199005127, "critic_grad_norm": 0.08370137214660645, "ratio": 0.9999836087226868, "entropy": 0.6592995166778565, "incre_win_rate": 0.8444444444444444, "step": 1754}
{"time": 1767339357.853575, "phase": "train", "update": 1755, "total_env_steps": 5616000, "episode_reward": 0.2638162076473236, "value_loss": 0.009226172231137753, "policy_loss": -0.0014056804968831215, "dist_entropy": 0.6420897126197815, "actor_grad_norm": 0.07669379562139511, "critic_grad_norm": 0.07323937863111496, "ratio": 0.9999827742576599, "entropy": 0.6420897126197815, "incre_win_rate": 0.9047619047619048, "step": 1755}
{"time": 1767339361.9247558, "phase": "train", "update": 1756, "total_env_steps": 5619200, "episode_reward": 0.2678890526294708, "value_loss": 0.005000832583755254, "policy_loss": -0.001002713056877269, "dist_entropy": 0.660610294342041, "actor_grad_norm": 0.07229895889759064, "critic_grad_norm": 0.035787101835012436, "ratio": 1.000016689300537, "entropy": 0.660610294342041, "incre_win_rate": 0.9333333333333333, "step": 1756}
{"time": 1767339366.04992, "phase": "train", "update": 1757, "total_env_steps": 5622400, "episode_reward": 0.2703600823879242, "value_loss": 0.004930766858160495, "policy_loss": -0.0014022141676967692, "dist_entropy": 0.6549586772918701, "actor_grad_norm": 0.07558698952198029, "critic_grad_norm": 0.04915382340550423, "ratio": 1.000076413154602, "entropy": 0.6549586772918701, "incre_win_rate": 0.9534883720930233, "step": 1757}
{"time": 1767339370.1953864, "phase": "train", "update": 1758, "total_env_steps": 5625600, "episode_reward": 0.2792135775089264, "value_loss": 0.0030140912625938655, "policy_loss": -0.0012365449975504817, "dist_entropy": 0.6684798479080201, "actor_grad_norm": 0.08068212121725082, "critic_grad_norm": 0.059787631034851074, "ratio": 0.9997275471687317, "entropy": 0.6684798479080201, "incre_win_rate": 0.9777777777777777, "step": 1758}
{"time": 1767339374.3186483, "phase": "train", "update": 1759, "total_env_steps": 5628800, "episode_reward": 0.28192055225372314, "value_loss": 0.0023630274925380947, "policy_loss": -0.0014616015354540935, "dist_entropy": 0.6575998187065124, "actor_grad_norm": 0.08735182136297226, "critic_grad_norm": 0.031079551205039024, "ratio": 1.0001064538955688, "entropy": 0.6575998187065124, "incre_win_rate": 1.0, "step": 1759}
{"time": 1767339378.4368463, "phase": "train", "update": 1760, "total_env_steps": 5632000, "episode_reward": 0.2747061252593994, "value_loss": 0.003010938595980406, "policy_loss": -0.00158355036360045, "dist_entropy": 0.66793292760849, "actor_grad_norm": 0.09080833196640015, "critic_grad_norm": 0.030372878536581993, "ratio": 0.999788761138916, "entropy": 0.66793292760849, "incre_win_rate": 0.9565217391304348, "step": 1760}
{"time": 1767339382.5289137, "phase": "train", "update": 1761, "total_env_steps": 5635200, "episode_reward": 0.26065394282341003, "value_loss": 0.007928214501589537, "policy_loss": -0.0014133681143572829, "dist_entropy": 0.6509637713432312, "actor_grad_norm": 0.07152890413999557, "critic_grad_norm": 0.1254088431596756, "ratio": 0.999934196472168, "entropy": 0.6509637713432312, "incre_win_rate": 0.8809523809523809, "step": 1761}
{"time": 1767339386.653825, "phase": "train", "update": 1762, "total_env_steps": 5638400, "episode_reward": 0.26614341139793396, "value_loss": 0.004767013993114233, "policy_loss": -0.0013407343875741161, "dist_entropy": 0.6589088201522827, "actor_grad_norm": 0.09751094877719879, "critic_grad_norm": 0.0592295303940773, "ratio": 1.0000933408737183, "entropy": 0.6589088201522827, "incre_win_rate": 0.9090909090909091, "step": 1762}
{"time": 1767339390.7748933, "phase": "train", "update": 1763, "total_env_steps": 5641600, "episode_reward": 0.2715267837047577, "value_loss": 0.005350310355424881, "policy_loss": -0.0012581922295279214, "dist_entropy": 0.6558669447898865, "actor_grad_norm": 0.09215164184570312, "critic_grad_norm": 0.04053385928273201, "ratio": 0.999707043170929, "entropy": 0.6558669447898865, "incre_win_rate": 0.9545454545454546, "step": 1763}
{"time": 1767339394.8664465, "phase": "train", "update": 1764, "total_env_steps": 5644800, "episode_reward": 0.2578875422477722, "value_loss": 0.006395724974572659, "policy_loss": -0.001251189741014258, "dist_entropy": 0.6413253664970398, "actor_grad_norm": 0.08881358802318573, "critic_grad_norm": 0.05056169256567955, "ratio": 1.0001407861709595, "entropy": 0.6413253664970398, "incre_win_rate": 0.9069767441860465, "step": 1764}
{"time": 1767339399.0237918, "phase": "train", "update": 1765, "total_env_steps": 5648000, "episode_reward": 0.27650660276412964, "value_loss": 0.003633317071944475, "policy_loss": -0.0014755820066923776, "dist_entropy": 0.6804704785346984, "actor_grad_norm": 0.11099199205636978, "critic_grad_norm": 0.05631568655371666, "ratio": 1.0000745058059692, "entropy": 0.6804704785346984, "incre_win_rate": 1.0, "step": 1765}
{"time": 1767339403.1216211, "phase": "train", "update": 1766, "total_env_steps": 5651200, "episode_reward": 0.26654699444770813, "value_loss": 0.007068865839391947, "policy_loss": -0.0015629312094986858, "dist_entropy": 0.6565704941749573, "actor_grad_norm": 0.1030200645327568, "critic_grad_norm": 0.066535584628582, "ratio": 0.999824047088623, "entropy": 0.6565704941749573, "incre_win_rate": 0.8863636363636364, "step": 1766}
{"time": 1767339407.2449553, "phase": "train", "update": 1767, "total_env_steps": 5654400, "episode_reward": 0.2735968828201294, "value_loss": 0.004896972700953484, "policy_loss": -0.0008878581241802408, "dist_entropy": 0.6749890089035034, "actor_grad_norm": 0.07601769268512726, "critic_grad_norm": 0.06431061029434204, "ratio": 0.9998551607131958, "entropy": 0.6749890089035034, "incre_win_rate": 0.9347826086956522, "step": 1767}
{"time": 1767339411.364491, "phase": "train", "update": 1768, "total_env_steps": 5657600, "episode_reward": 0.2783691883087158, "value_loss": 0.00504574840888381, "policy_loss": -0.0012298338632490413, "dist_entropy": 0.675978422164917, "actor_grad_norm": 0.08723747730255127, "critic_grad_norm": 0.052486296743154526, "ratio": 1.0000230073928833, "entropy": 0.675978422164917, "incre_win_rate": 0.9761904761904762, "step": 1768}
{"time": 1767339415.4586198, "phase": "train", "update": 1769, "total_env_steps": 5660800, "episode_reward": 0.26012831926345825, "value_loss": 0.006515080574899912, "policy_loss": -0.0012819166853944353, "dist_entropy": 0.6864248394966126, "actor_grad_norm": 0.09000233560800552, "critic_grad_norm": 0.029681900516152382, "ratio": 0.9996841549873352, "entropy": 0.6864248394966126, "incre_win_rate": 0.9090909090909091, "step": 1769}
{"time": 1767339419.614469, "phase": "train", "update": 1770, "total_env_steps": 5664000, "episode_reward": 0.2734183371067047, "value_loss": 0.005500789824873209, "policy_loss": -0.0009586507942216827, "dist_entropy": 0.6818843364715577, "actor_grad_norm": 0.08808114379644394, "critic_grad_norm": 0.07347612828016281, "ratio": 0.9998380541801453, "entropy": 0.6818843364715577, "incre_win_rate": 0.8863636363636364, "step": 1770}
{"time": 1767339423.7225778, "phase": "train", "update": 1771, "total_env_steps": 5667200, "episode_reward": 0.25700899958610535, "value_loss": 0.005198633205145598, "policy_loss": -0.0016675609823209926, "dist_entropy": 0.6722761273384095, "actor_grad_norm": 0.08395480364561081, "critic_grad_norm": 0.0716770812869072, "ratio": 1.0002187490463257, "entropy": 0.6722761273384095, "incre_win_rate": 0.8636363636363636, "step": 1771}
{"time": 1767339427.809165, "phase": "train", "update": 1772, "total_env_steps": 5670400, "episode_reward": 0.27666184306144714, "value_loss": 0.004558243043720722, "policy_loss": -0.001800364423691292, "dist_entropy": 0.6715577840805054, "actor_grad_norm": 0.08786940574645996, "critic_grad_norm": 0.07309702038764954, "ratio": 1.000108003616333, "entropy": 0.6715577840805054, "incre_win_rate": 0.9761904761904762, "step": 1772}
{"time": 1767339431.9238722, "phase": "train", "update": 1773, "total_env_steps": 5673600, "episode_reward": 0.2579604685306549, "value_loss": 0.008702940307557583, "policy_loss": -0.0012996393018781306, "dist_entropy": 0.6605514526367188, "actor_grad_norm": 0.07945463806390762, "critic_grad_norm": 0.0544142983853817, "ratio": 1.0001440048217773, "entropy": 0.6605514526367188, "incre_win_rate": 0.8444444444444444, "step": 1773}
{"time": 1767339435.9852288, "phase": "train", "update": 1774, "total_env_steps": 5676800, "episode_reward": 0.2622465193271637, "value_loss": 0.007671566586941481, "policy_loss": -0.0010191622876263295, "dist_entropy": 0.6610875368118286, "actor_grad_norm": 0.08418550342321396, "critic_grad_norm": 0.08301079273223877, "ratio": 1.0001238584518433, "entropy": 0.6610875368118286, "incre_win_rate": 0.926829268292683, "step": 1774}
{"time": 1767339440.127474, "phase": "train", "update": 1775, "total_env_steps": 5680000, "episode_reward": 0.265343576669693, "value_loss": 0.007792430277913809, "policy_loss": -0.0010700042288703138, "dist_entropy": 0.6828019380569458, "actor_grad_norm": 0.07769577950239182, "critic_grad_norm": 0.08848773688077927, "ratio": 1.0000208616256714, "entropy": 0.6828019380569458, "incre_win_rate": 0.9555555555555556, "step": 1775}
{"time": 1767339444.2068255, "phase": "train", "update": 1776, "total_env_steps": 5683200, "episode_reward": 0.27065396308898926, "value_loss": 0.00425097793340683, "policy_loss": -0.0011305501081537272, "dist_entropy": 0.6646476626396179, "actor_grad_norm": 0.0909949541091919, "critic_grad_norm": 0.031683433800935745, "ratio": 0.999968945980072, "entropy": 0.6646476626396179, "incre_win_rate": 0.9767441860465116, "step": 1776}
{"time": 1767339453.8733437, "phase": "eval", "update": 1776, "total_env_steps": 5683200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.878207781456954, "step": 1776}
{"time": 1767339457.9942396, "phase": "train", "update": 1777, "total_env_steps": 5686400, "episode_reward": 0.273042231798172, "value_loss": 0.004646189510822296, "policy_loss": -0.0010681383996470118, "dist_entropy": 0.6833104014396667, "actor_grad_norm": 0.06904949992895126, "critic_grad_norm": 0.06089053675532341, "ratio": 0.9999966025352478, "entropy": 0.6833104014396667, "incre_win_rate": 0.9333333333333333, "step": 1777}
{"time": 1767339462.0881088, "phase": "train", "update": 1778, "total_env_steps": 5689600, "episode_reward": 0.26454058289527893, "value_loss": 0.005459406320005656, "policy_loss": -0.0010669795505046764, "dist_entropy": 0.6663542747497558, "actor_grad_norm": 0.08665621280670166, "critic_grad_norm": 0.04009116068482399, "ratio": 0.9996801614761353, "entropy": 0.6663542747497558, "incre_win_rate": 0.9047619047619048, "step": 1778}
{"time": 1767339466.1941144, "phase": "train", "update": 1779, "total_env_steps": 5692800, "episode_reward": 0.2724337875843048, "value_loss": 0.004250685963779688, "policy_loss": -0.0009463496776525915, "dist_entropy": 0.6750589370727539, "actor_grad_norm": 0.09302740544080734, "critic_grad_norm": 0.061426401138305664, "ratio": 0.9998055696487427, "entropy": 0.6750589370727539, "incre_win_rate": 0.9777777777777777, "step": 1779}
{"time": 1767339470.336083, "phase": "train", "update": 1780, "total_env_steps": 5696000, "episode_reward": 0.272168904542923, "value_loss": 0.004941425565630197, "policy_loss": -0.0011332327683923893, "dist_entropy": 0.6919952869415283, "actor_grad_norm": 0.09737323224544525, "critic_grad_norm": 0.04782901704311371, "ratio": 1.0003305673599243, "entropy": 0.6919952869415283, "incre_win_rate": 0.9545454545454546, "step": 1780}
{"time": 1767339474.4334314, "phase": "train", "update": 1781, "total_env_steps": 5699200, "episode_reward": 0.26912304759025574, "value_loss": 0.0037932340055704117, "policy_loss": -0.0014262828632304546, "dist_entropy": 0.6941483616828918, "actor_grad_norm": 0.11136448383331299, "critic_grad_norm": 0.04032311961054802, "ratio": 0.9992514848709106, "entropy": 0.6941483616828918, "incre_win_rate": 0.9545454545454546, "step": 1781}
{"time": 1767339478.5727246, "phase": "train", "update": 1782, "total_env_steps": 5702400, "episode_reward": 0.26062914729118347, "value_loss": 0.005820837616920471, "policy_loss": -0.001317533902830803, "dist_entropy": 0.6962116122245788, "actor_grad_norm": 0.08382823318243027, "critic_grad_norm": 0.07458242774009705, "ratio": 1.0001232624053955, "entropy": 0.6962116122245788, "incre_win_rate": 0.9302325581395349, "step": 1782}
{"time": 1767339482.6801164, "phase": "train", "update": 1783, "total_env_steps": 5705600, "episode_reward": 0.26171770691871643, "value_loss": 0.007407977525144815, "policy_loss": -0.0011945576824789583, "dist_entropy": 0.6956326246261597, "actor_grad_norm": 0.08376650512218475, "critic_grad_norm": 0.04262620210647583, "ratio": 1.0000382661819458, "entropy": 0.6956326246261597, "incre_win_rate": 0.8780487804878049, "step": 1783}
{"time": 1767339486.8017054, "phase": "train", "update": 1784, "total_env_steps": 5708800, "episode_reward": 0.2697630226612091, "value_loss": 0.005047721415758133, "policy_loss": -0.0012017691427445242, "dist_entropy": 0.686740517616272, "actor_grad_norm": 0.09517519921064377, "critic_grad_norm": 0.04286836087703705, "ratio": 0.9998704791069031, "entropy": 0.686740517616272, "incre_win_rate": 0.9090909090909091, "step": 1784}
{"time": 1767339490.9348357, "phase": "train", "update": 1785, "total_env_steps": 5712000, "episode_reward": 0.2655215263366699, "value_loss": 0.006551022175699472, "policy_loss": -0.0011865116261326135, "dist_entropy": 0.690182626247406, "actor_grad_norm": 0.1038711667060852, "critic_grad_norm": 0.02508123591542244, "ratio": 1.0001966953277588, "entropy": 0.690182626247406, "incre_win_rate": 0.9090909090909091, "step": 1785}
{"time": 1767339495.0298576, "phase": "train", "update": 1786, "total_env_steps": 5715200, "episode_reward": 0.274722695350647, "value_loss": 0.003098510392010212, "policy_loss": -0.0011073803701741269, "dist_entropy": 0.6962520122528076, "actor_grad_norm": 0.11273987591266632, "critic_grad_norm": 0.025714710354804993, "ratio": 0.9997702836990356, "entropy": 0.6962520122528076, "incre_win_rate": 1.0, "step": 1786}
{"time": 1767339499.2029214, "phase": "train", "update": 1787, "total_env_steps": 5718400, "episode_reward": 0.2670871317386627, "value_loss": 0.004737266525626183, "policy_loss": -0.0011528274686895656, "dist_entropy": 0.6896746993064881, "actor_grad_norm": 0.1028376966714859, "critic_grad_norm": 0.040151193737983704, "ratio": 0.9996234774589539, "entropy": 0.6896746993064881, "incre_win_rate": 0.9318181818181818, "step": 1787}
{"time": 1767339503.3167574, "phase": "train", "update": 1788, "total_env_steps": 5721600, "episode_reward": 0.2580711841583252, "value_loss": 0.004958279523998499, "policy_loss": -0.0011029173565430205, "dist_entropy": 0.6666202545166016, "actor_grad_norm": 0.0972219705581665, "critic_grad_norm": 0.03821326047182083, "ratio": 1.000049352645874, "entropy": 0.6666202545166016, "incre_win_rate": 0.9069767441860465, "step": 1788}
{"time": 1767339507.4444606, "phase": "train", "update": 1789, "total_env_steps": 5724800, "episode_reward": 0.26488253474235535, "value_loss": 0.005843343213200569, "policy_loss": -0.0014581938201459366, "dist_entropy": 0.6923601746559143, "actor_grad_norm": 0.10566693544387817, "critic_grad_norm": 0.031097084283828735, "ratio": 0.9998742341995239, "entropy": 0.6923601746559143, "incre_win_rate": 0.8636363636363636, "step": 1789}
{"time": 1767339511.5884757, "phase": "train", "update": 1790, "total_env_steps": 5728000, "episode_reward": 0.2558547258377075, "value_loss": 0.008798649348318578, "policy_loss": -0.0014659143542299802, "dist_entropy": 0.6795261144638062, "actor_grad_norm": 0.09700331836938858, "critic_grad_norm": 0.034641336649656296, "ratio": 0.9997559785842896, "entropy": 0.6795261144638062, "incre_win_rate": 0.8536585365853658, "step": 1790}
{"time": 1767339515.673486, "phase": "train", "update": 1791, "total_env_steps": 5731200, "episode_reward": 0.25797080993652344, "value_loss": 0.006950963567942381, "policy_loss": -0.001371579697767089, "dist_entropy": 0.6695300936698914, "actor_grad_norm": 0.10211920738220215, "critic_grad_norm": 0.042747482657432556, "ratio": 0.9996275305747986, "entropy": 0.6695300936698914, "incre_win_rate": 0.8863636363636364, "step": 1791}
{"time": 1767339519.8080263, "phase": "train", "update": 1792, "total_env_steps": 5734400, "episode_reward": 0.272686243057251, "value_loss": 0.005193127039819956, "policy_loss": -0.0014223184932124155, "dist_entropy": 0.6694260597229004, "actor_grad_norm": 0.10175466537475586, "critic_grad_norm": 0.03974021226167679, "ratio": 0.999957263469696, "entropy": 0.6694260597229004, "incre_win_rate": 0.9772727272727273, "step": 1792}
{"time": 1767339523.9392047, "phase": "train", "update": 1793, "total_env_steps": 5737600, "episode_reward": 0.2701846957206726, "value_loss": 0.004159071855247021, "policy_loss": -0.0015343030955008885, "dist_entropy": 0.6729270219802856, "actor_grad_norm": 0.08350872993469238, "critic_grad_norm": 0.04790373519062996, "ratio": 1.000016450881958, "entropy": 0.6729270219802856, "incre_win_rate": 0.9302325581395349, "step": 1793}
{"time": 1767339528.0772173, "phase": "train", "update": 1794, "total_env_steps": 5740800, "episode_reward": 0.27831485867500305, "value_loss": 0.0032753221690654754, "policy_loss": -0.0009145850862076977, "dist_entropy": 0.6944805383682251, "actor_grad_norm": 0.07466971129179001, "critic_grad_norm": 0.030176902189850807, "ratio": 1.0000585317611694, "entropy": 0.6944805383682251, "incre_win_rate": 0.9777777777777777, "step": 1794}
{"time": 1767339532.2276497, "phase": "train", "update": 1795, "total_env_steps": 5744000, "episode_reward": 0.2761501371860504, "value_loss": 0.004164249263703823, "policy_loss": -0.0014933392042820516, "dist_entropy": 0.693622350692749, "actor_grad_norm": 0.08166737854480743, "critic_grad_norm": 0.021449366584420204, "ratio": 0.999686062335968, "entropy": 0.693622350692749, "incre_win_rate": 0.9347826086956522, "step": 1795}
{"time": 1767339536.346318, "phase": "train", "update": 1796, "total_env_steps": 5747200, "episode_reward": 0.2706741690635681, "value_loss": 0.005293923243880272, "policy_loss": -0.0009651468216453907, "dist_entropy": 0.6779544472694397, "actor_grad_norm": 0.09013309329748154, "critic_grad_norm": 0.048413824290037155, "ratio": 0.9999687075614929, "entropy": 0.6779544472694397, "incre_win_rate": 0.9302325581395349, "step": 1796}
{"time": 1767339569.8223965, "phase": "train", "update": 1797, "total_env_steps": 5750400, "episode_reward": 0.2705422341823578, "value_loss": 0.042982371896505354, "policy_loss": -0.0006910667954205252, "dist_entropy": 0.6717753291130066, "actor_grad_norm": 0.06806319206953049, "critic_grad_norm": 0.1441859006881714, "ratio": 1.000227689743042, "entropy": 0.6717753291130066, "incre_win_rate": 0.9487179487179487, "step": 1797}
{"time": 1767339573.9083726, "phase": "train", "update": 1798, "total_env_steps": 5753600, "episode_reward": 0.2694711983203888, "value_loss": 0.004924069438129663, "policy_loss": -0.0011907180945854635, "dist_entropy": 0.6863501787185669, "actor_grad_norm": 0.08563219010829926, "critic_grad_norm": 0.09908037632703781, "ratio": 1.00014066696167, "entropy": 0.6863501787185669, "incre_win_rate": 0.9361702127659575, "step": 1798}
{"time": 1767339577.9302862, "phase": "train", "update": 1799, "total_env_steps": 5756800, "episode_reward": 0.2753104269504547, "value_loss": 0.005370468180626631, "policy_loss": -0.0012630625237093796, "dist_entropy": 0.6615449547767639, "actor_grad_norm": 0.09732562303543091, "critic_grad_norm": 0.08898362517356873, "ratio": 0.9998429417610168, "entropy": 0.6615449547767639, "incre_win_rate": 0.9523809523809523, "step": 1799}
{"time": 1767339582.01542, "phase": "train", "update": 1800, "total_env_steps": 5760000, "episode_reward": 0.27613410353660583, "value_loss": 0.003305333713069558, "policy_loss": -0.001721875396317074, "dist_entropy": 0.6611872792243958, "actor_grad_norm": 0.09388238936662674, "critic_grad_norm": 0.047756507992744446, "ratio": 1.0002723932266235, "entropy": 0.6611872792243958, "incre_win_rate": 0.9782608695652174, "step": 1800}
{"time": 1767339586.0487108, "phase": "train", "update": 1801, "total_env_steps": 5763200, "episode_reward": 0.2705504894256592, "value_loss": 0.004117289651185274, "policy_loss": -0.0011446616875673498, "dist_entropy": 0.6436939477920532, "actor_grad_norm": 0.08188910037279129, "critic_grad_norm": 0.03250009939074516, "ratio": 1.000213861465454, "entropy": 0.6436939477920532, "incre_win_rate": 0.9767441860465116, "step": 1801}
{"time": 1767339595.281197, "phase": "eval", "update": 1801, "total_env_steps": 5763200, "eval_win_rate": 1.0, "eval_episode_reward": 20.000827814569536, "step": 1801}
{"time": 1767339599.3736155, "phase": "train", "update": 1802, "total_env_steps": 5766400, "episode_reward": 0.2809726893901825, "value_loss": 0.002137621911242604, "policy_loss": -0.001056497872675166, "dist_entropy": 0.6627546191215515, "actor_grad_norm": 0.08727452903985977, "critic_grad_norm": 0.018835658207535744, "ratio": 0.9997563362121582, "entropy": 0.6627546191215515, "incre_win_rate": 1.0, "step": 1802}
{"time": 1767339603.4897149, "phase": "train", "update": 1803, "total_env_steps": 5769600, "episode_reward": 0.27028560638427734, "value_loss": 0.004585749376565218, "policy_loss": -0.0011372126432537045, "dist_entropy": 0.6603769898414612, "actor_grad_norm": 0.07810252159833908, "critic_grad_norm": 0.030396193265914917, "ratio": 0.9996939897537231, "entropy": 0.6603769898414612, "incre_win_rate": 0.9302325581395349, "step": 1803}
{"time": 1767339607.5616896, "phase": "train", "update": 1804, "total_env_steps": 5772800, "episode_reward": 0.26745808124542236, "value_loss": 0.007324339915066957, "policy_loss": -0.0016110017927076115, "dist_entropy": 0.6689965486526489, "actor_grad_norm": 0.08978302776813507, "critic_grad_norm": 0.02463267184793949, "ratio": 0.9999775290489197, "entropy": 0.6689965486526489, "incre_win_rate": 0.8888888888888888, "step": 1804}
{"time": 1767339611.7530594, "phase": "train", "update": 1805, "total_env_steps": 5776000, "episode_reward": 0.2697930634021759, "value_loss": 0.007085606269538402, "policy_loss": -0.0009398896699053694, "dist_entropy": 0.6861477971076966, "actor_grad_norm": 0.07680191844701767, "critic_grad_norm": 0.03556592017412186, "ratio": 1.0000815391540527, "entropy": 0.6861477971076966, "incre_win_rate": 0.8888888888888888, "step": 1805}
{"time": 1767339615.8142178, "phase": "train", "update": 1806, "total_env_steps": 5779200, "episode_reward": 0.26824191212654114, "value_loss": 0.006724466849118471, "policy_loss": -0.0011467121051865093, "dist_entropy": 0.6928758382797241, "actor_grad_norm": 0.08183548599481583, "critic_grad_norm": 0.04737392067909241, "ratio": 0.9999295473098755, "entropy": 0.6928758382797241, "incre_win_rate": 0.9333333333333333, "step": 1806}
{"time": 1767339619.9258692, "phase": "train", "update": 1807, "total_env_steps": 5782400, "episode_reward": 0.26935791969299316, "value_loss": 0.007832120265811681, "policy_loss": -0.0014756895305097829, "dist_entropy": 0.7033642768859864, "actor_grad_norm": 0.09081219881772995, "critic_grad_norm": 0.03512632101774216, "ratio": 1.0001693964004517, "entropy": 0.7033642768859864, "incre_win_rate": 0.9069767441860465, "step": 1807}
{"time": 1767339623.9999452, "phase": "train", "update": 1808, "total_env_steps": 5785600, "episode_reward": 0.2726733386516571, "value_loss": 0.006481250654906035, "policy_loss": -0.0011868619969810368, "dist_entropy": 0.6972351789474487, "actor_grad_norm": 0.07330553978681564, "critic_grad_norm": 0.04413921386003494, "ratio": 1.0001782178878784, "entropy": 0.6972351789474487, "incre_win_rate": 0.9361702127659575, "step": 1808}
{"time": 1767339628.074833, "phase": "train", "update": 1809, "total_env_steps": 5788800, "episode_reward": 0.2554677128791809, "value_loss": 0.0053031488321721556, "policy_loss": -0.0009535462430989127, "dist_entropy": 0.6867106556892395, "actor_grad_norm": 0.07535028457641602, "critic_grad_norm": 0.03085118532180786, "ratio": 1.0001394748687744, "entropy": 0.6867106556892395, "incre_win_rate": 0.8461538461538461, "step": 1809}
{"time": 1767339632.1807435, "phase": "train", "update": 1810, "total_env_steps": 5792000, "episode_reward": 0.27186673879623413, "value_loss": 0.0035550343338400124, "policy_loss": -0.0018039356502077553, "dist_entropy": 0.69690842628479, "actor_grad_norm": 0.0772155150771141, "critic_grad_norm": 0.03377119451761246, "ratio": 0.9999720454216003, "entropy": 0.69690842628479, "incre_win_rate": 0.9777777777777777, "step": 1810}
{"time": 1767339636.2818453, "phase": "train", "update": 1811, "total_env_steps": 5795200, "episode_reward": 0.26973095536231995, "value_loss": 0.004432454798370599, "policy_loss": -0.0012923424077200707, "dist_entropy": 0.7111692905426026, "actor_grad_norm": 0.07371699064970016, "critic_grad_norm": 0.043899402022361755, "ratio": 0.9999963045120239, "entropy": 0.7111692905426026, "incre_win_rate": 0.9302325581395349, "step": 1811}
{"time": 1767339640.3988867, "phase": "train", "update": 1812, "total_env_steps": 5798400, "episode_reward": 0.27166491746902466, "value_loss": 0.005229547806084156, "policy_loss": -0.0015873020727127595, "dist_entropy": 0.7015303492546081, "actor_grad_norm": 0.07632090896368027, "critic_grad_norm": 0.04077781364321709, "ratio": 0.9998963475227356, "entropy": 0.7015303492546081, "incre_win_rate": 0.9777777777777777, "step": 1812}
{"time": 1767339644.48721, "phase": "train", "update": 1813, "total_env_steps": 5801600, "episode_reward": 0.26694539189338684, "value_loss": 0.005419100727885961, "policy_loss": -0.0012229952682048407, "dist_entropy": 0.6923494219779969, "actor_grad_norm": 0.08829568326473236, "critic_grad_norm": 0.03340015187859535, "ratio": 1.0000202655792236, "entropy": 0.6923494219779969, "incre_win_rate": 0.9090909090909091, "step": 1813}
{"time": 1767339648.561194, "phase": "train", "update": 1814, "total_env_steps": 5804800, "episode_reward": 0.2679594159126282, "value_loss": 0.004655691515654326, "policy_loss": -0.0011978670132183566, "dist_entropy": 0.6858600854873658, "actor_grad_norm": 0.09327983856201172, "critic_grad_norm": 0.03338818997144699, "ratio": 1.0000203847885132, "entropy": 0.6858600854873658, "incre_win_rate": 0.9285714285714286, "step": 1814}
{"time": 1767339652.6296918, "phase": "train", "update": 1815, "total_env_steps": 5808000, "episode_reward": 0.27107927203178406, "value_loss": 0.004462676215916872, "policy_loss": -0.0012131423313739731, "dist_entropy": 0.7151153326034546, "actor_grad_norm": 0.08148463815450668, "critic_grad_norm": 0.03423738107085228, "ratio": 1.0004066228866577, "entropy": 0.7151153326034546, "incre_win_rate": 0.9333333333333333, "step": 1815}
{"time": 1767339656.6874392, "phase": "train", "update": 1816, "total_env_steps": 5811200, "episode_reward": 0.2638384699821472, "value_loss": 0.005289616994559765, "policy_loss": -0.0016737840889717859, "dist_entropy": 0.7311303615570068, "actor_grad_norm": 0.08845547586679459, "critic_grad_norm": 0.038820214569568634, "ratio": 0.9999901652336121, "entropy": 0.7311303615570068, "incre_win_rate": 0.9523809523809523, "step": 1816}
{"time": 1767339660.7911177, "phase": "train", "update": 1817, "total_env_steps": 5814400, "episode_reward": 0.25588473677635193, "value_loss": 0.008009781781584024, "policy_loss": -0.0013459608986906347, "dist_entropy": 0.7131881594657898, "actor_grad_norm": 0.08808004856109619, "critic_grad_norm": 0.040071651339530945, "ratio": 0.9998242259025574, "entropy": 0.7131881594657898, "incre_win_rate": 0.8809523809523809, "step": 1817}
{"time": 1767339664.885519, "phase": "train", "update": 1818, "total_env_steps": 5817600, "episode_reward": 0.2658609449863434, "value_loss": 0.006307365652173757, "policy_loss": -0.0017293057179530002, "dist_entropy": 0.7155341386795044, "actor_grad_norm": 0.10477349907159805, "critic_grad_norm": 0.03374588117003441, "ratio": 0.9999465346336365, "entropy": 0.7155341386795044, "incre_win_rate": 0.9111111111111111, "step": 1818}
{"time": 1767339669.0215523, "phase": "train", "update": 1819, "total_env_steps": 5820800, "episode_reward": 0.27657386660575867, "value_loss": 0.004724707826972008, "policy_loss": -0.0016259106354496566, "dist_entropy": 0.7153862118721008, "actor_grad_norm": 0.092522032558918, "critic_grad_norm": 0.05510382726788521, "ratio": 1.0000736713409424, "entropy": 0.7153862118721008, "incre_win_rate": 0.9545454545454546, "step": 1819}
{"time": 1767339673.1466868, "phase": "train", "update": 1820, "total_env_steps": 5824000, "episode_reward": 0.2656167149543762, "value_loss": 0.004770733043551445, "policy_loss": -0.0011474230800551765, "dist_entropy": 0.7011864662170411, "actor_grad_norm": 0.09184844046831131, "critic_grad_norm": 0.052406251430511475, "ratio": 1.0004034042358398, "entropy": 0.7011864662170411, "incre_win_rate": 0.9069767441860465, "step": 1820}
{"time": 1767339677.186348, "phase": "train", "update": 1821, "total_env_steps": 5827200, "episode_reward": 0.25743740797042847, "value_loss": 0.005027326382696628, "policy_loss": -0.0014205046561926338, "dist_entropy": 0.7097571849822998, "actor_grad_norm": 0.0922456830739975, "critic_grad_norm": 0.04670577868819237, "ratio": 0.9997947812080383, "entropy": 0.7097571849822998, "incre_win_rate": 0.9, "step": 1821}
{"time": 1767339681.2909536, "phase": "train", "update": 1822, "total_env_steps": 5830400, "episode_reward": 0.2572997808456421, "value_loss": 0.00390747650526464, "policy_loss": -0.0014149173276223337, "dist_entropy": 0.6995072722434997, "actor_grad_norm": 0.0870106965303421, "critic_grad_norm": 0.0329742357134819, "ratio": 0.999821126461029, "entropy": 0.6995072722434997, "incre_win_rate": 0.9333333333333333, "step": 1822}
{"time": 1767339685.3844914, "phase": "train", "update": 1823, "total_env_steps": 5833600, "episode_reward": 0.2618558406829834, "value_loss": 0.009007166884839535, "policy_loss": -0.0015557756126993282, "dist_entropy": 0.6863122344017029, "actor_grad_norm": 0.08671870082616806, "critic_grad_norm": 0.042089033871889114, "ratio": 0.9996921420097351, "entropy": 0.6863122344017029, "incre_win_rate": 0.9512195121951219, "step": 1823}
{"time": 1767339689.4461617, "phase": "train", "update": 1824, "total_env_steps": 5836800, "episode_reward": 0.2617379128932953, "value_loss": 0.0072292470373213295, "policy_loss": -0.00154220039663997, "dist_entropy": 0.7105594277381897, "actor_grad_norm": 0.09292968362569809, "critic_grad_norm": 0.08616460859775543, "ratio": 1.0002731084823608, "entropy": 0.7105594277381897, "incre_win_rate": 0.8863636363636364, "step": 1824}
{"time": 1767339693.6005223, "phase": "train", "update": 1825, "total_env_steps": 5840000, "episode_reward": 0.2653326690196991, "value_loss": 0.005328721646219492, "policy_loss": -0.0011136663003647128, "dist_entropy": 0.715027642250061, "actor_grad_norm": 0.07646440714597702, "critic_grad_norm": 0.05553603172302246, "ratio": 1.0001245737075806, "entropy": 0.715027642250061, "incre_win_rate": 0.9545454545454546, "step": 1825}
{"time": 1767339697.6834424, "phase": "train", "update": 1826, "total_env_steps": 5843200, "episode_reward": 0.27168720960617065, "value_loss": 0.003613513382151723, "policy_loss": -0.001207165309071101, "dist_entropy": 0.7157458066940308, "actor_grad_norm": 0.10188108682632446, "critic_grad_norm": 0.01920522190630436, "ratio": 1.0003979206085205, "entropy": 0.7157458066940308, "incre_win_rate": 0.9767441860465116, "step": 1826}
{"time": 1767339707.2291973, "phase": "eval", "update": 1826, "total_env_steps": 5843200, "eval_win_rate": 1.0, "eval_episode_reward": 20.0, "step": 1826}
{"time": 1767339711.295966, "phase": "train", "update": 1827, "total_env_steps": 5846400, "episode_reward": 0.25833043456077576, "value_loss": 0.006474072858691215, "policy_loss": -0.0013196700315047493, "dist_entropy": 0.7035157322883606, "actor_grad_norm": 0.09567325562238693, "critic_grad_norm": 0.06912253051996231, "ratio": 1.0000115633010864, "entropy": 0.7035157322883606, "incre_win_rate": 0.8604651162790697, "step": 1827}
{"time": 1767339715.362113, "phase": "train", "update": 1828, "total_env_steps": 5849600, "episode_reward": 0.26042479276657104, "value_loss": 0.007303636241704226, "policy_loss": -0.0010933435626014898, "dist_entropy": 0.6967470049858093, "actor_grad_norm": 0.09700500220060349, "critic_grad_norm": 0.058994460850954056, "ratio": 1.0000184774398804, "entropy": 0.6967470049858093, "incre_win_rate": 0.8372093023255814, "step": 1828}
{"time": 1767339719.4624987, "phase": "train", "update": 1829, "total_env_steps": 5852800, "episode_reward": 0.26318761706352234, "value_loss": 0.006953578628599644, "policy_loss": -0.0011745431147097917, "dist_entropy": 0.6942566514015198, "actor_grad_norm": 0.09132590144872665, "critic_grad_norm": 0.029189977794885635, "ratio": 0.999763011932373, "entropy": 0.6942566514015198, "incre_win_rate": 0.8409090909090909, "step": 1829}
{"time": 1767339723.5522885, "phase": "train", "update": 1830, "total_env_steps": 5856000, "episode_reward": 0.2760678827762604, "value_loss": 0.003540408052504063, "policy_loss": -0.0012564890686398654, "dist_entropy": 0.7128390073776245, "actor_grad_norm": 0.1001562625169754, "critic_grad_norm": 0.047685861587524414, "ratio": 0.9999664425849915, "entropy": 0.7128390073776245, "incre_win_rate": 0.9772727272727273, "step": 1830}
{"time": 1767339727.64248, "phase": "train", "update": 1831, "total_env_steps": 5859200, "episode_reward": 0.2766137421131134, "value_loss": 0.003200718108564615, "policy_loss": -0.0010238490992216854, "dist_entropy": 0.6898499727249146, "actor_grad_norm": 0.08409365266561508, "critic_grad_norm": 0.0274952445179224, "ratio": 1.0000110864639282, "entropy": 0.6898499727249146, "incre_win_rate": 0.9772727272727273, "step": 1831}
{"time": 1767339731.7700016, "phase": "train", "update": 1832, "total_env_steps": 5862400, "episode_reward": 0.2712065279483795, "value_loss": 0.003961950587108731, "policy_loss": -0.0012388907006005035, "dist_entropy": 0.6962924122810363, "actor_grad_norm": 0.0753130242228508, "critic_grad_norm": 0.04687831923365593, "ratio": 0.9999092221260071, "entropy": 0.6962924122810363, "incre_win_rate": 0.9555555555555556, "step": 1832}
{"time": 1767339735.836694, "phase": "train", "update": 1833, "total_env_steps": 5865600, "episode_reward": 0.271407812833786, "value_loss": 0.0030025770422071217, "policy_loss": -0.0013946944428858022, "dist_entropy": 0.6994376063346863, "actor_grad_norm": 0.09034491330385208, "critic_grad_norm": 0.028988806530833244, "ratio": 0.9999006390571594, "entropy": 0.6994376063346863, "incre_win_rate": 1.0, "step": 1833}
{"time": 1767339739.92844, "phase": "train", "update": 1834, "total_env_steps": 5868800, "episode_reward": 0.2694106996059418, "value_loss": 0.005044578481465578, "policy_loss": -0.0010377498524611894, "dist_entropy": 0.6942098379135132, "actor_grad_norm": 0.08163096755743027, "critic_grad_norm": 0.02513103559613228, "ratio": 0.9997845888137817, "entropy": 0.6942098379135132, "incre_win_rate": 0.9111111111111111, "step": 1834}
{"time": 1767339744.0139027, "phase": "train", "update": 1835, "total_env_steps": 5872000, "episode_reward": 0.26513242721557617, "value_loss": 0.007384303212165833, "policy_loss": -0.0013556461181774893, "dist_entropy": 0.7163550972938537, "actor_grad_norm": 0.09882215410470963, "critic_grad_norm": 0.04279351234436035, "ratio": 0.9993529319763184, "entropy": 0.7163550972938537, "incre_win_rate": 0.9285714285714286, "step": 1835}
{"time": 1767339748.037965, "phase": "train", "update": 1836, "total_env_steps": 5875200, "episode_reward": 0.25976353883743286, "value_loss": 0.007036297768354416, "policy_loss": -0.0013153937697765628, "dist_entropy": 0.7177862167358399, "actor_grad_norm": 0.09560135006904602, "critic_grad_norm": 0.06654713302850723, "ratio": 0.9998413920402527, "entropy": 0.7177862167358399, "incre_win_rate": 0.8409090909090909, "step": 1836}
{"time": 1767339752.1657803, "phase": "train", "update": 1837, "total_env_steps": 5878400, "episode_reward": 0.26719993352890015, "value_loss": 0.007648950535804033, "policy_loss": -0.0012364218069500054, "dist_entropy": 0.7093026399612427, "actor_grad_norm": 0.08045767992734909, "critic_grad_norm": 0.06171301752328873, "ratio": 0.9997864961624146, "entropy": 0.7093026399612427, "incre_win_rate": 0.9534883720930233, "step": 1837}
{"time": 1767339756.269814, "phase": "train", "update": 1838, "total_env_steps": 5881600, "episode_reward": 0.2710554599761963, "value_loss": 0.005871960520744323, "policy_loss": -0.0011346053826571279, "dist_entropy": 0.7135823488235473, "actor_grad_norm": 0.08799370378255844, "critic_grad_norm": 0.04472806677222252, "ratio": 1.0000696182250977, "entropy": 0.7135823488235473, "incre_win_rate": 0.9555555555555556, "step": 1838}
{"time": 1767339760.3390713, "phase": "train", "update": 1839, "total_env_steps": 5884800, "episode_reward": 0.2744112014770508, "value_loss": 0.004597558733075857, "policy_loss": -0.0011700023655023984, "dist_entropy": 0.7244244813919067, "actor_grad_norm": 0.08941571414470673, "critic_grad_norm": 0.060613878071308136, "ratio": 1.0002626180648804, "entropy": 0.7244244813919067, "incre_win_rate": 0.9534883720930233, "step": 1839}
{"time": 1767339764.419686, "phase": "train", "update": 1840, "total_env_steps": 5888000, "episode_reward": 0.2716639041900635, "value_loss": 0.003010426135733724, "policy_loss": -0.0017605672473209211, "dist_entropy": 0.6998999238014221, "actor_grad_norm": 0.09439655393362045, "critic_grad_norm": 0.04990687221288681, "ratio": 1.0001543760299683, "entropy": 0.6998999238014221, "incre_win_rate": 0.9772727272727273, "step": 1840}
{"time": 1767339768.486476, "phase": "train", "update": 1841, "total_env_steps": 5891200, "episode_reward": 0.27220919728279114, "value_loss": 0.0043094497174024585, "policy_loss": -0.0012114775561940406, "dist_entropy": 0.6998422384262085, "actor_grad_norm": 0.09293758124113083, "critic_grad_norm": 0.03231845423579216, "ratio": 0.9999619722366333, "entropy": 0.6998422384262085, "incre_win_rate": 0.9111111111111111, "step": 1841}
{"time": 1767339772.5720623, "phase": "train", "update": 1842, "total_env_steps": 5894400, "episode_reward": 0.2765418291091919, "value_loss": 0.005050760414451361, "policy_loss": -0.001576887248688763, "dist_entropy": 0.7091288566589355, "actor_grad_norm": 0.08608286827802658, "critic_grad_norm": 0.05580028519034386, "ratio": 1.0002377033233643, "entropy": 0.7091288566589355, "incre_win_rate": 0.9333333333333333, "step": 1842}
{"time": 1767339776.630044, "phase": "train", "update": 1843, "total_env_steps": 5897600, "episode_reward": 0.2679816782474518, "value_loss": 0.0062167620286345485, "policy_loss": -0.0013247803669329983, "dist_entropy": 0.6740122556686401, "actor_grad_norm": 0.08409537374973297, "critic_grad_norm": 0.051678430289030075, "ratio": 1.0000475645065308, "entropy": 0.6740122556686401, "incre_win_rate": 0.9285714285714286, "step": 1843}
{"time": 1767339780.7002604, "phase": "train", "update": 1844, "total_env_steps": 5900800, "episode_reward": 0.2659095823764801, "value_loss": 0.005613322835415602, "policy_loss": -0.0010744699551160863, "dist_entropy": 0.6840965747833252, "actor_grad_norm": 0.07422099262475967, "critic_grad_norm": 0.03303498774766922, "ratio": 0.9999722838401794, "entropy": 0.6840965747833252, "incre_win_rate": 0.9333333333333333, "step": 1844}
{"time": 1767339784.7722936, "phase": "train", "update": 1845, "total_env_steps": 5904000, "episode_reward": 0.2658805847167969, "value_loss": 0.005609382502734661, "policy_loss": -0.0009608620772283416, "dist_entropy": 0.6923614740371704, "actor_grad_norm": 0.07100291550159454, "critic_grad_norm": 0.03154123201966286, "ratio": 0.9999348521232605, "entropy": 0.6923614740371704, "incre_win_rate": 0.9285714285714286, "step": 1845}
{"time": 1767339788.819779, "phase": "train", "update": 1846, "total_env_steps": 5907200, "episode_reward": 0.26555463671684265, "value_loss": 0.0068620268255472185, "policy_loss": -0.001241191795526575, "dist_entropy": 0.6964302062988281, "actor_grad_norm": 0.08261656016111374, "critic_grad_norm": 0.02020019106566906, "ratio": 1.000191569328308, "entropy": 0.6964302062988281, "incre_win_rate": 0.8888888888888888, "step": 1846}
{"time": 1767339792.8857307, "phase": "train", "update": 1847, "total_env_steps": 5910400, "episode_reward": 0.2682077884674072, "value_loss": 0.007179236505180597, "policy_loss": -0.0013587186407455932, "dist_entropy": 0.6943503260612488, "actor_grad_norm": 0.07938415557146072, "critic_grad_norm": 0.0629681721329689, "ratio": 1.0002225637435913, "entropy": 0.6943503260612488, "incre_win_rate": 0.8809523809523809, "step": 1847}
{"time": 1767339796.9304838, "phase": "train", "update": 1848, "total_env_steps": 5913600, "episode_reward": 0.2685766816139221, "value_loss": 0.004961206950247288, "policy_loss": -0.0014600776289981354, "dist_entropy": 0.6805493116378785, "actor_grad_norm": 0.10024237632751465, "critic_grad_norm": 0.05327029898762703, "ratio": 1.0000300407409668, "entropy": 0.6805493116378785, "incre_win_rate": 0.9574468085106383, "step": 1848}
{"time": 1767339801.0067165, "phase": "train", "update": 1849, "total_env_steps": 5916800, "episode_reward": 0.27775248885154724, "value_loss": 0.003754549007862806, "policy_loss": -0.001903443962018514, "dist_entropy": 0.6947853565216064, "actor_grad_norm": 0.10331135243177414, "critic_grad_norm": 0.046531543135643005, "ratio": 0.999511182308197, "entropy": 0.6947853565216064, "incre_win_rate": 0.9545454545454546, "step": 1849}
{"time": 1767339805.0750628, "phase": "train", "update": 1850, "total_env_steps": 5920000, "episode_reward": 0.26985928416252136, "value_loss": 0.00558387041091919, "policy_loss": -0.0014960718099031212, "dist_entropy": 0.6877858519554139, "actor_grad_norm": 0.09560864418745041, "critic_grad_norm": 0.02712235227227211, "ratio": 0.9997890591621399, "entropy": 0.6877858519554139, "incre_win_rate": 0.9545454545454546, "step": 1850}
{"time": 1767339809.1343374, "phase": "train", "update": 1851, "total_env_steps": 5923200, "episode_reward": 0.2856575846672058, "value_loss": 0.0030822646338492634, "policy_loss": -0.001351224679079266, "dist_entropy": 0.6815605282783508, "actor_grad_norm": 0.09446553885936737, "critic_grad_norm": 0.04445084556937218, "ratio": 0.9997963309288025, "entropy": 0.6815605282783508, "incre_win_rate": 0.9375, "step": 1851}
{"time": 1767339823.5943978, "phase": "eval", "update": 1851, "total_env_steps": 5923200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.67880794701987, "step": 1851}
{"time": 1767339827.659068, "phase": "train", "update": 1852, "total_env_steps": 5926400, "episode_reward": 0.2769370973110199, "value_loss": 0.0037897386588156222, "policy_loss": -0.0010684002030536988, "dist_entropy": 0.6759949922561646, "actor_grad_norm": 0.08498669415712357, "critic_grad_norm": 0.0368618443608284, "ratio": 0.9999246001243591, "entropy": 0.6759949922561646, "incre_win_rate": 0.9761904761904762, "step": 1852}
{"time": 1767339831.7638295, "phase": "train", "update": 1853, "total_env_steps": 5929600, "episode_reward": 0.2864445447921753, "value_loss": 0.003314088983461261, "policy_loss": -0.0014608410803294448, "dist_entropy": 0.6814532041549682, "actor_grad_norm": 0.08406290411949158, "critic_grad_norm": 0.025890547782182693, "ratio": 0.999821126461029, "entropy": 0.6814532041549682, "incre_win_rate": 0.9782608695652174, "step": 1853}
{"time": 1767339835.8916354, "phase": "train", "update": 1854, "total_env_steps": 5932800, "episode_reward": 0.2811506688594818, "value_loss": 0.002827217895537615, "policy_loss": -0.0013061154223344973, "dist_entropy": 0.681501054763794, "actor_grad_norm": 0.10535793751478195, "critic_grad_norm": 0.025264857336878777, "ratio": 1.000128149986267, "entropy": 0.681501054763794, "incre_win_rate": 0.9772727272727273, "step": 1854}
{"time": 1767339839.977439, "phase": "train", "update": 1855, "total_env_steps": 5936000, "episode_reward": 0.2750827670097351, "value_loss": 0.0034224375616759063, "policy_loss": -0.0012697622802116727, "dist_entropy": 0.6865284204483032, "actor_grad_norm": 0.09684448689222336, "critic_grad_norm": 0.015908164903521538, "ratio": 0.9999818801879883, "entropy": 0.6865284204483032, "incre_win_rate": 0.9555555555555556, "step": 1855}
{"time": 1767339844.1544852, "phase": "train", "update": 1856, "total_env_steps": 5939200, "episode_reward": 0.27842095494270325, "value_loss": 0.0041732114739716055, "policy_loss": -0.0013872671373999167, "dist_entropy": 0.6781428098678589, "actor_grad_norm": 0.09027957171201706, "critic_grad_norm": 0.030234280973672867, "ratio": 0.9998458027839661, "entropy": 0.6781428098678589, "incre_win_rate": 0.9574468085106383, "step": 1856}
{"time": 1767339848.2355683, "phase": "train", "update": 1857, "total_env_steps": 5942400, "episode_reward": 0.2716101109981537, "value_loss": 0.007512315176427364, "policy_loss": -0.0014257271532528647, "dist_entropy": 0.6797551274299621, "actor_grad_norm": 0.10185327380895615, "critic_grad_norm": 0.07465465366840363, "ratio": 0.9998330473899841, "entropy": 0.6797551274299621, "incre_win_rate": 0.8863636363636364, "step": 1857}
{"time": 1767339852.420015, "phase": "train", "update": 1858, "total_env_steps": 5945600, "episode_reward": 0.2734328508377075, "value_loss": 0.003997283335775137, "policy_loss": -0.0010557674029143982, "dist_entropy": 0.6876291751861572, "actor_grad_norm": 0.0998387336730957, "critic_grad_norm": 0.04419691488146782, "ratio": 1.000067114830017, "entropy": 0.6876291751861572, "incre_win_rate": 0.9545454545454546, "step": 1858}
{"time": 1767339856.5012934, "phase": "train", "update": 1859, "total_env_steps": 5948800, "episode_reward": 0.27756467461586, "value_loss": 0.006302516907453537, "policy_loss": -0.0011894669420712488, "dist_entropy": 0.684117591381073, "actor_grad_norm": 0.09089873731136322, "critic_grad_norm": 0.032065846025943756, "ratio": 1.0002127885818481, "entropy": 0.684117591381073, "incre_win_rate": 0.9318181818181818, "step": 1859}
{"time": 1767339860.5924294, "phase": "train", "update": 1860, "total_env_steps": 5952000, "episode_reward": 0.2677080035209656, "value_loss": 0.00772866727784276, "policy_loss": -0.0010747779477966902, "dist_entropy": 0.6865709781646728, "actor_grad_norm": 0.1048387885093689, "critic_grad_norm": 0.025149041786789894, "ratio": 0.9999008178710938, "entropy": 0.6865709781646728, "incre_win_rate": 0.8936170212765957, "step": 1860}
{"time": 1767339864.9200082, "phase": "train", "update": 1861, "total_env_steps": 5955200, "episode_reward": 0.2763058841228485, "value_loss": 0.008006096258759499, "policy_loss": -0.00102112308736082, "dist_entropy": 0.7243822693824769, "actor_grad_norm": 0.08855107426643372, "critic_grad_norm": 0.037914566695690155, "ratio": 1.000145435333252, "entropy": 0.7243822693824769, "incre_win_rate": 0.8888888888888888, "step": 1861}
{"time": 1767339869.2657397, "phase": "train", "update": 1862, "total_env_steps": 5958400, "episode_reward": 0.27241307497024536, "value_loss": 0.0070234380662441255, "policy_loss": -0.0011439477323039072, "dist_entropy": 0.7003159642219543, "actor_grad_norm": 0.08747376501560211, "critic_grad_norm": 0.034890856593847275, "ratio": 0.9999887347221375, "entropy": 0.7003159642219543, "incre_win_rate": 0.9333333333333333, "step": 1862}
{"time": 1767339873.3843443, "phase": "train", "update": 1863, "total_env_steps": 5961600, "episode_reward": 0.2727193534374237, "value_loss": 0.004012161120772362, "policy_loss": -0.0017537101015459467, "dist_entropy": 0.7235189557075501, "actor_grad_norm": 0.10053552687168121, "critic_grad_norm": 0.02838102914392948, "ratio": 0.9999128580093384, "entropy": 0.7235189557075501, "incre_win_rate": 0.9761904761904762, "step": 1863}
{"time": 1767339877.4615664, "phase": "train", "update": 1864, "total_env_steps": 5964800, "episode_reward": 0.26115530729293823, "value_loss": 0.005575314536690712, "policy_loss": -0.0013258581126304847, "dist_entropy": 0.7215836763381958, "actor_grad_norm": 0.08280306309461594, "critic_grad_norm": 0.025398751720786095, "ratio": 0.9998448491096497, "entropy": 0.7215836763381958, "incre_win_rate": 0.9302325581395349, "step": 1864}
{"time": 1767339881.5754352, "phase": "train", "update": 1865, "total_env_steps": 5968000, "episode_reward": 0.265085369348526, "value_loss": 0.004941507708281279, "policy_loss": -0.0014296642298987194, "dist_entropy": 0.7177793502807617, "actor_grad_norm": 0.10092437267303467, "critic_grad_norm": 0.02485768496990204, "ratio": 1.0001722574234009, "entropy": 0.7177793502807617, "incre_win_rate": 0.9090909090909091, "step": 1865}
{"time": 1767339885.6517062, "phase": "train", "update": 1866, "total_env_steps": 5971200, "episode_reward": 0.2721026837825775, "value_loss": 0.006388166733086109, "policy_loss": -0.0011857163329434429, "dist_entropy": 0.7398331761360168, "actor_grad_norm": 0.09588366746902466, "critic_grad_norm": 0.021137673407793045, "ratio": 0.999912679195404, "entropy": 0.7398331761360168, "incre_win_rate": 0.9523809523809523, "step": 1866}
{"time": 1767339889.7595303, "phase": "train", "update": 1867, "total_env_steps": 5974400, "episode_reward": 0.2635047435760498, "value_loss": 0.005927814450114965, "policy_loss": -0.0012404575060099177, "dist_entropy": 0.7267845034599304, "actor_grad_norm": 0.09494601935148239, "critic_grad_norm": 0.01616511680185795, "ratio": 1.0000180006027222, "entropy": 0.7267845034599304, "incre_win_rate": 0.9361702127659575, "step": 1867}
{"time": 1767339893.8870835, "phase": "train", "update": 1868, "total_env_steps": 5977600, "episode_reward": 0.2707926332950592, "value_loss": 0.005240609869360924, "policy_loss": -0.0014495464124550494, "dist_entropy": 0.7388770580291748, "actor_grad_norm": 0.09951446205377579, "critic_grad_norm": 0.02340315841138363, "ratio": 1.0000054836273193, "entropy": 0.7388770580291748, "incre_win_rate": 0.975609756097561, "step": 1868}
{"time": 1767339897.9546459, "phase": "train", "update": 1869, "total_env_steps": 5980800, "episode_reward": 0.2567782700061798, "value_loss": 0.0037548351567238568, "policy_loss": -0.0011775875616685028, "dist_entropy": 0.7201810479164124, "actor_grad_norm": 0.08386752754449844, "critic_grad_norm": 0.020863071084022522, "ratio": 1.0003477334976196, "entropy": 0.7201810479164124, "incre_win_rate": 0.9318181818181818, "step": 1869}
{"time": 1767339902.0722969, "phase": "train", "update": 1870, "total_env_steps": 5984000, "episode_reward": 0.26363620162010193, "value_loss": 0.00694744624197483, "policy_loss": -0.0014670805689689815, "dist_entropy": 0.7048530817031861, "actor_grad_norm": 0.08518029749393463, "critic_grad_norm": 0.03985206037759781, "ratio": 0.999532163143158, "entropy": 0.7048530817031861, "incre_win_rate": 0.8780487804878049, "step": 1870}
{"time": 1767339906.1331134, "phase": "train", "update": 1871, "total_env_steps": 5987200, "episode_reward": 0.2617787718772888, "value_loss": 0.0026802992448210715, "policy_loss": -0.0013080639672317317, "dist_entropy": 0.7130046725273133, "actor_grad_norm": 0.09281788021326065, "critic_grad_norm": 0.02978493832051754, "ratio": 1.000057578086853, "entropy": 0.7130046725273133, "incre_win_rate": 1.0, "step": 1871}
{"time": 1767339910.222336, "phase": "train", "update": 1872, "total_env_steps": 5990400, "episode_reward": 0.26548171043395996, "value_loss": 0.005925402976572514, "policy_loss": -0.0012090247512636764, "dist_entropy": 0.6911889314651489, "actor_grad_norm": 0.07861264795064926, "critic_grad_norm": 0.02339046820998192, "ratio": 1.0000993013381958, "entropy": 0.6911889314651489, "incre_win_rate": 0.9302325581395349, "step": 1872}
{"time": 1767339914.3245404, "phase": "train", "update": 1873, "total_env_steps": 5993600, "episode_reward": 0.2646109461784363, "value_loss": 0.0047837745398283, "policy_loss": -0.0012515227194299428, "dist_entropy": 0.70531085729599, "actor_grad_norm": 0.07773782312870026, "critic_grad_norm": 0.047058191150426865, "ratio": 1.0003794431686401, "entropy": 0.70531085729599, "incre_win_rate": 0.9318181818181818, "step": 1873}
{"time": 1767339918.4294, "phase": "train", "update": 1874, "total_env_steps": 5996800, "episode_reward": 0.26037201285362244, "value_loss": 0.008462879993021487, "policy_loss": -0.00143815168304684, "dist_entropy": 0.6913834929466247, "actor_grad_norm": 0.07930124551057816, "critic_grad_norm": 0.07716681063175201, "ratio": 1.0001685619354248, "entropy": 0.6913834929466247, "incre_win_rate": 0.8372093023255814, "step": 1874}
{"time": 1767339922.5463746, "phase": "train", "update": 1875, "total_env_steps": 6000000, "episode_reward": 0.25872260332107544, "value_loss": 0.008210733253508806, "policy_loss": -0.0014071459485954564, "dist_entropy": 0.6887913942337036, "actor_grad_norm": 0.08672702312469482, "critic_grad_norm": 0.08883403986692429, "ratio": 0.9999232292175293, "entropy": 0.6887913942337036, "incre_win_rate": 0.8372093023255814, "step": 1875}
{"time": 1767339926.624653, "phase": "train", "update": 1876, "total_env_steps": 6003200, "episode_reward": 0.25624120235443115, "value_loss": 0.009289837256073952, "policy_loss": -0.001403684614170686, "dist_entropy": 0.6794608354568481, "actor_grad_norm": 0.09620469808578491, "critic_grad_norm": 0.07731425017118454, "ratio": 1.0001606941223145, "entropy": 0.6794608354568481, "incre_win_rate": 0.8409090909090909, "step": 1876}
{"time": 1767339935.942216, "phase": "eval", "update": 1876, "total_env_steps": 6003200, "eval_win_rate": 1.0, "eval_episode_reward": 20.0, "step": 1876}
{"time": 1767339939.9613159, "phase": "train", "update": 1877, "total_env_steps": 6006400, "episode_reward": 0.2688896954059601, "value_loss": 0.006136819068342447, "policy_loss": -0.0016024742691023164, "dist_entropy": 0.6897962212562561, "actor_grad_norm": 0.10594964027404785, "critic_grad_norm": 0.03081432916224003, "ratio": 1.0002546310424805, "entropy": 0.6897962212562561, "incre_win_rate": 0.9302325581395349, "step": 1877}
{"time": 1767339944.0166209, "phase": "train", "update": 1878, "total_env_steps": 6009600, "episode_reward": 0.27533525228500366, "value_loss": 0.00536211347207427, "policy_loss": -0.0012751321923573755, "dist_entropy": 0.6821011304855347, "actor_grad_norm": 0.08538889139890671, "critic_grad_norm": 0.07819578796625137, "ratio": 1.0004938840866089, "entropy": 0.6821011304855347, "incre_win_rate": 0.9545454545454546, "step": 1878}
{"time": 1767339948.0583494, "phase": "train", "update": 1879, "total_env_steps": 6012800, "episode_reward": 0.27085578441619873, "value_loss": 0.004907096736133099, "policy_loss": -0.0016548162892632944, "dist_entropy": 0.671181607246399, "actor_grad_norm": 0.09045384079217911, "critic_grad_norm": 0.04405586048960686, "ratio": 1.0000377893447876, "entropy": 0.671181607246399, "incre_win_rate": 0.9333333333333333, "step": 1879}
{"time": 1767339952.1328728, "phase": "train", "update": 1880, "total_env_steps": 6016000, "episode_reward": 0.27977025508880615, "value_loss": 0.004839243367314339, "policy_loss": -0.0011989215670965337, "dist_entropy": 0.6829518914222718, "actor_grad_norm": 0.07802866399288177, "critic_grad_norm": 0.021669311448931694, "ratio": 0.9996775984764099, "entropy": 0.6829518914222718, "incre_win_rate": 0.9347826086956522, "step": 1880}
{"time": 1767339956.1752167, "phase": "train", "update": 1881, "total_env_steps": 6019200, "episode_reward": 0.2674368619918823, "value_loss": 0.006449912022799253, "policy_loss": -0.0011479270301506972, "dist_entropy": 0.6713441133499145, "actor_grad_norm": 0.08890480548143387, "critic_grad_norm": 0.0263337641954422, "ratio": 0.9999761581420898, "entropy": 0.6713441133499145, "incre_win_rate": 0.9090909090909091, "step": 1881}
{"time": 1767339960.210859, "phase": "train", "update": 1882, "total_env_steps": 6022400, "episode_reward": 0.27019402384757996, "value_loss": 0.006458940356969834, "policy_loss": -0.0008239847993060323, "dist_entropy": 0.6726761579513549, "actor_grad_norm": 0.0859556719660759, "critic_grad_norm": 0.01943398080766201, "ratio": 0.9997459650039673, "entropy": 0.6726761579513549, "incre_win_rate": 0.9302325581395349, "step": 1882}
{"time": 1767339964.277122, "phase": "train", "update": 1883, "total_env_steps": 6025600, "episode_reward": 0.27162978053092957, "value_loss": 0.004772373288869858, "policy_loss": -0.0012439514504469784, "dist_entropy": 0.6697899699211121, "actor_grad_norm": 0.09545107185840607, "critic_grad_norm": 0.038326382637023926, "ratio": 1.0000019073486328, "entropy": 0.6697899699211121, "incre_win_rate": 0.9347826086956522, "step": 1883}
{"time": 1767339968.3000166, "phase": "train", "update": 1884, "total_env_steps": 6028800, "episode_reward": 0.2686191201210022, "value_loss": 0.005644243769347667, "policy_loss": -0.001210761276528416, "dist_entropy": 0.6790495634078979, "actor_grad_norm": 0.0874975323677063, "critic_grad_norm": 0.05717625096440315, "ratio": 1.0002444982528687, "entropy": 0.6790495634078979, "incre_win_rate": 0.8809523809523809, "step": 1884}
{"time": 1767339972.384148, "phase": "train", "update": 1885, "total_env_steps": 6032000, "episode_reward": 0.26744982600212097, "value_loss": 0.007108550146222114, "policy_loss": -0.001507753516636967, "dist_entropy": 0.7080522179603577, "actor_grad_norm": 0.10474853962659836, "critic_grad_norm": 0.04749966785311699, "ratio": 1.0000542402267456, "entropy": 0.7080522179603577, "incre_win_rate": 0.8888888888888888, "step": 1885}
{"time": 1767339976.4007275, "phase": "train", "update": 1886, "total_env_steps": 6035200, "episode_reward": 0.27110928297042847, "value_loss": 0.005368753243237734, "policy_loss": -0.0015720085872558797, "dist_entropy": 0.6912710785865783, "actor_grad_norm": 0.09315157681703568, "critic_grad_norm": 0.027085844427347183, "ratio": 1.0000238418579102, "entropy": 0.6912710785865783, "incre_win_rate": 0.9111111111111111, "step": 1886}
{"time": 1767339980.4292142, "phase": "train", "update": 1887, "total_env_steps": 6038400, "episode_reward": 0.2625207006931305, "value_loss": 0.0109866788610816, "policy_loss": -0.0013472875959239516, "dist_entropy": 0.6810444831848145, "actor_grad_norm": 0.08879734575748444, "critic_grad_norm": 0.06329672783613205, "ratio": 0.9999802708625793, "entropy": 0.6810444831848145, "incre_win_rate": 0.8372093023255814, "step": 1887}
{"time": 1767339984.4546337, "phase": "train", "update": 1888, "total_env_steps": 6041600, "episode_reward": 0.26266711950302124, "value_loss": 0.008115543611347675, "policy_loss": -0.0013894947184549978, "dist_entropy": 0.6970217227935791, "actor_grad_norm": 0.08526391535997391, "critic_grad_norm": 0.048312924802303314, "ratio": 0.9999296069145203, "entropy": 0.6970217227935791, "incre_win_rate": 0.8837209302325582, "step": 1888}
{"time": 1767339988.4944391, "phase": "train", "update": 1889, "total_env_steps": 6044800, "episode_reward": 0.26354408264160156, "value_loss": 0.006181803997606039, "policy_loss": -0.0011908296537988861, "dist_entropy": 0.7255497336387634, "actor_grad_norm": 0.08627819269895554, "critic_grad_norm": 0.05050589516758919, "ratio": 1.0001094341278076, "entropy": 0.7255497336387634, "incre_win_rate": 0.8666666666666667, "step": 1889}
{"time": 1767339992.513327, "phase": "train", "update": 1890, "total_env_steps": 6048000, "episode_reward": 0.2620695233345032, "value_loss": 0.009965545684099197, "policy_loss": -0.0017113711254467035, "dist_entropy": 0.7041241526603699, "actor_grad_norm": 0.10260038822889328, "critic_grad_norm": 0.057558994740247726, "ratio": 0.9998669028282166, "entropy": 0.7041241526603699, "incre_win_rate": 0.8372093023255814, "step": 1890}
{"time": 1767339996.5427086, "phase": "train", "update": 1891, "total_env_steps": 6051200, "episode_reward": 0.27155837416648865, "value_loss": 0.006976309791207313, "policy_loss": -0.0010702314926511747, "dist_entropy": 0.692374849319458, "actor_grad_norm": 0.08723178505897522, "critic_grad_norm": 0.03960786014795303, "ratio": 1.0002905130386353, "entropy": 0.692374849319458, "incre_win_rate": 0.9545454545454546, "step": 1891}
{"time": 1767340000.606405, "phase": "train", "update": 1892, "total_env_steps": 6054400, "episode_reward": 0.271833598613739, "value_loss": 0.004497182834893465, "policy_loss": -0.001193147966505137, "dist_entropy": 0.682524311542511, "actor_grad_norm": 0.08589246869087219, "critic_grad_norm": 0.06230087950825691, "ratio": 1.0000648498535156, "entropy": 0.682524311542511, "incre_win_rate": 0.9555555555555556, "step": 1892}
{"time": 1767340004.6802824, "phase": "train", "update": 1893, "total_env_steps": 6057600, "episode_reward": 0.27979716658592224, "value_loss": 0.0027229479514062405, "policy_loss": -0.0013183083399070483, "dist_entropy": 0.6640612721443176, "actor_grad_norm": 0.11411269754171371, "critic_grad_norm": 0.062180906534194946, "ratio": 0.9999039769172668, "entropy": 0.6640612721443176, "incre_win_rate": 0.9772727272727273, "step": 1893}
{"time": 1767340008.7304075, "phase": "train", "update": 1894, "total_env_steps": 6060800, "episode_reward": 0.27523595094680786, "value_loss": 0.004248784761875868, "policy_loss": -0.0012210616906543237, "dist_entropy": 0.6724584341049195, "actor_grad_norm": 0.08519100397825241, "critic_grad_norm": 0.028958385810256004, "ratio": 1.00002121925354, "entropy": 0.6724584341049195, "incre_win_rate": 0.9565217391304348, "step": 1894}
{"time": 1767340012.7695227, "phase": "train", "update": 1895, "total_env_steps": 6064000, "episode_reward": 0.2767999768257141, "value_loss": 0.0029328334610909225, "policy_loss": -0.0013298463964126483, "dist_entropy": 0.6486584305763244, "actor_grad_norm": 0.07492616027593613, "critic_grad_norm": 0.023884404450654984, "ratio": 0.9997269511222839, "entropy": 0.6486584305763244, "incre_win_rate": 0.9772727272727273, "step": 1895}
{"time": 1767340016.7961829, "phase": "train", "update": 1896, "total_env_steps": 6067200, "episode_reward": 0.26376551389694214, "value_loss": 0.006344072706997395, "policy_loss": -0.0011305465207200882, "dist_entropy": 0.6220074892044067, "actor_grad_norm": 0.08251404762268066, "critic_grad_norm": 0.05875668674707413, "ratio": 1.0001667737960815, "entropy": 0.6220074892044067, "incre_win_rate": 0.9090909090909091, "step": 1896}
{"time": 1767340020.8244045, "phase": "train", "update": 1897, "total_env_steps": 6070400, "episode_reward": 0.27396783232688904, "value_loss": 0.006333974376320839, "policy_loss": -0.001119244733443736, "dist_entropy": 0.6352723598480224, "actor_grad_norm": 0.07965674251317978, "critic_grad_norm": 0.03632897511124611, "ratio": 0.9998898506164551, "entropy": 0.6352723598480224, "incre_win_rate": 0.8837209302325582, "step": 1897}
{"time": 1767340024.8762987, "phase": "train", "update": 1898, "total_env_steps": 6073600, "episode_reward": 0.2765733599662781, "value_loss": 0.005464374646544456, "policy_loss": -0.0010118494613216456, "dist_entropy": 0.6302075147628784, "actor_grad_norm": 0.08631438761949539, "critic_grad_norm": 0.02388296090066433, "ratio": 0.9999063611030579, "entropy": 0.6302075147628784, "incre_win_rate": 0.9333333333333333, "step": 1898}
{"time": 1767340028.883551, "phase": "train", "update": 1899, "total_env_steps": 6076800, "episode_reward": 0.2686465382575989, "value_loss": 0.006783713866025209, "policy_loss": -0.0012606276070949106, "dist_entropy": 0.627875030040741, "actor_grad_norm": 0.09137853235006332, "critic_grad_norm": 0.029753057286143303, "ratio": 0.9995671510696411, "entropy": 0.627875030040741, "incre_win_rate": 0.9565217391304348, "step": 1899}
{"time": 1767340033.004917, "phase": "train", "update": 1900, "total_env_steps": 6080000, "episode_reward": 0.27388349175453186, "value_loss": 0.005609760992228985, "policy_loss": -0.001431222880539451, "dist_entropy": 0.6208042979240418, "actor_grad_norm": 0.09109044820070267, "critic_grad_norm": 0.027422010898590088, "ratio": 0.9999489188194275, "entropy": 0.6208042979240418, "incre_win_rate": 0.9069767441860465, "step": 1900}
{"time": 1767340037.0003467, "phase": "train", "update": 1901, "total_env_steps": 6083200, "episode_reward": 0.2683448791503906, "value_loss": 0.006938880775123835, "policy_loss": -0.0012597288393017437, "dist_entropy": 0.6129607081413269, "actor_grad_norm": 0.10385224968194962, "critic_grad_norm": 0.05625785142183304, "ratio": 0.9998096823692322, "entropy": 0.6129607081413269, "incre_win_rate": 0.8863636363636364, "step": 1901}
{"time": 1767340046.2292275, "phase": "eval", "update": 1901, "total_env_steps": 6083200, "eval_win_rate": 0.875, "eval_episode_reward": 19.23970405629139, "step": 1901}
{"time": 1767340050.2218091, "phase": "train", "update": 1902, "total_env_steps": 6086400, "episode_reward": 0.25873032212257385, "value_loss": 0.011295030452311039, "policy_loss": -0.001420511125353663, "dist_entropy": 0.6218631267547607, "actor_grad_norm": 0.10232695192098618, "critic_grad_norm": 0.060789067298173904, "ratio": 1.000152826309204, "entropy": 0.6218631267547607, "incre_win_rate": 0.8297872340425532, "step": 1902}
{"time": 1767340054.2793777, "phase": "train", "update": 1903, "total_env_steps": 6089600, "episode_reward": 0.2734178602695465, "value_loss": 0.007635934371501207, "policy_loss": -0.0010855147510344665, "dist_entropy": 0.6282602190971375, "actor_grad_norm": 0.10779350250959396, "critic_grad_norm": 0.06961651146411896, "ratio": 0.9998769760131836, "entropy": 0.6282602190971375, "incre_win_rate": 0.9523809523809523, "step": 1903}
{"time": 1767340058.325195, "phase": "train", "update": 1904, "total_env_steps": 6092800, "episode_reward": 0.2779103219509125, "value_loss": 0.004767286777496338, "policy_loss": -0.0009316698141883962, "dist_entropy": 0.6353278994560242, "actor_grad_norm": 0.07811431586742401, "critic_grad_norm": 0.033665940165519714, "ratio": 1.0002418756484985, "entropy": 0.6353278994560242, "incre_win_rate": 0.8888888888888888, "step": 1904}
{"time": 1767340062.334853, "phase": "train", "update": 1905, "total_env_steps": 6096000, "episode_reward": 0.27112945914268494, "value_loss": 0.0049467115662992, "policy_loss": -0.0010646491342427566, "dist_entropy": 0.6147549271583557, "actor_grad_norm": 0.07423722743988037, "critic_grad_norm": 0.04439961910247803, "ratio": 0.9998556971549988, "entropy": 0.6147549271583557, "incre_win_rate": 0.9555555555555556, "step": 1905}
{"time": 1767340066.4305143, "phase": "train", "update": 1906, "total_env_steps": 6099200, "episode_reward": 0.2814362645149231, "value_loss": 0.0037618592847138642, "policy_loss": -0.0015125421331944721, "dist_entropy": 0.6210655331611633, "actor_grad_norm": 0.08875284343957901, "critic_grad_norm": 0.03351469710469246, "ratio": 1.000327706336975, "entropy": 0.6210655331611633, "incre_win_rate": 0.9565217391304348, "step": 1906}
{"time": 1767340070.4840662, "phase": "train", "update": 1907, "total_env_steps": 6102400, "episode_reward": 0.2820860743522644, "value_loss": 0.004985522944480181, "policy_loss": -0.0016392547530781343, "dist_entropy": 0.6361414074897767, "actor_grad_norm": 0.08632992208003998, "critic_grad_norm": 0.02583274245262146, "ratio": 1.0000996589660645, "entropy": 0.6361414074897767, "incre_win_rate": 0.9767441860465116, "step": 1907}
{"time": 1767340074.5540009, "phase": "train", "update": 1908, "total_env_steps": 6105600, "episode_reward": 0.2651350498199463, "value_loss": 0.008593241311609745, "policy_loss": -0.0018710759017281475, "dist_entropy": 0.6473013162612915, "actor_grad_norm": 0.08942476660013199, "critic_grad_norm": 0.04024920240044594, "ratio": 1.00006902217865, "entropy": 0.6473013162612915, "incre_win_rate": 0.8913043478260869, "step": 1908}
{"time": 1767340078.6131024, "phase": "train", "update": 1909, "total_env_steps": 6108800, "episode_reward": 0.2750289738178253, "value_loss": 0.0036378040444105864, "policy_loss": -0.0010181817333396737, "dist_entropy": 0.6363871455192566, "actor_grad_norm": 0.07497389614582062, "critic_grad_norm": 0.041133780032396317, "ratio": 1.0000427961349487, "entropy": 0.6363871455192566, "incre_win_rate": 0.9318181818181818, "step": 1909}
{"time": 1767340082.707012, "phase": "train", "update": 1910, "total_env_steps": 6112000, "episode_reward": 0.280953049659729, "value_loss": 0.0030297279357910157, "policy_loss": -0.0013937572449080448, "dist_entropy": 0.6632517218589783, "actor_grad_norm": 0.0952204018831253, "critic_grad_norm": 0.04436727240681648, "ratio": 1.0000666379928589, "entropy": 0.6632517218589783, "incre_win_rate": 0.9782608695652174, "step": 1910}
{"time": 1767340086.7945387, "phase": "train", "update": 1911, "total_env_steps": 6115200, "episode_reward": 0.27745240926742554, "value_loss": 0.003505538264289498, "policy_loss": -0.0013574181000961972, "dist_entropy": 0.6466906547546387, "actor_grad_norm": 0.08483810722827911, "critic_grad_norm": 0.022813940420746803, "ratio": 0.9999527931213379, "entropy": 0.6466906547546387, "incre_win_rate": 0.9090909090909091, "step": 1911}
{"time": 1767340090.9021988, "phase": "train", "update": 1912, "total_env_steps": 6118400, "episode_reward": 0.2659142017364502, "value_loss": 0.006483685411512852, "policy_loss": -0.0018489469200048347, "dist_entropy": 0.6697075486183166, "actor_grad_norm": 0.10820727795362473, "critic_grad_norm": 0.09550616890192032, "ratio": 0.9995344281196594, "entropy": 0.6697075486183166, "incre_win_rate": 0.8888888888888888, "step": 1912}
{"time": 1767340095.0068638, "phase": "train", "update": 1913, "total_env_steps": 6121600, "episode_reward": 0.2746187150478363, "value_loss": 0.004767436347901821, "policy_loss": -0.0013791457836722643, "dist_entropy": 0.6560400605201722, "actor_grad_norm": 0.07865837216377258, "critic_grad_norm": 0.054766591638326645, "ratio": 0.9998356103897095, "entropy": 0.6560400605201722, "incre_win_rate": 0.9090909090909091, "step": 1913}
{"time": 1767340099.0487478, "phase": "train", "update": 1914, "total_env_steps": 6124800, "episode_reward": 0.2730794847011566, "value_loss": 0.005492911022156477, "policy_loss": -0.0015780168118623816, "dist_entropy": 0.6442014575004578, "actor_grad_norm": 0.09583139419555664, "critic_grad_norm": 0.030825873836874962, "ratio": 0.9995536208152771, "entropy": 0.6442014575004578, "incre_win_rate": 0.9333333333333333, "step": 1914}
{"time": 1767340103.1391785, "phase": "train", "update": 1915, "total_env_steps": 6128000, "episode_reward": 0.28139176964759827, "value_loss": 0.0024913813453167678, "policy_loss": -0.0013342983106252148, "dist_entropy": 0.6615329027175904, "actor_grad_norm": 0.09734250605106354, "critic_grad_norm": 0.023199288174510002, "ratio": 0.9998467564582825, "entropy": 0.6615329027175904, "incre_win_rate": 0.9782608695652174, "step": 1915}
{"time": 1767340107.2083435, "phase": "train", "update": 1916, "total_env_steps": 6131200, "episode_reward": 0.27987170219421387, "value_loss": 0.004820949491113424, "policy_loss": -0.001392653040658587, "dist_entropy": 0.6526778221130372, "actor_grad_norm": 0.08903054893016815, "critic_grad_norm": 0.022897500544786453, "ratio": 1.000158667564392, "entropy": 0.6526778221130372, "incre_win_rate": 1.0, "step": 1916}
{"time": 1767340111.2892458, "phase": "train", "update": 1917, "total_env_steps": 6134400, "episode_reward": 0.26705867052078247, "value_loss": 0.003948050178587436, "policy_loss": -0.0014216077721886933, "dist_entropy": 0.6412821650505066, "actor_grad_norm": 0.1012670174241066, "critic_grad_norm": 0.029096031561493874, "ratio": 1.0001808404922485, "entropy": 0.6412821650505066, "incre_win_rate": 0.8863636363636364, "step": 1917}
{"time": 1767340115.4187787, "phase": "train", "update": 1918, "total_env_steps": 6137600, "episode_reward": 0.27383744716644287, "value_loss": 0.0036428760271519423, "policy_loss": -0.0015538899850014332, "dist_entropy": 0.6427543044090271, "actor_grad_norm": 0.09609083831310272, "critic_grad_norm": 0.03941041976213455, "ratio": 0.9999387860298157, "entropy": 0.6427543044090271, "incre_win_rate": 0.9555555555555556, "step": 1918}
{"time": 1767340119.504888, "phase": "train", "update": 1919, "total_env_steps": 6140800, "episode_reward": 0.2711009979248047, "value_loss": 0.004457081109285355, "policy_loss": -0.001041431123900427, "dist_entropy": 0.6754811763763428, "actor_grad_norm": 0.07760460674762726, "critic_grad_norm": 0.03261415287852287, "ratio": 1.00033438205719, "entropy": 0.6754811763763428, "incre_win_rate": 0.9555555555555556, "step": 1919}
{"time": 1767340123.6210318, "phase": "train", "update": 1920, "total_env_steps": 6144000, "episode_reward": 0.27478116750717163, "value_loss": 0.005727513507008552, "policy_loss": -0.0009682802981046734, "dist_entropy": 0.670610761642456, "actor_grad_norm": 0.08229192346334457, "critic_grad_norm": 0.015024581924080849, "ratio": 0.9996675848960876, "entropy": 0.670610761642456, "incre_win_rate": 0.9090909090909091, "step": 1920}
{"time": 1767340127.6740882, "phase": "train", "update": 1921, "total_env_steps": 6147200, "episode_reward": 0.2716245949268341, "value_loss": 0.007192457746714354, "policy_loss": -0.0012149150017648936, "dist_entropy": 0.6596697807312012, "actor_grad_norm": 0.09232045710086823, "critic_grad_norm": 0.0334751270711422, "ratio": 0.999838650226593, "entropy": 0.6596697807312012, "incre_win_rate": 0.9318181818181818, "step": 1921}
{"time": 1767340131.74112, "phase": "train", "update": 1922, "total_env_steps": 6150400, "episode_reward": 0.27235978841781616, "value_loss": 0.004653123673051596, "policy_loss": -0.00108139794370814, "dist_entropy": 0.6719494938850403, "actor_grad_norm": 0.108736552298069, "critic_grad_norm": 0.03230833634734154, "ratio": 1.0003632307052612, "entropy": 0.6719494938850403, "incre_win_rate": 0.9318181818181818, "step": 1922}
{"time": 1767340135.8300533, "phase": "train", "update": 1923, "total_env_steps": 6153600, "episode_reward": 0.26830193400382996, "value_loss": 0.00951803382486105, "policy_loss": -0.0012501225430085583, "dist_entropy": 0.6411889076232911, "actor_grad_norm": 0.07908585667610168, "critic_grad_norm": 0.07328639924526215, "ratio": 0.9997404217720032, "entropy": 0.6411889076232911, "incre_win_rate": 0.8837209302325582, "step": 1923}
{"time": 1767340139.9127579, "phase": "train", "update": 1924, "total_env_steps": 6156800, "episode_reward": 0.2689533531665802, "value_loss": 0.00536858756095171, "policy_loss": -0.0012909138113002428, "dist_entropy": 0.6683437585830688, "actor_grad_norm": 0.08681102842092514, "critic_grad_norm": 0.03857814893126488, "ratio": 0.9998096823692322, "entropy": 0.6683437585830688, "incre_win_rate": 0.9333333333333333, "step": 1924}
{"time": 1767340143.9879768, "phase": "train", "update": 1925, "total_env_steps": 6160000, "episode_reward": 0.2553466558456421, "value_loss": 0.005094138998538255, "policy_loss": -0.001391340308754252, "dist_entropy": 0.6830212712287903, "actor_grad_norm": 0.09456533193588257, "critic_grad_norm": 0.02301226556301117, "ratio": 0.9999122023582458, "entropy": 0.6830212712287903, "incre_win_rate": 0.8604651162790697, "step": 1925}
{"time": 1767340148.0713155, "phase": "train", "update": 1926, "total_env_steps": 6163200, "episode_reward": 0.27840903401374817, "value_loss": 0.002989951195195317, "policy_loss": -0.001755600255592782, "dist_entropy": 0.6651688098907471, "actor_grad_norm": 0.09897016733884811, "critic_grad_norm": 0.034139662981033325, "ratio": 1.000124216079712, "entropy": 0.6651688098907471, "incre_win_rate": 0.9545454545454546, "step": 1926}
{"time": 1767340157.5602431, "phase": "eval", "update": 1926, "total_env_steps": 6163200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.79061465231788, "step": 1926}
{"time": 1767340161.5836494, "phase": "train", "update": 1927, "total_env_steps": 6166400, "episode_reward": 0.279168039560318, "value_loss": 0.003303247783333063, "policy_loss": -0.001088223584018877, "dist_entropy": 0.6380497336387634, "actor_grad_norm": 0.07255127280950546, "critic_grad_norm": 0.029322728514671326, "ratio": 1.0001559257507324, "entropy": 0.6380497336387634, "incre_win_rate": 0.9565217391304348, "step": 1927}
{"time": 1767340165.6198037, "phase": "train", "update": 1928, "total_env_steps": 6169600, "episode_reward": 0.27880793809890747, "value_loss": 0.0025053768884390594, "policy_loss": -0.001317834910796023, "dist_entropy": 0.6447982549667358, "actor_grad_norm": 0.0739128515124321, "critic_grad_norm": 0.010239887051284313, "ratio": 1.0000221729278564, "entropy": 0.6447982549667358, "incre_win_rate": 1.0, "step": 1928}
{"time": 1767340169.65983, "phase": "train", "update": 1929, "total_env_steps": 6172800, "episode_reward": 0.27860045433044434, "value_loss": 0.003409198299050331, "policy_loss": -0.0012645521492466115, "dist_entropy": 0.6215150237083436, "actor_grad_norm": 0.07676829397678375, "critic_grad_norm": 0.013901278376579285, "ratio": 0.9995598793029785, "entropy": 0.6215150237083436, "incre_win_rate": 0.9565217391304348, "step": 1929}
{"time": 1767340173.6909604, "phase": "train", "update": 1930, "total_env_steps": 6176000, "episode_reward": 0.27603474259376526, "value_loss": 0.0031009717378765343, "policy_loss": -0.001420247378366568, "dist_entropy": 0.6456037521362304, "actor_grad_norm": 0.08672971278429031, "critic_grad_norm": 0.019312389194965363, "ratio": 1.0001357793807983, "entropy": 0.6456037521362304, "incre_win_rate": 1.0, "step": 1930}
{"time": 1767340177.7452946, "phase": "train", "update": 1931, "total_env_steps": 6179200, "episode_reward": 0.28083664178848267, "value_loss": 0.0032373009249567985, "policy_loss": -0.0010061053432968592, "dist_entropy": 0.612380301952362, "actor_grad_norm": 0.08478166162967682, "critic_grad_norm": 0.018629631027579308, "ratio": 1.000130295753479, "entropy": 0.612380301952362, "incre_win_rate": 0.9787234042553191, "step": 1931}
{"time": 1767340181.7699335, "phase": "train", "update": 1932, "total_env_steps": 6182400, "episode_reward": 0.28421562910079956, "value_loss": 0.0036581101827323436, "policy_loss": -0.0014083344671377064, "dist_entropy": 0.6205504536628723, "actor_grad_norm": 0.07084091752767563, "critic_grad_norm": 0.021644366905093193, "ratio": 1.0001109838485718, "entropy": 0.6205504536628723, "incre_win_rate": 0.9555555555555556, "step": 1932}
{"time": 1767340185.8356826, "phase": "train", "update": 1933, "total_env_steps": 6185600, "episode_reward": 0.27605703473091125, "value_loss": 0.004618343710899353, "policy_loss": -0.001382086997896792, "dist_entropy": 0.6214898943901062, "actor_grad_norm": 0.07801562547683716, "critic_grad_norm": 0.03559615835547447, "ratio": 1.0001466274261475, "entropy": 0.6214898943901062, "incre_win_rate": 0.8936170212765957, "step": 1933}
{"time": 1767340189.853796, "phase": "train", "update": 1934, "total_env_steps": 6188800, "episode_reward": 0.2840811312198639, "value_loss": 0.00435187267139554, "policy_loss": -0.0013851076652334094, "dist_entropy": 0.6125257849693299, "actor_grad_norm": 0.08176962286233902, "critic_grad_norm": 0.034702833741903305, "ratio": 0.9994703531265259, "entropy": 0.6125257849693299, "incre_win_rate": 0.9767441860465116, "step": 1934}
{"time": 1767340193.8826468, "phase": "train", "update": 1935, "total_env_steps": 6192000, "episode_reward": 0.2729387581348419, "value_loss": 0.004979028832167387, "policy_loss": -0.001527040600818097, "dist_entropy": 0.6041389346122742, "actor_grad_norm": 0.08574055880308151, "critic_grad_norm": 0.031231487169861794, "ratio": 0.9999698996543884, "entropy": 0.6041389346122742, "incre_win_rate": 0.9130434782608695, "step": 1935}
{"time": 1767340197.8818445, "phase": "train", "update": 1936, "total_env_steps": 6195200, "episode_reward": 0.27756211161613464, "value_loss": 0.006157472170889378, "policy_loss": -0.0011503889620541941, "dist_entropy": 0.5984930396080017, "actor_grad_norm": 0.09063763916492462, "critic_grad_norm": 0.03891177475452423, "ratio": 1.0002433061599731, "entropy": 0.5984930396080017, "incre_win_rate": 0.9772727272727273, "step": 1936}
{"time": 1767340201.950839, "phase": "train", "update": 1937, "total_env_steps": 6198400, "episode_reward": 0.27353787422180176, "value_loss": 0.007977011147886515, "policy_loss": -0.0008770054182022591, "dist_entropy": 0.6204723119735718, "actor_grad_norm": 0.08968301117420197, "critic_grad_norm": 0.031144529581069946, "ratio": 1.000367522239685, "entropy": 0.6204723119735718, "incre_win_rate": 0.9090909090909091, "step": 1937}
{"time": 1767340206.0058124, "phase": "train", "update": 1938, "total_env_steps": 6201600, "episode_reward": 0.2741934061050415, "value_loss": 0.005586523935198784, "policy_loss": -0.0014089366328583707, "dist_entropy": 0.6311112761497497, "actor_grad_norm": 0.08941370993852615, "critic_grad_norm": 0.06653163582086563, "ratio": 1.000227928161621, "entropy": 0.6311112761497497, "incre_win_rate": 0.9148936170212766, "step": 1938}
{"time": 1767340210.0755503, "phase": "train", "update": 1939, "total_env_steps": 6204800, "episode_reward": 0.2785549461841583, "value_loss": 0.003851616242900491, "policy_loss": -0.0009307145457565724, "dist_entropy": 0.6434985280036927, "actor_grad_norm": 0.08320201188325882, "critic_grad_norm": 0.0535835325717926, "ratio": 0.9998624920845032, "entropy": 0.6434985280036927, "incre_win_rate": 0.9333333333333333, "step": 1939}
{"time": 1767340214.1297834, "phase": "train", "update": 1940, "total_env_steps": 6208000, "episode_reward": 0.27636176347732544, "value_loss": 0.005810001306235791, "policy_loss": -0.0012339205646597407, "dist_entropy": 0.6543934583663941, "actor_grad_norm": 0.07949252426624298, "critic_grad_norm": 0.04547556862235069, "ratio": 1.0003851652145386, "entropy": 0.6543934583663941, "incre_win_rate": 0.9302325581395349, "step": 1940}
{"time": 1767340218.1653106, "phase": "train", "update": 1941, "total_env_steps": 6211200, "episode_reward": 0.27992549538612366, "value_loss": 0.005487800482660532, "policy_loss": -0.0010742651721365349, "dist_entropy": 0.6467567205429077, "actor_grad_norm": 0.07543372362852097, "critic_grad_norm": 0.03648185357451439, "ratio": 0.9996315240859985, "entropy": 0.6467567205429077, "incre_win_rate": 0.9347826086956522, "step": 1941}
{"time": 1767340222.1938531, "phase": "train", "update": 1942, "total_env_steps": 6214400, "episode_reward": 0.2787500023841858, "value_loss": 0.005169436894357204, "policy_loss": -0.0012774204505362264, "dist_entropy": 0.6597888708114624, "actor_grad_norm": 0.08713699132204056, "critic_grad_norm": 0.04312215372920036, "ratio": 0.9996704459190369, "entropy": 0.6597888708114624, "incre_win_rate": 0.9777777777777777, "step": 1942}
{"time": 1767340226.2842424, "phase": "train", "update": 1943, "total_env_steps": 6217600, "episode_reward": 0.27403873205184937, "value_loss": 0.003594948025420308, "policy_loss": -0.0012113160484354068, "dist_entropy": 0.6539015293121337, "actor_grad_norm": 0.09701453894376755, "critic_grad_norm": 0.04690231755375862, "ratio": 0.9998847246170044, "entropy": 0.6539015293121337, "incre_win_rate": 0.9545454545454546, "step": 1943}
{"time": 1767340230.3577454, "phase": "train", "update": 1944, "total_env_steps": 6220800, "episode_reward": 0.26646316051483154, "value_loss": 0.006987910065799951, "policy_loss": -0.0011362886011784922, "dist_entropy": 0.6348281264305115, "actor_grad_norm": 0.09716252982616425, "critic_grad_norm": 0.08565696328878403, "ratio": 0.9995169043540955, "entropy": 0.6348281264305115, "incre_win_rate": 0.8666666666666667, "step": 1944}
{"time": 1767340234.464573, "phase": "train", "update": 1945, "total_env_steps": 6224000, "episode_reward": 0.28156816959381104, "value_loss": 0.008105861768126488, "policy_loss": -0.0017959243741586307, "dist_entropy": 0.6362661004066468, "actor_grad_norm": 0.10132353752851486, "critic_grad_norm": 0.09555285423994064, "ratio": 1.000033974647522, "entropy": 0.6362661004066468, "incre_win_rate": 0.9148936170212766, "step": 1945}
{"time": 1767340238.517413, "phase": "train", "update": 1946, "total_env_steps": 6227200, "episode_reward": 0.2737707197666168, "value_loss": 0.0072433860041201115, "policy_loss": -0.0008743989627820525, "dist_entropy": 0.6339888215065003, "actor_grad_norm": 0.0860924944281578, "critic_grad_norm": 0.05342552065849304, "ratio": 0.9997267127037048, "entropy": 0.6339888215065003, "incre_win_rate": 0.9523809523809523, "step": 1946}
{"time": 1767340242.5897863, "phase": "train", "update": 1947, "total_env_steps": 6230400, "episode_reward": 0.2730008065700531, "value_loss": 0.00707821398973465, "policy_loss": -0.0010885516270377593, "dist_entropy": 0.6242721319198609, "actor_grad_norm": 0.07667162269353867, "critic_grad_norm": 0.06589557975530624, "ratio": 0.9999610185623169, "entropy": 0.6242721319198609, "incre_win_rate": 0.8723404255319149, "step": 1947}
{"time": 1767340246.6906888, "phase": "train", "update": 1948, "total_env_steps": 6233600, "episode_reward": 0.2816349267959595, "value_loss": 0.002996518835425377, "policy_loss": -0.0013195542712048703, "dist_entropy": 0.6662894368171692, "actor_grad_norm": 0.09948428720235825, "critic_grad_norm": 0.06670151650905609, "ratio": 0.9999338984489441, "entropy": 0.6662894368171692, "incre_win_rate": 0.9772727272727273, "step": 1948}
{"time": 1767340250.781697, "phase": "train", "update": 1949, "total_env_steps": 6236800, "episode_reward": 0.2834809720516205, "value_loss": 0.0022858474403619766, "policy_loss": -0.0012071939678953924, "dist_entropy": 0.6614887952804566, "actor_grad_norm": 0.07681675255298615, "critic_grad_norm": 0.03281879425048828, "ratio": 1.0002145767211914, "entropy": 0.6614887952804566, "incre_win_rate": 1.0, "step": 1949}
{"time": 1767340254.8972478, "phase": "train", "update": 1950, "total_env_steps": 6240000, "episode_reward": 0.2876448631286621, "value_loss": 0.002787459222599864, "policy_loss": -0.0013130420491432205, "dist_entropy": 0.6588243007659912, "actor_grad_norm": 0.07610214501619339, "critic_grad_norm": 0.028928084298968315, "ratio": 0.9998595118522644, "entropy": 0.6588243007659912, "incre_win_rate": 0.9782608695652174, "step": 1950}
{"time": 1767340258.9673479, "phase": "train", "update": 1951, "total_env_steps": 6243200, "episode_reward": 0.27544963359832764, "value_loss": 0.005399671010673046, "policy_loss": -0.001501525189167552, "dist_entropy": 0.6571539759635925, "actor_grad_norm": 0.09235178679227829, "critic_grad_norm": 0.05065178498625755, "ratio": 1.0000752210617065, "entropy": 0.6571539759635925, "incre_win_rate": 0.8936170212765957, "step": 1951}
{"time": 1767340268.4636695, "phase": "eval", "update": 1951, "total_env_steps": 6243200, "eval_win_rate": 0.84375, "eval_episode_reward": 19.29340852649007, "step": 1951}
{"time": 1767340272.546604, "phase": "train", "update": 1952, "total_env_steps": 6246400, "episode_reward": 0.2788628041744232, "value_loss": 0.0040539510548114775, "policy_loss": -0.0011612231416208373, "dist_entropy": 0.6476146221160889, "actor_grad_norm": 0.11019988358020782, "critic_grad_norm": 0.03233472257852554, "ratio": 1.0000202655792236, "entropy": 0.6476146221160889, "incre_win_rate": 0.9767441860465116, "step": 1952}
{"time": 1767340276.5978563, "phase": "train", "update": 1953, "total_env_steps": 6249600, "episode_reward": 0.2747107744216919, "value_loss": 0.00752862635999918, "policy_loss": -0.0011254392754191044, "dist_entropy": 0.6223034977912902, "actor_grad_norm": 0.0817091092467308, "critic_grad_norm": 0.07470410317182541, "ratio": 1.000105619430542, "entropy": 0.6223034977912902, "incre_win_rate": 0.9130434782608695, "step": 1953}
{"time": 1767340280.6403475, "phase": "train", "update": 1954, "total_env_steps": 6252800, "episode_reward": 0.275602251291275, "value_loss": 0.005753091815859079, "policy_loss": -0.0013172030338751029, "dist_entropy": 0.6453388452529907, "actor_grad_norm": 0.08870841562747955, "critic_grad_norm": 0.06503798812627792, "ratio": 1.0001962184906006, "entropy": 0.6453388452529907, "incre_win_rate": 0.8913043478260869, "step": 1954}
{"time": 1767340284.7050376, "phase": "train", "update": 1955, "total_env_steps": 6256000, "episode_reward": 0.28248655796051025, "value_loss": 0.008943909034132957, "policy_loss": -0.0012446972996742467, "dist_entropy": 0.6523926377296447, "actor_grad_norm": 0.07122956216335297, "critic_grad_norm": 0.04040684178471565, "ratio": 1.0000861883163452, "entropy": 0.6523926377296447, "incre_win_rate": 0.9333333333333333, "step": 1955}
{"time": 1767340288.7607388, "phase": "train", "update": 1956, "total_env_steps": 6259200, "episode_reward": 0.27418410778045654, "value_loss": 0.006801076978445053, "policy_loss": -0.0015329407981184318, "dist_entropy": 0.6104920506477356, "actor_grad_norm": 0.09825406968593597, "critic_grad_norm": 0.024891668930649757, "ratio": 0.999574601650238, "entropy": 0.6104920506477356, "incre_win_rate": 0.9111111111111111, "step": 1956}
{"time": 1767340292.840822, "phase": "train", "update": 1957, "total_env_steps": 6262400, "episode_reward": 0.28215646743774414, "value_loss": 0.0037161254789680243, "policy_loss": -0.0009376968475685032, "dist_entropy": 0.6155814886093139, "actor_grad_norm": 0.08607947081327438, "critic_grad_norm": 0.03442809730768204, "ratio": 0.9997398257255554, "entropy": 0.6155814886093139, "incre_win_rate": 0.9565217391304348, "step": 1957}
{"time": 1767340296.9191282, "phase": "train", "update": 1958, "total_env_steps": 6265600, "episode_reward": 0.27258434891700745, "value_loss": 0.007154371589422226, "policy_loss": -0.0012712038502513678, "dist_entropy": 0.6367783308029175, "actor_grad_norm": 0.09136544913053513, "critic_grad_norm": 0.053010791540145874, "ratio": 0.999838650226593, "entropy": 0.6367783308029175, "incre_win_rate": 0.8636363636363636, "step": 1958}
{"time": 1767340301.0286639, "phase": "train", "update": 1959, "total_env_steps": 6268800, "episode_reward": 0.27924978733062744, "value_loss": 0.0070877915248274805, "policy_loss": -0.001285199123022096, "dist_entropy": 0.6246866583824158, "actor_grad_norm": 0.07843445986509323, "critic_grad_norm": 0.03463006392121315, "ratio": 0.9999874234199524, "entropy": 0.6246866583824158, "incre_win_rate": 0.9347826086956522, "step": 1959}
{"time": 1767340334.377621, "phase": "train", "update": 1960, "total_env_steps": 6272000, "episode_reward": 0.2651076018810272, "value_loss": 0.09209139496088029, "policy_loss": -0.00154856774653922, "dist_entropy": 0.6171945810317994, "actor_grad_norm": 0.08569414168596268, "critic_grad_norm": 0.22681264579296112, "ratio": 1.0000791549682617, "entropy": 0.6171945810317994, "incre_win_rate": 0.8913043478260869, "step": 1960}
{"time": 1767340338.46847, "phase": "train", "update": 1961, "total_env_steps": 6275200, "episode_reward": 0.2623727321624756, "value_loss": 0.007155822217464447, "policy_loss": -0.0015682461333035747, "dist_entropy": 0.6329833984375, "actor_grad_norm": 0.09362346678972244, "critic_grad_norm": 0.06730632483959198, "ratio": 1.0001999139785767, "entropy": 0.6329833984375, "incre_win_rate": 0.8536585365853658, "step": 1961}
{"time": 1767340342.5888717, "phase": "train", "update": 1962, "total_env_steps": 6278400, "episode_reward": 0.274532288312912, "value_loss": 0.00585282789543271, "policy_loss": -0.0013114890631079844, "dist_entropy": 0.657006585597992, "actor_grad_norm": 0.09497198462486267, "critic_grad_norm": 0.07859814912080765, "ratio": 0.9998381733894348, "entropy": 0.657006585597992, "incre_win_rate": 0.9318181818181818, "step": 1962}
{"time": 1767340346.667775, "phase": "train", "update": 1963, "total_env_steps": 6281600, "episode_reward": 0.26947227120399475, "value_loss": 0.006801569275557995, "policy_loss": -0.001085627601615613, "dist_entropy": 0.6491004705429078, "actor_grad_norm": 0.07217920571565628, "critic_grad_norm": 0.03882531076669693, "ratio": 0.9997418522834778, "entropy": 0.6491004705429078, "incre_win_rate": 0.8913043478260869, "step": 1963}
{"time": 1767340350.7923832, "phase": "train", "update": 1964, "total_env_steps": 6284800, "episode_reward": 0.27682483196258545, "value_loss": 0.003860892355442047, "policy_loss": -0.0013764682961252106, "dist_entropy": 0.673943567276001, "actor_grad_norm": 0.09486711770296097, "critic_grad_norm": 0.02782071940600872, "ratio": 0.9998065829277039, "entropy": 0.673943567276001, "incre_win_rate": 0.9545454545454546, "step": 1964}
{"time": 1767340354.8995366, "phase": "train", "update": 1965, "total_env_steps": 6288000, "episode_reward": 0.27636176347732544, "value_loss": 0.004624766297638416, "policy_loss": -0.001497393008881076, "dist_entropy": 0.6735963582992553, "actor_grad_norm": 0.09281661361455917, "critic_grad_norm": 0.025870636105537415, "ratio": 0.9999322891235352, "entropy": 0.6735963582992553, "incre_win_rate": 0.9333333333333333, "step": 1965}
{"time": 1767340359.0007613, "phase": "train", "update": 1966, "total_env_steps": 6291200, "episode_reward": 0.2603228688240051, "value_loss": 0.009816884808242322, "policy_loss": -0.0012985167277399512, "dist_entropy": 0.6638808608055115, "actor_grad_norm": 0.09209650754928589, "critic_grad_norm": 0.0393054261803627, "ratio": 0.9997205138206482, "entropy": 0.6638808608055115, "incre_win_rate": 0.8604651162790697, "step": 1966}
{"time": 1767340363.0902069, "phase": "train", "update": 1967, "total_env_steps": 6294400, "episode_reward": 0.2773701250553131, "value_loss": 0.006469156499952078, "policy_loss": -0.0011997519455910321, "dist_entropy": 0.6840303897857666, "actor_grad_norm": 0.08230145275592804, "critic_grad_norm": 0.04796488210558891, "ratio": 1.000069499015808, "entropy": 0.6840303897857666, "incre_win_rate": 0.9555555555555556, "step": 1967}
{"time": 1767340367.2146428, "phase": "train", "update": 1968, "total_env_steps": 6297600, "episode_reward": 0.2657460868358612, "value_loss": 0.008772323653101922, "policy_loss": -0.00115332047602692, "dist_entropy": 0.6632998943328857, "actor_grad_norm": 0.07802021503448486, "critic_grad_norm": 0.042985036969184875, "ratio": 0.9998394250869751, "entropy": 0.6632998943328857, "incre_win_rate": 0.8444444444444444, "step": 1968}
{"time": 1767340371.2769542, "phase": "train", "update": 1969, "total_env_steps": 6300800, "episode_reward": 0.2686682641506195, "value_loss": 0.007677353173494339, "policy_loss": -0.0010149168451469848, "dist_entropy": 0.6771771907806396, "actor_grad_norm": 0.07447204738855362, "critic_grad_norm": 0.053568240255117416, "ratio": 0.9997631907463074, "entropy": 0.6771771907806396, "incre_win_rate": 0.9047619047619048, "step": 1969}
{"time": 1767340375.437788, "phase": "train", "update": 1970, "total_env_steps": 6304000, "episode_reward": 0.2744893431663513, "value_loss": 0.006027990393340588, "policy_loss": -0.0012734525862811096, "dist_entropy": 0.6893390893936158, "actor_grad_norm": 0.09430442750453949, "critic_grad_norm": 0.037393104285001755, "ratio": 0.9998003840446472, "entropy": 0.6893390893936158, "incre_win_rate": 0.9565217391304348, "step": 1970}
{"time": 1767340379.4821918, "phase": "train", "update": 1971, "total_env_steps": 6307200, "episode_reward": 0.26733702421188354, "value_loss": 0.008590173721313477, "policy_loss": -0.0011669772585683803, "dist_entropy": 0.6641643524169922, "actor_grad_norm": 0.080105260014534, "critic_grad_norm": 0.050506897270679474, "ratio": 1.000040888786316, "entropy": 0.6641643524169922, "incre_win_rate": 0.8222222222222222, "step": 1971}
{"time": 1767340383.5882761, "phase": "train", "update": 1972, "total_env_steps": 6310400, "episode_reward": 0.27129966020584106, "value_loss": 0.006307702604681253, "policy_loss": -0.0010599121282723444, "dist_entropy": 0.6617992639541626, "actor_grad_norm": 0.08786431699991226, "critic_grad_norm": 0.07111616432666779, "ratio": 0.9999510049819946, "entropy": 0.6617992639541626, "incre_win_rate": 0.9069767441860465, "step": 1972}
{"time": 1767340387.7200656, "phase": "train", "update": 1973, "total_env_steps": 6313600, "episode_reward": 0.2692275643348694, "value_loss": 0.004095599800348282, "policy_loss": -0.0011906463436545777, "dist_entropy": 0.6716256737709045, "actor_grad_norm": 0.07965771108865738, "critic_grad_norm": 0.05785534530878067, "ratio": 0.9999945759773254, "entropy": 0.6716256737709045, "incre_win_rate": 0.9333333333333333, "step": 1973}
{"time": 1767340391.8272672, "phase": "train", "update": 1974, "total_env_steps": 6316800, "episode_reward": 0.269736647605896, "value_loss": 0.0078017315827310085, "policy_loss": -0.0013035006693347562, "dist_entropy": 0.6744061350822449, "actor_grad_norm": 0.0836053118109703, "critic_grad_norm": 0.0754283219575882, "ratio": 0.99978107213974, "entropy": 0.6744061350822449, "incre_win_rate": 0.8666666666666667, "step": 1974}
{"time": 1767340395.9204636, "phase": "train", "update": 1975, "total_env_steps": 6320000, "episode_reward": 0.27634522318840027, "value_loss": 0.004638944938778877, "policy_loss": -0.0013332282787272831, "dist_entropy": 0.6666284084320069, "actor_grad_norm": 0.10301216691732407, "critic_grad_norm": 0.04436379671096802, "ratio": 1.0003104209899902, "entropy": 0.6666284084320069, "incre_win_rate": 0.9534883720930233, "step": 1975}
{"time": 1767340400.0213733, "phase": "train", "update": 1976, "total_env_steps": 6323200, "episode_reward": 0.26759520173072815, "value_loss": 0.0066464911215007305, "policy_loss": -0.0013123746470014908, "dist_entropy": 0.6413212537765502, "actor_grad_norm": 0.09479275345802307, "critic_grad_norm": 0.041847217828035355, "ratio": 1.0002243518829346, "entropy": 0.6413212537765502, "incre_win_rate": 0.8478260869565217, "step": 1976}
{"time": 1767340409.3377297, "phase": "eval", "update": 1976, "total_env_steps": 6323200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.797599337748345, "step": 1976}
{"time": 1767340413.427759, "phase": "train", "update": 1977, "total_env_steps": 6326400, "episode_reward": 0.2825729548931122, "value_loss": 0.005688804946839809, "policy_loss": -0.0011324892815228083, "dist_entropy": 0.6422518968582154, "actor_grad_norm": 0.07213003188371658, "critic_grad_norm": 0.06294440478086472, "ratio": 1.000106692314148, "entropy": 0.6422518968582154, "incre_win_rate": 0.9565217391304348, "step": 1977}
{"time": 1767340417.5369446, "phase": "train", "update": 1978, "total_env_steps": 6329600, "episode_reward": 0.27575746178627014, "value_loss": 0.004805231746286154, "policy_loss": -0.0012611064970784013, "dist_entropy": 0.6456265449523926, "actor_grad_norm": 0.07844407856464386, "critic_grad_norm": 0.053541429340839386, "ratio": 0.9996303915977478, "entropy": 0.6456265449523926, "incre_win_rate": 0.9285714285714286, "step": 1978}
{"time": 1767340421.6207936, "phase": "train", "update": 1979, "total_env_steps": 6332800, "episode_reward": 0.27830401062965393, "value_loss": 0.003488948429003358, "policy_loss": -0.0011742073643159045, "dist_entropy": 0.6226161122322083, "actor_grad_norm": 0.07142224162817001, "critic_grad_norm": 0.050338394939899445, "ratio": 0.9998930096626282, "entropy": 0.6226161122322083, "incre_win_rate": 1.0, "step": 1979}
{"time": 1767340425.7053964, "phase": "train", "update": 1980, "total_env_steps": 6336000, "episode_reward": 0.28458040952682495, "value_loss": 0.0030249795410782097, "policy_loss": -0.0012449837210873227, "dist_entropy": 0.6189054012298584, "actor_grad_norm": 0.07437732070684433, "critic_grad_norm": 0.04770943149924278, "ratio": 1.0004490613937378, "entropy": 0.6189054012298584, "incre_win_rate": 0.9772727272727273, "step": 1980}
{"time": 1767340429.7742963, "phase": "train", "update": 1981, "total_env_steps": 6339200, "episode_reward": 0.27713990211486816, "value_loss": 0.002914506895467639, "policy_loss": -0.0012040431268580676, "dist_entropy": 0.6071690082550049, "actor_grad_norm": 0.08673731982707977, "critic_grad_norm": 0.03361570090055466, "ratio": 1.0003525018692017, "entropy": 0.6071690082550049, "incre_win_rate": 0.9787234042553191, "step": 1981}
{"time": 1767340433.8200405, "phase": "train", "update": 1982, "total_env_steps": 6342400, "episode_reward": 0.2828848958015442, "value_loss": 0.0024549441877752542, "policy_loss": -0.0010750384716132545, "dist_entropy": 0.6208271861076355, "actor_grad_norm": 0.08785732835531235, "critic_grad_norm": 0.022585436701774597, "ratio": 1.0002617835998535, "entropy": 0.6208271861076355, "incre_win_rate": 0.9772727272727273, "step": 1982}
{"time": 1767340437.8656204, "phase": "train", "update": 1983, "total_env_steps": 6345600, "episode_reward": 0.2729734182357788, "value_loss": 0.005533602088689804, "policy_loss": -0.0008860045764905067, "dist_entropy": 0.5986576676368713, "actor_grad_norm": 0.06994786113500595, "critic_grad_norm": 0.07847843319177628, "ratio": 1.0003433227539062, "entropy": 0.5986576676368713, "incre_win_rate": 0.9333333333333333, "step": 1983}
{"time": 1767340441.9432714, "phase": "train", "update": 1984, "total_env_steps": 6348800, "episode_reward": 0.27379554510116577, "value_loss": 0.005685763154178858, "policy_loss": -0.0016210866327824648, "dist_entropy": 0.6237046122550964, "actor_grad_norm": 0.08568012714385986, "critic_grad_norm": 0.07477682828903198, "ratio": 1.0000702142715454, "entropy": 0.6237046122550964, "incre_win_rate": 0.9302325581395349, "step": 1984}
{"time": 1767340446.0758443, "phase": "train", "update": 1985, "total_env_steps": 6352000, "episode_reward": 0.27366361021995544, "value_loss": 0.0054698589257895945, "policy_loss": -0.0008799398994520757, "dist_entropy": 0.6027595520019531, "actor_grad_norm": 0.09507540613412857, "critic_grad_norm": 0.028926653787493706, "ratio": 0.9996933937072754, "entropy": 0.6027595520019531, "incre_win_rate": 0.9130434782608695, "step": 1985}
{"time": 1767340450.1376522, "phase": "train", "update": 1986, "total_env_steps": 6355200, "episode_reward": 0.27097734808921814, "value_loss": 0.007528658583760261, "policy_loss": -0.0017064227165690226, "dist_entropy": 0.6128731608390808, "actor_grad_norm": 0.10597796738147736, "critic_grad_norm": 0.04963478818535805, "ratio": 0.9996983408927917, "entropy": 0.6128731608390808, "incre_win_rate": 0.8863636363636364, "step": 1986}
{"time": 1767340454.2788599, "phase": "train", "update": 1987, "total_env_steps": 6358400, "episode_reward": 0.27725163102149963, "value_loss": 0.004929133597761393, "policy_loss": -0.0013131260488458806, "dist_entropy": 0.6117503762245178, "actor_grad_norm": 0.09116458892822266, "critic_grad_norm": 0.03882283717393875, "ratio": 1.0002444982528687, "entropy": 0.6117503762245178, "incre_win_rate": 0.9545454545454546, "step": 1987}
{"time": 1767340458.371226, "phase": "train", "update": 1988, "total_env_steps": 6361600, "episode_reward": 0.27794700860977173, "value_loss": 0.003890461474657059, "policy_loss": -0.0012138103762880936, "dist_entropy": 0.6277567028999329, "actor_grad_norm": 0.07743246108293533, "critic_grad_norm": 0.040832825005054474, "ratio": 0.9997183084487915, "entropy": 0.6277567028999329, "incre_win_rate": 0.9347826086956522, "step": 1988}
{"time": 1767340462.424849, "phase": "train", "update": 1989, "total_env_steps": 6364800, "episode_reward": 0.27542218565940857, "value_loss": 0.0036956604104489087, "policy_loss": -0.0011421340001426916, "dist_entropy": 0.6166438698768616, "actor_grad_norm": 0.07919400185346603, "critic_grad_norm": 0.05520527437329292, "ratio": 1.000184178352356, "entropy": 0.6166438698768616, "incre_win_rate": 0.9565217391304348, "step": 1989}
{"time": 1767340466.4843411, "phase": "train", "update": 1990, "total_env_steps": 6368000, "episode_reward": 0.286143958568573, "value_loss": 0.0036489666905254125, "policy_loss": -0.0010400100141495726, "dist_entropy": 0.6319369077682495, "actor_grad_norm": 0.07703389972448349, "critic_grad_norm": 0.029064495116472244, "ratio": 0.9995822310447693, "entropy": 0.6319369077682495, "incre_win_rate": 0.9782608695652174, "step": 1990}
{"time": 1767340470.5577018, "phase": "train", "update": 1991, "total_env_steps": 6371200, "episode_reward": 0.2844468951225281, "value_loss": 0.003274811943992972, "policy_loss": -0.0013504047243912964, "dist_entropy": 0.6229942679405213, "actor_grad_norm": 0.10249807685613632, "critic_grad_norm": 0.05813882499933243, "ratio": 0.9998503923416138, "entropy": 0.6229942679405213, "incre_win_rate": 1.0, "step": 1991}
{"time": 1767340474.6876426, "phase": "train", "update": 1992, "total_env_steps": 6374400, "episode_reward": 0.28119516372680664, "value_loss": 0.004237894807010889, "policy_loss": -0.0012303487965825255, "dist_entropy": 0.6054146409034729, "actor_grad_norm": 0.0902128741145134, "critic_grad_norm": 0.04346749931573868, "ratio": 0.9998521208763123, "entropy": 0.6054146409034729, "incre_win_rate": 0.9787234042553191, "step": 1992}
{"time": 1767340478.7906086, "phase": "train", "update": 1993, "total_env_steps": 6377600, "episode_reward": 0.27210164070129395, "value_loss": 0.0031774910166859627, "policy_loss": -0.0013187958481310602, "dist_entropy": 0.6071822643280029, "actor_grad_norm": 0.07912345975637436, "critic_grad_norm": 0.029034674167633057, "ratio": 1.000174880027771, "entropy": 0.6071822643280029, "incre_win_rate": 0.9090909090909091, "step": 1993}
{"time": 1767340482.8983986, "phase": "train", "update": 1994, "total_env_steps": 6380800, "episode_reward": 0.279441237449646, "value_loss": 0.003031389880925417, "policy_loss": -0.0009569937847450305, "dist_entropy": 0.6090547800064087, "actor_grad_norm": 0.08401323109865189, "critic_grad_norm": 0.05266121029853821, "ratio": 1.0001448392868042, "entropy": 0.6090547800064087, "incre_win_rate": 0.9545454545454546, "step": 1994}
{"time": 1767340487.0189023, "phase": "train", "update": 1995, "total_env_steps": 6384000, "episode_reward": 0.2820033133029938, "value_loss": 0.0031280305702239275, "policy_loss": -0.001127213613689193, "dist_entropy": 0.6050003290176391, "actor_grad_norm": 0.08039680123329163, "critic_grad_norm": 0.035622913390398026, "ratio": 0.999932587146759, "entropy": 0.6050003290176391, "incre_win_rate": 0.9787234042553191, "step": 1995}
{"time": 1767340491.0677319, "phase": "train", "update": 1996, "total_env_steps": 6387200, "episode_reward": 0.28154492378234863, "value_loss": 0.005064251739531756, "policy_loss": -0.001240175693081369, "dist_entropy": 0.595920729637146, "actor_grad_norm": 0.08590434491634369, "critic_grad_norm": 0.030094195157289505, "ratio": 0.9998735785484314, "entropy": 0.595920729637146, "incre_win_rate": 0.9777777777777777, "step": 1996}
{"time": 1767340495.1528418, "phase": "train", "update": 1997, "total_env_steps": 6390400, "episode_reward": 0.28085678815841675, "value_loss": 0.005215076915919781, "policy_loss": -0.0008998840435630485, "dist_entropy": 0.5684523105621337, "actor_grad_norm": 0.083165742456913, "critic_grad_norm": 0.05804513767361641, "ratio": 0.9998524785041809, "entropy": 0.5684523105621337, "incre_win_rate": 0.9333333333333333, "step": 1997}
{"time": 1767340499.2611115, "phase": "train", "update": 1998, "total_env_steps": 6393600, "episode_reward": 0.2806265354156494, "value_loss": 0.004054987290874124, "policy_loss": -0.0011814983162562243, "dist_entropy": 0.5987214803695678, "actor_grad_norm": 0.11785077303647995, "critic_grad_norm": 0.03418811783194542, "ratio": 1.0000720024108887, "entropy": 0.5987214803695678, "incre_win_rate": 0.9583333333333334, "step": 1998}
{"time": 1767340503.3520951, "phase": "train", "update": 1999, "total_env_steps": 6396800, "episode_reward": 0.2820943593978882, "value_loss": 0.0035760886501520874, "policy_loss": -0.000841328142796982, "dist_entropy": 0.59177086353302, "actor_grad_norm": 0.0825897604227066, "critic_grad_norm": 0.050386954098939896, "ratio": 1.0001360177993774, "entropy": 0.59177086353302, "incre_win_rate": 0.9772727272727273, "step": 1999}
{"time": 1767340507.5286782, "phase": "train", "update": 2000, "total_env_steps": 6400000, "episode_reward": 0.289730966091156, "value_loss": 0.0020795709919184447, "policy_loss": -0.0010093394967711333, "dist_entropy": 0.6052671313285828, "actor_grad_norm": 0.08845707774162292, "critic_grad_norm": 0.02337919920682907, "ratio": 0.999512791633606, "entropy": 0.6052671313285828, "incre_win_rate": 1.0, "step": 2000}
{"time": 1767340511.5867605, "phase": "train", "update": 2001, "total_env_steps": 6403200, "episode_reward": 0.27372050285339355, "value_loss": 0.00568955410271883, "policy_loss": -0.0014291504314442704, "dist_entropy": 0.5873955726623535, "actor_grad_norm": 0.08806216716766357, "critic_grad_norm": 0.027541622519493103, "ratio": 1.0000262260437012, "entropy": 0.5873955726623535, "incre_win_rate": 0.9523809523809523, "step": 2001}
{"time": 1767340520.7211392, "phase": "eval", "update": 2001, "total_env_steps": 6403200, "eval_win_rate": 1.0, "eval_episode_reward": 20.0, "step": 2001}
{"time": 1767340524.7763326, "phase": "train", "update": 2002, "total_env_steps": 6406400, "episode_reward": 0.26597267389297485, "value_loss": 0.007391234021633863, "policy_loss": -0.0014657179432957079, "dist_entropy": 0.5676658391952515, "actor_grad_norm": 0.0794130489230156, "critic_grad_norm": 0.0471881665289402, "ratio": 1.0000529289245605, "entropy": 0.5676658391952515, "incre_win_rate": 0.8695652173913043, "step": 2002}
{"time": 1767340528.8879483, "phase": "train", "update": 2003, "total_env_steps": 6409600, "episode_reward": 0.28406664729118347, "value_loss": 0.005326083023101091, "policy_loss": -0.000920206610481955, "dist_entropy": 0.5574583172798157, "actor_grad_norm": 0.08376102894544601, "critic_grad_norm": 0.06275028735399246, "ratio": 1.0001102685928345, "entropy": 0.5574583172798157, "incre_win_rate": 0.9555555555555556, "step": 2003}
{"time": 1767340533.011125, "phase": "train", "update": 2004, "total_env_steps": 6412800, "episode_reward": 0.28284355998039246, "value_loss": 0.004306243639439345, "policy_loss": -0.0009495053515621521, "dist_entropy": 0.5602661371231079, "actor_grad_norm": 0.08723961561918259, "critic_grad_norm": 0.05945218354463577, "ratio": 1.0002243518829346, "entropy": 0.5602661371231079, "incre_win_rate": 0.9565217391304348, "step": 2004}
{"time": 1767340537.1469924, "phase": "train", "update": 2005, "total_env_steps": 6416000, "episode_reward": 0.2808164358139038, "value_loss": 0.003360140975564718, "policy_loss": -0.0008945304900407792, "dist_entropy": 0.5605014443397522, "actor_grad_norm": 0.08197545260190964, "critic_grad_norm": 0.056104667484760284, "ratio": 1.0001615285873413, "entropy": 0.5605014443397522, "incre_win_rate": 0.9565217391304348, "step": 2005}
{"time": 1767340541.2062764, "phase": "train", "update": 2006, "total_env_steps": 6419200, "episode_reward": 0.2779015004634857, "value_loss": 0.00429222472012043, "policy_loss": -0.0011222872399969219, "dist_entropy": 0.5672729134559631, "actor_grad_norm": 0.08333133906126022, "critic_grad_norm": 0.03049052320420742, "ratio": 1.000223994255066, "entropy": 0.5672729134559631, "incre_win_rate": 0.9318181818181818, "step": 2006}
{"time": 1767340545.297312, "phase": "train", "update": 2007, "total_env_steps": 6422400, "episode_reward": 0.28106632828712463, "value_loss": 0.005320806242525578, "policy_loss": -0.0010630495655377104, "dist_entropy": 0.5835924267768859, "actor_grad_norm": 0.07617750018835068, "critic_grad_norm": 0.05334910377860069, "ratio": 1.0001271963119507, "entropy": 0.5835924267768859, "incre_win_rate": 0.9777777777777777, "step": 2007}
{"time": 1767340549.3675432, "phase": "train", "update": 2008, "total_env_steps": 6425600, "episode_reward": 0.2780390977859497, "value_loss": 0.004791645798832178, "policy_loss": -0.001310766481039849, "dist_entropy": 0.5912622094154358, "actor_grad_norm": 0.08617787808179855, "critic_grad_norm": 0.05122767761349678, "ratio": 1.0000532865524292, "entropy": 0.5912622094154358, "incre_win_rate": 0.9333333333333333, "step": 2008}
{"time": 1767340553.4653406, "phase": "train", "update": 2009, "total_env_steps": 6428800, "episode_reward": 0.28118792176246643, "value_loss": 0.004000902967527508, "policy_loss": -0.0012374881417223094, "dist_entropy": 0.5842182159423828, "actor_grad_norm": 0.09473635256290436, "critic_grad_norm": 0.03256940841674805, "ratio": 0.9996294975280762, "entropy": 0.5842182159423828, "incre_win_rate": 0.9565217391304348, "step": 2009}
{"time": 1767340557.5937836, "phase": "train", "update": 2010, "total_env_steps": 6432000, "episode_reward": 0.28211507201194763, "value_loss": 0.0026661910116672514, "policy_loss": -0.0013210352440822248, "dist_entropy": 0.5791911244392395, "actor_grad_norm": 0.0738489106297493, "critic_grad_norm": 0.036116693168878555, "ratio": 0.9998772740364075, "entropy": 0.5791911244392395, "incre_win_rate": 0.9565217391304348, "step": 2010}
{"time": 1767340561.71591, "phase": "train", "update": 2011, "total_env_steps": 6435200, "episode_reward": 0.2927525043487549, "value_loss": 0.004099290911108255, "policy_loss": -0.001143940217470174, "dist_entropy": 0.5904000639915467, "actor_grad_norm": 0.07318315654993057, "critic_grad_norm": 0.029394645243883133, "ratio": 0.9998558163642883, "entropy": 0.5904000639915467, "incre_win_rate": 0.9791666666666666, "step": 2011}
{"time": 1767340565.8672006, "phase": "train", "update": 2012, "total_env_steps": 6438400, "episode_reward": 0.2932615876197815, "value_loss": 0.0020409199874848126, "policy_loss": -0.0010766665626881888, "dist_entropy": 0.5962721586227417, "actor_grad_norm": 0.07087381184101105, "critic_grad_norm": 0.06017262861132622, "ratio": 0.9999025464057922, "entropy": 0.5962721586227417, "incre_win_rate": 0.9787234042553191, "step": 2012}
{"time": 1767340569.9547899, "phase": "train", "update": 2013, "total_env_steps": 6441600, "episode_reward": 0.27960991859436035, "value_loss": 0.003779600281268358, "policy_loss": -0.0010395884086140228, "dist_entropy": 0.5794262170791626, "actor_grad_norm": 0.07140148431062698, "critic_grad_norm": 0.03193327784538269, "ratio": 1.0000892877578735, "entropy": 0.5794262170791626, "incre_win_rate": 0.9555555555555556, "step": 2013}
{"time": 1767340574.0657413, "phase": "train", "update": 2014, "total_env_steps": 6444800, "episode_reward": 0.2835109829902649, "value_loss": 0.004345689620822668, "policy_loss": -0.0012835655624954256, "dist_entropy": 0.5690876364707946, "actor_grad_norm": 0.08459479361772537, "critic_grad_norm": 0.034792110323905945, "ratio": 1.0002104043960571, "entropy": 0.5690876364707946, "incre_win_rate": 0.9772727272727273, "step": 2014}
{"time": 1767340578.1706822, "phase": "train", "update": 2015, "total_env_steps": 6448000, "episode_reward": 0.2872392237186432, "value_loss": 0.0037159469444304704, "policy_loss": -0.0012564794586539473, "dist_entropy": 0.5620421290397644, "actor_grad_norm": 0.07976744323968887, "critic_grad_norm": 0.022959189489483833, "ratio": 1.000077486038208, "entropy": 0.5620421290397644, "incre_win_rate": 0.9782608695652174, "step": 2015}
{"time": 1767340582.3283658, "phase": "train", "update": 2016, "total_env_steps": 6451200, "episode_reward": 0.292048841714859, "value_loss": 0.0037581353913992642, "policy_loss": -0.0014300445691130647, "dist_entropy": 0.5702745914459229, "actor_grad_norm": 0.08617714792490005, "critic_grad_norm": 0.02384788542985916, "ratio": 0.9999184012413025, "entropy": 0.5702745914459229, "incre_win_rate": 0.9583333333333334, "step": 2016}
{"time": 1767340586.4317589, "phase": "train", "update": 2017, "total_env_steps": 6454400, "episode_reward": 0.2793005108833313, "value_loss": 0.006173695158213377, "policy_loss": -0.001508164519588151, "dist_entropy": 0.5543087601661683, "actor_grad_norm": 0.09024947136640549, "critic_grad_norm": 0.0317942313849926, "ratio": 0.9998626708984375, "entropy": 0.5543087601661683, "incre_win_rate": 0.8888888888888888, "step": 2017}
{"time": 1767340590.5524983, "phase": "train", "update": 2018, "total_env_steps": 6457600, "episode_reward": 0.26357409358024597, "value_loss": 0.009372860752046108, "policy_loss": -0.0014120023720629149, "dist_entropy": 0.5635442018508912, "actor_grad_norm": 0.08731105178594589, "critic_grad_norm": 0.06075158342719078, "ratio": 0.9999799728393555, "entropy": 0.5635442018508912, "incre_win_rate": 0.8, "step": 2018}
{"time": 1767340594.7073994, "phase": "train", "update": 2019, "total_env_steps": 6460800, "episode_reward": 0.2799058258533478, "value_loss": 0.004922254756093025, "policy_loss": -0.0012156591455749321, "dist_entropy": 0.5999704122543335, "actor_grad_norm": 0.10590153187513351, "critic_grad_norm": 0.03798428922891617, "ratio": 1.0002835988998413, "entropy": 0.5999704122543335, "incre_win_rate": 0.9347826086956522, "step": 2019}
{"time": 1767340598.894082, "phase": "train", "update": 2020, "total_env_steps": 6464000, "episode_reward": 0.27823469042778015, "value_loss": 0.0082106770016253, "policy_loss": -0.0012910306692852202, "dist_entropy": 0.5750155925750733, "actor_grad_norm": 0.09277495741844177, "critic_grad_norm": 0.06674026697874069, "ratio": 0.9999759793281555, "entropy": 0.5750155925750733, "incre_win_rate": 0.9333333333333333, "step": 2020}
{"time": 1767340603.0078855, "phase": "train", "update": 2021, "total_env_steps": 6467200, "episode_reward": 0.2817963659763336, "value_loss": 0.003170095104724169, "policy_loss": -0.001021426996018704, "dist_entropy": 0.5574149012565612, "actor_grad_norm": 0.10279418528079987, "critic_grad_norm": 0.04525071382522583, "ratio": 0.9998661875724792, "entropy": 0.5574149012565612, "incre_win_rate": 0.9361702127659575, "step": 2021}
{"time": 1767340607.1374125, "phase": "train", "update": 2022, "total_env_steps": 6470400, "episode_reward": 0.2771042287349701, "value_loss": 0.005689368769526482, "policy_loss": -0.0014350615701644643, "dist_entropy": 0.5776514768600464, "actor_grad_norm": 0.10669969767332077, "critic_grad_norm": 0.0350969024002552, "ratio": 1.0002425909042358, "entropy": 0.5776514768600464, "incre_win_rate": 0.9090909090909091, "step": 2022}
{"time": 1767340611.2603226, "phase": "train", "update": 2023, "total_env_steps": 6473600, "episode_reward": 0.28253722190856934, "value_loss": 0.005692506954073906, "policy_loss": -0.0010368796958601934, "dist_entropy": 0.584361445903778, "actor_grad_norm": 0.09056387096643448, "critic_grad_norm": 0.03303968533873558, "ratio": 1.0000383853912354, "entropy": 0.584361445903778, "incre_win_rate": 0.9361702127659575, "step": 2023}
{"time": 1767340615.3963547, "phase": "train", "update": 2024, "total_env_steps": 6476800, "episode_reward": 0.29175081849098206, "value_loss": 0.004215387813746929, "policy_loss": -0.0017719011062823143, "dist_entropy": 0.6116785645484925, "actor_grad_norm": 0.10030647367238998, "critic_grad_norm": 0.029169583693146706, "ratio": 0.9999299049377441, "entropy": 0.6116785645484925, "incre_win_rate": 0.9787234042553191, "step": 2024}
{"time": 1767340619.4997568, "phase": "train", "update": 2025, "total_env_steps": 6480000, "episode_reward": 0.2821424901485443, "value_loss": 0.005023873783648014, "policy_loss": -0.0013790454277245346, "dist_entropy": 0.5733630776405334, "actor_grad_norm": 0.07565809786319733, "critic_grad_norm": 0.03502209484577179, "ratio": 1.0002177953720093, "entropy": 0.5733630776405334, "incre_win_rate": 0.9565217391304348, "step": 2025}
{"time": 1767340623.6362195, "phase": "train", "update": 2026, "total_env_steps": 6483200, "episode_reward": 0.2733919620513916, "value_loss": 0.00730492128059268, "policy_loss": -0.001249991052857169, "dist_entropy": 0.5611464142799377, "actor_grad_norm": 0.09523468464612961, "critic_grad_norm": 0.033862318843603134, "ratio": 0.9999740719795227, "entropy": 0.5611464142799377, "incre_win_rate": 0.8837209302325582, "step": 2026}
{"time": 1767340633.0083177, "phase": "eval", "update": 2026, "total_env_steps": 6483200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.908992135761586, "step": 2026}
{"time": 1767340637.1211345, "phase": "train", "update": 2027, "total_env_steps": 6486400, "episode_reward": 0.2834395468235016, "value_loss": 0.0046700331382453445, "policy_loss": -0.0013373475779680176, "dist_entropy": 0.5791240334510803, "actor_grad_norm": 0.09937318414449692, "critic_grad_norm": 0.04727863892912865, "ratio": 0.9999522566795349, "entropy": 0.5791240334510803, "incre_win_rate": 0.9387755102040817, "step": 2027}
{"time": 1767340641.2132723, "phase": "train", "update": 2028, "total_env_steps": 6489600, "episode_reward": 0.2825160324573517, "value_loss": 0.006246782280504704, "policy_loss": -0.001287591409052613, "dist_entropy": 0.5585904240608215, "actor_grad_norm": 0.09393894672393799, "critic_grad_norm": 0.03604679927229881, "ratio": 1.0000461339950562, "entropy": 0.5585904240608215, "incre_win_rate": 0.9767441860465116, "step": 2028}
{"time": 1767340645.3122158, "phase": "train", "update": 2029, "total_env_steps": 6492800, "episode_reward": 0.28727030754089355, "value_loss": 0.0029415586963295937, "policy_loss": -0.001244260216374471, "dist_entropy": 0.5507936239242553, "actor_grad_norm": 0.10800977051258087, "critic_grad_norm": 0.027750670909881592, "ratio": 0.9998610615730286, "entropy": 0.5507936239242553, "incre_win_rate": 0.9791666666666666, "step": 2029}
{"time": 1767340649.4244866, "phase": "train", "update": 2030, "total_env_steps": 6496000, "episode_reward": 0.28780990839004517, "value_loss": 0.0031505787279456853, "policy_loss": -0.0011795646273043304, "dist_entropy": 0.5538355708122253, "actor_grad_norm": 0.08795273303985596, "critic_grad_norm": 0.025364423170685768, "ratio": 1.000348448753357, "entropy": 0.5538355708122253, "incre_win_rate": 0.9361702127659575, "step": 2030}
{"time": 1767340653.511119, "phase": "train", "update": 2031, "total_env_steps": 6499200, "episode_reward": 0.2887996733188629, "value_loss": 0.0029043053276836873, "policy_loss": -0.0007313398842567764, "dist_entropy": 0.5845953583717346, "actor_grad_norm": 0.07785917818546295, "critic_grad_norm": 0.00914574321359396, "ratio": 0.9998275637626648, "entropy": 0.5845953583717346, "incre_win_rate": 0.9782608695652174, "step": 2031}
{"time": 1767340657.6555128, "phase": "train", "update": 2032, "total_env_steps": 6502400, "episode_reward": 0.2875496745109558, "value_loss": 0.002014896459877491, "policy_loss": -0.0008570567048082012, "dist_entropy": 0.5864951133728027, "actor_grad_norm": 0.08441507816314697, "critic_grad_norm": 0.00953594595193863, "ratio": 0.9999904036521912, "entropy": 0.5864951133728027, "incre_win_rate": 1.0, "step": 2032}
{"time": 1767340661.7376027, "phase": "train", "update": 2033, "total_env_steps": 6505600, "episode_reward": 0.27789735794067383, "value_loss": 0.0052678374573588375, "policy_loss": -0.000949764856250468, "dist_entropy": 0.5902378916740417, "actor_grad_norm": 0.08349688351154327, "critic_grad_norm": 0.03919078782200813, "ratio": 1.0001081228256226, "entropy": 0.5902378916740417, "incre_win_rate": 0.8936170212765957, "step": 2033}
{"time": 1767340665.8709204, "phase": "train", "update": 2034, "total_env_steps": 6508800, "episode_reward": 0.27636176347732544, "value_loss": 0.006347894854843617, "policy_loss": -0.0007941235065480612, "dist_entropy": 0.5868284821510314, "actor_grad_norm": 0.08930360525846481, "critic_grad_norm": 0.04134198650717735, "ratio": 0.9996659159660339, "entropy": 0.5868284821510314, "incre_win_rate": 0.9302325581395349, "step": 2034}
{"time": 1767340669.969505, "phase": "train", "update": 2035, "total_env_steps": 6512000, "episode_reward": 0.2733733654022217, "value_loss": 0.007203683350235223, "policy_loss": -0.00137160087766528, "dist_entropy": 0.5871279835700989, "actor_grad_norm": 0.11219978332519531, "critic_grad_norm": 0.03134448453783989, "ratio": 1.0000369548797607, "entropy": 0.5871279835700989, "incre_win_rate": 0.9333333333333333, "step": 2035}
{"time": 1767340674.0918374, "phase": "train", "update": 2036, "total_env_steps": 6515200, "episode_reward": 0.2841644287109375, "value_loss": 0.004717121925204992, "policy_loss": -0.0011184111188171642, "dist_entropy": 0.6314906597137451, "actor_grad_norm": 0.07662658393383026, "critic_grad_norm": 0.06763268262147903, "ratio": 0.9999790191650391, "entropy": 0.6314906597137451, "incre_win_rate": 0.9565217391304348, "step": 2036}
{"time": 1767340678.2056625, "phase": "train", "update": 2037, "total_env_steps": 6518400, "episode_reward": 0.28016558289527893, "value_loss": 0.005645396839827299, "policy_loss": -0.001238621481972757, "dist_entropy": 0.6368913054466248, "actor_grad_norm": 0.06988219916820526, "critic_grad_norm": 0.04047980159521103, "ratio": 0.9998776316642761, "entropy": 0.6368913054466248, "incre_win_rate": 0.9565217391304348, "step": 2037}
{"time": 1767340682.3279426, "phase": "train", "update": 2038, "total_env_steps": 6521600, "episode_reward": 0.27780216932296753, "value_loss": 0.006335899420082569, "policy_loss": -0.0013168780034163775, "dist_entropy": 0.6151983737945557, "actor_grad_norm": 0.07672116905450821, "critic_grad_norm": 0.040836673229932785, "ratio": 0.9999820590019226, "entropy": 0.6151983737945557, "incre_win_rate": 0.8913043478260869, "step": 2038}
{"time": 1767340686.4603324, "phase": "train", "update": 2039, "total_env_steps": 6524800, "episode_reward": 0.28200438618659973, "value_loss": 0.0037124799098819496, "policy_loss": -0.0011982163030928917, "dist_entropy": 0.6029505014419556, "actor_grad_norm": 0.07463577389717102, "critic_grad_norm": 0.02965705096721649, "ratio": 0.9998759627342224, "entropy": 0.6029505014419556, "incre_win_rate": 0.9565217391304348, "step": 2039}
{"time": 1767340690.577159, "phase": "train", "update": 2040, "total_env_steps": 6528000, "episode_reward": 0.27904802560806274, "value_loss": 0.003610195079818368, "policy_loss": -0.001349250804351243, "dist_entropy": 0.6085542678833008, "actor_grad_norm": 0.07232961803674698, "critic_grad_norm": 0.028432754799723625, "ratio": 0.9997486472129822, "entropy": 0.6085542678833008, "incre_win_rate": 0.9111111111111111, "step": 2040}
{"time": 1767340694.6847532, "phase": "train", "update": 2041, "total_env_steps": 6531200, "episode_reward": 0.27063223719596863, "value_loss": 0.006886094622313976, "policy_loss": -0.0010465918644015915, "dist_entropy": 0.6046994805335999, "actor_grad_norm": 0.07706470042467117, "critic_grad_norm": 0.04370392486453056, "ratio": 1.0000851154327393, "entropy": 0.6046994805335999, "incre_win_rate": 0.8863636363636364, "step": 2041}
{"time": 1767340698.8160021, "phase": "train", "update": 2042, "total_env_steps": 6534400, "episode_reward": 0.28073936700820923, "value_loss": 0.005016768630594015, "policy_loss": -0.0014503485754460144, "dist_entropy": 0.6191438198089599, "actor_grad_norm": 0.08265190571546555, "critic_grad_norm": 0.04619012400507927, "ratio": 1.0000848770141602, "entropy": 0.6191438198089599, "incre_win_rate": 0.9777777777777777, "step": 2042}
{"time": 1767340702.9015603, "phase": "train", "update": 2043, "total_env_steps": 6537600, "episode_reward": 0.28656870126724243, "value_loss": 0.002073337836191058, "policy_loss": -0.0008399357181062328, "dist_entropy": 0.6303764462471009, "actor_grad_norm": 0.07658644020557404, "critic_grad_norm": 0.040858425199985504, "ratio": 0.999596118927002, "entropy": 0.6303764462471009, "incre_win_rate": 0.9787234042553191, "step": 2043}
{"time": 1767340707.0044317, "phase": "train", "update": 2044, "total_env_steps": 6540800, "episode_reward": 0.2802700698375702, "value_loss": 0.0029062000568956135, "policy_loss": -0.0012822188921091993, "dist_entropy": 0.6387942433357239, "actor_grad_norm": 0.09616296738386154, "critic_grad_norm": 0.02061653696000576, "ratio": 1.0000523328781128, "entropy": 0.6387942433357239, "incre_win_rate": 0.9333333333333333, "step": 2044}
{"time": 1767340711.105568, "phase": "train", "update": 2045, "total_env_steps": 6544000, "episode_reward": 0.27750828862190247, "value_loss": 0.003467646287754178, "policy_loss": -0.0015716042530591779, "dist_entropy": 0.6282663941383362, "actor_grad_norm": 0.09511077404022217, "critic_grad_norm": 0.014489869587123394, "ratio": 0.9997915625572205, "entropy": 0.6282663941383362, "incre_win_rate": 0.9555555555555556, "step": 2045}
{"time": 1767340715.2315643, "phase": "train", "update": 2046, "total_env_steps": 6547200, "episode_reward": 0.2815924882888794, "value_loss": 0.004839011095464229, "policy_loss": -0.0015095603138529866, "dist_entropy": 0.6138110518455505, "actor_grad_norm": 0.08652064204216003, "critic_grad_norm": 0.022452516481280327, "ratio": 0.9997747540473938, "entropy": 0.6138110518455505, "incre_win_rate": 0.9333333333333333, "step": 2046}
{"time": 1767340719.3432739, "phase": "train", "update": 2047, "total_env_steps": 6550400, "episode_reward": 0.27231064438819885, "value_loss": 0.007788189686834812, "policy_loss": -0.0011868272290129767, "dist_entropy": 0.6129164934158325, "actor_grad_norm": 0.08913106471300125, "critic_grad_norm": 0.02604086510837078, "ratio": 0.9998736381530762, "entropy": 0.6129164934158325, "incre_win_rate": 0.9347826086956522, "step": 2047}
{"time": 1767340723.468227, "phase": "train", "update": 2048, "total_env_steps": 6553600, "episode_reward": 0.27710264921188354, "value_loss": 0.006811246927827597, "policy_loss": -0.0014729850853189674, "dist_entropy": 0.6240333437919616, "actor_grad_norm": 0.1132657453417778, "critic_grad_norm": 0.028272384777665138, "ratio": 1.0001237392425537, "entropy": 0.6240333437919616, "incre_win_rate": 0.9318181818181818, "step": 2048}
{"time": 1767340727.5752006, "phase": "train", "update": 2049, "total_env_steps": 6556800, "episode_reward": 0.2754635810852051, "value_loss": 0.00465321745723486, "policy_loss": -0.0012110455321582946, "dist_entropy": 0.6256002068519593, "actor_grad_norm": 0.09945575147867203, "critic_grad_norm": 0.019720951095223427, "ratio": 1.0003187656402588, "entropy": 0.6256002068519593, "incre_win_rate": 0.9555555555555556, "step": 2049}
{"time": 1767340731.6633549, "phase": "train", "update": 2050, "total_env_steps": 6560000, "episode_reward": 0.2719826102256775, "value_loss": 0.004775772709399462, "policy_loss": -0.0011175686255427309, "dist_entropy": 0.645330011844635, "actor_grad_norm": 0.07677539438009262, "critic_grad_norm": 0.015913845971226692, "ratio": 0.9999179840087891, "entropy": 0.645330011844635, "incre_win_rate": 0.9534883720930233, "step": 2050}
{"time": 1767340735.7246222, "phase": "train", "update": 2051, "total_env_steps": 6563200, "episode_reward": 0.273361474275589, "value_loss": 0.005442988965660334, "policy_loss": -0.0013952771453634937, "dist_entropy": 0.644936490058899, "actor_grad_norm": 0.09666790068149567, "critic_grad_norm": 0.025701848790049553, "ratio": 0.9999842047691345, "entropy": 0.644936490058899, "incre_win_rate": 0.9318181818181818, "step": 2051}
{"time": 1767340745.2187645, "phase": "eval", "update": 2051, "total_env_steps": 6563200, "eval_win_rate": 1.0, "eval_episode_reward": 20.001034768211923, "step": 2051}
{"time": 1767340749.3158722, "phase": "train", "update": 2052, "total_env_steps": 6566400, "episode_reward": 0.2680949866771698, "value_loss": 0.004404250718653202, "policy_loss": -0.0012414231329248792, "dist_entropy": 0.6663669586181641, "actor_grad_norm": 0.08826618641614914, "critic_grad_norm": 0.040334057062864304, "ratio": 1.0001945495605469, "entropy": 0.6663669586181641, "incre_win_rate": 0.8913043478260869, "step": 2052}
{"time": 1767340753.4490504, "phase": "train", "update": 2053, "total_env_steps": 6569600, "episode_reward": 0.27250415086746216, "value_loss": 0.005964005831629038, "policy_loss": -0.001011373446090147, "dist_entropy": 0.6684487462043762, "actor_grad_norm": 0.0729818344116211, "critic_grad_norm": 0.04729282483458519, "ratio": 1.0000804662704468, "entropy": 0.6684487462043762, "incre_win_rate": 0.9069767441860465, "step": 2053}
{"time": 1767340757.5581627, "phase": "train", "update": 2054, "total_env_steps": 6572800, "episode_reward": 0.25470665097236633, "value_loss": 0.006367085687816143, "policy_loss": -0.0011512604078568246, "dist_entropy": 0.6693487405776978, "actor_grad_norm": 0.08120397478342056, "critic_grad_norm": 0.04753027483820915, "ratio": 1.000218152999878, "entropy": 0.6693487405776978, "incre_win_rate": 0.8636363636363636, "step": 2054}
{"time": 1767340761.646191, "phase": "train", "update": 2055, "total_env_steps": 6576000, "episode_reward": 0.2753218114376068, "value_loss": 0.009967415407299996, "policy_loss": -0.0011501088528518722, "dist_entropy": 0.6859133839607239, "actor_grad_norm": 0.09448932111263275, "critic_grad_norm": 0.05287454277276993, "ratio": 0.9997655153274536, "entropy": 0.6859133839607239, "incre_win_rate": 0.9318181818181818, "step": 2055}
{"time": 1767340765.6878889, "phase": "train", "update": 2056, "total_env_steps": 6579200, "episode_reward": 0.2602602243423462, "value_loss": 0.010123733803629876, "policy_loss": -0.0011588537193595982, "dist_entropy": 0.6756818652153015, "actor_grad_norm": 0.09196239709854126, "critic_grad_norm": 0.03923140838742256, "ratio": 0.9996575713157654, "entropy": 0.6756818652153015, "incre_win_rate": 0.8181818181818182, "step": 2056}
{"time": 1767340769.7763784, "phase": "train", "update": 2057, "total_env_steps": 6582400, "episode_reward": 0.26815861463546753, "value_loss": 0.006748416740447283, "policy_loss": -0.0013133738237669946, "dist_entropy": 0.6874075770378113, "actor_grad_norm": 0.10528718680143356, "critic_grad_norm": 0.07015271484851837, "ratio": 1.0000972747802734, "entropy": 0.6874075770378113, "incre_win_rate": 0.8888888888888888, "step": 2057}
{"time": 1767340773.8434515, "phase": "train", "update": 2058, "total_env_steps": 6585600, "episode_reward": 0.26451313495635986, "value_loss": 0.006846106052398682, "policy_loss": -0.001297038083370694, "dist_entropy": 0.7145942807197571, "actor_grad_norm": 0.0790952742099762, "critic_grad_norm": 0.07375850528478622, "ratio": 0.9998126029968262, "entropy": 0.7145942807197571, "incre_win_rate": 0.8571428571428571, "step": 2058}
{"time": 1767340777.9154246, "phase": "train", "update": 2059, "total_env_steps": 6588800, "episode_reward": 0.24279646575450897, "value_loss": 0.010544245876371861, "policy_loss": -0.001396783539209423, "dist_entropy": 0.7212382912635803, "actor_grad_norm": 0.09742312878370285, "critic_grad_norm": 0.07534714043140411, "ratio": 0.9998227953910828, "entropy": 0.7212382912635803, "incre_win_rate": 0.7619047619047619, "step": 2059}
{"time": 1767340781.9811504, "phase": "train", "update": 2060, "total_env_steps": 6592000, "episode_reward": 0.2624032497406006, "value_loss": 0.007515333592891693, "policy_loss": -0.0013957627070396938, "dist_entropy": 0.71920747756958, "actor_grad_norm": 0.09949783235788345, "critic_grad_norm": 0.03895358368754387, "ratio": 0.9999272227287292, "entropy": 0.71920747756958, "incre_win_rate": 0.9090909090909091, "step": 2060}
{"time": 1767340786.0455248, "phase": "train", "update": 2061, "total_env_steps": 6595200, "episode_reward": 0.2742384076118469, "value_loss": 0.00605182284489274, "policy_loss": -0.0009942846757944324, "dist_entropy": 0.7396712183952332, "actor_grad_norm": 0.10264936834573746, "critic_grad_norm": 0.06987019628286362, "ratio": 1.000178575515747, "entropy": 0.7396712183952332, "incre_win_rate": 0.8837209302325582, "step": 2061}
{"time": 1767340790.140647, "phase": "train", "update": 2062, "total_env_steps": 6598400, "episode_reward": 0.2661615312099457, "value_loss": 0.007882855925709009, "policy_loss": -0.0013987455248347658, "dist_entropy": 0.7103492736816406, "actor_grad_norm": 0.10494636744260788, "critic_grad_norm": 0.03193805739283562, "ratio": 1.0000170469284058, "entropy": 0.7103492736816406, "incre_win_rate": 0.9130434782608695, "step": 2062}
{"time": 1767340794.2066827, "phase": "train", "update": 2063, "total_env_steps": 6601600, "episode_reward": 0.27025920152664185, "value_loss": 0.006854938622564077, "policy_loss": -0.0013169003842826044, "dist_entropy": 0.702905786037445, "actor_grad_norm": 0.08683549612760544, "critic_grad_norm": 0.02298637665808201, "ratio": 1.0000770092010498, "entropy": 0.702905786037445, "incre_win_rate": 0.8863636363636364, "step": 2063}
{"time": 1767340798.3110626, "phase": "train", "update": 2064, "total_env_steps": 6604800, "episode_reward": 0.2736703157424927, "value_loss": 0.006822281051427126, "policy_loss": -0.0015735899067408354, "dist_entropy": 0.7015544414520264, "actor_grad_norm": 0.08896398544311523, "critic_grad_norm": 0.02222689799964428, "ratio": 0.9997922778129578, "entropy": 0.7015544414520264, "incre_win_rate": 0.9090909090909091, "step": 2064}
{"time": 1767340802.3928194, "phase": "train", "update": 2065, "total_env_steps": 6608000, "episode_reward": 0.27108755707740784, "value_loss": 0.00827038697898388, "policy_loss": -0.0014065673108561328, "dist_entropy": 0.6933157801628113, "actor_grad_norm": 0.09620337933301926, "critic_grad_norm": 0.02710113488137722, "ratio": 0.9999176263809204, "entropy": 0.6933157801628113, "incre_win_rate": 0.8888888888888888, "step": 2065}
{"time": 1767340806.4741325, "phase": "train", "update": 2066, "total_env_steps": 6611200, "episode_reward": 0.27170529961586, "value_loss": 0.007111191377043724, "policy_loss": -0.001413161535117524, "dist_entropy": 0.6985540151596069, "actor_grad_norm": 0.08862508833408356, "critic_grad_norm": 0.03736597299575806, "ratio": 1.000170350074768, "entropy": 0.6985540151596069, "incre_win_rate": 0.9302325581395349, "step": 2066}
{"time": 1767340810.6014516, "phase": "train", "update": 2067, "total_env_steps": 6614400, "episode_reward": 0.2725600302219391, "value_loss": 0.007252359669655562, "policy_loss": -0.001708973496067756, "dist_entropy": 0.689759123325348, "actor_grad_norm": 0.10095404833555222, "critic_grad_norm": 0.05114122852683067, "ratio": 0.9999874234199524, "entropy": 0.689759123325348, "incre_win_rate": 0.9148936170212766, "step": 2067}
{"time": 1767340814.7130892, "phase": "train", "update": 2068, "total_env_steps": 6617600, "episode_reward": 0.27249741554260254, "value_loss": 0.004949653334915638, "policy_loss": -0.0012696751067593937, "dist_entropy": 0.6919062018394471, "actor_grad_norm": 0.08303927630186081, "critic_grad_norm": 0.02495659701526165, "ratio": 1.0003622770309448, "entropy": 0.6919062018394471, "incre_win_rate": 0.9069767441860465, "step": 2068}
{"time": 1767340818.8303595, "phase": "train", "update": 2069, "total_env_steps": 6620800, "episode_reward": 0.2701655626296997, "value_loss": 0.005306550022214651, "policy_loss": -0.0013534914212325333, "dist_entropy": 0.6895788788795472, "actor_grad_norm": 0.09523264318704605, "critic_grad_norm": 0.028971588239073753, "ratio": 1.0002317428588867, "entropy": 0.6895788788795472, "incre_win_rate": 0.8888888888888888, "step": 2069}
{"time": 1767340822.9068754, "phase": "train", "update": 2070, "total_env_steps": 6624000, "episode_reward": 0.2798634171485901, "value_loss": 0.005794682260602713, "policy_loss": -0.0013755430866112307, "dist_entropy": 0.6830832958221436, "actor_grad_norm": 0.08435388654470444, "critic_grad_norm": 0.02167561650276184, "ratio": 1.0001529455184937, "entropy": 0.6830832958221436, "incre_win_rate": 0.9555555555555556, "step": 2070}
{"time": 1767340826.9702733, "phase": "train", "update": 2071, "total_env_steps": 6627200, "episode_reward": 0.26483961939811707, "value_loss": 0.010567180812358856, "policy_loss": -0.001681165228779946, "dist_entropy": 0.6594001889228821, "actor_grad_norm": 0.09579933434724808, "critic_grad_norm": 0.037377096712589264, "ratio": 1.0003763437271118, "entropy": 0.6594001889228821, "incre_win_rate": 0.8478260869565217, "step": 2071}
{"time": 1767340831.0856194, "phase": "train", "update": 2072, "total_env_steps": 6630400, "episode_reward": 0.28500205278396606, "value_loss": 0.006752119027078151, "policy_loss": -0.001264470103135551, "dist_entropy": 0.6665180921554565, "actor_grad_norm": 0.09017354249954224, "critic_grad_norm": 0.06825578212738037, "ratio": 0.9999157786369324, "entropy": 0.6665180921554565, "incre_win_rate": 0.9347826086956522, "step": 2072}
{"time": 1767340835.1831915, "phase": "train", "update": 2073, "total_env_steps": 6633600, "episode_reward": 0.2694205343723297, "value_loss": 0.006273680273443461, "policy_loss": -0.0010941038577854556, "dist_entropy": 0.6446642398834228, "actor_grad_norm": 0.08517853170633316, "critic_grad_norm": 0.07470116764307022, "ratio": 1.000126838684082, "entropy": 0.6446642398834228, "incre_win_rate": 0.9302325581395349, "step": 2073}
{"time": 1767340839.287166, "phase": "train", "update": 2074, "total_env_steps": 6636800, "episode_reward": 0.27383023500442505, "value_loss": 0.00514471922069788, "policy_loss": -0.001302928345362986, "dist_entropy": 0.6483429193496704, "actor_grad_norm": 0.10953419655561447, "critic_grad_norm": 0.03924053534865379, "ratio": 1.000270962715149, "entropy": 0.6483429193496704, "incre_win_rate": 0.9347826086956522, "step": 2074}
{"time": 1767340843.4170299, "phase": "train", "update": 2075, "total_env_steps": 6640000, "episode_reward": 0.28221800923347473, "value_loss": 0.002986689144745469, "policy_loss": -0.0013522256332628047, "dist_entropy": 0.6343732118606568, "actor_grad_norm": 0.11136654764413834, "critic_grad_norm": 0.04598991945385933, "ratio": 0.9997703433036804, "entropy": 0.6343732118606568, "incre_win_rate": 0.9767441860465116, "step": 2075}
{"time": 1767340847.5402157, "phase": "train", "update": 2076, "total_env_steps": 6643200, "episode_reward": 0.2789864242076874, "value_loss": 0.004000206245109439, "policy_loss": -0.000942935898022057, "dist_entropy": 0.6219144582748413, "actor_grad_norm": 0.07038410753011703, "critic_grad_norm": 0.05447443202137947, "ratio": 0.9998043179512024, "entropy": 0.6219144582748413, "incre_win_rate": 0.9565217391304348, "step": 2076}
{"time": 1767340857.1601784, "phase": "eval", "update": 2076, "total_env_steps": 6643200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.907181291390728, "step": 2076}
{"time": 1767340861.223025, "phase": "train", "update": 2077, "total_env_steps": 6646400, "episode_reward": 0.2784525156021118, "value_loss": 0.0029646474402397873, "policy_loss": -0.0012456087075690902, "dist_entropy": 0.6007667183876038, "actor_grad_norm": 0.08454816788434982, "critic_grad_norm": 0.0280348751693964, "ratio": 1.0000944137573242, "entropy": 0.6007667183876038, "incre_win_rate": 0.9782608695652174, "step": 2077}
{"time": 1767340865.3127534, "phase": "train", "update": 2078, "total_env_steps": 6649600, "episode_reward": 0.2798593044281006, "value_loss": 0.0036205838900059462, "policy_loss": -0.0012443930116052826, "dist_entropy": 0.6360934138298034, "actor_grad_norm": 0.11093904078006744, "critic_grad_norm": 0.025539815425872803, "ratio": 1.0001810789108276, "entropy": 0.6360934138298034, "incre_win_rate": 0.9772727272727273, "step": 2078}
{"time": 1767340869.4237325, "phase": "train", "update": 2079, "total_env_steps": 6652800, "episode_reward": 0.2727193534374237, "value_loss": 0.004608039930462837, "policy_loss": -0.0008583916365576983, "dist_entropy": 0.6417852640151978, "actor_grad_norm": 0.09239982068538666, "critic_grad_norm": 0.03146747127175331, "ratio": 1.0000511407852173, "entropy": 0.6417852640151978, "incre_win_rate": 0.9545454545454546, "step": 2079}
{"time": 1767340873.6829784, "phase": "train", "update": 2080, "total_env_steps": 6656000, "episode_reward": 0.2797977030277252, "value_loss": 0.004640947096049786, "policy_loss": -0.0010214716481193875, "dist_entropy": 0.6409548044204711, "actor_grad_norm": 0.08208103477954865, "critic_grad_norm": 0.014997392892837524, "ratio": 0.9998764991760254, "entropy": 0.6409548044204711, "incre_win_rate": 0.9555555555555556, "step": 2080}
{"time": 1767340877.79179, "phase": "train", "update": 2081, "total_env_steps": 6659200, "episode_reward": 0.26584333181381226, "value_loss": 0.007725197449326515, "policy_loss": -0.0014876586424747984, "dist_entropy": 0.6337468147277832, "actor_grad_norm": 0.10094135999679565, "critic_grad_norm": 0.05298374220728874, "ratio": 0.9996542930603027, "entropy": 0.6337468147277832, "incre_win_rate": 0.8695652173913043, "step": 2081}
{"time": 1767340881.8970366, "phase": "train", "update": 2082, "total_env_steps": 6662400, "episode_reward": 0.28362998366355896, "value_loss": 0.005709098652005196, "policy_loss": -0.0010593152806381845, "dist_entropy": 0.6443765997886658, "actor_grad_norm": 0.08489479124546051, "critic_grad_norm": 0.04759114608168602, "ratio": 0.9998888373374939, "entropy": 0.6443765997886658, "incre_win_rate": 1.0, "step": 2082}
{"time": 1767340885.9805758, "phase": "train", "update": 2083, "total_env_steps": 6665600, "episode_reward": 0.2775900363922119, "value_loss": 0.0024921696167439222, "policy_loss": -0.0011229470958042497, "dist_entropy": 0.6412814021110534, "actor_grad_norm": 0.09375512599945068, "critic_grad_norm": 0.04512008652091026, "ratio": 1.0001194477081299, "entropy": 0.6412814021110534, "incre_win_rate": 0.9545454545454546, "step": 2083}
{"time": 1767340890.0931115, "phase": "train", "update": 2084, "total_env_steps": 6668800, "episode_reward": 0.27326834201812744, "value_loss": 0.00488138496875763, "policy_loss": -0.001128055846049847, "dist_entropy": 0.6526511430740356, "actor_grad_norm": 0.07191874086856842, "critic_grad_norm": 0.04644133150577545, "ratio": 0.9998648762702942, "entropy": 0.6526511430740356, "incre_win_rate": 0.8888888888888888, "step": 2084}
{"time": 1767340894.1683419, "phase": "train", "update": 2085, "total_env_steps": 6672000, "episode_reward": 0.27584022283554077, "value_loss": 0.004666492622345686, "policy_loss": -0.0011350966805121487, "dist_entropy": 0.6589080572128296, "actor_grad_norm": 0.08131007105112076, "critic_grad_norm": 0.033665984869003296, "ratio": 0.9999273419380188, "entropy": 0.6589080572128296, "incre_win_rate": 0.9777777777777777, "step": 2085}
{"time": 1767340898.2705386, "phase": "train", "update": 2086, "total_env_steps": 6675200, "episode_reward": 0.2728021740913391, "value_loss": 0.00543806217610836, "policy_loss": -0.0015908233584369213, "dist_entropy": 0.6553428173065186, "actor_grad_norm": 0.10436022281646729, "critic_grad_norm": 0.0264032781124115, "ratio": 0.9997836947441101, "entropy": 0.6553428173065186, "incre_win_rate": 1.0, "step": 2086}
{"time": 1767340902.388744, "phase": "train", "update": 2087, "total_env_steps": 6678400, "episode_reward": 0.27460265159606934, "value_loss": 0.0024436798878014086, "policy_loss": -0.001605119009505529, "dist_entropy": 0.6312596559524536, "actor_grad_norm": 0.09689711779356003, "critic_grad_norm": 0.03289865702390671, "ratio": 1.0002855062484741, "entropy": 0.6312596559524536, "incre_win_rate": 0.9787234042553191, "step": 2087}
{"time": 1767340906.515197, "phase": "train", "update": 2088, "total_env_steps": 6681600, "episode_reward": 0.28367963433265686, "value_loss": 0.0020118578104302287, "policy_loss": -0.001289722786376224, "dist_entropy": 0.6671700477600098, "actor_grad_norm": 0.10424672812223434, "critic_grad_norm": 0.02847508154809475, "ratio": 1.000049352645874, "entropy": 0.6671700477600098, "incre_win_rate": 1.0, "step": 2088}
{"time": 1767340910.613364, "phase": "train", "update": 2089, "total_env_steps": 6684800, "episode_reward": 0.27177876234054565, "value_loss": 0.006291594728827477, "policy_loss": -0.0011820722512741356, "dist_entropy": 0.6655194282531738, "actor_grad_norm": 0.07110019773244858, "critic_grad_norm": 0.06955857574939728, "ratio": 1.0002363920211792, "entropy": 0.6655194282531738, "incre_win_rate": 0.8863636363636364, "step": 2089}
{"time": 1767340914.6950476, "phase": "train", "update": 2090, "total_env_steps": 6688000, "episode_reward": 0.27876242995262146, "value_loss": 0.005157850868999958, "policy_loss": -0.0015674179521525389, "dist_entropy": 0.666910445690155, "actor_grad_norm": 0.07539974898099899, "critic_grad_norm": 0.04987819865345955, "ratio": 0.9999887347221375, "entropy": 0.666910445690155, "incre_win_rate": 0.9361702127659575, "step": 2090}
{"time": 1767340918.7315269, "phase": "train", "update": 2091, "total_env_steps": 6691200, "episode_reward": 0.2610544264316559, "value_loss": 0.008367843553423881, "policy_loss": -0.0012155147303438696, "dist_entropy": 0.6487046360969544, "actor_grad_norm": 0.08411342650651932, "critic_grad_norm": 0.05117505416274071, "ratio": 0.9998568892478943, "entropy": 0.6487046360969544, "incre_win_rate": 0.8571428571428571, "step": 2091}
{"time": 1767340922.8323252, "phase": "train", "update": 2092, "total_env_steps": 6694400, "episode_reward": 0.27548375725746155, "value_loss": 0.005784910917282104, "policy_loss": -0.0011838174958263893, "dist_entropy": 0.6711595058441162, "actor_grad_norm": 0.08484186977148056, "critic_grad_norm": 0.06184573844075203, "ratio": 0.9999597668647766, "entropy": 0.6711595058441162, "incre_win_rate": 0.9130434782608695, "step": 2092}
{"time": 1767340926.9711158, "phase": "train", "update": 2093, "total_env_steps": 6697600, "episode_reward": 0.27571916580200195, "value_loss": 0.006006516609340906, "policy_loss": -0.0014261535560613936, "dist_entropy": 0.6607285618782044, "actor_grad_norm": 0.081528440117836, "critic_grad_norm": 0.07663159817457199, "ratio": 1.0000406503677368, "entropy": 0.6607285618782044, "incre_win_rate": 0.9318181818181818, "step": 2093}
{"time": 1767340931.1238756, "phase": "train", "update": 2094, "total_env_steps": 6700800, "episode_reward": 0.27682122588157654, "value_loss": 0.00508616054430604, "policy_loss": -0.001378469132862392, "dist_entropy": 0.6801991581916809, "actor_grad_norm": 0.08164280652999878, "critic_grad_norm": 0.027817821130156517, "ratio": 1.0001617670059204, "entropy": 0.6801991581916809, "incre_win_rate": 0.9777777777777777, "step": 2094}
{"time": 1767340935.2512662, "phase": "train", "update": 2095, "total_env_steps": 6704000, "episode_reward": 0.2833671271800995, "value_loss": 0.0036860543303191664, "policy_loss": -0.0013176065601641085, "dist_entropy": 0.6746522188186646, "actor_grad_norm": 0.0930914506316185, "critic_grad_norm": 0.023873327299952507, "ratio": 1.0002063512802124, "entropy": 0.6746522188186646, "incre_win_rate": 0.9565217391304348, "step": 2095}
{"time": 1767340939.3382494, "phase": "train", "update": 2096, "total_env_steps": 6707200, "episode_reward": 0.27646884322166443, "value_loss": 0.0040554818231612446, "policy_loss": -0.0010350888087478083, "dist_entropy": 0.6700252294540405, "actor_grad_norm": 0.08491005748510361, "critic_grad_norm": 0.051022808998823166, "ratio": 0.9996629953384399, "entropy": 0.6700252294540405, "incre_win_rate": 0.9545454545454546, "step": 2096}
{"time": 1767340943.4438584, "phase": "train", "update": 2097, "total_env_steps": 6710400, "episode_reward": 0.2828580141067505, "value_loss": 0.004763136245310306, "policy_loss": -0.0013007041214514459, "dist_entropy": 0.6761083483695984, "actor_grad_norm": 0.08962474018335342, "critic_grad_norm": 0.0359872542321682, "ratio": 1.0000079870224, "entropy": 0.6761083483695984, "incre_win_rate": 0.9375, "step": 2097}
{"time": 1767340947.5270848, "phase": "train", "update": 2098, "total_env_steps": 6713600, "episode_reward": 0.28108030557632446, "value_loss": 0.004189009219408036, "policy_loss": -0.0010613451031176169, "dist_entropy": 0.6697834253311157, "actor_grad_norm": 0.08359836041927338, "critic_grad_norm": 0.03778964281082153, "ratio": 0.9999791383743286, "entropy": 0.6697834253311157, "incre_win_rate": 0.9545454545454546, "step": 2098}
{"time": 1767340951.6365888, "phase": "train", "update": 2099, "total_env_steps": 6716800, "episode_reward": 0.2796083390712738, "value_loss": 0.0038697749376297, "policy_loss": -0.0012252722389387571, "dist_entropy": 0.667314636707306, "actor_grad_norm": 0.0843374952673912, "critic_grad_norm": 0.02712276577949524, "ratio": 0.9999956488609314, "entropy": 0.667314636707306, "incre_win_rate": 0.9545454545454546, "step": 2099}
{"time": 1767340955.7718663, "phase": "train", "update": 2100, "total_env_steps": 6720000, "episode_reward": 0.2765609622001648, "value_loss": 0.0035569653380662205, "policy_loss": -0.0009293609900964839, "dist_entropy": 0.6748058795928955, "actor_grad_norm": 0.08498172461986542, "critic_grad_norm": 0.02587728016078472, "ratio": 1.0002403259277344, "entropy": 0.6748058795928955, "incre_win_rate": 0.9574468085106383, "step": 2100}
{"time": 1767340959.891461, "phase": "train", "update": 2101, "total_env_steps": 6723200, "episode_reward": 0.2813990116119385, "value_loss": 0.0033681511878967283, "policy_loss": -0.0011164468435541862, "dist_entropy": 0.6799336314201355, "actor_grad_norm": 0.09099604934453964, "critic_grad_norm": 0.029781067743897438, "ratio": 0.9997096061706543, "entropy": 0.6799336314201355, "incre_win_rate": 0.9555555555555556, "step": 2101}
{"time": 1767340969.431344, "phase": "eval", "update": 2101, "total_env_steps": 6723200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.869981374172184, "step": 2101}
{"time": 1767340973.5304813, "phase": "train", "update": 2102, "total_env_steps": 6726400, "episode_reward": 0.27898749709129333, "value_loss": 0.004053369630128145, "policy_loss": -0.0008591686326880676, "dist_entropy": 0.6895448565483093, "actor_grad_norm": 0.08653489500284195, "critic_grad_norm": 0.025691727176308632, "ratio": 1.0004669427871704, "entropy": 0.6895448565483093, "incre_win_rate": 0.9347826086956522, "step": 2102}
{"time": 1767340977.6411219, "phase": "train", "update": 2103, "total_env_steps": 6729600, "episode_reward": 0.2791095972061157, "value_loss": 0.004571109917014838, "policy_loss": -0.001088934629071403, "dist_entropy": 0.6787347197532654, "actor_grad_norm": 0.09966760128736496, "critic_grad_norm": 0.03071017377078533, "ratio": 0.9998261332511902, "entropy": 0.6787347197532654, "incre_win_rate": 0.9545454545454546, "step": 2103}
{"time": 1767340981.8062265, "phase": "train", "update": 2104, "total_env_steps": 6732800, "episode_reward": 0.2719671130180359, "value_loss": 0.004418149311095476, "policy_loss": -0.0014671184922406156, "dist_entropy": 0.6905340552330017, "actor_grad_norm": 0.08601981401443481, "critic_grad_norm": 0.02775212936103344, "ratio": 1.0000978708267212, "entropy": 0.6905340552330017, "incre_win_rate": 0.9333333333333333, "step": 2104}
{"time": 1767340985.9372342, "phase": "train", "update": 2105, "total_env_steps": 6736000, "episode_reward": 0.28332576155662537, "value_loss": 0.002931632986292243, "policy_loss": -0.0012532994628585924, "dist_entropy": 0.6875087738037109, "actor_grad_norm": 0.09086001664400101, "critic_grad_norm": 0.01876343972980976, "ratio": 0.999748706817627, "entropy": 0.6875087738037109, "incre_win_rate": 0.9555555555555556, "step": 2105}
{"time": 1767340990.0525565, "phase": "train", "update": 2106, "total_env_steps": 6739200, "episode_reward": 0.2789279818534851, "value_loss": 0.00504962271079421, "policy_loss": -0.0010013803295789714, "dist_entropy": 0.6777765989303589, "actor_grad_norm": 0.08928853273391724, "critic_grad_norm": 0.023495767265558243, "ratio": 0.9997615218162537, "entropy": 0.6777765989303589, "incre_win_rate": 0.9555555555555556, "step": 2106}
{"time": 1767340994.1550937, "phase": "train", "update": 2107, "total_env_steps": 6742400, "episode_reward": 0.269819974899292, "value_loss": 0.006131322681903839, "policy_loss": -0.0012851974400149401, "dist_entropy": 0.6753610491752624, "actor_grad_norm": 0.09733564406633377, "critic_grad_norm": 0.03541044890880585, "ratio": 1.0002169609069824, "entropy": 0.6753610491752624, "incre_win_rate": 0.9772727272727273, "step": 2107}
{"time": 1767340998.234863, "phase": "train", "update": 2108, "total_env_steps": 6745600, "episode_reward": 0.2827897369861603, "value_loss": 0.004724116157740354, "policy_loss": -0.0010584730823687493, "dist_entropy": 0.6669029712677002, "actor_grad_norm": 0.08878078311681747, "critic_grad_norm": 0.053159069269895554, "ratio": 0.9996923804283142, "entropy": 0.6669029712677002, "incre_win_rate": 0.9555555555555556, "step": 2108}
{"time": 1767341002.3482144, "phase": "train", "update": 2109, "total_env_steps": 6748800, "episode_reward": 0.27278557419776917, "value_loss": 0.005335036385804415, "policy_loss": -0.0013643193817259203, "dist_entropy": 0.6729402780532837, "actor_grad_norm": 0.09535536915063858, "critic_grad_norm": 0.033682871609926224, "ratio": 0.9999544024467468, "entropy": 0.6729402780532837, "incre_win_rate": 0.9111111111111111, "step": 2109}
{"time": 1767341006.4754772, "phase": "train", "update": 2110, "total_env_steps": 6752000, "episode_reward": 0.27622824907302856, "value_loss": 0.003260692534968257, "policy_loss": -0.0009947542560517775, "dist_entropy": 0.692197847366333, "actor_grad_norm": 0.08495039492845535, "critic_grad_norm": 0.0232237596064806, "ratio": 0.9998965263366699, "entropy": 0.692197847366333, "incre_win_rate": 0.8913043478260869, "step": 2110}
{"time": 1767341010.6016464, "phase": "train", "update": 2111, "total_env_steps": 6755200, "episode_reward": 0.2778337001800537, "value_loss": 0.004922704678028822, "policy_loss": -0.0014861254115018595, "dist_entropy": 0.6709012985229492, "actor_grad_norm": 0.0941099300980568, "critic_grad_norm": 0.040214039385318756, "ratio": 0.999881386756897, "entropy": 0.6709012985229492, "incre_win_rate": 0.9777777777777777, "step": 2111}
{"time": 1767341014.6799712, "phase": "train", "update": 2112, "total_env_steps": 6758400, "episode_reward": 0.27576524019241333, "value_loss": 0.0047154401428997515, "policy_loss": -0.0010431609698571265, "dist_entropy": 0.6806615829467774, "actor_grad_norm": 0.09322541207075119, "critic_grad_norm": 0.03532912954688072, "ratio": 0.999847412109375, "entropy": 0.6806615829467774, "incre_win_rate": 0.9318181818181818, "step": 2112}
{"time": 1767341018.754386, "phase": "train", "update": 2113, "total_env_steps": 6761600, "episode_reward": 0.27334797382354736, "value_loss": 0.0042360457591712475, "policy_loss": -0.0010116166108952384, "dist_entropy": 0.6725644469261169, "actor_grad_norm": 0.08512403815984726, "critic_grad_norm": 0.03646031394600868, "ratio": 1.0002937316894531, "entropy": 0.6725644469261169, "incre_win_rate": 0.9318181818181818, "step": 2113}
{"time": 1767341022.8667958, "phase": "train", "update": 2114, "total_env_steps": 6764800, "episode_reward": 0.27359944581985474, "value_loss": 0.004741285648196936, "policy_loss": -0.001208522050787053, "dist_entropy": 0.671816611289978, "actor_grad_norm": 0.09347452223300934, "critic_grad_norm": 0.023549426347017288, "ratio": 0.999995231628418, "entropy": 0.671816611289978, "incre_win_rate": 0.9347826086956522, "step": 2114}
{"time": 1767341027.0011618, "phase": "train", "update": 2115, "total_env_steps": 6768000, "episode_reward": 0.2784064710140228, "value_loss": 0.003751121088862419, "policy_loss": -0.0007680424771443484, "dist_entropy": 0.6469310283660888, "actor_grad_norm": 0.08276354521512985, "critic_grad_norm": 0.04379303380846977, "ratio": 0.9996580481529236, "entropy": 0.6469310283660888, "incre_win_rate": 1.0, "step": 2115}
{"time": 1767341031.154362, "phase": "train", "update": 2116, "total_env_steps": 6771200, "episode_reward": 0.2749751806259155, "value_loss": 0.003933353209868073, "policy_loss": -0.0009774411181457054, "dist_entropy": 0.6703942537307739, "actor_grad_norm": 0.07531248033046722, "critic_grad_norm": 0.026533368974924088, "ratio": 0.9997314810752869, "entropy": 0.6703942537307739, "incre_win_rate": 0.9777777777777777, "step": 2116}
{"time": 1767341035.244578, "phase": "train", "update": 2117, "total_env_steps": 6774400, "episode_reward": 0.27427929639816284, "value_loss": 0.0036651305854320526, "policy_loss": -0.001427774778677815, "dist_entropy": 0.6586327433586121, "actor_grad_norm": 0.0804784819483757, "critic_grad_norm": 0.05971701070666313, "ratio": 0.99998539686203, "entropy": 0.6586327433586121, "incre_win_rate": 0.9772727272727273, "step": 2117}
{"time": 1767341039.3507566, "phase": "train", "update": 2118, "total_env_steps": 6777600, "episode_reward": 0.2747640907764435, "value_loss": 0.004142663162201643, "policy_loss": -0.0014281654937560618, "dist_entropy": 0.6296206712722778, "actor_grad_norm": 0.08984682708978653, "critic_grad_norm": 0.03726067394018173, "ratio": 1.0002117156982422, "entropy": 0.6296206712722778, "incre_win_rate": 0.9545454545454546, "step": 2118}
{"time": 1767341043.4321342, "phase": "train", "update": 2119, "total_env_steps": 6780800, "episode_reward": 0.2706493139266968, "value_loss": 0.005917022842913866, "policy_loss": -0.001075348973784429, "dist_entropy": 0.6338610768318176, "actor_grad_norm": 0.07966460287570953, "critic_grad_norm": 0.022794751450419426, "ratio": 1.0000218152999878, "entropy": 0.6338610768318176, "incre_win_rate": 0.9555555555555556, "step": 2119}
{"time": 1767341047.5702, "phase": "train", "update": 2120, "total_env_steps": 6784000, "episode_reward": 0.2760932445526123, "value_loss": 0.004572934191673994, "policy_loss": -0.0015930952407757105, "dist_entropy": 0.6423534512519836, "actor_grad_norm": 0.11631762981414795, "critic_grad_norm": 0.03923263028264046, "ratio": 1.0002012252807617, "entropy": 0.6423534512519836, "incre_win_rate": 0.9534883720930233, "step": 2120}
{"time": 1767341051.693226, "phase": "train", "update": 2121, "total_env_steps": 6787200, "episode_reward": 0.27292320132255554, "value_loss": 0.004195069428533316, "policy_loss": -0.0009010019514605006, "dist_entropy": 0.6153651714324951, "actor_grad_norm": 0.12147543579339981, "critic_grad_norm": 0.036322880536317825, "ratio": 1.0000617504119873, "entropy": 0.6153651714324951, "incre_win_rate": 0.9782608695652174, "step": 2121}
{"time": 1767341055.816585, "phase": "train", "update": 2122, "total_env_steps": 6790400, "episode_reward": 0.2802649140357971, "value_loss": 0.003274830849841237, "policy_loss": -0.0007821843908416781, "dist_entropy": 0.6403461337089539, "actor_grad_norm": 0.10220672190189362, "critic_grad_norm": 0.052108701318502426, "ratio": 0.9998430609703064, "entropy": 0.6403461337089539, "incre_win_rate": 0.9772727272727273, "step": 2122}
{"time": 1767341060.0174265, "phase": "train", "update": 2123, "total_env_steps": 6793600, "episode_reward": 0.2746647596359253, "value_loss": 0.004922603722661734, "policy_loss": -0.0008236747301360481, "dist_entropy": 0.6359722375869751, "actor_grad_norm": 0.09940582513809204, "critic_grad_norm": 0.02705472707748413, "ratio": 0.9998579025268555, "entropy": 0.6359722375869751, "incre_win_rate": 0.9111111111111111, "step": 2123}
{"time": 1767341093.5693285, "phase": "train", "update": 2124, "total_env_steps": 6796800, "episode_reward": 0.27268627285957336, "value_loss": 0.04563231468200683, "policy_loss": -0.0005018789907648369, "dist_entropy": 0.6620400547981262, "actor_grad_norm": 0.07098133116960526, "critic_grad_norm": 0.19195765256881714, "ratio": 0.9998578429222107, "entropy": 0.6620400547981262, "incre_win_rate": 0.9761904761904762, "step": 2124}
{"time": 1767341097.6727934, "phase": "train", "update": 2125, "total_env_steps": 6800000, "episode_reward": 0.28521111607551575, "value_loss": 0.004245352558791637, "policy_loss": -0.0012848226847474108, "dist_entropy": 0.6805311918258667, "actor_grad_norm": 0.07961703836917877, "critic_grad_norm": 0.12574456632137299, "ratio": 1.0000646114349365, "entropy": 0.6805311918258667, "incre_win_rate": 0.9767441860465116, "step": 2125}
{"time": 1767341101.77307, "phase": "train", "update": 2126, "total_env_steps": 6803200, "episode_reward": 0.26484736800193787, "value_loss": 0.003407350042834878, "policy_loss": -0.0011598490172957554, "dist_entropy": 0.6602673888206482, "actor_grad_norm": 0.08127854019403458, "critic_grad_norm": 0.09342164546251297, "ratio": 0.999811589717865, "entropy": 0.6602673888206482, "incre_win_rate": 0.9545454545454546, "step": 2126}
{"time": 1767341111.0393124, "phase": "eval", "update": 2126, "total_env_steps": 6803200, "eval_win_rate": 1.0, "eval_episode_reward": 20.0, "step": 2126}
{"time": 1767341115.147307, "phase": "train", "update": 2127, "total_env_steps": 6806400, "episode_reward": 0.2742916941642761, "value_loss": 0.006520581059157848, "policy_loss": -0.0014682714482219695, "dist_entropy": 0.646778678894043, "actor_grad_norm": 0.09059914201498032, "critic_grad_norm": 0.05892458185553551, "ratio": 0.9998499155044556, "entropy": 0.646778678894043, "incre_win_rate": 0.9090909090909091, "step": 2127}
{"time": 1767341119.29672, "phase": "train", "update": 2128, "total_env_steps": 6809600, "episode_reward": 0.276439368724823, "value_loss": 0.005046882294118404, "policy_loss": -0.0009710214170134179, "dist_entropy": 0.6836993932723999, "actor_grad_norm": 0.08446251600980759, "critic_grad_norm": 0.04202359914779663, "ratio": 0.9997723698616028, "entropy": 0.6836993932723999, "incre_win_rate": 0.9565217391304348, "step": 2128}
{"time": 1767341123.4359124, "phase": "train", "update": 2129, "total_env_steps": 6812800, "episode_reward": 0.28132036328315735, "value_loss": 0.0032827307004481554, "policy_loss": -0.0013193327155107681, "dist_entropy": 0.6923314929008484, "actor_grad_norm": 0.08225232362747192, "critic_grad_norm": 0.04302629455924034, "ratio": 1.0000593662261963, "entropy": 0.6923314929008484, "incre_win_rate": 0.9534883720930233, "step": 2129}
{"time": 1767341127.55452, "phase": "train", "update": 2130, "total_env_steps": 6816000, "episode_reward": 0.27475011348724365, "value_loss": 0.004781183507293463, "policy_loss": -0.0009009825438425878, "dist_entropy": 0.6695313215255737, "actor_grad_norm": 0.08317907154560089, "critic_grad_norm": 0.020797884091734886, "ratio": 0.9997386932373047, "entropy": 0.6695313215255737, "incre_win_rate": 0.8913043478260869, "step": 2130}
{"time": 1767341131.6391995, "phase": "train", "update": 2131, "total_env_steps": 6819200, "episode_reward": 0.2778642475605011, "value_loss": 0.005094605684280396, "policy_loss": -0.0013321709557205352, "dist_entropy": 0.6622073650360107, "actor_grad_norm": 0.08556311577558517, "critic_grad_norm": 0.030309362336993217, "ratio": 1.0001375675201416, "entropy": 0.6622073650360107, "incre_win_rate": 0.9787234042553191, "step": 2131}
{"time": 1767341135.7417903, "phase": "train", "update": 2132, "total_env_steps": 6822400, "episode_reward": 0.2826904058456421, "value_loss": 0.0029036698397248983, "policy_loss": -0.0012459567087013568, "dist_entropy": 0.6645751476287842, "actor_grad_norm": 0.07886399328708649, "critic_grad_norm": 0.030441537499427795, "ratio": 0.9998788237571716, "entropy": 0.6645751476287842, "incre_win_rate": 0.9772727272727273, "step": 2132}
{"time": 1767341139.9065926, "phase": "train", "update": 2133, "total_env_steps": 6825600, "episode_reward": 0.28132036328315735, "value_loss": 0.00425969585776329, "policy_loss": -0.0007935093783463465, "dist_entropy": 0.6688311100006104, "actor_grad_norm": 0.08333410322666168, "critic_grad_norm": 0.01953299716114998, "ratio": 1.0000219345092773, "entropy": 0.6688311100006104, "incre_win_rate": 0.9574468085106383, "step": 2133}
{"time": 1767341144.0731246, "phase": "train", "update": 2134, "total_env_steps": 6828800, "episode_reward": 0.2772340476512909, "value_loss": 0.0026869984809309243, "policy_loss": -0.001349110970488887, "dist_entropy": 0.6618733525276184, "actor_grad_norm": 0.0885162502527237, "critic_grad_norm": 0.014873984269797802, "ratio": 0.9996793866157532, "entropy": 0.6618733525276184, "incre_win_rate": 0.9767441860465116, "step": 2134}
{"time": 1767341148.1804028, "phase": "train", "update": 2135, "total_env_steps": 6832000, "episode_reward": 0.2805629074573517, "value_loss": 0.004161128308624029, "policy_loss": -0.0013925176616236712, "dist_entropy": 0.6668751835823059, "actor_grad_norm": 0.08103498071432114, "critic_grad_norm": 0.011262091808021069, "ratio": 1.0003899335861206, "entropy": 0.6668751835823059, "incre_win_rate": 0.9574468085106383, "step": 2135}
{"time": 1767341152.220986, "phase": "train", "update": 2136, "total_env_steps": 6835200, "episode_reward": 0.27529388666152954, "value_loss": 0.004606818407773971, "policy_loss": -0.0009566486423445042, "dist_entropy": 0.6420063138008117, "actor_grad_norm": 0.07844609022140503, "critic_grad_norm": 0.020046653226017952, "ratio": 1.000089168548584, "entropy": 0.6420063138008117, "incre_win_rate": 0.9069767441860465, "step": 2136}
{"time": 1767341156.2743456, "phase": "train", "update": 2137, "total_env_steps": 6838400, "episode_reward": 0.27889901399612427, "value_loss": 0.0030135670211166145, "policy_loss": -0.0012542325325469506, "dist_entropy": 0.6462802648544311, "actor_grad_norm": 0.08715610951185226, "critic_grad_norm": 0.02342018485069275, "ratio": 0.9998521208763123, "entropy": 0.6462802648544311, "incre_win_rate": 0.9777777777777777, "step": 2137}
{"time": 1767341160.3497107, "phase": "train", "update": 2138, "total_env_steps": 6841600, "episode_reward": 0.2868460416793823, "value_loss": 0.0016047831159085035, "policy_loss": -0.0011741399742732027, "dist_entropy": 0.6454267978668213, "actor_grad_norm": 0.08216989785432816, "critic_grad_norm": 0.03533446416258812, "ratio": 0.999711811542511, "entropy": 0.6454267978668213, "incre_win_rate": 1.0, "step": 2138}
{"time": 1767341164.4150846, "phase": "train", "update": 2139, "total_env_steps": 6844800, "episode_reward": 0.27992552518844604, "value_loss": 0.004625728167593479, "policy_loss": -0.000801506847754041, "dist_entropy": 0.6271872997283936, "actor_grad_norm": 0.06495296955108643, "critic_grad_norm": 0.022418277338147163, "ratio": 0.9999758005142212, "entropy": 0.6271872997283936, "incre_win_rate": 0.9545454545454546, "step": 2139}
{"time": 1767341168.5216484, "phase": "train", "update": 2140, "total_env_steps": 6848000, "episode_reward": 0.287376344203949, "value_loss": 0.003099907748401165, "policy_loss": -0.0012580925278292908, "dist_entropy": 0.6278132557868957, "actor_grad_norm": 0.0851009413599968, "critic_grad_norm": 0.01586335152387619, "ratio": 1.0000072717666626, "entropy": 0.6278132557868957, "incre_win_rate": 0.9787234042553191, "step": 2140}
{"time": 1767341172.637814, "phase": "train", "update": 2141, "total_env_steps": 6851200, "episode_reward": 0.27673014998435974, "value_loss": 0.00420691454783082, "policy_loss": -0.0013220014164385674, "dist_entropy": 0.6099027276039124, "actor_grad_norm": 0.09632895886898041, "critic_grad_norm": 0.033597856760025024, "ratio": 1.0002772808074951, "entropy": 0.6099027276039124, "incre_win_rate": 0.9111111111111111, "step": 2141}
{"time": 1767341176.7090027, "phase": "train", "update": 2142, "total_env_steps": 6854400, "episode_reward": 0.2730277180671692, "value_loss": 0.004547255579382181, "policy_loss": -0.0012320390457695395, "dist_entropy": 0.6166092276573181, "actor_grad_norm": 0.08790300786495209, "critic_grad_norm": 0.027441397309303284, "ratio": 0.9997564554214478, "entropy": 0.6166092276573181, "incre_win_rate": 0.9318181818181818, "step": 2142}
{"time": 1767341180.8433266, "phase": "train", "update": 2143, "total_env_steps": 6857600, "episode_reward": 0.2836103141307831, "value_loss": 0.0036881336476653815, "policy_loss": -0.0011934119866218395, "dist_entropy": 0.6401328802108764, "actor_grad_norm": 0.08979678153991699, "critic_grad_norm": 0.02622784487903118, "ratio": 0.9999273419380188, "entropy": 0.6401328802108764, "incre_win_rate": 0.9574468085106383, "step": 2143}
{"time": 1767341184.960071, "phase": "train", "update": 2144, "total_env_steps": 6860800, "episode_reward": 0.27223044633865356, "value_loss": 0.00601383214816451, "policy_loss": -0.0011429080829799432, "dist_entropy": 0.6277995705604553, "actor_grad_norm": 0.06605919450521469, "critic_grad_norm": 0.03503067046403885, "ratio": 0.9998486638069153, "entropy": 0.6277995705604553, "incre_win_rate": 0.8837209302325582, "step": 2144}
{"time": 1767341189.0556893, "phase": "train", "update": 2145, "total_env_steps": 6864000, "episode_reward": 0.27937912940979004, "value_loss": 0.004398388601839542, "policy_loss": -0.0011255183436148287, "dist_entropy": 0.6259744763374329, "actor_grad_norm": 0.07545548677444458, "critic_grad_norm": 0.03286707028746605, "ratio": 1.0001682043075562, "entropy": 0.6259744763374329, "incre_win_rate": 0.9787234042553191, "step": 2145}
{"time": 1767341193.1853607, "phase": "train", "update": 2146, "total_env_steps": 6867200, "episode_reward": 0.2760595977306366, "value_loss": 0.0069288376718759535, "policy_loss": -0.001423637628347052, "dist_entropy": 0.6095321297645568, "actor_grad_norm": 0.08495020121335983, "critic_grad_norm": 0.04945925995707512, "ratio": 0.9998731017112732, "entropy": 0.6095321297645568, "incre_win_rate": 0.9302325581395349, "step": 2146}
{"time": 1767341197.2827132, "phase": "train", "update": 2147, "total_env_steps": 6870400, "episode_reward": 0.2740687429904938, "value_loss": 0.003585177147760987, "policy_loss": -0.001162517728668111, "dist_entropy": 0.6052493214607239, "actor_grad_norm": 0.07577510923147202, "critic_grad_norm": 0.06563031673431396, "ratio": 0.9999545216560364, "entropy": 0.6052493214607239, "incre_win_rate": 0.9333333333333333, "step": 2147}
{"time": 1767341201.364833, "phase": "train", "update": 2148, "total_env_steps": 6873600, "episode_reward": 0.27003568410873413, "value_loss": 0.006928583607077599, "policy_loss": -0.0012883772250773973, "dist_entropy": 0.6195035219192505, "actor_grad_norm": 0.09669354557991028, "critic_grad_norm": 0.06207248196005821, "ratio": 1.0001742839813232, "entropy": 0.6195035219192505, "incre_win_rate": 0.8636363636363636, "step": 2148}
{"time": 1767341205.4850366, "phase": "train", "update": 2149, "total_env_steps": 6876800, "episode_reward": 0.27639642357826233, "value_loss": 0.004066905146464706, "policy_loss": -0.0009571550545622642, "dist_entropy": 0.6219844579696655, "actor_grad_norm": 0.07699621468782425, "critic_grad_norm": 0.043097034096717834, "ratio": 1.000197410583496, "entropy": 0.6219844579696655, "incre_win_rate": 0.9166666666666666, "step": 2149}
{"time": 1767341209.5863338, "phase": "train", "update": 2150, "total_env_steps": 6880000, "episode_reward": 0.28659769892692566, "value_loss": 0.003638159576803446, "policy_loss": -0.001317914775170581, "dist_entropy": 0.6117847084999084, "actor_grad_norm": 0.08583229035139084, "critic_grad_norm": 0.03664692863821983, "ratio": 0.9998152852058411, "entropy": 0.6117847084999084, "incre_win_rate": 0.9777777777777777, "step": 2150}
{"time": 1767341213.7237566, "phase": "train", "update": 2151, "total_env_steps": 6883200, "episode_reward": 0.2839362621307373, "value_loss": 0.0036162388045340777, "policy_loss": -0.0009804171661194517, "dist_entropy": 0.5895694732666016, "actor_grad_norm": 0.08530732244253159, "critic_grad_norm": 0.02931671403348446, "ratio": 0.9999572038650513, "entropy": 0.5895694732666016, "incre_win_rate": 0.9767441860465116, "step": 2151}
{"time": 1767341222.836232, "phase": "eval", "update": 2151, "total_env_steps": 6883200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.810378725165563, "step": 2151}
{"time": 1767341226.9255996, "phase": "train", "update": 2152, "total_env_steps": 6886400, "episode_reward": 0.2849368751049042, "value_loss": 0.004067392461001873, "policy_loss": -0.0011052375285046877, "dist_entropy": 0.6015823245048523, "actor_grad_norm": 0.09024044126272202, "critic_grad_norm": 0.030231419950723648, "ratio": 0.9996070861816406, "entropy": 0.6015823245048523, "incre_win_rate": 0.9791666666666666, "step": 2152}
{"time": 1767341231.0747573, "phase": "train", "update": 2153, "total_env_steps": 6889600, "episode_reward": 0.28924769163131714, "value_loss": 0.004080817429348826, "policy_loss": -0.0009073763117580569, "dist_entropy": 0.5809813737869263, "actor_grad_norm": 0.0732557475566864, "critic_grad_norm": 0.019686874002218246, "ratio": 1.0001649856567383, "entropy": 0.5809813737869263, "incre_win_rate": 0.9361702127659575, "step": 2153}
{"time": 1767341235.1968691, "phase": "train", "update": 2154, "total_env_steps": 6892800, "episode_reward": 0.28136590123176575, "value_loss": 0.0062880759127438065, "policy_loss": -0.0011603603146035368, "dist_entropy": 0.5829796195030212, "actor_grad_norm": 0.08061271160840988, "critic_grad_norm": 0.06024188548326492, "ratio": 0.9993900656700134, "entropy": 0.5829796195030212, "incre_win_rate": 0.8913043478260869, "step": 2154}
{"time": 1767341239.3095493, "phase": "train", "update": 2155, "total_env_steps": 6896000, "episode_reward": 0.2785678803920746, "value_loss": 0.00629646684974432, "policy_loss": -0.00097794845614807, "dist_entropy": 0.5926137566566467, "actor_grad_norm": 0.07164648920297623, "critic_grad_norm": 0.05111607536673546, "ratio": 1.0000368356704712, "entropy": 0.5926137566566467, "incre_win_rate": 0.9130434782608695, "step": 2155}
{"time": 1767341243.3719618, "phase": "train", "update": 2156, "total_env_steps": 6899200, "episode_reward": 0.26993119716644287, "value_loss": 0.007148105558007956, "policy_loss": -0.0011088104592673175, "dist_entropy": 0.587842607498169, "actor_grad_norm": 0.08652009814977646, "critic_grad_norm": 0.07024451345205307, "ratio": 1.0004760026931763, "entropy": 0.587842607498169, "incre_win_rate": 0.8863636363636364, "step": 2156}
{"time": 1767341247.4873843, "phase": "train", "update": 2157, "total_env_steps": 6902400, "episode_reward": 0.27741357684135437, "value_loss": 0.006612834520637989, "policy_loss": -0.0009744297676519409, "dist_entropy": 0.6035193085670472, "actor_grad_norm": 0.07705266028642654, "critic_grad_norm": 0.07864159345626831, "ratio": 0.9998921751976013, "entropy": 0.6035193085670472, "incre_win_rate": 0.9555555555555556, "step": 2157}
{"time": 1767341251.5602088, "phase": "train", "update": 2158, "total_env_steps": 6905600, "episode_reward": 0.27611497044563293, "value_loss": 0.006445034313946963, "policy_loss": -0.001134341497717628, "dist_entropy": 0.6143617272377014, "actor_grad_norm": 0.0756109431385994, "critic_grad_norm": 0.053490061312913895, "ratio": 1.00033700466156, "entropy": 0.6143617272377014, "incre_win_rate": 0.8936170212765957, "step": 2158}
{"time": 1767341255.682327, "phase": "train", "update": 2159, "total_env_steps": 6908800, "episode_reward": 0.27346181869506836, "value_loss": 0.0052850088104605675, "policy_loss": -0.0014491841615623003, "dist_entropy": 0.6199769496917724, "actor_grad_norm": 0.08034095168113708, "critic_grad_norm": 0.04116136208176613, "ratio": 1.0003491640090942, "entropy": 0.6199769496917724, "incre_win_rate": 0.9534883720930233, "step": 2159}
{"time": 1767341259.7516541, "phase": "train", "update": 2160, "total_env_steps": 6912000, "episode_reward": 0.2744215726852417, "value_loss": 0.005451601836830378, "policy_loss": -0.000815379609674416, "dist_entropy": 0.6335538864135742, "actor_grad_norm": 0.06549489498138428, "critic_grad_norm": 0.03652883321046829, "ratio": 0.9997650384902954, "entropy": 0.6335538864135742, "incre_win_rate": 0.8888888888888888, "step": 2160}
{"time": 1767341263.8278174, "phase": "train", "update": 2161, "total_env_steps": 6915200, "episode_reward": 0.27420374751091003, "value_loss": 0.006125772930681705, "policy_loss": -0.0011892198131320697, "dist_entropy": 0.613689637184143, "actor_grad_norm": 0.06675063818693161, "critic_grad_norm": 0.028683960437774658, "ratio": 0.9998015761375427, "entropy": 0.613689637184143, "incre_win_rate": 0.9090909090909091, "step": 2161}
{"time": 1767341267.8800251, "phase": "train", "update": 2162, "total_env_steps": 6918400, "episode_reward": 0.2712598145008087, "value_loss": 0.0052589763887226585, "policy_loss": -0.0009877789526491654, "dist_entropy": 0.6253280401229858, "actor_grad_norm": 0.0653320848941803, "critic_grad_norm": 0.020692363381385803, "ratio": 1.000082015991211, "entropy": 0.6253280401229858, "incre_win_rate": 0.8666666666666667, "step": 2162}
{"time": 1767341271.9001865, "phase": "train", "update": 2163, "total_env_steps": 6921600, "episode_reward": 0.26535284519195557, "value_loss": 0.006228206772357225, "policy_loss": -0.0011627891288391369, "dist_entropy": 0.618020522594452, "actor_grad_norm": 0.0650617703795433, "critic_grad_norm": 0.05729523301124573, "ratio": 1.0000256299972534, "entropy": 0.618020522594452, "incre_win_rate": 0.8888888888888888, "step": 2163}
{"time": 1767341275.9171607, "phase": "train", "update": 2164, "total_env_steps": 6924800, "episode_reward": 0.2741970121860504, "value_loss": 0.006029167491942644, "policy_loss": -0.000881230543204481, "dist_entropy": 0.5945206165313721, "actor_grad_norm": 0.06758896261453629, "critic_grad_norm": 0.0713798925280571, "ratio": 0.999947190284729, "entropy": 0.5945206165313721, "incre_win_rate": 0.9523809523809523, "step": 2164}
{"time": 1767341280.0166593, "phase": "train", "update": 2165, "total_env_steps": 6928000, "episode_reward": 0.2735549807548523, "value_loss": 0.005418486800044775, "policy_loss": -0.0013795736211484667, "dist_entropy": 0.622041654586792, "actor_grad_norm": 0.07434075325727463, "critic_grad_norm": 0.06283924728631973, "ratio": 0.999930202960968, "entropy": 0.622041654586792, "incre_win_rate": 0.9361702127659575, "step": 2165}
{"time": 1767341284.0749953, "phase": "train", "update": 2166, "total_env_steps": 6931200, "episode_reward": 0.27276286482810974, "value_loss": 0.005664100404828787, "policy_loss": -0.0013747032545877503, "dist_entropy": 0.6148274779319763, "actor_grad_norm": 0.07679826021194458, "critic_grad_norm": 0.039118774235248566, "ratio": 1.0000845193862915, "entropy": 0.6148274779319763, "incre_win_rate": 0.9090909090909091, "step": 2166}
{"time": 1767341288.1657307, "phase": "train", "update": 2167, "total_env_steps": 6934400, "episode_reward": 0.27789321541786194, "value_loss": 0.005485530570149421, "policy_loss": -0.0007802942661392365, "dist_entropy": 0.5988753080368042, "actor_grad_norm": 0.05959522724151611, "critic_grad_norm": 0.03775837644934654, "ratio": 1.0002772808074951, "entropy": 0.5988753080368042, "incre_win_rate": 0.9777777777777777, "step": 2167}
{"time": 1767341292.235444, "phase": "train", "update": 2168, "total_env_steps": 6937600, "episode_reward": 0.2775118947029114, "value_loss": 0.005570749007165432, "policy_loss": -0.0014074802122991058, "dist_entropy": 0.5898317098617554, "actor_grad_norm": 0.08210747689008713, "critic_grad_norm": 0.034470297396183014, "ratio": 0.9997774362564087, "entropy": 0.5898317098617554, "incre_win_rate": 0.9333333333333333, "step": 2168}
{"time": 1767341296.3095536, "phase": "train", "update": 2169, "total_env_steps": 6940800, "episode_reward": 0.26450592279434204, "value_loss": 0.006308802869170904, "policy_loss": -0.0010778555820948553, "dist_entropy": 0.6020111083984375, "actor_grad_norm": 0.08245301246643066, "critic_grad_norm": 0.023663513362407684, "ratio": 1.0006123781204224, "entropy": 0.6020111083984375, "incre_win_rate": 0.8636363636363636, "step": 2169}
{"time": 1767341300.39772, "phase": "train", "update": 2170, "total_env_steps": 6944000, "episode_reward": 0.28456488251686096, "value_loss": 0.00604432700201869, "policy_loss": -0.0009969181387127434, "dist_entropy": 0.6073574900627137, "actor_grad_norm": 0.08048496395349503, "critic_grad_norm": 0.05218357592821121, "ratio": 0.9999861717224121, "entropy": 0.6073574900627137, "incre_win_rate": 0.9361702127659575, "step": 2170}
{"time": 1767341304.4774384, "phase": "train", "update": 2171, "total_env_steps": 6947200, "episode_reward": 0.27573052048683167, "value_loss": 0.0058381564915180205, "policy_loss": -0.0008941200328746568, "dist_entropy": 0.6114414215087891, "actor_grad_norm": 0.08200549334287643, "critic_grad_norm": 0.043931182473897934, "ratio": 0.999666154384613, "entropy": 0.6114414215087891, "incre_win_rate": 0.9130434782608695, "step": 2171}
{"time": 1767341308.501044, "phase": "train", "update": 2172, "total_env_steps": 6950400, "episode_reward": 0.2813990116119385, "value_loss": 0.003793871775269508, "policy_loss": -0.0009441661525208644, "dist_entropy": 0.5895929574966431, "actor_grad_norm": 0.07659255713224411, "critic_grad_norm": 0.04211009666323662, "ratio": 1.0001623630523682, "entropy": 0.5895929574966431, "incre_win_rate": 0.9534883720930233, "step": 2172}
{"time": 1767341312.5863607, "phase": "train", "update": 2173, "total_env_steps": 6953600, "episode_reward": 0.2724461853504181, "value_loss": 0.00563688650727272, "policy_loss": -0.001049420445025362, "dist_entropy": 0.5941196918487549, "actor_grad_norm": 0.07336293905973434, "critic_grad_norm": 0.027267251163721085, "ratio": 0.9997102618217468, "entropy": 0.5941196918487549, "incre_win_rate": 0.9318181818181818, "step": 2173}
{"time": 1767341316.6865554, "phase": "train", "update": 2174, "total_env_steps": 6956800, "episode_reward": 0.2757450342178345, "value_loss": 0.006454071123152971, "policy_loss": -0.0011346144511264812, "dist_entropy": 0.6078020334243774, "actor_grad_norm": 0.07764602452516556, "critic_grad_norm": 0.03140440210700035, "ratio": 0.9995614886283875, "entropy": 0.6078020334243774, "incre_win_rate": 0.9130434782608695, "step": 2174}
{"time": 1767341320.7997794, "phase": "train", "update": 2175, "total_env_steps": 6960000, "episode_reward": 0.2656938135623932, "value_loss": 0.013187387399375439, "policy_loss": -0.0015149814891906033, "dist_entropy": 0.5969852685928345, "actor_grad_norm": 0.09104826301336288, "critic_grad_norm": 0.0376616045832634, "ratio": 0.9999284744262695, "entropy": 0.5969852685928345, "incre_win_rate": 0.8043478260869565, "step": 2175}
{"time": 1767341324.8781576, "phase": "train", "update": 2176, "total_env_steps": 6963200, "episode_reward": 0.2661118805408478, "value_loss": 0.008833170123398303, "policy_loss": -0.0011449500312098238, "dist_entropy": 0.6053406834602356, "actor_grad_norm": 0.06976450234651566, "critic_grad_norm": 0.045821886509656906, "ratio": 0.9998666644096375, "entropy": 0.6053406834602356, "incre_win_rate": 0.8372093023255814, "step": 2176}
{"time": 1767341334.3579793, "phase": "eval", "update": 2176, "total_env_steps": 6963200, "eval_win_rate": 0.84375, "eval_episode_reward": 18.987427566225165, "step": 2176}
{"time": 1767341338.42869, "phase": "train", "update": 2177, "total_env_steps": 6966400, "episode_reward": 0.26188328862190247, "value_loss": 0.011473720148205756, "policy_loss": -0.0012964119407456564, "dist_entropy": 0.6189033269882203, "actor_grad_norm": 0.08075273782014847, "critic_grad_norm": 0.10465141385793686, "ratio": 1.0001062154769897, "entropy": 0.6189033269882203, "incre_win_rate": 0.8181818181818182, "step": 2177}
{"time": 1767341342.560435, "phase": "train", "update": 2178, "total_env_steps": 6969600, "episode_reward": 0.264478474855423, "value_loss": 0.010900153405964374, "policy_loss": -0.0011294887743048322, "dist_entropy": 0.6085509896278382, "actor_grad_norm": 0.07809969037771225, "critic_grad_norm": 0.07358045876026154, "ratio": 0.9999366998672485, "entropy": 0.6085509896278382, "incre_win_rate": 0.7608695652173914, "step": 2178}
{"time": 1767341346.6863492, "phase": "train", "update": 2179, "total_env_steps": 6972800, "episode_reward": 0.2638798654079437, "value_loss": 0.010465820878744125, "policy_loss": -0.001337004908060635, "dist_entropy": 0.605117678642273, "actor_grad_norm": 0.09199044853448868, "critic_grad_norm": 0.030508672818541527, "ratio": 0.999851405620575, "entropy": 0.605117678642273, "incre_win_rate": 0.7619047619047619, "step": 2179}
{"time": 1767341350.8600605, "phase": "train", "update": 2180, "total_env_steps": 6976000, "episode_reward": 0.2732600271701813, "value_loss": 0.007441857550293207, "policy_loss": -0.0015458822648259484, "dist_entropy": 0.609314215183258, "actor_grad_norm": 0.08750980347394943, "critic_grad_norm": 0.05150460824370384, "ratio": 0.9997938275337219, "entropy": 0.609314215183258, "incre_win_rate": 0.9166666666666666, "step": 2180}
{"time": 1767341355.0296693, "phase": "train", "update": 2181, "total_env_steps": 6979200, "episode_reward": 0.279873251914978, "value_loss": 0.005539554823189974, "policy_loss": -0.0014741046927383649, "dist_entropy": 0.5998505711555481, "actor_grad_norm": 0.08791755884885788, "critic_grad_norm": 0.055512573570013046, "ratio": 1.0002473592758179, "entropy": 0.5998505711555481, "incre_win_rate": 0.9090909090909091, "step": 2181}
{"time": 1767341359.173504, "phase": "train", "update": 2182, "total_env_steps": 6982400, "episode_reward": 0.28509521484375, "value_loss": 0.003918863646686077, "policy_loss": -0.0012209076317958533, "dist_entropy": 0.6174293160438538, "actor_grad_norm": 0.07091907411813736, "critic_grad_norm": 0.011385180056095123, "ratio": 1.0001890659332275, "entropy": 0.6174293160438538, "incre_win_rate": 0.9787234042553191, "step": 2182}
{"time": 1767341363.2644265, "phase": "train", "update": 2183, "total_env_steps": 6985600, "episode_reward": 0.27080193161964417, "value_loss": 0.004419002216309309, "policy_loss": -0.0014460034614298678, "dist_entropy": 0.584125030040741, "actor_grad_norm": 0.07870599627494812, "critic_grad_norm": 0.03545316681265831, "ratio": 1.000076174736023, "entropy": 0.584125030040741, "incre_win_rate": 0.9318181818181818, "step": 2183}
{"time": 1767341367.3408303, "phase": "train", "update": 2184, "total_env_steps": 6988800, "episode_reward": 0.2733278274536133, "value_loss": 0.005583338066935539, "policy_loss": -0.0013732967461670853, "dist_entropy": 0.6104500412940979, "actor_grad_norm": 0.07636633515357971, "critic_grad_norm": 0.03356463089585304, "ratio": 1.0000914335250854, "entropy": 0.6104500412940979, "incre_win_rate": 0.8888888888888888, "step": 2184}
{"time": 1767341371.4773006, "phase": "train", "update": 2185, "total_env_steps": 6992000, "episode_reward": 0.28610512614250183, "value_loss": 0.003157244483008981, "policy_loss": -0.0010769054597489004, "dist_entropy": 0.6146155834197998, "actor_grad_norm": 0.08946391195058823, "critic_grad_norm": 0.03941687196493149, "ratio": 0.9997221827507019, "entropy": 0.6146155834197998, "incre_win_rate": 0.9777777777777777, "step": 2185}
{"time": 1767341375.5674853, "phase": "train", "update": 2186, "total_env_steps": 6995200, "episode_reward": 0.2744702100753784, "value_loss": 0.004043571185320616, "policy_loss": -0.0010098357107324318, "dist_entropy": 0.5888539791107178, "actor_grad_norm": 0.08935954421758652, "critic_grad_norm": 0.029833614826202393, "ratio": 0.9995828866958618, "entropy": 0.5888539791107178, "incre_win_rate": 0.9565217391304348, "step": 2186}
{"time": 1767341379.6860778, "phase": "train", "update": 2187, "total_env_steps": 6998400, "episode_reward": 0.2768004834651947, "value_loss": 0.004169368464499712, "policy_loss": -0.0012528929192441752, "dist_entropy": 0.6336827278137207, "actor_grad_norm": 0.09024862200021744, "critic_grad_norm": 0.02515866793692112, "ratio": 0.999603271484375, "entropy": 0.6336827278137207, "incre_win_rate": 0.9318181818181818, "step": 2187}
{"time": 1767341383.823001, "phase": "train", "update": 2188, "total_env_steps": 7001600, "episode_reward": 0.2792368531227112, "value_loss": 0.004100778046995402, "policy_loss": -0.001441272539483407, "dist_entropy": 0.6175593733787537, "actor_grad_norm": 0.08213972300291061, "critic_grad_norm": 0.014739331789314747, "ratio": 0.9998199343681335, "entropy": 0.6175593733787537, "incre_win_rate": 0.9555555555555556, "step": 2188}
{"time": 1767341387.9091837, "phase": "train", "update": 2189, "total_env_steps": 7004800, "episode_reward": 0.28002482652664185, "value_loss": 0.004767110850661993, "policy_loss": -0.0013428053634115145, "dist_entropy": 0.6371728777885437, "actor_grad_norm": 0.07127697765827179, "critic_grad_norm": 0.017049727961421013, "ratio": 0.9998273849487305, "entropy": 0.6371728777885437, "incre_win_rate": 0.9555555555555556, "step": 2189}
{"time": 1767341392.031771, "phase": "train", "update": 2190, "total_env_steps": 7008000, "episode_reward": 0.283552348613739, "value_loss": 0.004914675839245319, "policy_loss": -0.0016047847379539349, "dist_entropy": 0.6136492013931274, "actor_grad_norm": 0.08347376435995102, "critic_grad_norm": 0.020082678645849228, "ratio": 0.9998050928115845, "entropy": 0.6136492013931274, "incre_win_rate": 0.9361702127659575, "step": 2190}
{"time": 1767341396.1132152, "phase": "train", "update": 2191, "total_env_steps": 7011200, "episode_reward": 0.27212488651275635, "value_loss": 0.009575004503130913, "policy_loss": -0.0013763815263416745, "dist_entropy": 0.6236041188240051, "actor_grad_norm": 0.07691945880651474, "critic_grad_norm": 0.0568866990506649, "ratio": 1.0002164840698242, "entropy": 0.6236041188240051, "incre_win_rate": 0.8888888888888888, "step": 2191}
{"time": 1767341400.211246, "phase": "train", "update": 2192, "total_env_steps": 7014400, "episode_reward": 0.27673113346099854, "value_loss": 0.006106704287230968, "policy_loss": -0.0013102916197233582, "dist_entropy": 0.6252078056335449, "actor_grad_norm": 0.0769798681139946, "critic_grad_norm": 0.03818940743803978, "ratio": 1.0003693103790283, "entropy": 0.6252078056335449, "incre_win_rate": 0.9534883720930233, "step": 2192}
{"time": 1767341404.3623135, "phase": "train", "update": 2193, "total_env_steps": 7017600, "episode_reward": 0.27430880069732666, "value_loss": 0.0042096364311873915, "policy_loss": -0.001204136123817534, "dist_entropy": 0.6556151509284973, "actor_grad_norm": 0.09319974482059479, "critic_grad_norm": 0.03199153020977974, "ratio": 1.000222086906433, "entropy": 0.6556151509284973, "incre_win_rate": 0.9148936170212766, "step": 2193}
{"time": 1767341408.6214085, "phase": "train", "update": 2194, "total_env_steps": 7020800, "episode_reward": 0.27245447039604187, "value_loss": 0.0036354571115225554, "policy_loss": -0.0012533983881880318, "dist_entropy": 0.6729959845542908, "actor_grad_norm": 0.08603277802467346, "critic_grad_norm": 0.032460909336805344, "ratio": 0.9999836087226868, "entropy": 0.6729959845542908, "incre_win_rate": 0.9555555555555556, "step": 2194}
{"time": 1767341412.740084, "phase": "train", "update": 2195, "total_env_steps": 7024000, "episode_reward": 0.27723923325538635, "value_loss": 0.0035124317277222873, "policy_loss": -0.001205978551237763, "dist_entropy": 0.6801840186119079, "actor_grad_norm": 0.07080180943012238, "critic_grad_norm": 0.02520275115966797, "ratio": 0.9997477531433105, "entropy": 0.6801840186119079, "incre_win_rate": 0.9302325581395349, "step": 2195}
{"time": 1767341416.8634825, "phase": "train", "update": 2196, "total_env_steps": 7027200, "episode_reward": 0.2753104269504547, "value_loss": 0.003923271130770445, "policy_loss": -0.001237706948572992, "dist_entropy": 0.6427393794059754, "actor_grad_norm": 0.08597935736179352, "critic_grad_norm": 0.016357136890292168, "ratio": 1.0001716613769531, "entropy": 0.6427393794059754, "incre_win_rate": 0.9333333333333333, "step": 2196}
{"time": 1767341420.9633653, "phase": "train", "update": 2197, "total_env_steps": 7030400, "episode_reward": 0.28094372153282166, "value_loss": 0.0035120103508234023, "policy_loss": -0.00116367998576834, "dist_entropy": 0.6886703252792359, "actor_grad_norm": 0.0689254030585289, "critic_grad_norm": 0.018541375175118446, "ratio": 0.9998043179512024, "entropy": 0.6886703252792359, "incre_win_rate": 0.9777777777777777, "step": 2197}
{"time": 1767341425.055389, "phase": "train", "update": 2198, "total_env_steps": 7033600, "episode_reward": 0.2627224624156952, "value_loss": 0.005006497353315353, "policy_loss": -0.0013358748827183575, "dist_entropy": 0.6861837863922119, "actor_grad_norm": 0.07168146222829819, "critic_grad_norm": 0.02972453646361828, "ratio": 1.0003442764282227, "entropy": 0.6861837863922119, "incre_win_rate": 0.9069767441860465, "step": 2198}
{"time": 1767341429.1756594, "phase": "train", "update": 2199, "total_env_steps": 7036800, "episode_reward": 0.2761925756931305, "value_loss": 0.004523113183677196, "policy_loss": -0.0014085209082242756, "dist_entropy": 0.6876824736595154, "actor_grad_norm": 0.07198816537857056, "critic_grad_norm": 0.04337295517325401, "ratio": 0.9998738169670105, "entropy": 0.6876824736595154, "incre_win_rate": 0.9111111111111111, "step": 2199}
{"time": 1767341433.334953, "phase": "train", "update": 2200, "total_env_steps": 7040000, "episode_reward": 0.27635297179222107, "value_loss": 0.004758573416620493, "policy_loss": -0.0013347118729484463, "dist_entropy": 0.7121723413467407, "actor_grad_norm": 0.0711214691400528, "critic_grad_norm": 0.043110817670822144, "ratio": 1.0001537799835205, "entropy": 0.7121723413467407, "incre_win_rate": 0.9347826086956522, "step": 2200}
{"time": 1767341437.4501898, "phase": "train", "update": 2201, "total_env_steps": 7043200, "episode_reward": 0.27081072330474854, "value_loss": 0.004240648169070482, "policy_loss": -0.0012396248089146412, "dist_entropy": 0.6921852946281433, "actor_grad_norm": 0.06812430918216705, "critic_grad_norm": 0.029442762956023216, "ratio": 0.9998071789741516, "entropy": 0.6921852946281433, "incre_win_rate": 0.9534883720930233, "step": 2201}
{"time": 1767341446.523521, "phase": "eval", "update": 2201, "total_env_steps": 7043200, "eval_win_rate": 1.0, "eval_episode_reward": 20.000827814569536, "step": 2201}
{"time": 1767341450.6391692, "phase": "train", "update": 2202, "total_env_steps": 7046400, "episode_reward": 0.2655908465385437, "value_loss": 0.005663761775940657, "policy_loss": -0.0014790302735139705, "dist_entropy": 0.6863596200942993, "actor_grad_norm": 0.08961548656225204, "critic_grad_norm": 0.04254333674907684, "ratio": 0.9997655749320984, "entropy": 0.6863596200942993, "incre_win_rate": 0.9302325581395349, "step": 2202}
{"time": 1767341454.7093198, "phase": "train", "update": 2203, "total_env_steps": 7049600, "episode_reward": 0.2558594048023224, "value_loss": 0.012125829607248307, "policy_loss": -0.0014729394220438508, "dist_entropy": 0.6613048195838929, "actor_grad_norm": 0.08338414877653122, "critic_grad_norm": 0.053049542009830475, "ratio": 1.0003302097320557, "entropy": 0.6613048195838929, "incre_win_rate": 0.8409090909090909, "step": 2203}
{"time": 1767341458.7919633, "phase": "train", "update": 2204, "total_env_steps": 7052800, "episode_reward": 0.2568594813346863, "value_loss": 0.010773214139044284, "policy_loss": -0.0010467348013200705, "dist_entropy": 0.6677003741264343, "actor_grad_norm": 0.10651254653930664, "critic_grad_norm": 0.062417324632406235, "ratio": 0.9998259544372559, "entropy": 0.6677003741264343, "incre_win_rate": 0.7857142857142857, "step": 2204}
{"time": 1767341462.9424784, "phase": "train", "update": 2205, "total_env_steps": 7056000, "episode_reward": 0.2738886773586273, "value_loss": 0.005425208155065775, "policy_loss": -0.0007697111678488966, "dist_entropy": 0.6831160306930542, "actor_grad_norm": 0.08161311596632004, "critic_grad_norm": 0.06512030214071274, "ratio": 0.999881386756897, "entropy": 0.6831160306930542, "incre_win_rate": 0.9347826086956522, "step": 2205}
{"time": 1767341467.0222242, "phase": "train", "update": 2206, "total_env_steps": 7059200, "episode_reward": 0.2657817602157593, "value_loss": 0.005819065216928721, "policy_loss": -0.00128862010919093, "dist_entropy": 0.6895508408546448, "actor_grad_norm": 0.08488882333040237, "critic_grad_norm": 0.07510490715503693, "ratio": 0.9998422861099243, "entropy": 0.6895508408546448, "incre_win_rate": 0.8409090909090909, "step": 2206}
{"time": 1767341471.1460435, "phase": "train", "update": 2207, "total_env_steps": 7062400, "episode_reward": 0.27279698848724365, "value_loss": 0.004288490395992994, "policy_loss": -0.0010869059369412071, "dist_entropy": 0.7193818092346191, "actor_grad_norm": 0.08314874023199081, "critic_grad_norm": 0.06976349651813507, "ratio": 0.9998819231987, "entropy": 0.7193818092346191, "incre_win_rate": 0.9545454545454546, "step": 2207}
{"time": 1767341475.2604575, "phase": "train", "update": 2208, "total_env_steps": 7065600, "episode_reward": 0.2793000042438507, "value_loss": 0.005730427429080009, "policy_loss": -0.0012275836117851212, "dist_entropy": 0.7061702966690063, "actor_grad_norm": 0.08673956990242004, "critic_grad_norm": 0.042872872203588486, "ratio": 0.9996762275695801, "entropy": 0.7061702966690063, "incre_win_rate": 0.9555555555555556, "step": 2208}
{"time": 1767341479.3772128, "phase": "train", "update": 2209, "total_env_steps": 7068800, "episode_reward": 0.2726697027683258, "value_loss": 0.003476302605122328, "policy_loss": -0.001491765038490911, "dist_entropy": 0.7202944040298462, "actor_grad_norm": 0.09571817517280579, "critic_grad_norm": 0.045946937054395676, "ratio": 0.9997127652168274, "entropy": 0.7202944040298462, "incre_win_rate": 0.9772727272727273, "step": 2209}
{"time": 1767341483.4686208, "phase": "train", "update": 2210, "total_env_steps": 7072000, "episode_reward": 0.26893627643585205, "value_loss": 0.005237156711518765, "policy_loss": -0.0012328114611557695, "dist_entropy": 0.7105152368545532, "actor_grad_norm": 0.09718667715787888, "critic_grad_norm": 0.02360835298895836, "ratio": 0.9995521903038025, "entropy": 0.7105152368545532, "incre_win_rate": 0.9090909090909091, "step": 2210}
{"time": 1767341487.594601, "phase": "train", "update": 2211, "total_env_steps": 7075200, "episode_reward": 0.2618708908557892, "value_loss": 0.012043680064380169, "policy_loss": -0.0014543718823091466, "dist_entropy": 0.7130265593528747, "actor_grad_norm": 0.08531206101179123, "critic_grad_norm": 0.07391642779111862, "ratio": 1.0002708435058594, "entropy": 0.7130265593528747, "incre_win_rate": 0.8863636363636364, "step": 2211}
{"time": 1767341491.698666, "phase": "train", "update": 2212, "total_env_steps": 7078400, "episode_reward": 0.2692425549030304, "value_loss": 0.004273255541920662, "policy_loss": -0.0012123680591287211, "dist_entropy": 0.7657603979110718, "actor_grad_norm": 0.09909661114215851, "critic_grad_norm": 0.038082607090473175, "ratio": 1.0000386238098145, "entropy": 0.7657603979110718, "incre_win_rate": 0.9761904761904762, "step": 2212}
{"time": 1767341495.837814, "phase": "train", "update": 2213, "total_env_steps": 7081600, "episode_reward": 0.2639108896255493, "value_loss": 0.004467579629272222, "policy_loss": -0.0011613586620839555, "dist_entropy": 0.7136127948760986, "actor_grad_norm": 0.08674772828817368, "critic_grad_norm": 0.05120399221777916, "ratio": 1.000247597694397, "entropy": 0.7136127948760986, "incre_win_rate": 0.9333333333333333, "step": 2213}
{"time": 1767341499.967701, "phase": "train", "update": 2214, "total_env_steps": 7084800, "episode_reward": 0.26931601762771606, "value_loss": 0.002969837561249733, "policy_loss": -0.0012244238057057544, "dist_entropy": 0.7144302129745483, "actor_grad_norm": 0.08499222993850708, "critic_grad_norm": 0.03511079028248787, "ratio": 0.9998787045478821, "entropy": 0.7144302129745483, "incre_win_rate": 0.9534883720930233, "step": 2214}
{"time": 1767341504.086008, "phase": "train", "update": 2215, "total_env_steps": 7088000, "episode_reward": 0.2745891809463501, "value_loss": 0.002784998482093215, "policy_loss": -0.0012552965036491059, "dist_entropy": 0.732268500328064, "actor_grad_norm": 0.0709690973162651, "critic_grad_norm": 0.031515490263700485, "ratio": 1.0001205205917358, "entropy": 0.732268500328064, "incre_win_rate": 1.0, "step": 2215}
{"time": 1767341508.1937647, "phase": "train", "update": 2216, "total_env_steps": 7091200, "episode_reward": 0.27416908740997314, "value_loss": 0.0036986768711358307, "policy_loss": -0.0011220029884455585, "dist_entropy": 0.6889229655265808, "actor_grad_norm": 0.07481218874454498, "critic_grad_norm": 0.029457837343215942, "ratio": 1.0002082586288452, "entropy": 0.6889229655265808, "incre_win_rate": 0.9347826086956522, "step": 2216}
{"time": 1767341512.287008, "phase": "train", "update": 2217, "total_env_steps": 7094400, "episode_reward": 0.2692715525627136, "value_loss": 0.004511397704482079, "policy_loss": -0.0011640990022697584, "dist_entropy": 0.6969802737236023, "actor_grad_norm": 0.08421113342046738, "critic_grad_norm": 0.02337169647216797, "ratio": 0.999954342842102, "entropy": 0.6969802737236023, "incre_win_rate": 0.9302325581395349, "step": 2217}
{"time": 1767341516.372989, "phase": "train", "update": 2218, "total_env_steps": 7097600, "episode_reward": 0.26824918389320374, "value_loss": 0.003741510305553675, "policy_loss": -0.001018398416552202, "dist_entropy": 0.7066961765289307, "actor_grad_norm": 0.07598908990621567, "critic_grad_norm": 0.01841781847178936, "ratio": 1.0000362396240234, "entropy": 0.7066961765289307, "incre_win_rate": 0.9534883720930233, "step": 2218}
{"time": 1767341520.4758618, "phase": "train", "update": 2219, "total_env_steps": 7100800, "episode_reward": 0.2758319675922394, "value_loss": 0.00213629100471735, "policy_loss": -0.0016758655977056947, "dist_entropy": 0.7321943879127503, "actor_grad_norm": 0.1171749010682106, "critic_grad_norm": 0.012299253605306149, "ratio": 1.000055193901062, "entropy": 0.7321943879127503, "incre_win_rate": 0.9782608695652174, "step": 2219}
{"time": 1767341524.563938, "phase": "train", "update": 2220, "total_env_steps": 7104000, "episode_reward": 0.2689724862575531, "value_loss": 0.0035377808846533297, "policy_loss": -0.001145875177607536, "dist_entropy": 0.7104449033737182, "actor_grad_norm": 0.09033419191837311, "critic_grad_norm": 0.02226812019944191, "ratio": 0.9996633529663086, "entropy": 0.7104449033737182, "incre_win_rate": 0.9047619047619048, "step": 2220}
{"time": 1767341528.7099056, "phase": "train", "update": 2221, "total_env_steps": 7107200, "episode_reward": 0.26978686451911926, "value_loss": 0.002928428491577506, "policy_loss": -0.0014178490732490445, "dist_entropy": 0.7037940979003906, "actor_grad_norm": 0.10786886513233185, "critic_grad_norm": 0.029641468077898026, "ratio": 1.0000216960906982, "entropy": 0.7037940979003906, "incre_win_rate": 1.0, "step": 2221}
{"time": 1767341532.81495, "phase": "train", "update": 2222, "total_env_steps": 7110400, "episode_reward": 0.2688700258731842, "value_loss": 0.003516334481537342, "policy_loss": -0.001284977922340147, "dist_entropy": 0.7104581117630004, "actor_grad_norm": 0.09318270534276962, "critic_grad_norm": 0.018538113683462143, "ratio": 0.9995636343955994, "entropy": 0.7104581117630004, "incre_win_rate": 0.975609756097561, "step": 2222}
{"time": 1767341536.9285235, "phase": "train", "update": 2223, "total_env_steps": 7113600, "episode_reward": 0.26633280515670776, "value_loss": 0.004748004395514727, "policy_loss": -0.0012306441205007345, "dist_entropy": 0.7000770688056945, "actor_grad_norm": 0.0836561769247055, "critic_grad_norm": 0.02713356353342533, "ratio": 1.0001262426376343, "entropy": 0.7000770688056945, "incre_win_rate": 0.9347826086956522, "step": 2223}
{"time": 1767341541.0227532, "phase": "train", "update": 2224, "total_env_steps": 7116800, "episode_reward": 0.2707626223564148, "value_loss": 0.005790890753269195, "policy_loss": -0.001374241512061758, "dist_entropy": 0.6851991057395935, "actor_grad_norm": 0.08545179665088654, "critic_grad_norm": 0.03174590691924095, "ratio": 1.000077486038208, "entropy": 0.6851991057395935, "incre_win_rate": 0.8837209302325582, "step": 2224}
{"time": 1767341545.1184, "phase": "train", "update": 2225, "total_env_steps": 7120000, "episode_reward": 0.2715231776237488, "value_loss": 0.0043485104106366634, "policy_loss": -0.0014991093927775978, "dist_entropy": 0.7010919332504273, "actor_grad_norm": 0.08987288922071457, "critic_grad_norm": 0.03025633655488491, "ratio": 1.0001921653747559, "entropy": 0.7010919332504273, "incre_win_rate": 0.9777777777777777, "step": 2225}
{"time": 1767341549.185749, "phase": "train", "update": 2226, "total_env_steps": 7123200, "episode_reward": 0.2570943832397461, "value_loss": 0.005893111042678356, "policy_loss": -0.0014256998922732578, "dist_entropy": 0.6986931324005127, "actor_grad_norm": 0.07722625881433487, "critic_grad_norm": 0.07281125336885452, "ratio": 0.9997175335884094, "entropy": 0.6986931324005127, "incre_win_rate": 0.9047619047619048, "step": 2226}
{"time": 1767341559.2659054, "phase": "eval", "update": 2226, "total_env_steps": 7123200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.921047185430464, "step": 2226}
{"time": 1767341563.3544722, "phase": "train", "update": 2227, "total_env_steps": 7126400, "episode_reward": 0.26514071226119995, "value_loss": 0.0046649687923491, "policy_loss": -0.0012559162108189525, "dist_entropy": 0.6861015796661377, "actor_grad_norm": 0.0739201232790947, "critic_grad_norm": 0.057775624096393585, "ratio": 0.9998688101768494, "entropy": 0.6861015796661377, "incre_win_rate": 0.9047619047619048, "step": 2227}
{"time": 1767341567.4596632, "phase": "train", "update": 2228, "total_env_steps": 7129600, "episode_reward": 0.2675967514514923, "value_loss": 0.003756913961842656, "policy_loss": -0.0015287425513321295, "dist_entropy": 0.6939082980155945, "actor_grad_norm": 0.07073885947465897, "critic_grad_norm": 0.04489019140601158, "ratio": 1.000064492225647, "entropy": 0.6939082980155945, "incre_win_rate": 0.9555555555555556, "step": 2228}
{"time": 1767341571.5757313, "phase": "train", "update": 2229, "total_env_steps": 7132800, "episode_reward": 0.281059592962265, "value_loss": 0.002158838463947177, "policy_loss": -0.0010769797804897508, "dist_entropy": 0.6826390743255615, "actor_grad_norm": 0.09236790984869003, "critic_grad_norm": 0.03275862708687782, "ratio": 1.0000542402267456, "entropy": 0.6826390743255615, "incre_win_rate": 1.0, "step": 2229}
{"time": 1767341575.6960702, "phase": "train", "update": 2230, "total_env_steps": 7136000, "episode_reward": 0.2771150767803192, "value_loss": 0.0022942439187318086, "policy_loss": -0.001215819913212357, "dist_entropy": 0.7229264736175537, "actor_grad_norm": 0.08577192574739456, "critic_grad_norm": 0.023470813408493996, "ratio": 0.999686062335968, "entropy": 0.7229264736175537, "incre_win_rate": 0.9782608695652174, "step": 2230}
{"time": 1767341579.8134427, "phase": "train", "update": 2231, "total_env_steps": 7139200, "episode_reward": 0.2759188711643219, "value_loss": 0.0024893021211028097, "policy_loss": -0.0012949900238499624, "dist_entropy": 0.7075021266937256, "actor_grad_norm": 0.07039614766836166, "critic_grad_norm": 0.015981478616595268, "ratio": 0.9998717308044434, "entropy": 0.7075021266937256, "incre_win_rate": 1.0, "step": 2231}
{"time": 1767341583.9374106, "phase": "train", "update": 2232, "total_env_steps": 7142400, "episode_reward": 0.26562395691871643, "value_loss": 0.005199406668543816, "policy_loss": -0.0011304495329397923, "dist_entropy": 0.7101932168006897, "actor_grad_norm": 0.07720888406038284, "critic_grad_norm": 0.02862648107111454, "ratio": 0.9998035430908203, "entropy": 0.7101932168006897, "incre_win_rate": 0.9111111111111111, "step": 2232}
{"time": 1767341588.0402138, "phase": "train", "update": 2233, "total_env_steps": 7145600, "episode_reward": 0.25990065932273865, "value_loss": 0.0050080657936632635, "policy_loss": -0.0014565237337265558, "dist_entropy": 0.6842352867126464, "actor_grad_norm": 0.07628186047077179, "critic_grad_norm": 0.02617485821247101, "ratio": 0.9997370839118958, "entropy": 0.6842352867126464, "incre_win_rate": 0.8571428571428571, "step": 2233}
{"time": 1767341592.1134446, "phase": "train", "update": 2234, "total_env_steps": 7148800, "episode_reward": 0.270298033952713, "value_loss": 0.006289913970977068, "policy_loss": -0.0012606847982596036, "dist_entropy": 0.6723962903022767, "actor_grad_norm": 0.07188042998313904, "critic_grad_norm": 0.03576677665114403, "ratio": 0.9999313354492188, "entropy": 0.6723962903022767, "incre_win_rate": 0.9772727272727273, "step": 2234}
{"time": 1767341596.2160711, "phase": "train", "update": 2235, "total_env_steps": 7152000, "episode_reward": 0.2704118490219116, "value_loss": 0.004149116575717926, "policy_loss": -0.0013580690118459415, "dist_entropy": 0.7015658974647522, "actor_grad_norm": 0.08536353707313538, "critic_grad_norm": 0.032320138067007065, "ratio": 1.0001468658447266, "entropy": 0.7015658974647522, "incre_win_rate": 0.9111111111111111, "step": 2235}
{"time": 1767341600.2879207, "phase": "train", "update": 2236, "total_env_steps": 7155200, "episode_reward": 0.27143624424934387, "value_loss": 0.003509470261633396, "policy_loss": -0.0011747539501058668, "dist_entropy": 0.7039114475250244, "actor_grad_norm": 0.0800747200846672, "critic_grad_norm": 0.022305777296423912, "ratio": 0.9997503161430359, "entropy": 0.7039114475250244, "incre_win_rate": 0.9545454545454546, "step": 2236}
{"time": 1767341604.412365, "phase": "train", "update": 2237, "total_env_steps": 7158400, "episode_reward": 0.2693833112716675, "value_loss": 0.0038433661684393883, "policy_loss": -0.0013531377582509663, "dist_entropy": 0.6999793887138367, "actor_grad_norm": 0.08074049651622772, "critic_grad_norm": 0.028809804469347, "ratio": 0.999986469745636, "entropy": 0.6999793887138367, "incre_win_rate": 0.9761904761904762, "step": 2237}
{"time": 1767341608.509244, "phase": "train", "update": 2238, "total_env_steps": 7161600, "episode_reward": 0.26839300990104675, "value_loss": 0.004706277512013912, "policy_loss": -0.0013583716180527005, "dist_entropy": 0.6540803551673889, "actor_grad_norm": 0.08813363313674927, "critic_grad_norm": 0.04050340875983238, "ratio": 1.000080943107605, "entropy": 0.6540803551673889, "incre_win_rate": 0.9090909090909091, "step": 2238}
{"time": 1767341612.6325588, "phase": "train", "update": 2239, "total_env_steps": 7164800, "episode_reward": 0.27933359146118164, "value_loss": 0.0024835339747369288, "policy_loss": -0.0012864372129754997, "dist_entropy": 0.6736949324607849, "actor_grad_norm": 0.07754995673894882, "critic_grad_norm": 0.023914966732263565, "ratio": 1.0001407861709595, "entropy": 0.6736949324607849, "incre_win_rate": 0.9777777777777777, "step": 2239}
{"time": 1767341616.7513223, "phase": "train", "update": 2240, "total_env_steps": 7168000, "episode_reward": 0.2854635715484619, "value_loss": 0.002770795067772269, "policy_loss": -0.0013760213658535747, "dist_entropy": 0.6938225507736206, "actor_grad_norm": 0.0892447680234909, "critic_grad_norm": 0.037250690162181854, "ratio": 1.0003594160079956, "entropy": 0.6938225507736206, "incre_win_rate": 1.0, "step": 2240}
{"time": 1767341620.876345, "phase": "train", "update": 2241, "total_env_steps": 7171200, "episode_reward": 0.2811051309108734, "value_loss": 0.0034281041007488966, "policy_loss": -0.001589361474690776, "dist_entropy": 0.7066450119018555, "actor_grad_norm": 0.09008630365133286, "critic_grad_norm": 0.024140072986483574, "ratio": 0.9995962381362915, "entropy": 0.7066450119018555, "incre_win_rate": 0.9787234042553191, "step": 2241}
{"time": 1767341624.9892282, "phase": "train", "update": 2242, "total_env_steps": 7174400, "episode_reward": 0.28188326954841614, "value_loss": 0.002231345232576132, "policy_loss": -0.001219017705083303, "dist_entropy": 0.7123897552490235, "actor_grad_norm": 0.0921076163649559, "critic_grad_norm": 0.017422622069716454, "ratio": 1.0001071691513062, "entropy": 0.7123897552490235, "incre_win_rate": 1.0, "step": 2242}
{"time": 1767341629.1267989, "phase": "train", "update": 2243, "total_env_steps": 7177600, "episode_reward": 0.2767084240913391, "value_loss": 0.0032993816304951904, "policy_loss": -0.0013412830060099523, "dist_entropy": 0.681106162071228, "actor_grad_norm": 0.08248332142829895, "critic_grad_norm": 0.04968912526965141, "ratio": 1.0003507137298584, "entropy": 0.681106162071228, "incre_win_rate": 0.9555555555555556, "step": 2243}
{"time": 1767341633.228528, "phase": "train", "update": 2244, "total_env_steps": 7180800, "episode_reward": 0.27206334471702576, "value_loss": 0.003736625146120787, "policy_loss": -0.001258011524214453, "dist_entropy": 0.6660443067550659, "actor_grad_norm": 0.06933250278234482, "critic_grad_norm": 0.029883623123168945, "ratio": 0.9998268485069275, "entropy": 0.6660443067550659, "incre_win_rate": 0.9318181818181818, "step": 2244}
{"time": 1767341637.359981, "phase": "train", "update": 2245, "total_env_steps": 7184000, "episode_reward": 0.2759648859500885, "value_loss": 0.005359821021556854, "policy_loss": -0.0011356309210007963, "dist_entropy": 0.669286024570465, "actor_grad_norm": 0.06855922192335129, "critic_grad_norm": 0.03021649830043316, "ratio": 0.9999060034751892, "entropy": 0.669286024570465, "incre_win_rate": 0.9555555555555556, "step": 2245}
{"time": 1767341641.4980018, "phase": "train", "update": 2246, "total_env_steps": 7187200, "episode_reward": 0.28169286251068115, "value_loss": 0.0035324285738170145, "policy_loss": -0.0012435655518711285, "dist_entropy": 0.6838141918182373, "actor_grad_norm": 0.0854792520403862, "critic_grad_norm": 0.03175695613026619, "ratio": 0.9998738169670105, "entropy": 0.6838141918182373, "incre_win_rate": 0.9583333333333334, "step": 2246}
{"time": 1767341645.5731015, "phase": "train", "update": 2247, "total_env_steps": 7190400, "episode_reward": 0.2748592793941498, "value_loss": 0.004843648057430983, "policy_loss": -0.0010768732460022079, "dist_entropy": 0.642900824546814, "actor_grad_norm": 0.07302194088697433, "critic_grad_norm": 0.048138175159692764, "ratio": 0.9997634291648865, "entropy": 0.642900824546814, "incre_win_rate": 0.9523809523809523, "step": 2247}
{"time": 1767341650.0055897, "phase": "train", "update": 2248, "total_env_steps": 7193600, "episode_reward": 0.27839404344558716, "value_loss": 0.005047694314271212, "policy_loss": -0.0012711836660344034, "dist_entropy": 0.6844707250595092, "actor_grad_norm": 0.0690590962767601, "critic_grad_norm": 0.04084772244095802, "ratio": 0.999943196773529, "entropy": 0.6844707250595092, "incre_win_rate": 0.9565217391304348, "step": 2248}
{"time": 1767341654.3946035, "phase": "train", "update": 2249, "total_env_steps": 7196800, "episode_reward": 0.2749379277229309, "value_loss": 0.004790908377617598, "policy_loss": -0.0014910699916669268, "dist_entropy": 0.7164488673210144, "actor_grad_norm": 0.08296148478984833, "critic_grad_norm": 0.03344443067908287, "ratio": 0.9999127388000488, "entropy": 0.7164488673210144, "incre_win_rate": 0.9555555555555556, "step": 2249}
{"time": 1767341658.5091743, "phase": "train", "update": 2250, "total_env_steps": 7200000, "episode_reward": 0.2775372564792633, "value_loss": 0.0032816532999277114, "policy_loss": -0.0010698892487482682, "dist_entropy": 0.6912011742591858, "actor_grad_norm": 0.07707792520523071, "critic_grad_norm": 0.015855705365538597, "ratio": 0.9999243021011353, "entropy": 0.6912011742591858, "incre_win_rate": 0.9534883720930233, "step": 2250}
{"time": 1767341662.6300907, "phase": "train", "update": 2251, "total_env_steps": 7203200, "episode_reward": 0.2737375497817993, "value_loss": 0.0054498562589287754, "policy_loss": -0.0015704402576858455, "dist_entropy": 0.6989630579948425, "actor_grad_norm": 0.08167500793933868, "critic_grad_norm": 0.013690783642232418, "ratio": 1.0006775856018066, "entropy": 0.6989630579948425, "incre_win_rate": 0.9318181818181818, "step": 2251}
{"time": 1767341672.021591, "phase": "eval", "update": 2251, "total_env_steps": 7203200, "eval_win_rate": 1.0, "eval_episode_reward": 20.0, "step": 2251}
{"time": 1767341676.1367805, "phase": "train", "update": 2252, "total_env_steps": 7206400, "episode_reward": 0.27771109342575073, "value_loss": 0.0024511776864528656, "policy_loss": -0.0014276297711676377, "dist_entropy": 0.7051286458969116, "actor_grad_norm": 0.1034701019525528, "critic_grad_norm": 0.018730279058218002, "ratio": 1.0003658533096313, "entropy": 0.7051286458969116, "incre_win_rate": 0.9565217391304348, "step": 2252}
{"time": 1767341680.217369, "phase": "train", "update": 2253, "total_env_steps": 7209600, "episode_reward": 0.2732284963130951, "value_loss": 0.003745903866365552, "policy_loss": -0.0011821196416662793, "dist_entropy": 0.69871426820755, "actor_grad_norm": 0.08901546895503998, "critic_grad_norm": 0.03435726836323738, "ratio": 1.000108242034912, "entropy": 0.69871426820755, "incre_win_rate": 0.9555555555555556, "step": 2253}
{"time": 1767341684.3335583, "phase": "train", "update": 2254, "total_env_steps": 7212800, "episode_reward": 0.2765795886516571, "value_loss": 0.003096996806561947, "policy_loss": -0.0011311613114992625, "dist_entropy": 0.7011043667793274, "actor_grad_norm": 0.08394840359687805, "critic_grad_norm": 0.02697356417775154, "ratio": 0.9996656775474548, "entropy": 0.7011043667793274, "incre_win_rate": 0.9545454545454546, "step": 2254}
{"time": 1767341688.4410756, "phase": "train", "update": 2255, "total_env_steps": 7216000, "episode_reward": 0.26838576793670654, "value_loss": 0.004011685261502862, "policy_loss": -0.0013818457071138822, "dist_entropy": 0.6817426800727844, "actor_grad_norm": 0.08642692118883133, "critic_grad_norm": 0.019017061218619347, "ratio": 0.9999188780784607, "entropy": 0.6817426800727844, "incre_win_rate": 0.9285714285714286, "step": 2255}
{"time": 1767341692.5513873, "phase": "train", "update": 2256, "total_env_steps": 7219200, "episode_reward": 0.2625392973423004, "value_loss": 0.006469550728797913, "policy_loss": -0.0013656254129507772, "dist_entropy": 0.7006280422210693, "actor_grad_norm": 0.08739332854747772, "critic_grad_norm": 0.028269220143556595, "ratio": 0.9999589920043945, "entropy": 0.7006280422210693, "incre_win_rate": 0.8666666666666667, "step": 2256}
{"time": 1767341696.7003121, "phase": "train", "update": 2257, "total_env_steps": 7222400, "episode_reward": 0.2765149176120758, "value_loss": 0.0035434015560895206, "policy_loss": -0.0013166581012477251, "dist_entropy": 0.6995250582695007, "actor_grad_norm": 0.07715108245611191, "critic_grad_norm": 0.024934718385338783, "ratio": 1.000095248222351, "entropy": 0.6995250582695007, "incre_win_rate": 0.9545454545454546, "step": 2257}
{"time": 1767341700.788485, "phase": "train", "update": 2258, "total_env_steps": 7225600, "episode_reward": 0.2691582143306732, "value_loss": 0.0031763464212417603, "policy_loss": -0.0013698509177785922, "dist_entropy": 0.6890971899032593, "actor_grad_norm": 0.0948713943362236, "critic_grad_norm": 0.054814618080854416, "ratio": 0.9999019503593445, "entropy": 0.6890971899032593, "incre_win_rate": 0.9534883720930233, "step": 2258}
{"time": 1767341704.8953438, "phase": "train", "update": 2259, "total_env_steps": 7228800, "episode_reward": 0.27250000834465027, "value_loss": 0.0030226482544094325, "policy_loss": -0.0017672194055201374, "dist_entropy": 0.7172647356987, "actor_grad_norm": 0.11863761395215988, "critic_grad_norm": 0.041117794811725616, "ratio": 0.9996616244316101, "entropy": 0.7172647356987, "incre_win_rate": 1.0, "step": 2259}
{"time": 1767341709.0510993, "phase": "train", "update": 2260, "total_env_steps": 7232000, "episode_reward": 0.2772754728794098, "value_loss": 0.0038295545149594546, "policy_loss": -0.0010495867092906509, "dist_entropy": 0.7268380165100098, "actor_grad_norm": 0.08017974346876144, "critic_grad_norm": 0.051908016204833984, "ratio": 1.000020980834961, "entropy": 0.7268380165100098, "incre_win_rate": 0.975609756097561, "step": 2260}
{"time": 1767341713.1671104, "phase": "train", "update": 2261, "total_env_steps": 7235200, "episode_reward": 0.2633330225944519, "value_loss": 0.0039554104208946225, "policy_loss": -0.001428011390179762, "dist_entropy": 0.7053750157356262, "actor_grad_norm": 0.09580772370100021, "critic_grad_norm": 0.02951531484723091, "ratio": 0.9996895790100098, "entropy": 0.7053750157356262, "incre_win_rate": 0.9347826086956522, "step": 2261}
{"time": 1767341717.265154, "phase": "train", "update": 2262, "total_env_steps": 7238400, "episode_reward": 0.27338629961013794, "value_loss": 0.004151639249175787, "policy_loss": -0.0009938378724744013, "dist_entropy": 0.6922623515129089, "actor_grad_norm": 0.1056235060095787, "critic_grad_norm": 0.02856236696243286, "ratio": 1.000251293182373, "entropy": 0.6922623515129089, "incre_win_rate": 0.9302325581395349, "step": 2262}
{"time": 1767341721.3689327, "phase": "train", "update": 2263, "total_env_steps": 7241600, "episode_reward": 0.27055877447128296, "value_loss": 0.004014411894604564, "policy_loss": -0.0015480840168063282, "dist_entropy": 0.702669894695282, "actor_grad_norm": 0.09253396838903427, "critic_grad_norm": 0.05513010174036026, "ratio": 0.9998485445976257, "entropy": 0.702669894695282, "incre_win_rate": 0.9534883720930233, "step": 2263}
{"time": 1767341725.4795718, "phase": "train", "update": 2264, "total_env_steps": 7244800, "episode_reward": 0.27190396189689636, "value_loss": 0.0049653960391879085, "policy_loss": -0.0013819201201638264, "dist_entropy": 0.7046598434448242, "actor_grad_norm": 0.0876116156578064, "critic_grad_norm": 0.04085899144411087, "ratio": 0.9997641444206238, "entropy": 0.7046598434448242, "incre_win_rate": 0.9347826086956522, "step": 2264}
{"time": 1767341729.5919955, "phase": "train", "update": 2265, "total_env_steps": 7248000, "episode_reward": 0.2674368917942047, "value_loss": 0.006878956779837608, "policy_loss": -0.0018530068541515732, "dist_entropy": 0.6933125495910645, "actor_grad_norm": 0.1032274141907692, "critic_grad_norm": 0.02305391989648342, "ratio": 0.9993212819099426, "entropy": 0.6933125495910645, "incre_win_rate": 0.8636363636363636, "step": 2265}
{"time": 1767341733.699432, "phase": "train", "update": 2266, "total_env_steps": 7251200, "episode_reward": 0.27792632579803467, "value_loss": 0.005400812719017267, "policy_loss": -0.0014189949553731652, "dist_entropy": 0.7215865254402161, "actor_grad_norm": 0.11242586374282837, "critic_grad_norm": 0.0321190319955349, "ratio": 1.000018835067749, "entropy": 0.7215865254402161, "incre_win_rate": 0.9555555555555556, "step": 2266}
{"time": 1767341737.7590337, "phase": "train", "update": 2267, "total_env_steps": 7254400, "episode_reward": 0.2735399305820465, "value_loss": 0.005610193405300379, "policy_loss": -0.0014357382425734145, "dist_entropy": 0.7114141583442688, "actor_grad_norm": 0.08729485422372818, "critic_grad_norm": 0.023198649287223816, "ratio": 0.999872624874115, "entropy": 0.7114141583442688, "incre_win_rate": 0.9333333333333333, "step": 2267}
{"time": 1767341741.8116868, "phase": "train", "update": 2268, "total_env_steps": 7257600, "episode_reward": 0.27147766947746277, "value_loss": 0.0030557407066226006, "policy_loss": -0.0012069266704678228, "dist_entropy": 0.722210419178009, "actor_grad_norm": 0.10694489628076553, "critic_grad_norm": 0.019701037555933, "ratio": 1.0000582933425903, "entropy": 0.722210419178009, "incre_win_rate": 0.9318181818181818, "step": 2268}
{"time": 1767341745.8777432, "phase": "train", "update": 2269, "total_env_steps": 7260800, "episode_reward": 0.27397972345352173, "value_loss": 0.005933954194188118, "policy_loss": -0.0014879295908922785, "dist_entropy": 0.7174357533454895, "actor_grad_norm": 0.10116570442914963, "critic_grad_norm": 0.0186527818441391, "ratio": 0.9996517300605774, "entropy": 0.7174357533454895, "incre_win_rate": 0.9111111111111111, "step": 2269}
{"time": 1767341749.9467182, "phase": "train", "update": 2270, "total_env_steps": 7264000, "episode_reward": 0.2742094397544861, "value_loss": 0.006162451673299074, "policy_loss": -0.0019367443370903459, "dist_entropy": 0.7254153490066528, "actor_grad_norm": 0.09612639993429184, "critic_grad_norm": 0.01895095966756344, "ratio": 0.9999138116836548, "entropy": 0.7254153490066528, "incre_win_rate": 0.9302325581395349, "step": 2270}
{"time": 1767341753.9713898, "phase": "train", "update": 2271, "total_env_steps": 7267200, "episode_reward": 0.2710290849208832, "value_loss": 0.0066120952367782595, "policy_loss": -0.001381240371292236, "dist_entropy": 0.6943089962005615, "actor_grad_norm": 0.09516365081071854, "critic_grad_norm": 0.022701602429151535, "ratio": 1.0001806020736694, "entropy": 0.6943089962005615, "incre_win_rate": 0.9318181818181818, "step": 2271}
{"time": 1767341758.0435586, "phase": "train", "update": 2272, "total_env_steps": 7270400, "episode_reward": 0.266118586063385, "value_loss": 0.007276591565459967, "policy_loss": -0.0017285966248952178, "dist_entropy": 0.7038612484931945, "actor_grad_norm": 0.09943097829818726, "critic_grad_norm": 0.017151078209280968, "ratio": 1.000252604484558, "entropy": 0.7038612484931945, "incre_win_rate": 0.8888888888888888, "step": 2272}
{"time": 1767341762.1438506, "phase": "train", "update": 2273, "total_env_steps": 7273600, "episode_reward": 0.2752276360988617, "value_loss": 0.004535022750496864, "policy_loss": -0.0011557506011513397, "dist_entropy": 0.7252570390701294, "actor_grad_norm": 0.08257801830768585, "critic_grad_norm": 0.02600373886525631, "ratio": 0.999848484992981, "entropy": 0.7252570390701294, "incre_win_rate": 0.9772727272727273, "step": 2273}
{"time": 1767341766.2297804, "phase": "train", "update": 2274, "total_env_steps": 7276800, "episode_reward": 0.2739155888557434, "value_loss": 0.004768363852053881, "policy_loss": -0.0017167000850847104, "dist_entropy": 0.6962774157524109, "actor_grad_norm": 0.09322141855955124, "critic_grad_norm": 0.01782682165503502, "ratio": 0.9999526143074036, "entropy": 0.6962774157524109, "incre_win_rate": 0.9333333333333333, "step": 2274}
{"time": 1767341770.286394, "phase": "train", "update": 2275, "total_env_steps": 7280000, "episode_reward": 0.2688741683959961, "value_loss": 0.004140192922204733, "policy_loss": -0.001640761369012722, "dist_entropy": 0.7183719873428345, "actor_grad_norm": 0.0978386253118515, "critic_grad_norm": 0.017591023817658424, "ratio": 1.0000144243240356, "entropy": 0.7183719873428345, "incre_win_rate": 0.9318181818181818, "step": 2275}
{"time": 1767341774.3828325, "phase": "train", "update": 2276, "total_env_steps": 7283200, "episode_reward": 0.2701396942138672, "value_loss": 0.003330851951614022, "policy_loss": -0.0012676235230671296, "dist_entropy": 0.7249992728233338, "actor_grad_norm": 0.08692341297864914, "critic_grad_norm": 0.0223249401897192, "ratio": 1.0002717971801758, "entropy": 0.7249992728233338, "incre_win_rate": 0.9545454545454546, "step": 2276}
{"time": 1767341783.4849982, "phase": "eval", "update": 2276, "total_env_steps": 7283200, "eval_win_rate": 1.0, "eval_episode_reward": 20.0, "step": 2276}
{"time": 1767341787.599375, "phase": "train", "update": 2277, "total_env_steps": 7286400, "episode_reward": 0.2713622748851776, "value_loss": 0.003711368888616562, "policy_loss": -0.0011640527226916219, "dist_entropy": 0.7356947660446167, "actor_grad_norm": 0.08525890856981277, "critic_grad_norm": 0.033283621072769165, "ratio": 1.000268816947937, "entropy": 0.7356947660446167, "incre_win_rate": 0.9090909090909091, "step": 2277}
{"time": 1767341791.74438, "phase": "train", "update": 2278, "total_env_steps": 7289600, "episode_reward": 0.2683112621307373, "value_loss": 0.005786629673093557, "policy_loss": -0.0014118037831714503, "dist_entropy": 0.7120795965194702, "actor_grad_norm": 0.09481565654277802, "critic_grad_norm": 0.030325835570693016, "ratio": 1.0001330375671387, "entropy": 0.7120795965194702, "incre_win_rate": 0.9302325581395349, "step": 2278}
{"time": 1767341795.9058046, "phase": "train", "update": 2279, "total_env_steps": 7292800, "episode_reward": 0.27083611488342285, "value_loss": 0.0033873661421239378, "policy_loss": -0.0009529105619481726, "dist_entropy": 0.7598957538604736, "actor_grad_norm": 0.09752602875232697, "critic_grad_norm": 0.01950989104807377, "ratio": 1.000150203704834, "entropy": 0.7598957538604736, "incre_win_rate": 0.9767441860465116, "step": 2279}
{"time": 1767341799.996365, "phase": "train", "update": 2280, "total_env_steps": 7296000, "episode_reward": 0.262074738740921, "value_loss": 0.006382646970450878, "policy_loss": -0.0014712693969883618, "dist_entropy": 0.7317964434623718, "actor_grad_norm": 0.07154715061187744, "critic_grad_norm": 0.020307082682847977, "ratio": 1.0001006126403809, "entropy": 0.7317964434623718, "incre_win_rate": 0.9111111111111111, "step": 2280}
{"time": 1767341804.0736861, "phase": "train", "update": 2281, "total_env_steps": 7299200, "episode_reward": 0.2623261511325836, "value_loss": 0.0072367189452052115, "policy_loss": -0.0013276402999533587, "dist_entropy": 0.7460590243339539, "actor_grad_norm": 0.08865612745285034, "critic_grad_norm": 0.029127776622772217, "ratio": 1.0003175735473633, "entropy": 0.7460590243339539, "incre_win_rate": 0.8809523809523809, "step": 2281}
{"time": 1767341808.233925, "phase": "train", "update": 2282, "total_env_steps": 7302400, "episode_reward": 0.26112687587738037, "value_loss": 0.006216267310082913, "policy_loss": -0.001410308793852355, "dist_entropy": 0.7475876450538635, "actor_grad_norm": 0.10949333757162094, "critic_grad_norm": 0.048425473272800446, "ratio": 0.99993896484375, "entropy": 0.7475876450538635, "incre_win_rate": 0.8636363636363636, "step": 2282}
{"time": 1767341812.3598306, "phase": "train", "update": 2283, "total_env_steps": 7305600, "episode_reward": 0.26444950699806213, "value_loss": 0.004772153310477733, "policy_loss": -0.0013273153369420144, "dist_entropy": 0.7410507678985596, "actor_grad_norm": 0.0911238044500351, "critic_grad_norm": 0.026404788717627525, "ratio": 1.0005180835723877, "entropy": 0.7410507678985596, "incre_win_rate": 0.975609756097561, "step": 2283}
{"time": 1767341816.4647508, "phase": "train", "update": 2284, "total_env_steps": 7308800, "episode_reward": 0.267342209815979, "value_loss": 0.006103350780904293, "policy_loss": -0.001542859548086284, "dist_entropy": 0.712899649143219, "actor_grad_norm": 0.09705489873886108, "critic_grad_norm": 0.046454060822725296, "ratio": 1.0001976490020752, "entropy": 0.712899649143219, "incre_win_rate": 0.9347826086956522, "step": 2284}
{"time": 1767341820.6197379, "phase": "train", "update": 2285, "total_env_steps": 7312000, "episode_reward": 0.27492859959602356, "value_loss": 0.004212360084056854, "policy_loss": -0.0015012752210537884, "dist_entropy": 0.7144874215126038, "actor_grad_norm": 0.08711902797222137, "critic_grad_norm": 0.03179146721959114, "ratio": 0.9993963241577148, "entropy": 0.7144874215126038, "incre_win_rate": 0.9302325581395349, "step": 2285}
{"time": 1767341824.7198393, "phase": "train", "update": 2286, "total_env_steps": 7315200, "episode_reward": 0.2708303928375244, "value_loss": 0.003947638487443328, "policy_loss": -0.0010658536305783173, "dist_entropy": 0.7168855309486389, "actor_grad_norm": 0.07902955263853073, "critic_grad_norm": 0.013059000484645367, "ratio": 1.0001094341278076, "entropy": 0.7168855309486389, "incre_win_rate": 0.9318181818181818, "step": 2286}
{"time": 1767341858.037095, "phase": "train", "update": 2287, "total_env_steps": 7318400, "episode_reward": 0.2632036507129669, "value_loss": 0.04989308938384056, "policy_loss": -0.001288075974558467, "dist_entropy": 0.663606870174408, "actor_grad_norm": 0.08011994510889053, "critic_grad_norm": 0.15760654211044312, "ratio": 0.9998310208320618, "entropy": 0.663606870174408, "incre_win_rate": 1.0, "step": 2287}
{"time": 1767341862.0951653, "phase": "train", "update": 2288, "total_env_steps": 7321600, "episode_reward": 0.26167580485343933, "value_loss": 0.009811131097376347, "policy_loss": -0.0013136748285219823, "dist_entropy": 0.6648245811462402, "actor_grad_norm": 0.08686558157205582, "critic_grad_norm": 0.10593272745609283, "ratio": 0.99993896484375, "entropy": 0.6648245811462402, "incre_win_rate": 0.8222222222222222, "step": 2288}
{"time": 1767341866.2293916, "phase": "train", "update": 2289, "total_env_steps": 7324800, "episode_reward": 0.2660802900791168, "value_loss": 0.008326861076056957, "policy_loss": -0.0012652548996138434, "dist_entropy": 0.6616457462310791, "actor_grad_norm": 0.09544610977172852, "critic_grad_norm": 0.12374444305896759, "ratio": 1.0001085996627808, "entropy": 0.6616457462310791, "incre_win_rate": 0.8636363636363636, "step": 2289}
{"time": 1767341870.340069, "phase": "train", "update": 2290, "total_env_steps": 7328000, "episode_reward": 0.2610270380973816, "value_loss": 0.008444618061184883, "policy_loss": -0.0011878862207961305, "dist_entropy": 0.6719776749610901, "actor_grad_norm": 0.08621109277009964, "critic_grad_norm": 0.04358974099159241, "ratio": 1.0001941919326782, "entropy": 0.6719776749610901, "incre_win_rate": 0.8571428571428571, "step": 2290}
{"time": 1767341874.448293, "phase": "train", "update": 2291, "total_env_steps": 7331200, "episode_reward": 0.2686837911605835, "value_loss": 0.007618947699666023, "policy_loss": -0.001224848988453786, "dist_entropy": 0.6550174474716186, "actor_grad_norm": 0.09598352015018463, "critic_grad_norm": 0.052444782108068466, "ratio": 1.0000643730163574, "entropy": 0.6550174474716186, "incre_win_rate": 0.8222222222222222, "step": 2291}
{"time": 1767341878.5543818, "phase": "train", "update": 2292, "total_env_steps": 7334400, "episode_reward": 0.2701360881328583, "value_loss": 0.008230404648929834, "policy_loss": -0.0014365141363185785, "dist_entropy": 0.6746851682662964, "actor_grad_norm": 0.09270050376653671, "critic_grad_norm": 0.10279027372598648, "ratio": 1.0000321865081787, "entropy": 0.6746851682662964, "incre_win_rate": 0.8695652173913043, "step": 2292}
{"time": 1767341882.6698751, "phase": "train", "update": 2293, "total_env_steps": 7337600, "episode_reward": 0.2739812731742859, "value_loss": 0.005262548010796309, "policy_loss": -0.0011599775358455133, "dist_entropy": 0.6587252855300904, "actor_grad_norm": 0.08765707165002823, "critic_grad_norm": 0.05641744285821915, "ratio": 0.9997949004173279, "entropy": 0.6587252855300904, "incre_win_rate": 0.9090909090909091, "step": 2293}
{"time": 1767341886.7663941, "phase": "train", "update": 2294, "total_env_steps": 7340800, "episode_reward": 0.26878106594085693, "value_loss": 0.0044685364700853825, "policy_loss": -0.0011090647904005379, "dist_entropy": 0.6467595577239991, "actor_grad_norm": 0.08190222084522247, "critic_grad_norm": 0.03762386366724968, "ratio": 0.9997469782829285, "entropy": 0.6467595577239991, "incre_win_rate": 0.8863636363636364, "step": 2294}
{"time": 1767341890.9411461, "phase": "train", "update": 2295, "total_env_steps": 7344000, "episode_reward": 0.2742477357387543, "value_loss": 0.0063154295086860655, "policy_loss": -0.0012667182265448606, "dist_entropy": 0.6279397010803223, "actor_grad_norm": 0.07922446727752686, "critic_grad_norm": 0.03469626232981682, "ratio": 0.9998241662979126, "entropy": 0.6279397010803223, "incre_win_rate": 0.8888888888888888, "step": 2295}
{"time": 1767341895.0478966, "phase": "train", "update": 2296, "total_env_steps": 7347200, "episode_reward": 0.272935688495636, "value_loss": 0.008678437024354935, "policy_loss": -0.0012354070646786396, "dist_entropy": 0.6038683652877808, "actor_grad_norm": 0.07980120927095413, "critic_grad_norm": 0.05015208199620247, "ratio": 0.9998888373374939, "entropy": 0.6038683652877808, "incre_win_rate": 0.9347826086956522, "step": 2296}
{"time": 1767341899.1518304, "phase": "train", "update": 2297, "total_env_steps": 7350400, "episode_reward": 0.2873220145702362, "value_loss": 0.003456518519669771, "policy_loss": -0.001103642084473222, "dist_entropy": 0.6230437874794006, "actor_grad_norm": 0.07870841771364212, "critic_grad_norm": 0.05154384300112724, "ratio": 1.0002092123031616, "entropy": 0.6230437874794006, "incre_win_rate": 1.0, "step": 2297}
{"time": 1767341903.245062, "phase": "train", "update": 2298, "total_env_steps": 7353600, "episode_reward": 0.2801660895347595, "value_loss": 0.007332423701882362, "policy_loss": -0.001244809496497834, "dist_entropy": 0.620085084438324, "actor_grad_norm": 0.08017122745513916, "critic_grad_norm": 0.05924162268638611, "ratio": 0.9997369647026062, "entropy": 0.620085084438324, "incre_win_rate": 0.8695652173913043, "step": 2298}
{"time": 1767341907.3868637, "phase": "train", "update": 2299, "total_env_steps": 7356800, "episode_reward": 0.2672123312950134, "value_loss": 0.007202222757041454, "policy_loss": -0.0013763083803453925, "dist_entropy": 0.6232402563095093, "actor_grad_norm": 0.07644016295671463, "critic_grad_norm": 0.03566817566752434, "ratio": 1.0000146627426147, "entropy": 0.6232402563095093, "incre_win_rate": 0.8636363636363636, "step": 2299}
{"time": 1767341911.4937053, "phase": "train", "update": 2300, "total_env_steps": 7360000, "episode_reward": 0.265039324760437, "value_loss": 0.008867288380861283, "policy_loss": -0.0015869840796284506, "dist_entropy": 0.6243848204612732, "actor_grad_norm": 0.07545437663793564, "critic_grad_norm": 0.05743161588907242, "ratio": 1.0000636577606201, "entropy": 0.6243848204612732, "incre_win_rate": 0.8604651162790697, "step": 2300}
{"time": 1767341915.6441045, "phase": "train", "update": 2301, "total_env_steps": 7363200, "episode_reward": 0.2801966071128845, "value_loss": 0.004829258006066084, "policy_loss": -0.0012309661876702903, "dist_entropy": 0.6660261392593384, "actor_grad_norm": 0.08235380798578262, "critic_grad_norm": 0.05263398215174675, "ratio": 1.0004245042800903, "entropy": 0.6660261392593384, "incre_win_rate": 0.9565217391304348, "step": 2301}
{"time": 1767341924.7371037, "phase": "eval", "update": 2301, "total_env_steps": 7363200, "eval_win_rate": 1.0, "eval_episode_reward": 20.0, "step": 2301}
{"time": 1767341928.8334212, "phase": "train", "update": 2302, "total_env_steps": 7366400, "episode_reward": 0.27549099922180176, "value_loss": 0.005762208346277475, "policy_loss": -0.0015229094877472482, "dist_entropy": 0.6630243062973022, "actor_grad_norm": 0.08485106378793716, "critic_grad_norm": 0.04176688939332962, "ratio": 0.9997748732566833, "entropy": 0.6630243062973022, "incre_win_rate": 0.9130434782608695, "step": 2302}
{"time": 1767341932.9547987, "phase": "train", "update": 2303, "total_env_steps": 7369600, "episode_reward": 0.26713576912879944, "value_loss": 0.007151660323143005, "policy_loss": -0.001080738567656958, "dist_entropy": 0.6428496718406678, "actor_grad_norm": 0.08301486074924469, "critic_grad_norm": 0.037677910178899765, "ratio": 0.9995128512382507, "entropy": 0.6428496718406678, "incre_win_rate": 0.8809523809523809, "step": 2303}
{"time": 1767341937.0541902, "phase": "train", "update": 2304, "total_env_steps": 7372800, "episode_reward": 0.27297598123550415, "value_loss": 0.00508430041372776, "policy_loss": -0.0009127854433795158, "dist_entropy": 0.6644419670104981, "actor_grad_norm": 0.08168110251426697, "critic_grad_norm": 0.0217499490827322, "ratio": 0.9997114539146423, "entropy": 0.6644419670104981, "incre_win_rate": 0.9090909090909091, "step": 2304}
{"time": 1767341941.1192904, "phase": "train", "update": 2305, "total_env_steps": 7376000, "episode_reward": 0.2726365923881531, "value_loss": 0.00340738445520401, "policy_loss": -0.0012240150421632735, "dist_entropy": 0.6779832363128662, "actor_grad_norm": 0.07749351859092712, "critic_grad_norm": 0.032600484788417816, "ratio": 0.9998741149902344, "entropy": 0.6779832363128662, "incre_win_rate": 0.9574468085106383, "step": 2305}
{"time": 1767341945.238886, "phase": "train", "update": 2306, "total_env_steps": 7379200, "episode_reward": 0.2829594314098358, "value_loss": 0.003846636554226279, "policy_loss": -0.0014339334255488723, "dist_entropy": 0.6737393736839294, "actor_grad_norm": 0.08336540311574936, "critic_grad_norm": 0.04722772166132927, "ratio": 1.0000609159469604, "entropy": 0.6737393736839294, "incre_win_rate": 0.9534883720930233, "step": 2306}
{"time": 1767341949.351303, "phase": "train", "update": 2307, "total_env_steps": 7382400, "episode_reward": 0.27519866824150085, "value_loss": 0.0030741637106984853, "policy_loss": -0.0011348930548763293, "dist_entropy": 0.6529325127601624, "actor_grad_norm": 0.08093144744634628, "critic_grad_norm": 0.020691266283392906, "ratio": 0.9998087286949158, "entropy": 0.6529325127601624, "incre_win_rate": 0.9574468085106383, "step": 2307}
{"time": 1767341953.5161943, "phase": "train", "update": 2308, "total_env_steps": 7385600, "episode_reward": 0.2832947075366974, "value_loss": 0.0024716844316571953, "policy_loss": -0.0013646916351199856, "dist_entropy": 0.6743120193481446, "actor_grad_norm": 0.08224254101514816, "critic_grad_norm": 0.02021806500852108, "ratio": 1.0002224445343018, "entropy": 0.6743120193481446, "incre_win_rate": 0.9772727272727273, "step": 2308}
{"time": 1767341957.637258, "phase": "train", "update": 2309, "total_env_steps": 7388800, "episode_reward": 0.2730960249900818, "value_loss": 0.004282708745449781, "policy_loss": -0.0014550657835428638, "dist_entropy": 0.6687585473060608, "actor_grad_norm": 0.08683348447084427, "critic_grad_norm": 0.046760011464357376, "ratio": 1.000016450881958, "entropy": 0.6687585473060608, "incre_win_rate": 0.9555555555555556, "step": 2309}
{"time": 1767341961.7829916, "phase": "train", "update": 2310, "total_env_steps": 7392000, "episode_reward": 0.2818656861782074, "value_loss": 0.0049670589156448845, "policy_loss": -0.001347278397938112, "dist_entropy": 0.7058823227882385, "actor_grad_norm": 0.07399953901767731, "critic_grad_norm": 0.04039096459746361, "ratio": 0.9999347925186157, "entropy": 0.7058823227882385, "incre_win_rate": 0.9565217391304348, "step": 2310}
{"time": 1767341965.899641, "phase": "train", "update": 2311, "total_env_steps": 7395200, "episode_reward": 0.2747718393802643, "value_loss": 0.0060366191901266575, "policy_loss": -0.0011971232271889675, "dist_entropy": 0.6732935667037964, "actor_grad_norm": 0.08824322372674942, "critic_grad_norm": 0.03637094423174858, "ratio": 1.0000373125076294, "entropy": 0.6732935667037964, "incre_win_rate": 0.8695652173913043, "step": 2311}
{"time": 1767341970.0230262, "phase": "train", "update": 2312, "total_env_steps": 7398400, "episode_reward": 0.2747030258178711, "value_loss": 0.007609155587852001, "policy_loss": -0.0012366994722405877, "dist_entropy": 0.66928151845932, "actor_grad_norm": 0.07105507701635361, "critic_grad_norm": 0.04641750454902649, "ratio": 1.0001715421676636, "entropy": 0.66928151845932, "incre_win_rate": 0.9069767441860465, "step": 2312}
{"time": 1767341974.1272678, "phase": "train", "update": 2313, "total_env_steps": 7401600, "episode_reward": 0.27738410234451294, "value_loss": 0.00407938240095973, "policy_loss": -0.0014015163340694414, "dist_entropy": 0.6852150917053222, "actor_grad_norm": 0.07326503843069077, "critic_grad_norm": 0.03598438575863838, "ratio": 0.9997599720954895, "entropy": 0.6852150917053222, "incre_win_rate": 0.9333333333333333, "step": 2313}
{"time": 1767341978.2831218, "phase": "train", "update": 2314, "total_env_steps": 7404800, "episode_reward": 0.2786139249801636, "value_loss": 0.005989788565784693, "policy_loss": -0.0014135245327310032, "dist_entropy": 0.6924972414970398, "actor_grad_norm": 0.07341518253087997, "critic_grad_norm": 0.024009058251976967, "ratio": 1.000315546989441, "entropy": 0.6924972414970398, "incre_win_rate": 0.9361702127659575, "step": 2314}
{"time": 1767341982.3876033, "phase": "train", "update": 2315, "total_env_steps": 7408000, "episode_reward": 0.2803792357444763, "value_loss": 0.00420514140278101, "policy_loss": -0.0010626128132685154, "dist_entropy": 0.6797300577163696, "actor_grad_norm": 0.0709659680724144, "critic_grad_norm": 0.04667103663086891, "ratio": 1.000038981437683, "entropy": 0.6797300577163696, "incre_win_rate": 0.9761904761904762, "step": 2315}
{"time": 1767341986.5119936, "phase": "train", "update": 2316, "total_env_steps": 7411200, "episode_reward": 0.2747516930103302, "value_loss": 0.0048943738453090194, "policy_loss": -0.001340426535155359, "dist_entropy": 0.6764843106269837, "actor_grad_norm": 0.07413491606712341, "critic_grad_norm": 0.035515278577804565, "ratio": 1.0004624128341675, "entropy": 0.6764843106269837, "incre_win_rate": 0.9148936170212766, "step": 2316}
{"time": 1767341990.587944, "phase": "train", "update": 2317, "total_env_steps": 7414400, "episode_reward": 0.2686201333999634, "value_loss": 0.0070111993700265884, "policy_loss": -0.001591548083978367, "dist_entropy": 0.6817950487136841, "actor_grad_norm": 0.08069662004709244, "critic_grad_norm": 0.0467703640460968, "ratio": 0.9997852444648743, "entropy": 0.6817950487136841, "incre_win_rate": 0.9090909090909091, "step": 2317}
{"time": 1767341994.6932979, "phase": "train", "update": 2318, "total_env_steps": 7417600, "episode_reward": 0.2735234200954437, "value_loss": 0.004778589773923159, "policy_loss": -0.0011408036192378291, "dist_entropy": 0.6930218577384949, "actor_grad_norm": 0.06863730400800705, "critic_grad_norm": 0.041693247854709625, "ratio": 0.9999938011169434, "entropy": 0.6930218577384949, "incre_win_rate": 0.9111111111111111, "step": 2318}
{"time": 1767341998.8332233, "phase": "train", "update": 2319, "total_env_steps": 7420800, "episode_reward": 0.27964144945144653, "value_loss": 0.004456499591469765, "policy_loss": -0.001205196221569338, "dist_entropy": 0.7205200076103211, "actor_grad_norm": 0.07795035094022751, "critic_grad_norm": 0.024620292708277702, "ratio": 1.0002014636993408, "entropy": 0.7205200076103211, "incre_win_rate": 0.9333333333333333, "step": 2319}
{"time": 1767342002.9749088, "phase": "train", "update": 2320, "total_env_steps": 7424000, "episode_reward": 0.27066847681999207, "value_loss": 0.005907906591892243, "policy_loss": -0.0014369158916899493, "dist_entropy": 0.741382110118866, "actor_grad_norm": 0.07670769095420837, "critic_grad_norm": 0.039410293102264404, "ratio": 0.9998946189880371, "entropy": 0.741382110118866, "incre_win_rate": 0.9302325581395349, "step": 2320}
{"time": 1767342007.1015778, "phase": "train", "update": 2321, "total_env_steps": 7427200, "episode_reward": 0.27478066086769104, "value_loss": 0.003704270534217358, "policy_loss": -0.0012711118674801013, "dist_entropy": 0.7227326035499573, "actor_grad_norm": 0.0881638303399086, "critic_grad_norm": 0.03683388978242874, "ratio": 0.9997307062149048, "entropy": 0.7227326035499573, "incre_win_rate": 0.9782608695652174, "step": 2321}
{"time": 1767342011.244715, "phase": "train", "update": 2322, "total_env_steps": 7430400, "episode_reward": 0.2686351537704468, "value_loss": 0.006564507819712162, "policy_loss": -0.0012713391786860484, "dist_entropy": 0.6913835763931274, "actor_grad_norm": 0.07781217247247696, "critic_grad_norm": 0.033122558146715164, "ratio": 1.0000991821289062, "entropy": 0.6913835763931274, "incre_win_rate": 0.9047619047619048, "step": 2322}
{"time": 1767342015.3184075, "phase": "train", "update": 2323, "total_env_steps": 7433600, "episode_reward": 0.27803653478622437, "value_loss": 0.004247555136680603, "policy_loss": -0.0012291682139931482, "dist_entropy": 0.7065057635307312, "actor_grad_norm": 0.08479473739862442, "critic_grad_norm": 0.033743809908628464, "ratio": 0.9997631311416626, "entropy": 0.7065057635307312, "incre_win_rate": 0.9565217391304348, "step": 2323}
{"time": 1767342019.4051945, "phase": "train", "update": 2324, "total_env_steps": 7436800, "episode_reward": 0.2652856111526489, "value_loss": 0.008418954443186522, "policy_loss": -0.0015152817059984613, "dist_entropy": 0.7276121258735657, "actor_grad_norm": 0.09239740669727325, "critic_grad_norm": 0.077428437769413, "ratio": 0.9999409914016724, "entropy": 0.7276121258735657, "incre_win_rate": 0.9069767441860465, "step": 2324}
{"time": 1767342023.4846146, "phase": "train", "update": 2325, "total_env_steps": 7440000, "episode_reward": 0.2650434672832489, "value_loss": 0.007775536179542542, "policy_loss": -0.0011237765425828883, "dist_entropy": 0.6678482174873352, "actor_grad_norm": 0.08504033833742142, "critic_grad_norm": 0.05739566683769226, "ratio": 1.0003159046173096, "entropy": 0.6678482174873352, "incre_win_rate": 0.8888888888888888, "step": 2325}
{"time": 1767342027.6221943, "phase": "train", "update": 2326, "total_env_steps": 7443200, "episode_reward": 0.28072020411491394, "value_loss": 0.004514714702963829, "policy_loss": -0.0014361268233727743, "dist_entropy": 0.7065781712532043, "actor_grad_norm": 0.06978348642587662, "critic_grad_norm": 0.06006009504199028, "ratio": 1.0000414848327637, "entropy": 0.7065781712532043, "incre_win_rate": 0.9565217391304348, "step": 2326}
{"time": 1767342036.7737336, "phase": "eval", "update": 2326, "total_env_steps": 7443200, "eval_win_rate": 1.0, "eval_episode_reward": 20.0, "step": 2326}
{"time": 1767342040.8952305, "phase": "train", "update": 2327, "total_env_steps": 7446400, "episode_reward": 0.27621278166770935, "value_loss": 0.0038319390267133715, "policy_loss": -0.001215422913582742, "dist_entropy": 0.7058541417121887, "actor_grad_norm": 0.07769819349050522, "critic_grad_norm": 0.01931210234761238, "ratio": 0.9999763369560242, "entropy": 0.7058541417121887, "incre_win_rate": 0.9318181818181818, "step": 2327}
{"time": 1767342045.0420372, "phase": "train", "update": 2328, "total_env_steps": 7449600, "episode_reward": 0.2737489640712738, "value_loss": 0.006928063742816448, "policy_loss": -0.0015122754571073927, "dist_entropy": 0.7060348391532898, "actor_grad_norm": 0.07874133437871933, "critic_grad_norm": 0.06801004707813263, "ratio": 0.9999901652336121, "entropy": 0.7060348391532898, "incre_win_rate": 0.9090909090909091, "step": 2328}
{"time": 1767342049.17986, "phase": "train", "update": 2329, "total_env_steps": 7452800, "episode_reward": 0.27750569581985474, "value_loss": 0.0036890502087771893, "policy_loss": -0.0012021678666542357, "dist_entropy": 0.715470290184021, "actor_grad_norm": 0.08683061599731445, "critic_grad_norm": 0.04018416255712509, "ratio": 0.9998842477798462, "entropy": 0.715470290184021, "incre_win_rate": 0.9574468085106383, "step": 2329}
{"time": 1767342053.305579, "phase": "train", "update": 2330, "total_env_steps": 7456000, "episode_reward": 0.2678978741168976, "value_loss": 0.005138600897043944, "policy_loss": -0.0014792731539031933, "dist_entropy": 0.7183439135551453, "actor_grad_norm": 0.08750592917203903, "critic_grad_norm": 0.05035652592778206, "ratio": 0.9999151229858398, "entropy": 0.7183439135551453, "incre_win_rate": 0.9285714285714286, "step": 2330}
{"time": 1767342057.4301562, "phase": "train", "update": 2331, "total_env_steps": 7459200, "episode_reward": 0.2685668468475342, "value_loss": 0.006362608447670936, "policy_loss": -0.0014082563343372101, "dist_entropy": 0.7101163744926453, "actor_grad_norm": 0.0874205231666565, "critic_grad_norm": 0.035444021224975586, "ratio": 1.0002403259277344, "entropy": 0.7101163744926453, "incre_win_rate": 0.8913043478260869, "step": 2331}
{"time": 1767342061.585132, "phase": "train", "update": 2332, "total_env_steps": 7462400, "episode_reward": 0.26409146189689636, "value_loss": 0.013329355232417583, "policy_loss": -0.0013568360362683051, "dist_entropy": 0.6618301510810852, "actor_grad_norm": 0.0871228575706482, "critic_grad_norm": 0.06578084826469421, "ratio": 0.9998054504394531, "entropy": 0.6618301510810852, "incre_win_rate": 0.7954545454545454, "step": 2332}
{"time": 1767342065.6972585, "phase": "train", "update": 2333, "total_env_steps": 7465600, "episode_reward": 0.26184603571891785, "value_loss": 0.008036832883954048, "policy_loss": -0.0018632652203848465, "dist_entropy": 0.6581856727600097, "actor_grad_norm": 0.09914443641901016, "critic_grad_norm": 0.0421169213950634, "ratio": 0.9996042251586914, "entropy": 0.6581856727600097, "incre_win_rate": 0.8222222222222222, "step": 2333}
{"time": 1767342069.8713644, "phase": "train", "update": 2334, "total_env_steps": 7468800, "episode_reward": 0.2665480375289917, "value_loss": 0.010652225278317929, "policy_loss": -0.0008488256647311232, "dist_entropy": 0.6750339150428772, "actor_grad_norm": 0.07840511202812195, "critic_grad_norm": 0.03608987480401993, "ratio": 0.9997617602348328, "entropy": 0.6750339150428772, "incre_win_rate": 0.8888888888888888, "step": 2334}
{"time": 1767342073.9519997, "phase": "train", "update": 2335, "total_env_steps": 7472000, "episode_reward": 0.2629340887069702, "value_loss": 0.009018431790173054, "policy_loss": -0.0019108241473915655, "dist_entropy": 0.6703122735023499, "actor_grad_norm": 0.11032035201787949, "critic_grad_norm": 0.024389585480093956, "ratio": 1.0000903606414795, "entropy": 0.6703122735023499, "incre_win_rate": 0.8095238095238095, "step": 2335}
{"time": 1767342078.0478206, "phase": "train", "update": 2336, "total_env_steps": 7475200, "episode_reward": 0.2649751603603363, "value_loss": 0.01073198951780796, "policy_loss": -0.0019126901393050843, "dist_entropy": 0.6961113929748535, "actor_grad_norm": 0.10057089477777481, "critic_grad_norm": 0.037843044847249985, "ratio": 0.99964439868927, "entropy": 0.6961113929748535, "incre_win_rate": 0.8863636363636364, "step": 2336}
{"time": 1767342082.1531343, "phase": "train", "update": 2337, "total_env_steps": 7478400, "episode_reward": 0.26801741123199463, "value_loss": 0.009770951047539712, "policy_loss": -0.0009736465468193955, "dist_entropy": 0.7019302725791932, "actor_grad_norm": 0.07256937772035599, "critic_grad_norm": 0.031948022544384, "ratio": 0.9998373985290527, "entropy": 0.7019302725791932, "incre_win_rate": 0.8888888888888888, "step": 2337}
{"time": 1767342086.3229156, "phase": "train", "update": 2338, "total_env_steps": 7481600, "episode_reward": 0.27530625462532043, "value_loss": 0.005924574472010136, "policy_loss": -0.0014291331282834108, "dist_entropy": 0.7210589528083802, "actor_grad_norm": 0.09523052722215652, "critic_grad_norm": 0.0570339560508728, "ratio": 0.9998523592948914, "entropy": 0.7210589528083802, "incre_win_rate": 0.9555555555555556, "step": 2338}
{"time": 1767342090.4813387, "phase": "train", "update": 2339, "total_env_steps": 7484800, "episode_reward": 0.2731332778930664, "value_loss": 0.0032433577813208102, "policy_loss": -0.0012688832821605267, "dist_entropy": 0.7372749328613282, "actor_grad_norm": 0.10851825773715973, "critic_grad_norm": 0.03739641234278679, "ratio": 1.000419020652771, "entropy": 0.7372749328613282, "incre_win_rate": 0.9333333333333333, "step": 2339}
{"time": 1767342094.6865075, "phase": "train", "update": 2340, "total_env_steps": 7488000, "episode_reward": 0.26995447278022766, "value_loss": 0.006426446605473757, "policy_loss": -0.001355474611881391, "dist_entropy": 0.7336346507072449, "actor_grad_norm": 0.08612509071826935, "critic_grad_norm": 0.04374029114842415, "ratio": 1.0000258684158325, "entropy": 0.7336346507072449, "incre_win_rate": 0.9090909090909091, "step": 2340}
{"time": 1767342098.813757, "phase": "train", "update": 2341, "total_env_steps": 7491200, "episode_reward": 0.2782284915447235, "value_loss": 0.002914470201358199, "policy_loss": -0.0008187605147263355, "dist_entropy": 0.7341222286224365, "actor_grad_norm": 0.0739227756857872, "critic_grad_norm": 0.033175669610500336, "ratio": 1.0001848936080933, "entropy": 0.7341222286224365, "incre_win_rate": 0.9565217391304348, "step": 2341}
{"time": 1767342102.9347718, "phase": "train", "update": 2342, "total_env_steps": 7494400, "episode_reward": 0.27619001269340515, "value_loss": 0.0035421929322183134, "policy_loss": -0.001274826792658068, "dist_entropy": 0.7329586029052735, "actor_grad_norm": 0.07565046101808548, "critic_grad_norm": 0.02892259694635868, "ratio": 0.9999759793281555, "entropy": 0.7329586029052735, "incre_win_rate": 0.9545454545454546, "step": 2342}
{"time": 1767342107.0299568, "phase": "train", "update": 2343, "total_env_steps": 7497600, "episode_reward": 0.26211920380592346, "value_loss": 0.005020282790064811, "policy_loss": -0.0014010274762096485, "dist_entropy": 0.7175961136817932, "actor_grad_norm": 0.0866653174161911, "critic_grad_norm": 0.037242792546749115, "ratio": 1.0002336502075195, "entropy": 0.7175961136817932, "incre_win_rate": 0.9318181818181818, "step": 2343}
{"time": 1767342111.1917076, "phase": "train", "update": 2344, "total_env_steps": 7500800, "episode_reward": 0.2728021442890167, "value_loss": 0.006380357034504414, "policy_loss": -0.00149122024892705, "dist_entropy": 0.7445417642593384, "actor_grad_norm": 0.09530886262655258, "critic_grad_norm": 0.019457057118415833, "ratio": 1.000051736831665, "entropy": 0.7445417642593384, "incre_win_rate": 0.9285714285714286, "step": 2344}
{"time": 1767342115.323465, "phase": "train", "update": 2345, "total_env_steps": 7504000, "episode_reward": 0.2751283049583435, "value_loss": 0.005663563217967749, "policy_loss": -0.0008442333575660932, "dist_entropy": 0.7192405700683594, "actor_grad_norm": 0.0899263247847557, "critic_grad_norm": 0.027086002752184868, "ratio": 1.0000556707382202, "entropy": 0.7192405700683594, "incre_win_rate": 0.9565217391304348, "step": 2345}
{"time": 1767342119.4912436, "phase": "train", "update": 2346, "total_env_steps": 7507200, "episode_reward": 0.2846895456314087, "value_loss": 0.0023712671361863615, "policy_loss": -0.001748525414123492, "dist_entropy": 0.770977795124054, "actor_grad_norm": 0.12738268077373505, "critic_grad_norm": 0.025565916672348976, "ratio": 0.9993519186973572, "entropy": 0.770977795124054, "incre_win_rate": 0.9777777777777777, "step": 2346}
{"time": 1767342123.6228554, "phase": "train", "update": 2347, "total_env_steps": 7510400, "episode_reward": 0.2686077058315277, "value_loss": 0.003747539734467864, "policy_loss": -0.0009187733499928186, "dist_entropy": 0.7452113509178162, "actor_grad_norm": 0.09872861206531525, "critic_grad_norm": 0.05340535566210747, "ratio": 0.9999033212661743, "entropy": 0.7452113509178162, "incre_win_rate": 0.9130434782608695, "step": 2347}
{"time": 1767342127.7266457, "phase": "train", "update": 2348, "total_env_steps": 7513600, "episode_reward": 0.26768937706947327, "value_loss": 0.006724930554628372, "policy_loss": -0.001249128000718258, "dist_entropy": 0.7429647326469422, "actor_grad_norm": 0.08935069292783737, "critic_grad_norm": 0.05477110296487808, "ratio": 0.9997950792312622, "entropy": 0.7429647326469422, "incre_win_rate": 0.95, "step": 2348}
{"time": 1767342131.8760958, "phase": "train", "update": 2349, "total_env_steps": 7516800, "episode_reward": 0.2713214159011841, "value_loss": 0.003851473471149802, "policy_loss": -0.0011504580769482685, "dist_entropy": 0.7384780883789063, "actor_grad_norm": 0.09194325655698776, "critic_grad_norm": 0.054480958729982376, "ratio": 0.9999216198921204, "entropy": 0.7384780883789063, "incre_win_rate": 0.9787234042553191, "step": 2349}
{"time": 1767342135.9766726, "phase": "train", "update": 2350, "total_env_steps": 7520000, "episode_reward": 0.25599804520606995, "value_loss": 0.007601992972195148, "policy_loss": -0.0008152074918701402, "dist_entropy": 0.7139989495277405, "actor_grad_norm": 0.0829290971159935, "critic_grad_norm": 0.06210196018218994, "ratio": 0.9999992251396179, "entropy": 0.7139989495277405, "incre_win_rate": 0.8095238095238095, "step": 2350}
{"time": 1767342140.137459, "phase": "train", "update": 2351, "total_env_steps": 7523200, "episode_reward": 0.2766607999801636, "value_loss": 0.0035952196922153234, "policy_loss": -0.0013882006851176243, "dist_entropy": 0.7301780700683593, "actor_grad_norm": 0.0813201442360878, "critic_grad_norm": 0.03659822791814804, "ratio": 0.9997715353965759, "entropy": 0.7301780700683593, "incre_win_rate": 0.9772727272727273, "step": 2351}
{"time": 1767342149.502784, "phase": "eval", "update": 2351, "total_env_steps": 7523200, "eval_win_rate": 1.0, "eval_episode_reward": 20.0, "step": 2351}
{"time": 1767342153.5636022, "phase": "train", "update": 2352, "total_env_steps": 7526400, "episode_reward": 0.26063641905784607, "value_loss": 0.005091093853116036, "policy_loss": -0.0012971227267020602, "dist_entropy": 0.7345885396003723, "actor_grad_norm": 0.08008774369955063, "critic_grad_norm": 0.08084813505411148, "ratio": 0.9996358156204224, "entropy": 0.7345885396003723, "incre_win_rate": 0.9512195121951219, "step": 2352}
{"time": 1767342157.6813893, "phase": "train", "update": 2353, "total_env_steps": 7529600, "episode_reward": 0.26633796095848083, "value_loss": 0.0068807931616902355, "policy_loss": -0.001485698651919165, "dist_entropy": 0.7528448224067688, "actor_grad_norm": 0.08938581496477127, "critic_grad_norm": 0.07186197489500046, "ratio": 0.9999319314956665, "entropy": 0.7528448224067688, "incre_win_rate": 0.9148936170212766, "step": 2353}
{"time": 1767342161.7785158, "phase": "train", "update": 2354, "total_env_steps": 7532800, "episode_reward": 0.2657771110534668, "value_loss": 0.005074745416641236, "policy_loss": -0.0008856009742407523, "dist_entropy": 0.7483146548271179, "actor_grad_norm": 0.0659802183508873, "critic_grad_norm": 0.07942424714565277, "ratio": 0.9999797940254211, "entropy": 0.7483146548271179, "incre_win_rate": 1.0, "step": 2354}
{"time": 1767342165.848454, "phase": "train", "update": 2355, "total_env_steps": 7536000, "episode_reward": 0.25575074553489685, "value_loss": 0.004711977485567331, "policy_loss": -0.0017090927541119072, "dist_entropy": 0.7285101413726807, "actor_grad_norm": 0.08999526500701904, "critic_grad_norm": 0.05100575089454651, "ratio": 1.0000100135803223, "entropy": 0.7285101413726807, "incre_win_rate": 0.9285714285714286, "step": 2355}
{"time": 1767342169.9356709, "phase": "train", "update": 2356, "total_env_steps": 7539200, "episode_reward": 0.2659023404121399, "value_loss": 0.0032366318162530662, "policy_loss": -0.001381849760279863, "dist_entropy": 0.7470522284507751, "actor_grad_norm": 0.09727326780557632, "critic_grad_norm": 0.028282610699534416, "ratio": 1.0003340244293213, "entropy": 0.7470522284507751, "incre_win_rate": 0.9545454545454546, "step": 2356}
{"time": 1767342174.0395787, "phase": "train", "update": 2357, "total_env_steps": 7542400, "episode_reward": 0.26911890506744385, "value_loss": 0.0032635563984513283, "policy_loss": -0.0014087498372113317, "dist_entropy": 0.7279962658882141, "actor_grad_norm": 0.07893889397382736, "critic_grad_norm": 0.021090731024742126, "ratio": 0.999898374080658, "entropy": 0.7279962658882141, "incre_win_rate": 0.9302325581395349, "step": 2357}
{"time": 1767342178.1292548, "phase": "train", "update": 2358, "total_env_steps": 7545600, "episode_reward": 0.26264485716819763, "value_loss": 0.006405313592404127, "policy_loss": -0.0013292028704171345, "dist_entropy": 0.7074703216552735, "actor_grad_norm": 0.08366342633962631, "critic_grad_norm": 0.04653225094079971, "ratio": 0.9995291829109192, "entropy": 0.7074703216552735, "incre_win_rate": 0.8837209302325582, "step": 2358}
{"time": 1767342182.244722, "phase": "train", "update": 2359, "total_env_steps": 7548800, "episode_reward": 0.27426326274871826, "value_loss": 0.0042286221869289875, "policy_loss": -0.001289121060460019, "dist_entropy": 0.6881340384483338, "actor_grad_norm": 0.10376908630132675, "critic_grad_norm": 0.06308664381504059, "ratio": 1.0002918243408203, "entropy": 0.6881340384483338, "incre_win_rate": 0.9534883720930233, "step": 2359}
{"time": 1767342186.313699, "phase": "train", "update": 2360, "total_env_steps": 7552000, "episode_reward": 0.2655101716518402, "value_loss": 0.008486261405050755, "policy_loss": -0.0008254206530097008, "dist_entropy": 0.6834059238433838, "actor_grad_norm": 0.09499769657850266, "critic_grad_norm": 0.04685891792178154, "ratio": 0.9997440576553345, "entropy": 0.6834059238433838, "incre_win_rate": 0.8636363636363636, "step": 2360}
{"time": 1767342190.4460442, "phase": "train", "update": 2361, "total_env_steps": 7555200, "episode_reward": 0.275596559047699, "value_loss": 0.0026439268607646228, "policy_loss": -0.001758394490465065, "dist_entropy": 0.6990440607070922, "actor_grad_norm": 0.10941050201654434, "critic_grad_norm": 0.05740892514586449, "ratio": 1.0000900030136108, "entropy": 0.6990440607070922, "incre_win_rate": 0.9347826086956522, "step": 2361}
{"time": 1767342194.5567553, "phase": "train", "update": 2362, "total_env_steps": 7558400, "episode_reward": 0.2775745093822479, "value_loss": 0.0034622962586581705, "policy_loss": -0.0009661134213102774, "dist_entropy": 0.6879511952400208, "actor_grad_norm": 0.0890282690525055, "critic_grad_norm": 0.05049870163202286, "ratio": 0.9997550249099731, "entropy": 0.6879511952400208, "incre_win_rate": 0.9318181818181818, "step": 2362}
{"time": 1767342198.6325684, "phase": "train", "update": 2363, "total_env_steps": 7561600, "episode_reward": 0.27018627524375916, "value_loss": 0.0072931026108562945, "policy_loss": -0.0014602367377581694, "dist_entropy": 0.6639194369316102, "actor_grad_norm": 0.09706088155508041, "critic_grad_norm": 0.0585559606552124, "ratio": 0.9997910857200623, "entropy": 0.6639194369316102, "incre_win_rate": 0.9333333333333333, "step": 2363}
{"time": 1767342202.7381241, "phase": "train", "update": 2364, "total_env_steps": 7564800, "episode_reward": 0.27163803577423096, "value_loss": 0.007424970623105764, "policy_loss": -0.0009303849060586344, "dist_entropy": 0.6771522641181946, "actor_grad_norm": 0.08760423958301544, "critic_grad_norm": 0.026063082739710808, "ratio": 1.0004147291183472, "entropy": 0.6771522641181946, "incre_win_rate": 0.8888888888888888, "step": 2364}
{"time": 1767342206.8226087, "phase": "train", "update": 2365, "total_env_steps": 7568000, "episode_reward": 0.27476823329925537, "value_loss": 0.004971126839518547, "policy_loss": -0.001293741095174994, "dist_entropy": 0.6923313617706299, "actor_grad_norm": 0.09506359696388245, "critic_grad_norm": 0.04516715928912163, "ratio": 0.9998918771743774, "entropy": 0.6923313617706299, "incre_win_rate": 0.9302325581395349, "step": 2365}
{"time": 1767342210.9067612, "phase": "train", "update": 2366, "total_env_steps": 7571200, "episode_reward": 0.275298535823822, "value_loss": 0.005115334503352642, "policy_loss": -0.0013268245387493493, "dist_entropy": 0.6587477922439575, "actor_grad_norm": 0.09113138169050217, "critic_grad_norm": 0.028771182522177696, "ratio": 0.9999135136604309, "entropy": 0.6587477922439575, "incre_win_rate": 0.9565217391304348, "step": 2366}
{"time": 1767342215.0059395, "phase": "train", "update": 2367, "total_env_steps": 7574400, "episode_reward": 0.2775144875049591, "value_loss": 0.0032337257172912358, "policy_loss": -0.001432477625630213, "dist_entropy": 0.6874670863151551, "actor_grad_norm": 0.09622584283351898, "critic_grad_norm": 0.01357510406523943, "ratio": 0.9996291995048523, "entropy": 0.6874670863151551, "incre_win_rate": 0.9777777777777777, "step": 2367}
{"time": 1767342219.1280355, "phase": "train", "update": 2368, "total_env_steps": 7577600, "episode_reward": 0.269911527633667, "value_loss": 0.003836985258385539, "policy_loss": -0.00114465213806767, "dist_entropy": 0.6757482409477233, "actor_grad_norm": 0.07350162416696548, "critic_grad_norm": 0.018323874101042747, "ratio": 1.0001211166381836, "entropy": 0.6757482409477233, "incre_win_rate": 0.9302325581395349, "step": 2368}
{"time": 1767342223.242503, "phase": "train", "update": 2369, "total_env_steps": 7580800, "episode_reward": 0.275519460439682, "value_loss": 0.0036149820312857627, "policy_loss": -0.0011953139611591724, "dist_entropy": 0.6711674451828002, "actor_grad_norm": 0.06921543180942535, "critic_grad_norm": 0.015073396265506744, "ratio": 0.9998055696487427, "entropy": 0.6711674451828002, "incre_win_rate": 0.9555555555555556, "step": 2369}
{"time": 1767342227.3245215, "phase": "train", "update": 2370, "total_env_steps": 7584000, "episode_reward": 0.2696109414100647, "value_loss": 0.00648674126714468, "policy_loss": -0.001267691731513132, "dist_entropy": 0.65012127161026, "actor_grad_norm": 0.07272517681121826, "critic_grad_norm": 0.01682768203318119, "ratio": 1.000223994255066, "entropy": 0.65012127161026, "incre_win_rate": 0.8636363636363636, "step": 2370}
{"time": 1767342231.4015977, "phase": "train", "update": 2371, "total_env_steps": 7587200, "episode_reward": 0.26981377601623535, "value_loss": 0.006001770123839378, "policy_loss": -0.001544643460484485, "dist_entropy": 0.6354509592056274, "actor_grad_norm": 0.085954450070858, "critic_grad_norm": 0.017571119591593742, "ratio": 1.0000284910202026, "entropy": 0.6354509592056274, "incre_win_rate": 0.9130434782608695, "step": 2371}
{"time": 1767342235.4461477, "phase": "train", "update": 2372, "total_env_steps": 7590400, "episode_reward": 0.2822268307209015, "value_loss": 0.0052141471765935424, "policy_loss": -0.0013058299674469254, "dist_entropy": 0.617921781539917, "actor_grad_norm": 0.08510183542966843, "critic_grad_norm": 0.02325592003762722, "ratio": 1.000009536743164, "entropy": 0.617921781539917, "incre_win_rate": 0.9318181818181818, "step": 2372}
{"time": 1767342239.5600212, "phase": "train", "update": 2373, "total_env_steps": 7593600, "episode_reward": 0.2751365900039673, "value_loss": 0.005681352410465479, "policy_loss": -0.0015980579589360388, "dist_entropy": 0.6305240392684937, "actor_grad_norm": 0.08249248564243317, "critic_grad_norm": 0.05316983535885811, "ratio": 0.9996859431266785, "entropy": 0.6305240392684937, "incre_win_rate": 0.9333333333333333, "step": 2373}
{"time": 1767342243.6575093, "phase": "train", "update": 2374, "total_env_steps": 7596800, "episode_reward": 0.2764818072319031, "value_loss": 0.005660759471356869, "policy_loss": -0.001252395699425124, "dist_entropy": 0.6261274933815002, "actor_grad_norm": 0.0729810819029808, "critic_grad_norm": 0.03616786003112793, "ratio": 0.9996587634086609, "entropy": 0.6261274933815002, "incre_win_rate": 0.9534883720930233, "step": 2374}
{"time": 1767342247.7237906, "phase": "train", "update": 2375, "total_env_steps": 7600000, "episode_reward": 0.26870033144950867, "value_loss": 0.004445620626211166, "policy_loss": -0.001286872265680472, "dist_entropy": 0.6120672106742859, "actor_grad_norm": 0.08868681639432907, "critic_grad_norm": 0.04841234162449837, "ratio": 0.9997984170913696, "entropy": 0.6120672106742859, "incre_win_rate": 0.9130434782608695, "step": 2375}
{"time": 1767342251.8856475, "phase": "train", "update": 2376, "total_env_steps": 7603200, "episode_reward": 0.2799161970615387, "value_loss": 0.0033568228129297493, "policy_loss": -0.001213492976245334, "dist_entropy": 0.6478099942207336, "actor_grad_norm": 0.0935102254152298, "critic_grad_norm": 0.033380549401044846, "ratio": 1.0000269412994385, "entropy": 0.6478099942207336, "incre_win_rate": 0.9777777777777777, "step": 2376}
{"time": 1767342261.6922176, "phase": "eval", "update": 2376, "total_env_steps": 7603200, "eval_win_rate": 0.875, "eval_episode_reward": 19.5104511589404, "step": 2376}
{"time": 1767342265.8296094, "phase": "train", "update": 2377, "total_env_steps": 7606400, "episode_reward": 0.2857491672039032, "value_loss": 0.0028288929723203184, "policy_loss": -0.0006893930637343004, "dist_entropy": 0.6460828661918641, "actor_grad_norm": 0.07424191385507584, "critic_grad_norm": 0.01810615323483944, "ratio": 1.0001083612442017, "entropy": 0.6460828661918641, "incre_win_rate": 0.9555555555555556, "step": 2377}
{"time": 1767342269.9248657, "phase": "train", "update": 2378, "total_env_steps": 7609600, "episode_reward": 0.2685394287109375, "value_loss": 0.003165794676169753, "policy_loss": -0.0013916767035500044, "dist_entropy": 0.6468031764030456, "actor_grad_norm": 0.08253585547208786, "critic_grad_norm": 0.03858509659767151, "ratio": 0.9999972581863403, "entropy": 0.6468031764030456, "incre_win_rate": 0.9302325581395349, "step": 2378}
{"time": 1767342274.0579932, "phase": "train", "update": 2379, "total_env_steps": 7612800, "episode_reward": 0.28533217310905457, "value_loss": 0.00295747509226203, "policy_loss": -0.0012597493024458118, "dist_entropy": 0.6632735252380371, "actor_grad_norm": 0.08447613567113876, "critic_grad_norm": 0.030798593536019325, "ratio": 0.9995421767234802, "entropy": 0.6632735252380371, "incre_win_rate": 1.0, "step": 2379}
{"time": 1767342278.187257, "phase": "train", "update": 2380, "total_env_steps": 7616000, "episode_reward": 0.280094176530838, "value_loss": 0.003719012252986431, "policy_loss": -0.0010643155294062013, "dist_entropy": 0.6335312724113464, "actor_grad_norm": 0.07272183895111084, "critic_grad_norm": 0.05449739098548889, "ratio": 0.9998041987419128, "entropy": 0.6335312724113464, "incre_win_rate": 0.9777777777777777, "step": 2380}
{"time": 1767342282.3053017, "phase": "train", "update": 2381, "total_env_steps": 7619200, "episode_reward": 0.28578850626945496, "value_loss": 0.0026770846918225287, "policy_loss": -0.0010801451241157166, "dist_entropy": 0.6492411971092225, "actor_grad_norm": 0.09223505854606628, "critic_grad_norm": 0.03573344275355339, "ratio": 0.9999668002128601, "entropy": 0.6492411971092225, "incre_win_rate": 0.9787234042553191, "step": 2381}
{"time": 1767342286.4341116, "phase": "train", "update": 2382, "total_env_steps": 7622400, "episode_reward": 0.27751603722572327, "value_loss": 0.0044255457818508145, "policy_loss": -0.0014415726892480051, "dist_entropy": 0.6569682359695435, "actor_grad_norm": 0.07933870702981949, "critic_grad_norm": 0.05298004299402237, "ratio": 0.9997637867927551, "entropy": 0.6569682359695435, "incre_win_rate": 0.9318181818181818, "step": 2382}
{"time": 1767342290.5633516, "phase": "train", "update": 2383, "total_env_steps": 7625600, "episode_reward": 0.2860140800476074, "value_loss": 0.0019445110578089953, "policy_loss": -0.0013682683651097705, "dist_entropy": 0.6764963746070862, "actor_grad_norm": 0.07455798238515854, "critic_grad_norm": 0.037870850414037704, "ratio": 0.999786376953125, "entropy": 0.6764963746070862, "incre_win_rate": 0.9777777777777777, "step": 2383}
{"time": 1767342294.6829007, "phase": "train", "update": 2384, "total_env_steps": 7628800, "episode_reward": 0.274259090423584, "value_loss": 0.004104736540466547, "policy_loss": -0.0015324949347537142, "dist_entropy": 0.6597668051719665, "actor_grad_norm": 0.0896143764257431, "critic_grad_norm": 0.032549526542425156, "ratio": 1.00006103515625, "entropy": 0.6597668051719665, "incre_win_rate": 0.9772727272727273, "step": 2384}
{"time": 1767342298.8255951, "phase": "train", "update": 2385, "total_env_steps": 7632000, "episode_reward": 0.2793563902378082, "value_loss": 0.003019195143133402, "policy_loss": -0.0011351301529273882, "dist_entropy": 0.6498654246330261, "actor_grad_norm": 0.06940659135580063, "critic_grad_norm": 0.055571962147951126, "ratio": 0.9995713233947754, "entropy": 0.6498654246330261, "incre_win_rate": 0.9574468085106383, "step": 2385}
{"time": 1767342302.9542396, "phase": "train", "update": 2386, "total_env_steps": 7635200, "episode_reward": 0.2799089550971985, "value_loss": 0.006060382165014744, "policy_loss": -0.0013939702509654594, "dist_entropy": 0.6933974385261535, "actor_grad_norm": 0.08502912521362305, "critic_grad_norm": 0.04345278814435005, "ratio": 1.0001238584518433, "entropy": 0.6933974385261535, "incre_win_rate": 0.9148936170212766, "step": 2386}
{"time": 1767342307.053435, "phase": "train", "update": 2387, "total_env_steps": 7638400, "episode_reward": 0.2758267819881439, "value_loss": 0.0064290489070117475, "policy_loss": -0.0010723339941030475, "dist_entropy": 0.6741057991981506, "actor_grad_norm": 0.08145982027053833, "critic_grad_norm": 0.028198281303048134, "ratio": 1.0001204013824463, "entropy": 0.6741057991981506, "incre_win_rate": 0.9318181818181818, "step": 2387}
{"time": 1767342311.210184, "phase": "train", "update": 2388, "total_env_steps": 7641600, "episode_reward": 0.27629968523979187, "value_loss": 0.006442527286708355, "policy_loss": -0.0011736381565143005, "dist_entropy": 0.6487722754478454, "actor_grad_norm": 0.07821287959814072, "critic_grad_norm": 0.08143385499715805, "ratio": 1.0001964569091797, "entropy": 0.6487722754478454, "incre_win_rate": 0.9318181818181818, "step": 2388}
{"time": 1767342315.3240187, "phase": "train", "update": 2389, "total_env_steps": 7644800, "episode_reward": 0.2789859175682068, "value_loss": 0.0028595179319381714, "policy_loss": -0.0013661853050948025, "dist_entropy": 0.674595308303833, "actor_grad_norm": 0.08806472271680832, "critic_grad_norm": 0.04963807016611099, "ratio": 1.0000345706939697, "entropy": 0.674595308303833, "incre_win_rate": 0.9782608695652174, "step": 2389}
{"time": 1767342319.4530325, "phase": "train", "update": 2390, "total_env_steps": 7648000, "episode_reward": 0.2750362455844879, "value_loss": 0.00293101305142045, "policy_loss": -0.0012040984173026458, "dist_entropy": 0.6597790241241455, "actor_grad_norm": 0.0950012058019638, "critic_grad_norm": 0.04228196665644646, "ratio": 1.000278353691101, "entropy": 0.6597790241241455, "incre_win_rate": 0.9767441860465116, "step": 2390}
{"time": 1767342323.5767255, "phase": "train", "update": 2391, "total_env_steps": 7651200, "episode_reward": 0.28706541657447815, "value_loss": 0.0031165884342044593, "policy_loss": -0.001542824159874101, "dist_entropy": 0.6354616284370422, "actor_grad_norm": 0.10139068216085434, "critic_grad_norm": 0.052507251501083374, "ratio": 1.000566840171814, "entropy": 0.6354616284370422, "incre_win_rate": 0.9782608695652174, "step": 2391}
{"time": 1767342327.6894233, "phase": "train", "update": 2392, "total_env_steps": 7654400, "episode_reward": 0.2806493043899536, "value_loss": 0.0034122098237276076, "policy_loss": -0.0011398695742503406, "dist_entropy": 0.6405866026878357, "actor_grad_norm": 0.09023666381835938, "critic_grad_norm": 0.03183937445282936, "ratio": 1.0001775026321411, "entropy": 0.6405866026878357, "incre_win_rate": 0.9782608695652174, "step": 2392}
{"time": 1767342331.817295, "phase": "train", "update": 2393, "total_env_steps": 7657600, "episode_reward": 0.28590646386146545, "value_loss": 0.0026810470037162302, "policy_loss": -0.0009007551444298656, "dist_entropy": 0.6374392151832581, "actor_grad_norm": 0.08297181129455566, "critic_grad_norm": 0.01844305917620659, "ratio": 1.000179648399353, "entropy": 0.6374392151832581, "incre_win_rate": 0.9555555555555556, "step": 2393}
{"time": 1767342335.9455109, "phase": "train", "update": 2394, "total_env_steps": 7660800, "episode_reward": 0.2761361598968506, "value_loss": 0.004361404106020927, "policy_loss": -0.0012332017174763621, "dist_entropy": 0.6481504082679749, "actor_grad_norm": 0.08535920083522797, "critic_grad_norm": 0.05503183603286743, "ratio": 0.9999909400939941, "entropy": 0.6481504082679749, "incre_win_rate": 0.9111111111111111, "step": 2394}
{"time": 1767342340.063737, "phase": "train", "update": 2395, "total_env_steps": 7664000, "episode_reward": 0.28151488304138184, "value_loss": 0.0048038468696177, "policy_loss": -0.0012521535623818635, "dist_entropy": 0.6257958889007569, "actor_grad_norm": 0.08948012441396713, "critic_grad_norm": 0.03847170248627663, "ratio": 0.9997461438179016, "entropy": 0.6257958889007569, "incre_win_rate": 0.9777777777777777, "step": 2395}
{"time": 1767342344.165192, "phase": "train", "update": 2396, "total_env_steps": 7667200, "episode_reward": 0.2654009759426117, "value_loss": 0.004565560724586248, "policy_loss": -0.0012875041685077803, "dist_entropy": 0.6160597920417785, "actor_grad_norm": 0.0988885685801506, "critic_grad_norm": 0.01974213495850563, "ratio": 1.0004466772079468, "entropy": 0.6160597920417785, "incre_win_rate": 0.8666666666666667, "step": 2396}
{"time": 1767342348.252705, "phase": "train", "update": 2397, "total_env_steps": 7670400, "episode_reward": 0.269432932138443, "value_loss": 0.005040926765650511, "policy_loss": -0.0010539887059934471, "dist_entropy": 0.6704562187194825, "actor_grad_norm": 0.0874749943614006, "critic_grad_norm": 0.03092014230787754, "ratio": 0.9995828866958618, "entropy": 0.6704562187194825, "incre_win_rate": 0.9534883720930233, "step": 2397}
{"time": 1767342352.3657727, "phase": "train", "update": 2398, "total_env_steps": 7673600, "episode_reward": 0.2739429771900177, "value_loss": 0.00441302852705121, "policy_loss": -0.0012772051237655902, "dist_entropy": 0.6439296722412109, "actor_grad_norm": 0.08236243575811386, "critic_grad_norm": 0.026517555117607117, "ratio": 0.9998345375061035, "entropy": 0.6439296722412109, "incre_win_rate": 0.9545454545454546, "step": 2398}
{"time": 1767342356.4840477, "phase": "train", "update": 2399, "total_env_steps": 7676800, "episode_reward": 0.2692389190196991, "value_loss": 0.004683521576225758, "policy_loss": -0.0011110943426487553, "dist_entropy": 0.6556063771247864, "actor_grad_norm": 0.07521648705005646, "critic_grad_norm": 0.038153812289237976, "ratio": 1.0001407861709595, "entropy": 0.6556063771247864, "incre_win_rate": 0.8888888888888888, "step": 2399}
{"time": 1767342360.5985706, "phase": "train", "update": 2400, "total_env_steps": 7680000, "episode_reward": 0.27922186255455017, "value_loss": 0.0038108167238533495, "policy_loss": -0.0012240648543999423, "dist_entropy": 0.6580114841461182, "actor_grad_norm": 0.08386959880590439, "critic_grad_norm": 0.04111438989639282, "ratio": 1.0001343488693237, "entropy": 0.6580114841461182, "incre_win_rate": 0.9782608695652174, "step": 2400}
{"time": 1767342364.6935709, "phase": "train", "update": 2401, "total_env_steps": 7683200, "episode_reward": 0.27249637246131897, "value_loss": 0.004647759161889553, "policy_loss": -0.0011083881665776118, "dist_entropy": 0.6550506949424744, "actor_grad_norm": 0.09518560022115707, "critic_grad_norm": 0.03688475489616394, "ratio": 1.0000954866409302, "entropy": 0.6550506949424744, "incre_win_rate": 0.8888888888888888, "step": 2401}
{"time": 1767342374.1406174, "phase": "eval", "update": 2401, "total_env_steps": 7683200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.651438327814567, "step": 2401}
{"time": 1767342378.27525, "phase": "train", "update": 2402, "total_env_steps": 7686400, "episode_reward": 0.28225165605545044, "value_loss": 0.003668956970795989, "policy_loss": -0.0013236146756511857, "dist_entropy": 0.6473089694976807, "actor_grad_norm": 0.10289766639471054, "critic_grad_norm": 0.040032435208559036, "ratio": 1.000475287437439, "entropy": 0.6473089694976807, "incre_win_rate": 0.9318181818181818, "step": 2402}
{"time": 1767342382.3816233, "phase": "train", "update": 2403, "total_env_steps": 7689600, "episode_reward": 0.2802571654319763, "value_loss": 0.004002746008336544, "policy_loss": -0.0008825973409685162, "dist_entropy": 0.6633450388908386, "actor_grad_norm": 0.08755938708782196, "critic_grad_norm": 0.03310316801071167, "ratio": 1.00020432472229, "entropy": 0.6633450388908386, "incre_win_rate": 0.9555555555555556, "step": 2403}
{"time": 1767342386.4784946, "phase": "train", "update": 2404, "total_env_steps": 7692800, "episode_reward": 0.2736956775188446, "value_loss": 0.006897404510527849, "policy_loss": -0.0010483094749524468, "dist_entropy": 0.6360789179801941, "actor_grad_norm": 0.08536534756422043, "critic_grad_norm": 0.04835658147931099, "ratio": 1.0001393556594849, "entropy": 0.6360789179801941, "incre_win_rate": 0.8936170212765957, "step": 2404}
{"time": 1767342390.5435007, "phase": "train", "update": 2405, "total_env_steps": 7696000, "episode_reward": 0.26999691128730774, "value_loss": 0.0058103824965655805, "policy_loss": -0.0014818794248753874, "dist_entropy": 0.6221166968345642, "actor_grad_norm": 0.08838265389204025, "critic_grad_norm": 0.03814534470438957, "ratio": 0.9997319579124451, "entropy": 0.6221166968345642, "incre_win_rate": 0.8837209302325582, "step": 2405}
{"time": 1767342394.6769178, "phase": "train", "update": 2406, "total_env_steps": 7699200, "episode_reward": 0.2664678394794464, "value_loss": 0.008883335255086422, "policy_loss": -0.001416557244242256, "dist_entropy": 0.6231227874755859, "actor_grad_norm": 0.08697477728128433, "critic_grad_norm": 0.043697960674762726, "ratio": 0.9998515248298645, "entropy": 0.6231227874755859, "incre_win_rate": 0.8, "step": 2406}
{"time": 1767342398.7672067, "phase": "train", "update": 2407, "total_env_steps": 7702400, "episode_reward": 0.27408528327941895, "value_loss": 0.008524230495095254, "policy_loss": -0.0015798522945232208, "dist_entropy": 0.6457488059997558, "actor_grad_norm": 0.0839451476931572, "critic_grad_norm": 0.08693373203277588, "ratio": 1.0002362728118896, "entropy": 0.6457488059997558, "incre_win_rate": 0.8913043478260869, "step": 2407}
{"time": 1767342402.9217715, "phase": "train", "update": 2408, "total_env_steps": 7705600, "episode_reward": 0.2834312915802002, "value_loss": 0.0059475481510162355, "policy_loss": -0.0012121756047747568, "dist_entropy": 0.6298234462738037, "actor_grad_norm": 0.09633873403072357, "critic_grad_norm": 0.07493435591459274, "ratio": 1.0000602006912231, "entropy": 0.6298234462738037, "incre_win_rate": 0.9333333333333333, "step": 2408}
{"time": 1767342407.034613, "phase": "train", "update": 2409, "total_env_steps": 7708800, "episode_reward": 0.27854201197624207, "value_loss": 0.004154311865568161, "policy_loss": -0.0013150890230541278, "dist_entropy": 0.6684167504310607, "actor_grad_norm": 0.09770690649747849, "critic_grad_norm": 0.06431169807910919, "ratio": 0.9996986389160156, "entropy": 0.6684167504310607, "incre_win_rate": 0.9565217391304348, "step": 2409}
{"time": 1767342411.1301844, "phase": "train", "update": 2410, "total_env_steps": 7712000, "episode_reward": 0.27105912566185, "value_loss": 0.006764924246817827, "policy_loss": -0.0010189432849823988, "dist_entropy": 0.6560168981552124, "actor_grad_norm": 0.07597578316926956, "critic_grad_norm": 0.03744581341743469, "ratio": 1.0001269578933716, "entropy": 0.6560168981552124, "incre_win_rate": 0.9318181818181818, "step": 2410}
{"time": 1767342415.2071166, "phase": "train", "update": 2411, "total_env_steps": 7715200, "episode_reward": 0.2811175584793091, "value_loss": 0.0030086022801697255, "policy_loss": -0.0010903572352937373, "dist_entropy": 0.6750640392303466, "actor_grad_norm": 0.07557349652051926, "critic_grad_norm": 0.09813829511404037, "ratio": 1.0000083446502686, "entropy": 0.6750640392303466, "incre_win_rate": 1.0, "step": 2411}
{"time": 1767342419.291723, "phase": "train", "update": 2412, "total_env_steps": 7718400, "episode_reward": 0.27511176466941833, "value_loss": 0.004705158062279224, "policy_loss": -0.0009222937600847026, "dist_entropy": 0.6581836581230164, "actor_grad_norm": 0.07681947201490402, "critic_grad_norm": 0.05087980255484581, "ratio": 1.000022053718567, "entropy": 0.6581836581230164, "incre_win_rate": 0.9565217391304348, "step": 2412}
{"time": 1767342423.419608, "phase": "train", "update": 2413, "total_env_steps": 7721600, "episode_reward": 0.27630332112312317, "value_loss": 0.003511037398129702, "policy_loss": -0.001114365724066957, "dist_entropy": 0.666133189201355, "actor_grad_norm": 0.08787084370851517, "critic_grad_norm": 0.04268272593617439, "ratio": 1.000282883644104, "entropy": 0.666133189201355, "incre_win_rate": 0.9302325581395349, "step": 2413}
{"time": 1767342427.508853, "phase": "train", "update": 2414, "total_env_steps": 7724800, "episode_reward": 0.2754925489425659, "value_loss": 0.0030943617690354585, "policy_loss": -0.001057650114555031, "dist_entropy": 0.6372704148292542, "actor_grad_norm": 0.0813412070274353, "critic_grad_norm": 0.060256458818912506, "ratio": 0.9999169707298279, "entropy": 0.6372704148292542, "incre_win_rate": 0.9555555555555556, "step": 2414}
{"time": 1767342431.6609237, "phase": "train", "update": 2415, "total_env_steps": 7728000, "episode_reward": 0.2748515009880066, "value_loss": 0.008138635847717523, "policy_loss": -0.0013841591154115207, "dist_entropy": 0.6676902651786805, "actor_grad_norm": 0.08650851994752884, "critic_grad_norm": 0.08053689450025558, "ratio": 0.9992746710777283, "entropy": 0.6676902651786805, "incre_win_rate": 0.8913043478260869, "step": 2415}
{"time": 1767342435.7106857, "phase": "train", "update": 2416, "total_env_steps": 7731200, "episode_reward": 0.2746109366416931, "value_loss": 0.007805605698376894, "policy_loss": -0.0012231367246329228, "dist_entropy": 0.644187843799591, "actor_grad_norm": 0.08503019064664841, "critic_grad_norm": 0.05295363813638687, "ratio": 1.0004780292510986, "entropy": 0.644187843799591, "incre_win_rate": 0.9302325581395349, "step": 2416}
{"time": 1767342439.819259, "phase": "train", "update": 2417, "total_env_steps": 7734400, "episode_reward": 0.27896109223365784, "value_loss": 0.005456311814486981, "policy_loss": -0.001021650453675349, "dist_entropy": 0.6766220927238464, "actor_grad_norm": 0.08558893203735352, "critic_grad_norm": 0.07535605877637863, "ratio": 0.9995993971824646, "entropy": 0.6766220927238464, "incre_win_rate": 0.9148936170212766, "step": 2417}
{"time": 1767342443.9081743, "phase": "train", "update": 2418, "total_env_steps": 7737600, "episode_reward": 0.2770695388317108, "value_loss": 0.004153866786509752, "policy_loss": -0.001100764511355834, "dist_entropy": 0.6872522354125976, "actor_grad_norm": 0.07665085792541504, "critic_grad_norm": 0.03037749044597149, "ratio": 1.0002245903015137, "entropy": 0.6872522354125976, "incre_win_rate": 0.9318181818181818, "step": 2418}
{"time": 1767342447.9967525, "phase": "train", "update": 2419, "total_env_steps": 7740800, "episode_reward": 0.26744207739830017, "value_loss": 0.0038678236305713654, "policy_loss": -0.001154692926375489, "dist_entropy": 0.6833742141723633, "actor_grad_norm": 0.09054937213659286, "critic_grad_norm": 0.05216683819890022, "ratio": 0.9996671676635742, "entropy": 0.6833742141723633, "incre_win_rate": 0.9555555555555556, "step": 2419}
{"time": 1767342452.1260018, "phase": "train", "update": 2420, "total_env_steps": 7744000, "episode_reward": 0.27746689319610596, "value_loss": 0.004317037016153336, "policy_loss": -0.0010199109810940855, "dist_entropy": 0.6949069142341614, "actor_grad_norm": 0.077120840549469, "critic_grad_norm": 0.0490635521709919, "ratio": 0.99998539686203, "entropy": 0.6949069142341614, "incre_win_rate": 0.9534883720930233, "step": 2420}
{"time": 1767342456.246792, "phase": "train", "update": 2421, "total_env_steps": 7747200, "episode_reward": 0.27690449357032776, "value_loss": 0.006430422514677047, "policy_loss": -0.0012631942676122776, "dist_entropy": 0.6701642990112304, "actor_grad_norm": 0.08330749720335007, "critic_grad_norm": 0.055710773915052414, "ratio": 1.0003204345703125, "entropy": 0.6701642990112304, "incre_win_rate": 0.9111111111111111, "step": 2421}
{"time": 1767342460.3631532, "phase": "train", "update": 2422, "total_env_steps": 7750400, "episode_reward": 0.2736423909664154, "value_loss": 0.006481899414211512, "policy_loss": -0.0011263068697161317, "dist_entropy": 0.6730688333511352, "actor_grad_norm": 0.08420903980731964, "critic_grad_norm": 0.060659099370241165, "ratio": 0.9996193051338196, "entropy": 0.6730688333511352, "incre_win_rate": 0.9347826086956522, "step": 2422}
{"time": 1767342464.4725125, "phase": "train", "update": 2423, "total_env_steps": 7753600, "episode_reward": 0.27343541383743286, "value_loss": 0.0032432747539132833, "policy_loss": -0.0017420432132553287, "dist_entropy": 0.6708363175392151, "actor_grad_norm": 0.10427959263324738, "critic_grad_norm": 0.042477209120988846, "ratio": 0.9998583197593689, "entropy": 0.6708363175392151, "incre_win_rate": 0.9545454545454546, "step": 2423}
{"time": 1767342468.558597, "phase": "train", "update": 2424, "total_env_steps": 7756800, "episode_reward": 0.27570781111717224, "value_loss": 0.004887774307280779, "policy_loss": -0.001308344816406759, "dist_entropy": 0.6683300137519836, "actor_grad_norm": 0.10056177526712418, "critic_grad_norm": 0.04587888345122337, "ratio": 0.999821662902832, "entropy": 0.6683300137519836, "incre_win_rate": 0.9545454545454546, "step": 2424}
{"time": 1767342472.6694686, "phase": "train", "update": 2425, "total_env_steps": 7760000, "episode_reward": 0.2731788158416748, "value_loss": 0.005254781898111105, "policy_loss": -0.0014660191735544003, "dist_entropy": 0.6756734132766724, "actor_grad_norm": 0.09184522926807404, "critic_grad_norm": 0.07308745384216309, "ratio": 1.0004757642745972, "entropy": 0.6756734132766724, "incre_win_rate": 0.9361702127659575, "step": 2425}
{"time": 1767342476.7548273, "phase": "train", "update": 2426, "total_env_steps": 7763200, "episode_reward": 0.28474751114845276, "value_loss": 0.0032863262109458446, "policy_loss": -0.001687250407623253, "dist_entropy": 0.6509175896644592, "actor_grad_norm": 0.08124807476997375, "critic_grad_norm": 0.037201832979917526, "ratio": 0.9997466206550598, "entropy": 0.6509175896644592, "incre_win_rate": 1.0, "step": 2426}
{"time": 1767342485.9816587, "phase": "eval", "update": 2426, "total_env_steps": 7763200, "eval_win_rate": 1.0, "eval_episode_reward": 20.0, "step": 2426}
{"time": 1767342490.0998805, "phase": "train", "update": 2427, "total_env_steps": 7766400, "episode_reward": 0.27061671018600464, "value_loss": 0.00901111178100109, "policy_loss": -0.0015521542523789123, "dist_entropy": 0.6484747529029846, "actor_grad_norm": 0.0888906717300415, "critic_grad_norm": 0.03343486413359642, "ratio": 0.9998082518577576, "entropy": 0.6484747529029846, "incre_win_rate": 0.8863636363636364, "step": 2427}
{"time": 1767342494.277872, "phase": "train", "update": 2428, "total_env_steps": 7769600, "episode_reward": 0.2756234407424927, "value_loss": 0.006709072180092335, "policy_loss": -0.0010634700772712336, "dist_entropy": 0.6522018551826477, "actor_grad_norm": 0.10326017439365387, "critic_grad_norm": 0.05916750431060791, "ratio": 0.9999797940254211, "entropy": 0.6522018551826477, "incre_win_rate": 0.9148936170212766, "step": 2428}
{"time": 1767342498.3867595, "phase": "train", "update": 2429, "total_env_steps": 7772800, "episode_reward": 0.27983495593070984, "value_loss": 0.003456716565415263, "policy_loss": -0.0012648868902814137, "dist_entropy": 0.6431579113006591, "actor_grad_norm": 0.0809863731265068, "critic_grad_norm": 0.043825939297676086, "ratio": 0.9999182820320129, "entropy": 0.6431579113006591, "incre_win_rate": 0.9555555555555556, "step": 2429}
{"time": 1767342502.49737, "phase": "train", "update": 2430, "total_env_steps": 7776000, "episode_reward": 0.28391554951667786, "value_loss": 0.002659897133708, "policy_loss": -0.0011426753026796631, "dist_entropy": 0.6724172472953797, "actor_grad_norm": 0.0822267159819603, "critic_grad_norm": 0.03154926374554634, "ratio": 0.9999298453330994, "entropy": 0.6724172472953797, "incre_win_rate": 1.0, "step": 2430}
{"time": 1767342506.5989246, "phase": "train", "update": 2431, "total_env_steps": 7779200, "episode_reward": 0.2750776410102844, "value_loss": 0.00403463626280427, "policy_loss": -0.00133896092482928, "dist_entropy": 0.6568145036697388, "actor_grad_norm": 0.0900043174624443, "critic_grad_norm": 0.025030065327882767, "ratio": 1.0001500844955444, "entropy": 0.6568145036697388, "incre_win_rate": 0.9347826086956522, "step": 2431}
{"time": 1767342510.7453773, "phase": "train", "update": 2432, "total_env_steps": 7782400, "episode_reward": 0.28005483746528625, "value_loss": 0.00813647909089923, "policy_loss": -0.0017111878773787836, "dist_entropy": 0.6901417016983032, "actor_grad_norm": 0.09878676384687424, "critic_grad_norm": 0.038487162441015244, "ratio": 0.9995641112327576, "entropy": 0.6901417016983032, "incre_win_rate": 0.9565217391304348, "step": 2432}
{"time": 1767342514.8818638, "phase": "train", "update": 2433, "total_env_steps": 7785600, "episode_reward": 0.27308207750320435, "value_loss": 0.005416406597942114, "policy_loss": -0.001270556704658754, "dist_entropy": 0.6889143943786621, "actor_grad_norm": 0.11330293864011765, "critic_grad_norm": 0.03263555094599724, "ratio": 0.9999710321426392, "entropy": 0.6889143943786621, "incre_win_rate": 0.9090909090909091, "step": 2433}
{"time": 1767342519.000924, "phase": "train", "update": 2434, "total_env_steps": 7788800, "episode_reward": 0.27490997314453125, "value_loss": 0.006688945088535547, "policy_loss": -0.001360118326487836, "dist_entropy": 0.6793510556221009, "actor_grad_norm": 0.10873766243457794, "critic_grad_norm": 0.021931124851107597, "ratio": 1.000342607498169, "entropy": 0.6793510556221009, "incre_win_rate": 0.9347826086956522, "step": 2434}
{"time": 1767342523.1485546, "phase": "train", "update": 2435, "total_env_steps": 7792000, "episode_reward": 0.280269056558609, "value_loss": 0.0073360418900847435, "policy_loss": -0.0009711831560892392, "dist_entropy": 0.6622774243354798, "actor_grad_norm": 0.09055041521787643, "critic_grad_norm": 0.04479515552520752, "ratio": 1.0000660419464111, "entropy": 0.6622774243354798, "incre_win_rate": 0.9347826086956522, "step": 2435}
{"time": 1767342527.2615042, "phase": "train", "update": 2436, "total_env_steps": 7795200, "episode_reward": 0.2804816961288452, "value_loss": 0.006510325986891985, "policy_loss": -0.0013241487142334307, "dist_entropy": 0.6699349164962769, "actor_grad_norm": 0.11824531853199005, "critic_grad_norm": 0.03860022872686386, "ratio": 0.9998661279678345, "entropy": 0.6699349164962769, "incre_win_rate": 0.9333333333333333, "step": 2436}
{"time": 1767342531.4167385, "phase": "train", "update": 2437, "total_env_steps": 7798400, "episode_reward": 0.2896067798137665, "value_loss": 0.003820473188534379, "policy_loss": -0.0007713551848240741, "dist_entropy": 0.6822905778884888, "actor_grad_norm": 0.10806330293416977, "critic_grad_norm": 0.07239558547735214, "ratio": 1.0000790357589722, "entropy": 0.6822905778884888, "incre_win_rate": 0.9574468085106383, "step": 2437}
{"time": 1767342535.5334182, "phase": "train", "update": 2438, "total_env_steps": 7801600, "episode_reward": 0.2812080979347229, "value_loss": 0.0035907033365219832, "policy_loss": -0.000973429653919311, "dist_entropy": 0.6683682322502136, "actor_grad_norm": 0.10786093771457672, "critic_grad_norm": 0.031053412705659866, "ratio": 1.0000900030136108, "entropy": 0.6683682322502136, "incre_win_rate": 0.9347826086956522, "step": 2438}
{"time": 1767342539.6656523, "phase": "train", "update": 2439, "total_env_steps": 7804800, "episode_reward": 0.28137367963790894, "value_loss": 0.002836804511025548, "policy_loss": -0.0014069439101078273, "dist_entropy": 0.6643844246864319, "actor_grad_norm": 0.12853321433067322, "critic_grad_norm": 0.03531573340296745, "ratio": 0.9997608065605164, "entropy": 0.6643844246864319, "incre_win_rate": 0.9777777777777777, "step": 2439}
{"time": 1767342543.8221164, "phase": "train", "update": 2440, "total_env_steps": 7808000, "episode_reward": 0.2814735174179077, "value_loss": 0.004788199998438358, "policy_loss": -0.0014225829900006205, "dist_entropy": 0.6659088850021362, "actor_grad_norm": 0.10217058658599854, "critic_grad_norm": 0.04375649616122246, "ratio": 0.9998790621757507, "entropy": 0.6659088850021362, "incre_win_rate": 0.9347826086956522, "step": 2440}
{"time": 1767342547.92318, "phase": "train", "update": 2441, "total_env_steps": 7811200, "episode_reward": 0.27770283818244934, "value_loss": 0.005154400411993265, "policy_loss": -0.0013052746459877086, "dist_entropy": 0.6451406478881836, "actor_grad_norm": 0.10512186586856842, "critic_grad_norm": 0.039022572338581085, "ratio": 0.999981701374054, "entropy": 0.6451406478881836, "incre_win_rate": 0.9130434782608695, "step": 2441}
{"time": 1767342552.1094046, "phase": "train", "update": 2442, "total_env_steps": 7814400, "episode_reward": 0.26977959275245667, "value_loss": 0.011018972657620908, "policy_loss": -0.0009148944378669199, "dist_entropy": 0.6382350921630859, "actor_grad_norm": 0.09855062514543533, "critic_grad_norm": 0.0376499779522419, "ratio": 0.9996349215507507, "entropy": 0.6382350921630859, "incre_win_rate": 0.8222222222222222, "step": 2442}
{"time": 1767342556.2353935, "phase": "train", "update": 2443, "total_env_steps": 7817600, "episode_reward": 0.27050498127937317, "value_loss": 0.008315598778426646, "policy_loss": -0.0016727643380335167, "dist_entropy": 0.6351743221282959, "actor_grad_norm": 0.1007375493645668, "critic_grad_norm": 0.023838546127080917, "ratio": 0.999992311000824, "entropy": 0.6351743221282959, "incre_win_rate": 0.8666666666666667, "step": 2443}
{"time": 1767342560.3746064, "phase": "train", "update": 2444, "total_env_steps": 7820800, "episode_reward": 0.27328330278396606, "value_loss": 0.006918063387274742, "policy_loss": -0.0010460222044915922, "dist_entropy": 0.6489117622375489, "actor_grad_norm": 0.10975728183984756, "critic_grad_norm": 0.03579191491007805, "ratio": 0.9999893307685852, "entropy": 0.6489117622375489, "incre_win_rate": 0.9069767441860465, "step": 2444}
{"time": 1767342564.5408535, "phase": "train", "update": 2445, "total_env_steps": 7824000, "episode_reward": 0.26556187868118286, "value_loss": 0.007829487789422274, "policy_loss": -0.0015824863491399554, "dist_entropy": 0.6468812942504882, "actor_grad_norm": 0.0932898074388504, "critic_grad_norm": 0.06396395713090897, "ratio": 0.9998189806938171, "entropy": 0.6468812942504882, "incre_win_rate": 0.8863636363636364, "step": 2445}
{"time": 1767342568.6947508, "phase": "train", "update": 2446, "total_env_steps": 7827200, "episode_reward": 0.2840645909309387, "value_loss": 0.006449349783360958, "policy_loss": -0.001347296595529457, "dist_entropy": 0.6608429193496704, "actor_grad_norm": 0.07589141279459, "critic_grad_norm": 0.06986334919929504, "ratio": 1.0001556873321533, "entropy": 0.6608429193496704, "incre_win_rate": 0.9361702127659575, "step": 2446}
{"time": 1767342572.7971175, "phase": "train", "update": 2447, "total_env_steps": 7830400, "episode_reward": 0.2853683531284332, "value_loss": 0.0036666168831288814, "policy_loss": -0.0014165416877318648, "dist_entropy": 0.6651260733604432, "actor_grad_norm": 0.09197957813739777, "critic_grad_norm": 0.08767037838697433, "ratio": 1.0000330209732056, "entropy": 0.6651260733604432, "incre_win_rate": 0.9772727272727273, "step": 2447}
{"time": 1767342576.898759, "phase": "train", "update": 2448, "total_env_steps": 7833600, "episode_reward": 0.2817590832710266, "value_loss": 0.005064165871590376, "policy_loss": -0.001423063163665006, "dist_entropy": 0.6471513509750366, "actor_grad_norm": 0.09009595960378647, "critic_grad_norm": 0.030065307393670082, "ratio": 0.999906063079834, "entropy": 0.6471513509750366, "incre_win_rate": 0.9347826086956522, "step": 2448}
{"time": 1767342581.0146809, "phase": "train", "update": 2449, "total_env_steps": 7836800, "episode_reward": 0.2789817750453949, "value_loss": 0.0040494994260370735, "policy_loss": -0.0008596255610285652, "dist_entropy": 0.6325619459152222, "actor_grad_norm": 0.07732107490301132, "critic_grad_norm": 0.03403362259268761, "ratio": 0.9997535943984985, "entropy": 0.6325619459152222, "incre_win_rate": 0.9787234042553191, "step": 2449}
{"time": 1767342619.13371, "phase": "train", "update": 2450, "total_env_steps": 7840000, "episode_reward": 0.2598297894001007, "value_loss": 0.03731626123189926, "policy_loss": -0.0009012691352829449, "dist_entropy": 0.6467492461204529, "actor_grad_norm": 0.06971465796232224, "critic_grad_norm": 0.2000192254781723, "ratio": 0.9997483491897583, "entropy": 0.6467492461204529, "incre_win_rate": 0.875, "step": 2450}
{"time": 1767342623.2143734, "phase": "train", "update": 2451, "total_env_steps": 7843200, "episode_reward": 0.2744898498058319, "value_loss": 0.006421670038253069, "policy_loss": -0.0012399763244721029, "dist_entropy": 0.6475972652435302, "actor_grad_norm": 0.08622881025075912, "critic_grad_norm": 0.1349385678768158, "ratio": 0.9999421238899231, "entropy": 0.6475972652435302, "incre_win_rate": 0.9090909090909091, "step": 2451}
{"time": 1767342632.7032416, "phase": "eval", "update": 2451, "total_env_steps": 7843200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.871999172185433, "step": 2451}
{"time": 1767342636.7938142, "phase": "train", "update": 2452, "total_env_steps": 7846400, "episode_reward": 0.28410595655441284, "value_loss": 0.005619877763092518, "policy_loss": -0.001081948154429213, "dist_entropy": 0.6544126152992249, "actor_grad_norm": 0.07566255331039429, "critic_grad_norm": 0.11670982837677002, "ratio": 1.000054121017456, "entropy": 0.6544126152992249, "incre_win_rate": 0.9555555555555556, "step": 2452}
{"time": 1767342640.8692417, "phase": "train", "update": 2453, "total_env_steps": 7849600, "episode_reward": 0.2654159963130951, "value_loss": 0.007179717626422643, "policy_loss": -0.0013475295300158674, "dist_entropy": 0.627053952217102, "actor_grad_norm": 0.08946947008371353, "critic_grad_norm": 0.06351394206285477, "ratio": 1.0000066757202148, "entropy": 0.627053952217102, "incre_win_rate": 0.8695652173913043, "step": 2453}
{"time": 1767342644.929687, "phase": "train", "update": 2454, "total_env_steps": 7852800, "episode_reward": 0.2657491862773895, "value_loss": 0.006665818113833666, "policy_loss": -0.0013510874086172463, "dist_entropy": 0.6521020889282226, "actor_grad_norm": 0.10610399395227432, "critic_grad_norm": 0.02340167760848999, "ratio": 1.0000051259994507, "entropy": 0.6521020889282226, "incre_win_rate": 0.8809523809523809, "step": 2454}
{"time": 1767342649.040609, "phase": "train", "update": 2455, "total_env_steps": 7856000, "episode_reward": 0.2790878713130951, "value_loss": 0.004191080946475268, "policy_loss": -0.0008436598695141129, "dist_entropy": 0.6469926834106445, "actor_grad_norm": 0.09889665246009827, "critic_grad_norm": 0.024351436644792557, "ratio": 0.9998456835746765, "entropy": 0.6469926834106445, "incre_win_rate": 0.9574468085106383, "step": 2455}
{"time": 1767342653.1180415, "phase": "train", "update": 2456, "total_env_steps": 7859200, "episode_reward": 0.2788146734237671, "value_loss": 0.005636837333440781, "policy_loss": -0.0012805138947982186, "dist_entropy": 0.6449325442314148, "actor_grad_norm": 0.08618852496147156, "critic_grad_norm": 0.017821278423070908, "ratio": 1.0002495050430298, "entropy": 0.6449325442314148, "incre_win_rate": 0.9555555555555556, "step": 2456}
{"time": 1767342657.1850972, "phase": "train", "update": 2457, "total_env_steps": 7862400, "episode_reward": 0.28236135840415955, "value_loss": 0.004532109759747982, "policy_loss": -0.0013704411611971778, "dist_entropy": 0.6327088236808777, "actor_grad_norm": 0.09294365346431732, "critic_grad_norm": 0.07214009761810303, "ratio": 1.0000234842300415, "entropy": 0.6327088236808777, "incre_win_rate": 0.9772727272727273, "step": 2457}
{"time": 1767342661.279858, "phase": "train", "update": 2458, "total_env_steps": 7865600, "episode_reward": 0.28298014402389526, "value_loss": 0.005215955059975385, "policy_loss": -0.001399846292989082, "dist_entropy": 0.6553180098533631, "actor_grad_norm": 0.09636974334716797, "critic_grad_norm": 0.04821047931909561, "ratio": 1.0001338720321655, "entropy": 0.6553180098533631, "incre_win_rate": 0.9347826086956522, "step": 2458}
{"time": 1767342665.360769, "phase": "train", "update": 2459, "total_env_steps": 7868800, "episode_reward": 0.2755877375602722, "value_loss": 0.0059488313272595406, "policy_loss": -0.0012177717148880163, "dist_entropy": 0.663797664642334, "actor_grad_norm": 0.09052859246730804, "critic_grad_norm": 0.05034227296710014, "ratio": 1.0000852346420288, "entropy": 0.663797664642334, "incre_win_rate": 0.8913043478260869, "step": 2459}
{"time": 1767342669.4415145, "phase": "train", "update": 2460, "total_env_steps": 7872000, "episode_reward": 0.2756824195384979, "value_loss": 0.007750835828483104, "policy_loss": -0.0013655197041174461, "dist_entropy": 0.6322557330131531, "actor_grad_norm": 0.08508026599884033, "critic_grad_norm": 0.054103683680295944, "ratio": 0.9996757507324219, "entropy": 0.6322557330131531, "incre_win_rate": 0.9111111111111111, "step": 2460}
{"time": 1767342673.544725, "phase": "train", "update": 2461, "total_env_steps": 7875200, "episode_reward": 0.28301018476486206, "value_loss": 0.006416928023099899, "policy_loss": -0.0009785221701276825, "dist_entropy": 0.6449602246284485, "actor_grad_norm": 0.0795295462012291, "critic_grad_norm": 0.03696193918585777, "ratio": 1.000027060508728, "entropy": 0.6449602246284485, "incre_win_rate": 0.9565217391304348, "step": 2461}
{"time": 1767342677.6057272, "phase": "train", "update": 2462, "total_env_steps": 7878400, "episode_reward": 0.2649441361427307, "value_loss": 0.009651303105056287, "policy_loss": -0.0014881808683774977, "dist_entropy": 0.653884768486023, "actor_grad_norm": 0.08836480230093002, "critic_grad_norm": 0.04320984706282616, "ratio": 0.9997785687446594, "entropy": 0.653884768486023, "incre_win_rate": 0.8222222222222222, "step": 2462}
{"time": 1767342681.6458938, "phase": "train", "update": 2463, "total_env_steps": 7881600, "episode_reward": 0.2574772238731384, "value_loss": 0.01089941468089819, "policy_loss": -0.0014557766718141351, "dist_entropy": 0.6603363633155823, "actor_grad_norm": 0.09515560418367386, "critic_grad_norm": 0.051027875393629074, "ratio": 0.9999774098396301, "entropy": 0.6603363633155823, "incre_win_rate": 0.7954545454545454, "step": 2463}
{"time": 1767342685.7181156, "phase": "train", "update": 2464, "total_env_steps": 7884800, "episode_reward": 0.2734944224357605, "value_loss": 0.006693399511277676, "policy_loss": -0.0013437855961711876, "dist_entropy": 0.6603838562965393, "actor_grad_norm": 0.08916123956441879, "critic_grad_norm": 0.07533363252878189, "ratio": 1.000025749206543, "entropy": 0.6603838562965393, "incre_win_rate": 0.9534883720930233, "step": 2464}
{"time": 1767342689.7454634, "phase": "train", "update": 2465, "total_env_steps": 7888000, "episode_reward": 0.2618258595466614, "value_loss": 0.007836266607046127, "policy_loss": -0.001095935040867957, "dist_entropy": 0.6649604201316833, "actor_grad_norm": 0.08685975521802902, "critic_grad_norm": 0.07856259495019913, "ratio": 1.0000696182250977, "entropy": 0.6649604201316833, "incre_win_rate": 0.8409090909090909, "step": 2465}
{"time": 1767342693.8237479, "phase": "train", "update": 2466, "total_env_steps": 7891200, "episode_reward": 0.27865323424339294, "value_loss": 0.0035655665677040817, "policy_loss": -0.0010325973269999622, "dist_entropy": 0.6719496488571167, "actor_grad_norm": 0.08127611130475998, "critic_grad_norm": 0.09355862438678741, "ratio": 0.99969482421875, "entropy": 0.6719496488571167, "incre_win_rate": 0.9777777777777777, "step": 2466}
{"time": 1767342697.8671572, "phase": "train", "update": 2467, "total_env_steps": 7894400, "episode_reward": 0.27686673402786255, "value_loss": 0.006482418719679117, "policy_loss": -0.0012528796126819231, "dist_entropy": 0.7108301877975464, "actor_grad_norm": 0.082039013504982, "critic_grad_norm": 0.058117546141147614, "ratio": 1.0002168416976929, "entropy": 0.7108301877975464, "incre_win_rate": 0.9130434782608695, "step": 2467}
{"time": 1767342701.9198227, "phase": "train", "update": 2468, "total_env_steps": 7897600, "episode_reward": 0.2812494933605194, "value_loss": 0.005462362058460712, "policy_loss": -0.0012307222019902753, "dist_entropy": 0.689674460887909, "actor_grad_norm": 0.07443790882825851, "critic_grad_norm": 0.08180328458547592, "ratio": 1.0002089738845825, "entropy": 0.689674460887909, "incre_win_rate": 0.9130434782608695, "step": 2468}
{"time": 1767342705.9805603, "phase": "train", "update": 2469, "total_env_steps": 7900800, "episode_reward": 0.2769815921783447, "value_loss": 0.005158254131674767, "policy_loss": -0.0011114109452096343, "dist_entropy": 0.6948550701141357, "actor_grad_norm": 0.06776975840330124, "critic_grad_norm": 0.07664307206869125, "ratio": 0.9999120831489563, "entropy": 0.6948550701141357, "incre_win_rate": 0.8888888888888888, "step": 2469}
{"time": 1767342710.0462456, "phase": "train", "update": 2470, "total_env_steps": 7904000, "episode_reward": 0.27886176109313965, "value_loss": 0.00924154482781887, "policy_loss": -0.0013058487304533628, "dist_entropy": 0.6753781318664551, "actor_grad_norm": 0.07430466264486313, "critic_grad_norm": 0.08400563150644302, "ratio": 1.0000022649765015, "entropy": 0.6753781318664551, "incre_win_rate": 0.9111111111111111, "step": 2470}
{"time": 1767342714.1603913, "phase": "train", "update": 2471, "total_env_steps": 7907200, "episode_reward": 0.27360770106315613, "value_loss": 0.008451705984771251, "policy_loss": -0.0009691021838159841, "dist_entropy": 0.6718070268630981, "actor_grad_norm": 0.07167018949985504, "critic_grad_norm": 0.030209550634026527, "ratio": 0.9998840689659119, "entropy": 0.6718070268630981, "incre_win_rate": 0.9090909090909091, "step": 2471}
{"time": 1767342718.2457504, "phase": "train", "update": 2472, "total_env_steps": 7910400, "episode_reward": 0.2807708978652954, "value_loss": 0.004768680687993765, "policy_loss": -0.0012224617127344572, "dist_entropy": 0.6902268528938293, "actor_grad_norm": 0.08815516531467438, "critic_grad_norm": 0.03181175887584686, "ratio": 0.9999851584434509, "entropy": 0.6902268528938293, "incre_win_rate": 0.9375, "step": 2472}
{"time": 1767342722.3483646, "phase": "train", "update": 2473, "total_env_steps": 7913600, "episode_reward": 0.2781917452812195, "value_loss": 0.005956549104303122, "policy_loss": -0.0016555721763992892, "dist_entropy": 0.6611669301986695, "actor_grad_norm": 0.09454900771379471, "critic_grad_norm": 0.019477754831314087, "ratio": 1.0000666379928589, "entropy": 0.6611669301986695, "incre_win_rate": 0.9111111111111111, "step": 2473}
{"time": 1767342726.411847, "phase": "train", "update": 2474, "total_env_steps": 7916800, "episode_reward": 0.26553553342819214, "value_loss": 0.006637831311672926, "policy_loss": -0.0013240229502120115, "dist_entropy": 0.6684967398643493, "actor_grad_norm": 0.0774289071559906, "critic_grad_norm": 0.0476858876645565, "ratio": 1.0001710653305054, "entropy": 0.6684967398643493, "incre_win_rate": 0.8333333333333334, "step": 2474}
{"time": 1767342730.5054662, "phase": "train", "update": 2475, "total_env_steps": 7920000, "episode_reward": 0.2884809374809265, "value_loss": 0.0030007712543010713, "policy_loss": -0.0010827191936128243, "dist_entropy": 0.6759390711784363, "actor_grad_norm": 0.09172701090574265, "critic_grad_norm": 0.04532620310783386, "ratio": 1.0000461339950562, "entropy": 0.6759390711784363, "incre_win_rate": 1.0, "step": 2475}
{"time": 1767342734.6195235, "phase": "train", "update": 2476, "total_env_steps": 7923200, "episode_reward": 0.28135761618614197, "value_loss": 0.003861107863485813, "policy_loss": -0.0013896538409270743, "dist_entropy": 0.6803943991661072, "actor_grad_norm": 0.10013841837644577, "critic_grad_norm": 0.038466282188892365, "ratio": 1.0001132488250732, "entropy": 0.6803943991661072, "incre_win_rate": 0.9375, "step": 2476}
{"time": 1767342743.9887319, "phase": "eval", "update": 2476, "total_env_steps": 7923200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.86134105960265, "step": 2476}
{"time": 1767342748.019714, "phase": "train", "update": 2477, "total_env_steps": 7926400, "episode_reward": 0.2820695638656616, "value_loss": 0.003966858983039856, "policy_loss": -0.0013234995557766637, "dist_entropy": 0.6683169484138489, "actor_grad_norm": 0.10593511909246445, "critic_grad_norm": 0.04406621307134628, "ratio": 0.9997348785400391, "entropy": 0.6683169484138489, "incre_win_rate": 0.9361702127659575, "step": 2477}
{"time": 1767342752.177863, "phase": "train", "update": 2478, "total_env_steps": 7929600, "episode_reward": 0.292711079120636, "value_loss": 0.002691050199791789, "policy_loss": -0.0006692745485501917, "dist_entropy": 0.6628114700317382, "actor_grad_norm": 0.12222938984632492, "critic_grad_norm": 0.03312128409743309, "ratio": 1.0002868175506592, "entropy": 0.6628114700317382, "incre_win_rate": 0.9782608695652174, "step": 2478}
{"time": 1767342756.3155296, "phase": "train", "update": 2479, "total_env_steps": 7932800, "episode_reward": 0.2916390895843506, "value_loss": 0.0034226016607135533, "policy_loss": -0.0012838022386766567, "dist_entropy": 0.6769901275634765, "actor_grad_norm": 0.09609698504209518, "critic_grad_norm": 0.04513093829154968, "ratio": 0.9998062252998352, "entropy": 0.6769901275634765, "incre_win_rate": 0.9787234042553191, "step": 2479}
{"time": 1767342760.410461, "phase": "train", "update": 2480, "total_env_steps": 7936000, "episode_reward": 0.28160181641578674, "value_loss": 0.004247139673680067, "policy_loss": -0.00120153541810879, "dist_entropy": 0.6876964688301086, "actor_grad_norm": 0.09813638776540756, "critic_grad_norm": 0.05742150545120239, "ratio": 0.9999659657478333, "entropy": 0.6876964688301086, "incre_win_rate": 0.9782608695652174, "step": 2480}
{"time": 1767342764.4785814, "phase": "train", "update": 2481, "total_env_steps": 7939200, "episode_reward": 0.27680206298828125, "value_loss": 0.0057906778529286385, "policy_loss": -0.0011750210444603226, "dist_entropy": 0.681039559841156, "actor_grad_norm": 0.06867603957653046, "critic_grad_norm": 0.03735365346074104, "ratio": 0.9997744560241699, "entropy": 0.681039559841156, "incre_win_rate": 0.9333333333333333, "step": 2481}
{"time": 1767342768.5735135, "phase": "train", "update": 2482, "total_env_steps": 7942400, "episode_reward": 0.2849958539009094, "value_loss": 0.0050570257939398285, "policy_loss": -0.0012488926355104014, "dist_entropy": 0.6537038683891296, "actor_grad_norm": 0.07697410881519318, "critic_grad_norm": 0.05793134123086929, "ratio": 0.9998985528945923, "entropy": 0.6537038683891296, "incre_win_rate": 0.9545454545454546, "step": 2482}
{"time": 1767342772.6885319, "phase": "train", "update": 2483, "total_env_steps": 7945600, "episode_reward": 0.28020694851875305, "value_loss": 0.007231306936591864, "policy_loss": -0.0011210143592336407, "dist_entropy": 0.6607007622718811, "actor_grad_norm": 0.09310440719127655, "critic_grad_norm": 0.04005296155810356, "ratio": 0.9998134970664978, "entropy": 0.6607007622718811, "incre_win_rate": 0.8958333333333334, "step": 2483}
{"time": 1767342776.7577682, "phase": "train", "update": 2484, "total_env_steps": 7948800, "episode_reward": 0.28219786286354065, "value_loss": 0.00639004660770297, "policy_loss": -0.0008026258546784071, "dist_entropy": 0.6657290816307068, "actor_grad_norm": 0.0830795019865036, "critic_grad_norm": 0.046139977872371674, "ratio": 0.999967098236084, "entropy": 0.6657290816307068, "incre_win_rate": 0.9111111111111111, "step": 2484}
{"time": 1767342780.8513892, "phase": "train", "update": 2485, "total_env_steps": 7952000, "episode_reward": 0.28552567958831787, "value_loss": 0.005562571994960308, "policy_loss": -0.0012207928917177923, "dist_entropy": 0.6758793830871582, "actor_grad_norm": 0.10263923555612564, "critic_grad_norm": 0.02613733522593975, "ratio": 0.9999085664749146, "entropy": 0.6758793830871582, "incre_win_rate": 0.9787234042553191, "step": 2485}
{"time": 1767342784.9241712, "phase": "train", "update": 2486, "total_env_steps": 7955200, "episode_reward": 0.2793874442577362, "value_loss": 0.003541490249335766, "policy_loss": -0.000663460753710865, "dist_entropy": 0.699286413192749, "actor_grad_norm": 0.09288273006677628, "critic_grad_norm": 0.03324558958411217, "ratio": 1.0001776218414307, "entropy": 0.699286413192749, "incre_win_rate": 0.9347826086956522, "step": 2486}
{"time": 1767342789.003744, "phase": "train", "update": 2487, "total_env_steps": 7958400, "episode_reward": 0.2857305407524109, "value_loss": 0.003335859952494502, "policy_loss": -0.0007214701839084014, "dist_entropy": 0.7049298644065857, "actor_grad_norm": 0.07823580503463745, "critic_grad_norm": 0.031157061457633972, "ratio": 1.0002789497375488, "entropy": 0.7049298644065857, "incre_win_rate": 0.9545454545454546, "step": 2487}
{"time": 1767342793.15835, "phase": "train", "update": 2488, "total_env_steps": 7961600, "episode_reward": 0.2732243239879608, "value_loss": 0.0032596591860055923, "policy_loss": -0.0010974070099578626, "dist_entropy": 0.6869798541069031, "actor_grad_norm": 0.07816558331251144, "critic_grad_norm": 0.04244459420442581, "ratio": 0.9995590448379517, "entropy": 0.6869798541069031, "incre_win_rate": 0.9361702127659575, "step": 2488}
{"time": 1767342797.240399, "phase": "train", "update": 2489, "total_env_steps": 7964800, "episode_reward": 0.27988409996032715, "value_loss": 0.0037473616190254687, "policy_loss": -0.0014459080452802198, "dist_entropy": 0.7094778299331665, "actor_grad_norm": 0.09152131527662277, "critic_grad_norm": 0.024408068507909775, "ratio": 0.999851644039154, "entropy": 0.7094778299331665, "incre_win_rate": 0.9761904761904762, "step": 2489}
{"time": 1767342801.3342624, "phase": "train", "update": 2490, "total_env_steps": 7968000, "episode_reward": 0.28021833300590515, "value_loss": 0.00446631945669651, "policy_loss": -0.0010133734153654928, "dist_entropy": 0.6979637265205383, "actor_grad_norm": 0.0645301565527916, "critic_grad_norm": 0.018190210685133934, "ratio": 0.9998165369033813, "entropy": 0.6979637265205383, "incre_win_rate": 0.9574468085106383, "step": 2490}
{"time": 1767342805.4359336, "phase": "train", "update": 2491, "total_env_steps": 7971200, "episode_reward": 0.27975940704345703, "value_loss": 0.004990585986524821, "policy_loss": -0.0016285529483752725, "dist_entropy": 0.7018382310867309, "actor_grad_norm": 0.09587283432483673, "critic_grad_norm": 0.024620506912469864, "ratio": 1.000329852104187, "entropy": 0.7018382310867309, "incre_win_rate": 0.8936170212765957, "step": 2491}
{"time": 1767342809.491101, "phase": "train", "update": 2492, "total_env_steps": 7974400, "episode_reward": 0.28168410062789917, "value_loss": 0.0043193063698709015, "policy_loss": -0.0014146765256979777, "dist_entropy": 0.6938555359840393, "actor_grad_norm": 0.08923304826021194, "critic_grad_norm": 0.019293148070573807, "ratio": 1.0003241300582886, "entropy": 0.6938555359840393, "incre_win_rate": 0.9545454545454546, "step": 2492}
{"time": 1767342813.5988994, "phase": "train", "update": 2493, "total_env_steps": 7977600, "episode_reward": 0.28010350465774536, "value_loss": 0.004499723389744759, "policy_loss": -0.0008775511226662758, "dist_entropy": 0.6747851371765137, "actor_grad_norm": 0.0824679508805275, "critic_grad_norm": 0.02417936734855175, "ratio": 0.9999213218688965, "entropy": 0.6747851371765137, "incre_win_rate": 0.9333333333333333, "step": 2493}
{"time": 1767342817.6929102, "phase": "train", "update": 2494, "total_env_steps": 7980800, "episode_reward": 0.2732290029525757, "value_loss": 0.005464761424809695, "policy_loss": -0.0012572678157138028, "dist_entropy": 0.7030638217926025, "actor_grad_norm": 0.07881344854831696, "critic_grad_norm": 0.019596857950091362, "ratio": 0.9997245073318481, "entropy": 0.7030638217926025, "incre_win_rate": 0.9148936170212766, "step": 2494}
{"time": 1767342821.7917125, "phase": "train", "update": 2495, "total_env_steps": 7984000, "episode_reward": 0.2789445221424103, "value_loss": 0.004301046766340732, "policy_loss": -0.001194823316171778, "dist_entropy": 0.6764282345771789, "actor_grad_norm": 0.09768582135438919, "critic_grad_norm": 0.016048168763518333, "ratio": 0.9998053908348083, "entropy": 0.6764282345771789, "incre_win_rate": 0.9302325581395349, "step": 2495}
{"time": 1767342825.8637598, "phase": "train", "update": 2496, "total_env_steps": 7987200, "episode_reward": 0.2697288990020752, "value_loss": 0.007138480618596077, "policy_loss": -0.0013324415011044088, "dist_entropy": 0.6652763247489929, "actor_grad_norm": 0.08636707812547684, "critic_grad_norm": 0.017982948571443558, "ratio": 0.9999189376831055, "entropy": 0.6652763247489929, "incre_win_rate": 0.8636363636363636, "step": 2496}
{"time": 1767342829.9303553, "phase": "train", "update": 2497, "total_env_steps": 7990400, "episode_reward": 0.28011587262153625, "value_loss": 0.003924713842570782, "policy_loss": -0.0014088473466827623, "dist_entropy": 0.6762697458267212, "actor_grad_norm": 0.10028576105833054, "critic_grad_norm": 0.03004375658929348, "ratio": 1.000266671180725, "entropy": 0.6762697458267212, "incre_win_rate": 0.9583333333333334, "step": 2497}
{"time": 1767342834.0144546, "phase": "train", "update": 2498, "total_env_steps": 7993600, "episode_reward": 0.2806803584098816, "value_loss": 0.004811251163482666, "policy_loss": -0.001254027185238016, "dist_entropy": 0.7052106499671936, "actor_grad_norm": 0.0879167914390564, "critic_grad_norm": 0.05191019922494888, "ratio": 1.000089168548584, "entropy": 0.7052106499671936, "incre_win_rate": 0.9090909090909091, "step": 2498}
{"time": 1767342838.1199353, "phase": "train", "update": 2499, "total_env_steps": 7996800, "episode_reward": 0.27783477306365967, "value_loss": 0.005914661660790443, "policy_loss": -0.0011934083204288015, "dist_entropy": 0.6894471406936645, "actor_grad_norm": 0.0759565606713295, "critic_grad_norm": 0.03911644220352173, "ratio": 1.0000028610229492, "entropy": 0.6894471406936645, "incre_win_rate": 0.9555555555555556, "step": 2499}
{"time": 1767342842.2235596, "phase": "train", "update": 2500, "total_env_steps": 8000000, "episode_reward": 0.27086764574050903, "value_loss": 0.004449762310832739, "policy_loss": -0.0010803157575416833, "dist_entropy": 0.6782617092132568, "actor_grad_norm": 0.07879383116960526, "critic_grad_norm": 0.03341009095311165, "ratio": 1.000235915184021, "entropy": 0.6782617092132568, "incre_win_rate": 0.9534883720930233, "step": 2500}
{"time": 1767342846.3212252, "phase": "train", "update": 2501, "total_env_steps": 8003200, "episode_reward": 0.27937811613082886, "value_loss": 0.003297771792858839, "policy_loss": -0.0010143502479294853, "dist_entropy": 0.6866427659988403, "actor_grad_norm": 0.07280109077692032, "critic_grad_norm": 0.05551503971219063, "ratio": 1.0001033544540405, "entropy": 0.6866427659988403, "incre_win_rate": 0.9782608695652174, "step": 2501}
{"time": 1767342855.460703, "phase": "eval", "update": 2501, "total_env_steps": 8003200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.879139072847682, "step": 2501}
{"time": 1767342859.503964, "phase": "train", "update": 2502, "total_env_steps": 8006400, "episode_reward": 0.27682945132255554, "value_loss": 0.0034402948804199696, "policy_loss": -0.0016190610594058797, "dist_entropy": 0.7121634721755982, "actor_grad_norm": 0.0868036076426506, "critic_grad_norm": 0.03545154258608818, "ratio": 1.0003634691238403, "entropy": 0.7121634721755982, "incre_win_rate": 0.9555555555555556, "step": 2502}
{"time": 1767342863.5779686, "phase": "train", "update": 2503, "total_env_steps": 8009600, "episode_reward": 0.2863162159919739, "value_loss": 0.0017688007093966008, "policy_loss": -0.0014350640121620017, "dist_entropy": 0.7130156397819519, "actor_grad_norm": 0.08997976034879684, "critic_grad_norm": 0.024384597316384315, "ratio": 0.9999290704727173, "entropy": 0.7130156397819519, "incre_win_rate": 1.0, "step": 2503}
{"time": 1767342867.6798334, "phase": "train", "update": 2504, "total_env_steps": 8012800, "episode_reward": 0.2781042754650116, "value_loss": 0.003104893397539854, "policy_loss": -0.0011463170556833546, "dist_entropy": 0.7066648960113525, "actor_grad_norm": 0.0704868733882904, "critic_grad_norm": 0.030470961704850197, "ratio": 0.9999194145202637, "entropy": 0.7066648960113525, "incre_win_rate": 0.9583333333333334, "step": 2504}
{"time": 1767342871.8032966, "phase": "train", "update": 2505, "total_env_steps": 8016000, "episode_reward": 0.281523197889328, "value_loss": 0.00429574828594923, "policy_loss": -0.0011926412171545664, "dist_entropy": 0.7298690795898437, "actor_grad_norm": 0.06659378111362457, "critic_grad_norm": 0.0382368229329586, "ratio": 0.9999541640281677, "entropy": 0.7298690795898437, "incre_win_rate": 0.9347826086956522, "step": 2505}
{"time": 1767342875.915793, "phase": "train", "update": 2506, "total_env_steps": 8019200, "episode_reward": 0.28457367420196533, "value_loss": 0.002786820847541094, "policy_loss": -0.0013802522316726852, "dist_entropy": 0.7141778707504273, "actor_grad_norm": 0.07971712201833725, "critic_grad_norm": 0.030034726485610008, "ratio": 1.0003669261932373, "entropy": 0.7141778707504273, "incre_win_rate": 1.0, "step": 2506}
{"time": 1767342879.979058, "phase": "train", "update": 2507, "total_env_steps": 8022400, "episode_reward": 0.2611744701862335, "value_loss": 0.004566141497343778, "policy_loss": -0.0014592645529977965, "dist_entropy": 0.6831452369689941, "actor_grad_norm": 0.07665519416332245, "critic_grad_norm": 0.033745184540748596, "ratio": 1.0001500844955444, "entropy": 0.6831452369689941, "incre_win_rate": 0.8863636363636364, "step": 2507}
{"time": 1767342884.0842075, "phase": "train", "update": 2508, "total_env_steps": 8025600, "episode_reward": 0.2792011499404907, "value_loss": 0.002696244837716222, "policy_loss": -0.0012871345708425964, "dist_entropy": 0.7112522840499877, "actor_grad_norm": 0.07428379356861115, "critic_grad_norm": 0.022254904732108116, "ratio": 0.9999859929084778, "entropy": 0.7112522840499877, "incre_win_rate": 0.9574468085106383, "step": 2508}
{"time": 1767342888.2037444, "phase": "train", "update": 2509, "total_env_steps": 8028800, "episode_reward": 0.2870819568634033, "value_loss": 0.0019723497796803715, "policy_loss": -0.0012969101974988461, "dist_entropy": 0.680019474029541, "actor_grad_norm": 0.08887877315282822, "critic_grad_norm": 0.020378684625029564, "ratio": 1.000015139579773, "entropy": 0.680019474029541, "incre_win_rate": 0.9782608695652174, "step": 2509}
{"time": 1767342892.2595687, "phase": "train", "update": 2510, "total_env_steps": 8032000, "episode_reward": 0.2831540107727051, "value_loss": 0.004294771049171686, "policy_loss": -0.0010780281165985173, "dist_entropy": 0.6487154126167297, "actor_grad_norm": 0.07488609850406647, "critic_grad_norm": 0.014931382611393929, "ratio": 0.9998521208763123, "entropy": 0.6487154126167297, "incre_win_rate": 0.9772727272727273, "step": 2510}
{"time": 1767342896.3970826, "phase": "train", "update": 2511, "total_env_steps": 8035200, "episode_reward": 0.2831374406814575, "value_loss": 0.0033145750407129527, "policy_loss": -0.0013425765045504523, "dist_entropy": 0.684526240825653, "actor_grad_norm": 0.08956744521856308, "critic_grad_norm": 0.03690006211400032, "ratio": 0.99989253282547, "entropy": 0.684526240825653, "incre_win_rate": 0.9375, "step": 2511}
{"time": 1767342900.5436397, "phase": "train", "update": 2512, "total_env_steps": 8038400, "episode_reward": 0.28099337220191956, "value_loss": 0.0028041827026754618, "policy_loss": -0.0011997829427746964, "dist_entropy": 0.6979156017303467, "actor_grad_norm": 0.07101328670978546, "critic_grad_norm": 0.032154932618141174, "ratio": 0.9999563097953796, "entropy": 0.6979156017303467, "incre_win_rate": 0.9772727272727273, "step": 2512}
{"time": 1767342904.6792543, "phase": "train", "update": 2513, "total_env_steps": 8041600, "episode_reward": 0.2862168848514557, "value_loss": 0.0027390059549361467, "policy_loss": -0.0017766695800801812, "dist_entropy": 0.6874013543128967, "actor_grad_norm": 0.08489230275154114, "critic_grad_norm": 0.03042595088481903, "ratio": 1.0001684427261353, "entropy": 0.6874013543128967, "incre_win_rate": 0.9777777777777777, "step": 2513}
{"time": 1767342908.7788758, "phase": "train", "update": 2514, "total_env_steps": 8044800, "episode_reward": 0.28089404106140137, "value_loss": 0.0036918611731380224, "policy_loss": -0.0011821531124986961, "dist_entropy": 0.68049076795578, "actor_grad_norm": 0.0676935464143753, "critic_grad_norm": 0.019344370812177658, "ratio": 1.0000251531600952, "entropy": 0.68049076795578, "incre_win_rate": 0.9565217391304348, "step": 2514}
{"time": 1767342912.9293706, "phase": "train", "update": 2515, "total_env_steps": 8048000, "episode_reward": 0.2749001383781433, "value_loss": 0.003912729863077402, "policy_loss": -0.0015616986993245874, "dist_entropy": 0.6959141969680787, "actor_grad_norm": 0.07286233454942703, "critic_grad_norm": 0.01487145759165287, "ratio": 0.9999812245368958, "entropy": 0.6959141969680787, "incre_win_rate": 0.9347826086956522, "step": 2515}
{"time": 1767342917.0226963, "phase": "train", "update": 2516, "total_env_steps": 8051200, "episode_reward": 0.279950350522995, "value_loss": 0.003089145850390196, "policy_loss": -0.0011066389968313218, "dist_entropy": 0.6707710385322571, "actor_grad_norm": 0.06746161729097366, "critic_grad_norm": 0.01661323569715023, "ratio": 1.0001970529556274, "entropy": 0.6707710385322571, "incre_win_rate": 0.9772727272727273, "step": 2516}
{"time": 1767342921.1070979, "phase": "train", "update": 2517, "total_env_steps": 8054400, "episode_reward": 0.27519509196281433, "value_loss": 0.006931752990931272, "policy_loss": -0.00152224946737487, "dist_entropy": 0.6561490774154664, "actor_grad_norm": 0.0943853110074997, "critic_grad_norm": 0.05593424662947655, "ratio": 1.000020146369934, "entropy": 0.6561490774154664, "incre_win_rate": 0.8636363636363636, "step": 2517}
{"time": 1767342925.2158344, "phase": "train", "update": 2518, "total_env_steps": 8057600, "episode_reward": 0.26738613843917847, "value_loss": 0.007192142400890588, "policy_loss": -0.0015979221909987018, "dist_entropy": 0.6438040852546691, "actor_grad_norm": 0.08216499537229538, "critic_grad_norm": 0.03437237814068794, "ratio": 0.9999080896377563, "entropy": 0.6438040852546691, "incre_win_rate": 0.8297872340425532, "step": 2518}
{"time": 1767342929.3457463, "phase": "train", "update": 2519, "total_env_steps": 8060800, "episode_reward": 0.28070002794265747, "value_loss": 0.006746545154601336, "policy_loss": -0.00152071962934599, "dist_entropy": 0.6583972692489624, "actor_grad_norm": 0.08521357923746109, "critic_grad_norm": 0.03365912288427353, "ratio": 0.9994811415672302, "entropy": 0.6583972692489624, "incre_win_rate": 0.9130434782608695, "step": 2519}
{"time": 1767342933.4801817, "phase": "train", "update": 2520, "total_env_steps": 8064000, "episode_reward": 0.2888069450855255, "value_loss": 0.0030941620003432035, "policy_loss": -0.0007143656906890783, "dist_entropy": 0.6608288526535034, "actor_grad_norm": 0.08633525669574738, "critic_grad_norm": 0.036633480340242386, "ratio": 1.000119686126709, "entropy": 0.6608288526535034, "incre_win_rate": 1.0, "step": 2520}
{"time": 1767342937.5952728, "phase": "train", "update": 2521, "total_env_steps": 8067200, "episode_reward": 0.280977338552475, "value_loss": 0.0027728205546736716, "policy_loss": -0.0010669388915554023, "dist_entropy": 0.6739038109779358, "actor_grad_norm": 0.0780465379357338, "critic_grad_norm": 0.036780692636966705, "ratio": 0.9999565482139587, "entropy": 0.6739038109779358, "incre_win_rate": 0.9777777777777777, "step": 2521}
{"time": 1767342941.6986566, "phase": "train", "update": 2522, "total_env_steps": 8070400, "episode_reward": 0.27822381258010864, "value_loss": 0.003933678101748228, "policy_loss": -0.0009151324617469925, "dist_entropy": 0.6439257979393005, "actor_grad_norm": 0.07563158869743347, "critic_grad_norm": 0.03769640251994133, "ratio": 0.9996336102485657, "entropy": 0.6439257979393005, "incre_win_rate": 0.9333333333333333, "step": 2522}
{"time": 1767342945.8092415, "phase": "train", "update": 2523, "total_env_steps": 8073600, "episode_reward": 0.2724218964576721, "value_loss": 0.007169085089117289, "policy_loss": -0.0011582496542118293, "dist_entropy": 0.6458615064620972, "actor_grad_norm": 0.07945269346237183, "critic_grad_norm": 0.033088427037000656, "ratio": 1.0001089572906494, "entropy": 0.6458615064620972, "incre_win_rate": 0.8695652173913043, "step": 2523}
{"time": 1767342949.9178655, "phase": "train", "update": 2524, "total_env_steps": 8076800, "episode_reward": 0.28313329815864563, "value_loss": 0.0037624103017151354, "policy_loss": -0.0010148036780691428, "dist_entropy": 0.6684836506843567, "actor_grad_norm": 0.06988345831632614, "critic_grad_norm": 0.0297880657017231, "ratio": 1.000059723854065, "entropy": 0.6684836506843567, "incre_win_rate": 0.9772727272727273, "step": 2524}
{"time": 1767342954.0272453, "phase": "train", "update": 2525, "total_env_steps": 8080000, "episode_reward": 0.27014124393463135, "value_loss": 0.008501246571540833, "policy_loss": -0.0013005877658109454, "dist_entropy": 0.6561463832855224, "actor_grad_norm": 0.0738120898604393, "critic_grad_norm": 0.0784977599978447, "ratio": 0.9998793601989746, "entropy": 0.6561463832855224, "incre_win_rate": 0.8723404255319149, "step": 2525}
{"time": 1767342958.1427445, "phase": "train", "update": 2526, "total_env_steps": 8083200, "episode_reward": 0.2756223976612091, "value_loss": 0.00657378975301981, "policy_loss": -0.0012146740627017039, "dist_entropy": 0.671554696559906, "actor_grad_norm": 0.073357492685318, "critic_grad_norm": 0.04831579327583313, "ratio": 0.9995219111442566, "entropy": 0.671554696559906, "incre_win_rate": 0.9090909090909091, "step": 2526}
{"time": 1767342967.2962363, "phase": "eval", "update": 2526, "total_env_steps": 8083200, "eval_win_rate": 1.0, "eval_episode_reward": 20.0, "step": 2526}
{"time": 1767342971.366196, "phase": "train", "update": 2527, "total_env_steps": 8086400, "episode_reward": 0.2837872803211212, "value_loss": 0.002588327182456851, "policy_loss": -0.0010236468261730636, "dist_entropy": 0.693686306476593, "actor_grad_norm": 0.08315711468458176, "critic_grad_norm": 0.06594140082597733, "ratio": 1.000057578086853, "entropy": 0.693686306476593, "incre_win_rate": 0.9782608695652174, "step": 2527}
{"time": 1767342975.534079, "phase": "train", "update": 2528, "total_env_steps": 8089600, "episode_reward": 0.2787913680076599, "value_loss": 0.003543254733085632, "policy_loss": -0.0013205070080289261, "dist_entropy": 0.6704609870910645, "actor_grad_norm": 0.06830387562513351, "critic_grad_norm": 0.02055247128009796, "ratio": 0.9998838305473328, "entropy": 0.6704609870910645, "incre_win_rate": 0.9555555555555556, "step": 2528}
{"time": 1767342979.606397, "phase": "train", "update": 2529, "total_env_steps": 8092800, "episode_reward": 0.27812811732292175, "value_loss": 0.0047942308709025385, "policy_loss": -0.0013713801156896466, "dist_entropy": 0.7080221056938172, "actor_grad_norm": 0.0704692006111145, "critic_grad_norm": 0.03227520361542702, "ratio": 1.0001221895217896, "entropy": 0.7080221056938172, "incre_win_rate": 0.9148936170212766, "step": 2529}
{"time": 1767342983.6854417, "phase": "train", "update": 2530, "total_env_steps": 8096000, "episode_reward": 0.27199089527130127, "value_loss": 0.008046704996377229, "policy_loss": -0.0013443032833663437, "dist_entropy": 0.661774730682373, "actor_grad_norm": 0.07960178703069687, "critic_grad_norm": 0.05988801270723343, "ratio": 0.9998722076416016, "entropy": 0.661774730682373, "incre_win_rate": 0.8372093023255814, "step": 2530}
{"time": 1767342987.7679513, "phase": "train", "update": 2531, "total_env_steps": 8099200, "episode_reward": 0.2798349857330322, "value_loss": 0.004838864412158727, "policy_loss": -0.0010531136700009825, "dist_entropy": 0.678044068813324, "actor_grad_norm": 0.09236703813076019, "critic_grad_norm": 0.030345970764756203, "ratio": 1.0000848770141602, "entropy": 0.678044068813324, "incre_win_rate": 0.9565217391304348, "step": 2531}
{"time": 1767342991.8414319, "phase": "train", "update": 2532, "total_env_steps": 8102400, "episode_reward": 0.2730836272239685, "value_loss": 0.0050849893130362036, "policy_loss": -0.0012682432172642422, "dist_entropy": 0.6771624326705933, "actor_grad_norm": 0.07755684852600098, "critic_grad_norm": 0.026143277063965797, "ratio": 1.0000025033950806, "entropy": 0.6771624326705933, "incre_win_rate": 0.8888888888888888, "step": 2532}
{"time": 1767342995.9222825, "phase": "train", "update": 2533, "total_env_steps": 8105600, "episode_reward": 0.29248756170272827, "value_loss": 0.003604637738317251, "policy_loss": -0.0017063213526057552, "dist_entropy": 0.6928602695465088, "actor_grad_norm": 0.08592107146978378, "critic_grad_norm": 0.024730674922466278, "ratio": 0.9996880888938904, "entropy": 0.6928602695465088, "incre_win_rate": 1.0, "step": 2533}
{"time": 1767343000.0190566, "phase": "train", "update": 2534, "total_env_steps": 8108800, "episode_reward": 0.2730541527271271, "value_loss": 0.00588946919888258, "policy_loss": -0.0010542176772622368, "dist_entropy": 0.6579988241195679, "actor_grad_norm": 0.07848343998193741, "critic_grad_norm": 0.02920369803905487, "ratio": 0.9996798634529114, "entropy": 0.6579988241195679, "incre_win_rate": 0.8936170212765957, "step": 2534}
{"time": 1767343004.1020713, "phase": "train", "update": 2535, "total_env_steps": 8112000, "episode_reward": 0.2835383713245392, "value_loss": 0.0035380607936531306, "policy_loss": -0.0013562699418272928, "dist_entropy": 0.703474497795105, "actor_grad_norm": 0.09129887074232101, "critic_grad_norm": 0.02205042354762554, "ratio": 0.9999432563781738, "entropy": 0.703474497795105, "incre_win_rate": 0.9782608695652174, "step": 2535}
{"time": 1767343008.1626284, "phase": "train", "update": 2536, "total_env_steps": 8115200, "episode_reward": 0.2708888649940491, "value_loss": 0.005563791282474995, "policy_loss": -0.0012438439440458637, "dist_entropy": 0.657363772392273, "actor_grad_norm": 0.08581418544054031, "critic_grad_norm": 0.017487002536654472, "ratio": 1.0001853704452515, "entropy": 0.657363772392273, "incre_win_rate": 0.8837209302325582, "step": 2536}
{"time": 1767343012.2373185, "phase": "train", "update": 2537, "total_env_steps": 8118400, "episode_reward": 0.2796688973903656, "value_loss": 0.004436103813350201, "policy_loss": -0.0011400178256500304, "dist_entropy": 0.6699002981185913, "actor_grad_norm": 0.07060810923576355, "critic_grad_norm": 0.022006021812558174, "ratio": 0.9999011158943176, "entropy": 0.6699002981185913, "incre_win_rate": 0.9361702127659575, "step": 2537}
{"time": 1767343016.3573146, "phase": "train", "update": 2538, "total_env_steps": 8121600, "episode_reward": 0.2850605249404907, "value_loss": 0.0034115939401090146, "policy_loss": -0.0010629468133103615, "dist_entropy": 0.6623990774154663, "actor_grad_norm": 0.07500795274972916, "critic_grad_norm": 0.018197951838374138, "ratio": 0.9999212622642517, "entropy": 0.6623990774154663, "incre_win_rate": 0.9347826086956522, "step": 2538}
{"time": 1767343020.4454303, "phase": "train", "update": 2539, "total_env_steps": 8124800, "episode_reward": 0.2728450894355774, "value_loss": 0.0060673788189888, "policy_loss": -0.0011664028652823787, "dist_entropy": 0.6434335112571716, "actor_grad_norm": 0.08977793902158737, "critic_grad_norm": 0.05586227402091026, "ratio": 1.0001212358474731, "entropy": 0.6434335112571716, "incre_win_rate": 0.8863636363636364, "step": 2539}
{"time": 1767343024.5713837, "phase": "train", "update": 2540, "total_env_steps": 8128000, "episode_reward": 0.27778300642967224, "value_loss": 0.004642386082559824, "policy_loss": -0.0009106867782378459, "dist_entropy": 0.6576875925064087, "actor_grad_norm": 0.08837433904409409, "critic_grad_norm": 0.047158583998680115, "ratio": 1.0000832080841064, "entropy": 0.6576875925064087, "incre_win_rate": 0.9565217391304348, "step": 2540}
{"time": 1767343028.6244652, "phase": "train", "update": 2541, "total_env_steps": 8131200, "episode_reward": 0.27905938029289246, "value_loss": 0.00549520431086421, "policy_loss": -0.0011940004017611527, "dist_entropy": 0.6549735546112061, "actor_grad_norm": 0.08618492633104324, "critic_grad_norm": 0.03357063606381416, "ratio": 0.9998459219932556, "entropy": 0.6549735546112061, "incre_win_rate": 0.9130434782608695, "step": 2541}
{"time": 1767343032.7648637, "phase": "train", "update": 2542, "total_env_steps": 8134400, "episode_reward": 0.2819826006889343, "value_loss": 0.005415518302470446, "policy_loss": -0.001048983784768609, "dist_entropy": 0.6830848574638366, "actor_grad_norm": 0.08009039610624313, "critic_grad_norm": 0.03572835400700569, "ratio": 0.9999454617500305, "entropy": 0.6830848574638366, "incre_win_rate": 0.9545454545454546, "step": 2542}
{"time": 1767343036.876697, "phase": "train", "update": 2543, "total_env_steps": 8137600, "episode_reward": 0.28436723351478577, "value_loss": 0.005021344125270844, "policy_loss": -0.0013886958765709778, "dist_entropy": 0.6971499443054199, "actor_grad_norm": 0.0844915509223938, "critic_grad_norm": 0.03852587565779686, "ratio": 1.0004278421401978, "entropy": 0.6971499443054199, "incre_win_rate": 0.9347826086956522, "step": 2543}
{"time": 1767343040.9462192, "phase": "train", "update": 2544, "total_env_steps": 8140800, "episode_reward": 0.2731819152832031, "value_loss": 0.006744059268385172, "policy_loss": -0.0009578254614510228, "dist_entropy": 0.7014066338539123, "actor_grad_norm": 0.0760917067527771, "critic_grad_norm": 0.050626855343580246, "ratio": 0.9998631477355957, "entropy": 0.7014066338539123, "incre_win_rate": 0.9555555555555556, "step": 2544}
{"time": 1767343045.0186555, "phase": "train", "update": 2545, "total_env_steps": 8144000, "episode_reward": 0.2696600556373596, "value_loss": 0.006834407337009907, "policy_loss": -0.0013860593375536467, "dist_entropy": 0.7151047468185425, "actor_grad_norm": 0.0843268558382988, "critic_grad_norm": 0.039573829621076584, "ratio": 0.9998347163200378, "entropy": 0.7151047468185425, "incre_win_rate": 0.9111111111111111, "step": 2545}
{"time": 1767343049.1111526, "phase": "train", "update": 2546, "total_env_steps": 8147200, "episode_reward": 0.26638659834861755, "value_loss": 0.008336241357028484, "policy_loss": -0.0010331002491469122, "dist_entropy": 0.7182179808616638, "actor_grad_norm": 0.08363714069128036, "critic_grad_norm": 0.04452444612979889, "ratio": 0.9999958276748657, "entropy": 0.7182179808616638, "incre_win_rate": 0.7906976744186046, "step": 2546}
{"time": 1767343053.1796372, "phase": "train", "update": 2547, "total_env_steps": 8150400, "episode_reward": 0.2699456512928009, "value_loss": 0.009052368812263012, "policy_loss": -0.0016582308456008833, "dist_entropy": 0.7201026916503906, "actor_grad_norm": 0.12270398437976837, "critic_grad_norm": 0.031447213143110275, "ratio": 1.000194787979126, "entropy": 0.7201026916503906, "incre_win_rate": 0.8695652173913043, "step": 2547}
{"time": 1767343057.2650082, "phase": "train", "update": 2548, "total_env_steps": 8153600, "episode_reward": 0.26342612504959106, "value_loss": 0.007612158451229334, "policy_loss": -0.0011073883296376153, "dist_entropy": 0.7026183843612671, "actor_grad_norm": 0.08489104360342026, "critic_grad_norm": 0.04495326802134514, "ratio": 0.9999329447746277, "entropy": 0.7026183843612671, "incre_win_rate": 0.8181818181818182, "step": 2548}
{"time": 1767343061.3147566, "phase": "train", "update": 2549, "total_env_steps": 8156800, "episode_reward": 0.26919445395469666, "value_loss": 0.008524166606366634, "policy_loss": -0.0014570077395088532, "dist_entropy": 0.7116950988769531, "actor_grad_norm": 0.10033252090215683, "critic_grad_norm": 0.04257833585143089, "ratio": 0.9999837279319763, "entropy": 0.7116950988769531, "incre_win_rate": 0.8888888888888888, "step": 2549}
{"time": 1767343065.417242, "phase": "train", "update": 2550, "total_env_steps": 8160000, "episode_reward": 0.27007347345352173, "value_loss": 0.004373338725417853, "policy_loss": -0.0008750217347824219, "dist_entropy": 0.710049283504486, "actor_grad_norm": 0.08403026312589645, "critic_grad_norm": 0.03148823603987694, "ratio": 0.9999868273735046, "entropy": 0.710049283504486, "incre_win_rate": 0.8666666666666667, "step": 2550}
{"time": 1767343069.499707, "phase": "train", "update": 2551, "total_env_steps": 8163200, "episode_reward": 0.26619258522987366, "value_loss": 0.006690418440848589, "policy_loss": -0.0011614205355730434, "dist_entropy": 0.6881284475326538, "actor_grad_norm": 0.09420312196016312, "critic_grad_norm": 0.033606138080358505, "ratio": 0.9999486207962036, "entropy": 0.6881284475326538, "incre_win_rate": 0.8372093023255814, "step": 2551}
{"time": 1767343078.7083664, "phase": "eval", "update": 2551, "total_env_steps": 8163200, "eval_win_rate": 1.0, "eval_episode_reward": 20.0, "step": 2551}
{"time": 1767343082.7789404, "phase": "train", "update": 2552, "total_env_steps": 8166400, "episode_reward": 0.27851563692092896, "value_loss": 0.004783349577337503, "policy_loss": -0.0015091655812980776, "dist_entropy": 0.70509272813797, "actor_grad_norm": 0.09243158996105194, "critic_grad_norm": 0.046736933290958405, "ratio": 0.9998598098754883, "entropy": 0.70509272813797, "incre_win_rate": 0.9777777777777777, "step": 2552}
{"time": 1767343086.8288689, "phase": "train", "update": 2553, "total_env_steps": 8169600, "episode_reward": 0.2642301321029663, "value_loss": 0.005266240797936916, "policy_loss": -0.0010517589654511993, "dist_entropy": 0.7140764594078064, "actor_grad_norm": 0.08608882129192352, "critic_grad_norm": 0.032327163964509964, "ratio": 0.9997615218162537, "entropy": 0.7140764594078064, "incre_win_rate": 0.8409090909090909, "step": 2553}
{"time": 1767343090.9218721, "phase": "train", "update": 2554, "total_env_steps": 8172800, "episode_reward": 0.2773634195327759, "value_loss": 0.003873411100357771, "policy_loss": -0.0012837003844559547, "dist_entropy": 0.7512622117996216, "actor_grad_norm": 0.0825355052947998, "critic_grad_norm": 0.032303839921951294, "ratio": 0.9999497532844543, "entropy": 0.7512622117996216, "incre_win_rate": 0.9777777777777777, "step": 2554}
{"time": 1767343095.0361629, "phase": "train", "update": 2555, "total_env_steps": 8176000, "episode_reward": 0.26338836550712585, "value_loss": 0.008610632829368114, "policy_loss": -0.0012738943432175631, "dist_entropy": 0.6967398285865783, "actor_grad_norm": 0.08354339748620987, "critic_grad_norm": 0.0627661645412445, "ratio": 0.9997049570083618, "entropy": 0.6967398285865783, "incre_win_rate": 0.8372093023255814, "step": 2555}
{"time": 1767343099.082497, "phase": "train", "update": 2556, "total_env_steps": 8179200, "episode_reward": 0.2718481123447418, "value_loss": 0.0046552312560379505, "policy_loss": -0.0012215556709151087, "dist_entropy": 0.7130564093589783, "actor_grad_norm": 0.0830565094947815, "critic_grad_norm": 0.06237049773335457, "ratio": 0.99986332654953, "entropy": 0.7130564093589783, "incre_win_rate": 0.9555555555555556, "step": 2556}
{"time": 1767343103.1443613, "phase": "train", "update": 2557, "total_env_steps": 8182400, "episode_reward": 0.2557010352611542, "value_loss": 0.00441250940784812, "policy_loss": -0.00150557766534547, "dist_entropy": 0.7108971238136291, "actor_grad_norm": 0.09194246679544449, "critic_grad_norm": 0.053140051662921906, "ratio": 1.0005072355270386, "entropy": 0.7108971238136291, "incre_win_rate": 0.926829268292683, "step": 2557}
{"time": 1767343107.2132456, "phase": "train", "update": 2558, "total_env_steps": 8185600, "episode_reward": 0.2733278274536133, "value_loss": 0.0037647067103534935, "policy_loss": -0.0011853508196313812, "dist_entropy": 0.7029412627220154, "actor_grad_norm": 0.10682334750890732, "critic_grad_norm": 0.029242852702736855, "ratio": 0.9999744296073914, "entropy": 0.7029412627220154, "incre_win_rate": 0.9302325581395349, "step": 2558}
{"time": 1767343111.309633, "phase": "train", "update": 2559, "total_env_steps": 8188800, "episode_reward": 0.2762375771999359, "value_loss": 0.0036100513767451047, "policy_loss": -0.0008072951165942754, "dist_entropy": 0.6814247846603394, "actor_grad_norm": 0.08807121962308884, "critic_grad_norm": 0.040514446794986725, "ratio": 1.000058650970459, "entropy": 0.6814247846603394, "incre_win_rate": 0.9787234042553191, "step": 2559}
{"time": 1767343115.38473, "phase": "train", "update": 2560, "total_env_steps": 8192000, "episode_reward": 0.2763317823410034, "value_loss": 0.00249496684409678, "policy_loss": -0.0009505420661639619, "dist_entropy": 0.6941372036933899, "actor_grad_norm": 0.07944145798683167, "critic_grad_norm": 0.024798426777124405, "ratio": 0.999963104724884, "entropy": 0.6941372036933899, "incre_win_rate": 1.0, "step": 2560}
{"time": 1767343119.489425, "phase": "train", "update": 2561, "total_env_steps": 8195200, "episode_reward": 0.28368380665779114, "value_loss": 0.0026115503627806903, "policy_loss": -0.0011200442666286393, "dist_entropy": 0.6982978224754334, "actor_grad_norm": 0.08181633055210114, "critic_grad_norm": 0.05029497668147087, "ratio": 0.9999513626098633, "entropy": 0.6982978224754334, "incre_win_rate": 0.9787234042553191, "step": 2561}
{"time": 1767343123.5560453, "phase": "train", "update": 2562, "total_env_steps": 8198400, "episode_reward": 0.27801844477653503, "value_loss": 0.0022710232064127923, "policy_loss": -0.0012591884630943184, "dist_entropy": 0.6587853312492371, "actor_grad_norm": 0.08362879604101181, "critic_grad_norm": 0.04145234823226929, "ratio": 0.9998859763145447, "entropy": 0.6587853312492371, "incre_win_rate": 0.9772727272727273, "step": 2562}
{"time": 1767343127.6450512, "phase": "train", "update": 2563, "total_env_steps": 8201600, "episode_reward": 0.2810264825820923, "value_loss": 0.003126481780782342, "policy_loss": -0.0011644898687306338, "dist_entropy": 0.6675801396369934, "actor_grad_norm": 0.08241940289735794, "critic_grad_norm": 0.030420536175370216, "ratio": 0.9995579719543457, "entropy": 0.6675801396369934, "incre_win_rate": 0.9574468085106383, "step": 2563}
{"time": 1767343131.74691, "phase": "train", "update": 2564, "total_env_steps": 8204800, "episode_reward": 0.2777799069881439, "value_loss": 0.004689756408333778, "policy_loss": -0.0009555005921441761, "dist_entropy": 0.7026956796646118, "actor_grad_norm": 0.08668874204158783, "critic_grad_norm": 0.0628664493560791, "ratio": 1.0003423690795898, "entropy": 0.7026956796646118, "incre_win_rate": 0.9545454545454546, "step": 2564}
{"time": 1767343135.8569045, "phase": "train", "update": 2565, "total_env_steps": 8208000, "episode_reward": 0.26556396484375, "value_loss": 0.0051157035864889625, "policy_loss": -0.0012888519164569346, "dist_entropy": 0.6733981966972351, "actor_grad_norm": 0.0802992656826973, "critic_grad_norm": 0.07096755504608154, "ratio": 1.0000184774398804, "entropy": 0.6733981966972351, "incre_win_rate": 0.8604651162790697, "step": 2565}
{"time": 1767343139.9298751, "phase": "train", "update": 2566, "total_env_steps": 8211200, "episode_reward": 0.2701624631881714, "value_loss": 0.0056665769778192045, "policy_loss": -0.0012632197149429203, "dist_entropy": 0.6656500101089478, "actor_grad_norm": 0.07937854528427124, "critic_grad_norm": 0.04484523460268974, "ratio": 0.9997146725654602, "entropy": 0.6656500101089478, "incre_win_rate": 0.9333333333333333, "step": 2566}
{"time": 1767343144.0224547, "phase": "train", "update": 2567, "total_env_steps": 8214400, "episode_reward": 0.2719319462776184, "value_loss": 0.003978276159614325, "policy_loss": -0.0012170437467656115, "dist_entropy": 0.6828725695610046, "actor_grad_norm": 0.07830210030078888, "critic_grad_norm": 0.06346670538187027, "ratio": 1.0000567436218262, "entropy": 0.6828725695610046, "incre_win_rate": 0.9545454545454546, "step": 2567}
{"time": 1767343148.1576116, "phase": "train", "update": 2568, "total_env_steps": 8217600, "episode_reward": 0.26654645800590515, "value_loss": 0.003413712326437235, "policy_loss": -0.0012981112590843224, "dist_entropy": 0.6943398714065552, "actor_grad_norm": 0.0855245590209961, "critic_grad_norm": 0.04180620238184929, "ratio": 0.9996665120124817, "entropy": 0.6943398714065552, "incre_win_rate": 0.9772727272727273, "step": 2568}
{"time": 1767343152.231259, "phase": "train", "update": 2569, "total_env_steps": 8220800, "episode_reward": 0.27126240730285645, "value_loss": 0.004691555537283421, "policy_loss": -0.0014187264048953984, "dist_entropy": 0.7012715697288513, "actor_grad_norm": 0.09161833673715591, "critic_grad_norm": 0.07228223234415054, "ratio": 0.9997323155403137, "entropy": 0.7012715697288513, "incre_win_rate": 0.975, "step": 2569}
{"time": 1767343156.3165002, "phase": "train", "update": 2570, "total_env_steps": 8224000, "episode_reward": 0.2536480724811554, "value_loss": 0.004919075127691031, "policy_loss": -0.0017320669486565522, "dist_entropy": 0.7034287929534913, "actor_grad_norm": 0.0880313441157341, "critic_grad_norm": 0.056903231889009476, "ratio": 0.9999831318855286, "entropy": 0.7034287929534913, "incre_win_rate": 0.8636363636363636, "step": 2570}
{"time": 1767343160.3754683, "phase": "train", "update": 2571, "total_env_steps": 8227200, "episode_reward": 0.26552048325538635, "value_loss": 0.0031323366798460483, "policy_loss": -0.0014444607757354787, "dist_entropy": 0.6901106595993042, "actor_grad_norm": 0.08632715046405792, "critic_grad_norm": 0.022239698097109795, "ratio": 1.0000334978103638, "entropy": 0.6901106595993042, "incre_win_rate": 0.9545454545454546, "step": 2571}
{"time": 1767343164.4483814, "phase": "train", "update": 2572, "total_env_steps": 8230400, "episode_reward": 0.2665252685546875, "value_loss": 0.004378855414688587, "policy_loss": -0.0016134320258885282, "dist_entropy": 0.6772086262702942, "actor_grad_norm": 0.10605096817016602, "critic_grad_norm": 0.06777957081794739, "ratio": 0.9993305206298828, "entropy": 0.6772086262702942, "incre_win_rate": 0.9285714285714286, "step": 2572}
{"time": 1767343168.5457006, "phase": "train", "update": 2573, "total_env_steps": 8233600, "episode_reward": 0.2777623236179352, "value_loss": 0.003388499701395631, "policy_loss": -0.001359617156609616, "dist_entropy": 0.6866039037704468, "actor_grad_norm": 0.09398116171360016, "critic_grad_norm": 0.043347280472517014, "ratio": 1.0002235174179077, "entropy": 0.6866039037704468, "incre_win_rate": 0.9777777777777777, "step": 2573}
{"time": 1767343172.6257496, "phase": "train", "update": 2574, "total_env_steps": 8236800, "episode_reward": 0.27641141414642334, "value_loss": 0.0026969837490469217, "policy_loss": -0.0014085199485535326, "dist_entropy": 0.6853161454200745, "actor_grad_norm": 0.08690622448921204, "critic_grad_norm": 0.025989383459091187, "ratio": 1.0000320672988892, "entropy": 0.6853161454200745, "incre_win_rate": 0.9772727272727273, "step": 2574}
{"time": 1767343176.7217712, "phase": "train", "update": 2575, "total_env_steps": 8240000, "episode_reward": 0.27133744955062866, "value_loss": 0.005074835941195488, "policy_loss": -0.0012103629974674845, "dist_entropy": 0.6644065260887146, "actor_grad_norm": 0.08679918199777603, "critic_grad_norm": 0.06438538432121277, "ratio": 1.000078558921814, "entropy": 0.6644065260887146, "incre_win_rate": 0.9090909090909091, "step": 2575}
{"time": 1767343180.788364, "phase": "train", "update": 2576, "total_env_steps": 8243200, "episode_reward": 0.26566535234451294, "value_loss": 0.007586679887026548, "policy_loss": -0.001556899251855981, "dist_entropy": 0.6870634198188782, "actor_grad_norm": 0.10217026621103287, "critic_grad_norm": 0.06568729877471924, "ratio": 0.9996232390403748, "entropy": 0.6870634198188782, "incre_win_rate": 0.8444444444444444, "step": 2576}
{"time": 1767343190.1901147, "phase": "eval", "update": 2576, "total_env_steps": 8243200, "eval_win_rate": 1.0, "eval_episode_reward": 20.005794701986755, "step": 2576}
{"time": 1767343194.2471206, "phase": "train", "update": 2577, "total_env_steps": 8246400, "episode_reward": 0.2677643895149231, "value_loss": 0.0077858736738562586, "policy_loss": -0.0014027185806405385, "dist_entropy": 0.6992431163787842, "actor_grad_norm": 0.09875698387622833, "critic_grad_norm": 0.033246736973524094, "ratio": 0.9999570846557617, "entropy": 0.6992431163787842, "incre_win_rate": 0.8636363636363636, "step": 2577}
{"time": 1767343198.410026, "phase": "train", "update": 2578, "total_env_steps": 8249600, "episode_reward": 0.2772257924079895, "value_loss": 0.007280805893242359, "policy_loss": -0.0010752991476465467, "dist_entropy": 0.7133335471153259, "actor_grad_norm": 0.09928455203771591, "critic_grad_norm": 0.06693241745233536, "ratio": 1.0001940727233887, "entropy": 0.7133335471153259, "incre_win_rate": 0.9361702127659575, "step": 2578}
{"time": 1767343202.5311148, "phase": "train", "update": 2579, "total_env_steps": 8252800, "episode_reward": 0.27117133140563965, "value_loss": 0.006011107750236988, "policy_loss": -0.001417425006883377, "dist_entropy": 0.715139102935791, "actor_grad_norm": 0.0961313471198082, "critic_grad_norm": 0.03306998685002327, "ratio": 0.9998208284378052, "entropy": 0.715139102935791, "incre_win_rate": 0.9047619047619048, "step": 2579}
{"time": 1767343206.6348226, "phase": "train", "update": 2580, "total_env_steps": 8256000, "episode_reward": 0.27659767866134644, "value_loss": 0.0031575584784150124, "policy_loss": -0.0011980738896752996, "dist_entropy": 0.723170256614685, "actor_grad_norm": 0.09725107252597809, "critic_grad_norm": 0.02042526938021183, "ratio": 1.0001641511917114, "entropy": 0.723170256614685, "incre_win_rate": 0.9347826086956522, "step": 2580}
{"time": 1767343210.7513225, "phase": "train", "update": 2581, "total_env_steps": 8259200, "episode_reward": 0.28212645649909973, "value_loss": 0.0029815849848091602, "policy_loss": -0.001577061387919798, "dist_entropy": 0.7092749834060669, "actor_grad_norm": 0.09102413803339005, "critic_grad_norm": 0.013521059416234493, "ratio": 1.0001362562179565, "entropy": 0.7092749834060669, "incre_win_rate": 0.9555555555555556, "step": 2581}
{"time": 1767343214.8661108, "phase": "train", "update": 2582, "total_env_steps": 8262400, "episode_reward": 0.28332987427711487, "value_loss": 0.004684587754309177, "policy_loss": -0.0012088424504311135, "dist_entropy": 0.6866652607917786, "actor_grad_norm": 0.07114287465810776, "critic_grad_norm": 0.022959262132644653, "ratio": 1.0001128911972046, "entropy": 0.6866652607917786, "incre_win_rate": 0.9565217391304348, "step": 2582}
{"time": 1767343218.960422, "phase": "train", "update": 2583, "total_env_steps": 8265600, "episode_reward": 0.2726547122001648, "value_loss": 0.003794024046510458, "policy_loss": -0.001374498725780171, "dist_entropy": 0.675891888141632, "actor_grad_norm": 0.08979371190071106, "critic_grad_norm": 0.02207081764936447, "ratio": 0.9995891451835632, "entropy": 0.675891888141632, "incre_win_rate": 0.9318181818181818, "step": 2583}
{"time": 1767343223.048649, "phase": "train", "update": 2584, "total_env_steps": 8268800, "episode_reward": 0.27867135405540466, "value_loss": 0.0036590812262147663, "policy_loss": -0.0011310317283111716, "dist_entropy": 0.7051719188690185, "actor_grad_norm": 0.08674788475036621, "critic_grad_norm": 0.01997283287346363, "ratio": 0.999880313873291, "entropy": 0.7051719188690185, "incre_win_rate": 0.9782608695652174, "step": 2584}
{"time": 1767343227.1665115, "phase": "train", "update": 2585, "total_env_steps": 8272000, "episode_reward": 0.2729734182357788, "value_loss": 0.00406197477132082, "policy_loss": -0.0012674085369923204, "dist_entropy": 0.6850600004196167, "actor_grad_norm": 0.09711345285177231, "critic_grad_norm": 0.015317290090024471, "ratio": 1.0000195503234863, "entropy": 0.6850600004196167, "incre_win_rate": 0.9318181818181818, "step": 2585}
{"time": 1767343231.2621675, "phase": "train", "update": 2586, "total_env_steps": 8275200, "episode_reward": 0.28159356117248535, "value_loss": 0.0031615266110748053, "policy_loss": -0.0012321125461435046, "dist_entropy": 0.6881507039070129, "actor_grad_norm": 0.08218852430582047, "critic_grad_norm": 0.02437519282102585, "ratio": 1.0003957748413086, "entropy": 0.6881507039070129, "incre_win_rate": 0.9534883720930233, "step": 2586}
{"time": 1767343235.3462844, "phase": "train", "update": 2587, "total_env_steps": 8278400, "episode_reward": 0.2762086093425751, "value_loss": 0.0032113798428326846, "policy_loss": -0.0013748553740697389, "dist_entropy": 0.6618633151054383, "actor_grad_norm": 0.08859454840421677, "critic_grad_norm": 0.018397875130176544, "ratio": 1.0001845359802246, "entropy": 0.6618633151054383, "incre_win_rate": 0.9347826086956522, "step": 2587}
{"time": 1767343239.459102, "phase": "train", "update": 2588, "total_env_steps": 8281600, "episode_reward": 0.2836247980594635, "value_loss": 0.003168579610064626, "policy_loss": -0.0012882019983564419, "dist_entropy": 0.6589203715324402, "actor_grad_norm": 0.08524136990308762, "critic_grad_norm": 0.04534929618239403, "ratio": 0.9997031092643738, "entropy": 0.6589203715324402, "incre_win_rate": 1.0, "step": 2588}
{"time": 1767343243.568747, "phase": "train", "update": 2589, "total_env_steps": 8284800, "episode_reward": 0.28692880272865295, "value_loss": 0.001836674613878131, "policy_loss": -0.001149335824516129, "dist_entropy": 0.6548025965690613, "actor_grad_norm": 0.07736777514219284, "critic_grad_norm": 0.038978394120931625, "ratio": 0.9995490908622742, "entropy": 0.6548025965690613, "incre_win_rate": 1.0, "step": 2589}
{"time": 1767343247.670556, "phase": "train", "update": 2590, "total_env_steps": 8288000, "episode_reward": 0.27719631791114807, "value_loss": 0.003864103928208351, "policy_loss": -0.001460301263607633, "dist_entropy": 0.6719884634017944, "actor_grad_norm": 0.09453088790178299, "critic_grad_norm": 0.02538003958761692, "ratio": 1.0003361701965332, "entropy": 0.6719884634017944, "incre_win_rate": 0.9333333333333333, "step": 2590}
{"time": 1767343251.7728791, "phase": "train", "update": 2591, "total_env_steps": 8291200, "episode_reward": 0.2838110327720642, "value_loss": 0.004111860273405909, "policy_loss": -0.0012797680607562257, "dist_entropy": 0.6566474437713623, "actor_grad_norm": 0.07885493338108063, "critic_grad_norm": 0.03507112339138985, "ratio": 0.9999122619628906, "entropy": 0.6566474437713623, "incre_win_rate": 0.9574468085106383, "step": 2591}
{"time": 1767343255.8231034, "phase": "train", "update": 2592, "total_env_steps": 8294400, "episode_reward": 0.27634209394454956, "value_loss": 0.004347002878785133, "policy_loss": -0.0013807781623583538, "dist_entropy": 0.6516821265220643, "actor_grad_norm": 0.08724700659513474, "critic_grad_norm": 0.03063216805458069, "ratio": 0.9996817708015442, "entropy": 0.6516821265220643, "incre_win_rate": 0.9777777777777777, "step": 2592}
{"time": 1767343259.9256709, "phase": "train", "update": 2593, "total_env_steps": 8297600, "episode_reward": 0.27945780754089355, "value_loss": 0.003577042045071721, "policy_loss": -0.0016186607942030307, "dist_entropy": 0.6474807262420654, "actor_grad_norm": 0.07989156246185303, "critic_grad_norm": 0.026540786027908325, "ratio": 0.9998661875724792, "entropy": 0.6474807262420654, "incre_win_rate": 0.9534883720930233, "step": 2593}
{"time": 1767343263.9771316, "phase": "train", "update": 2594, "total_env_steps": 8300800, "episode_reward": 0.28108030557632446, "value_loss": 0.003122031269595027, "policy_loss": -0.0010676377557430783, "dist_entropy": 0.6399202227592469, "actor_grad_norm": 0.07490470260381699, "critic_grad_norm": 0.026119157671928406, "ratio": 0.9998737573623657, "entropy": 0.6399202227592469, "incre_win_rate": 0.9574468085106383, "step": 2594}
{"time": 1767343268.072934, "phase": "train", "update": 2595, "total_env_steps": 8304000, "episode_reward": 0.2900817394256592, "value_loss": 0.00168650324922055, "policy_loss": -0.001459299700221095, "dist_entropy": 0.6596861839294433, "actor_grad_norm": 0.08270639181137085, "critic_grad_norm": 0.028218304738402367, "ratio": 0.9999392628669739, "entropy": 0.6596861839294433, "incre_win_rate": 1.0, "step": 2595}
{"time": 1767343272.163781, "phase": "train", "update": 2596, "total_env_steps": 8307200, "episode_reward": 0.28595614433288574, "value_loss": 0.0025253070052713156, "policy_loss": -0.0011174348298151672, "dist_entropy": 0.659006679058075, "actor_grad_norm": 0.0794893428683281, "critic_grad_norm": 0.03298013657331467, "ratio": 0.9996256828308105, "entropy": 0.659006679058075, "incre_win_rate": 0.9782608695652174, "step": 2596}
{"time": 1767343276.2674923, "phase": "train", "update": 2597, "total_env_steps": 8310400, "episode_reward": 0.28659045696258545, "value_loss": 0.003838774608448148, "policy_loss": -0.0013534280444218894, "dist_entropy": 0.6645686626434326, "actor_grad_norm": 0.09584555774927139, "critic_grad_norm": 0.03885023295879364, "ratio": 0.9996883273124695, "entropy": 0.6645686626434326, "incre_win_rate": 0.9333333333333333, "step": 2597}
{"time": 1767343280.387085, "phase": "train", "update": 2598, "total_env_steps": 8313600, "episode_reward": 0.2747448980808258, "value_loss": 0.004563271719962359, "policy_loss": -0.002071988616708609, "dist_entropy": 0.6398557305335999, "actor_grad_norm": 0.08470350503921509, "critic_grad_norm": 0.030327482149004936, "ratio": 0.9999362826347351, "entropy": 0.6398557305335999, "incre_win_rate": 0.8913043478260869, "step": 2598}
{"time": 1767343284.478038, "phase": "train", "update": 2599, "total_env_steps": 8316800, "episode_reward": 0.28710734844207764, "value_loss": 0.00447776960209012, "policy_loss": -0.001430504091789686, "dist_entropy": 0.6501400351524353, "actor_grad_norm": 0.0796140655875206, "critic_grad_norm": 0.021472064778208733, "ratio": 0.9996218085289001, "entropy": 0.6501400351524353, "incre_win_rate": 0.9565217391304348, "step": 2599}
{"time": 1767343288.5716467, "phase": "train", "update": 2600, "total_env_steps": 8320000, "episode_reward": 0.2791897654533386, "value_loss": 0.0038701046258211138, "policy_loss": -0.0010415463876206842, "dist_entropy": 0.6708075046539307, "actor_grad_norm": 0.07137666642665863, "critic_grad_norm": 0.031798355281353, "ratio": 1.0001071691513062, "entropy": 0.6708075046539307, "incre_win_rate": 0.9565217391304348, "step": 2600}
{"time": 1767343292.6509116, "phase": "train", "update": 2601, "total_env_steps": 8323200, "episode_reward": 0.27789732813835144, "value_loss": 0.0028371565509587525, "policy_loss": -0.0014083858736796627, "dist_entropy": 0.6577265977859497, "actor_grad_norm": 0.08993802964687347, "critic_grad_norm": 0.019756464287638664, "ratio": 1.0000437498092651, "entropy": 0.6577265977859497, "incre_win_rate": 0.9545454545454546, "step": 2601}
{"time": 1767343306.941342, "phase": "eval", "update": 2601, "total_env_steps": 8323200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.723251241721854, "step": 2601}
{"time": 1767343311.0605974, "phase": "train", "update": 2602, "total_env_steps": 8326400, "episode_reward": 0.27902472019195557, "value_loss": 0.004012027103453874, "policy_loss": -0.0013484924263835296, "dist_entropy": 0.654117476940155, "actor_grad_norm": 0.07380454987287521, "critic_grad_norm": 0.022878311574459076, "ratio": 0.9999498724937439, "entropy": 0.654117476940155, "incre_win_rate": 0.9111111111111111, "step": 2602}
{"time": 1767343315.2737627, "phase": "train", "update": 2603, "total_env_steps": 8329600, "episode_reward": 0.2773085832595825, "value_loss": 0.004941936209797859, "policy_loss": -0.0011844783334254317, "dist_entropy": 0.6541621327400208, "actor_grad_norm": 0.06691383570432663, "critic_grad_norm": 0.02845091186463833, "ratio": 0.9998108148574829, "entropy": 0.6541621327400208, "incre_win_rate": 0.9347826086956522, "step": 2603}
{"time": 1767343319.4071093, "phase": "train", "update": 2604, "total_env_steps": 8332800, "episode_reward": 0.28442054986953735, "value_loss": 0.00488224932923913, "policy_loss": -0.0015162547488699828, "dist_entropy": 0.6577455997467041, "actor_grad_norm": 0.08735131472349167, "critic_grad_norm": 0.02608335018157959, "ratio": 0.9996632933616638, "entropy": 0.6577455997467041, "incre_win_rate": 0.9347826086956522, "step": 2604}
{"time": 1767343323.5108464, "phase": "train", "update": 2605, "total_env_steps": 8336000, "episode_reward": 0.2855546474456787, "value_loss": 0.003333809599280357, "policy_loss": -0.0015532101670848951, "dist_entropy": 0.6601553320884704, "actor_grad_norm": 0.07686381787061691, "critic_grad_norm": 0.029532629996538162, "ratio": 0.9998454451560974, "entropy": 0.6601553320884704, "incre_win_rate": 0.9782608695652174, "step": 2605}
{"time": 1767343327.619831, "phase": "train", "update": 2606, "total_env_steps": 8339200, "episode_reward": 0.2886175811290741, "value_loss": 0.002150689484551549, "policy_loss": -0.0012212412930949768, "dist_entropy": 0.6726128101348877, "actor_grad_norm": 0.07749826461076736, "critic_grad_norm": 0.011050236411392689, "ratio": 0.9997730255126953, "entropy": 0.6726128101348877, "incre_win_rate": 0.9787234042553191, "step": 2606}
{"time": 1767343331.7693214, "phase": "train", "update": 2607, "total_env_steps": 8342400, "episode_reward": 0.28302979469299316, "value_loss": 0.0022782938089221717, "policy_loss": -0.0013089533381261732, "dist_entropy": 0.6176568150520325, "actor_grad_norm": 0.07451506704092026, "critic_grad_norm": 0.017165634781122208, "ratio": 0.9999786615371704, "entropy": 0.6176568150520325, "incre_win_rate": 1.0, "step": 2607}
{"time": 1767343335.917764, "phase": "train", "update": 2608, "total_env_steps": 8345600, "episode_reward": 0.29702815413475037, "value_loss": 0.0015268816379830242, "policy_loss": -0.000968434627080228, "dist_entropy": 0.64108966588974, "actor_grad_norm": 0.07084282487630844, "critic_grad_norm": 0.029006868600845337, "ratio": 0.9999560713768005, "entropy": 0.64108966588974, "incre_win_rate": 1.0, "step": 2608}
{"time": 1767343340.101446, "phase": "train", "update": 2609, "total_env_steps": 8348800, "episode_reward": 0.28767797350883484, "value_loss": 0.0013710221974179149, "policy_loss": -0.0014395442907698453, "dist_entropy": 0.6214561462402344, "actor_grad_norm": 0.08509441465139389, "critic_grad_norm": 0.01795487478375435, "ratio": 1.0001035928726196, "entropy": 0.6214561462402344, "incre_win_rate": 1.0, "step": 2609}
{"time": 1767343344.212046, "phase": "train", "update": 2610, "total_env_steps": 8352000, "episode_reward": 0.28876036405563354, "value_loss": 0.0022389721125364304, "policy_loss": -0.0011779424794241323, "dist_entropy": 0.6282619833946228, "actor_grad_norm": 0.08748916536569595, "critic_grad_norm": 0.007882283069193363, "ratio": 1.0000940561294556, "entropy": 0.6282619833946228, "incre_win_rate": 0.9791666666666666, "step": 2610}
{"time": 1767343348.3382425, "phase": "train", "update": 2611, "total_env_steps": 8355200, "episode_reward": 0.28619205951690674, "value_loss": 0.003961393563076854, "policy_loss": -0.0008790067158415127, "dist_entropy": 0.6318240642547608, "actor_grad_norm": 0.0722685381770134, "critic_grad_norm": 0.030350511893630028, "ratio": 0.999947726726532, "entropy": 0.6318240642547608, "incre_win_rate": 0.9574468085106383, "step": 2611}
{"time": 1767343352.4593093, "phase": "train", "update": 2612, "total_env_steps": 8358400, "episode_reward": 0.29300087690353394, "value_loss": 0.0035541549324989317, "policy_loss": -0.0009535473921673087, "dist_entropy": 0.641629159450531, "actor_grad_norm": 0.06755208969116211, "critic_grad_norm": 0.024618301540613174, "ratio": 0.9998238682746887, "entropy": 0.641629159450531, "incre_win_rate": 0.9583333333333334, "step": 2612}
{"time": 1767343356.6281745, "phase": "train", "update": 2613, "total_env_steps": 8361600, "episode_reward": 0.293615460395813, "value_loss": 0.00490543944761157, "policy_loss": -0.0018689346152200414, "dist_entropy": 0.679931890964508, "actor_grad_norm": 0.09148084372282028, "critic_grad_norm": 0.01677827350795269, "ratio": 0.9999934434890747, "entropy": 0.679931890964508, "incre_win_rate": 0.9565217391304348, "step": 2613}
{"time": 1767343390.0511408, "phase": "train", "update": 2614, "total_env_steps": 8364800, "episode_reward": 0.27053654193878174, "value_loss": 0.06833030432462692, "policy_loss": -0.001320902317429784, "dist_entropy": 0.6454317331314087, "actor_grad_norm": 0.06767471134662628, "critic_grad_norm": 0.1916147619485855, "ratio": 1.000103235244751, "entropy": 0.6454317331314087, "incre_win_rate": 0.9767441860465116, "step": 2614}
{"time": 1767343394.1799896, "phase": "train", "update": 2615, "total_env_steps": 8368000, "episode_reward": 0.28372102975845337, "value_loss": 0.0061745566315948965, "policy_loss": -0.0011943274704499629, "dist_entropy": 0.6840837478637696, "actor_grad_norm": 0.08374994248151779, "critic_grad_norm": 0.12152814120054245, "ratio": 1.0002073049545288, "entropy": 0.6840837478637696, "incre_win_rate": 0.9333333333333333, "step": 2615}
{"time": 1767343398.3180966, "phase": "train", "update": 2616, "total_env_steps": 8371200, "episode_reward": 0.28908011317253113, "value_loss": 0.003447618242353201, "policy_loss": -0.0008343364966819422, "dist_entropy": 0.6707593202590942, "actor_grad_norm": 0.0764850601553917, "critic_grad_norm": 0.12330656498670578, "ratio": 1.000227928161621, "entropy": 0.6707593202590942, "incre_win_rate": 0.9555555555555556, "step": 2616}
{"time": 1767343402.462643, "phase": "train", "update": 2617, "total_env_steps": 8374400, "episode_reward": 0.29120033979415894, "value_loss": 0.003205130808055401, "policy_loss": -0.0015540672597909478, "dist_entropy": 0.6634458184242249, "actor_grad_norm": 0.08592100441455841, "critic_grad_norm": 0.042165085673332214, "ratio": 1.0003976821899414, "entropy": 0.6634458184242249, "incre_win_rate": 0.9782608695652174, "step": 2617}
{"time": 1767343406.6281023, "phase": "train", "update": 2618, "total_env_steps": 8377600, "episode_reward": 0.2874254882335663, "value_loss": 0.0034409258514642715, "policy_loss": -0.00112800586759505, "dist_entropy": 0.6495460629463196, "actor_grad_norm": 0.07021486014127731, "critic_grad_norm": 0.042246900498867035, "ratio": 0.9998969435691833, "entropy": 0.6495460629463196, "incre_win_rate": 0.9791666666666666, "step": 2618}
{"time": 1767343410.787591, "phase": "train", "update": 2619, "total_env_steps": 8380800, "episode_reward": 0.29192984104156494, "value_loss": 0.002250689873471856, "policy_loss": -0.0011625285605106229, "dist_entropy": 0.6656378030776977, "actor_grad_norm": 0.06621866673231125, "critic_grad_norm": 0.03988686949014664, "ratio": 0.9999491572380066, "entropy": 0.6656378030776977, "incre_win_rate": 0.9791666666666666, "step": 2619}
{"time": 1767343414.9157045, "phase": "train", "update": 2620, "total_env_steps": 8384000, "episode_reward": 0.2844236493110657, "value_loss": 0.006082509364932776, "policy_loss": -0.0014710338696886538, "dist_entropy": 0.6481809735298156, "actor_grad_norm": 0.06978265941143036, "critic_grad_norm": 0.026965279132127762, "ratio": 0.9999564290046692, "entropy": 0.6481809735298156, "incre_win_rate": 0.8936170212765957, "step": 2620}
{"time": 1767343419.037234, "phase": "train", "update": 2621, "total_env_steps": 8387200, "episode_reward": 0.2875455319881439, "value_loss": 0.003989947680383921, "policy_loss": -0.0009299687121242072, "dist_entropy": 0.6812630534172058, "actor_grad_norm": 0.07365595549345016, "critic_grad_norm": 0.04562857002019882, "ratio": 1.0003294944763184, "entropy": 0.6812630534172058, "incre_win_rate": 0.9555555555555556, "step": 2621}
{"time": 1767343423.1419115, "phase": "train", "update": 2622, "total_env_steps": 8390400, "episode_reward": 0.2883857786655426, "value_loss": 0.003984691994264722, "policy_loss": -0.0018053700528483318, "dist_entropy": 0.6515047788619995, "actor_grad_norm": 0.08520125597715378, "critic_grad_norm": 0.03884204104542732, "ratio": 1.0000437498092651, "entropy": 0.6515047788619995, "incre_win_rate": 0.9777777777777777, "step": 2622}
{"time": 1767343427.2994254, "phase": "train", "update": 2623, "total_env_steps": 8393600, "episode_reward": 0.28421252965927124, "value_loss": 0.004769052565097809, "policy_loss": -0.0009373248714276361, "dist_entropy": 0.6400201439857482, "actor_grad_norm": 0.06498170644044876, "critic_grad_norm": 0.041509922593832016, "ratio": 0.9999584555625916, "entropy": 0.6400201439857482, "incre_win_rate": 0.9574468085106383, "step": 2623}
{"time": 1767343431.4373267, "phase": "train", "update": 2624, "total_env_steps": 8396800, "episode_reward": 0.27908629179000854, "value_loss": 0.006540621723979711, "policy_loss": -0.0010437314258851416, "dist_entropy": 0.6274790167808533, "actor_grad_norm": 0.060842402279376984, "critic_grad_norm": 0.06499607861042023, "ratio": 1.0001195669174194, "entropy": 0.6274790167808533, "incre_win_rate": 0.9148936170212766, "step": 2624}
{"time": 1767343435.5223079, "phase": "train", "update": 2625, "total_env_steps": 8400000, "episode_reward": 0.2822257876396179, "value_loss": 0.00911827404052019, "policy_loss": -0.0017458598671197477, "dist_entropy": 0.6182218313217163, "actor_grad_norm": 0.08492154628038406, "critic_grad_norm": 0.04925386607646942, "ratio": 0.9999427199363708, "entropy": 0.6182218313217163, "incre_win_rate": 0.9361702127659575, "step": 2625}
{"time": 1767343439.6703732, "phase": "train", "update": 2626, "total_env_steps": 8403200, "episode_reward": 0.2926117777824402, "value_loss": 0.00507752662524581, "policy_loss": -0.0011493958142182238, "dist_entropy": 0.6491409778594971, "actor_grad_norm": 0.07349395006895065, "critic_grad_norm": 0.0894615575671196, "ratio": 1.0000091791152954, "entropy": 0.6491409778594971, "incre_win_rate": 0.9565217391304348, "step": 2626}
{"time": 1767343448.9779115, "phase": "eval", "update": 2626, "total_env_steps": 8403200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.733133278145694, "step": 2626}
{"time": 1767343453.0948384, "phase": "train", "update": 2627, "total_env_steps": 8406400, "episode_reward": 0.2831125557422638, "value_loss": 0.004384496062994003, "policy_loss": -0.0011637075525090968, "dist_entropy": 0.6326275110244751, "actor_grad_norm": 0.09282632172107697, "critic_grad_norm": 0.040261801332235336, "ratio": 1.0002903938293457, "entropy": 0.6326275110244751, "incre_win_rate": 0.9555555555555556, "step": 2627}
{"time": 1767343457.2344735, "phase": "train", "update": 2628, "total_env_steps": 8409600, "episode_reward": 0.28414785861968994, "value_loss": 0.00455645527690649, "policy_loss": -0.0009463576286282916, "dist_entropy": 0.627537214756012, "actor_grad_norm": 0.08008213341236115, "critic_grad_norm": 0.07614388316869736, "ratio": 0.9996204376220703, "entropy": 0.627537214756012, "incre_win_rate": 0.9148936170212766, "step": 2628}
{"time": 1767343461.389234, "phase": "train", "update": 2629, "total_env_steps": 8412800, "episode_reward": 0.28049567341804504, "value_loss": 0.006942884903401137, "policy_loss": -0.001716001049842575, "dist_entropy": 0.6308894991874695, "actor_grad_norm": 0.08522714674472809, "critic_grad_norm": 0.07415100187063217, "ratio": 0.9994987845420837, "entropy": 0.6308894991874695, "incre_win_rate": 0.9130434782608695, "step": 2629}
{"time": 1767343465.500329, "phase": "train", "update": 2630, "total_env_steps": 8416000, "episode_reward": 0.28962334990501404, "value_loss": 0.0032987982500344514, "policy_loss": -0.0009967699751280534, "dist_entropy": 0.6316703915596008, "actor_grad_norm": 0.07824695110321045, "critic_grad_norm": 0.07547064125537872, "ratio": 1.0002306699752808, "entropy": 0.6316703915596008, "incre_win_rate": 0.9782608695652174, "step": 2630}
{"time": 1767343469.6550148, "phase": "train", "update": 2631, "total_env_steps": 8419200, "episode_reward": 0.28121379017829895, "value_loss": 0.005336815677583218, "policy_loss": -0.0009906274050223373, "dist_entropy": 0.6431966304779053, "actor_grad_norm": 0.07156546413898468, "critic_grad_norm": 0.0489203967154026, "ratio": 0.9999143481254578, "entropy": 0.6431966304779053, "incre_win_rate": 0.8913043478260869, "step": 2631}
{"time": 1767343473.8287916, "phase": "train", "update": 2632, "total_env_steps": 8422400, "episode_reward": 0.2836475670337677, "value_loss": 0.0056377721950411795, "policy_loss": -0.0012279940118874676, "dist_entropy": 0.6582667469978333, "actor_grad_norm": 0.06804287433624268, "critic_grad_norm": 0.03912457823753357, "ratio": 0.999968945980072, "entropy": 0.6582667469978333, "incre_win_rate": 0.9565217391304348, "step": 2632}
{"time": 1767343477.9778502, "phase": "train", "update": 2633, "total_env_steps": 8425600, "episode_reward": 0.28117290139198303, "value_loss": 0.005690079368650913, "policy_loss": -0.0016072596969330278, "dist_entropy": 0.6507597804069519, "actor_grad_norm": 0.08533917367458344, "critic_grad_norm": 0.06594602018594742, "ratio": 1.0003206729888916, "entropy": 0.6507597804069519, "incre_win_rate": 0.9148936170212766, "step": 2633}
{"time": 1767343482.0963938, "phase": "train", "update": 2634, "total_env_steps": 8428800, "episode_reward": 0.28752896189689636, "value_loss": 0.0029847352765500546, "policy_loss": -0.0009583260270012772, "dist_entropy": 0.6325515151023865, "actor_grad_norm": 0.07372581958770752, "critic_grad_norm": 0.0375949889421463, "ratio": 1.0001658201217651, "entropy": 0.6325515151023865, "incre_win_rate": 0.9777777777777777, "step": 2634}
{"time": 1767343486.238536, "phase": "train", "update": 2635, "total_env_steps": 8432000, "episode_reward": 0.27955400943756104, "value_loss": 0.006968153454363346, "policy_loss": -0.00122136196876923, "dist_entropy": 0.6375332832336426, "actor_grad_norm": 0.08223897963762283, "critic_grad_norm": 0.034438829869031906, "ratio": 1.0002080202102661, "entropy": 0.6375332832336426, "incre_win_rate": 0.8888888888888888, "step": 2635}
{"time": 1767343490.383935, "phase": "train", "update": 2636, "total_env_steps": 8435200, "episode_reward": 0.2838384807109833, "value_loss": 0.006800361443310976, "policy_loss": -0.0009443625609206307, "dist_entropy": 0.652406120300293, "actor_grad_norm": 0.08211328834295273, "critic_grad_norm": 0.08283990621566772, "ratio": 0.9999346137046814, "entropy": 0.652406120300293, "incre_win_rate": 0.8958333333333334, "step": 2636}
{"time": 1767343494.4743783, "phase": "train", "update": 2637, "total_env_steps": 8438400, "episode_reward": 0.2773737609386444, "value_loss": 0.008056590054184198, "policy_loss": -0.0010816881975591387, "dist_entropy": 0.636129868030548, "actor_grad_norm": 0.07323267310857773, "critic_grad_norm": 0.0694727823138237, "ratio": 0.9998647570610046, "entropy": 0.636129868030548, "incre_win_rate": 0.851063829787234, "step": 2637}
{"time": 1767343498.6347215, "phase": "train", "update": 2638, "total_env_steps": 8441600, "episode_reward": 0.2928849160671234, "value_loss": 0.007743259612470865, "policy_loss": -0.0012891513673537248, "dist_entropy": 0.668168020248413, "actor_grad_norm": 0.08325600624084473, "critic_grad_norm": 0.06277859210968018, "ratio": 1.0000158548355103, "entropy": 0.668168020248413, "incre_win_rate": 0.9791666666666666, "step": 2638}
{"time": 1767343502.791248, "phase": "train", "update": 2639, "total_env_steps": 8444800, "episode_reward": 0.27310895919799805, "value_loss": 0.009950296021997929, "policy_loss": -0.0012921262955394753, "dist_entropy": 0.637771737575531, "actor_grad_norm": 0.08439779281616211, "critic_grad_norm": 0.08191850781440735, "ratio": 0.9998196959495544, "entropy": 0.637771737575531, "incre_win_rate": 0.8863636363636364, "step": 2639}
{"time": 1767343506.926671, "phase": "train", "update": 2640, "total_env_steps": 8448000, "episode_reward": 0.28558361530303955, "value_loss": 0.005199919361621142, "policy_loss": -0.0013404795359505783, "dist_entropy": 0.67490154504776, "actor_grad_norm": 0.07578291743993759, "critic_grad_norm": 0.10962846130132675, "ratio": 0.9999569058418274, "entropy": 0.67490154504776, "incre_win_rate": 0.9333333333333333, "step": 2640}
{"time": 1767343511.0853667, "phase": "train", "update": 2641, "total_env_steps": 8451200, "episode_reward": 0.27145591378211975, "value_loss": 0.008207223564386367, "policy_loss": -0.001270325154864338, "dist_entropy": 0.6657595276832581, "actor_grad_norm": 0.07793872803449631, "critic_grad_norm": 0.07050532102584839, "ratio": 1.0002644062042236, "entropy": 0.6657595276832581, "incre_win_rate": 0.8936170212765957, "step": 2641}
{"time": 1767343515.1882088, "phase": "train", "update": 2642, "total_env_steps": 8454400, "episode_reward": 0.27840232849121094, "value_loss": 0.006158650573343039, "policy_loss": -0.0012634684790764795, "dist_entropy": 0.6989680528640747, "actor_grad_norm": 0.08867404609918594, "critic_grad_norm": 0.04604918509721756, "ratio": 0.9997110366821289, "entropy": 0.6989680528640747, "incre_win_rate": 0.9555555555555556, "step": 2642}
{"time": 1767343519.3781583, "phase": "train", "update": 2643, "total_env_steps": 8457600, "episode_reward": 0.2893667221069336, "value_loss": 0.0035208766348659992, "policy_loss": -0.0011586363864154237, "dist_entropy": 0.716220247745514, "actor_grad_norm": 0.07827334851026535, "critic_grad_norm": 0.05267781764268875, "ratio": 0.9997520446777344, "entropy": 0.716220247745514, "incre_win_rate": 0.9782608695652174, "step": 2643}
{"time": 1767343523.5132742, "phase": "train", "update": 2644, "total_env_steps": 8460800, "episode_reward": 0.27437499165534973, "value_loss": 0.004645068012177944, "policy_loss": -0.0013287480719796462, "dist_entropy": 0.7066910743713379, "actor_grad_norm": 0.07977773994207382, "critic_grad_norm": 0.06511513888835907, "ratio": 1.0002344846725464, "entropy": 0.7066910743713379, "incre_win_rate": 0.9111111111111111, "step": 2644}
{"time": 1767343527.6496065, "phase": "train", "update": 2645, "total_env_steps": 8464000, "episode_reward": 0.27887728810310364, "value_loss": 0.004973936825990677, "policy_loss": -0.0015240586382802234, "dist_entropy": 0.6987305641174316, "actor_grad_norm": 0.09639153629541397, "critic_grad_norm": 0.015536797232925892, "ratio": 0.9999094009399414, "entropy": 0.6987305641174316, "incre_win_rate": 0.9130434782608695, "step": 2645}
{"time": 1767343531.8435204, "phase": "train", "update": 2646, "total_env_steps": 8467200, "episode_reward": 0.27702346444129944, "value_loss": 0.009190086834132671, "policy_loss": -0.0012835252855635914, "dist_entropy": 0.6812824130058288, "actor_grad_norm": 0.09023210406303406, "critic_grad_norm": 0.044906701892614365, "ratio": 0.9999398589134216, "entropy": 0.6812824130058288, "incre_win_rate": 0.8478260869565217, "step": 2646}
{"time": 1767343535.967285, "phase": "train", "update": 2647, "total_env_steps": 8470400, "episode_reward": 0.2840019762516022, "value_loss": 0.008175455592572689, "policy_loss": -0.0012529113057926367, "dist_entropy": 0.6802455186843872, "actor_grad_norm": 0.10177657753229141, "critic_grad_norm": 0.09330885857343674, "ratio": 1.000109076499939, "entropy": 0.6802455186843872, "incre_win_rate": 0.9166666666666666, "step": 2647}
{"time": 1767343540.086919, "phase": "train", "update": 2648, "total_env_steps": 8473600, "episode_reward": 0.2897806465625763, "value_loss": 0.002790435636416078, "policy_loss": -0.0010470205458259052, "dist_entropy": 0.7138775229454041, "actor_grad_norm": 0.09481754153966904, "critic_grad_norm": 0.07449863106012344, "ratio": 0.9998548626899719, "entropy": 0.7138775229454041, "incre_win_rate": 1.0, "step": 2648}
{"time": 1767343544.226878, "phase": "train", "update": 2649, "total_env_steps": 8476800, "episode_reward": 0.283948689699173, "value_loss": 0.004397031106054783, "policy_loss": -0.00111258654172417, "dist_entropy": 0.6879930973052979, "actor_grad_norm": 0.0829649567604065, "critic_grad_norm": 0.047107648104429245, "ratio": 1.0002750158309937, "entropy": 0.6879930973052979, "incre_win_rate": 0.9333333333333333, "step": 2649}
{"time": 1767343548.3953466, "phase": "train", "update": 2650, "total_env_steps": 8480000, "episode_reward": 0.2676500380039215, "value_loss": 0.020137536525726318, "policy_loss": -0.0015043774176220382, "dist_entropy": 0.7205593824386597, "actor_grad_norm": 0.10063798725605011, "critic_grad_norm": 0.14330361783504486, "ratio": 0.9998617172241211, "entropy": 0.7205593824386597, "incre_win_rate": 0.8913043478260869, "step": 2650}
{"time": 1767343552.5228455, "phase": "train", "update": 2651, "total_env_steps": 8483200, "episode_reward": 0.2688395082950592, "value_loss": 0.010906756483018398, "policy_loss": -0.0016296952678402476, "dist_entropy": 0.6779648184776306, "actor_grad_norm": 0.08267758786678314, "critic_grad_norm": 0.08645733445882797, "ratio": 0.9996839761734009, "entropy": 0.6779648184776306, "incre_win_rate": 0.8666666666666667, "step": 2651}
{"time": 1767343562.1479247, "phase": "eval", "update": 2651, "total_env_steps": 8483200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.843801738410598, "step": 2651}
{"time": 1767343566.2691436, "phase": "train", "update": 2652, "total_env_steps": 8486400, "episode_reward": 0.2845752239227295, "value_loss": 0.00953554417937994, "policy_loss": -0.0012490253656139317, "dist_entropy": 0.6971500515937805, "actor_grad_norm": 0.08160122483968735, "critic_grad_norm": 0.08227735012769699, "ratio": 1.0001376867294312, "entropy": 0.6971500515937805, "incre_win_rate": 0.9148936170212766, "step": 2652}
{"time": 1767343570.4279695, "phase": "train", "update": 2653, "total_env_steps": 8489600, "episode_reward": 0.28205713629722595, "value_loss": 0.007113521546125412, "policy_loss": -0.0010321223379509803, "dist_entropy": 0.6831221580505371, "actor_grad_norm": 0.08989442139863968, "critic_grad_norm": 0.030166838318109512, "ratio": 0.9997360110282898, "entropy": 0.6831221580505371, "incre_win_rate": 0.9333333333333333, "step": 2653}
{"time": 1767343574.5572329, "phase": "train", "update": 2654, "total_env_steps": 8492800, "episode_reward": 0.27561259269714355, "value_loss": 0.006083502434194088, "policy_loss": -0.0011595455654763499, "dist_entropy": 0.6826910495758056, "actor_grad_norm": 0.08391229808330536, "critic_grad_norm": 0.04963082820177078, "ratio": 0.9998992085456848, "entropy": 0.6826910495758056, "incre_win_rate": 0.9347826086956522, "step": 2654}
{"time": 1767343578.6951442, "phase": "train", "update": 2655, "total_env_steps": 8496000, "episode_reward": 0.2757931649684906, "value_loss": 0.004928645212203264, "policy_loss": -0.000832803657834802, "dist_entropy": 0.6653067350387574, "actor_grad_norm": 0.07077539712190628, "critic_grad_norm": 0.052259694784879684, "ratio": 0.9999797940254211, "entropy": 0.6653067350387574, "incre_win_rate": 0.9318181818181818, "step": 2655}
{"time": 1767343582.831043, "phase": "train", "update": 2656, "total_env_steps": 8499200, "episode_reward": 0.2792549431324005, "value_loss": 0.005085581075400114, "policy_loss": -0.0014293800436618654, "dist_entropy": 0.6925503492355347, "actor_grad_norm": 0.08620118349790573, "critic_grad_norm": 0.06523901969194412, "ratio": 0.9995498061180115, "entropy": 0.6925503492355347, "incre_win_rate": 0.9130434782608695, "step": 2656}
{"time": 1767343586.984258, "phase": "train", "update": 2657, "total_env_steps": 8502400, "episode_reward": 0.2802152633666992, "value_loss": 0.00513995997607708, "policy_loss": -0.0013624162813826502, "dist_entropy": 0.6978033304214477, "actor_grad_norm": 0.075936459004879, "critic_grad_norm": 0.07073511928319931, "ratio": 1.000056505203247, "entropy": 0.6978033304214477, "incre_win_rate": 0.9555555555555556, "step": 2657}
{"time": 1767343591.136944, "phase": "train", "update": 2658, "total_env_steps": 8505600, "episode_reward": 0.27817413210868835, "value_loss": 0.005459382943809032, "policy_loss": -0.001374025700740411, "dist_entropy": 0.7248993039131164, "actor_grad_norm": 0.08205821365118027, "critic_grad_norm": 0.0386471152305603, "ratio": 0.9999451637268066, "entropy": 0.7248993039131164, "incre_win_rate": 0.9347826086956522, "step": 2658}
{"time": 1767343595.294246, "phase": "train", "update": 2659, "total_env_steps": 8508800, "episode_reward": 0.2797713279724121, "value_loss": 0.0030607358086854218, "policy_loss": -0.0015941063434596003, "dist_entropy": 0.7328298926353455, "actor_grad_norm": 0.07218306511640549, "critic_grad_norm": 0.04593086615204811, "ratio": 1.000340223312378, "entropy": 0.7328298926353455, "incre_win_rate": 0.9777777777777777, "step": 2659}
{"time": 1767343599.3967733, "phase": "train", "update": 2660, "total_env_steps": 8512000, "episode_reward": 0.27693501114845276, "value_loss": 0.00531203281134367, "policy_loss": -0.0010722385622731422, "dist_entropy": 0.6929559111595154, "actor_grad_norm": 0.07459001988172531, "critic_grad_norm": 0.09837550669908524, "ratio": 0.9996687769889832, "entropy": 0.6929559111595154, "incre_win_rate": 0.9545454545454546, "step": 2660}
{"time": 1767343603.4990118, "phase": "train", "update": 2661, "total_env_steps": 8515200, "episode_reward": 0.27340230345726013, "value_loss": 0.007145437877625227, "policy_loss": -0.0014558668734142798, "dist_entropy": 0.6813567876815796, "actor_grad_norm": 0.08094768226146698, "critic_grad_norm": 0.0669984370470047, "ratio": 0.9996866583824158, "entropy": 0.6813567876815796, "incre_win_rate": 0.9090909090909091, "step": 2661}
{"time": 1767343607.5993087, "phase": "train", "update": 2662, "total_env_steps": 8518400, "episode_reward": 0.2627002000808716, "value_loss": 0.0056448220275342464, "policy_loss": -0.0010267601195256936, "dist_entropy": 0.6964016318321228, "actor_grad_norm": 0.0710814967751503, "critic_grad_norm": 0.09051573276519775, "ratio": 1.0000345706939697, "entropy": 0.6964016318321228, "incre_win_rate": 0.9302325581395349, "step": 2662}
{"time": 1767343611.7855353, "phase": "train", "update": 2663, "total_env_steps": 8521600, "episode_reward": 0.27319690585136414, "value_loss": 0.00632470054551959, "policy_loss": -0.001505750725644761, "dist_entropy": 0.6842028260231018, "actor_grad_norm": 0.08382468670606613, "critic_grad_norm": 0.05362581089138985, "ratio": 1.0001591444015503, "entropy": 0.6842028260231018, "incre_win_rate": 0.8666666666666667, "step": 2663}
{"time": 1767343615.9060302, "phase": "train", "update": 2664, "total_env_steps": 8524800, "episode_reward": 0.2676526606082916, "value_loss": 0.006491497624665499, "policy_loss": -0.0011357474745743446, "dist_entropy": 0.6893924474716187, "actor_grad_norm": 0.07495735585689545, "critic_grad_norm": 0.05144205316901207, "ratio": 0.9999716877937317, "entropy": 0.6893924474716187, "incre_win_rate": 0.8888888888888888, "step": 2664}
{"time": 1767343620.0471432, "phase": "train", "update": 2665, "total_env_steps": 8528000, "episode_reward": 0.27116721868515015, "value_loss": 0.005926510877907276, "policy_loss": -0.0013916467765376695, "dist_entropy": 0.6903119921684265, "actor_grad_norm": 0.08184321969747543, "critic_grad_norm": 0.08022137731313705, "ratio": 0.9997531771659851, "entropy": 0.6903119921684265, "incre_win_rate": 0.9090909090909091, "step": 2665}
{"time": 1767343624.1364734, "phase": "train", "update": 2666, "total_env_steps": 8531200, "episode_reward": 0.27162253856658936, "value_loss": 0.00806714929640293, "policy_loss": -0.001226329948237037, "dist_entropy": 0.7176652431488038, "actor_grad_norm": 0.07811145484447479, "critic_grad_norm": 0.05922960862517357, "ratio": 0.9997677206993103, "entropy": 0.7176652431488038, "incre_win_rate": 0.8863636363636364, "step": 2666}
{"time": 1767343628.2760088, "phase": "train", "update": 2667, "total_env_steps": 8534400, "episode_reward": 0.2736646234989166, "value_loss": 0.004346723388880491, "policy_loss": -0.001268347834469674, "dist_entropy": 0.7419397234916687, "actor_grad_norm": 0.06905294954776764, "critic_grad_norm": 0.0804135873913765, "ratio": 0.9999896883964539, "entropy": 0.7419397234916687, "incre_win_rate": 0.9782608695652174, "step": 2667}
{"time": 1767343632.4591053, "phase": "train", "update": 2668, "total_env_steps": 8537600, "episode_reward": 0.26601770520210266, "value_loss": 0.01071385871618986, "policy_loss": -0.0010862660456595562, "dist_entropy": 0.7326162576675415, "actor_grad_norm": 0.06963234394788742, "critic_grad_norm": 0.062285907566547394, "ratio": 0.9996930956840515, "entropy": 0.7326162576675415, "incre_win_rate": 0.813953488372093, "step": 2668}
{"time": 1767343636.59477, "phase": "train", "update": 2669, "total_env_steps": 8540800, "episode_reward": 0.26902681589126587, "value_loss": 0.008730288408696652, "policy_loss": -0.0014073540871152091, "dist_entropy": 0.7339216828346252, "actor_grad_norm": 0.09259755909442902, "critic_grad_norm": 0.041047561913728714, "ratio": 1.0003101825714111, "entropy": 0.7339216828346252, "incre_win_rate": 0.8478260869565217, "step": 2669}
{"time": 1767343640.735577, "phase": "train", "update": 2670, "total_env_steps": 8544000, "episode_reward": 0.26842352747917175, "value_loss": 0.00828773844987154, "policy_loss": -0.0009427392892845887, "dist_entropy": 0.7636909723281861, "actor_grad_norm": 0.08046611398458481, "critic_grad_norm": 0.08188965916633606, "ratio": 0.9999693036079407, "entropy": 0.7636909723281861, "incre_win_rate": 0.8181818181818182, "step": 2670}
{"time": 1767343644.8759077, "phase": "train", "update": 2671, "total_env_steps": 8547200, "episode_reward": 0.2668594717979431, "value_loss": 0.010229159891605378, "policy_loss": -0.001229443500424665, "dist_entropy": 0.7730733394622803, "actor_grad_norm": 0.08142495155334473, "critic_grad_norm": 0.06421323120594025, "ratio": 0.9997672438621521, "entropy": 0.7730733394622803, "incre_win_rate": 0.9302325581395349, "step": 2671}
{"time": 1767343648.95845, "phase": "train", "update": 2672, "total_env_steps": 8550400, "episode_reward": 0.2487044483423233, "value_loss": 0.012561172433197498, "policy_loss": -0.0014172114060290396, "dist_entropy": 0.7386226534843445, "actor_grad_norm": 0.08473499119281769, "critic_grad_norm": 0.048459574580192566, "ratio": 1.0000097751617432, "entropy": 0.7386226534843445, "incre_win_rate": 0.7727272727272727, "step": 2672}
{"time": 1767343653.1008873, "phase": "train", "update": 2673, "total_env_steps": 8553600, "episode_reward": 0.2698934078216553, "value_loss": 0.00507245296612382, "policy_loss": -0.0014021917129010575, "dist_entropy": 0.781744408607483, "actor_grad_norm": 0.07505761086940765, "critic_grad_norm": 0.12176728248596191, "ratio": 0.9999217391014099, "entropy": 0.781744408607483, "incre_win_rate": 0.9523809523809523, "step": 2673}
{"time": 1767343657.233528, "phase": "train", "update": 2674, "total_env_steps": 8556800, "episode_reward": 0.26326417922973633, "value_loss": 0.009414314106106759, "policy_loss": -0.001414098617388504, "dist_entropy": 0.7785238862037659, "actor_grad_norm": 0.08608982712030411, "critic_grad_norm": 0.06616898626089096, "ratio": 1.000085711479187, "entropy": 0.7785238862037659, "incre_win_rate": 0.8863636363636364, "step": 2674}
{"time": 1767343661.3720376, "phase": "train", "update": 2675, "total_env_steps": 8560000, "episode_reward": 0.268960565328598, "value_loss": 0.00605083117261529, "policy_loss": -0.0014426346485819862, "dist_entropy": 0.7811605930328369, "actor_grad_norm": 0.085656076669693, "critic_grad_norm": 0.04307540878653526, "ratio": 1.000052809715271, "entropy": 0.7811605930328369, "incre_win_rate": 0.8913043478260869, "step": 2675}
{"time": 1767343665.505836, "phase": "train", "update": 2676, "total_env_steps": 8563200, "episode_reward": 0.2660389244556427, "value_loss": 0.006099628657102585, "policy_loss": -0.0011990538559880192, "dist_entropy": 0.7670416712760926, "actor_grad_norm": 0.06919868290424347, "critic_grad_norm": 0.06972949951887131, "ratio": 0.9997526407241821, "entropy": 0.7670416712760926, "incre_win_rate": 0.9047619047619048, "step": 2676}
{"time": 1767343675.067318, "phase": "eval", "update": 2676, "total_env_steps": 8563200, "eval_win_rate": 1.0, "eval_episode_reward": 20.000827814569533, "step": 2676}
{"time": 1767343679.1689615, "phase": "train", "update": 2677, "total_env_steps": 8566400, "episode_reward": 0.26450642943382263, "value_loss": 0.006174995005130768, "policy_loss": -0.0015702113993732781, "dist_entropy": 0.7467175841331481, "actor_grad_norm": 0.07785233855247498, "critic_grad_norm": 0.04736609384417534, "ratio": 1.0000429153442383, "entropy": 0.7467175841331481, "incre_win_rate": 0.8636363636363636, "step": 2677}
{"time": 1767343683.2804468, "phase": "train", "update": 2678, "total_env_steps": 8569600, "episode_reward": 0.2652002274990082, "value_loss": 0.006812874879688025, "policy_loss": -0.0012549864992536185, "dist_entropy": 0.7122451424598694, "actor_grad_norm": 0.08897753059864044, "critic_grad_norm": 0.03737587109208107, "ratio": 0.9999898076057434, "entropy": 0.7122451424598694, "incre_win_rate": 0.9069767441860465, "step": 2678}
{"time": 1767343687.3868504, "phase": "train", "update": 2679, "total_env_steps": 8572800, "episode_reward": 0.27225059270858765, "value_loss": 0.005198284238576889, "policy_loss": -0.0011538625962771222, "dist_entropy": 0.724479341506958, "actor_grad_norm": 0.07687773555517197, "critic_grad_norm": 0.08928806334733963, "ratio": 0.9998383522033691, "entropy": 0.724479341506958, "incre_win_rate": 0.9777777777777777, "step": 2679}
{"time": 1767343691.519813, "phase": "train", "update": 2680, "total_env_steps": 8576000, "episode_reward": 0.2719138264656067, "value_loss": 0.006552404351532459, "policy_loss": -0.00126955303625067, "dist_entropy": 0.7045146226882935, "actor_grad_norm": 0.08679071813821793, "critic_grad_norm": 0.040425658226013184, "ratio": 1.000111699104309, "entropy": 0.7045146226882935, "incre_win_rate": 0.9302325581395349, "step": 2680}
{"time": 1767343695.5843978, "phase": "train", "update": 2681, "total_env_steps": 8579200, "episode_reward": 0.252318412065506, "value_loss": 0.006985187996178865, "policy_loss": -0.0013856570190426964, "dist_entropy": 0.7154058814048767, "actor_grad_norm": 0.09982992708683014, "critic_grad_norm": 0.06918022781610489, "ratio": 0.9999927878379822, "entropy": 0.7154058814048767, "incre_win_rate": 0.813953488372093, "step": 2681}
{"time": 1767343699.7105293, "phase": "train", "update": 2682, "total_env_steps": 8582400, "episode_reward": 0.27171874046325684, "value_loss": 0.006047749705612659, "policy_loss": -0.0013011510951844052, "dist_entropy": 0.7075733184814453, "actor_grad_norm": 0.09096331894397736, "critic_grad_norm": 0.04958352446556091, "ratio": 1.0001559257507324, "entropy": 0.7075733184814453, "incre_win_rate": 0.9534883720930233, "step": 2682}
{"time": 1767343703.8146122, "phase": "train", "update": 2683, "total_env_steps": 8585600, "episode_reward": 0.26116207242012024, "value_loss": 0.004964869562536478, "policy_loss": -0.0015615509958699647, "dist_entropy": 0.7215823769569397, "actor_grad_norm": 0.08548714965581894, "critic_grad_norm": 0.05793362855911255, "ratio": 0.999987781047821, "entropy": 0.7215823769569397, "incre_win_rate": 0.8863636363636364, "step": 2683}
{"time": 1767343707.9481108, "phase": "train", "update": 2684, "total_env_steps": 8588800, "episode_reward": 0.27098146080970764, "value_loss": 0.00474596843123436, "policy_loss": -0.0012103226760459052, "dist_entropy": 0.7230711221694947, "actor_grad_norm": 0.10000642389059067, "critic_grad_norm": 0.058578021824359894, "ratio": 0.9998300671577454, "entropy": 0.7230711221694947, "incre_win_rate": 0.9318181818181818, "step": 2684}
{"time": 1767343712.0481794, "phase": "train", "update": 2685, "total_env_steps": 8592000, "episode_reward": 0.2639828622341156, "value_loss": 0.006032922863960266, "policy_loss": -0.0016030980816744034, "dist_entropy": 0.6923725247383118, "actor_grad_norm": 0.09032275527715683, "critic_grad_norm": 0.039865583181381226, "ratio": 1.0000258684158325, "entropy": 0.6923725247383118, "incre_win_rate": 0.9302325581395349, "step": 2685}
{"time": 1767343716.1944997, "phase": "train", "update": 2686, "total_env_steps": 8595200, "episode_reward": 0.27868273854255676, "value_loss": 0.006666367035359144, "policy_loss": -0.0009921389268646053, "dist_entropy": 0.700278925895691, "actor_grad_norm": 0.07659018039703369, "critic_grad_norm": 0.06751874834299088, "ratio": 0.9998494982719421, "entropy": 0.700278925895691, "incre_win_rate": 0.9333333333333333, "step": 2686}
{"time": 1767343720.3426054, "phase": "train", "update": 2687, "total_env_steps": 8598400, "episode_reward": 0.27741310000419617, "value_loss": 0.0035121942404657603, "policy_loss": -0.0010704236065983252, "dist_entropy": 0.71683748960495, "actor_grad_norm": 0.07364504784345627, "critic_grad_norm": 0.030595263466238976, "ratio": 1.0000580549240112, "entropy": 0.71683748960495, "incre_win_rate": 0.9555555555555556, "step": 2687}
{"time": 1767343724.456307, "phase": "train", "update": 2688, "total_env_steps": 8601600, "episode_reward": 0.27838265895843506, "value_loss": 0.003593909228220582, "policy_loss": -0.0010098731294817752, "dist_entropy": 0.7085700750350952, "actor_grad_norm": 0.06992844492197037, "critic_grad_norm": 0.032012298703193665, "ratio": 0.999943196773529, "entropy": 0.7085700750350952, "incre_win_rate": 0.9782608695652174, "step": 2688}
{"time": 1767343728.5688071, "phase": "train", "update": 2689, "total_env_steps": 8604800, "episode_reward": 0.26856890320777893, "value_loss": 0.005644997116178274, "policy_loss": -0.0013460972401070138, "dist_entropy": 0.7243363499641419, "actor_grad_norm": 0.07676755636930466, "critic_grad_norm": 0.04994000867009163, "ratio": 1.000064730644226, "entropy": 0.7243363499641419, "incre_win_rate": 0.9069767441860465, "step": 2689}
{"time": 1767343732.710173, "phase": "train", "update": 2690, "total_env_steps": 8608000, "episode_reward": 0.2694365680217743, "value_loss": 0.005764435604214668, "policy_loss": -0.0012702590399646496, "dist_entropy": 0.729858684539795, "actor_grad_norm": 0.08307424932718277, "critic_grad_norm": 0.036746323108673096, "ratio": 1.0004026889801025, "entropy": 0.729858684539795, "incre_win_rate": 0.8863636363636364, "step": 2690}
{"time": 1767343736.8225641, "phase": "train", "update": 2691, "total_env_steps": 8611200, "episode_reward": 0.27442416548728943, "value_loss": 0.004916692990809679, "policy_loss": -0.0013511079238085698, "dist_entropy": 0.71998211145401, "actor_grad_norm": 0.0920243188738823, "critic_grad_norm": 0.03661016747355461, "ratio": 1.0000094175338745, "entropy": 0.71998211145401, "incre_win_rate": 0.9130434782608695, "step": 2691}
{"time": 1767343740.9501233, "phase": "train", "update": 2692, "total_env_steps": 8614400, "episode_reward": 0.27418822050094604, "value_loss": 0.005482829641550779, "policy_loss": -0.001269155469021399, "dist_entropy": 0.7212573170661927, "actor_grad_norm": 0.09384458512067795, "critic_grad_norm": 0.03205939382314682, "ratio": 0.9999974370002747, "entropy": 0.7212573170661927, "incre_win_rate": 0.8888888888888888, "step": 2692}
{"time": 1767343745.0903966, "phase": "train", "update": 2693, "total_env_steps": 8617600, "episode_reward": 0.26166704297065735, "value_loss": 0.00916032139211893, "policy_loss": -0.0014070715988454552, "dist_entropy": 0.7010042548179627, "actor_grad_norm": 0.07958193868398666, "critic_grad_norm": 0.07810480892658234, "ratio": 1.0002570152282715, "entropy": 0.7010042548179627, "incre_win_rate": 0.813953488372093, "step": 2693}
{"time": 1767343749.223962, "phase": "train", "update": 2694, "total_env_steps": 8620800, "episode_reward": 0.27092716097831726, "value_loss": 0.006804379727691412, "policy_loss": -0.0009602234721342029, "dist_entropy": 0.6899582147598267, "actor_grad_norm": 0.07105258852243423, "critic_grad_norm": 0.036135073751211166, "ratio": 0.9998733401298523, "entropy": 0.6899582147598267, "incre_win_rate": 0.8695652173913043, "step": 2694}
{"time": 1767343753.387747, "phase": "train", "update": 2695, "total_env_steps": 8624000, "episode_reward": 0.2784302830696106, "value_loss": 0.003412420954555273, "policy_loss": -0.0010470996187444737, "dist_entropy": 0.7200344681739808, "actor_grad_norm": 0.07109041512012482, "critic_grad_norm": 0.04362831637263298, "ratio": 1.0003471374511719, "entropy": 0.7200344681739808, "incre_win_rate": 0.9545454545454546, "step": 2695}
{"time": 1767343757.5323174, "phase": "train", "update": 2696, "total_env_steps": 8627200, "episode_reward": 0.27464455366134644, "value_loss": 0.007540737837553024, "policy_loss": -0.0017084183716522094, "dist_entropy": 0.6972693085670472, "actor_grad_norm": 0.08590022474527359, "critic_grad_norm": 0.036416225135326385, "ratio": 0.9996706247329712, "entropy": 0.6972693085670472, "incre_win_rate": 0.9111111111111111, "step": 2696}
{"time": 1767343761.6306345, "phase": "train", "update": 2697, "total_env_steps": 8630400, "episode_reward": 0.28010350465774536, "value_loss": 0.004396423045545816, "policy_loss": -0.0009612830555482787, "dist_entropy": 0.7330100893974304, "actor_grad_norm": 0.0758904442191124, "critic_grad_norm": 0.060147203505039215, "ratio": 0.9994056820869446, "entropy": 0.7330100893974304, "incre_win_rate": 0.9565217391304348, "step": 2697}
{"time": 1767343765.7569158, "phase": "train", "update": 2698, "total_env_steps": 8633600, "episode_reward": 0.2754765450954437, "value_loss": 0.006043466832488775, "policy_loss": -0.0012139987304053078, "dist_entropy": 0.7160117506980896, "actor_grad_norm": 0.068159319460392, "critic_grad_norm": 0.020344203338027, "ratio": 0.9999770522117615, "entropy": 0.7160117506980896, "incre_win_rate": 0.9111111111111111, "step": 2698}
{"time": 1767343769.8852117, "phase": "train", "update": 2699, "total_env_steps": 8636800, "episode_reward": 0.2815547585487366, "value_loss": 0.004186144284904003, "policy_loss": -0.0013049678011070043, "dist_entropy": 0.721432375907898, "actor_grad_norm": 0.07304614037275314, "critic_grad_norm": 0.03154830262064934, "ratio": 0.9999791979789734, "entropy": 0.721432375907898, "incre_win_rate": 0.9787234042553191, "step": 2699}
{"time": 1767343773.979834, "phase": "train", "update": 2700, "total_env_steps": 8640000, "episode_reward": 0.2755919098854065, "value_loss": 0.003507259301841259, "policy_loss": -0.001230827416293323, "dist_entropy": 0.714598560333252, "actor_grad_norm": 0.07174813747406006, "critic_grad_norm": 0.018570784479379654, "ratio": 0.9998989105224609, "entropy": 0.714598560333252, "incre_win_rate": 0.975609756097561, "step": 2700}
{"time": 1767343778.1374352, "phase": "train", "update": 2701, "total_env_steps": 8643200, "episode_reward": 0.2803228497505188, "value_loss": 0.0031735429540276526, "policy_loss": -0.001540994456676259, "dist_entropy": 0.7320275068283081, "actor_grad_norm": 0.09089965373277664, "critic_grad_norm": 0.034819915890693665, "ratio": 1.0000152587890625, "entropy": 0.7320275068283081, "incre_win_rate": 0.9574468085106383, "step": 2701}
{"time": 1767343787.4567065, "phase": "eval", "update": 2701, "total_env_steps": 8643200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.861754966887418, "step": 2701}
{"time": 1767343791.5402472, "phase": "train", "update": 2702, "total_env_steps": 8646400, "episode_reward": 0.2693631052970886, "value_loss": 0.005324555281549692, "policy_loss": -0.0011955567724431404, "dist_entropy": 0.6958353042602539, "actor_grad_norm": 0.08342295140028, "critic_grad_norm": 0.03155583143234253, "ratio": 1.0001620054244995, "entropy": 0.6958353042602539, "incre_win_rate": 0.8636363636363636, "step": 2702}
{"time": 1767343795.6459374, "phase": "train", "update": 2703, "total_env_steps": 8649600, "episode_reward": 0.2706782817840576, "value_loss": 0.006551193539053202, "policy_loss": -0.0009426083775691651, "dist_entropy": 0.690325653553009, "actor_grad_norm": 0.09263613075017929, "critic_grad_norm": 0.04492783546447754, "ratio": 1.000026822090149, "entropy": 0.690325653553009, "incre_win_rate": 0.8636363636363636, "step": 2703}
{"time": 1767343799.7881663, "phase": "train", "update": 2704, "total_env_steps": 8652800, "episode_reward": 0.28326570987701416, "value_loss": 0.0046906514093279835, "policy_loss": -0.0011148602834214927, "dist_entropy": 0.7103051543235779, "actor_grad_norm": 0.07537763565778732, "critic_grad_norm": 0.031794942915439606, "ratio": 1.000366449356079, "entropy": 0.7103051543235779, "incre_win_rate": 0.9361702127659575, "step": 2704}
{"time": 1767343803.972337, "phase": "train", "update": 2705, "total_env_steps": 8656000, "episode_reward": 0.2775910496711731, "value_loss": 0.005232472438365221, "policy_loss": -0.0016507070748691178, "dist_entropy": 0.6971843361854553, "actor_grad_norm": 0.0897912010550499, "critic_grad_norm": 0.028391901403665543, "ratio": 0.9996724128723145, "entropy": 0.6971843361854553, "incre_win_rate": 0.9333333333333333, "step": 2705}
{"time": 1767343808.0615897, "phase": "train", "update": 2706, "total_env_steps": 8659200, "episode_reward": 0.27909356355667114, "value_loss": 0.004386485181748867, "policy_loss": -0.0013248925805932287, "dist_entropy": 0.6549769163131713, "actor_grad_norm": 0.085090771317482, "critic_grad_norm": 0.03042101301252842, "ratio": 0.9998113512992859, "entropy": 0.6549769163131713, "incre_win_rate": 0.9565217391304348, "step": 2706}
{"time": 1767343812.2149463, "phase": "train", "update": 2707, "total_env_steps": 8662400, "episode_reward": 0.2735854983329773, "value_loss": 0.005701178871095181, "policy_loss": -0.0013737176659119553, "dist_entropy": 0.6313457489013672, "actor_grad_norm": 0.08843757957220078, "critic_grad_norm": 0.018060311675071716, "ratio": 0.9998151659965515, "entropy": 0.6313457489013672, "incre_win_rate": 0.9302325581395349, "step": 2707}
{"time": 1767343816.3338494, "phase": "train", "update": 2708, "total_env_steps": 8665600, "episode_reward": 0.2713240087032318, "value_loss": 0.007227883301675319, "policy_loss": -0.0015596901984197941, "dist_entropy": 0.6555685043334961, "actor_grad_norm": 0.08271121233701706, "critic_grad_norm": 0.0509251244366169, "ratio": 0.9997267127037048, "entropy": 0.6555685043334961, "incre_win_rate": 0.851063829787234, "step": 2708}
{"time": 1767343820.4724069, "phase": "train", "update": 2709, "total_env_steps": 8668800, "episode_reward": 0.28049564361572266, "value_loss": 0.004009688645601273, "policy_loss": -0.001254236011011045, "dist_entropy": 0.6695791840553283, "actor_grad_norm": 0.0763276070356369, "critic_grad_norm": 0.04075438156723976, "ratio": 1.0002375841140747, "entropy": 0.6695791840553283, "incre_win_rate": 0.9111111111111111, "step": 2709}
{"time": 1767343824.619734, "phase": "train", "update": 2710, "total_env_steps": 8672000, "episode_reward": 0.28865066170692444, "value_loss": 0.002298195939511061, "policy_loss": -0.001496641230550555, "dist_entropy": 0.6786761283874512, "actor_grad_norm": 0.08162643015384674, "critic_grad_norm": 0.04196988418698311, "ratio": 0.9998452067375183, "entropy": 0.6786761283874512, "incre_win_rate": 1.0, "step": 2710}
{"time": 1767343828.773817, "phase": "train", "update": 2711, "total_env_steps": 8675200, "episode_reward": 0.2863162159919739, "value_loss": 0.002154314424842596, "policy_loss": -0.0012082639143883966, "dist_entropy": 0.6677774786949158, "actor_grad_norm": 0.07989685982465744, "critic_grad_norm": 0.018909187987446785, "ratio": 0.9997591376304626, "entropy": 0.6677774786949158, "incre_win_rate": 0.9791666666666666, "step": 2711}
{"time": 1767343832.900192, "phase": "train", "update": 2712, "total_env_steps": 8678400, "episode_reward": 0.28058362007141113, "value_loss": 0.002317509613931179, "policy_loss": -0.000976945703891019, "dist_entropy": 0.6639756083488464, "actor_grad_norm": 0.0852191150188446, "critic_grad_norm": 0.01596233807504177, "ratio": 1.000254511833191, "entropy": 0.6639756083488464, "incre_win_rate": 0.9767441860465116, "step": 2712}
{"time": 1767343837.08588, "phase": "train", "update": 2713, "total_env_steps": 8681600, "episode_reward": 0.2810533940792084, "value_loss": 0.00283630071207881, "policy_loss": -0.0013649576820171205, "dist_entropy": 0.6505674004554749, "actor_grad_norm": 0.09017552435398102, "critic_grad_norm": 0.007807995658367872, "ratio": 1.0000765323638916, "entropy": 0.6505674004554749, "incre_win_rate": 0.9782608695652174, "step": 2713}
{"time": 1767343841.2402213, "phase": "train", "update": 2714, "total_env_steps": 8684800, "episode_reward": 0.27910441160202026, "value_loss": 0.0036742165219038727, "policy_loss": -0.0013423193368545584, "dist_entropy": 0.6663090229034424, "actor_grad_norm": 0.09480322897434235, "critic_grad_norm": 0.022445974871516228, "ratio": 1.000174880027771, "entropy": 0.6663090229034424, "incre_win_rate": 0.9333333333333333, "step": 2714}
{"time": 1767343845.3916898, "phase": "train", "update": 2715, "total_env_steps": 8688000, "episode_reward": 0.279837042093277, "value_loss": 0.004956102557480335, "policy_loss": -0.0009639043818317816, "dist_entropy": 0.623784863948822, "actor_grad_norm": 0.08602209389209747, "critic_grad_norm": 0.056728389114141464, "ratio": 0.9999771118164062, "entropy": 0.623784863948822, "incre_win_rate": 0.9347826086956522, "step": 2715}
{"time": 1767343849.4923553, "phase": "train", "update": 2716, "total_env_steps": 8691200, "episode_reward": 0.2704314887523651, "value_loss": 0.006412325892597437, "policy_loss": -0.0011322450923586303, "dist_entropy": 0.6281807065010071, "actor_grad_norm": 0.09279739111661911, "critic_grad_norm": 0.025904063135385513, "ratio": 0.9998262524604797, "entropy": 0.6281807065010071, "incre_win_rate": 0.8222222222222222, "step": 2716}
{"time": 1767343853.5972362, "phase": "train", "update": 2717, "total_env_steps": 8694400, "episode_reward": 0.2756255269050598, "value_loss": 0.007928789127618074, "policy_loss": -0.0012166509928846381, "dist_entropy": 0.6509718537330628, "actor_grad_norm": 0.08816488832235336, "critic_grad_norm": 0.027044817805290222, "ratio": 1.000112533569336, "entropy": 0.6509718537330628, "incre_win_rate": 0.9130434782608695, "step": 2717}
{"time": 1767343857.7410266, "phase": "train", "update": 2718, "total_env_steps": 8697600, "episode_reward": 0.2898789346218109, "value_loss": 0.0039282393176108595, "policy_loss": -0.0013471968637595922, "dist_entropy": 0.6693925499916077, "actor_grad_norm": 0.08449529856443405, "critic_grad_norm": 0.06339224427938461, "ratio": 1.0001862049102783, "entropy": 0.6693925499916077, "incre_win_rate": 0.9782608695652174, "step": 2718}
{"time": 1767343861.930446, "phase": "train", "update": 2719, "total_env_steps": 8700800, "episode_reward": 0.2748592793941498, "value_loss": 0.00369872497394681, "policy_loss": -0.0013099230352951353, "dist_entropy": 0.6611543416976928, "actor_grad_norm": 0.09662869572639465, "critic_grad_norm": 0.01660756953060627, "ratio": 0.9998539090156555, "entropy": 0.6611543416976928, "incre_win_rate": 0.9318181818181818, "step": 2719}
{"time": 1767343866.111952, "phase": "train", "update": 2720, "total_env_steps": 8704000, "episode_reward": 0.28249120712280273, "value_loss": 0.0029116223100572824, "policy_loss": -0.0014589898037236538, "dist_entropy": 0.6671199679374695, "actor_grad_norm": 0.08535640686750412, "critic_grad_norm": 0.018545247614383698, "ratio": 0.9994847178459167, "entropy": 0.6671199679374695, "incre_win_rate": 0.9565217391304348, "step": 2720}
{"time": 1767343870.2572074, "phase": "train", "update": 2721, "total_env_steps": 8707200, "episode_reward": 0.289884090423584, "value_loss": 0.0020455523626878858, "policy_loss": -0.0014794230562394262, "dist_entropy": 0.6622068166732789, "actor_grad_norm": 0.09263592213392258, "critic_grad_norm": 0.02188279666006565, "ratio": 0.9994813203811646, "entropy": 0.6622068166732789, "incre_win_rate": 0.9787234042553191, "step": 2721}
{"time": 1767343874.4218042, "phase": "train", "update": 2722, "total_env_steps": 8710400, "episode_reward": 0.2821197211742401, "value_loss": 0.0033757875207811594, "policy_loss": -0.001127409503502008, "dist_entropy": 0.63795325756073, "actor_grad_norm": 0.07717733830213547, "critic_grad_norm": 0.013369875028729439, "ratio": 0.9999960064888, "entropy": 0.63795325756073, "incre_win_rate": 0.9777777777777777, "step": 2722}
{"time": 1767343878.5122435, "phase": "train", "update": 2723, "total_env_steps": 8713600, "episode_reward": 0.2697589099407196, "value_loss": 0.005070117115974426, "policy_loss": -0.001073066436892134, "dist_entropy": 0.6488807082176209, "actor_grad_norm": 0.07987918704748154, "critic_grad_norm": 0.029522676020860672, "ratio": 0.9997500777244568, "entropy": 0.6488807082176209, "incre_win_rate": 0.9090909090909091, "step": 2723}
{"time": 1767343882.6311498, "phase": "train", "update": 2724, "total_env_steps": 8716800, "episode_reward": 0.28658217191696167, "value_loss": 0.0022011431865394115, "policy_loss": -0.0011054941394259999, "dist_entropy": 0.6342758417129517, "actor_grad_norm": 0.08615145087242126, "critic_grad_norm": 0.04184313490986824, "ratio": 0.9999967813491821, "entropy": 0.6342758417129517, "incre_win_rate": 0.9782608695652174, "step": 2724}
{"time": 1767343886.7818816, "phase": "train", "update": 2725, "total_env_steps": 8720000, "episode_reward": 0.28238099813461304, "value_loss": 0.0029645116068422795, "policy_loss": -0.0012752895802819353, "dist_entropy": 0.6372559070587158, "actor_grad_norm": 0.07472412288188934, "critic_grad_norm": 0.02282854914665222, "ratio": 1.0002163648605347, "entropy": 0.6372559070587158, "incre_win_rate": 0.9361702127659575, "step": 2725}
{"time": 1767343890.9768178, "phase": "train", "update": 2726, "total_env_steps": 8723200, "episode_reward": 0.28469783067703247, "value_loss": 0.002629628637805581, "policy_loss": -0.0018200570725312559, "dist_entropy": 0.6693522334098816, "actor_grad_norm": 0.09371085464954376, "critic_grad_norm": 0.034221548587083817, "ratio": 0.9998245239257812, "entropy": 0.6693522334098816, "incre_win_rate": 0.9782608695652174, "step": 2726}
{"time": 1767343900.398974, "phase": "eval", "update": 2726, "total_env_steps": 8723200, "eval_win_rate": 1.0, "eval_episode_reward": 20.002379966887418, "step": 2726}
{"time": 1767343904.5431309, "phase": "train", "update": 2727, "total_env_steps": 8726400, "episode_reward": 0.28748759627342224, "value_loss": 0.002093034842982888, "policy_loss": -0.001237766309128574, "dist_entropy": 0.668557608127594, "actor_grad_norm": 0.08154040575027466, "critic_grad_norm": 0.010895210318267345, "ratio": 1.0001131296157837, "entropy": 0.668557608127594, "incre_win_rate": 0.9782608695652174, "step": 2727}
{"time": 1767343908.7062054, "phase": "train", "update": 2728, "total_env_steps": 8729600, "episode_reward": 0.286888986825943, "value_loss": 0.004519396834075451, "policy_loss": -0.0009791116000556598, "dist_entropy": 0.6442135453224183, "actor_grad_norm": 0.06165754422545433, "critic_grad_norm": 0.013033277355134487, "ratio": 1.0000399351119995, "entropy": 0.6442135453224183, "incre_win_rate": 0.9375, "step": 2728}
{"time": 1767343912.8082705, "phase": "train", "update": 2729, "total_env_steps": 8732800, "episode_reward": 0.27334022521972656, "value_loss": 0.0068112176842987536, "policy_loss": -0.001591971714589846, "dist_entropy": 0.640242338180542, "actor_grad_norm": 0.0964297279715538, "critic_grad_norm": 0.055112432688474655, "ratio": 1.0001392364501953, "entropy": 0.640242338180542, "incre_win_rate": 0.8837209302325582, "step": 2729}
{"time": 1767343916.9488206, "phase": "train", "update": 2730, "total_env_steps": 8736000, "episode_reward": 0.2874544560909271, "value_loss": 0.003843596717342734, "policy_loss": -0.001404192009353622, "dist_entropy": 0.6146989226341247, "actor_grad_norm": 0.08282285183668137, "critic_grad_norm": 0.054484207183122635, "ratio": 0.9994263052940369, "entropy": 0.6146989226341247, "incre_win_rate": 0.9565217391304348, "step": 2730}
{"time": 1767343921.1112504, "phase": "train", "update": 2731, "total_env_steps": 8739200, "episode_reward": 0.29063743352890015, "value_loss": 0.002672796929255128, "policy_loss": -0.0010039125777272062, "dist_entropy": 0.6450568556785583, "actor_grad_norm": 0.08011233806610107, "critic_grad_norm": 0.05359312891960144, "ratio": 1.0000150203704834, "entropy": 0.6450568556785583, "incre_win_rate": 1.0, "step": 2731}
{"time": 1767343925.3309915, "phase": "train", "update": 2732, "total_env_steps": 8742400, "episode_reward": 0.27658629417419434, "value_loss": 0.004701520781964064, "policy_loss": -0.0015900275890256665, "dist_entropy": 0.6327438950538635, "actor_grad_norm": 0.08161414414644241, "critic_grad_norm": 0.0369437038898468, "ratio": 0.9999896287918091, "entropy": 0.6327438950538635, "incre_win_rate": 0.9090909090909091, "step": 2732}
{"time": 1767343929.466242, "phase": "train", "update": 2733, "total_env_steps": 8745600, "episode_reward": 0.28879034519195557, "value_loss": 0.002809256734326482, "policy_loss": -0.0009160266086254865, "dist_entropy": 0.6598456978797913, "actor_grad_norm": 0.07951807230710983, "critic_grad_norm": 0.012523806653916836, "ratio": 1.0004198551177979, "entropy": 0.6598456978797913, "incre_win_rate": 0.9787234042553191, "step": 2733}
{"time": 1767343933.5936158, "phase": "train", "update": 2734, "total_env_steps": 8748800, "episode_reward": 0.28048428893089294, "value_loss": 0.00654899375513196, "policy_loss": -0.0013551756303122886, "dist_entropy": 0.6145053505897522, "actor_grad_norm": 0.07966449111700058, "critic_grad_norm": 0.025020405650138855, "ratio": 0.999626636505127, "entropy": 0.6145053505897522, "incre_win_rate": 0.9347826086956522, "step": 2734}
{"time": 1767343937.7459185, "phase": "train", "update": 2735, "total_env_steps": 8752000, "episode_reward": 0.28245028853416443, "value_loss": 0.0050347096286714075, "policy_loss": -0.0008335333146092694, "dist_entropy": 0.6303086161613465, "actor_grad_norm": 0.06539490073919296, "critic_grad_norm": 0.01776192896068096, "ratio": 1.000104308128357, "entropy": 0.6303086161613465, "incre_win_rate": 0.9361702127659575, "step": 2735}
{"time": 1767343941.854141, "phase": "train", "update": 2736, "total_env_steps": 8755200, "episode_reward": 0.2755148112773895, "value_loss": 0.005019214935600758, "policy_loss": -0.0013460189632780839, "dist_entropy": 0.624701452255249, "actor_grad_norm": 0.07675133645534515, "critic_grad_norm": 0.02889903262257576, "ratio": 0.9999452829360962, "entropy": 0.624701452255249, "incre_win_rate": 0.9111111111111111, "step": 2736}
{"time": 1767343946.0101812, "phase": "train", "update": 2737, "total_env_steps": 8758400, "episode_reward": 0.2837086021900177, "value_loss": 0.004417531378567219, "policy_loss": -0.0011906161710228957, "dist_entropy": 0.6608041286468506, "actor_grad_norm": 0.07561440020799637, "critic_grad_norm": 0.03946259617805481, "ratio": 1.0000554323196411, "entropy": 0.6608041286468506, "incre_win_rate": 0.9777777777777777, "step": 2737}
{"time": 1767343950.1748412, "phase": "train", "update": 2738, "total_env_steps": 8761600, "episode_reward": 0.28665149211883545, "value_loss": 0.002562484238296747, "policy_loss": -0.0010508548631570137, "dist_entropy": 0.6702783823013305, "actor_grad_norm": 0.08461008220911026, "critic_grad_norm": 0.041185058653354645, "ratio": 0.9999995231628418, "entropy": 0.6702783823013305, "incre_win_rate": 1.0, "step": 2738}
{"time": 1767343954.3348265, "phase": "train", "update": 2739, "total_env_steps": 8764800, "episode_reward": 0.2878642678260803, "value_loss": 0.0027360151987522842, "policy_loss": -0.0016777585647936633, "dist_entropy": 0.6465391755104065, "actor_grad_norm": 0.09538553655147552, "critic_grad_norm": 0.03170642629265785, "ratio": 0.9999038577079773, "entropy": 0.6465391755104065, "incre_win_rate": 1.0, "step": 2739}
{"time": 1767343958.4670506, "phase": "train", "update": 2740, "total_env_steps": 8768000, "episode_reward": 0.28288906812667847, "value_loss": 0.004032815620303154, "policy_loss": -0.001190303388912639, "dist_entropy": 0.6607196211814881, "actor_grad_norm": 0.08469018340110779, "critic_grad_norm": 0.022778738290071487, "ratio": 1.000368356704712, "entropy": 0.6607196211814881, "incre_win_rate": 0.9361702127659575, "step": 2740}
{"time": 1767343962.5453644, "phase": "train", "update": 2741, "total_env_steps": 8771200, "episode_reward": 0.2756984829902649, "value_loss": 0.006239375937730074, "policy_loss": -0.001171487360689838, "dist_entropy": 0.6317878723144531, "actor_grad_norm": 0.07223653793334961, "critic_grad_norm": 0.038912396878004074, "ratio": 0.9998319745063782, "entropy": 0.6317878723144531, "incre_win_rate": 0.8571428571428571, "step": 2741}
{"time": 1767343966.6517222, "phase": "train", "update": 2742, "total_env_steps": 8774400, "episode_reward": 0.2759757936000824, "value_loss": 0.006185498647391796, "policy_loss": -0.0011477728941244436, "dist_entropy": 0.64077730178833, "actor_grad_norm": 0.07229547947645187, "critic_grad_norm": 0.022856488823890686, "ratio": 0.9997528195381165, "entropy": 0.64077730178833, "incre_win_rate": 0.9166666666666666, "step": 2742}
{"time": 1767343970.7884743, "phase": "train", "update": 2743, "total_env_steps": 8777600, "episode_reward": 0.2778714895248413, "value_loss": 0.004153081588447094, "policy_loss": -0.0013732033062410665, "dist_entropy": 0.6422677874565125, "actor_grad_norm": 0.09974972158670425, "critic_grad_norm": 0.018160974606871605, "ratio": 1.000100016593933, "entropy": 0.6422677874565125, "incre_win_rate": 0.9111111111111111, "step": 2743}
{"time": 1767343974.9432473, "phase": "train", "update": 2744, "total_env_steps": 8780800, "episode_reward": 0.2958526611328125, "value_loss": 0.002728377003222704, "policy_loss": -0.0013436074499121986, "dist_entropy": 0.6557160496711731, "actor_grad_norm": 0.08030795305967331, "critic_grad_norm": 0.021302348002791405, "ratio": 1.0001232624053955, "entropy": 0.6557160496711731, "incre_win_rate": 1.0, "step": 2744}
{"time": 1767343979.084035, "phase": "train", "update": 2745, "total_env_steps": 8784000, "episode_reward": 0.29599130153656006, "value_loss": 0.0020757155492901803, "policy_loss": -0.0013078234399884537, "dist_entropy": 0.6553743600845336, "actor_grad_norm": 0.08522402495145798, "critic_grad_norm": 0.013945057056844234, "ratio": 1.0001076459884644, "entropy": 0.6553743600845336, "incre_win_rate": 0.9791666666666666, "step": 2745}
{"time": 1767343983.1823995, "phase": "train", "update": 2746, "total_env_steps": 8787200, "episode_reward": 0.27074190974235535, "value_loss": 0.007585668005049229, "policy_loss": -0.0012199676131809055, "dist_entropy": 0.6343685150146484, "actor_grad_norm": 0.08078660815954208, "critic_grad_norm": 0.06894480437040329, "ratio": 0.9999025464057922, "entropy": 0.6343685150146484, "incre_win_rate": 0.8636363636363636, "step": 2746}
{"time": 1767343987.424155, "phase": "train", "update": 2747, "total_env_steps": 8790400, "episode_reward": 0.2846440374851227, "value_loss": 0.003479911759495735, "policy_loss": -0.0010748017124839748, "dist_entropy": 0.6200675249099732, "actor_grad_norm": 0.0770590528845787, "critic_grad_norm": 0.041804227977991104, "ratio": 1.0000771284103394, "entropy": 0.6200675249099732, "incre_win_rate": 0.9777777777777777, "step": 2747}
{"time": 1767343991.5444813, "phase": "train", "update": 2748, "total_env_steps": 8793600, "episode_reward": 0.28911423683166504, "value_loss": 0.0032530587632209063, "policy_loss": -0.001093196309519584, "dist_entropy": 0.6202738165855408, "actor_grad_norm": 0.07402431964874268, "critic_grad_norm": 0.038478072732686996, "ratio": 1.000495195388794, "entropy": 0.6202738165855408, "incre_win_rate": 0.9782608695652174, "step": 2748}
{"time": 1767343995.7402124, "phase": "train", "update": 2749, "total_env_steps": 8796800, "episode_reward": 0.29472681879997253, "value_loss": 0.0022133342456072567, "policy_loss": -0.001229006169770841, "dist_entropy": 0.6352394461631775, "actor_grad_norm": 0.08271314948797226, "critic_grad_norm": 0.029932832345366478, "ratio": 1.0002169609069824, "entropy": 0.6352394461631775, "incre_win_rate": 1.0, "step": 2749}
{"time": 1767343999.8871496, "phase": "train", "update": 2750, "total_env_steps": 8800000, "episode_reward": 0.28267383575439453, "value_loss": 0.0039228253532201055, "policy_loss": -0.0011736172579546178, "dist_entropy": 0.6647801041603089, "actor_grad_norm": 0.09284781664609909, "critic_grad_norm": 0.04493239149451256, "ratio": 1.0000032186508179, "entropy": 0.6647801041603089, "incre_win_rate": 0.9555555555555556, "step": 2750}
{"time": 1767344004.0013318, "phase": "train", "update": 2751, "total_env_steps": 8803200, "episode_reward": 0.2790924906730652, "value_loss": 0.005416156630963087, "policy_loss": -0.0015700226921378402, "dist_entropy": 0.6465016365051269, "actor_grad_norm": 0.0907798632979393, "critic_grad_norm": 0.057969607412815094, "ratio": 1.0000066757202148, "entropy": 0.6465016365051269, "incre_win_rate": 0.9130434782608695, "step": 2751}
{"time": 1767344013.12496, "phase": "eval", "update": 2751, "total_env_steps": 8803200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.841473509933778, "step": 2751}
{"time": 1767344017.28202, "phase": "train", "update": 2752, "total_env_steps": 8806400, "episode_reward": 0.28531455993652344, "value_loss": 0.004107591882348061, "policy_loss": -0.0014971175613439414, "dist_entropy": 0.6276219964027405, "actor_grad_norm": 0.08606269210577011, "critic_grad_norm": 0.03673260658979416, "ratio": 1.000019907951355, "entropy": 0.6276219964027405, "incre_win_rate": 0.9565217391304348, "step": 2752}
{"time": 1767344021.422657, "phase": "train", "update": 2753, "total_env_steps": 8809600, "episode_reward": 0.29463991522789, "value_loss": 0.0024722910951822997, "policy_loss": -0.0008647401534162214, "dist_entropy": 0.6584664344787597, "actor_grad_norm": 0.08964209258556366, "critic_grad_norm": 0.045545052736997604, "ratio": 0.999997615814209, "entropy": 0.6584664344787597, "incre_win_rate": 0.9791666666666666, "step": 2753}
{"time": 1767344025.5969374, "phase": "train", "update": 2754, "total_env_steps": 8812800, "episode_reward": 0.2894076108932495, "value_loss": 0.002954376908019185, "policy_loss": -0.0011014594611381766, "dist_entropy": 0.6660068988800049, "actor_grad_norm": 0.09333398193120956, "critic_grad_norm": 0.01847652532160282, "ratio": 0.9997426271438599, "entropy": 0.6660068988800049, "incre_win_rate": 0.9782608695652174, "step": 2754}
{"time": 1767344029.7118921, "phase": "train", "update": 2755, "total_env_steps": 8816000, "episode_reward": 0.28796979784965515, "value_loss": 0.0018977262545377017, "policy_loss": -0.000995573181101861, "dist_entropy": 0.66718510389328, "actor_grad_norm": 0.07301994413137436, "critic_grad_norm": 0.03347724676132202, "ratio": 1.0000871419906616, "entropy": 0.66718510389328, "incre_win_rate": 0.9777777777777777, "step": 2755}
{"time": 1767344033.8029423, "phase": "train", "update": 2756, "total_env_steps": 8819200, "episode_reward": 0.2806146740913391, "value_loss": 0.002640049671754241, "policy_loss": -0.0010283824905815918, "dist_entropy": 0.6686416268348694, "actor_grad_norm": 0.07341461628675461, "critic_grad_norm": 0.03424832224845886, "ratio": 0.9997164011001587, "entropy": 0.6686416268348694, "incre_win_rate": 0.9782608695652174, "step": 2756}
{"time": 1767344037.9128308, "phase": "train", "update": 2757, "total_env_steps": 8822400, "episode_reward": 0.281804621219635, "value_loss": 0.0032676263712346555, "policy_loss": -0.0009065384685527534, "dist_entropy": 0.6767809987068176, "actor_grad_norm": 0.07306670397520065, "critic_grad_norm": 0.027185523882508278, "ratio": 1.0000890493392944, "entropy": 0.6767809987068176, "incre_win_rate": 0.9777777777777777, "step": 2757}
{"time": 1767344042.0750222, "phase": "train", "update": 2758, "total_env_steps": 8825600, "episode_reward": 0.27759984135627747, "value_loss": 0.0036124382633715866, "policy_loss": -0.0013105927656891225, "dist_entropy": 0.6487173557281494, "actor_grad_norm": 0.0933089405298233, "critic_grad_norm": 0.03049088828265667, "ratio": 1.0002444982528687, "entropy": 0.6487173557281494, "incre_win_rate": 0.9555555555555556, "step": 2758}
{"time": 1767344046.1935709, "phase": "train", "update": 2759, "total_env_steps": 8828800, "episode_reward": 0.2534623444080353, "value_loss": 0.006251943483948708, "policy_loss": -0.0007530989285221779, "dist_entropy": 0.6542725920677185, "actor_grad_norm": 0.07223089039325714, "critic_grad_norm": 0.046019166707992554, "ratio": 0.9996404051780701, "entropy": 0.6542725920677185, "incre_win_rate": 0.8409090909090909, "step": 2759}
{"time": 1767344050.3404055, "phase": "train", "update": 2760, "total_env_steps": 8832000, "episode_reward": 0.2806012034416199, "value_loss": 0.003019046178087592, "policy_loss": -0.0014091343998758887, "dist_entropy": 0.699709701538086, "actor_grad_norm": 0.08264466375112534, "critic_grad_norm": 0.026349592953920364, "ratio": 0.9999858736991882, "entropy": 0.699709701538086, "incre_win_rate": 0.9761904761904762, "step": 2760}
{"time": 1767344054.4714093, "phase": "train", "update": 2761, "total_env_steps": 8835200, "episode_reward": 0.28261587023735046, "value_loss": 0.003823103429749608, "policy_loss": -0.0009577992868038621, "dist_entropy": 0.6520490527153016, "actor_grad_norm": 0.08224319666624069, "critic_grad_norm": 0.03625165671110153, "ratio": 0.9996946454048157, "entropy": 0.6520490527153016, "incre_win_rate": 0.9565217391304348, "step": 2761}
{"time": 1767344058.5928442, "phase": "train", "update": 2762, "total_env_steps": 8838400, "episode_reward": 0.2802462875843048, "value_loss": 0.004462371580302715, "policy_loss": -0.0012195789093293996, "dist_entropy": 0.6373181819915772, "actor_grad_norm": 0.08259329199790955, "critic_grad_norm": 0.037022702395915985, "ratio": 1.0003396272659302, "entropy": 0.6373181819915772, "incre_win_rate": 0.9782608695652174, "step": 2762}
{"time": 1767344062.7167377, "phase": "train", "update": 2763, "total_env_steps": 8841600, "episode_reward": 0.2845710813999176, "value_loss": 0.0033470508176833393, "policy_loss": -0.0010688511036960335, "dist_entropy": 0.6664491891860962, "actor_grad_norm": 0.07366044819355011, "critic_grad_norm": 0.06861663609743118, "ratio": 1.0001024007797241, "entropy": 0.6664491891860962, "incre_win_rate": 0.9782608695652174, "step": 2763}
{"time": 1767344066.8700404, "phase": "train", "update": 2764, "total_env_steps": 8844800, "episode_reward": 0.2926076054573059, "value_loss": 0.002068780898116529, "policy_loss": -0.0011038584547730323, "dist_entropy": 0.6792968511581421, "actor_grad_norm": 0.07476881891489029, "critic_grad_norm": 0.049573179334402084, "ratio": 0.999869167804718, "entropy": 0.6792968511581421, "incre_win_rate": 1.0, "step": 2764}
{"time": 1767344070.9956744, "phase": "train", "update": 2765, "total_env_steps": 8848000, "episode_reward": 0.27808621525764465, "value_loss": 0.003956751991063356, "policy_loss": -0.001478841381015883, "dist_entropy": 0.6577632427215576, "actor_grad_norm": 0.08518265187740326, "critic_grad_norm": 0.060599323362112045, "ratio": 1.0000488758087158, "entropy": 0.6577632427215576, "incre_win_rate": 0.9318181818181818, "step": 2765}
{"time": 1767344075.1497135, "phase": "train", "update": 2766, "total_env_steps": 8851200, "episode_reward": 0.28080710768699646, "value_loss": 0.002735492819920182, "policy_loss": -0.001097249791742172, "dist_entropy": 0.674377727508545, "actor_grad_norm": 0.06643368303775787, "critic_grad_norm": 0.0587119460105896, "ratio": 0.9999009370803833, "entropy": 0.674377727508545, "incre_win_rate": 0.9782608695652174, "step": 2766}
{"time": 1767344079.2817993, "phase": "train", "update": 2767, "total_env_steps": 8854400, "episode_reward": 0.27530109882354736, "value_loss": 0.005050041433423758, "policy_loss": -0.0014437894113967786, "dist_entropy": 0.6703977465629578, "actor_grad_norm": 0.08417155593633652, "critic_grad_norm": 0.03794084116816521, "ratio": 0.9993332028388977, "entropy": 0.6703977465629578, "incre_win_rate": 0.8888888888888888, "step": 2767}
{"time": 1767344083.4574533, "phase": "train", "update": 2768, "total_env_steps": 8857600, "episode_reward": 0.28025662899017334, "value_loss": 0.0035483155399560927, "policy_loss": -0.001159054120910241, "dist_entropy": 0.6801519870758057, "actor_grad_norm": 0.07878492772579193, "critic_grad_norm": 0.07689129561185837, "ratio": 1.0002301931381226, "entropy": 0.6801519870758057, "incre_win_rate": 0.9772727272727273, "step": 2768}
{"time": 1767344087.6072862, "phase": "train", "update": 2769, "total_env_steps": 8860800, "episode_reward": 0.28784769773483276, "value_loss": 0.002389841713011265, "policy_loss": -0.0012179546420928223, "dist_entropy": 0.6753289699554443, "actor_grad_norm": 0.07957115024328232, "critic_grad_norm": 0.049218785017728806, "ratio": 1.0001487731933594, "entropy": 0.6753289699554443, "incre_win_rate": 0.9782608695652174, "step": 2769}
{"time": 1767344091.7579894, "phase": "train", "update": 2770, "total_env_steps": 8864000, "episode_reward": 0.28854718804359436, "value_loss": 0.0019692631205543874, "policy_loss": -0.0013211837027796492, "dist_entropy": 0.69980788230896, "actor_grad_norm": 0.09056494385004044, "critic_grad_norm": 0.021539991721510887, "ratio": 1.0001026391983032, "entropy": 0.69980788230896, "incre_win_rate": 1.0, "step": 2770}
{"time": 1767344095.875996, "phase": "train", "update": 2771, "total_env_steps": 8867200, "episode_reward": 0.2861713767051697, "value_loss": 0.00216990583576262, "policy_loss": -0.0014169673112342629, "dist_entropy": 0.6617820024490356, "actor_grad_norm": 0.09758318215608597, "critic_grad_norm": 0.04556073248386383, "ratio": 0.9998856782913208, "entropy": 0.6617820024490356, "incre_win_rate": 0.9787234042553191, "step": 2771}
{"time": 1767344100.0121017, "phase": "train", "update": 2772, "total_env_steps": 8870400, "episode_reward": 0.2889072895050049, "value_loss": 0.001324873138219118, "policy_loss": -0.0009624853214237561, "dist_entropy": 0.6720412135124206, "actor_grad_norm": 0.08718404918909073, "critic_grad_norm": 0.023452429100871086, "ratio": 1.0002193450927734, "entropy": 0.6720412135124206, "incre_win_rate": 1.0, "step": 2772}
{"time": 1767344104.129389, "phase": "train", "update": 2773, "total_env_steps": 8873600, "episode_reward": 0.288158118724823, "value_loss": 0.002359930379316211, "policy_loss": -0.0008786702226728949, "dist_entropy": 0.6387726426124573, "actor_grad_norm": 0.07878255099058151, "critic_grad_norm": 0.032113272696733475, "ratio": 0.9999367594718933, "entropy": 0.6387726426124573, "incre_win_rate": 0.9565217391304348, "step": 2773}
{"time": 1767344108.291415, "phase": "train", "update": 2774, "total_env_steps": 8876800, "episode_reward": 0.2869272530078888, "value_loss": 0.003328699292615056, "policy_loss": -0.001211555787427443, "dist_entropy": 0.6404443264007569, "actor_grad_norm": 0.0701567605137825, "critic_grad_norm": 0.03002183511853218, "ratio": 0.9998853802680969, "entropy": 0.6404443264007569, "incre_win_rate": 0.9375, "step": 2774}
{"time": 1767344112.4340153, "phase": "train", "update": 2775, "total_env_steps": 8880000, "episode_reward": 0.28123757243156433, "value_loss": 0.005070484708994627, "policy_loss": -0.0011154983701793242, "dist_entropy": 0.6498846173286438, "actor_grad_norm": 0.07217207551002502, "critic_grad_norm": 0.044536393135786057, "ratio": 0.9999979138374329, "entropy": 0.6498846173286438, "incre_win_rate": 0.9148936170212766, "step": 2775}
{"time": 1767344116.5922565, "phase": "train", "update": 2776, "total_env_steps": 8883200, "episode_reward": 0.2850372791290283, "value_loss": 0.0049849930219352245, "policy_loss": -0.0010601718191651343, "dist_entropy": 0.6646595954895019, "actor_grad_norm": 0.07090725749731064, "critic_grad_norm": 0.03031069040298462, "ratio": 1.0001041889190674, "entropy": 0.6646595954895019, "incre_win_rate": 0.9772727272727273, "step": 2776}
{"time": 1767344125.7891502, "phase": "eval", "update": 2776, "total_env_steps": 8883200, "eval_win_rate": 1.0, "eval_episode_reward": 20.0, "step": 2776}
{"time": 1767344159.2572668, "phase": "train", "update": 2777, "total_env_steps": 8886400, "episode_reward": 0.2668527662754059, "value_loss": 0.05120855197310448, "policy_loss": -0.0010053655900872371, "dist_entropy": 0.6320274591445922, "actor_grad_norm": 0.0630083978176117, "critic_grad_norm": 0.20052409172058105, "ratio": 1.0003265142440796, "entropy": 0.6320274591445922, "incre_win_rate": 0.8717948717948718, "step": 2777}
{"time": 1767344163.3682477, "phase": "train", "update": 2778, "total_env_steps": 8889600, "episode_reward": 0.28438326716423035, "value_loss": 0.004083684599027038, "policy_loss": -0.001013991097910516, "dist_entropy": 0.6233978033065796, "actor_grad_norm": 0.07505898922681808, "critic_grad_norm": 0.13946287333965302, "ratio": 0.9999315142631531, "entropy": 0.6233978033065796, "incre_win_rate": 0.9787234042553191, "step": 2778}
{"time": 1767344167.4684098, "phase": "train", "update": 2779, "total_env_steps": 8892800, "episode_reward": 0.28689154982566833, "value_loss": 0.003915824182331562, "policy_loss": -0.0010765500380259141, "dist_entropy": 0.6372233510017395, "actor_grad_norm": 0.07090840488672256, "critic_grad_norm": 0.11936316639184952, "ratio": 1.000305414199829, "entropy": 0.6372233510017395, "incre_win_rate": 1.0, "step": 2779}
{"time": 1767344171.6555932, "phase": "train", "update": 2780, "total_env_steps": 8896000, "episode_reward": 0.290681928396225, "value_loss": 0.002864693896844983, "policy_loss": -0.0012947574019605667, "dist_entropy": 0.6550588130950927, "actor_grad_norm": 0.09035681933164597, "critic_grad_norm": 0.0579170361161232, "ratio": 0.9999880790710449, "entropy": 0.6550588130950927, "incre_win_rate": 0.9574468085106383, "step": 2780}
{"time": 1767344175.762629, "phase": "train", "update": 2781, "total_env_steps": 8899200, "episode_reward": 0.2926490008831024, "value_loss": 0.002860542107373476, "policy_loss": -0.0013452851788706254, "dist_entropy": 0.6542420864105225, "actor_grad_norm": 0.08020185679197311, "critic_grad_norm": 0.07146306335926056, "ratio": 0.9999932646751404, "entropy": 0.6542420864105225, "incre_win_rate": 0.9791666666666666, "step": 2781}
{"time": 1767344179.853974, "phase": "train", "update": 2782, "total_env_steps": 8902400, "episode_reward": 0.2959105968475342, "value_loss": 0.0025983025319874288, "policy_loss": -0.0014146463588900816, "dist_entropy": 0.6594448328018189, "actor_grad_norm": 0.07666289806365967, "critic_grad_norm": 0.059100475162267685, "ratio": 0.9991478323936462, "entropy": 0.6594448328018189, "incre_win_rate": 1.0, "step": 2782}
{"time": 1767344183.9830165, "phase": "train", "update": 2783, "total_env_steps": 8905600, "episode_reward": 0.2796730101108551, "value_loss": 0.004083883250132203, "policy_loss": -0.0009187326276830276, "dist_entropy": 0.6397192716598511, "actor_grad_norm": 0.07452711462974548, "critic_grad_norm": 0.02958115004003048, "ratio": 0.9994878768920898, "entropy": 0.6397192716598511, "incre_win_rate": 0.9361702127659575, "step": 2783}
{"time": 1767344188.0778425, "phase": "train", "update": 2784, "total_env_steps": 8908800, "episode_reward": 0.28249484300613403, "value_loss": 0.004260229365900159, "policy_loss": -0.0011387583165680087, "dist_entropy": 0.6429599285125732, "actor_grad_norm": 0.07307378202676773, "critic_grad_norm": 0.0609402060508728, "ratio": 0.9998717308044434, "entropy": 0.6429599285125732, "incre_win_rate": 0.9555555555555556, "step": 2784}
{"time": 1767344192.2017465, "phase": "train", "update": 2785, "total_env_steps": 8912000, "episode_reward": 0.29044291377067566, "value_loss": 0.003563226154074073, "policy_loss": -0.0012198917706015776, "dist_entropy": 0.6581619381904602, "actor_grad_norm": 0.07738669216632843, "critic_grad_norm": 0.04882023110985756, "ratio": 0.9999452829360962, "entropy": 0.6581619381904602, "incre_win_rate": 0.9791666666666666, "step": 2785}
{"time": 1767344197.4786685, "phase": "train", "update": 2786, "total_env_steps": 8915200, "episode_reward": 0.2886279225349426, "value_loss": 0.004247389547526836, "policy_loss": -0.0011765360422032246, "dist_entropy": 0.6666154384613037, "actor_grad_norm": 0.07444868981838226, "critic_grad_norm": 0.06691405922174454, "ratio": 0.9997920393943787, "entropy": 0.6666154384613037, "incre_win_rate": 0.9545454545454546, "step": 2786}
{"time": 1767344201.93066, "phase": "train", "update": 2787, "total_env_steps": 8918400, "episode_reward": 0.27020490169525146, "value_loss": 0.006703093368560076, "policy_loss": -0.001207749218350429, "dist_entropy": 0.635148561000824, "actor_grad_norm": 0.07425893843173981, "critic_grad_norm": 0.0952407643198967, "ratio": 0.9999370574951172, "entropy": 0.635148561000824, "incre_win_rate": 0.8695652173913043, "step": 2787}
{"time": 1767344206.0502362, "phase": "train", "update": 2788, "total_env_steps": 8921600, "episode_reward": 0.2736920416355133, "value_loss": 0.007439508475363255, "policy_loss": -0.0014481405107687807, "dist_entropy": 0.6484450936317444, "actor_grad_norm": 0.07396449893712997, "critic_grad_norm": 0.048381607979536057, "ratio": 0.9994926452636719, "entropy": 0.6484450936317444, "incre_win_rate": 0.8888888888888888, "step": 2788}
{"time": 1767344210.2407312, "phase": "train", "update": 2789, "total_env_steps": 8924800, "episode_reward": 0.28034302592277527, "value_loss": 0.005128253996372223, "policy_loss": -0.0015139120115009064, "dist_entropy": 0.6599337100982666, "actor_grad_norm": 0.08236050605773926, "critic_grad_norm": 0.07119794934988022, "ratio": 1.0001835823059082, "entropy": 0.6599337100982666, "incre_win_rate": 0.9555555555555556, "step": 2789}
{"time": 1767344214.4280944, "phase": "train", "update": 2790, "total_env_steps": 8928000, "episode_reward": 0.28656041622161865, "value_loss": 0.0030353080946952105, "policy_loss": -0.0014520131168117346, "dist_entropy": 0.6905826926231384, "actor_grad_norm": 0.09217952191829681, "critic_grad_norm": 0.07127487659454346, "ratio": 0.9996855854988098, "entropy": 0.6905826926231384, "incre_win_rate": 1.0, "step": 2790}
{"time": 1767344218.604362, "phase": "train", "update": 2791, "total_env_steps": 8931200, "episode_reward": 0.2809416651725769, "value_loss": 0.002999517973512411, "policy_loss": -0.0011711191591826874, "dist_entropy": 0.694612693786621, "actor_grad_norm": 0.09418188035488129, "critic_grad_norm": 0.03495483472943306, "ratio": 1.0001524686813354, "entropy": 0.694612693786621, "incre_win_rate": 0.9787234042553191, "step": 2791}
{"time": 1767344222.8169818, "phase": "train", "update": 2792, "total_env_steps": 8934400, "episode_reward": 0.28997719287872314, "value_loss": 0.0028291573282331227, "policy_loss": -0.0014868836559891463, "dist_entropy": 0.678538179397583, "actor_grad_norm": 0.09244943410158157, "critic_grad_norm": 0.029162898659706116, "ratio": 1.000165343284607, "entropy": 0.678538179397583, "incre_win_rate": 0.9555555555555556, "step": 2792}
{"time": 1767344227.013907, "phase": "train", "update": 2793, "total_env_steps": 8937600, "episode_reward": 0.2876945436000824, "value_loss": 0.0028167367447167633, "policy_loss": -0.0011641291376449203, "dist_entropy": 0.6890112280845642, "actor_grad_norm": 0.08078642934560776, "critic_grad_norm": 0.022808942943811417, "ratio": 0.999972939491272, "entropy": 0.6890112280845642, "incre_win_rate": 0.9361702127659575, "step": 2793}
{"time": 1767344231.1800208, "phase": "train", "update": 2794, "total_env_steps": 8940800, "episode_reward": 0.2972392141819, "value_loss": 0.0014410580275580286, "policy_loss": -0.001091112950559392, "dist_entropy": 0.6765946030616761, "actor_grad_norm": 0.0890105813741684, "critic_grad_norm": 0.04736306518316269, "ratio": 0.9999212622642517, "entropy": 0.6765946030616761, "incre_win_rate": 1.0, "step": 2794}
{"time": 1767344235.2661695, "phase": "train", "update": 2795, "total_env_steps": 8944000, "episode_reward": 0.28586453199386597, "value_loss": 0.004707765206694603, "policy_loss": -0.00143753540922944, "dist_entropy": 0.6494246602058411, "actor_grad_norm": 0.08874744921922684, "critic_grad_norm": 0.029411112889647484, "ratio": 1.0000267028808594, "entropy": 0.6494246602058411, "incre_win_rate": 0.9347826086956522, "step": 2795}
{"time": 1767344239.3693764, "phase": "train", "update": 2796, "total_env_steps": 8947200, "episode_reward": 0.2844495177268982, "value_loss": 0.003737490205094218, "policy_loss": -0.0011660526262723182, "dist_entropy": 0.6353137493133545, "actor_grad_norm": 0.08616777509450912, "critic_grad_norm": 0.02849162183701992, "ratio": 1.0001214742660522, "entropy": 0.6353137493133545, "incre_win_rate": 0.9375, "step": 2796}
{"time": 1767344243.4638476, "phase": "train", "update": 2797, "total_env_steps": 8950400, "episode_reward": 0.2905360162258148, "value_loss": 0.005503661744296551, "policy_loss": -0.0015138680185502018, "dist_entropy": 0.6624749183654786, "actor_grad_norm": 0.07282832264900208, "critic_grad_norm": 0.03756861016154289, "ratio": 0.9998108744621277, "entropy": 0.6624749183654786, "incre_win_rate": 0.9361702127659575, "step": 2797}
{"time": 1767344247.6155255, "phase": "train", "update": 2798, "total_env_steps": 8953600, "episode_reward": 0.29679635167121887, "value_loss": 0.003574083838611841, "policy_loss": -0.0013342550270381004, "dist_entropy": 0.6559765338897705, "actor_grad_norm": 0.07773410528898239, "critic_grad_norm": 0.023987511172890663, "ratio": 1.000042200088501, "entropy": 0.6559765338897705, "incre_win_rate": 1.0, "step": 2798}
{"time": 1767344251.733738, "phase": "train", "update": 2799, "total_env_steps": 8956800, "episode_reward": 0.27569329738616943, "value_loss": 0.0059149213135242466, "policy_loss": -0.0018741651177666796, "dist_entropy": 0.6579294443130493, "actor_grad_norm": 0.09779003262519836, "critic_grad_norm": 0.03368354216217995, "ratio": 1.0000900030136108, "entropy": 0.6579294443130493, "incre_win_rate": 0.8888888888888888, "step": 2799}
{"time": 1767344255.8514404, "phase": "train", "update": 2800, "total_env_steps": 8960000, "episode_reward": 0.2837686240673065, "value_loss": 0.0048034521751105785, "policy_loss": -0.001272468564386031, "dist_entropy": 0.6418062448501587, "actor_grad_norm": 0.0862419530749321, "critic_grad_norm": 0.03428812697529793, "ratio": 1.0000132322311401, "entropy": 0.6418062448501587, "incre_win_rate": 0.9166666666666666, "step": 2800}
{"time": 1767344259.91297, "phase": "train", "update": 2801, "total_env_steps": 8963200, "episode_reward": 0.28616827726364136, "value_loss": 0.003869384806603193, "policy_loss": -0.0011002133975546613, "dist_entropy": 0.644741439819336, "actor_grad_norm": 0.0764126107096672, "critic_grad_norm": 0.03083743527531624, "ratio": 1.0002645254135132, "entropy": 0.644741439819336, "incre_win_rate": 0.9782608695652174, "step": 2801}
{"time": 1767344269.4956744, "phase": "eval", "update": 2801, "total_env_steps": 8963200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.89859271523179, "step": 2801}
{"time": 1767344273.6014464, "phase": "train", "update": 2802, "total_env_steps": 8966400, "episode_reward": 0.2828756272792816, "value_loss": 0.004515141062438488, "policy_loss": -0.001221876385766052, "dist_entropy": 0.6343172907829284, "actor_grad_norm": 0.09448845684528351, "critic_grad_norm": 0.015168159268796444, "ratio": 0.9997329711914062, "entropy": 0.6343172907829284, "incre_win_rate": 0.9318181818181818, "step": 2802}
{"time": 1767344277.7261128, "phase": "train", "update": 2803, "total_env_steps": 8969600, "episode_reward": 0.2857077717781067, "value_loss": 0.003201084490865469, "policy_loss": -0.001366971563348507, "dist_entropy": 0.6457945346832276, "actor_grad_norm": 0.07708877325057983, "critic_grad_norm": 0.016786813735961914, "ratio": 0.999982476234436, "entropy": 0.6457945346832276, "incre_win_rate": 0.9361702127659575, "step": 2803}
{"time": 1767344281.8776536, "phase": "train", "update": 2804, "total_env_steps": 8972800, "episode_reward": 0.29069533944129944, "value_loss": 0.0023107499815523624, "policy_loss": -0.0011381523853088993, "dist_entropy": 0.6442888140678406, "actor_grad_norm": 0.07313152402639389, "critic_grad_norm": 0.0197161715477705, "ratio": 1.0000947713851929, "entropy": 0.6442888140678406, "incre_win_rate": 1.0, "step": 2804}
{"time": 1767344286.0110636, "phase": "train", "update": 2805, "total_env_steps": 8976000, "episode_reward": 0.28252482414245605, "value_loss": 0.00565043929964304, "policy_loss": -0.00152071134341476, "dist_entropy": 0.6412724614143371, "actor_grad_norm": 0.08513734489679337, "critic_grad_norm": 0.03441249951720238, "ratio": 0.9998656511306763, "entropy": 0.6412724614143371, "incre_win_rate": 0.8913043478260869, "step": 2805}
{"time": 1767344290.0783212, "phase": "train", "update": 2806, "total_env_steps": 8979200, "episode_reward": 0.2837541401386261, "value_loss": 0.0065599045716226104, "policy_loss": -0.0012589639832023991, "dist_entropy": 0.649245822429657, "actor_grad_norm": 0.07841817289590836, "critic_grad_norm": 0.03433699533343315, "ratio": 0.9998568892478943, "entropy": 0.649245822429657, "incre_win_rate": 0.9361702127659575, "step": 2806}
{"time": 1767344294.1605191, "phase": "train", "update": 2807, "total_env_steps": 8982400, "episode_reward": 0.2869386374950409, "value_loss": 0.005032651033252478, "policy_loss": -0.0010773316083870555, "dist_entropy": 0.6516714453697204, "actor_grad_norm": 0.07875977456569672, "critic_grad_norm": 0.048530951142311096, "ratio": 1.0000619888305664, "entropy": 0.6516714453697204, "incre_win_rate": 0.9565217391304348, "step": 2807}
{"time": 1767344298.2741046, "phase": "train", "update": 2808, "total_env_steps": 8985600, "episode_reward": 0.2884473502635956, "value_loss": 0.004242072906345129, "policy_loss": -0.0010896986216195614, "dist_entropy": 0.6500651597976684, "actor_grad_norm": 0.06444379687309265, "critic_grad_norm": 0.02932717278599739, "ratio": 0.9998480081558228, "entropy": 0.6500651597976684, "incre_win_rate": 0.9574468085106383, "step": 2808}
{"time": 1767344302.3848546, "phase": "train", "update": 2809, "total_env_steps": 8988800, "episode_reward": 0.2924586236476898, "value_loss": 0.0025125736836344005, "policy_loss": -0.0013751291656262765, "dist_entropy": 0.6617396593093872, "actor_grad_norm": 0.07377811521291733, "critic_grad_norm": 0.019946057349443436, "ratio": 1.0000056028366089, "entropy": 0.6617396593093872, "incre_win_rate": 0.9777777777777777, "step": 2809}
{"time": 1767344306.4796538, "phase": "train", "update": 2810, "total_env_steps": 8992000, "episode_reward": 0.278202086687088, "value_loss": 0.005639118514955044, "policy_loss": -0.0012910201785176767, "dist_entropy": 0.6258239030838013, "actor_grad_norm": 0.07553845643997192, "critic_grad_norm": 0.06630253046751022, "ratio": 1.000013828277588, "entropy": 0.6258239030838013, "incre_win_rate": 0.8979591836734694, "step": 2810}
{"time": 1767344310.596691, "phase": "train", "update": 2811, "total_env_steps": 8995200, "episode_reward": 0.2855173945426941, "value_loss": 0.005466040596365929, "policy_loss": -0.0012178348280748707, "dist_entropy": 0.6364761233329773, "actor_grad_norm": 0.08226343989372253, "critic_grad_norm": 0.05476948246359825, "ratio": 1.0000373125076294, "entropy": 0.6364761233329773, "incre_win_rate": 0.9555555555555556, "step": 2811}
{"time": 1767344314.7080522, "phase": "train", "update": 2812, "total_env_steps": 8998400, "episode_reward": 0.28710266947746277, "value_loss": 0.004052394349128008, "policy_loss": -0.0015014448322567375, "dist_entropy": 0.6258508563041687, "actor_grad_norm": 0.07750009745359421, "critic_grad_norm": 0.04694271460175514, "ratio": 1.0001354217529297, "entropy": 0.6258508563041687, "incre_win_rate": 0.9565217391304348, "step": 2812}
{"time": 1767344318.8673556, "phase": "train", "update": 2813, "total_env_steps": 9001600, "episode_reward": 0.292793869972229, "value_loss": 0.0018802278209477663, "policy_loss": -0.0012502952166229876, "dist_entropy": 0.645335566997528, "actor_grad_norm": 0.0822630450129509, "critic_grad_norm": 0.034492384642362595, "ratio": 0.9999120831489563, "entropy": 0.645335566997528, "incre_win_rate": 1.0, "step": 2813}
{"time": 1767344322.9795182, "phase": "train", "update": 2814, "total_env_steps": 9004800, "episode_reward": 0.29541388154029846, "value_loss": 0.0014338522916659713, "policy_loss": -0.0014724116532875086, "dist_entropy": 0.6437867283821106, "actor_grad_norm": 0.10366826504468918, "critic_grad_norm": 0.02507922612130642, "ratio": 1.000093698501587, "entropy": 0.6437867283821106, "incre_win_rate": 1.0, "step": 2814}
{"time": 1767344327.1039083, "phase": "train", "update": 2815, "total_env_steps": 9008000, "episode_reward": 0.28846442699432373, "value_loss": 0.002104254858568311, "policy_loss": -0.0013685647998642025, "dist_entropy": 0.6674428224563599, "actor_grad_norm": 0.09610086679458618, "critic_grad_norm": 0.025309128686785698, "ratio": 1.0000966787338257, "entropy": 0.6674428224563599, "incre_win_rate": 0.9787234042553191, "step": 2815}
{"time": 1767344331.2046814, "phase": "train", "update": 2816, "total_env_steps": 9011200, "episode_reward": 0.2891928553581238, "value_loss": 0.0016646351665258407, "policy_loss": -0.0012444122672420122, "dist_entropy": 0.6570577025413513, "actor_grad_norm": 0.07489188015460968, "critic_grad_norm": 0.011972656473517418, "ratio": 1.0001180171966553, "entropy": 0.6570577025413513, "incre_win_rate": 1.0, "step": 2816}
{"time": 1767344335.2963512, "phase": "train", "update": 2817, "total_env_steps": 9014400, "episode_reward": 0.28939467668533325, "value_loss": 0.001968724955804646, "policy_loss": -0.0015051336940043569, "dist_entropy": 0.6519842982292176, "actor_grad_norm": 0.08302988111972809, "critic_grad_norm": 0.013668808154761791, "ratio": 0.9998742938041687, "entropy": 0.6519842982292176, "incre_win_rate": 0.9777777777777777, "step": 2817}
{"time": 1767344339.4153826, "phase": "train", "update": 2818, "total_env_steps": 9017600, "episode_reward": 0.28960680961608887, "value_loss": 0.0033590699546039104, "policy_loss": -0.001508309818931508, "dist_entropy": 0.6625330924987793, "actor_grad_norm": 0.08240572363138199, "critic_grad_norm": 0.023096878081560135, "ratio": 0.999572217464447, "entropy": 0.6625330924987793, "incre_win_rate": 0.9361702127659575, "step": 2818}
{"time": 1767344343.5565355, "phase": "train", "update": 2819, "total_env_steps": 9020800, "episode_reward": 0.28232821822166443, "value_loss": 0.007452714070677757, "policy_loss": -0.0014500849879475197, "dist_entropy": 0.6531463265419006, "actor_grad_norm": 0.0720042884349823, "critic_grad_norm": 0.028972899541258812, "ratio": 0.9998597502708435, "entropy": 0.6531463265419006, "incre_win_rate": 0.9347826086956522, "step": 2819}
{"time": 1767344347.7247322, "phase": "train", "update": 2820, "total_env_steps": 9024000, "episode_reward": 0.28823211789131165, "value_loss": 0.004706578329205513, "policy_loss": -0.0013875682163558168, "dist_entropy": 0.6516183853149414, "actor_grad_norm": 0.08305858820676804, "critic_grad_norm": 0.03133232519030571, "ratio": 0.9996227622032166, "entropy": 0.6516183853149414, "incre_win_rate": 0.9347826086956522, "step": 2820}
{"time": 1767344351.8455539, "phase": "train", "update": 2821, "total_env_steps": 9027200, "episode_reward": 0.28725168108940125, "value_loss": 0.0038879992440342902, "policy_loss": -0.001135000522132401, "dist_entropy": 0.663094985485077, "actor_grad_norm": 0.07333467155694962, "critic_grad_norm": 0.02614007703959942, "ratio": 0.9999282956123352, "entropy": 0.663094985485077, "incre_win_rate": 0.9787234042553191, "step": 2821}
{"time": 1767344355.9681902, "phase": "train", "update": 2822, "total_env_steps": 9030400, "episode_reward": 0.27500465512275696, "value_loss": 0.0063938387669622895, "policy_loss": -0.001576547200822631, "dist_entropy": 0.6194061994552612, "actor_grad_norm": 0.08373230695724487, "critic_grad_norm": 0.03605229780077934, "ratio": 0.999969482421875, "entropy": 0.6194061994552612, "incre_win_rate": 0.9111111111111111, "step": 2822}
{"time": 1767344360.08389, "phase": "train", "update": 2823, "total_env_steps": 9033600, "episode_reward": 0.2804636061191559, "value_loss": 0.004848423879593611, "policy_loss": -0.0013786315020695382, "dist_entropy": 0.6650225639343261, "actor_grad_norm": 0.07007061690092087, "critic_grad_norm": 0.013665183447301388, "ratio": 0.9996384978294373, "entropy": 0.6650225639343261, "incre_win_rate": 0.8888888888888888, "step": 2823}
{"time": 1767344364.1983194, "phase": "train", "update": 2824, "total_env_steps": 9036800, "episode_reward": 0.28323259949684143, "value_loss": 0.004385664407163858, "policy_loss": -0.0013801878344494867, "dist_entropy": 0.6602652311325073, "actor_grad_norm": 0.0772465392947197, "critic_grad_norm": 0.030142778530716896, "ratio": 1.0000313520431519, "entropy": 0.6602652311325073, "incre_win_rate": 0.9574468085106383, "step": 2824}
{"time": 1767344368.2723937, "phase": "train", "update": 2825, "total_env_steps": 9040000, "episode_reward": 0.280269056558609, "value_loss": 0.0033302387688308953, "policy_loss": -0.001190443922399842, "dist_entropy": 0.6434553980827331, "actor_grad_norm": 0.07280400395393372, "critic_grad_norm": 0.02738674357533455, "ratio": 1.000059723854065, "entropy": 0.6434553980827331, "incre_win_rate": 0.9574468085106383, "step": 2825}
{"time": 1767344372.3879387, "phase": "train", "update": 2826, "total_env_steps": 9043200, "episode_reward": 0.28022143244743347, "value_loss": 0.003915002476423979, "policy_loss": -0.0014187919210051803, "dist_entropy": 0.6315822958946228, "actor_grad_norm": 0.07647975534200668, "critic_grad_norm": 0.01153124775737524, "ratio": 1.0000723600387573, "entropy": 0.6315822958946228, "incre_win_rate": 0.9318181818181818, "step": 2826}
{"time": 1767344381.7948034, "phase": "eval", "update": 2826, "total_env_steps": 9043200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.880794701986755, "step": 2826}
{"time": 1767344385.8432517, "phase": "train", "update": 2827, "total_env_steps": 9046400, "episode_reward": 0.27479302883148193, "value_loss": 0.0048294165171682835, "policy_loss": -0.0011434013410468679, "dist_entropy": 0.6509985089302063, "actor_grad_norm": 0.09321080893278122, "critic_grad_norm": 0.022840214893221855, "ratio": 1.0000873804092407, "entropy": 0.6509985089302063, "incre_win_rate": 0.9318181818181818, "step": 2827}
{"time": 1767344389.978101, "phase": "train", "update": 2828, "total_env_steps": 9049600, "episode_reward": 0.2780541181564331, "value_loss": 0.004036902589723468, "policy_loss": -0.0012682852001844936, "dist_entropy": 0.6424313068389893, "actor_grad_norm": 0.08330939710140228, "critic_grad_norm": 0.012594940140843391, "ratio": 1.000143051147461, "entropy": 0.6424313068389893, "incre_win_rate": 0.9361702127659575, "step": 2828}
{"time": 1767344394.0989087, "phase": "train", "update": 2829, "total_env_steps": 9052800, "episode_reward": 0.277981162071228, "value_loss": 0.003761128336191177, "policy_loss": -0.001542078681870862, "dist_entropy": 0.6763064384460449, "actor_grad_norm": 0.07805933803319931, "critic_grad_norm": 0.018615493550896645, "ratio": 1.000016450881958, "entropy": 0.6763064384460449, "incre_win_rate": 0.8888888888888888, "step": 2829}
{"time": 1767344398.2017133, "phase": "train", "update": 2830, "total_env_steps": 9056000, "episode_reward": 0.27642539143562317, "value_loss": 0.005083348043262959, "policy_loss": -0.0016178818075097468, "dist_entropy": 0.6327532649040222, "actor_grad_norm": 0.1018035039305687, "critic_grad_norm": 0.024265168234705925, "ratio": 0.999642550945282, "entropy": 0.6327532649040222, "incre_win_rate": 0.9545454545454546, "step": 2830}
{"time": 1767344402.2999308, "phase": "train", "update": 2831, "total_env_steps": 9059200, "episode_reward": 0.2831012010574341, "value_loss": 0.004225759021937847, "policy_loss": -0.0016727463759806938, "dist_entropy": 0.6748655080795288, "actor_grad_norm": 0.07979476451873779, "critic_grad_norm": 0.020661231130361557, "ratio": 0.9998750686645508, "entropy": 0.6748655080795288, "incre_win_rate": 0.9347826086956522, "step": 2831}
{"time": 1767344406.48388, "phase": "train", "update": 2832, "total_env_steps": 9062400, "episode_reward": 0.27737581729888916, "value_loss": 0.006267328467220068, "policy_loss": -0.0012176251533425387, "dist_entropy": 0.6750336170196534, "actor_grad_norm": 0.07463250309228897, "critic_grad_norm": 0.022863885387778282, "ratio": 1.0000178813934326, "entropy": 0.6750336170196534, "incre_win_rate": 0.9565217391304348, "step": 2832}
{"time": 1767344410.5765302, "phase": "train", "update": 2833, "total_env_steps": 9065600, "episode_reward": 0.28627899289131165, "value_loss": 0.005172010883688927, "policy_loss": -0.0015410879503832576, "dist_entropy": 0.6540230751037598, "actor_grad_norm": 0.08873437345027924, "critic_grad_norm": 0.030933424830436707, "ratio": 1.0000442266464233, "entropy": 0.6540230751037598, "incre_win_rate": 0.9555555555555556, "step": 2833}
{"time": 1767344414.6866522, "phase": "train", "update": 2834, "total_env_steps": 9068800, "episode_reward": 0.27961093187332153, "value_loss": 0.0032381858211010693, "policy_loss": -0.0012738101858786877, "dist_entropy": 0.6665577530860901, "actor_grad_norm": 0.0817222148180008, "critic_grad_norm": 0.019778357818722725, "ratio": 0.9998783469200134, "entropy": 0.6665577530860901, "incre_win_rate": 0.9555555555555556, "step": 2834}
{"time": 1767344418.7996662, "phase": "train", "update": 2835, "total_env_steps": 9072000, "episode_reward": 0.2864145338535309, "value_loss": 0.0027174131013453008, "policy_loss": -0.0014295689634373776, "dist_entropy": 0.612509548664093, "actor_grad_norm": 0.0912618339061737, "critic_grad_norm": 0.015845950692892075, "ratio": 0.9999055862426758, "entropy": 0.612509548664093, "incre_win_rate": 0.9782608695652174, "step": 2835}
{"time": 1767344422.9052086, "phase": "train", "update": 2836, "total_env_steps": 9075200, "episode_reward": 0.27612584829330444, "value_loss": 0.005969659239053726, "policy_loss": -0.0014836741718099234, "dist_entropy": 0.6216029286384582, "actor_grad_norm": 0.08912365883588791, "critic_grad_norm": 0.046075548976659775, "ratio": 0.9998562932014465, "entropy": 0.6216029286384582, "incre_win_rate": 0.9090909090909091, "step": 2836}
{"time": 1767344426.9656422, "phase": "train", "update": 2837, "total_env_steps": 9078400, "episode_reward": 0.2737153172492981, "value_loss": 0.0053127331659197806, "policy_loss": -0.0013435012110637246, "dist_entropy": 0.6218327522277832, "actor_grad_norm": 0.08246473222970963, "critic_grad_norm": 0.02642599120736122, "ratio": 1.0000418424606323, "entropy": 0.6218327522277832, "incre_win_rate": 0.8723404255319149, "step": 2837}
{"time": 1767344431.1110356, "phase": "train", "update": 2838, "total_env_steps": 9081600, "episode_reward": 0.28660595417022705, "value_loss": 0.004153594467788934, "policy_loss": -0.0011836154244194929, "dist_entropy": 0.6027524948120118, "actor_grad_norm": 0.09753856807947159, "critic_grad_norm": 0.03556803986430168, "ratio": 1.0000721216201782, "entropy": 0.6027524948120118, "incre_win_rate": 0.9787234042553191, "step": 2838}
{"time": 1767344435.2226276, "phase": "train", "update": 2839, "total_env_steps": 9084800, "episode_reward": 0.28244102001190186, "value_loss": 0.0033836763352155684, "policy_loss": -0.001442931186048213, "dist_entropy": 0.5985366463661194, "actor_grad_norm": 0.0777265653014183, "critic_grad_norm": 0.018448667600750923, "ratio": 0.9997736215591431, "entropy": 0.5985366463661194, "incre_win_rate": 0.9333333333333333, "step": 2839}
{"time": 1767344439.3351324, "phase": "train", "update": 2840, "total_env_steps": 9088000, "episode_reward": 0.28585267066955566, "value_loss": 0.003965843841433525, "policy_loss": -0.0012786284124928216, "dist_entropy": 0.5906534433364868, "actor_grad_norm": 0.0769842267036438, "critic_grad_norm": 0.02396586537361145, "ratio": 0.9998636245727539, "entropy": 0.5906534433364868, "incre_win_rate": 0.9574468085106383, "step": 2840}
{"time": 1767344443.438016, "phase": "train", "update": 2841, "total_env_steps": 9091200, "episode_reward": 0.29129552841186523, "value_loss": 0.0027003342285752295, "policy_loss": -0.0009970905436904153, "dist_entropy": 0.588290524482727, "actor_grad_norm": 0.06449657678604126, "critic_grad_norm": 0.01645897887647152, "ratio": 1.00005042552948, "entropy": 0.588290524482727, "incre_win_rate": 0.9782608695652174, "step": 2841}
{"time": 1767344447.5235057, "phase": "train", "update": 2842, "total_env_steps": 9094400, "episode_reward": 0.28456127643585205, "value_loss": 0.004316459037363529, "policy_loss": -0.0011013359717296112, "dist_entropy": 0.5797910451889038, "actor_grad_norm": 0.07947289198637009, "critic_grad_norm": 0.03560050204396248, "ratio": 0.9998504519462585, "entropy": 0.5797910451889038, "incre_win_rate": 0.9333333333333333, "step": 2842}
{"time": 1767344451.632902, "phase": "train", "update": 2843, "total_env_steps": 9097600, "episode_reward": 0.2858050465583801, "value_loss": 0.004200879298150539, "policy_loss": -0.0012440978754000298, "dist_entropy": 0.590105164051056, "actor_grad_norm": 0.07889281958341599, "critic_grad_norm": 0.017948901280760765, "ratio": 1.0005123615264893, "entropy": 0.590105164051056, "incre_win_rate": 0.9583333333333334, "step": 2843}
{"time": 1767344455.7254393, "phase": "train", "update": 2844, "total_env_steps": 9100800, "episode_reward": 0.28609323501586914, "value_loss": 0.003777094837278128, "policy_loss": -0.0013075068965761715, "dist_entropy": 0.5992812633514404, "actor_grad_norm": 0.07485704869031906, "critic_grad_norm": 0.024326955899596214, "ratio": 1.0000736713409424, "entropy": 0.5992812633514404, "incre_win_rate": 0.9782608695652174, "step": 2844}
{"time": 1767344459.8731568, "phase": "train", "update": 2845, "total_env_steps": 9104000, "episode_reward": 0.2897734045982361, "value_loss": 0.0019335158867761493, "policy_loss": -0.001409697041698088, "dist_entropy": 0.6112510085105896, "actor_grad_norm": 0.07821980863809586, "critic_grad_norm": 0.020521489903330803, "ratio": 1.0001826286315918, "entropy": 0.6112510085105896, "incre_win_rate": 0.9787234042553191, "step": 2845}
{"time": 1767344464.0251434, "phase": "train", "update": 2846, "total_env_steps": 9107200, "episode_reward": 0.2983899414539337, "value_loss": 0.002542248275130987, "policy_loss": -0.00116981940844596, "dist_entropy": 0.6262049436569214, "actor_grad_norm": 0.08867164701223373, "critic_grad_norm": 0.013970347121357918, "ratio": 0.9996108412742615, "entropy": 0.6262049436569214, "incre_win_rate": 0.9791666666666666, "step": 2846}
{"time": 1767344468.131985, "phase": "train", "update": 2847, "total_env_steps": 9110400, "episode_reward": 0.28627899289131165, "value_loss": 0.004513550456613303, "policy_loss": -0.0011821123320139293, "dist_entropy": 0.6275543212890625, "actor_grad_norm": 0.08088498562574387, "critic_grad_norm": 0.024332234635949135, "ratio": 1.0003031492233276, "entropy": 0.6275543212890625, "incre_win_rate": 0.9333333333333333, "step": 2847}
{"time": 1767344472.3432636, "phase": "train", "update": 2848, "total_env_steps": 9113600, "episode_reward": 0.2818951904773712, "value_loss": 0.0030947702936828135, "policy_loss": -0.0014425413754153738, "dist_entropy": 0.6051928162574768, "actor_grad_norm": 0.08845847845077515, "critic_grad_norm": 0.01482198666781187, "ratio": 0.9998162388801575, "entropy": 0.6051928162574768, "incre_win_rate": 0.9361702127659575, "step": 2848}
{"time": 1767344476.5054595, "phase": "train", "update": 2849, "total_env_steps": 9116800, "episode_reward": 0.2971647381782532, "value_loss": 0.0015533102210611104, "policy_loss": -0.001235485864160779, "dist_entropy": 0.6182078361511231, "actor_grad_norm": 0.09643717855215073, "critic_grad_norm": 0.024188250303268433, "ratio": 1.0000625848770142, "entropy": 0.6182078361511231, "incre_win_rate": 1.0, "step": 2849}
{"time": 1767344480.6356897, "phase": "train", "update": 2850, "total_env_steps": 9120000, "episode_reward": 0.28604304790496826, "value_loss": 0.003538862895220518, "policy_loss": -0.0015247722985087364, "dist_entropy": 0.6232942938804626, "actor_grad_norm": 0.0822192057967186, "critic_grad_norm": 0.03134649619460106, "ratio": 0.9998942613601685, "entropy": 0.6232942938804626, "incre_win_rate": 0.9361702127659575, "step": 2850}
{"time": 1767344484.793227, "phase": "train", "update": 2851, "total_env_steps": 9123200, "episode_reward": 0.29341885447502136, "value_loss": 0.002184237353503704, "policy_loss": -0.0013518683677485655, "dist_entropy": 0.6444295287132263, "actor_grad_norm": 0.0918758437037468, "critic_grad_norm": 0.015886599197983742, "ratio": 0.9997870326042175, "entropy": 0.6444295287132263, "incre_win_rate": 0.9777777777777777, "step": 2851}
{"time": 1767344494.0499387, "phase": "eval", "update": 2851, "total_env_steps": 9123200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.9010761589404, "step": 2851}
{"time": 1767344498.169525, "phase": "train", "update": 2852, "total_env_steps": 9126400, "episode_reward": 0.29013243317604065, "value_loss": 0.002160951215773821, "policy_loss": -0.0014341368622723394, "dist_entropy": 0.6142661452293396, "actor_grad_norm": 0.08865366131067276, "critic_grad_norm": 0.018576379865407944, "ratio": 1.0003137588500977, "entropy": 0.6142661452293396, "incre_win_rate": 0.9787234042553191, "step": 2852}
{"time": 1767344502.3246403, "phase": "train", "update": 2853, "total_env_steps": 9129600, "episode_reward": 0.28893160820007324, "value_loss": 0.003195794252678752, "policy_loss": -0.0009350279748115753, "dist_entropy": 0.5968308925628663, "actor_grad_norm": 0.06892625242471695, "critic_grad_norm": 0.012318797409534454, "ratio": 0.9999591112136841, "entropy": 0.5968308925628663, "incre_win_rate": 0.9787234042553191, "step": 2853}
{"time": 1767344506.4492128, "phase": "train", "update": 2854, "total_env_steps": 9132800, "episode_reward": 0.28293871879577637, "value_loss": 0.003827273799106479, "policy_loss": -0.0015759722210660243, "dist_entropy": 0.6158110618591308, "actor_grad_norm": 0.07725813239812851, "critic_grad_norm": 0.03457917645573616, "ratio": 1.0003705024719238, "entropy": 0.6158110618591308, "incre_win_rate": 0.9148936170212766, "step": 2854}
{"time": 1767344510.5880568, "phase": "train", "update": 2855, "total_env_steps": 9136000, "episode_reward": 0.2857823073863983, "value_loss": 0.00680456543341279, "policy_loss": -0.0011927323038179339, "dist_entropy": 0.5992154717445374, "actor_grad_norm": 0.06702952086925507, "critic_grad_norm": 0.04491203650832176, "ratio": 0.9998742341995239, "entropy": 0.5992154717445374, "incre_win_rate": 0.9130434782608695, "step": 2855}
{"time": 1767344514.7025526, "phase": "train", "update": 2856, "total_env_steps": 9139200, "episode_reward": 0.2858981788158417, "value_loss": 0.004236254282295704, "policy_loss": -0.001443403544812405, "dist_entropy": 0.6139268279075623, "actor_grad_norm": 0.07359474897384644, "critic_grad_norm": 0.019078735262155533, "ratio": 0.9999544024467468, "entropy": 0.6139268279075623, "incre_win_rate": 0.9565217391304348, "step": 2856}
{"time": 1767344518.847935, "phase": "train", "update": 2857, "total_env_steps": 9142400, "episode_reward": 0.2941380441188812, "value_loss": 0.0022265252657234667, "policy_loss": -0.001354961427072965, "dist_entropy": 0.641401731967926, "actor_grad_norm": 0.07351704686880112, "critic_grad_norm": 0.04431941732764244, "ratio": 1.0002760887145996, "entropy": 0.641401731967926, "incre_win_rate": 1.0, "step": 2857}
{"time": 1767344522.985211, "phase": "train", "update": 2858, "total_env_steps": 9145600, "episode_reward": 0.29007554054260254, "value_loss": 0.0018218394834548235, "policy_loss": -0.0012240130600947197, "dist_entropy": 0.5925819635391235, "actor_grad_norm": 0.08038290590047836, "critic_grad_norm": 0.018955042585730553, "ratio": 1.0000901222229004, "entropy": 0.5925819635391235, "incre_win_rate": 1.0, "step": 2858}
{"time": 1767344527.1707118, "phase": "train", "update": 2859, "total_env_steps": 9148800, "episode_reward": 0.29412662982940674, "value_loss": 0.0013661099597811698, "policy_loss": -0.00140049240322071, "dist_entropy": 0.6103739976882935, "actor_grad_norm": 0.08672311156988144, "critic_grad_norm": 0.023369556292891502, "ratio": 1.0001972913742065, "entropy": 0.6103739976882935, "incre_win_rate": 1.0, "step": 2859}
{"time": 1767344531.35636, "phase": "train", "update": 2860, "total_env_steps": 9152000, "episode_reward": 0.2952152192592621, "value_loss": 0.0013579382793977857, "policy_loss": -0.0013346694758062938, "dist_entropy": 0.6317987442016602, "actor_grad_norm": 0.08506572246551514, "critic_grad_norm": 0.017949586734175682, "ratio": 0.9998283386230469, "entropy": 0.6317987442016602, "incre_win_rate": 1.0, "step": 2860}
{"time": 1767344535.4992166, "phase": "train", "update": 2861, "total_env_steps": 9155200, "episode_reward": 0.2908366322517395, "value_loss": 0.003183598816394806, "policy_loss": -0.0010571996494320502, "dist_entropy": 0.5990891933441163, "actor_grad_norm": 0.06985317915678024, "critic_grad_norm": 0.02893674373626709, "ratio": 1.0002501010894775, "entropy": 0.5990891933441163, "incre_win_rate": 0.9777777777777777, "step": 2861}
{"time": 1767344539.636746, "phase": "train", "update": 2862, "total_env_steps": 9158400, "episode_reward": 0.30241671204566956, "value_loss": 0.0015258047031238675, "policy_loss": -0.0015786308181986897, "dist_entropy": 0.6052708864212036, "actor_grad_norm": 0.08133979886770248, "critic_grad_norm": 0.021950555965304375, "ratio": 1.0001492500305176, "entropy": 0.6052708864212036, "incre_win_rate": 1.0, "step": 2862}
{"time": 1767344543.7896607, "phase": "train", "update": 2863, "total_env_steps": 9161600, "episode_reward": 0.2973427176475525, "value_loss": 0.0024016247130930423, "policy_loss": -0.00133674324205586, "dist_entropy": 0.5921590685844421, "actor_grad_norm": 0.07631854712963104, "critic_grad_norm": 0.020224792882800102, "ratio": 1.0000879764556885, "entropy": 0.5921590685844421, "incre_win_rate": 0.9791666666666666, "step": 2863}
{"time": 1767344547.9148498, "phase": "train", "update": 2864, "total_env_steps": 9164800, "episode_reward": 0.28218957781791687, "value_loss": 0.005694537796080113, "policy_loss": -0.0014008714359004415, "dist_entropy": 0.5763762354850769, "actor_grad_norm": 0.06948428601026535, "critic_grad_norm": 0.04966818913817406, "ratio": 0.9996544122695923, "entropy": 0.5763762354850769, "incre_win_rate": 0.9361702127659575, "step": 2864}
{"time": 1767344552.115713, "phase": "train", "update": 2865, "total_env_steps": 9168000, "episode_reward": 0.2961920499801636, "value_loss": 0.0028970447834581136, "policy_loss": -0.0013093270189898476, "dist_entropy": 0.5899903535842895, "actor_grad_norm": 0.06754375994205475, "critic_grad_norm": 0.01915484294295311, "ratio": 0.9998985528945923, "entropy": 0.5899903535842895, "incre_win_rate": 0.9574468085106383, "step": 2865}
{"time": 1767344556.2274823, "phase": "train", "update": 2866, "total_env_steps": 9171200, "episode_reward": 0.2863420844078064, "value_loss": 0.004101734515279532, "policy_loss": -0.0017186321031370966, "dist_entropy": 0.586406135559082, "actor_grad_norm": 0.08145210891962051, "critic_grad_norm": 0.04648622125387192, "ratio": 0.9998846054077148, "entropy": 0.586406135559082, "incre_win_rate": 0.9130434782608695, "step": 2866}
{"time": 1767344560.3410985, "phase": "train", "update": 2867, "total_env_steps": 9174400, "episode_reward": 0.28633224964141846, "value_loss": 0.0072687285020947455, "policy_loss": -0.0009479592249689972, "dist_entropy": 0.5625420093536377, "actor_grad_norm": 0.07333075255155563, "critic_grad_norm": 0.04855368658900261, "ratio": 0.9997419714927673, "entropy": 0.5625420093536377, "incre_win_rate": 0.9347826086956522, "step": 2867}
{"time": 1767344564.5042443, "phase": "train", "update": 2868, "total_env_steps": 9177600, "episode_reward": 0.2931167483329773, "value_loss": 0.003974308492615819, "policy_loss": -0.0014102620955725343, "dist_entropy": 0.5712140798568726, "actor_grad_norm": 0.08116313815116882, "critic_grad_norm": 0.06224020943045616, "ratio": 1.0001477003097534, "entropy": 0.5712140798568726, "incre_win_rate": 0.9591836734693877, "step": 2868}
{"time": 1767344568.6227086, "phase": "train", "update": 2869, "total_env_steps": 9180800, "episode_reward": 0.28100061416625977, "value_loss": 0.006042788550257683, "policy_loss": -0.0016151960941016342, "dist_entropy": 0.595051383972168, "actor_grad_norm": 0.09557908028364182, "critic_grad_norm": 0.027368372306227684, "ratio": 1.0000317096710205, "entropy": 0.595051383972168, "incre_win_rate": 0.9347826086956522, "step": 2869}
{"time": 1767344572.7376666, "phase": "train", "update": 2870, "total_env_steps": 9184000, "episode_reward": 0.2827897369861603, "value_loss": 0.003291837265715003, "policy_loss": -0.0009618925134404321, "dist_entropy": 0.5785972714424134, "actor_grad_norm": 0.06950336694717407, "critic_grad_norm": 0.01802067831158638, "ratio": 0.9999232292175293, "entropy": 0.5785972714424134, "incre_win_rate": 0.9333333333333333, "step": 2870}
{"time": 1767344576.8549027, "phase": "train", "update": 2871, "total_env_steps": 9187200, "episode_reward": 0.28910648822784424, "value_loss": 0.004215626232326031, "policy_loss": -0.0015561843981856782, "dist_entropy": 0.569890832901001, "actor_grad_norm": 0.09263172000646591, "critic_grad_norm": 0.024261176586151123, "ratio": 0.99964439868927, "entropy": 0.569890832901001, "incre_win_rate": 0.9361702127659575, "step": 2871}
{"time": 1767344580.9890912, "phase": "train", "update": 2872, "total_env_steps": 9190400, "episode_reward": 0.2745897173881531, "value_loss": 0.003949557431042194, "policy_loss": -0.0012611178548027624, "dist_entropy": 0.5709960579872131, "actor_grad_norm": 0.07367855310440063, "critic_grad_norm": 0.01707296259701252, "ratio": 0.9999778866767883, "entropy": 0.5709960579872131, "incre_win_rate": 0.9130434782608695, "step": 2872}
{"time": 1767344585.0932765, "phase": "train", "update": 2873, "total_env_steps": 9193600, "episode_reward": 0.28546926379203796, "value_loss": 0.004919209145009517, "policy_loss": -0.001282206144594511, "dist_entropy": 0.5753600835800171, "actor_grad_norm": 0.07750673592090607, "critic_grad_norm": 0.014045769348740578, "ratio": 0.9999416470527649, "entropy": 0.5753600835800171, "incre_win_rate": 0.9333333333333333, "step": 2873}
{"time": 1767344589.2580879, "phase": "train", "update": 2874, "total_env_steps": 9196800, "episode_reward": 0.2948721945285797, "value_loss": 0.0038976611103862524, "policy_loss": -0.0013311741908793805, "dist_entropy": 0.5889325261116027, "actor_grad_norm": 0.0843183770775795, "critic_grad_norm": 0.05012816935777664, "ratio": 1.0000876188278198, "entropy": 0.5889325261116027, "incre_win_rate": 1.0, "step": 2874}
{"time": 1767344593.376584, "phase": "train", "update": 2875, "total_env_steps": 9200000, "episode_reward": 0.290962815284729, "value_loss": 0.0022967437282204626, "policy_loss": -0.0013286658943911789, "dist_entropy": 0.5890336155891418, "actor_grad_norm": 0.08100005239248276, "critic_grad_norm": 0.04226784408092499, "ratio": 1.0000046491622925, "entropy": 0.5890336155891418, "incre_win_rate": 0.9777777777777777, "step": 2875}
{"time": 1767344597.4818997, "phase": "train", "update": 2876, "total_env_steps": 9203200, "episode_reward": 0.2912629544734955, "value_loss": 0.0026317483745515345, "policy_loss": -0.0013826449422225551, "dist_entropy": 0.592309033870697, "actor_grad_norm": 0.10387089103460312, "critic_grad_norm": 0.02727477066218853, "ratio": 0.9997374415397644, "entropy": 0.592309033870697, "incre_win_rate": 0.9791666666666666, "step": 2876}
{"time": 1767344606.7575536, "phase": "eval", "update": 2876, "total_env_steps": 9203200, "eval_win_rate": 0.90625, "eval_episode_reward": 19.3880380794702, "step": 2876}
{"time": 1767344610.8762662, "phase": "train", "update": 2877, "total_env_steps": 9206400, "episode_reward": 0.2809188663959503, "value_loss": 0.004240622837096452, "policy_loss": -0.0014227477428448766, "dist_entropy": 0.5706898927688598, "actor_grad_norm": 0.08888448774814606, "critic_grad_norm": 0.039338573813438416, "ratio": 0.9997516870498657, "entropy": 0.5706898927688598, "incre_win_rate": 0.9318181818181818, "step": 2877}
{"time": 1767344614.9878128, "phase": "train", "update": 2878, "total_env_steps": 9209600, "episode_reward": 0.29161426424980164, "value_loss": 0.0038680021185427903, "policy_loss": -0.0010973083670847926, "dist_entropy": 0.5673872709274292, "actor_grad_norm": 0.08093664050102234, "critic_grad_norm": 0.02202497608959675, "ratio": 0.99974125623703, "entropy": 0.5673872709274292, "incre_win_rate": 0.9387755102040817, "step": 2878}
{"time": 1767344619.080706, "phase": "train", "update": 2879, "total_env_steps": 9212800, "episode_reward": 0.2820902168750763, "value_loss": 0.005394522193819284, "policy_loss": -0.0018393053954568472, "dist_entropy": 0.5858633518218994, "actor_grad_norm": 0.09675055742263794, "critic_grad_norm": 0.03517034649848938, "ratio": 1.0000157356262207, "entropy": 0.5858633518218994, "incre_win_rate": 0.9130434782608695, "step": 2879}
{"time": 1767344623.1176739, "phase": "train", "update": 2880, "total_env_steps": 9216000, "episode_reward": 0.2805442810058594, "value_loss": 0.0066213089972734455, "policy_loss": -0.001289499556549867, "dist_entropy": 0.5776691913604737, "actor_grad_norm": 0.08730227500200272, "critic_grad_norm": 0.04288079962134361, "ratio": 0.9999698996543884, "entropy": 0.5776691913604737, "incre_win_rate": 0.9545454545454546, "step": 2880}
{"time": 1767344627.1745403, "phase": "train", "update": 2881, "total_env_steps": 9219200, "episode_reward": 0.28230082988739014, "value_loss": 0.004756532795727253, "policy_loss": -0.0015177267682176421, "dist_entropy": 0.6001735925674438, "actor_grad_norm": 0.09955985099077225, "critic_grad_norm": 0.03937950357794762, "ratio": 0.9999761581420898, "entropy": 0.6001735925674438, "incre_win_rate": 0.9130434782608695, "step": 2881}
{"time": 1767344631.2721088, "phase": "train", "update": 2882, "total_env_steps": 9222400, "episode_reward": 0.29573261737823486, "value_loss": 0.0022641018964350223, "policy_loss": -0.0010440875630379765, "dist_entropy": 0.6280189990997315, "actor_grad_norm": 0.07669561356306076, "critic_grad_norm": 0.043383970856666565, "ratio": 0.9999842643737793, "entropy": 0.6280189990997315, "incre_win_rate": 0.9791666666666666, "step": 2882}
{"time": 1767344635.3326008, "phase": "train", "update": 2883, "total_env_steps": 9225600, "episode_reward": 0.284374475479126, "value_loss": 0.004462962690740824, "policy_loss": -0.0014931217812179653, "dist_entropy": 0.5917146682739258, "actor_grad_norm": 0.08391829580068588, "critic_grad_norm": 0.04766491428017616, "ratio": 0.9999576807022095, "entropy": 0.5917146682739258, "incre_win_rate": 0.9148936170212766, "step": 2883}
{"time": 1767344639.4892027, "phase": "train", "update": 2884, "total_env_steps": 9228800, "episode_reward": 0.29826676845550537, "value_loss": 0.0026282222010195256, "policy_loss": -0.0011337957218117366, "dist_entropy": 0.6196191430091857, "actor_grad_norm": 0.06757864356040955, "critic_grad_norm": 0.034627508372068405, "ratio": 0.9999038577079773, "entropy": 0.6196191430091857, "incre_win_rate": 0.9791666666666666, "step": 2884}
{"time": 1767344643.6198025, "phase": "train", "update": 2885, "total_env_steps": 9232000, "episode_reward": 0.2764962911605835, "value_loss": 0.006585817504674196, "policy_loss": -0.0015577571059544938, "dist_entropy": 0.6199156284332276, "actor_grad_norm": 0.07177058607339859, "critic_grad_norm": 0.04674425721168518, "ratio": 0.9995309114456177, "entropy": 0.6199156284332276, "incre_win_rate": 0.9333333333333333, "step": 2885}
{"time": 1767344647.7265785, "phase": "train", "update": 2886, "total_env_steps": 9235200, "episode_reward": 0.2740878462791443, "value_loss": 0.0064932313747704026, "policy_loss": -0.0014811021060808117, "dist_entropy": 0.6009257912635804, "actor_grad_norm": 0.07843954861164093, "critic_grad_norm": 0.03088739514350891, "ratio": 0.9997124075889587, "entropy": 0.6009257912635804, "incre_win_rate": 0.8695652173913043, "step": 2886}
{"time": 1767344651.8227217, "phase": "train", "update": 2887, "total_env_steps": 9238400, "episode_reward": 0.2789900600910187, "value_loss": 0.004626641795039177, "policy_loss": -0.0010018850613320752, "dist_entropy": 0.6018420815467834, "actor_grad_norm": 0.06244445964694023, "critic_grad_norm": 0.04844217374920845, "ratio": 1.000104308128357, "entropy": 0.6018420815467834, "incre_win_rate": 0.9534883720930233, "step": 2887}
{"time": 1767344655.909635, "phase": "train", "update": 2888, "total_env_steps": 9241600, "episode_reward": 0.2715562880039215, "value_loss": 0.006435948703438043, "policy_loss": -0.0017099010166830909, "dist_entropy": 0.6280781745910644, "actor_grad_norm": 0.07821466773748398, "critic_grad_norm": 0.03955536335706711, "ratio": 1.0000402927398682, "entropy": 0.6280781745910644, "incre_win_rate": 0.8888888888888888, "step": 2888}
{"time": 1767344660.0927784, "phase": "train", "update": 2889, "total_env_steps": 9244800, "episode_reward": 0.28420117497444153, "value_loss": 0.003973950166255236, "policy_loss": -0.0014017741063724997, "dist_entropy": 0.6024766802787781, "actor_grad_norm": 0.08238880336284637, "critic_grad_norm": 0.028765225782990456, "ratio": 1.00005304813385, "entropy": 0.6024766802787781, "incre_win_rate": 0.9787234042553191, "step": 2889}
{"time": 1767344664.2363172, "phase": "train", "update": 2890, "total_env_steps": 9248000, "episode_reward": 0.2789471447467804, "value_loss": 0.003924651723355055, "policy_loss": -0.0011910958843923236, "dist_entropy": 0.614016842842102, "actor_grad_norm": 0.0724792554974556, "critic_grad_norm": 0.03465846925973892, "ratio": 0.9999850392341614, "entropy": 0.614016842842102, "incre_win_rate": 0.9111111111111111, "step": 2890}
{"time": 1767344668.34782, "phase": "train", "update": 2891, "total_env_steps": 9251200, "episode_reward": 0.28470665216445923, "value_loss": 0.004439429473131895, "policy_loss": -0.0014140102334104343, "dist_entropy": 0.6150994300842285, "actor_grad_norm": 0.07847719639539719, "critic_grad_norm": 0.041679784655570984, "ratio": 0.9998157620429993, "entropy": 0.6150994300842285, "incre_win_rate": 0.9361702127659575, "step": 2891}
{"time": 1767344672.475038, "phase": "train", "update": 2892, "total_env_steps": 9254400, "episode_reward": 0.2878808081150055, "value_loss": 0.0028690982609987257, "policy_loss": -0.0013479592050025246, "dist_entropy": 0.6193645477294922, "actor_grad_norm": 0.07357990741729736, "critic_grad_norm": 0.04360806569457054, "ratio": 0.9998306632041931, "entropy": 0.6193645477294922, "incre_win_rate": 0.9782608695652174, "step": 2892}
{"time": 1767344676.6072865, "phase": "train", "update": 2893, "total_env_steps": 9257600, "episode_reward": 0.29495862126350403, "value_loss": 0.003012847527861595, "policy_loss": -0.0012408390065791863, "dist_entropy": 0.6131752014160157, "actor_grad_norm": 0.09379494190216064, "critic_grad_norm": 0.023121826350688934, "ratio": 1.0001028776168823, "entropy": 0.6131752014160157, "incre_win_rate": 0.9791666666666666, "step": 2893}
{"time": 1767344680.7077215, "phase": "train", "update": 2894, "total_env_steps": 9260800, "episode_reward": 0.28246739506721497, "value_loss": 0.004518099781125784, "policy_loss": -0.0013126397456030502, "dist_entropy": 0.5941097378730774, "actor_grad_norm": 0.08765975385904312, "critic_grad_norm": 0.03898141160607338, "ratio": 1.0003526210784912, "entropy": 0.5941097378730774, "incre_win_rate": 0.9565217391304348, "step": 2894}
{"time": 1767344684.8264744, "phase": "train", "update": 2895, "total_env_steps": 9264000, "episode_reward": 0.2898716926574707, "value_loss": 0.0024863226804882287, "policy_loss": -0.000981432038521035, "dist_entropy": 0.6295174598693848, "actor_grad_norm": 0.09348120540380478, "critic_grad_norm": 0.021975576877593994, "ratio": 1.0000475645065308, "entropy": 0.6295174598693848, "incre_win_rate": 1.0, "step": 2895}
{"time": 1767344688.9989054, "phase": "train", "update": 2896, "total_env_steps": 9267200, "episode_reward": 0.2947878837585449, "value_loss": 0.001751650287769735, "policy_loss": -0.0012094004775519806, "dist_entropy": 0.6064557433128357, "actor_grad_norm": 0.07628344744443893, "critic_grad_norm": 0.01698680780827999, "ratio": 0.9999971389770508, "entropy": 0.6064557433128357, "incre_win_rate": 1.0, "step": 2896}
{"time": 1767344693.1347313, "phase": "train", "update": 2897, "total_env_steps": 9270400, "episode_reward": 0.29099753499031067, "value_loss": 0.0018475434975698591, "policy_loss": -0.001127689223736894, "dist_entropy": 0.6218749523162842, "actor_grad_norm": 0.07226072251796722, "critic_grad_norm": 0.02116866409778595, "ratio": 0.9997859001159668, "entropy": 0.6218749523162842, "incre_win_rate": 1.0, "step": 2897}
{"time": 1767344697.2668161, "phase": "train", "update": 2898, "total_env_steps": 9273600, "episode_reward": 0.2850884795188904, "value_loss": 0.003958404203876853, "policy_loss": -0.0011436299473615464, "dist_entropy": 0.5984598278999329, "actor_grad_norm": 0.08490957319736481, "critic_grad_norm": 0.02540663443505764, "ratio": 0.9998634457588196, "entropy": 0.5984598278999329, "incre_win_rate": 0.9555555555555556, "step": 2898}
{"time": 1767344701.4127128, "phase": "train", "update": 2899, "total_env_steps": 9276800, "episode_reward": 0.2817508280277252, "value_loss": 0.0035980378277599813, "policy_loss": -0.0013445963062764577, "dist_entropy": 0.6001664876937867, "actor_grad_norm": 0.07714279741048813, "critic_grad_norm": 0.016884777694940567, "ratio": 1.0000534057617188, "entropy": 0.6001664876937867, "incre_win_rate": 0.9565217391304348, "step": 2899}
{"time": 1767344705.5197902, "phase": "train", "update": 2900, "total_env_steps": 9280000, "episode_reward": 0.2851604223251343, "value_loss": 0.002337589394301176, "policy_loss": -0.0011893447356190912, "dist_entropy": 0.6132357716560364, "actor_grad_norm": 0.07855652272701263, "critic_grad_norm": 0.016758901998400688, "ratio": 0.9996969103813171, "entropy": 0.6132357716560364, "incre_win_rate": 1.0, "step": 2900}
{"time": 1767344709.6290915, "phase": "train", "update": 2901, "total_env_steps": 9283200, "episode_reward": 0.28007450699806213, "value_loss": 0.0033767505548894404, "policy_loss": -0.0014386118893424892, "dist_entropy": 0.6325782179832459, "actor_grad_norm": 0.07709606736898422, "critic_grad_norm": 0.026438742876052856, "ratio": 0.999661922454834, "entropy": 0.6325782179832459, "incre_win_rate": 0.9347826086956522, "step": 2901}
{"time": 1767344719.4465358, "phase": "eval", "update": 2901, "total_env_steps": 9283200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.730132450331126, "step": 2901}
{"time": 1767344723.556287, "phase": "train", "update": 2902, "total_env_steps": 9286400, "episode_reward": 0.27982980012893677, "value_loss": 0.004491483327001333, "policy_loss": -0.001552255507711564, "dist_entropy": 0.6232993841171265, "actor_grad_norm": 0.0841640904545784, "critic_grad_norm": 0.02409348450601101, "ratio": 1.0000916719436646, "entropy": 0.6232993841171265, "incre_win_rate": 0.9347826086956522, "step": 2902}
{"time": 1767344727.7007663, "phase": "train", "update": 2903, "total_env_steps": 9289600, "episode_reward": 0.285057932138443, "value_loss": 0.004561166372150182, "policy_loss": -0.001489297235622189, "dist_entropy": 0.6603417515754699, "actor_grad_norm": 0.1045285016298294, "critic_grad_norm": 0.03591027855873108, "ratio": 0.9997889399528503, "entropy": 0.6603417515754699, "incre_win_rate": 0.9333333333333333, "step": 2903}
{"time": 1767344731.8600547, "phase": "train", "update": 2904, "total_env_steps": 9292800, "episode_reward": 0.28394559025764465, "value_loss": 0.0037002299446612596, "policy_loss": -0.0007448412404500004, "dist_entropy": 0.6362358093261719, "actor_grad_norm": 0.0710919126868248, "critic_grad_norm": 0.022607123479247093, "ratio": 0.9997825026512146, "entropy": 0.6362358093261719, "incre_win_rate": 0.9782608695652174, "step": 2904}
{"time": 1767344736.006037, "phase": "train", "update": 2905, "total_env_steps": 9296000, "episode_reward": 0.28758692741394043, "value_loss": 0.004554626252502203, "policy_loss": -0.001559768266991135, "dist_entropy": 0.6456964254379273, "actor_grad_norm": 0.08307653665542603, "critic_grad_norm": 0.03710681200027466, "ratio": 1.0003376007080078, "entropy": 0.6456964254379273, "incre_win_rate": 0.9347826086956522, "step": 2905}
{"time": 1767344740.1006815, "phase": "train", "update": 2906, "total_env_steps": 9299200, "episode_reward": 0.2798960208892822, "value_loss": 0.005891498364508152, "policy_loss": -0.0010097276852974347, "dist_entropy": 0.6191628932952881, "actor_grad_norm": 0.06801438331604004, "critic_grad_norm": 0.02681787870824337, "ratio": 1.0002126693725586, "entropy": 0.6191628932952881, "incre_win_rate": 0.8936170212765957, "step": 2906}
{"time": 1767344744.2517958, "phase": "train", "update": 2907, "total_env_steps": 9302400, "episode_reward": 0.28560692071914673, "value_loss": 0.003242539009079337, "policy_loss": -0.001336131263939322, "dist_entropy": 0.6167347073554993, "actor_grad_norm": 0.07613813132047653, "critic_grad_norm": 0.012727230787277222, "ratio": 0.9997206926345825, "entropy": 0.6167347073554993, "incre_win_rate": 0.9347826086956522, "step": 2907}
{"time": 1767344748.3799853, "phase": "train", "update": 2908, "total_env_steps": 9305600, "episode_reward": 0.2826562821865082, "value_loss": 0.004319016635417938, "policy_loss": -0.0016025922601137666, "dist_entropy": 0.6212256193161011, "actor_grad_norm": 0.08613302558660507, "critic_grad_norm": 0.020053109154105186, "ratio": 0.9998073577880859, "entropy": 0.6212256193161011, "incre_win_rate": 0.9148936170212766, "step": 2908}
{"time": 1767344752.5032043, "phase": "train", "update": 2909, "total_env_steps": 9308800, "episode_reward": 0.28386589884757996, "value_loss": 0.0046093020588159565, "policy_loss": -0.0011116964484202186, "dist_entropy": 0.6404682874679566, "actor_grad_norm": 0.07612971216440201, "critic_grad_norm": 0.03053213469684124, "ratio": 1.000034213066101, "entropy": 0.6404682874679566, "incre_win_rate": 0.9318181818181818, "step": 2909}
{"time": 1767344756.6926436, "phase": "train", "update": 2910, "total_env_steps": 9312000, "episode_reward": 0.285270094871521, "value_loss": 0.00479530319571495, "policy_loss": -0.001050846092368829, "dist_entropy": 0.6523175835609436, "actor_grad_norm": 0.0699492022395134, "critic_grad_norm": 0.030398091301321983, "ratio": 0.9999745488166809, "entropy": 0.6523175835609436, "incre_win_rate": 0.9574468085106383, "step": 2910}
{"time": 1767344760.7789989, "phase": "train", "update": 2911, "total_env_steps": 9315200, "episode_reward": 0.2825579345226288, "value_loss": 0.004263717774301767, "policy_loss": -0.0017286028453852964, "dist_entropy": 0.6508613586425781, "actor_grad_norm": 0.08767763525247574, "critic_grad_norm": 0.025347188115119934, "ratio": 0.9999181032180786, "entropy": 0.6508613586425781, "incre_win_rate": 0.9555555555555556, "step": 2911}
{"time": 1767344764.9023738, "phase": "train", "update": 2912, "total_env_steps": 9318400, "episode_reward": 0.29003727436065674, "value_loss": 0.004786237142980099, "policy_loss": -0.001312632468591346, "dist_entropy": 0.645277988910675, "actor_grad_norm": 0.0777260959148407, "critic_grad_norm": 0.02889561653137207, "ratio": 1.0000425577163696, "entropy": 0.645277988910675, "incre_win_rate": 0.9583333333333334, "step": 2912}
{"time": 1767344769.0104778, "phase": "train", "update": 2913, "total_env_steps": 9321600, "episode_reward": 0.2781539857387543, "value_loss": 0.004090594127774239, "policy_loss": -0.0012221243961434425, "dist_entropy": 0.6382737994194031, "actor_grad_norm": 0.07779426127672195, "critic_grad_norm": 0.016318727284669876, "ratio": 1.0000118017196655, "entropy": 0.6382737994194031, "incre_win_rate": 0.9347826086956522, "step": 2913}
{"time": 1767344773.150597, "phase": "train", "update": 2914, "total_env_steps": 9324800, "episode_reward": 0.2718573808670044, "value_loss": 0.00803368529304862, "policy_loss": -0.0013688722117631614, "dist_entropy": 0.6456796407699585, "actor_grad_norm": 0.08946461975574493, "critic_grad_norm": 0.08860835433006287, "ratio": 0.9993287920951843, "entropy": 0.6456796407699585, "incre_win_rate": 0.8260869565217391, "step": 2914}
{"time": 1767344777.2914512, "phase": "train", "update": 2915, "total_env_steps": 9328000, "episode_reward": 0.2874922454357147, "value_loss": 0.0047686387784779075, "policy_loss": -0.0015403861909728533, "dist_entropy": 0.6647778391838074, "actor_grad_norm": 0.0778600201010704, "critic_grad_norm": 0.06475195288658142, "ratio": 0.9995720982551575, "entropy": 0.6647778391838074, "incre_win_rate": 0.9782608695652174, "step": 2915}
{"time": 1767344781.4079278, "phase": "train", "update": 2916, "total_env_steps": 9331200, "episode_reward": 0.2781084477901459, "value_loss": 0.0036057616118341683, "policy_loss": -0.0013625280114681003, "dist_entropy": 0.6437437415122986, "actor_grad_norm": 0.07357864081859589, "critic_grad_norm": 0.046151772141456604, "ratio": 0.9997779130935669, "entropy": 0.6437437415122986, "incre_win_rate": 0.9333333333333333, "step": 2916}
{"time": 1767344785.4777577, "phase": "train", "update": 2917, "total_env_steps": 9334400, "episode_reward": 0.28109633922576904, "value_loss": 0.0038971737492829563, "policy_loss": -0.0015752668108504509, "dist_entropy": 0.6360964298248291, "actor_grad_norm": 0.08118399232625961, "critic_grad_norm": 0.038541898131370544, "ratio": 0.9997243881225586, "entropy": 0.6360964298248291, "incre_win_rate": 0.9347826086956522, "step": 2917}
{"time": 1767344789.6060932, "phase": "train", "update": 2918, "total_env_steps": 9337600, "episode_reward": 0.2833692133426666, "value_loss": 0.003083412582054734, "policy_loss": -0.001207554043114989, "dist_entropy": 0.6425725817680359, "actor_grad_norm": 0.06697597354650497, "critic_grad_norm": 0.02711910381913185, "ratio": 0.9998357892036438, "entropy": 0.6425725817680359, "incre_win_rate": 0.9555555555555556, "step": 2918}
{"time": 1767344793.7327487, "phase": "train", "update": 2919, "total_env_steps": 9340800, "episode_reward": 0.2777732014656067, "value_loss": 0.0034387778490781785, "policy_loss": -0.0013750539090749303, "dist_entropy": 0.6450469017028808, "actor_grad_norm": 0.06852370500564575, "critic_grad_norm": 0.026637081056833267, "ratio": 1.0001856088638306, "entropy": 0.6450469017028808, "incre_win_rate": 0.9545454545454546, "step": 2919}
{"time": 1767344797.8516114, "phase": "train", "update": 2920, "total_env_steps": 9344000, "episode_reward": 0.2843087911605835, "value_loss": 0.0018755098339170218, "policy_loss": -0.0015839787282352802, "dist_entropy": 0.635828697681427, "actor_grad_norm": 0.08023544400930405, "critic_grad_norm": 0.021965239197015762, "ratio": 0.9999846816062927, "entropy": 0.635828697681427, "incre_win_rate": 0.9787234042553191, "step": 2920}
{"time": 1767344802.0193567, "phase": "train", "update": 2921, "total_env_steps": 9347200, "episode_reward": 0.28472113609313965, "value_loss": 0.004515142925083637, "policy_loss": -0.0012693603826861022, "dist_entropy": 0.6454370617866516, "actor_grad_norm": 0.07558722794055939, "critic_grad_norm": 0.020594866946339607, "ratio": 1.0000529289245605, "entropy": 0.6454370617866516, "incre_win_rate": 0.9361702127659575, "step": 2921}
{"time": 1767344806.1876218, "phase": "train", "update": 2922, "total_env_steps": 9350400, "episode_reward": 0.2908340096473694, "value_loss": 0.004757334105670452, "policy_loss": -0.0015390613814219023, "dist_entropy": 0.6628180265426635, "actor_grad_norm": 0.07448797672986984, "critic_grad_norm": 0.013804882764816284, "ratio": 0.9998356699943542, "entropy": 0.6628180265426635, "incre_win_rate": 0.9347826086956522, "step": 2922}
{"time": 1767344810.3032405, "phase": "train", "update": 2923, "total_env_steps": 9353600, "episode_reward": 0.2883360981941223, "value_loss": 0.005867541581392288, "policy_loss": -0.0014246609959043255, "dist_entropy": 0.6703700304031373, "actor_grad_norm": 0.09894809871912003, "critic_grad_norm": 0.019279997795820236, "ratio": 0.9995757937431335, "entropy": 0.6703700304031373, "incre_win_rate": 0.9361702127659575, "step": 2923}
{"time": 1767344814.4351642, "phase": "train", "update": 2924, "total_env_steps": 9356800, "episode_reward": 0.2845374643802643, "value_loss": 0.005626601260155439, "policy_loss": -0.0011836718210901155, "dist_entropy": 0.6606932878494263, "actor_grad_norm": 0.09538017958402634, "critic_grad_norm": 0.019706280902028084, "ratio": 1.000093936920166, "entropy": 0.6606932878494263, "incre_win_rate": 0.8936170212765957, "step": 2924}
{"time": 1767344818.5568407, "phase": "train", "update": 2925, "total_env_steps": 9360000, "episode_reward": 0.28664374351501465, "value_loss": 0.002848660945892334, "policy_loss": -0.0011450068428665362, "dist_entropy": 0.6775592923164367, "actor_grad_norm": 0.07709859311580658, "critic_grad_norm": 0.020392639562487602, "ratio": 1.0001877546310425, "entropy": 0.6775592923164367, "incre_win_rate": 1.0, "step": 2925}
{"time": 1767344822.6963692, "phase": "train", "update": 2926, "total_env_steps": 9363200, "episode_reward": 0.28538909554481506, "value_loss": 0.0032115849666297437, "policy_loss": -0.0011549871240002397, "dist_entropy": 0.6938055872917175, "actor_grad_norm": 0.07496010512113571, "critic_grad_norm": 0.0233690794557333, "ratio": 0.9997749328613281, "entropy": 0.6938055872917175, "incre_win_rate": 0.9574468085106383, "step": 2926}
{"time": 1767344831.6050284, "phase": "eval", "update": 2926, "total_env_steps": 9363200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.820364238410594, "step": 2926}
{"time": 1767344835.67603, "phase": "train", "update": 2927, "total_env_steps": 9366400, "episode_reward": 0.28561675548553467, "value_loss": 0.002578636398538947, "policy_loss": -0.0010981964775666597, "dist_entropy": 0.6541253209114075, "actor_grad_norm": 0.07430750131607056, "critic_grad_norm": 0.023187367245554924, "ratio": 0.9994258284568787, "entropy": 0.6541253209114075, "incre_win_rate": 0.9791666666666666, "step": 2927}
{"time": 1767344839.776904, "phase": "train", "update": 2928, "total_env_steps": 9369600, "episode_reward": 0.28496846556663513, "value_loss": 0.004737781081348658, "policy_loss": -0.001176373401510844, "dist_entropy": 0.6486000657081604, "actor_grad_norm": 0.09676401317119598, "critic_grad_norm": 0.01281224936246872, "ratio": 0.9998154044151306, "entropy": 0.6486000657081604, "incre_win_rate": 0.9545454545454546, "step": 2928}
{"time": 1767344843.8864288, "phase": "train", "update": 2929, "total_env_steps": 9372800, "episode_reward": 0.2905670702457428, "value_loss": 0.0037523915991187094, "policy_loss": -0.001316051769043014, "dist_entropy": 0.6342443346977233, "actor_grad_norm": 0.09073801338672638, "critic_grad_norm": 0.012106754817068577, "ratio": 0.9997249841690063, "entropy": 0.6342443346977233, "incre_win_rate": 0.9347826086956522, "step": 2929}
{"time": 1767344847.9890537, "phase": "train", "update": 2930, "total_env_steps": 9376000, "episode_reward": 0.29076260328292847, "value_loss": 0.00372223318554461, "policy_loss": -0.001380908592274821, "dist_entropy": 0.65119309425354, "actor_grad_norm": 0.09323658794164658, "critic_grad_norm": 0.011095684953033924, "ratio": 1.0001806020736694, "entropy": 0.65119309425354, "incre_win_rate": 0.9782608695652174, "step": 2930}
{"time": 1767344852.1652186, "phase": "train", "update": 2931, "total_env_steps": 9379200, "episode_reward": 0.2918626070022583, "value_loss": 0.0035862419288605453, "policy_loss": -0.0011802812000965446, "dist_entropy": 0.6545619249343873, "actor_grad_norm": 0.08853277564048767, "critic_grad_norm": 0.01817259192466736, "ratio": 1.0000686645507812, "entropy": 0.6545619249343873, "incre_win_rate": 0.9387755102040817, "step": 2931}
{"time": 1767344856.362115, "phase": "train", "update": 2932, "total_env_steps": 9382400, "episode_reward": 0.29802826046943665, "value_loss": 0.002210368402302265, "policy_loss": -0.001506182000646561, "dist_entropy": 0.6599443554878235, "actor_grad_norm": 0.0925799012184143, "critic_grad_norm": 0.02019556425511837, "ratio": 1.000057339668274, "entropy": 0.6599443554878235, "incre_win_rate": 0.9795918367346939, "step": 2932}
{"time": 1767344860.498916, "phase": "train", "update": 2933, "total_env_steps": 9385600, "episode_reward": 0.2932988405227661, "value_loss": 0.0037438522558659315, "policy_loss": -0.001515399416591734, "dist_entropy": 0.6219964027404785, "actor_grad_norm": 0.0918700322508812, "critic_grad_norm": 0.03154411539435387, "ratio": 0.999984860420227, "entropy": 0.6219964027404785, "incre_win_rate": 0.9387755102040817, "step": 2933}
{"time": 1767344864.642835, "phase": "train", "update": 2934, "total_env_steps": 9388800, "episode_reward": 0.2896088659763336, "value_loss": 0.0038000848609954117, "policy_loss": -0.0011913203745109514, "dist_entropy": 0.6223981857299805, "actor_grad_norm": 0.08665202558040619, "critic_grad_norm": 0.03627123683691025, "ratio": 0.9996231198310852, "entropy": 0.6223981857299805, "incre_win_rate": 0.9555555555555556, "step": 2934}
{"time": 1767344868.7824976, "phase": "train", "update": 2935, "total_env_steps": 9392000, "episode_reward": 0.2883061170578003, "value_loss": 0.00392345036379993, "policy_loss": -0.0012224492410638278, "dist_entropy": 0.6182617902755737, "actor_grad_norm": 0.06561940163373947, "critic_grad_norm": 0.01387884933501482, "ratio": 0.9998564124107361, "entropy": 0.6182617902755737, "incre_win_rate": 0.9574468085106383, "step": 2935}
{"time": 1767344872.8966286, "phase": "train", "update": 2936, "total_env_steps": 9395200, "episode_reward": 0.2845447063446045, "value_loss": 0.003024948248639703, "policy_loss": -0.00141845027053904, "dist_entropy": 0.6209123730659485, "actor_grad_norm": 0.08364307135343552, "critic_grad_norm": 0.020636113360524178, "ratio": 1.0002497434616089, "entropy": 0.6209123730659485, "incre_win_rate": 0.9777777777777777, "step": 2936}
{"time": 1767344877.030893, "phase": "train", "update": 2937, "total_env_steps": 9398400, "episode_reward": 0.2890335023403168, "value_loss": 0.0043156958185136315, "policy_loss": -0.0016658650986599356, "dist_entropy": 0.6114338040351868, "actor_grad_norm": 0.09491845220327377, "critic_grad_norm": 0.027924153953790665, "ratio": 1.000395655632019, "entropy": 0.6114338040351868, "incre_win_rate": 0.9574468085106383, "step": 2937}
{"time": 1767344881.1712153, "phase": "train", "update": 2938, "total_env_steps": 9401600, "episode_reward": 0.29004967212677, "value_loss": 0.004213108774274587, "policy_loss": -0.0016444146482335498, "dist_entropy": 0.5988313913345337, "actor_grad_norm": 0.09831589460372925, "critic_grad_norm": 0.01845533773303032, "ratio": 0.9999207854270935, "entropy": 0.5988313913345337, "incre_win_rate": 0.9574468085106383, "step": 2938}
{"time": 1767344885.2783148, "phase": "train", "update": 2939, "total_env_steps": 9404800, "episode_reward": 0.29095718264579773, "value_loss": 0.004114734847098589, "policy_loss": -0.0012674642330217979, "dist_entropy": 0.6114804863929748, "actor_grad_norm": 0.07649967819452286, "critic_grad_norm": 0.0288089569658041, "ratio": 1.0001095533370972, "entropy": 0.6114804863929748, "incre_win_rate": 0.9375, "step": 2939}
{"time": 1767344918.7618666, "phase": "train", "update": 2940, "total_env_steps": 9408000, "episode_reward": 0.28322020173072815, "value_loss": 0.06194397434592247, "policy_loss": -0.0012034204015643369, "dist_entropy": 0.5972026348114013, "actor_grad_norm": 0.09147480130195618, "critic_grad_norm": 0.22120773792266846, "ratio": 0.9999157786369324, "entropy": 0.5972026348114013, "incre_win_rate": 0.9767441860465116, "step": 2940}
{"time": 1767344922.862974, "phase": "train", "update": 2941, "total_env_steps": 9411200, "episode_reward": 0.29310017824172974, "value_loss": 0.005716607347130776, "policy_loss": -0.0012286800540930898, "dist_entropy": 0.5887591004371643, "actor_grad_norm": 0.08126070350408554, "critic_grad_norm": 0.16016258299350739, "ratio": 0.9996828436851501, "entropy": 0.5887591004371643, "incre_win_rate": 0.9791666666666666, "step": 2941}
{"time": 1767344926.9690483, "phase": "train", "update": 2942, "total_env_steps": 9414400, "episode_reward": 0.2928559482097626, "value_loss": 0.003898221906274557, "policy_loss": -0.0014346903600554128, "dist_entropy": 0.5935512065887452, "actor_grad_norm": 0.08618088811635971, "critic_grad_norm": 0.13842561841011047, "ratio": 1.0002647638320923, "entropy": 0.5935512065887452, "incre_win_rate": 0.9782608695652174, "step": 2942}
{"time": 1767344931.0983057, "phase": "train", "update": 2943, "total_env_steps": 9417600, "episode_reward": 0.297254741191864, "value_loss": 0.0028709933161735536, "policy_loss": -0.0013371515877185658, "dist_entropy": 0.6011221408843994, "actor_grad_norm": 0.1010989099740982, "critic_grad_norm": 0.05768692493438721, "ratio": 1.0001453161239624, "entropy": 0.6011221408843994, "incre_win_rate": 1.0, "step": 2943}
{"time": 1767344935.2242918, "phase": "train", "update": 2944, "total_env_steps": 9420800, "episode_reward": 0.2835415005683899, "value_loss": 0.005300499964505434, "policy_loss": -0.0011128812331307359, "dist_entropy": 0.5981058835983276, "actor_grad_norm": 0.07891829311847687, "critic_grad_norm": 0.11034691333770752, "ratio": 0.9999464154243469, "entropy": 0.5981058835983276, "incre_win_rate": 0.9555555555555556, "step": 2944}
{"time": 1767344939.320806, "phase": "train", "update": 2945, "total_env_steps": 9424000, "episode_reward": 0.28104978799819946, "value_loss": 0.005715965200215578, "policy_loss": -0.0012274990062664415, "dist_entropy": 0.5826525449752807, "actor_grad_norm": 0.07938423752784729, "critic_grad_norm": 0.09387462586164474, "ratio": 0.9998642802238464, "entropy": 0.5826525449752807, "incre_win_rate": 0.8936170212765957, "step": 2945}
{"time": 1767344943.4333606, "phase": "train", "update": 2946, "total_env_steps": 9427200, "episode_reward": 0.28188639879226685, "value_loss": 0.004160204296931624, "policy_loss": -0.0013643115598505062, "dist_entropy": 0.5721173524856568, "actor_grad_norm": 0.08672875910997391, "critic_grad_norm": 0.051880862563848495, "ratio": 1.0000038146972656, "entropy": 0.5721173524856568, "incre_win_rate": 0.9333333333333333, "step": 2946}
{"time": 1767344947.5661578, "phase": "train", "update": 2947, "total_env_steps": 9430400, "episode_reward": 0.28395748138427734, "value_loss": 0.007030876912176609, "policy_loss": -0.0010468487279074346, "dist_entropy": 0.5802161931991577, "actor_grad_norm": 0.07562743127346039, "critic_grad_norm": 0.06713899224996567, "ratio": 1.0001085996627808, "entropy": 0.5802161931991577, "incre_win_rate": 0.9565217391304348, "step": 2947}
{"time": 1767344951.675229, "phase": "train", "update": 2948, "total_env_steps": 9433600, "episode_reward": 0.2779858112335205, "value_loss": 0.006106876768171787, "policy_loss": -0.0012007327324127458, "dist_entropy": 0.5703848600387573, "actor_grad_norm": 0.09051916003227234, "critic_grad_norm": 0.049953579902648926, "ratio": 1.0001575946807861, "entropy": 0.5703848600387573, "incre_win_rate": 0.9347826086956522, "step": 2948}
{"time": 1767344955.8710551, "phase": "train", "update": 2949, "total_env_steps": 9436800, "episode_reward": 0.2843667268753052, "value_loss": 0.006314991880208254, "policy_loss": -0.0014222827327019516, "dist_entropy": 0.609301221370697, "actor_grad_norm": 0.07500021904706955, "critic_grad_norm": 0.05901532247662544, "ratio": 1.000045657157898, "entropy": 0.609301221370697, "incre_win_rate": 0.9148936170212766, "step": 2949}
{"time": 1767344959.9803922, "phase": "train", "update": 2950, "total_env_steps": 9440000, "episode_reward": 0.2814326584339142, "value_loss": 0.006098673213273287, "policy_loss": -0.001390500254060001, "dist_entropy": 0.6145839691162109, "actor_grad_norm": 0.06722681224346161, "critic_grad_norm": 0.06597931683063507, "ratio": 1.00001859664917, "entropy": 0.6145839691162109, "incre_win_rate": 0.9545454545454546, "step": 2950}
{"time": 1767344964.1445749, "phase": "train", "update": 2951, "total_env_steps": 9443200, "episode_reward": 0.2938617765903473, "value_loss": 0.002748942095786333, "policy_loss": -0.0010894343450644328, "dist_entropy": 0.6063580393791199, "actor_grad_norm": 0.07005218416452408, "critic_grad_norm": 0.054847218096256256, "ratio": 0.9998151659965515, "entropy": 0.6063580393791199, "incre_win_rate": 1.0, "step": 2951}
{"time": 1767344973.124965, "phase": "eval", "update": 2951, "total_env_steps": 9443200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.875827814569536, "step": 2951}
{"time": 1767344977.2543962, "phase": "train", "update": 2952, "total_env_steps": 9446400, "episode_reward": 0.29217612743377686, "value_loss": 0.004073979705572129, "policy_loss": -0.0012916786343723174, "dist_entropy": 0.6222389817237854, "actor_grad_norm": 0.08254703134298325, "critic_grad_norm": 0.05502460151910782, "ratio": 1.0002104043960571, "entropy": 0.6222389817237854, "incre_win_rate": 0.9574468085106383, "step": 2952}
{"time": 1767344981.408921, "phase": "train", "update": 2953, "total_env_steps": 9449600, "episode_reward": 0.2845571041107178, "value_loss": 0.004348435439169407, "policy_loss": -0.0010390162015337268, "dist_entropy": 0.6230357527732849, "actor_grad_norm": 0.07317821681499481, "critic_grad_norm": 0.041653864085674286, "ratio": 1.0000486373901367, "entropy": 0.6230357527732849, "incre_win_rate": 0.9361702127659575, "step": 2953}
{"time": 1767344985.5546353, "phase": "train", "update": 2954, "total_env_steps": 9452800, "episode_reward": 0.29448261857032776, "value_loss": 0.002794016245752573, "policy_loss": -0.0012425183770348625, "dist_entropy": 0.6302125930786133, "actor_grad_norm": 0.07999702543020248, "critic_grad_norm": 0.024998916313052177, "ratio": 1.0003588199615479, "entropy": 0.6302125930786133, "incre_win_rate": 1.0, "step": 2954}
{"time": 1767344989.6735544, "phase": "train", "update": 2955, "total_env_steps": 9456000, "episode_reward": 0.28923842310905457, "value_loss": 0.004099483136087656, "policy_loss": -0.0014707865538774456, "dist_entropy": 0.6486144900321961, "actor_grad_norm": 0.07912568002939224, "critic_grad_norm": 0.04363004118204117, "ratio": 1.000334620475769, "entropy": 0.6486144900321961, "incre_win_rate": 0.9361702127659575, "step": 2955}
{"time": 1767344993.8114228, "phase": "train", "update": 2956, "total_env_steps": 9459200, "episode_reward": 0.28656870126724243, "value_loss": 0.0038543880917131903, "policy_loss": -0.0009816683382277702, "dist_entropy": 0.6620819687843322, "actor_grad_norm": 0.06732072681188583, "critic_grad_norm": 0.03701416030526161, "ratio": 0.9999537467956543, "entropy": 0.6620819687843322, "incre_win_rate": 1.0, "step": 2956}
{"time": 1767344997.951108, "phase": "train", "update": 2957, "total_env_steps": 9462400, "episode_reward": 0.2931663990020752, "value_loss": 0.002538343099877238, "policy_loss": -0.0014982666966972147, "dist_entropy": 0.6666235446929931, "actor_grad_norm": 0.07874461263418198, "critic_grad_norm": 0.04391772300004959, "ratio": 0.9999748468399048, "entropy": 0.6666235446929931, "incre_win_rate": 0.9787234042553191, "step": 2957}
{"time": 1767345002.1353838, "phase": "train", "update": 2958, "total_env_steps": 9465600, "episode_reward": 0.28888246417045593, "value_loss": 0.002673988742753863, "policy_loss": -0.0015177221251249761, "dist_entropy": 0.6739591598510742, "actor_grad_norm": 0.0835581049323082, "critic_grad_norm": 0.030012577772140503, "ratio": 0.9998758435249329, "entropy": 0.6739591598510742, "incre_win_rate": 0.9782608695652174, "step": 2958}
{"time": 1767345006.8298955, "phase": "train", "update": 2959, "total_env_steps": 9468800, "episode_reward": 0.28233805298805237, "value_loss": 0.003368758363649249, "policy_loss": -0.0014023858171768211, "dist_entropy": 0.6842549204826355, "actor_grad_norm": 0.07627736032009125, "critic_grad_norm": 0.02584129013121128, "ratio": 0.9999690055847168, "entropy": 0.6842549204826355, "incre_win_rate": 0.9787234042553191, "step": 2959}
{"time": 1767345011.3674426, "phase": "train", "update": 2960, "total_env_steps": 9472000, "episode_reward": 0.2776629626750946, "value_loss": 0.005745109356939793, "policy_loss": -0.0013993904783205836, "dist_entropy": 0.6788166761398315, "actor_grad_norm": 0.07758861780166626, "critic_grad_norm": 0.0569632314145565, "ratio": 1.0000578165054321, "entropy": 0.6788166761398315, "incre_win_rate": 0.9111111111111111, "step": 2960}
{"time": 1767345015.684952, "phase": "train", "update": 2961, "total_env_steps": 9475200, "episode_reward": 0.27548840641975403, "value_loss": 0.005125020910054445, "policy_loss": -0.00137270676303487, "dist_entropy": 0.6754807591438293, "actor_grad_norm": 0.07977622002363205, "critic_grad_norm": 0.046586424112319946, "ratio": 0.9997453689575195, "entropy": 0.6754807591438293, "incre_win_rate": 0.9302325581395349, "step": 2961}
{"time": 1767345020.003571, "phase": "train", "update": 2962, "total_env_steps": 9478400, "episode_reward": 0.2748137414455414, "value_loss": 0.0059926996007561685, "policy_loss": -0.00120149677488115, "dist_entropy": 0.6794247031211853, "actor_grad_norm": 0.07645179331302643, "critic_grad_norm": 0.026577383279800415, "ratio": 0.9998389482498169, "entropy": 0.6794247031211853, "incre_win_rate": 0.9090909090909091, "step": 2962}
{"time": 1767345024.1384144, "phase": "train", "update": 2963, "total_env_steps": 9481600, "episode_reward": 0.28697431087493896, "value_loss": 0.0029594541527330877, "policy_loss": -0.0012315317860867481, "dist_entropy": 0.6893310189247132, "actor_grad_norm": 0.07033353298902512, "critic_grad_norm": 0.07062284648418427, "ratio": 1.0000202655792236, "entropy": 0.6893310189247132, "incre_win_rate": 0.9787234042553191, "step": 2963}
{"time": 1767345028.2527215, "phase": "train", "update": 2964, "total_env_steps": 9484800, "episode_reward": 0.28519144654273987, "value_loss": 0.0025230019818991423, "policy_loss": -0.0013402544159220042, "dist_entropy": 0.6795960307121277, "actor_grad_norm": 0.06782185286283493, "critic_grad_norm": 0.03661121055483818, "ratio": 0.9998728036880493, "entropy": 0.6795960307121277, "incre_win_rate": 1.0, "step": 2964}
{"time": 1767345032.3947315, "phase": "train", "update": 2965, "total_env_steps": 9488000, "episode_reward": 0.2903352677822113, "value_loss": 0.002328738011419773, "policy_loss": -0.001464844739403759, "dist_entropy": 0.6700608134269714, "actor_grad_norm": 0.07824652642011642, "critic_grad_norm": 0.018636999651789665, "ratio": 1.000245213508606, "entropy": 0.6700608134269714, "incre_win_rate": 0.9791666666666666, "step": 2965}
{"time": 1767345036.5202138, "phase": "train", "update": 2966, "total_env_steps": 9491200, "episode_reward": 0.28098925948143005, "value_loss": 0.005312359798699618, "policy_loss": -0.001525226907481425, "dist_entropy": 0.6371302843093872, "actor_grad_norm": 0.08264109492301941, "critic_grad_norm": 0.06863177567720413, "ratio": 1.0002267360687256, "entropy": 0.6371302843093872, "incre_win_rate": 0.9111111111111111, "step": 2966}
{"time": 1767345040.6207988, "phase": "train", "update": 2967, "total_env_steps": 9494400, "episode_reward": 0.286219984292984, "value_loss": 0.002990544307976961, "policy_loss": -0.0018074852825492372, "dist_entropy": 0.6683260679244996, "actor_grad_norm": 0.09197565168142319, "critic_grad_norm": 0.032949335873126984, "ratio": 0.9997574687004089, "entropy": 0.6683260679244996, "incre_win_rate": 0.9787234042553191, "step": 2967}
{"time": 1767345044.783272, "phase": "train", "update": 2968, "total_env_steps": 9497600, "episode_reward": 0.28654804825782776, "value_loss": 0.0034695058595389126, "policy_loss": -0.0011258975195545418, "dist_entropy": 0.663067078590393, "actor_grad_norm": 0.07306778430938721, "critic_grad_norm": 0.02523135580122471, "ratio": 0.9998957514762878, "entropy": 0.663067078590393, "incre_win_rate": 0.9782608695652174, "step": 2968}
{"time": 1767345048.9409258, "phase": "train", "update": 2969, "total_env_steps": 9500800, "episode_reward": 0.29058772325515747, "value_loss": 0.0025649402756243943, "policy_loss": -0.0013083149698374541, "dist_entropy": 0.6574211955070496, "actor_grad_norm": 0.07293178886175156, "critic_grad_norm": 0.03475074842572212, "ratio": 1.0003201961517334, "entropy": 0.6574211955070496, "incre_win_rate": 1.0, "step": 2969}
{"time": 1767345053.0981975, "phase": "train", "update": 2970, "total_env_steps": 9504000, "episode_reward": 0.2914983630180359, "value_loss": 0.0028614156413823365, "policy_loss": -0.0013644791591417515, "dist_entropy": 0.6882233262062073, "actor_grad_norm": 0.07209205627441406, "critic_grad_norm": 0.020862704142928123, "ratio": 0.9999530911445618, "entropy": 0.6882233262062073, "incre_win_rate": 0.9782608695652174, "step": 2970}
{"time": 1767345057.2081416, "phase": "train", "update": 2971, "total_env_steps": 9507200, "episode_reward": 0.2882155179977417, "value_loss": 0.002824940951541066, "policy_loss": -0.001320938430658103, "dist_entropy": 0.6719326257705689, "actor_grad_norm": 0.06998046487569809, "critic_grad_norm": 0.02429751679301262, "ratio": 0.9999580383300781, "entropy": 0.6719326257705689, "incre_win_rate": 0.9555555555555556, "step": 2971}
{"time": 1767345061.343103, "phase": "train", "update": 2972, "total_env_steps": 9510400, "episode_reward": 0.28971853852272034, "value_loss": 0.0015975280897691847, "policy_loss": -0.001393272921369082, "dist_entropy": 0.6724098682403564, "actor_grad_norm": 0.07759714126586914, "critic_grad_norm": 0.01955460198223591, "ratio": 1.000008225440979, "entropy": 0.6724098682403564, "incre_win_rate": 1.0, "step": 2972}
{"time": 1767345065.4610562, "phase": "train", "update": 2973, "total_env_steps": 9513600, "episode_reward": 0.2903078496456146, "value_loss": 0.0025811719708144663, "policy_loss": -0.0013267094221781407, "dist_entropy": 0.658449399471283, "actor_grad_norm": 0.073744036257267, "critic_grad_norm": 0.02950863540172577, "ratio": 0.9997836947441101, "entropy": 0.658449399471283, "incre_win_rate": 0.9574468085106383, "step": 2973}
{"time": 1767345069.5967865, "phase": "train", "update": 2974, "total_env_steps": 9516800, "episode_reward": 0.2865231931209564, "value_loss": 0.00412687174975872, "policy_loss": -0.0012580788886964456, "dist_entropy": 0.6676494598388671, "actor_grad_norm": 0.08914501965045929, "critic_grad_norm": 0.04532252252101898, "ratio": 0.9996371269226074, "entropy": 0.6676494598388671, "incre_win_rate": 0.9333333333333333, "step": 2974}
{"time": 1767345073.7288675, "phase": "train", "update": 2975, "total_env_steps": 9520000, "episode_reward": 0.2770022749900818, "value_loss": 0.0056559893302619456, "policy_loss": -0.0013410816105575041, "dist_entropy": 0.6734733581542969, "actor_grad_norm": 0.07766550034284592, "critic_grad_norm": 0.03625524416565895, "ratio": 0.9999906420707703, "entropy": 0.6734733581542969, "incre_win_rate": 0.9130434782608695, "step": 2975}
{"time": 1767345077.846306, "phase": "train", "update": 2976, "total_env_steps": 9523200, "episode_reward": 0.2852359116077423, "value_loss": 0.0038227098528295757, "policy_loss": -0.0011645437772145328, "dist_entropy": 0.6885945320129394, "actor_grad_norm": 0.07268877327442169, "critic_grad_norm": 0.0385456457734108, "ratio": 0.9998853802680969, "entropy": 0.6885945320129394, "incre_win_rate": 0.9782608695652174, "step": 2976}
{"time": 1767345086.8709376, "phase": "eval", "update": 2976, "total_env_steps": 9523200, "eval_win_rate": 1.0, "eval_episode_reward": 20.0, "step": 2976}
{"time": 1767345090.9983952, "phase": "train", "update": 2977, "total_env_steps": 9526400, "episode_reward": 0.2862706780433655, "value_loss": 0.004184040892869234, "policy_loss": -0.0011888749862329461, "dist_entropy": 0.6707936525344849, "actor_grad_norm": 0.09301028400659561, "critic_grad_norm": 0.024311481043696404, "ratio": 1.0000313520431519, "entropy": 0.6707936525344849, "incre_win_rate": 0.9565217391304348, "step": 2977}
{"time": 1767345095.2477114, "phase": "train", "update": 2978, "total_env_steps": 9529600, "episode_reward": 0.281485915184021, "value_loss": 0.005902477726340294, "policy_loss": -0.0011267817092402766, "dist_entropy": 0.6565943360328674, "actor_grad_norm": 0.0916655883193016, "critic_grad_norm": 0.019527336582541466, "ratio": 0.9998928904533386, "entropy": 0.6565943360328674, "incre_win_rate": 0.9130434782608695, "step": 2978}
{"time": 1767345099.3831484, "phase": "train", "update": 2979, "total_env_steps": 9532800, "episode_reward": 0.27516451478004456, "value_loss": 0.007128003239631653, "policy_loss": -0.0013888448928256025, "dist_entropy": 0.665394413471222, "actor_grad_norm": 0.09412967413663864, "critic_grad_norm": 0.03265932947397232, "ratio": 0.9999982118606567, "entropy": 0.665394413471222, "incre_win_rate": 0.9130434782608695, "step": 2979}
{"time": 1767345103.5295973, "phase": "train", "update": 2980, "total_env_steps": 9536000, "episode_reward": 0.2902897596359253, "value_loss": 0.0023828964214771984, "policy_loss": -0.001222346859915291, "dist_entropy": 0.6883004546165467, "actor_grad_norm": 0.10308697074651718, "critic_grad_norm": 0.018934795632958412, "ratio": 0.9999171495437622, "entropy": 0.6883004546165467, "incre_win_rate": 0.9583333333333334, "step": 2980}
{"time": 1767345107.6263266, "phase": "train", "update": 2981, "total_env_steps": 9539200, "episode_reward": 0.27675187587738037, "value_loss": 0.0061236322857439515, "policy_loss": -0.001155090419427296, "dist_entropy": 0.6816025853157044, "actor_grad_norm": 0.07381327450275421, "critic_grad_norm": 0.044188883155584335, "ratio": 1.0000752210617065, "entropy": 0.6816025853157044, "incre_win_rate": 0.9069767441860465, "step": 2981}
{"time": 1767345111.766629, "phase": "train", "update": 2982, "total_env_steps": 9542400, "episode_reward": 0.2890521287918091, "value_loss": 0.003820338984951377, "policy_loss": -0.001423015555842344, "dist_entropy": 0.6985726952552795, "actor_grad_norm": 0.07795392721891403, "critic_grad_norm": 0.05975215509533882, "ratio": 1.000270128250122, "entropy": 0.6985726952552795, "incre_win_rate": 0.9574468085106383, "step": 2982}
{"time": 1767345115.9583685, "phase": "train", "update": 2983, "total_env_steps": 9545600, "episode_reward": 0.2947232127189636, "value_loss": 0.0038620310369879007, "policy_loss": -0.0013841172200933726, "dist_entropy": 0.7085676789283752, "actor_grad_norm": 0.07671213150024414, "critic_grad_norm": 0.04279077425599098, "ratio": 1.0001212358474731, "entropy": 0.7085676789283752, "incre_win_rate": 0.9574468085106383, "step": 2983}
{"time": 1767345120.1022565, "phase": "train", "update": 2984, "total_env_steps": 9548800, "episode_reward": 0.28249070048332214, "value_loss": 0.0039335574954748155, "policy_loss": -0.0019491359117509433, "dist_entropy": 0.7046477913856506, "actor_grad_norm": 0.09015493839979172, "critic_grad_norm": 0.028257468715310097, "ratio": 0.9997623562812805, "entropy": 0.7046477913856506, "incre_win_rate": 0.9148936170212766, "step": 2984}
{"time": 1767345124.2577605, "phase": "train", "update": 2985, "total_env_steps": 9552000, "episode_reward": 0.2876055836677551, "value_loss": 0.0035664293449372054, "policy_loss": -0.0013172078503558282, "dist_entropy": 0.706778371334076, "actor_grad_norm": 0.08829542249441147, "critic_grad_norm": 0.022621890529990196, "ratio": 0.9998976588249207, "entropy": 0.706778371334076, "incre_win_rate": 0.9574468085106383, "step": 2985}
{"time": 1767345128.5808554, "phase": "train", "update": 2986, "total_env_steps": 9555200, "episode_reward": 0.28481581807136536, "value_loss": 0.0026092751882970332, "policy_loss": -0.0013705919314205063, "dist_entropy": 0.6837811231613159, "actor_grad_norm": 0.09003546088933945, "critic_grad_norm": 0.015844622626900673, "ratio": 0.9999909400939941, "entropy": 0.6837811231613159, "incre_win_rate": 0.9777777777777777, "step": 2986}
{"time": 1767345132.7260237, "phase": "train", "update": 2987, "total_env_steps": 9558400, "episode_reward": 0.2852809429168701, "value_loss": 0.0022360322065651415, "policy_loss": -0.0017183273574829627, "dist_entropy": 0.6972793817520142, "actor_grad_norm": 0.07235304266214371, "critic_grad_norm": 0.012968271970748901, "ratio": 0.9997017979621887, "entropy": 0.6972793817520142, "incre_win_rate": 0.9777777777777777, "step": 2987}
{"time": 1767345136.9618907, "phase": "train", "update": 2988, "total_env_steps": 9561600, "episode_reward": 0.2809757888317108, "value_loss": 0.003068237891420722, "policy_loss": -0.0011708893344678727, "dist_entropy": 0.6903711915016174, "actor_grad_norm": 0.06690564751625061, "critic_grad_norm": 0.012011473067104816, "ratio": 1.000073790550232, "entropy": 0.6903711915016174, "incre_win_rate": 0.9574468085106383, "step": 2988}
{"time": 1767345141.118414, "phase": "train", "update": 2989, "total_env_steps": 9564800, "episode_reward": 0.27828487753868103, "value_loss": 0.004492926970124244, "policy_loss": -0.0017015425976865117, "dist_entropy": 0.668744957447052, "actor_grad_norm": 0.08620163053274155, "critic_grad_norm": 0.027928052470088005, "ratio": 0.9999523162841797, "entropy": 0.668744957447052, "incre_win_rate": 0.8888888888888888, "step": 2989}
{"time": 1767345145.2618828, "phase": "train", "update": 2990, "total_env_steps": 9568000, "episode_reward": 0.2848489284515381, "value_loss": 0.00400469247251749, "policy_loss": -0.0013357322873723376, "dist_entropy": 0.6714206337928772, "actor_grad_norm": 0.07623594254255295, "critic_grad_norm": 0.016687793657183647, "ratio": 0.9996526837348938, "entropy": 0.6714206337928772, "incre_win_rate": 0.9772727272727273, "step": 2990}
{"time": 1767345149.3911018, "phase": "train", "update": 2991, "total_env_steps": 9571200, "episode_reward": 0.27450746297836304, "value_loss": 0.006856880802661181, "policy_loss": -0.001195129752996138, "dist_entropy": 0.666832971572876, "actor_grad_norm": 0.07787299901247025, "critic_grad_norm": 0.025522535666823387, "ratio": 0.9998243451118469, "entropy": 0.666832971572876, "incre_win_rate": 0.9130434782608695, "step": 2991}
{"time": 1767345153.5400233, "phase": "train", "update": 2992, "total_env_steps": 9574400, "episode_reward": 0.28040462732315063, "value_loss": 0.002608117088675499, "policy_loss": -0.001447362711293465, "dist_entropy": 0.6803244590759278, "actor_grad_norm": 0.0774209201335907, "critic_grad_norm": 0.012620316818356514, "ratio": 0.9997426271438599, "entropy": 0.6803244590759278, "incre_win_rate": 0.9565217391304348, "step": 2992}
{"time": 1767345157.684032, "phase": "train", "update": 2993, "total_env_steps": 9577600, "episode_reward": 0.2874523997306824, "value_loss": 0.00210262481123209, "policy_loss": -0.0015732811806385527, "dist_entropy": 0.6674909234046936, "actor_grad_norm": 0.08561138063669205, "critic_grad_norm": 0.03586956486105919, "ratio": 0.9995080232620239, "entropy": 0.6674909234046936, "incre_win_rate": 1.0, "step": 2993}
{"time": 1767345161.8325858, "phase": "train", "update": 2994, "total_env_steps": 9580800, "episode_reward": 0.2827928364276886, "value_loss": 0.0053506562486290935, "policy_loss": -0.0011793550782299266, "dist_entropy": 0.6301238536834717, "actor_grad_norm": 0.06844564527273178, "critic_grad_norm": 0.027226654812693596, "ratio": 0.9999269843101501, "entropy": 0.6301238536834717, "incre_win_rate": 0.9130434782608695, "step": 2994}
{"time": 1767345166.0179586, "phase": "train", "update": 2995, "total_env_steps": 9584000, "episode_reward": 0.28841060400009155, "value_loss": 0.004900994058698416, "policy_loss": -0.0015041284855296766, "dist_entropy": 0.6321801543235779, "actor_grad_norm": 0.08644932508468628, "critic_grad_norm": 0.022188330069184303, "ratio": 1.0006237030029297, "entropy": 0.6321801543235779, "incre_win_rate": 0.9375, "step": 2995}
{"time": 1767345170.159768, "phase": "train", "update": 2996, "total_env_steps": 9587200, "episode_reward": 0.2760016620159149, "value_loss": 0.006240404583513737, "policy_loss": -0.0016299535232548123, "dist_entropy": 0.632001531124115, "actor_grad_norm": 0.09411584585905075, "critic_grad_norm": 0.05760765075683594, "ratio": 0.9996734857559204, "entropy": 0.632001531124115, "incre_win_rate": 0.8837209302325582, "step": 2996}
{"time": 1767345174.3259208, "phase": "train", "update": 2997, "total_env_steps": 9590400, "episode_reward": 0.2837913930416107, "value_loss": 0.003548872983083129, "policy_loss": -0.001393527370788661, "dist_entropy": 0.6507861852645874, "actor_grad_norm": 0.08864358067512512, "critic_grad_norm": 0.02736300230026245, "ratio": 1.0002024173736572, "entropy": 0.6507861852645874, "incre_win_rate": 0.9333333333333333, "step": 2997}
{"time": 1767345178.455857, "phase": "train", "update": 2998, "total_env_steps": 9593600, "episode_reward": 0.2853911519050598, "value_loss": 0.0034424610435962676, "policy_loss": -0.001168674840429773, "dist_entropy": 0.648714017868042, "actor_grad_norm": 0.08258730173110962, "critic_grad_norm": 0.030662838369607925, "ratio": 0.9998294115066528, "entropy": 0.648714017868042, "incre_win_rate": 0.9795918367346939, "step": 2998}
{"time": 1767345182.6166122, "phase": "train", "update": 2999, "total_env_steps": 9596800, "episode_reward": 0.28035181760787964, "value_loss": 0.004519753064960242, "policy_loss": -0.001217547575062028, "dist_entropy": 0.6535616278648376, "actor_grad_norm": 0.07657361030578613, "critic_grad_norm": 0.04114377126097679, "ratio": 0.9999423027038574, "entropy": 0.6535616278648376, "incre_win_rate": 0.9555555555555556, "step": 2999}
{"time": 1767345186.7594972, "phase": "train", "update": 3000, "total_env_steps": 9600000, "episode_reward": 0.2838534712791443, "value_loss": 0.003591690445318818, "policy_loss": -0.0013542038345931927, "dist_entropy": 0.6646006107330322, "actor_grad_norm": 0.09733923524618149, "critic_grad_norm": 0.030101671814918518, "ratio": 1.0006858110427856, "entropy": 0.6646006107330322, "incre_win_rate": 0.9555555555555556, "step": 3000}
{"time": 1767345190.9438717, "phase": "train", "update": 3001, "total_env_steps": 9603200, "episode_reward": 0.2832321226596832, "value_loss": 0.004019131232053041, "policy_loss": -0.0016175114004113311, "dist_entropy": 0.6259234547615051, "actor_grad_norm": 0.08433540910482407, "critic_grad_norm": 0.01799887791275978, "ratio": 0.9999592900276184, "entropy": 0.6259234547615051, "incre_win_rate": 0.9565217391304348, "step": 3001}
{"time": 1767345200.1654732, "phase": "eval", "update": 3001, "total_env_steps": 9603200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.87789735099338, "step": 3001}
{"time": 1767345204.3312197, "phase": "train", "update": 3002, "total_env_steps": 9606400, "episode_reward": 0.2846233546733856, "value_loss": 0.002642638422548771, "policy_loss": -0.001283046489053774, "dist_entropy": 0.6477473139762878, "actor_grad_norm": 0.08267682790756226, "critic_grad_norm": 0.041286565363407135, "ratio": 0.9998902678489685, "entropy": 0.6477473139762878, "incre_win_rate": 0.9782608695652174, "step": 3002}
{"time": 1767345208.4825182, "phase": "train", "update": 3003, "total_env_steps": 9609600, "episode_reward": 0.28477078676223755, "value_loss": 0.00420919070020318, "policy_loss": -0.0013558353364729215, "dist_entropy": 0.6318913340568543, "actor_grad_norm": 0.0806492269039154, "critic_grad_norm": 0.027763700112700462, "ratio": 1.0002135038375854, "entropy": 0.6318913340568543, "incre_win_rate": 0.9555555555555556, "step": 3003}
{"time": 1767345212.6206746, "phase": "train", "update": 3004, "total_env_steps": 9612800, "episode_reward": 0.2862127423286438, "value_loss": 0.004620177578181029, "policy_loss": -0.0013123950181125111, "dist_entropy": 0.6358620762825012, "actor_grad_norm": 0.0881132036447525, "critic_grad_norm": 0.027625268325209618, "ratio": 0.9999419450759888, "entropy": 0.6358620762825012, "incre_win_rate": 0.9387755102040817, "step": 3004}
{"time": 1767345216.7569518, "phase": "train", "update": 3005, "total_env_steps": 9616000, "episode_reward": 0.2833816409111023, "value_loss": 0.005634760856628418, "policy_loss": -0.0014180624482527549, "dist_entropy": 0.6502814769744873, "actor_grad_norm": 0.07368268817663193, "critic_grad_norm": 0.03155548498034477, "ratio": 1.000144362449646, "entropy": 0.6502814769744873, "incre_win_rate": 0.9534883720930233, "step": 3005}
{"time": 1767345220.8694952, "phase": "train", "update": 3006, "total_env_steps": 9619200, "episode_reward": 0.2820126414299011, "value_loss": 0.005831007566303015, "policy_loss": -0.0010403185769774837, "dist_entropy": 0.6415838718414306, "actor_grad_norm": 0.08319550007581711, "critic_grad_norm": 0.017834892496466637, "ratio": 1.0001728534698486, "entropy": 0.6415838718414306, "incre_win_rate": 0.9148936170212766, "step": 3006}
{"time": 1767345225.0312972, "phase": "train", "update": 3007, "total_env_steps": 9622400, "episode_reward": 0.28396522998809814, "value_loss": 0.004646211490035057, "policy_loss": -0.001398267883172366, "dist_entropy": 0.6694328427314759, "actor_grad_norm": 0.08283670246601105, "critic_grad_norm": 0.01838262937963009, "ratio": 1.000091552734375, "entropy": 0.6694328427314759, "incre_win_rate": 0.9166666666666666, "step": 3007}
{"time": 1767345229.1817794, "phase": "train", "update": 3008, "total_env_steps": 9625600, "episode_reward": 0.2771812677383423, "value_loss": 0.006274351011961698, "policy_loss": -0.00156427290878014, "dist_entropy": 0.6619969844818115, "actor_grad_norm": 0.09979426115751266, "critic_grad_norm": 0.05315809324383736, "ratio": 0.9999487996101379, "entropy": 0.6619969844818115, "incre_win_rate": 0.8863636363636364, "step": 3008}
{"time": 1767345233.2985544, "phase": "train", "update": 3009, "total_env_steps": 9628800, "episode_reward": 0.28078019618988037, "value_loss": 0.005396862979978323, "policy_loss": -0.0011421989525474351, "dist_entropy": 0.6637763619422913, "actor_grad_norm": 0.09681548923254013, "critic_grad_norm": 0.027679314836859703, "ratio": 0.9999702572822571, "entropy": 0.6637763619422913, "incre_win_rate": 0.9148936170212766, "step": 3009}
{"time": 1767345237.4141724, "phase": "train", "update": 3010, "total_env_steps": 9632000, "episode_reward": 0.2732429802417755, "value_loss": 0.005487005412578583, "policy_loss": -0.0010337917931188656, "dist_entropy": 0.6620502829551697, "actor_grad_norm": 0.0861581340432167, "critic_grad_norm": 0.030148332938551903, "ratio": 1.0000592470169067, "entropy": 0.6620502829551697, "incre_win_rate": 0.9523809523809523, "step": 3010}
{"time": 1767345241.5950317, "phase": "train", "update": 3011, "total_env_steps": 9635200, "episode_reward": 0.28426894545555115, "value_loss": 0.005321070179343223, "policy_loss": -0.0012517884358189235, "dist_entropy": 0.6685415387153626, "actor_grad_norm": 0.10266095399856567, "critic_grad_norm": 0.024723319336771965, "ratio": 0.999699056148529, "entropy": 0.6685415387153626, "incre_win_rate": 0.9375, "step": 3011}
{"time": 1767345245.7410858, "phase": "train", "update": 3012, "total_env_steps": 9638400, "episode_reward": 0.2787086069583893, "value_loss": 0.007260374166071415, "policy_loss": -0.0010480126773472875, "dist_entropy": 0.6807291865348816, "actor_grad_norm": 0.09946400672197342, "critic_grad_norm": 0.035020407289266586, "ratio": 0.9995371103286743, "entropy": 0.6807291865348816, "incre_win_rate": 0.8723404255319149, "step": 3012}
{"time": 1767345250.2054899, "phase": "train", "update": 3013, "total_env_steps": 9641600, "episode_reward": 0.27944692969322205, "value_loss": 0.008128905110061169, "policy_loss": -0.0015249418456672714, "dist_entropy": 0.6606773972511292, "actor_grad_norm": 0.09997036308050156, "critic_grad_norm": 0.03848078101873398, "ratio": 0.9998520016670227, "entropy": 0.6606773972511292, "incre_win_rate": 0.8888888888888888, "step": 3013}
{"time": 1767345254.5838373, "phase": "train", "update": 3014, "total_env_steps": 9644800, "episode_reward": 0.27885711193084717, "value_loss": 0.011293790489435195, "policy_loss": -0.0016992662562596906, "dist_entropy": 0.6766733527183533, "actor_grad_norm": 0.09417085349559784, "critic_grad_norm": 0.04362350329756737, "ratio": 1.0000919103622437, "entropy": 0.6766733527183533, "incre_win_rate": 0.8695652173913043, "step": 3014}
{"time": 1767345258.7338793, "phase": "train", "update": 3015, "total_env_steps": 9648000, "episode_reward": 0.2728104293346405, "value_loss": 0.004966874793171883, "policy_loss": -0.0015178487726728918, "dist_entropy": 0.6799060106277466, "actor_grad_norm": 0.1001039668917656, "critic_grad_norm": 0.052504003047943115, "ratio": 1.0001130104064941, "entropy": 0.6799060106277466, "incre_win_rate": 0.8666666666666667, "step": 3015}
{"time": 1767345262.8744693, "phase": "train", "update": 3016, "total_env_steps": 9651200, "episode_reward": 0.2919650375843048, "value_loss": 0.0029553919564932586, "policy_loss": -0.0012523840946952803, "dist_entropy": 0.6814675450325012, "actor_grad_norm": 0.08923548460006714, "critic_grad_norm": 0.04878205806016922, "ratio": 1.0000685453414917, "entropy": 0.6814675450325012, "incre_win_rate": 0.9787234042553191, "step": 3016}
{"time": 1767345266.9960592, "phase": "train", "update": 3017, "total_env_steps": 9654400, "episode_reward": 0.277631938457489, "value_loss": 0.006216118298470974, "policy_loss": -0.001303038186851424, "dist_entropy": 0.6345268368721009, "actor_grad_norm": 0.09030117839574814, "critic_grad_norm": 0.0253413375467062, "ratio": 0.9998003840446472, "entropy": 0.6345268368721009, "incre_win_rate": 0.8888888888888888, "step": 3017}
{"time": 1767345271.135243, "phase": "train", "update": 3018, "total_env_steps": 9657600, "episode_reward": 0.2923499643802643, "value_loss": 0.0035583556164056063, "policy_loss": -0.001022463254472683, "dist_entropy": 0.6456774711608887, "actor_grad_norm": 0.07731636613607407, "critic_grad_norm": 0.017645088955760002, "ratio": 0.9998106360435486, "entropy": 0.6456774711608887, "incre_win_rate": 0.9787234042553191, "step": 3018}
{"time": 1767345275.2569225, "phase": "train", "update": 3019, "total_env_steps": 9660800, "episode_reward": 0.27663081884384155, "value_loss": 0.008170130848884582, "policy_loss": -0.0012355173315853562, "dist_entropy": 0.6450208306312561, "actor_grad_norm": 0.07785370200872421, "critic_grad_norm": 0.03372079133987427, "ratio": 0.9997334480285645, "entropy": 0.6450208306312561, "incre_win_rate": 0.8723404255319149, "step": 3019}
{"time": 1767345279.4180396, "phase": "train", "update": 3020, "total_env_steps": 9664000, "episode_reward": 0.2745198607444763, "value_loss": 0.007525615021586418, "policy_loss": -0.0013942816597314334, "dist_entropy": 0.648910653591156, "actor_grad_norm": 0.07853394001722336, "critic_grad_norm": 0.020500654354691505, "ratio": 0.9999380111694336, "entropy": 0.648910653591156, "incre_win_rate": 0.8636363636363636, "step": 3020}
{"time": 1767345283.6133528, "phase": "train", "update": 3021, "total_env_steps": 9667200, "episode_reward": 0.2816721796989441, "value_loss": 0.004811672121286392, "policy_loss": -0.0015870450186142194, "dist_entropy": 0.6477327942848206, "actor_grad_norm": 0.0970243364572525, "critic_grad_norm": 0.03203892335295677, "ratio": 0.9999357461929321, "entropy": 0.6477327942848206, "incre_win_rate": 0.9574468085106383, "step": 3021}
{"time": 1767345287.7774787, "phase": "train", "update": 3022, "total_env_steps": 9670400, "episode_reward": 0.2843925952911377, "value_loss": 0.0035920387133955957, "policy_loss": -0.0013596472189021825, "dist_entropy": 0.6589638948440552, "actor_grad_norm": 0.08400563895702362, "critic_grad_norm": 0.03464426472783089, "ratio": 1.0001484155654907, "entropy": 0.6589638948440552, "incre_win_rate": 1.0, "step": 3022}
{"time": 1767345291.9496288, "phase": "train", "update": 3023, "total_env_steps": 9673600, "episode_reward": 0.28537094593048096, "value_loss": 0.004194131493568421, "policy_loss": -0.0014753139411837423, "dist_entropy": 0.6426785945892334, "actor_grad_norm": 0.08472155779600143, "critic_grad_norm": 0.03925392031669617, "ratio": 1.0001444816589355, "entropy": 0.6426785945892334, "incre_win_rate": 0.9148936170212766, "step": 3023}
{"time": 1767345296.060804, "phase": "train", "update": 3024, "total_env_steps": 9676800, "episode_reward": 0.28077197074890137, "value_loss": 0.00414963522925973, "policy_loss": -0.0013262768746230337, "dist_entropy": 0.6559000611305237, "actor_grad_norm": 0.07305534929037094, "critic_grad_norm": 0.015912044793367386, "ratio": 1.0000600814819336, "entropy": 0.6559000611305237, "incre_win_rate": 0.9333333333333333, "step": 3024}
{"time": 1767345300.1811876, "phase": "train", "update": 3025, "total_env_steps": 9680000, "episode_reward": 0.28739237785339355, "value_loss": 0.00366676882840693, "policy_loss": -0.0009308215983542034, "dist_entropy": 0.6565478205680847, "actor_grad_norm": 0.07483243197202682, "critic_grad_norm": 0.015602277591824532, "ratio": 0.9999311566352844, "entropy": 0.6565478205680847, "incre_win_rate": 0.9574468085106383, "step": 3025}
{"time": 1767345304.3356051, "phase": "train", "update": 3026, "total_env_steps": 9683200, "episode_reward": 0.281765341758728, "value_loss": 0.0059464692138135435, "policy_loss": -0.0012681082816090594, "dist_entropy": 0.6745122075080872, "actor_grad_norm": 0.07956531643867493, "critic_grad_norm": 0.0513647086918354, "ratio": 1.00014328956604, "entropy": 0.6745122075080872, "incre_win_rate": 0.9130434782608695, "step": 3026}
{"time": 1767345313.5550497, "phase": "eval", "update": 3026, "total_env_steps": 9683200, "eval_win_rate": 0.96875, "eval_episode_reward": 19.84312913907285, "step": 3026}
{"time": 1767345317.7075186, "phase": "train", "update": 3027, "total_env_steps": 9686400, "episode_reward": 0.29421359300613403, "value_loss": 0.003825232433155179, "policy_loss": -0.0014490300040719717, "dist_entropy": 0.7001857161521912, "actor_grad_norm": 0.08477740734815598, "critic_grad_norm": 0.03400271758437157, "ratio": 0.9999047517776489, "entropy": 0.7001857161521912, "incre_win_rate": 0.9787234042553191, "step": 3027}
{"time": 1767345321.8531415, "phase": "train", "update": 3028, "total_env_steps": 9689600, "episode_reward": 0.28717613220214844, "value_loss": 0.004487771727144718, "policy_loss": -0.0013850757457319674, "dist_entropy": 0.6657108306884766, "actor_grad_norm": 0.07852846384048462, "critic_grad_norm": 0.029335159808397293, "ratio": 1.0001245737075806, "entropy": 0.6657108306884766, "incre_win_rate": 0.9565217391304348, "step": 3028}
{"time": 1767345325.9900541, "phase": "train", "update": 3029, "total_env_steps": 9692800, "episode_reward": 0.28222787380218506, "value_loss": 0.0032287743408232926, "policy_loss": -0.0013993943485573368, "dist_entropy": 0.66472829580307, "actor_grad_norm": 0.10922320187091827, "critic_grad_norm": 0.021314913406968117, "ratio": 1.0000718832015991, "entropy": 0.66472829580307, "incre_win_rate": 0.9565217391304348, "step": 3029}
{"time": 1767345330.1363342, "phase": "train", "update": 3030, "total_env_steps": 9696000, "episode_reward": 0.2841716706752777, "value_loss": 0.006403717491775751, "policy_loss": -0.000918422680976505, "dist_entropy": 0.6661570549011231, "actor_grad_norm": 0.08188517391681671, "critic_grad_norm": 0.02659395895898342, "ratio": 0.9998330473899841, "entropy": 0.6661570549011231, "incre_win_rate": 0.9347826086956522, "step": 3030}
{"time": 1767345334.263183, "phase": "train", "update": 3031, "total_env_steps": 9699200, "episode_reward": 0.29052358865737915, "value_loss": 0.003152419254183769, "policy_loss": -0.0013918362345838986, "dist_entropy": 0.6480537533760071, "actor_grad_norm": 0.09578128159046173, "critic_grad_norm": 0.0547531358897686, "ratio": 0.9997914433479309, "entropy": 0.6480537533760071, "incre_win_rate": 0.9791666666666666, "step": 3031}
{"time": 1767345338.4427042, "phase": "train", "update": 3032, "total_env_steps": 9702400, "episode_reward": 0.280747652053833, "value_loss": 0.004860907606780529, "policy_loss": -0.0012117000263412337, "dist_entropy": 0.6593921899795532, "actor_grad_norm": 0.08251192420721054, "critic_grad_norm": 0.034393470734357834, "ratio": 0.9996184706687927, "entropy": 0.6593921899795532, "incre_win_rate": 0.9347826086956522, "step": 3032}
{"time": 1767345342.650559, "phase": "train", "update": 3033, "total_env_steps": 9705600, "episode_reward": 0.2892177104949951, "value_loss": 0.001991295488551259, "policy_loss": -0.001137815468260328, "dist_entropy": 0.643397581577301, "actor_grad_norm": 0.07729125022888184, "critic_grad_norm": 0.04011332616209984, "ratio": 0.9999621510505676, "entropy": 0.643397581577301, "incre_win_rate": 0.9777777777777777, "step": 3033}
{"time": 1767345346.7815905, "phase": "train", "update": 3034, "total_env_steps": 9708800, "episode_reward": 0.28029388189315796, "value_loss": 0.005209216475486755, "policy_loss": -0.0012259851858626547, "dist_entropy": 0.6510822892189025, "actor_grad_norm": 0.0731135681271553, "critic_grad_norm": 0.04821709915995598, "ratio": 0.999701201915741, "entropy": 0.6510822892189025, "incre_win_rate": 0.9347826086956522, "step": 3034}
{"time": 1767345350.8927307, "phase": "train", "update": 3035, "total_env_steps": 9712000, "episode_reward": 0.2881508767604828, "value_loss": 0.002847460564225912, "policy_loss": -0.001613037910686188, "dist_entropy": 0.6370540976524353, "actor_grad_norm": 0.08612170070409775, "critic_grad_norm": 0.03808305412530899, "ratio": 1.0001660585403442, "entropy": 0.6370540976524353, "incre_win_rate": 0.9574468085106383, "step": 3035}
{"time": 1767345355.0183203, "phase": "train", "update": 3036, "total_env_steps": 9715200, "episode_reward": 0.28485098481178284, "value_loss": 0.0036683307960629465, "policy_loss": -0.001481510400713315, "dist_entropy": 0.6538692474365234, "actor_grad_norm": 0.0787358507514, "critic_grad_norm": 0.028359493240714073, "ratio": 0.9998138546943665, "entropy": 0.6538692474365234, "incre_win_rate": 0.9333333333333333, "step": 3036}
{"time": 1767345359.1602554, "phase": "train", "update": 3037, "total_env_steps": 9718400, "episode_reward": 0.29123085737228394, "value_loss": 0.004422045592218637, "policy_loss": -0.0011607539966881574, "dist_entropy": 0.6393279671669007, "actor_grad_norm": 0.07597529143095016, "critic_grad_norm": 0.03762828931212425, "ratio": 1.0000783205032349, "entropy": 0.6393279671669007, "incre_win_rate": 0.9375, "step": 3037}
{"time": 1767345363.3151543, "phase": "train", "update": 3038, "total_env_steps": 9721600, "episode_reward": 0.2836630940437317, "value_loss": 0.005512815713882446, "policy_loss": -0.0014306299932599132, "dist_entropy": 0.6411662220954895, "actor_grad_norm": 0.07473017275333405, "critic_grad_norm": 0.02983025088906288, "ratio": 0.9994713068008423, "entropy": 0.6411662220954895, "incre_win_rate": 0.9565217391304348, "step": 3038}
{"time": 1767345367.4634752, "phase": "train", "update": 3039, "total_env_steps": 9724800, "episode_reward": 0.28864961862564087, "value_loss": 0.0051454008556902405, "policy_loss": -0.001424705516384961, "dist_entropy": 0.6595202088356018, "actor_grad_norm": 0.07478656619787216, "critic_grad_norm": 0.01487638708204031, "ratio": 0.9999037981033325, "entropy": 0.6595202088356018, "incre_win_rate": 0.9574468085106383, "step": 3039}
{"time": 1767345371.6836462, "phase": "train", "update": 3040, "total_env_steps": 9728000, "episode_reward": 0.2934095561504364, "value_loss": 0.0019579166546463966, "policy_loss": -0.0014353775481183106, "dist_entropy": 0.6735517978668213, "actor_grad_norm": 0.07886426150798798, "critic_grad_norm": 0.030878329649567604, "ratio": 1.000252604484558, "entropy": 0.6735517978668213, "incre_win_rate": 0.9782608695652174, "step": 3040}
{"time": 1767345375.847511, "phase": "train", "update": 3041, "total_env_steps": 9731200, "episode_reward": 0.29100680351257324, "value_loss": 0.003396048862487078, "policy_loss": -0.0012016440685026276, "dist_entropy": 0.6603050470352173, "actor_grad_norm": 0.06348422914743423, "critic_grad_norm": 0.023459414020180702, "ratio": 0.9998319745063782, "entropy": 0.6603050470352173, "incre_win_rate": 0.9361702127659575, "step": 3041}
{"time": 1767345379.9957032, "phase": "train", "update": 3042, "total_env_steps": 9734400, "episode_reward": 0.285932332277298, "value_loss": 0.003929942147806287, "policy_loss": -0.0010930812715585602, "dist_entropy": 0.6384958863258362, "actor_grad_norm": 0.07494980096817017, "critic_grad_norm": 0.01598603092133999, "ratio": 0.9998566508293152, "entropy": 0.6384958863258362, "incre_win_rate": 0.9574468085106383, "step": 3042}
{"time": 1767345384.1162302, "phase": "train", "update": 3043, "total_env_steps": 9737600, "episode_reward": 0.2870478332042694, "value_loss": 0.003670823620632291, "policy_loss": -0.0011797165730349946, "dist_entropy": 0.6483810424804688, "actor_grad_norm": 0.0898744985461235, "critic_grad_norm": 0.009693835861980915, "ratio": 0.9998802542686462, "entropy": 0.6483810424804688, "incre_win_rate": 0.9375, "step": 3043}
{"time": 1767345388.253896, "phase": "train", "update": 3044, "total_env_steps": 9740800, "episode_reward": 0.2851671278476715, "value_loss": 0.003789210692048073, "policy_loss": -0.0012153602245263072, "dist_entropy": 0.644280219078064, "actor_grad_norm": 0.08333933353424072, "critic_grad_norm": 0.014995013363659382, "ratio": 0.9999624490737915, "entropy": 0.644280219078064, "incre_win_rate": 0.9318181818181818, "step": 3044}
{"time": 1767345392.4256356, "phase": "train", "update": 3045, "total_env_steps": 9744000, "episode_reward": 0.29018574953079224, "value_loss": 0.00438609542325139, "policy_loss": -0.0010962688628341154, "dist_entropy": 0.6387672901153565, "actor_grad_norm": 0.07880250364542007, "critic_grad_norm": 0.013187638483941555, "ratio": 1.0000418424606323, "entropy": 0.6387672901153565, "incre_win_rate": 0.9591836734693877, "step": 3045}
{"time": 1767345396.5867097, "phase": "train", "update": 3046, "total_env_steps": 9747200, "episode_reward": 0.28516140580177307, "value_loss": 0.004655574634671211, "policy_loss": -0.0011461620150688746, "dist_entropy": 0.6414880990982056, "actor_grad_norm": 0.07517398148775101, "critic_grad_norm": 0.010993885807693005, "ratio": 1.0001949071884155, "entropy": 0.6414880990982056, "incre_win_rate": 0.9333333333333333, "step": 3046}
{"time": 1767345400.733655, "phase": "train", "update": 3047, "total_env_steps": 9750400, "episode_reward": 0.2864435315132141, "value_loss": 0.004148340411484241, "policy_loss": -0.0013992925535966094, "dist_entropy": 0.6591449022293091, "actor_grad_norm": 0.07538095861673355, "critic_grad_norm": 0.018961505964398384, "ratio": 0.9999740719795227, "entropy": 0.6591449022293091, "incre_win_rate": 0.9347826086956522, "step": 3047}
{"time": 1767345404.812079, "phase": "train", "update": 3048, "total_env_steps": 9753600, "episode_reward": 0.26360151171684265, "value_loss": 0.008032923750579356, "policy_loss": -0.000948261033045128, "dist_entropy": 0.6219505071640015, "actor_grad_norm": 0.0812220349907875, "critic_grad_norm": 0.06200925260782242, "ratio": 0.9996849894523621, "entropy": 0.6219505071640015, "incre_win_rate": 0.7954545454545454, "step": 3048}
{"time": 1767345409.0922382, "phase": "train", "update": 3049, "total_env_steps": 9756800, "episode_reward": 0.2830779254436493, "value_loss": 0.005277576483786106, "policy_loss": -0.0009011206474170308, "dist_entropy": 0.6436754941940308, "actor_grad_norm": 0.07377471774816513, "critic_grad_norm": 0.05609320476651192, "ratio": 1.0001726150512695, "entropy": 0.6436754941940308, "incre_win_rate": 0.9787234042553191, "step": 3049}
{"time": 1767345413.2247362, "phase": "train", "update": 3050, "total_env_steps": 9760000, "episode_reward": 0.28155216574668884, "value_loss": 0.004895276576280594, "policy_loss": -0.0011339358698293721, "dist_entropy": 0.6441606044769287, "actor_grad_norm": 0.0734483078122139, "critic_grad_norm": 0.04094495624303818, "ratio": 0.9999702572822571, "entropy": 0.6441606044769287, "incre_win_rate": 0.9148936170212766, "step": 3050}
{"time": 1767345417.367597, "phase": "train", "update": 3051, "total_env_steps": 9763200, "episode_reward": 0.28437861800193787, "value_loss": 0.004604971222579479, "policy_loss": -0.0009120049494399041, "dist_entropy": 0.6381051659584045, "actor_grad_norm": 0.07060166448354721, "critic_grad_norm": 0.036489084362983704, "ratio": 0.9997382164001465, "entropy": 0.6381051659584045, "incre_win_rate": 0.9111111111111111, "step": 3051}
{"time": 1767345426.7448275, "phase": "eval", "update": 3051, "total_env_steps": 9763200, "eval_win_rate": 1.0, "eval_episode_reward": 20.0, "step": 3051}
{"time": 1767345430.943494, "phase": "train", "update": 3052, "total_env_steps": 9766400, "episode_reward": 0.29383692145347595, "value_loss": 0.003933966811746359, "policy_loss": -0.0013286092456889164, "dist_entropy": 0.6615390539169311, "actor_grad_norm": 0.08502944558858871, "critic_grad_norm": 0.03806152567267418, "ratio": 0.9999514818191528, "entropy": 0.6615390539169311, "incre_win_rate": 0.9787234042553191, "step": 3052}
{"time": 1767345435.0768318, "phase": "train", "update": 3053, "total_env_steps": 9769600, "episode_reward": 0.28842663764953613, "value_loss": 0.003421893622726202, "policy_loss": -0.0010313756362627657, "dist_entropy": 0.6412723779678344, "actor_grad_norm": 0.07206617295742035, "critic_grad_norm": 0.01456404384225607, "ratio": 0.9998461604118347, "entropy": 0.6412723779678344, "incre_win_rate": 0.9574468085106383, "step": 3053}
{"time": 1767345439.2043, "phase": "train", "update": 3054, "total_env_steps": 9772800, "episode_reward": 0.28577038645744324, "value_loss": 0.004299129731953144, "policy_loss": -0.0010886654148256735, "dist_entropy": 0.6264275074005127, "actor_grad_norm": 0.07950135320425034, "critic_grad_norm": 0.029298944398760796, "ratio": 1.000193476676941, "entropy": 0.6264275074005127, "incre_win_rate": 0.9361702127659575, "step": 3054}
{"time": 1767345443.3017926, "phase": "train", "update": 3055, "total_env_steps": 9776000, "episode_reward": 0.291761189699173, "value_loss": 0.0044292151927947995, "policy_loss": -0.0009620297884161743, "dist_entropy": 0.6326964378356934, "actor_grad_norm": 0.06669323891401291, "critic_grad_norm": 0.01469369512051344, "ratio": 0.9997346997261047, "entropy": 0.6326964378356934, "incre_win_rate": 0.9361702127659575, "step": 3055}
{"time": 1767345447.425141, "phase": "train", "update": 3056, "total_env_steps": 9779200, "episode_reward": 0.29355543851852417, "value_loss": 0.002901690313592553, "policy_loss": -0.0014130468955144693, "dist_entropy": 0.6428079605102539, "actor_grad_norm": 0.078348807990551, "critic_grad_norm": 0.013859517872333527, "ratio": 0.999862790107727, "entropy": 0.6428079605102539, "incre_win_rate": 0.9795918367346939, "step": 3056}
{"time": 1767345451.5872445, "phase": "train", "update": 3057, "total_env_steps": 9782400, "episode_reward": 0.29008278250694275, "value_loss": 0.0028658044058829544, "policy_loss": -0.0013920237170395922, "dist_entropy": 0.637320590019226, "actor_grad_norm": 0.07602528482675552, "critic_grad_norm": 0.023266447708010674, "ratio": 0.9997698068618774, "entropy": 0.637320590019226, "incre_win_rate": 1.0, "step": 3057}
{"time": 1767345455.7496314, "phase": "train", "update": 3058, "total_env_steps": 9785600, "episode_reward": 0.2893899977207184, "value_loss": 0.0033114705234766006, "policy_loss": -0.0009252601676678296, "dist_entropy": 0.6338173866271972, "actor_grad_norm": 0.07420436292886734, "critic_grad_norm": 0.01556910015642643, "ratio": 0.9999249577522278, "entropy": 0.6338173866271972, "incre_win_rate": 0.9782608695652174, "step": 3058}
{"time": 1767345459.8949127, "phase": "train", "update": 3059, "total_env_steps": 9788800, "episode_reward": 0.2810637354850769, "value_loss": 0.005118511617183685, "policy_loss": -0.0011999015572358828, "dist_entropy": 0.6343706488609314, "actor_grad_norm": 0.082435242831707, "critic_grad_norm": 0.03736799582839012, "ratio": 1.0000208616256714, "entropy": 0.6343706488609314, "incre_win_rate": 0.9333333333333333, "step": 3059}
{"time": 1767345464.0130286, "phase": "train", "update": 3060, "total_env_steps": 9792000, "episode_reward": 0.28475579619407654, "value_loss": 0.0032817103900015356, "policy_loss": -0.0014393097501856134, "dist_entropy": 0.654663622379303, "actor_grad_norm": 0.0694628581404686, "critic_grad_norm": 0.027644315734505653, "ratio": 0.9995861053466797, "entropy": 0.654663622379303, "incre_win_rate": 0.9782608695652174, "step": 3060}
{"time": 1767345468.150979, "phase": "train", "update": 3061, "total_env_steps": 9795200, "episode_reward": 0.2844076156616211, "value_loss": 0.0031976875849068164, "policy_loss": -0.0016286109303635498, "dist_entropy": 0.6642762780189514, "actor_grad_norm": 0.08645394444465637, "critic_grad_norm": 0.024743665009737015, "ratio": 0.9997382164001465, "entropy": 0.6642762780189514, "incre_win_rate": 0.9787234042553191, "step": 3061}
{"time": 1767345472.2991302, "phase": "train", "update": 3062, "total_env_steps": 9798400, "episode_reward": 0.29671773314476013, "value_loss": 0.0017502096481621266, "policy_loss": -0.0013901260710053264, "dist_entropy": 0.6578699111938476, "actor_grad_norm": 0.08167671412229538, "critic_grad_norm": 0.02434002421796322, "ratio": 0.9997604489326477, "entropy": 0.6578699111938476, "incre_win_rate": 1.0, "step": 3062}
{"time": 1767345476.4609509, "phase": "train", "update": 3063, "total_env_steps": 9801600, "episode_reward": 0.2888162434101105, "value_loss": 0.0023863046895712613, "policy_loss": -0.001116540314652781, "dist_entropy": 0.650746488571167, "actor_grad_norm": 0.07848560810089111, "critic_grad_norm": 0.020105157047510147, "ratio": 1.0003525018692017, "entropy": 0.650746488571167, "incre_win_rate": 0.9782608695652174, "step": 3063}
{"time": 1767345480.6062949, "phase": "train", "update": 3064, "total_env_steps": 9804800, "episode_reward": 0.2791639268398285, "value_loss": 0.003202917892485857, "policy_loss": -0.0010716908522027779, "dist_entropy": 0.644683837890625, "actor_grad_norm": 0.07415176182985306, "critic_grad_norm": 0.017991742119193077, "ratio": 0.9999012351036072, "entropy": 0.644683837890625, "incre_win_rate": 0.9565217391304348, "step": 3064}
{"time": 1767345484.7168884, "phase": "train", "update": 3065, "total_env_steps": 9808000, "episode_reward": 0.2813410758972168, "value_loss": 0.004663094785064459, "policy_loss": -0.0016833957586030123, "dist_entropy": 0.6335825443267822, "actor_grad_norm": 0.08159275352954865, "critic_grad_norm": 0.014117139391601086, "ratio": 0.9999314546585083, "entropy": 0.6335825443267822, "incre_win_rate": 0.9333333333333333, "step": 3065}
{"time": 1767345488.919947, "phase": "train", "update": 3066, "total_env_steps": 9811200, "episode_reward": 0.2978435456752777, "value_loss": 0.0016580836148932577, "policy_loss": -0.0013064095890513272, "dist_entropy": 0.6541677594184876, "actor_grad_norm": 0.1007780060172081, "critic_grad_norm": 0.028815079480409622, "ratio": 0.9999759793281555, "entropy": 0.6541677594184876, "incre_win_rate": 1.0, "step": 3066}
{"time": 1767345493.0954165, "phase": "train", "update": 3067, "total_env_steps": 9814400, "episode_reward": 0.2936211824417114, "value_loss": 0.00209777532145381, "policy_loss": -0.0011343074094384066, "dist_entropy": 0.6511055111885071, "actor_grad_norm": 0.08263224363327026, "critic_grad_norm": 0.016455145552754402, "ratio": 0.9998891949653625, "entropy": 0.6511055111885071, "incre_win_rate": 0.9787234042553191, "step": 3067}
{"time": 1767345497.1961098, "phase": "train", "update": 3068, "total_env_steps": 9817600, "episode_reward": 0.2864280045032501, "value_loss": 0.004035339737311005, "policy_loss": -0.0015313653659580595, "dist_entropy": 0.6200782775878906, "actor_grad_norm": 0.08459652960300446, "critic_grad_norm": 0.022651640698313713, "ratio": 1.0002548694610596, "entropy": 0.6200782775878906, "incre_win_rate": 0.9565217391304348, "step": 3068}
{"time": 1767345501.3580105, "phase": "train", "update": 3069, "total_env_steps": 9820800, "episode_reward": 0.28683775663375854, "value_loss": 0.003741680923849344, "policy_loss": -0.0011470617075080014, "dist_entropy": 0.6156027555465698, "actor_grad_norm": 0.08149661868810654, "critic_grad_norm": 0.017368480563163757, "ratio": 1.000224232673645, "entropy": 0.6156027555465698, "incre_win_rate": 0.9347826086956522, "step": 3069}
{"time": 1767345505.4680882, "phase": "train", "update": 3070, "total_env_steps": 9824000, "episode_reward": 0.26813173294067383, "value_loss": 0.006149405334144831, "policy_loss": -0.0016066469410453976, "dist_entropy": 0.6338366150856019, "actor_grad_norm": 0.08434480428695679, "critic_grad_norm": 0.03041536919772625, "ratio": 1.0001450777053833, "entropy": 0.6338366150856019, "incre_win_rate": 0.9111111111111111, "step": 3070}
{"time": 1767345509.6699224, "phase": "train", "update": 3071, "total_env_steps": 9827200, "episode_reward": 0.2837526202201843, "value_loss": 0.0048547349870204926, "policy_loss": -0.0015137081905383099, "dist_entropy": 0.6297657251358032, "actor_grad_norm": 0.08110158145427704, "critic_grad_norm": 0.03297615796327591, "ratio": 1.0002771615982056, "entropy": 0.6297657251358032, "incre_win_rate": 0.9534883720930233, "step": 3071}
{"time": 1767345513.7932062, "phase": "train", "update": 3072, "total_env_steps": 9830400, "episode_reward": 0.2847723662853241, "value_loss": 0.005085870530456305, "policy_loss": -0.0015076064300870939, "dist_entropy": 0.6007506608963012, "actor_grad_norm": 0.09846346825361252, "critic_grad_norm": 0.03585128113627434, "ratio": 1.000299334526062, "entropy": 0.6007506608963012, "incre_win_rate": 0.9183673469387755, "step": 3072}
{"time": 1767345517.939091, "phase": "train", "update": 3073, "total_env_steps": 9833600, "episode_reward": 0.2832905650138855, "value_loss": 0.0048702767118811606, "policy_loss": -0.0007827263147707874, "dist_entropy": 0.618687653541565, "actor_grad_norm": 0.07773745059967041, "critic_grad_norm": 0.023852011188864708, "ratio": 1.0002365112304688, "entropy": 0.618687653541565, "incre_win_rate": 0.9347826086956522, "step": 3073}
{"time": 1767345522.0890403, "phase": "train", "update": 3074, "total_env_steps": 9836800, "episode_reward": 0.28513607382774353, "value_loss": 0.0040404429659247395, "policy_loss": -0.001067043462148831, "dist_entropy": 0.6274243593215942, "actor_grad_norm": 0.07929467409849167, "critic_grad_norm": 0.02325635962188244, "ratio": 1.0001558065414429, "entropy": 0.6274243593215942, "incre_win_rate": 0.9565217391304348, "step": 3074}
{"time": 1767345526.2708492, "phase": "train", "update": 3075, "total_env_steps": 9840000, "episode_reward": 0.2896026372909546, "value_loss": 0.004398819617927074, "policy_loss": -0.001061148651345789, "dist_entropy": 0.6371562600135803, "actor_grad_norm": 0.09034644067287445, "critic_grad_norm": 0.03156137093901634, "ratio": 0.9999760985374451, "entropy": 0.6371562600135803, "incre_win_rate": 0.9361702127659575, "step": 3075}
{"time": 1767345530.4679723, "phase": "train", "update": 3076, "total_env_steps": 9843200, "episode_reward": 0.28532129526138306, "value_loss": 0.006144340895116329, "policy_loss": -0.000838383723996472, "dist_entropy": 0.6429404735565185, "actor_grad_norm": 0.08188579231500626, "critic_grad_norm": 0.021992383524775505, "ratio": 0.9997838139533997, "entropy": 0.6429404735565185, "incre_win_rate": 0.9361702127659575, "step": 3076}
{"time": 1767345539.8080833, "phase": "eval", "update": 3076, "total_env_steps": 9843200, "eval_win_rate": 0.9375, "eval_episode_reward": 19.732512417218544, "step": 3076}
{"time": 1767345543.9671044, "phase": "train", "update": 3077, "total_env_steps": 9846400, "episode_reward": 0.28358447551727295, "value_loss": 0.004081871267408133, "policy_loss": -0.0010350411779398883, "dist_entropy": 0.6669039845466613, "actor_grad_norm": 0.08013700693845749, "critic_grad_norm": 0.020709121599793434, "ratio": 0.9998246431350708, "entropy": 0.6669039845466613, "incre_win_rate": 0.9574468085106383, "step": 3077}
{"time": 1767345548.1259267, "phase": "train", "update": 3078, "total_env_steps": 9849600, "episode_reward": 0.28746792674064636, "value_loss": 0.003362465649843216, "policy_loss": -0.0011965147063602189, "dist_entropy": 0.6554892063140869, "actor_grad_norm": 0.08458270132541656, "critic_grad_norm": 0.020364005118608475, "ratio": 0.9995757937431335, "entropy": 0.6554892063140869, "incre_win_rate": 0.9782608695652174, "step": 3078}
{"time": 1767345552.2808938, "phase": "train", "update": 3079, "total_env_steps": 9852800, "episode_reward": 0.2857140004634857, "value_loss": 0.0032976520713418724, "policy_loss": -0.0009629861965542829, "dist_entropy": 0.666454303264618, "actor_grad_norm": 0.08034797757863998, "critic_grad_norm": 0.015728136524558067, "ratio": 0.9998718500137329, "entropy": 0.666454303264618, "incre_win_rate": 0.9772727272727273, "step": 3079}
{"time": 1767345556.4208205, "phase": "train", "update": 3080, "total_env_steps": 9856000, "episode_reward": 0.2911517024040222, "value_loss": 0.002450437005609274, "policy_loss": -0.0015163450633703945, "dist_entropy": 0.6804105997085571, "actor_grad_norm": 0.09542535990476608, "critic_grad_norm": 0.03537359461188316, "ratio": 0.9998403787612915, "entropy": 0.6804105997085571, "incre_win_rate": 0.9574468085106383, "step": 3080}
{"time": 1767345560.5692723, "phase": "train", "update": 3081, "total_env_steps": 9859200, "episode_reward": 0.2844567596912384, "value_loss": 0.004656772781163454, "policy_loss": -0.0010896265484539925, "dist_entropy": 0.6445006012916565, "actor_grad_norm": 0.0797218605875969, "critic_grad_norm": 0.023040620610117912, "ratio": 0.9996744394302368, "entropy": 0.6445006012916565, "incre_win_rate": 0.9347826086956522, "step": 3081}
{"time": 1767345564.6979795, "phase": "train", "update": 3082, "total_env_steps": 9862400, "episode_reward": 0.2851547300815582, "value_loss": 0.003460179595276713, "policy_loss": -0.0009167651302661283, "dist_entropy": 0.647590720653534, "actor_grad_norm": 0.07483664900064468, "critic_grad_norm": 0.017825180664658546, "ratio": 1.0001808404922485, "entropy": 0.647590720653534, "incre_win_rate": 0.9565217391304348, "step": 3082}
{"time": 1767345568.8443947, "phase": "train", "update": 3083, "total_env_steps": 9865600, "episode_reward": 0.28896936774253845, "value_loss": 0.004131663450971245, "policy_loss": -0.0014385330040630252, "dist_entropy": 0.6556776285171508, "actor_grad_norm": 0.08443620800971985, "critic_grad_norm": 0.03633348271250725, "ratio": 0.9999580383300781, "entropy": 0.6556776285171508, "incre_win_rate": 1.0, "step": 3083}
{"time": 1767345573.0251555, "phase": "train", "update": 3084, "total_env_steps": 9868800, "episode_reward": 0.2923949956893921, "value_loss": 0.0025907221250236036, "policy_loss": -0.001144234699545521, "dist_entropy": 0.6451908707618713, "actor_grad_norm": 0.06634870916604996, "critic_grad_norm": 0.040700241923332214, "ratio": 1.0001167058944702, "entropy": 0.6451908707618713, "incre_win_rate": 0.9574468085106383, "step": 3084}
{"time": 1767345577.206783, "phase": "train", "update": 3085, "total_env_steps": 9872000, "episode_reward": 0.2939528226852417, "value_loss": 0.0029210862703621387, "policy_loss": -0.0011344530057300517, "dist_entropy": 0.6491861820220948, "actor_grad_norm": 0.06621794402599335, "critic_grad_norm": 0.025924427434802055, "ratio": 0.9997545480728149, "entropy": 0.6491861820220948, "incre_win_rate": 0.9791666666666666, "step": 3085}
{"time": 1767345581.3608325, "phase": "train", "update": 3086, "total_env_steps": 9875200, "episode_reward": 0.2863907516002655, "value_loss": 0.0033080685883760453, "policy_loss": -0.0013718667040357956, "dist_entropy": 0.6364514827728271, "actor_grad_norm": 0.07041916996240616, "critic_grad_norm": 0.02380409650504589, "ratio": 1.000123381614685, "entropy": 0.6364514827728271, "incre_win_rate": 0.9148936170212766, "step": 3086}
{"time": 1767345585.5469418, "phase": "train", "update": 3087, "total_env_steps": 9878400, "episode_reward": 0.29333198070526123, "value_loss": 0.003225520486012101, "policy_loss": -0.001511723364808404, "dist_entropy": 0.6420552134513855, "actor_grad_norm": 0.0833052322268486, "critic_grad_norm": 0.018768418580293655, "ratio": 0.9997396469116211, "entropy": 0.6420552134513855, "incre_win_rate": 0.9583333333333334, "step": 3087}
{"time": 1767345589.703381, "phase": "train", "update": 3088, "total_env_steps": 9881600, "episode_reward": 0.28358447551727295, "value_loss": 0.0036206678953021763, "policy_loss": -0.0012677323306295562, "dist_entropy": 0.6527565479278564, "actor_grad_norm": 0.0764361247420311, "critic_grad_norm": 0.03415264934301376, "ratio": 1.0000250339508057, "entropy": 0.6527565479278564, "incre_win_rate": 0.9761904761904762, "step": 3088}
{"time": 1767345593.8849835, "phase": "train", "update": 3089, "total_env_steps": 9884800, "episode_reward": 0.29036423563957214, "value_loss": 0.002751039993017912, "policy_loss": -0.00126308034841216, "dist_entropy": 0.6444643974304199, "actor_grad_norm": 0.0713639184832573, "critic_grad_norm": 0.0345580019056797, "ratio": 0.9997669458389282, "entropy": 0.6444643974304199, "incre_win_rate": 0.9591836734693877, "step": 3089}
{"time": 1767345598.0352123, "phase": "train", "update": 3090, "total_env_steps": 9888000, "episode_reward": 0.2893087863922119, "value_loss": 0.0031321375165134667, "policy_loss": -0.0012753956222510965, "dist_entropy": 0.6212655544281006, "actor_grad_norm": 0.07295309752225876, "critic_grad_norm": 0.02544349804520607, "ratio": 1.0002282857894897, "entropy": 0.6212655544281006, "incre_win_rate": 0.9777777777777777, "step": 3090}
{"time": 1767345602.2666674, "phase": "train", "update": 3091, "total_env_steps": 9891200, "episode_reward": 0.2846771478652954, "value_loss": 0.0037968602031469346, "policy_loss": -0.0008570118043753183, "dist_entropy": 0.6113550782203674, "actor_grad_norm": 0.061736494302749634, "critic_grad_norm": 0.021434184163808823, "ratio": 1.0001140832901, "entropy": 0.6113550782203674, "incre_win_rate": 0.9375, "step": 3091}
{"time": 1767345606.3816633, "phase": "train", "update": 3092, "total_env_steps": 9894400, "episode_reward": 0.2795483469963074, "value_loss": 0.006405778508633375, "policy_loss": -0.0009571134709851492, "dist_entropy": 0.5983489632606507, "actor_grad_norm": 0.059787821024656296, "critic_grad_norm": 0.048195403069257736, "ratio": 0.9997972846031189, "entropy": 0.5983489632606507, "incre_win_rate": 0.9166666666666666, "step": 3092}
{"time": 1767345610.6083038, "phase": "train", "update": 3093, "total_env_steps": 9897600, "episode_reward": 0.285125195980072, "value_loss": 0.005552223976701498, "policy_loss": -0.001289460774210127, "dist_entropy": 0.6338399171829223, "actor_grad_norm": 0.07338903099298477, "critic_grad_norm": 0.03540181368589401, "ratio": 0.999607503414154, "entropy": 0.6338399171829223, "incre_win_rate": 0.9333333333333333, "step": 3093}
{"time": 1767345614.766308, "phase": "train", "update": 3094, "total_env_steps": 9900800, "episode_reward": 0.2890480160713196, "value_loss": 0.0038374578580260277, "policy_loss": -0.0014377307116151261, "dist_entropy": 0.6094191312789917, "actor_grad_norm": 0.08556221425533295, "critic_grad_norm": 0.04625215753912926, "ratio": 0.9998248219490051, "entropy": 0.6094191312789917, "incre_win_rate": 0.9555555555555556, "step": 3094}
{"time": 1767345618.9347944, "phase": "train", "update": 3095, "total_env_steps": 9904000, "episode_reward": 0.2826143205165863, "value_loss": 0.007217555865645408, "policy_loss": -0.0012279527126018764, "dist_entropy": 0.5974240660667419, "actor_grad_norm": 0.0748361125588417, "critic_grad_norm": 0.04246054217219353, "ratio": 0.9999865889549255, "entropy": 0.5974240660667419, "incre_win_rate": 0.9148936170212766, "step": 3095}
{"time": 1767345623.1142232, "phase": "train", "update": 3096, "total_env_steps": 9907200, "episode_reward": 0.2898380756378174, "value_loss": 0.003269938984885812, "policy_loss": -0.000960920666189935, "dist_entropy": 0.6090389490127563, "actor_grad_norm": 0.07342038303613663, "critic_grad_norm": 0.041415292769670486, "ratio": 1.0002424716949463, "entropy": 0.6090389490127563, "incre_win_rate": 0.9574468085106383, "step": 3096}
{"time": 1767345627.2474003, "phase": "train", "update": 3097, "total_env_steps": 9910400, "episode_reward": 0.2938989996910095, "value_loss": 0.002295218035578728, "policy_loss": -0.0011704385097303315, "dist_entropy": 0.6124376654624939, "actor_grad_norm": 0.07988020777702332, "critic_grad_norm": 0.028652111068367958, "ratio": 0.9998685121536255, "entropy": 0.6124376654624939, "incre_win_rate": 0.9787234042553191, "step": 3097}
{"time": 1767345631.4048603, "phase": "train", "update": 3098, "total_env_steps": 9913600, "episode_reward": 0.28931447863578796, "value_loss": 0.004710735473781824, "policy_loss": -0.0011215060087508277, "dist_entropy": 0.6187713980674744, "actor_grad_norm": 0.07812872529029846, "critic_grad_norm": 0.03106851316988468, "ratio": 1.0000025033950806, "entropy": 0.6187713980674744, "incre_win_rate": 0.9375, "step": 3098}
{"time": 1767345635.583153, "phase": "train", "update": 3099, "total_env_steps": 9916800, "episode_reward": 0.29727232456207275, "value_loss": 0.0037462185602635143, "policy_loss": -0.0011198694225868166, "dist_entropy": 0.6281568169593811, "actor_grad_norm": 0.07902434468269348, "critic_grad_norm": 0.03100232593715191, "ratio": 0.9995753169059753, "entropy": 0.6281568169593811, "incre_win_rate": 1.0, "step": 3099}
{"time": 1767345639.7806172, "phase": "train", "update": 3100, "total_env_steps": 9920000, "episode_reward": 0.29463160037994385, "value_loss": 0.0035265177488327027, "policy_loss": -0.0011998716727738667, "dist_entropy": 0.62416090965271, "actor_grad_norm": 0.07278352230787277, "critic_grad_norm": 0.01908046565949917, "ratio": 0.9997404217720032, "entropy": 0.62416090965271, "incre_win_rate": 0.9787234042553191, "step": 3100}
{"time": 1767345643.9153318, "phase": "train", "update": 3101, "total_env_steps": 9923200, "episode_reward": 0.28776901960372925, "value_loss": 0.005920678190886974, "policy_loss": -0.0010657841091351373, "dist_entropy": 0.6095181822776794, "actor_grad_norm": 0.06841543316841125, "critic_grad_norm": 0.03454120084643364, "ratio": 0.9997342228889465, "entropy": 0.6095181822776794, "incre_win_rate": 0.9166666666666666, "step": 3101}
{"time": 1767345652.8887959, "phase": "eval", "update": 3101, "total_env_steps": 9923200, "eval_win_rate": 1.0, "eval_episode_reward": 20.000827814569536, "step": 3101}
{"time": 1767345657.0431051, "phase": "train", "update": 3102, "total_env_steps": 9926400, "episode_reward": 0.2923302948474884, "value_loss": 0.003529010433703661, "policy_loss": -0.0010288088106783278, "dist_entropy": 0.6257639646530151, "actor_grad_norm": 0.07007139921188354, "critic_grad_norm": 0.026418954133987427, "ratio": 0.9999086260795593, "entropy": 0.6257639646530151, "incre_win_rate": 0.9574468085106383, "step": 3102}
{"time": 1767345695.2224607, "phase": "train", "update": 3103, "total_env_steps": 9929600, "episode_reward": 0.28179219365119934, "value_loss": 0.057123041898012164, "policy_loss": -0.0014037067433420702, "dist_entropy": 0.6323280215263367, "actor_grad_norm": 0.08130047470331192, "critic_grad_norm": 0.2679206430912018, "ratio": 1.0000450611114502, "entropy": 0.6323280215263367, "incre_win_rate": 0.9487179487179487, "step": 3103}
{"time": 1767345699.3370588, "phase": "train", "update": 3104, "total_env_steps": 9932800, "episode_reward": 0.29453226923942566, "value_loss": 0.004554248554632068, "policy_loss": -0.0009391250347490221, "dist_entropy": 0.6078916788101196, "actor_grad_norm": 0.07001819461584091, "critic_grad_norm": 0.2094104290008545, "ratio": 1.000141978263855, "entropy": 0.6078916788101196, "incre_win_rate": 1.0, "step": 3104}
{"time": 1767345703.4422388, "phase": "train", "update": 3105, "total_env_steps": 9936000, "episode_reward": 0.2832139730453491, "value_loss": 0.004441523691639304, "policy_loss": -0.0013517498424775454, "dist_entropy": 0.6008395552635193, "actor_grad_norm": 0.07609477639198303, "critic_grad_norm": 0.1614164263010025, "ratio": 1.0002233982086182, "entropy": 0.6008395552635193, "incre_win_rate": 0.9787234042553191, "step": 3105}
{"time": 1767345707.5585449, "phase": "train", "update": 3106, "total_env_steps": 9939200, "episode_reward": 0.29227131605148315, "value_loss": 0.0036280613858252764, "policy_loss": -0.0014579871563142888, "dist_entropy": 0.6094875574111939, "actor_grad_norm": 0.08530622720718384, "critic_grad_norm": 0.10225393623113632, "ratio": 1.0000313520431519, "entropy": 0.6094875574111939, "incre_win_rate": 0.9782608695652174, "step": 3106}
{"time": 1767345711.7423365, "phase": "train", "update": 3107, "total_env_steps": 9942400, "episode_reward": 0.2926614284515381, "value_loss": 0.004405973386019469, "policy_loss": -0.0011246600187426736, "dist_entropy": 0.5840983748435974, "actor_grad_norm": 0.0744154080748558, "critic_grad_norm": 0.09896882623434067, "ratio": 0.9998894929885864, "entropy": 0.5840983748435974, "incre_win_rate": 0.9574468085106383, "step": 3107}
{"time": 1767345715.8408473, "phase": "train", "update": 3108, "total_env_steps": 9945600, "episode_reward": 0.28972941637039185, "value_loss": 0.00385606880299747, "policy_loss": -0.001417156025832611, "dist_entropy": 0.6148783087730407, "actor_grad_norm": 0.08071327954530716, "critic_grad_norm": 0.07335422188043594, "ratio": 0.9997673034667969, "entropy": 0.6148783087730407, "incre_win_rate": 0.9387755102040817, "step": 3108}
{"time": 1767345720.0114324, "phase": "train", "update": 3109, "total_env_steps": 9948800, "episode_reward": 0.2968558669090271, "value_loss": 0.00216316357254982, "policy_loss": -0.0013757856914828892, "dist_entropy": 0.6091634035110474, "actor_grad_norm": 0.08728527277708054, "critic_grad_norm": 0.05227632075548172, "ratio": 0.9998857378959656, "entropy": 0.6091634035110474, "incre_win_rate": 1.0, "step": 3109}
{"time": 1767345724.1396332, "phase": "train", "update": 3110, "total_env_steps": 9952000, "episode_reward": 0.29594317078590393, "value_loss": 0.003932708315551281, "policy_loss": -0.0011194594195530038, "dist_entropy": 0.5908897757530213, "actor_grad_norm": 0.0689164325594902, "critic_grad_norm": 0.04200892150402069, "ratio": 0.9998921751976013, "entropy": 0.5908897757530213, "incre_win_rate": 0.9591836734693877, "step": 3110}
{"time": 1767345728.2825127, "phase": "train", "update": 3111, "total_env_steps": 9955200, "episode_reward": 0.29827818274497986, "value_loss": 0.004459228087216616, "policy_loss": -0.001210576944662023, "dist_entropy": 0.6298839569091796, "actor_grad_norm": 0.08645101636648178, "critic_grad_norm": 0.0355878546833992, "ratio": 0.9998237490653992, "entropy": 0.6298839569091796, "incre_win_rate": 0.9782608695652174, "step": 3111}
{"time": 1767345732.4908328, "phase": "train", "update": 3112, "total_env_steps": 9958400, "episode_reward": 0.30016452074050903, "value_loss": 0.002989871380850673, "policy_loss": -0.0010985806030269884, "dist_entropy": 0.61181161403656, "actor_grad_norm": 0.07551825046539307, "critic_grad_norm": 0.024316532537341118, "ratio": 1.0000569820404053, "entropy": 0.61181161403656, "incre_win_rate": 0.9791666666666666, "step": 3112}
{"time": 1767345736.583346, "phase": "train", "update": 3113, "total_env_steps": 9961600, "episode_reward": 0.29343181848526, "value_loss": 0.0036005205940455197, "policy_loss": -0.00120442706485413, "dist_entropy": 0.5997331380844116, "actor_grad_norm": 0.08339124172925949, "critic_grad_norm": 0.04874027520418167, "ratio": 0.9994049072265625, "entropy": 0.5997331380844116, "incre_win_rate": 0.9791666666666666, "step": 3113}
{"time": 1767345740.7852657, "phase": "train", "update": 3114, "total_env_steps": 9964800, "episode_reward": 0.2969624400138855, "value_loss": 0.004403676930814981, "policy_loss": -0.0015386118239561597, "dist_entropy": 0.6172099828720092, "actor_grad_norm": 0.08392644673585892, "critic_grad_norm": 0.0341888964176178, "ratio": 1.000034213066101, "entropy": 0.6172099828720092, "incre_win_rate": 0.9166666666666666, "step": 3114}
{"time": 1767345744.911665, "phase": "train", "update": 3115, "total_env_steps": 9968000, "episode_reward": 0.291858434677124, "value_loss": 0.0038594964891672133, "policy_loss": -0.0015735456877180808, "dist_entropy": 0.603648042678833, "actor_grad_norm": 0.08048557490110397, "critic_grad_norm": 0.027302175760269165, "ratio": 1.0001634359359741, "entropy": 0.603648042678833, "incre_win_rate": 0.9791666666666666, "step": 3115}
{"time": 1767345749.0635583, "phase": "train", "update": 3116, "total_env_steps": 9971200, "episode_reward": 0.29280734062194824, "value_loss": 0.002929830504581332, "policy_loss": -0.0013612513597706765, "dist_entropy": 0.606070613861084, "actor_grad_norm": 0.0884130522608757, "critic_grad_norm": 0.017222708091139793, "ratio": 1.0001630783081055, "entropy": 0.606070613861084, "incre_win_rate": 0.9782608695652174, "step": 3116}
{"time": 1767345753.217226, "phase": "train", "update": 3117, "total_env_steps": 9974400, "episode_reward": 0.2941323220729828, "value_loss": 0.006166423950344324, "policy_loss": -0.0011769237400024225, "dist_entropy": 0.5911962985992432, "actor_grad_norm": 0.07644183933734894, "critic_grad_norm": 0.03455783799290657, "ratio": 0.9998378753662109, "entropy": 0.5911962985992432, "incre_win_rate": 0.9166666666666666, "step": 3117}
{"time": 1767345757.361983, "phase": "train", "update": 3118, "total_env_steps": 9977600, "episode_reward": 0.2834348976612091, "value_loss": 0.005967409629374742, "policy_loss": -0.0014389280065209898, "dist_entropy": 0.6038432121276855, "actor_grad_norm": 0.07888609170913696, "critic_grad_norm": 0.04722064360976219, "ratio": 0.9998804330825806, "entropy": 0.6038432121276855, "incre_win_rate": 0.8723404255319149, "step": 3118}
{"time": 1767345761.5270805, "phase": "train", "update": 3119, "total_env_steps": 9980800, "episode_reward": 0.2891887426376343, "value_loss": 0.006645650416612625, "policy_loss": -0.001113250209958494, "dist_entropy": 0.5938475728034973, "actor_grad_norm": 0.0920003205537796, "critic_grad_norm": 0.024696839973330498, "ratio": 0.9998733401298523, "entropy": 0.5938475728034973, "incre_win_rate": 0.8958333333333334, "step": 3119}
{"time": 1767345765.636345, "phase": "train", "update": 3120, "total_env_steps": 9984000, "episode_reward": 0.2913700342178345, "value_loss": 0.0058113780803978445, "policy_loss": -0.0011329503326741985, "dist_entropy": 0.5782590389251709, "actor_grad_norm": 0.08454623073339462, "critic_grad_norm": 0.03901341184973717, "ratio": 0.9998462796211243, "entropy": 0.5782590389251709, "incre_win_rate": 0.9777777777777777, "step": 3120}
{"time": 1767345769.8235235, "phase": "train", "update": 3121, "total_env_steps": 9987200, "episode_reward": 0.28449711203575134, "value_loss": 0.0060093442909419535, "policy_loss": -0.0009582969202831748, "dist_entropy": 0.5973878145217896, "actor_grad_norm": 0.08208337426185608, "critic_grad_norm": 0.04357665777206421, "ratio": 1.000175952911377, "entropy": 0.5973878145217896, "incre_win_rate": 0.9148936170212766, "step": 3121}
{"time": 1767345773.9841018, "phase": "train", "update": 3122, "total_env_steps": 9990400, "episode_reward": 0.29481375217437744, "value_loss": 0.0032472520601004363, "policy_loss": -0.0012540843755076026, "dist_entropy": 0.5785229206085205, "actor_grad_norm": 0.08811533451080322, "critic_grad_norm": 0.04831400141119957, "ratio": 1.000046730041504, "entropy": 0.5785229206085205, "incre_win_rate": 0.9791666666666666, "step": 3122}
{"time": 1767345778.111869, "phase": "train", "update": 3123, "total_env_steps": 9993600, "episode_reward": 0.2872645854949951, "value_loss": 0.00439837658777833, "policy_loss": -0.001328061100605993, "dist_entropy": 0.5687886595726013, "actor_grad_norm": 0.0818290039896965, "critic_grad_norm": 0.04051108658313751, "ratio": 1.0000096559524536, "entropy": 0.5687886595726013, "incre_win_rate": 0.9361702127659575, "step": 3123}
{"time": 1767345782.2769003, "phase": "train", "update": 3124, "total_env_steps": 9996800, "episode_reward": 0.2924715578556061, "value_loss": 0.005729911848902702, "policy_loss": -0.0015459366895267835, "dist_entropy": 0.6129013299942017, "actor_grad_norm": 0.07620634138584137, "critic_grad_norm": 0.0503569021821022, "ratio": 0.9999155402183533, "entropy": 0.6129013299942017, "incre_win_rate": 0.9565217391304348, "step": 3124}
{"time": 1767345786.3875763, "phase": "train", "update": 3125, "total_env_steps": 10000000, "episode_reward": 0.2877131700515747, "value_loss": 0.004518951382488012, "policy_loss": -0.0012824882822119466, "dist_entropy": 0.6034099340438843, "actor_grad_norm": 0.07072348892688751, "critic_grad_norm": 0.04266975447535515, "ratio": 1.0003693103790283, "entropy": 0.6034099340438843, "incre_win_rate": 0.9361702127659575, "step": 3125}
