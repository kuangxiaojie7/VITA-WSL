from __future__ import annotations

import argparse
import json
from pathlib import Path
from typing import Dict, List, Sequence

import matplotlib.pyplot as plt


def load_log(path: Path) -> List[Dict[str, float]]:
    data: List[Dict[str, float]] = []
    with path.open("r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            try:
                data.append(json.loads(line))
            except json.JSONDecodeError:
                continue
    if not data:
        raise ValueError(f"No valid JSON lines found in {path}")
    return data


def moving_average(values: List[float], window: int) -> List[float]:
    if window <= 1:
        return values
    smoothed: List[float] = []
    acc = 0.0
    for idx, val in enumerate(values):
        acc += val
        if idx >= window:
            acc -= values[idx - window]
            smoothed.append(acc / window)
        elif idx == window - 1:
            smoothed.append(acc / window)
    if len(smoothed) < len(values):
        padding = [smoothed[-1]] * (len(values) - len(smoothed))
        smoothed.extend(padding)
    return smoothed


def plot_metric(
    metric: str,
    runs: Sequence[Dict[str, object]],
    smooth: int,
    output_dir: Path | None,
) -> None:
    plt.figure(figsize=(10, 5))
    for run in runs:
        entries: List[Dict[str, float]] = run["entries"]  # type: ignore
        steps = [entry.get("step", idx + 1) for idx, entry in enumerate(entries)]
        values = [entry.get(metric) for entry in entries]
        if any(v is None for v in values):
            print(f"[WARN] '{metric}' missing in some entries for run {run['label']}, skipping.")
            continue
        smoothed = moving_average(values, smooth)
        plt.plot(steps, smoothed, label=f"{run['label']} (window={smooth})")
    plt.title(metric)
    plt.xlabel("Training Update")
    plt.ylabel(metric)
    plt.grid(True, alpha=0.3)
    plt.legend()
    plt.tight_layout()
    if output_dir:
        output_dir.mkdir(parents=True, exist_ok=True)
        out_path = output_dir / f"{metric}.png"
        plt.savefig(out_path, dpi=200)
        print(f"Saved {out_path}")
        plt.close()
    else:
        plt.show()


def main() -> None:
    parser = argparse.ArgumentParser(description="Plot metrics for multiple runs.")
    parser.add_argument(
        "--log-files",
        type=Path,
        nargs="+",
        required=True,
        help="One or more train.log paths (JSON lines).",
    )
    parser.add_argument(
        "--labels",
        type=str,
        nargs="*",
        help="Optional labels for each log file. Defaults to filename stem.",
    )
    parser.add_argument(
        "--metrics",
        type=str,
        default="episode_reward,policy_loss,value_loss",
        help="Comma-separated metric names to visualize.",
    )
    parser.add_argument("--smooth", type=int, default=10, help="Moving-average window size.")
    parser.add_argument(
        "--output-dir",
        type=Path,
        default=None,
        help="If provided, saves each metric figure to this directory.",
    )
    args = parser.parse_args()

    if args.labels and len(args.labels) != len(args.log_files):
        raise ValueError("Number of labels must match number of log files.")

    metrics = [m.strip() for m in args.metrics.split(",") if m.strip()]
    runs = []
    for idx, log_path in enumerate(args.log_files):
        entries = load_log(log_path)
        label = args.labels[idx] if args.labels else log_path.stem
        runs.append({"label": label, "entries": entries})

    for metric in metrics:
        plot_metric(metric, runs, max(1, args.smooth), args.output_dir)


if __name__ == "__main__":
    main()
